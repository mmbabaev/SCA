<td class="line srcData" title="W06-2403
Automatic Extraction Of Chinese Multiword Expressions With A Statistical Tool
Piao, Scott S. L.;Sun, Guangfan;Rayson, Paul;Yuan, Qi;">
</td>
Automatic
Extraction
of
Chinese
Multiword
Expressions
with
a
Statistical
Tool
Scott
S.L.
Piao
1
s.piao@lancaster.ac.uk
Guangfan
Sun
2
morgan2001_sun@sohu.com
Paul
Rayson
1
paul@comp.lancs.ac.uk
Qi
Yuan
2
yq@trans.ccidnet.com
1
UCREL
Computing
Department
Lancaster
University
Lancaster
,
UK
2
CIPOL
China
Centre
for
Information
Industry
Development
-LRB-
CCID
-RRB-
Beijing
,
China
Abstract
In
this
paper
,
we
report
on
our
experiment
to
extract
Chinese
multiword
expressions
from
corpus
resources
as
part
of
a
larger
research
effort
to
improve
a
machine
translation
-LRB-
MT
-RRB-
system
.
''
>
</td>
For
existing
MT
systems
,
the
issue
of
multiword
expression
-LRB-
MWE
-RRB-
identification
and
accurate
interpretation
from
source
to
target
language
remains
an
unsolved
problem
.
''
>
</td>
Our
initial
test
on
the
Chineseto-English
translation
functions
of
Systran
and
CCIDs
Huan-Yu-Tong
MT
systems
reveal
that
,
where
MWEs
are
involved
,
MT
tools
suffer
in
terms
of
both
comprehensibility
and
adequacy
of
the
translated
texts
.
''
>
</td>
For
MT
systems
to
become
of
further
practical
use
,
they
need
to
be
enhanced
with
MWE
processing
capability
.
''
>
</td>
As
part
of
our
study
towards
this
goal
,
we
test
and
evaluate
a
statistical
tool
,
which
was
developed
for
English
,
for
identifying
and
extracting
Chinese
MWEs
.
''
>
</td>
In
our
evaluation
,
the
tool
achieved
precisions
ranging
from
61.16
%
to
93.96
%
for
different
types
of
MWEs
.
''
>
</td>
Such
results
demonstrate
that
it
is
feasible
to
automatically
identify
many
Chinese
MWEs
using
our
tool
,
although
it
needs
further
improvement
.
''
>
</td>
1
Introduction
In
real-life
human
communication
,
meaning
is
often
conveyed
by
word
groups
,
or
meaning
groups
,
rather
than
by
single
words
.
''
>
</td>
Very
often
,
it
is
difficult
to
interpret
human
speech
word
by
word
.
''
>
</td>
Consequently
,
for
an
MT
system
,
it
is
important
to
identify
and
interpret
accurate
meaning
of
such
word
groups
,
or
multiword
expressions
-LRB-
MWE
hereafter
-RRB-
,
in
a
source
language
and
interpret
them
accurately
in
a
target
language
.
''
>
</td>
However
,
accurate
identification
and
interpretation
of
MWEs
still
remains
an
unsolved
problem
in
MT
research
.
''
>
</td>
In
this
paper
,
we
present
our
experiment
on
identifying
Chinese
MWEs
using
a
statistical
tool
for
MT
purposes
.
''
>
</td>
Here
,
by
multiword
expressions
,
we
refer
to
word
groups
whose
constituent
words
have
strong
collocational
relations
and
which
can
be
translated
in
the
target
language
into
stable
translation
equivalents
,
either
single
words
or
MWEs
,
e.g.
noun
phrases
,
prepositional
phrases
etc.
.
They
may
include
technical
terminology
in
specific
domains
as
well
as
more
general
fixed
expressions
and
idioms
.
''
>
</td>
Our
observations
found
that
existing
ChineseEnglish
MT
systems
can
not
satisfactorily
translate
MWEs
,
although
some
may
employ
a
machine-readable
bilingual
dictionary
of
idioms
.
''
>
</td>
Whereas
highly
compositional
MWEs
may
pose
a
trivial
challenge
to
human
speakers
for
interpretation
,
they
present
a
tough
challenge
for
fully
automatic
MT
systems
to
produce
even
remotely
fluent
translations
.
''
>
</td>
Therefore
,
in
our
context
,
we
expand
the
concept
of
MWE
to
include
those
compositional
ones
which
have
relatively
stable
identifiable
patterns
of
translations
in
the
target
language
.
''
>
</td>
By
way
of
illustration
of
the
challenge
,
we
experimented
with
simple
Chinese
sentences
containing
some
commonly-used
MWEs
in
SYSTRAN
-LRB-
http://www.systransoft.com/
-RRB-
and
Huan-Yu-Tong
-LRB-
HYT
henceforth
-RRB-
of
CCID
-LRB-
China
Centre
for
Information
Industry
Development
-RRB-
-LRB-
Sun
,
2004
-RRB-
.
''
>
</td>
The
former
is
one
of
the
most
efficient
MT
systems
today
,
claiming
to
be
the
leading
provider
of
the
worlds
most
scalable
and
modular
translation
architecture
,
while
the
latter
is
one
of
the
most
successful
MT
systems
in
China
.
''
>
</td>
Table
1
shows
the
result
,
where
SL
and
TL
denote
source
and
target
languages
respectively
As
shown
by
the
samples
,
such
17
highly
sophisticated
MT
tools
still
struggle
to
produce
adequate
English
sentences
Chinese
Sentences
English
-LRB-
Systran
-RRB-
English
-LRB-
HYT
-RRB-
nullnullnull
null
null
nullnull
This
afternoon
can
practice
a
ball
game
?
''
>
</td>
I
hope
not
to
be
able
.
''
>
</td>
Can
practise
a
ball
game
this
afternoon
?
''
>
</td>
I
hope
can
not
.
''
>
</td>
nullnull
null
null
null
null
You
may
not
such
do
,
let
us
pay
respectively
each
.
''
>
</td>
You
can
not
do
like
that
,
and
let
us
make
it
Dutch
.
''
>
</td>
null
null
null
nullnull
nullnullnull
Perhaps
does
not
have
the
means
to
let
you
sit
shares
a
table
,
did
you
mind
sits
separately
?
''
>
</td>
Perhaps
no
way
out
-LRB-
ly
-RRB-
let
you
sit
with
table
,
are
you
situated
between
not
mind
to
separate
to
sit
?
''
>
</td>
nullnull
null
null
null
Selects
the
milk
coffee
which
ices
.
''
>
</td>
Ice
breasts
coffee
take
is
selected
.
''
>
</td>
nullnullnullnull
null
null
null
null
Good
,
I
want
the
beer
,
again
comes
to
select
the
coffee
.
''
>
</td>
Alright
,
I
want
beer
,
and
take
the
coffee
of
ordering
again
.
''
>
</td>
Table
1
:
Samples
of
Chinese-to-English
translations
of
Systran
and
HYT
.
''
>
</td>
Ignoring
the
eccentric
English
syntactic
structures
these
tools
produced
,
we
focus
on
the
translations
of
Chinese
MWEs
-LRB-
see
the
italic
characters
in
the
Table
1
-RRB-
which
have
straightforward
expression
equivalents
in
English
.
''
>
</td>
For
example
,
in
this
context
,
can
be
translated
into
hope
not
,
into
go
Dutch
,
into
together
or
at
the
same
table
,
into
white
coffee
or
coffee
with
milk
,
into
want
some
more
-LRB-
in
addition
to
something
already
ordered
-RRB-
.
''
>
</td>
While
these
Chinese
MWEs
are
highly
compositional
ones
,
when
they
are
translated
word
by
word
,
we
see
verbose
and
awkward
translations
-LRB-
for
correct
translations
,
see
the
appendix
-RRB-
.
''
>
</td>
To
solve
such
problems
,
we
need
algorithms
and
tools
for
identifying
MWEs
in
the
source
language
-LRB-
Chinese
in
this
case
-RRB-
and
to
accurately
map
them
to
their
adequate
translation
equivalents
in
the
target
language
-LRB-
English
in
our
case
-RRB-
that
are
appropriate
for
given
contexts
.
''
>
</td>
In
the
previous
examples
,
an
MT
tool
should
be
able
to
identify
the
Chinese
MWE
and
either
provide
the
literal
translation
of
pay
for
each
or
map
it
to
the
more
idomatic
expressions
of
go
Dutch
.
''
>
</td>
Obviously
,
it
would
involve
a
wide
range
of
issues
and
techniques
for
a
satisfactory
solution
to
this
problem
.
''
>
</td>
In
this
paper
,
we
focus
on
the
sub-issue
of
automatically
recognising
and
extracting
Chinese
MWEs
.
''
>
</td>
Specifically
,
we
test
and
evaluate
a
statistical
tool
for
automatic
MWE
extraction
in
Chinese
corpus
data
.
''
>
</td>
As
the
results
of
our
experiment
demonstrate
,
the
tool
is
capable
of
identifying
many
MWEs
with
little
language-specific
knowledge
.
''
>
</td>
Coupled
with
an
MT
system
,
such
a
tool
could
be
useful
for
addressing
the
MWE
issue
.
''
>
</td>
2
Related
Work
The
issue
of
MWE
processing
has
attracted
much
attention
from
the
Natural
Language
Processing
-LRB-
NLP
-RRB-
community
,
including
Smadja
,
1993
;
Dagan
and
Church
,
1994
;
Daille
,
1995
;
1995
;
McEnery
et
al.
,
1997
;
Wu
,
1997
;
Michiels
and
Dufour
,
1998
;
Maynard
and
Ananiadou
,
2000
;
Merkel
and
Andersson
,
2000
;
Piao
and
McEnery
,
2001
;
Sag
et
al.
,
2001
;
Tanaka
and
Baldwin
,
2003
;
Dias
,
2003
;
Baldwin
et
al.
,
2003
;
Nivre
and
Nilsson
,
2004
Pereira
et
al
,
.
''
>
</td>
2004
;
Piao
et
al.
,
2005
.
''
>
</td>
Study
in
this
area
covers
a
wide
range
of
sub-issues
,
including
MWE
identification
and
extraction
from
monolingual
and
multilingual
corpora
,
classification
of
MWEs
according
to
a
variety
of
viewpoints
such
as
types
,
compositionality
and
alignment
of
MWEs
across
different
languages
.
''
>
</td>
However
studies
in
this
area
on
Chinese
language
are
limited
.
''
>
</td>
A
number
of
approaches
have
been
suggested
,
including
rule-based
and
statistical
approaches
,
and
have
achieved
success
to
various
extents
.
''
>
</td>
Despite
this
research
,
however
,
MWE
processing
still
presents
a
tough
challenge
,
and
it
has
been
receiving
increasing
attention
,
as
exemplified
by
recent
MWE-related
ACL
workshops
.
''
>
</td>
Directly
related
to
our
work
is
the
development
of
a
statistical
MWE
tool
at
Lancaster
for
searching
and
identifying
English
MWEs
in
running
text
-LRB-
Piao
et
al.
,
2003
,
2005
-RRB-
.
''
>
</td>
Trained
on
corpus
data
in
a
given
domain
or
genre
,
this
tool
can
automatically
identify
MWEs
in
running
text
or
extract
MWEs
from
corpus
data
from
the
similar
domain/genre
-LRB-
see
further
information
about
this
tool
in
section
3.1
-RRB-
.
''
>
</td>
It
has
been
tested
and
compared
with
an
English
semantic
tagger
-LRB-
Rayson
et
al.
,
2004
-RRB-
and
was
found
to
be
efficient
in
identifying
domain-specific
MWEs
in
English
corpora
,
and
complementary
to
the
se18
mantic
tagger
which
relies
on
a
large
manually
compiled
lexicon
.
''
>
</td>
Other
directly
related
work
includes
the
development
of
the
HYT
MT
system
at
CCID
in
Beijing
,
China
.
''
>
</td>
It
has
been
under
development
since
1991
-LRB-
Sun
,
2004
-RRB-
and
it
is
one
of
the
most
successful
MT
systems
in
China
.
''
>
</td>
However
,
being
a
mainly
rule-based
system
,
its
performance
degrades
when
processing
texts
from
domains
previously
unknown
to
its
knowledge
database
.
''
>
</td>
Recently
a
corpus-based
approach
has
been
adopted
for
its
improvement
,
and
efforts
are
being
made
to
improve
its
capability
of
processing
MWEs
.
''
>
</td>
Our
main
interest
in
this
study
is
in
the
application
of
a
MWE
identification
tool
to
the
improvement
of
MT
system
.
''
>
</td>
As
far
as
we
know
,
there
has
not
been
a
satisfactory
solution
to
the
efficient
handling
of
Chinese
MWEs
in
MT
systems
,
and
our
experiment
contributes
to
a
deeper
understanding
of
this
problem
.
''
>
</td>
3
Automatic
Identification
and
extraction
of
Chinese
MWEs
In
order
to
test
the
feasibility
of
automatic
identification
and
extraction
of
Chinese
MWEs
on
a
large
scale
,
we
used
an
existing
statistical
tool
built
for
English
and
a
Chinese
corpus
built
at
CCID
.
''
>
</td>
A
CCID
tool
is
used
for
tokenizing
and
POS-tagging
the
Chinese
corpus
.
''
>
</td>
The
result
was
thoroughly
manually
checked
by
Chinese
experts
at
CCID
.
''
>
</td>
In
this
paper
,
we
aim
to
evaluate
this
existing
tool
from
two
perspectives
a
-RRB-
its
performance
on
MWE
extraction
,
and
b
-RRB-
its
performance
on
a
language
other
than
English
.
''
>
</td>
In
the
following
sections
,
we
describe
our
experiment
in
detail
and
discuss
main
issues
that
arose
during
the
course
of
our
experiment
.
''
>
</td>
3.1
MWE
extraction
tool
The
tool
we
used
for
the
experiment
exploits
statistical
collocational
information
between
near-context
words
-LRB-
Piao
et
al.
,
2005
-RRB-
.
''
>
</td>
It
first
collects
collocates
within
a
given
scanning
window
,
and
then
searches
for
MWEs
using
the
collocational
information
as
a
statistical
dictionary
.
''
>
</td>
As
the
collocational
information
can
be
extracted
on
the
fly
from
the
corpus
to
be
processed
for
a
reasonably
large
corpus
,
this
process
is
fully
automatic
.
''
>
</td>
To
search
for
MWEs
in
a
small
corpus
,
such
as
a
few
sentences
,
the
tool
needs
to
be
trained
on
other
corpus
data
in
advance
.
''
>
</td>
With
regards
to
the
statistical
measure
of
collocation
,
the
option
of
several
formulae
are
available
,
including
mutual
information
and
log
likelihood
,
etc.
.
Our
past
experience
shows
that
log-likelihood
provides
an
efficient
metric
for
corpus
data
of
moderate
sizes
.
''
>
</td>
Therefore
it
is
used
in
our
experiment
.
''
>
</td>
It
is
calculated
as
follows
-LRB-
Scott
,
2001
-RRB-
.
''
>
</td>
For
a
given
pair
of
words
X
and
Y
and
a
search
window
W
,
let
a
be
the
number
of
windows
in
which
X
and
Y
co-occur
,
let
b
be
the
number
of
windows
in
which
only
X
occurs
,
let
c
be
the
number
of
windows
in
which
only
Y
occurs
,
and
let
d
be
the
number
of
windows
in
which
none
of
them
occurs
,
then
G
2
=
2
-LRB-
alna
+
blnb
+
clnc
+
dlnd
-LRB-
a
+
b
-RRB-
ln
-LRB-
a
+
b
-RRB-
-LRB-
a
+
c
-RRB-
ln
-LRB-
a
+
c
-RRB-
-LRB-
b
+
d
-RRB-
ln
-LRB-
b
+
d
-RRB-
-LRB-
c
+
d
-RRB-
ln
-LRB-
c
+
d
-RRB-
-RRB-
+
-LRB-
a
+
b
+
c
+
d
-RRB-
ln
-LRB-
a
+
b
+
c
+
d
-RRB-
-RRB-
In
addition
to
the
log-likelihood
,
the
t-score
is
used
to
filter
out
insignificant
co-occurrence
word
pairs
-LRB-
Fung
and
Church
,
1994
-RRB-
,
which
is
calculated
as
follows
:
-RRB-
,
-LRB-
1
-RRB-
-LRB-
-RRB-
-LRB-
-RRB-
,
-LRB-
ba
baba
WWprob
M
WprobWprobWWprob
t
=
In
order
to
filter
out
weak
collocates
,
a
threshold
is
often
used
,
i.e.
in
the
stage
of
collocation
extraction
,
any
pairs
of
items
producing
word
affinity
scores
lower
than
a
given
threshold
are
excluded
from
the
MWE
searching
process
.
''
>
</td>
Furthermore
,
in
order
to
avoid
the
noise
caused
by
functional
words
and
some
extremely
frequent
words
,
a
stop
word
list
is
used
to
filter
such
words
out
from
the
process
.
''
>
</td>
If
the
corpus
data
is
POS-tagged
,
some
simple
POS
patterns
can
be
used
to
filter
certain
syntactic
patterns
from
the
candidates
.
''
>
</td>
It
can
either
be
implemented
as
an
internal
part
of
the
process
,
or
as
a
post-process
.
''
>
</td>
In
our
case
,
such
pattern
filters
are
mostly
applied
to
the
output
of
the
MWE
searching
tool
in
order
to
allow
the
tool
to
be
language-independent
as
much
as
possible
.
''
>
</td>
Consequently
,
for
our
experiment
,
the
major
adjustment
to
the
tool
was
to
add
a
Chinese
stop
word
list
.
''
>
</td>
Because
the
tool
is
based
on
Unicode
,
the
stop
words
of
different
languages
can
be
kept
in
a
single
file
,
avoiding
any
need
for
adjusting
the
program
itself
.
''
>
</td>
Unless
different
languages
involved
happen
to
share
words
with
the
same
form
,
this
practice
is
safe
and
reliable
.
''
>
</td>
In
our
particular
case
,
because
we
are
dealing
with
English
and
Chinese
,
which
use
widely
different
characters
,
such
a
practice
performs
well
.
''
>
</td>
19
Another
language-specific
adjustment
needed
was
to
use
a
Chinese
POS-pattern
filter
for
selecting
various
patterns
of
the
candidate
MWEs
-LRB-
see
Table
6
-RRB-
.
''
>
</td>
As
pointed
out
previously
,
it
was
implemented
as
a
simple
pattern-matching
program
that
is
separate
from
the
MWE
tool
itself
,
hence
minimizing
the
modification
needed
for
porting
the
tool
from
English
to
Chinese
language
.
''
>
</td>
A
major
advantage
of
this
tool
is
its
capability
of
identifying
MWEs
of
various
lengths
which
are
generally
representative
of
the
given
topic
or
domain
.
''
>
</td>
Furthermore
,
for
English
it
was
found
effective
in
extracting
domain-specific
multiword
terms
and
expressions
which
are
not
included
in
manually
compiled
lexicons
and
dictionaries
.
''
>
</td>
Indeed
,
due
to
the
open-ended
nature
of
such
MWEs
,
any
manually
compiled
lexicons
,
however
large
they
may
be
,
are
unlikely
to
cover
them
exhaustively
.
''
>
</td>
It
is
also
efficient
in
finding
newly
emerging
MWEs
,
particularly
technical
terms
,
that
reflect
the
changes
in
the
real
world
.
''
>
</td>
3.2
Experiment
In
this
experiment
,
our
main
aim
was
to
examine
the
feasibility
of
practical
application
of
the
MWE
tool
as
a
component
of
an
MT
system
,
therefore
we
used
test
data
from
some
domains
in
which
translation
services
are
in
strong
demand
.
''
>
</td>
We
selected
Chinese
corpus
data
of
approximately
696,000
tokenised
words
-LRB-
including
punctuation
marks
-RRB-
which
cover
the
topics
of
food
,
transportation
,
tourism
,
sports
-LRB-
including
the
Olympics
-RRB-
and
business
.
''
>
</td>
In
our
experiment
,
we
processed
the
texts
from
different
topics
together
.
''
>
</td>
These
topics
are
related
to
each
other
under
the
themes
of
entertainment
and
business
.
''
>
</td>
Therefore
we
assume
,
by
mixing
the
data
together
,
we
could
examine
the
performance
of
the
MWE
tool
in
processing
data
from
a
broad
range
of
related
domains
.
''
>
</td>
We
expect
that
the
different
features
of
texts
from
different
domains
will
have
a
certain
impact
on
the
result
,
but
the
examination
of
such
impact
is
beyond
the
scope
of
this
paper
.
''
>
</td>
As
mentioned
earlier
,
the
Chinese
word
tokeniser
and
POS
tagger
used
in
our
experiment
has
been
developed
at
CCID
.
''
>
</td>
It
is
an
efficient
tool
running
with
accuracy
of
98
%
for
word
tokenisation
and
95
%
for
POS
annotation
.
''
>
</td>
It
employs
a
part-of-speech
tagset
of
15
categories
shown
in
Table
2
.
''
>
</td>
Although
it
is
not
a
finely
grained
tagset
,
it
meets
the
need
for
creating
POS
pattern
filters
for
MWE
extraction
.
''
>
</td>
N
Name
V
Verb
A
Adjective
F
Adverb
R
Pronoun
I
Preposition
J
Conjunction
U
Number
S
classifier
-LRB-
measure
word
-RRB-
G
Auxiliary
verb
E
Accessory
word
L
directional
noun
P
Punctuation
H
Onomatopoeia
X
Subject-predicate
phrase
Table
2
:
CCID
Chinese
tagset
Since
function
words
are
found
to
cause
noise
in
the
process
of
MWE
identification
,
a
Chinese
stop
list
was
collected
.
''
>
</td>
First
,
a
word
frequency
list
was
extracted
.
''
>
</td>
Next
,
the
top
items
were
considered
and
we
selected
70
closed
class
words
for
the
stop
word
list
.
''
>
</td>
When
the
program
searches
for
MWEs
,
such
words
are
ignored
.
''
>
</td>
The
threshold
of
word
affinity
strength
is
another
issue
to
be
addressed
.
''
>
</td>
In
this
experiment
,
we
used
log-likelihood
to
measure
the
strength
of
collocation
between
word
pairs
.
''
>
</td>
Generally
the
log-likelihood
score
of
6.6
-LRB-
p
<
0.01
or
99
%
confidence
-RRB-
is
recommended
as
the
threshold
-LRB-
Rayson
et
al.
,
2004
-RRB-
,
but
it
was
found
to
produce
too
many
false
candidates
in
our
case
.
''
>
</td>
Based
on
our
initial
trials
,
we
used
a
higher
threshold
of
30
,
i.e.
any
word
pairs
producing
log-likelihood
score
less
than
this
value
are
ignored
in
the
MWE
searching
process
.
''
>
</td>
Furthermore
,
for
the
sake
of
the
reliability
of
the
statistical
score
,
when
extracting
collocates
,
a
frequency
threshold
of
five
was
used
to
filter
out
low-frequency
words
,
i.e.
word
pairs
with
frequencies
less
than
five
were
ignored
.
''
>
</td>
An
interesting
issue
for
us
in
this
experiment
is
the
impact
of
the
length
of
collocation
searching
window
on
the
MWE
identification
.
''
>
</td>
For
this
purpose
,
we
tested
two
search
window
lengths
2
and
3
,
and
compared
the
results
obtained
by
using
them
.
''
>
</td>
Our
initial
hypothesis
was
that
the
shorter
window
length
may
produce
higher
precision
while
the
longer
window
length
may
sacrifice
precision
but
boost
the
MWE
coverage
.
''
>
</td>
The
output
of
the
tool
was
manually
checked
by
Chinese
experts
at
CCID
,
including
cross
checking
to
guarantee
the
reliability
of
the
results
.
''
>
</td>
There
were
some
MWE
candidates
on
which
disagreements
arose
.
''
>
</td>
In
such
cases
,
the
20
candidate
was
counted
as
false
.
''
>
</td>
Furthermore
,
in
order
to
estimate
the
recall
,
experts
manually
identified
MWEs
in
the
whole
test
corpus
,
so
that
the
output
of
the
automatic
tool
could
be
compared
against
it
.
''
>
</td>
In
the
following
section
,
we
present
a
detailed
report
on
our
evaluation
of
the
MWE
tool
.
''
>
</td>
3.3
Evaluation
We
first
evaluated
the
overall
precision
of
the
tool
.
''
>
</td>
A
total
of
7,142
MWE
candidates
-LRB-
types
-RRB-
were
obtained
for
window
lengths
of
2
,
of
which
4,915
were
accepted
as
true
MWEs
,
resulting
in
a
precision
of
68.82
%
.
''
>
</td>
On
the
other
hand
,
a
total
of
8,123
MWE
candidates
-LRB-
types
-RRB-
were
obtained
for
window
lengths
of
3
,
of
which
4,968
were
accepted
as
true
MWEs
,
resulting
in
a
precision
of
61.16
%
.
''
>
</td>
This
result
is
in
agreement
with
our
hypothesis
that
shorter
search
window
length
tends
to
produce
higher
precision
.
''
>
</td>
Next
,
we
estimated
the
recall
based
on
the
manually
analysed
data
.
''
>
</td>
When
we
compared
the
accepted
MWEs
from
the
automatic
result
against
the
manually
collected
ones
,
we
found
that
the
experts
tend
to
mark
longer
MWEs
,
which
often
contain
the
items
identified
by
the
automatic
tool
.
''
>
</td>
For
example
,
the
manually
marked
MWE
-LRB-
development
plan
for
the
tennis
sport
-RRB-
contains
shorter
MWEs
-LRB-
tennis
sport
-RRB-
and
-LRB-
development
plan
-RRB-
which
were
identified
by
the
tool
separately
.
''
>
</td>
So
we
decided
to
take
the
partial
matches
into
account
when
we
estimate
the
recall
.
''
>
</td>
We
found
that
a
total
14,045
MWEs
were
manually
identified
and
,
when
the
search
window
length
was
set
to
two
and
three
,
1,988
and
2,044
of
them
match
the
automatic
output
,
producing
recalls
of
14.15
%
and
14.55
%
respectively
.
''
>
</td>
It
should
be
noted
that
many
of
the
manually
accepted
MWEs
from
the
automatic
output
were
not
found
in
the
manual
MWE
collection
.
''
>
</td>
This
discrepancy
was
likely
caused
by
the
manual
analysis
being
carried
out
independently
of
the
automatic
tool
,
resulting
in
a
lower
recall
than
expected
.
''
>
</td>
Table
3
lists
the
precisions
and
recalls
.
''
>
</td>
Window
length
=
2
Window
length
=
3
Precision
Recall
Precision
Recall
68.82
%
14.15
%
61.16
%
14.55
%
Table
3
:
Overall
precisions
and
recalls
Furthermore
,
we
evaluated
the
performance
of
the
MWE
tool
from
two
aspects
:
frequency
and
MWE
pattern
.
''
>
</td>
Generally
speaking
,
statistical
algorithms
work
better
on
items
of
higher
frequency
as
it
depends
on
the
collocational
information
.
''
>
</td>
However
,
our
tool
does
not
select
MWEs
directly
from
the
collocates
.
''
>
</td>
Rather
,
it
uses
the
collocational
information
as
a
statistical
dictionary
and
searches
for
word
sequences
whose
constituent
words
have
significantly
strong
collocational
bonds
between
them
.
''
>
</td>
As
a
result
,
it
is
capable
of
identifying
many
low-frequency
MWEs
.
''
>
</td>
Table
4
lists
the
breakdown
of
the
precision
for
five
frequency
bands
-LRB-
window
length
=
2
-RRB-
.
''
>
</td>
Freq
Candidates
True
MWEs
Precision
>
=
100
17
9
52.94
%
10
~
99 846 646
76.36
%
3
~
9
2,873
2,178
75.81
%
2
949
608
64.07
%
1
2,457
1,474
59.99
%
Total
7,142
4,915
68.82
%
Table
4
:
Breakdown
of
precision
for
frequencies
-LRB-
window
length
=
2
-RRB-
.
''
>
</td>
As
shown
in
the
table
above
,
the
highest
precisions
were
obtained
for
the
frequency
range
between
3
and
99
.
''
>
</td>
However
,
2,082
of
the
accepted
MWEs
have
frequencies
of
one
or
two
,
accounting
for
42.36
%
of
the
total
accepted
MWEs
.
''
>
</td>
Such
a
result
demonstrates
again
that
our
tool
is
capable
of
identifying
low-frequency
items
.
''
>
</td>
An
interesting
result
is
for
the
top
frequency
band
-LRB-
greater
than
100
-RRB-
.
''
>
</td>
Against
our
general
assumption
that
higher
frequency
brings
higher
precision
,
we
saw
the
lowest
precision
in
the
table
for
this
band
.
''
>
</td>
Our
manual
examination
reveals
this
was
caused
by
the
high
frequency
numbers
,
such
as
one
or
two
in
the
expressions
-LRB-
a/one
-RRB-
and
-LRB-
a
kind
of
-RRB-
.
''
>
</td>
This
type
of
expression
were
classified
as
uninteresting
candidates
in
the
manual
checking
,
resulting
in
higher
error
rates
for
the
high
frequency
band
.
''
>
</td>
When
we
carry
out
a
parallel
evaluation
for
the
case
of
searching
window
length
of
3
,
we
see
a
similar
distribution
of
precision
across
the
frequency
bands
except
that
the
lowest
frequency
band
has
the
lowest
precision
,
as
shown
by
Table
5
.
''
>
</td>
When
we
compare
this
table
against
Table
4
,
we
can
see
,
for
all
of
the
frequency
bands
except
the
top
one
,
that
the
precision
drops
as
the
search
window
increases
.
''
>
</td>
This
further
supports
our
earlier
assumption
that
wider
searching
window
tends
to
reduce
the
precision
.
''
>
</td>
21
Freq
candidates
true
MWEs
Precision
>
=
100
17
9
52.94
%
10
~
99 831 597
71.84
%
3
~
9
3,093
2,221
71.81
%
2
1,157
669
57.82
%
1
3,025
1,472
48.66
%
Total
8,123
4,968
61.16
%
Table
5
:
Breakdown
of
precision
for
frequencies
-LRB-
window
length
=
3
-RRB-
.
''
>
</td>
In
fact
,
not
only
the
top
frequency
band
,
much
of
the
errors
of
the
total
output
were
found
to
be
caused
by
the
numbers
that
frequently
occur
in
the
test
data
,
e.g.
_
U
_
S
-LRB-
one
-RRB-
,
_
U
_
S
-LRB-
two
-RRB-
etc.
.
When
a
POS
filter
was
used
to
filter
them
out
,
for
the
window
length
2
,
we
obtained
a
total
5,660
candidates
,
of
which
4,386
were
accepted
as
true
MWEs
,
producing
a
precision
of
77.49
%
.
''
>
</td>
Similarly
for
the
window
length
3
,
a
total
of
6,526
candidates
were
extracted
in
this
way
and
4,685
of
them
were
accepted
as
true
MWEs
,
yielding
a
precision
of
71.79
%
.
''
>
</td>
Another
factor
affecting
the
performance
of
the
tool
is
the
type
of
MWEs
.
''
>
</td>
In
order
to
examine
the
potential
impact
of
MWE
types
to
the
performance
of
the
tool
,
we
used
filters
to
select
MWEs
of
the
following
three
patterns
:
1
-RRB-
AN
:
Adjective
+
noun
structure
;
2
-RRB-
NN
:
Noun
+
noun
Structure
;
3
-RRB-
FV
:
Adverb
+
Verb
.
''
>
</td>
Table
6
lists
the
precision
for
each
of
the
MWE
types
and
for
search
window
lengths
of
2
and
3
.
''
>
</td>
Search
window
length
=
2
Pattern
Candidate
True
MWEs
Precision
A+N
236
221
93.64
%
N+N
644
589
91.46
%
F+V
345
321
93.04
%
total
1,225
1,131
92.33
%
Search
window
length
=
3
Pattern
Candidate
True
MWEs
Precision
A+N
259
233
89.96
%
N+N
712
635
89.19
%
F+V
381
358
93.96
%
Total
1,352
1,226
90.68
%
Table
6
:
Precisions
for
three
types
of
MWEs
As
shown
in
the
table
,
the
MWE
tool
achieved
high
precisions
above
91
%
when
we
use
a
search
window
of
two
words
.
''
>
</td>
Even
when
the
search
window
expands
to
three
words
,
the
tool
still
obtained
precision
around
90
%
.
''
>
</td>
In
particular
,
the
tool
is
efficient
for
the
verb
phrase
type
.
''
>
</td>
Such
a
result
demonstrates
that
,
when
we
constrain
the
search
algorithm
to
some
specific
types
of
MWEs
,
we
can
obtain
higher
precisions
.
''
>
</td>
While
one
may
argue
that
rule-based
parser
can
do
the
same
work
,
it
must
be
noted
that
we
are
not
interested
in
all
grammatical
phrases
,
but
those
which
reflect
the
features
of
the
given
domain
.
''
>
</td>
This
is
achieved
by
combining
statistical
word
collocation
measures
,
a
searching
strategy
and
simple
POS
pattern
filters
.
''
>
</td>
Another
interesting
finding
in
our
experiment
is
that
our
tool
extracted
clauses
,
such
as
-LRB-
What
would
you
like
to
drink
-RRB-
?
''
>
</td>
and
-LRB-
Would
you
like
a
drink
first
?
-RRB-
.
''
>
</td>
The
clauses
occur
only
once
or
twice
in
the
entire
test
data
,
but
were
recognized
by
the
tool
because
of
the
strong
collocational
bond
between
their
constituent
words
.
''
>
</td>
The
significance
of
such
performance
is
that
such
clauses
are
typical
expressions
which
are
frequently
used
in
real-life
conversation
in
the
contexts
of
the
canteen
,
tourism
etc.
.
Such
a
function
of
our
tool
may
have
practical
usage
in
automatically
collecting
longer
typical
expressions
for
the
given
domains
.
''
>
</td>
4
Discussion
As
our
experiment
demonstrates
,
our
tool
provides
a
practical
means
of
identifying
and
extracting
domain
specific
MWEs
with
a
minimum
amount
of
linguistic
knowledge
.
''
>
</td>
This
becomes
important
in
multilingual
tasks
in
which
it
can
be
costly
and
time
consuming
to
build
comprehensive
rules
for
several
languages
.
''
>
</td>
In
particular
,
it
is
capable
of
detecting
MWEs
of
various
lengths
,
sometimes
whole
clauses
,
which
are
often
typical
of
the
given
domains
of
the
corpus
data
.
''
>
</td>
For
example
,
in
our
experiment
,
the
tool
successfully
identified
several
daily
used
long
expressions
in
the
domain
of
food
and
tourism
.
''
>
</td>
MT
systems
often
suffer
when
translating
conversation
.
''
>
</td>
An
efficient
MWE
tool
can
potentially
alleviate
the
problem
by
extracting
typical
clauses
used
in
daily
life
and
mapping
them
to
adequate
translations
in
the
target
language
.
''
>
</td>
Despite
the
flexibility
of
the
statistical
tool
,
however
,
there
is
a
limit
to
its
performance
in
terms
of
precision
.
''
>
</td>
While
it
is
quite
efficient
in
providing
MWE
candidates
,
its
output
has
to
be
either
verified
by
human
or
refined
by
using
linguistic
rules
.
''
>
</td>
In
our
particular
case
,
we
improved
the
precision
of
our
tool
by
employing
simple
POS
pattern
filters
.
''
>
</td>
Another
limitation
of
this
tool
is
that
currently
it
can
only
recognise
continuous
MWEs
.
''
>
</td>
A
more
flexible
searching
algo22
rithm
is
needed
to
identify
discontinuous
MWEs
,
which
are
important
for
NLP
tasks
.
''
>
</td>
Besides
the
technical
problem
,
a
major
unresolved
issue
we
face
is
what
constitutes
MWEs
.
''
>
</td>
Despite
agreement
on
the
core
MWE
types
,
such
as
idioms
and
highly
idiosyncratic
expressions
,
like
-LRB-
Cheng-Yu
-RRB-
in
Chinese
,
it
is
difficult
to
reach
agreement
on
less
fixed
expressions
.
''
>
</td>
We
contend
that
MWEs
may
have
different
definitions
for
different
research
purposes
.
''
>
</td>
For
example
,
for
dictionary
compilation
,
lexicographers
tend
to
constrain
MWEs
to
highly
noncompositional
expressions
-LRB-
Moon
,
1998
:
18
-RRB-
.
''
>
</td>
This
is
because
monolingual
dictionary
users
can
easily
understand
compositional
MWEs
and
there
is
no
need
to
include
them
in
a
dictionary
for
native
speakers
.
''
>
</td>
For
lexicon
compilation
aimed
at
practical
NLP
tasks
,
however
,
we
may
apply
a
looser
definition
of
MWEs
.
''
>
</td>
For
example
,
in
the
Lancaster
semantic
lexicon
-LRB-
Rayson
et
al.
,
2004
-RRB-
,
compositional
word
groups
such
as
youth
club
are
considered
as
MWEs
alongside
non-compositional
expressions
such
as
food
for
thought
as
they
depict
single
semantic
units
or
concepts
.
''
>
</td>
Furthermore
,
for
the
MT
research
community
whose
primary
concern
is
crosslanguage
interpretation
,
any
multiword
units
that
have
stable
translation
equivalent
-LRB-
s
-RRB-
in
a
target
language
can
be
of
interest
.
''
>
</td>
As
we
discussed
earlier
,
a
highly
idiomatic
expression
in
a
language
can
be
translated
into
a
highly
compositional
expression
in
another
language
,
and
vice
versa
.
''
>
</td>
In
such
situations
,
it
can
be
more
practically
useful
to
identify
and
map
translation
equivalents
between
the
source
and
target
languages
regardless
of
their
level
of
compositionality
.
''
>
</td>
Finally
,
the
long
Chinese
clauses
identified
by
the
tool
can
potentially
be
useful
for
the
improvement
of
MT
systems
.
''
>
</td>
In
fact
,
most
of
them
are
colloquial
expressions
in
daily
conversation
,
and
many
such
Chinese
expressions
are
difficult
to
parse
syntactically
.
''
>
</td>
It
may
be
more
feasible
to
identify
such
expressions
and
map
them
as
a
whole
to
English
equivalent
expressions
.
''
>
</td>
The
same
may
apply
to
technical
terms
,
jargon
and
slang
.
''
>
</td>
In
our
experiment
,
our
tool
demonstrated
its
capability
of
detecting
such
expressions
,
and
will
prove
useful
in
this
regard
.
''
>
</td>
5
Conclusion
In
this
paper
,
we
have
reported
on
our
experiment
of
automatic
extraction
of
Chinese
MWEs
using
a
statistical
tool
originally
developed
for
English
.
''
>
</td>
Our
statistical
tool
produced
encouraging
results
,
although
further
improvement
is
needed
to
become
practically
applicable
for
MT
system
in
terms
of
recall
.
''
>
</td>
Indeed
,
for
some
constrained
types
of
MWEs
,
high
precisions
above
90
%
have
been
achieved
.
''
>
</td>
This
shows
,
enhanced
with
some
linguistic
filters
,
it
can
provide
a
practically
useful
tool
for
identifying
and
extracting
MWEs
.
''
>
</td>
Furthermore
,
in
our
experiment
,
our
tool
demonstrated
its
capability
of
multilingual
processing
.
''
>
</td>
With
only
minor
adjustment
,
it
can
be
ported
to
other
languages
.
''
>
</td>
Meanwhile
,
further
study
is
needed
for
a
fuller
understanding
of
the
factors
affecting
the
performance
of
statistical
tools
,
including
the
text
styles
and
topic/domains
of
the
texts
,
etc.
.
Acknowledgement
This
work
was
supported
by
the
National
Natural
Science
Foundation
of
China
-LRB-
grant
no.
60520130297
-RRB-
and
the
British
Academy
-LRB-
grant
no
.
''
>
</td>
SG-42140
-RRB-
.
''
>
</td>
References
Biber
,
D.
,
Conrad
,
S.
,
Cortes
,
V.
,
2003
.
''
>
</td>
Lexical
bundles
in
speech
and
writing
:
an
initial
taxonomy
.
''
>
</td>
In
:
Wilson
,
A.
,
Rayson
P.
,
McEnery
,
T.
''
>
</td>
-LRB-
Eds
.
-RRB-
,
Corpus
Linguistics
by
the
Lune
:
A
Festschrift
for
Geoffrey
Leech
.
''
>
</td>
Peter
Lang
,
Frankfurt
.
''
>
</td>
pp
.
''
>
</td>
71-92
.
''
>
</td>
Baldwin
,
T.
,
Bannard
,
C.
,
Tanaka
,
T.
and
Widdows
,
D.
2003
An
Empirical
Model
of
Multiword
Expression
Decomposability
,
In
Proceedings
of
the
ACL-2003
Workshop
on
Multiword
Expressions
:
Analysis
,
Acquisition
and
Treatment
,
Sapporo
,
Japan
,
pp
.
''
>
</td>
8996
.
''
>
</td>
Dagan
,
I.
,
Church
,
K.
,
1994
.
''
>
</td>
Termight
:
identifying
and
translating
technical
terminology
.
''
>
</td>
In
:
Proceedings
of
the
4th
Conference
on
Applied
Natural
Language
Processing
,
Stuttgart
,
German
.
''
>
</td>
pp
.
''
>
</td>
3440
.
''
>
</td>
Daille
,
B.
,
1995
.
''
>
</td>
Combined
approach
for
terminology
extraction
:
lexical
statistics
and
linguistic
filtering
.
''
>
</td>
Technical
paper
5
,
UCREL
,
Lancaster
University
.
''
>
</td>
Dias
,
G.
,
2003
.
''
>
</td>
Multiword
unit
hybrid
extraction
.
''
>
</td>
In
:
Proceedings
of
the
Workshop
on
Multiword
Expressions
:
Analysis
,
Acquisition
and
Treatment
,
at
ACL
'
03
,
Sapporo
,
Japan
.
''
>
</td>
pp
.
''
>
</td>
41-48
.
''
>
</td>
Dunning
,
T.
,
1993
.
''
>
</td>
Accurate
methods
for
the
statistics
of
surprise
and
coincidence
.
''
>
</td>
Computational
Linguistics
19
-LRB-
1
-RRB-
,
61-74
.
''
>
</td>
Fung
,
P.
,
Church
,
K.
,
1994
.
''
>
</td>
K-vec
:
a
new
approach
for
aligning
parallel
texts
.
''
>
</td>
In
:
Proceedings
of
COLING
'
94
,
Kyoto
,
Japan
.
''
>
</td>
pp
.
''
>
</td>
1996-2001
.
''
>
</td>
Maynard
,
D.
,
Ananiadou
,
S.
,
2000
.
''
>
</td>
Trucks
:
a
model
for
automatic
multiword
term
recognition
.
''
>
</td>
Journal
of
Natural
Language
Processing
8
-LRB-
1
-RRB-
,
101-126
.
''
>
</td>
McEnery
,
T.
,
Lange
,
J.
M.
,
Oakes
,
M.
,
Vernonis
,
J
,
1997
.
''
>
</td>
The
exploitation
of
multilingual
annotated
corpora
for
term
extraction
.
''
>
</td>
In
:
Garside
,
R.
,
Leech
,
G.
,
McEnery
,
A.
''
>
</td>
-LRB-
Eds
.
-RRB-
,
Corpus
Annotation
--
Linguistic
Information
from
Computer
Text
Corpora
.
''
>
</td>
Longman
,
London
&
New
York
.
''
>
</td>
pp
220230
.
''
>
</td>
Merkel
,
M.
,
Andersson
,
M.
,
2000
.
''
>
</td>
Knowledge-lite
extraction
of
multi-word
units
with
language
filters
and
entropy
thresholds
.
''
>
</td>
In
:
Proceedings
of
2000
Conference
User-Oriented
Content-Based
Text
and
Image
Handling
-LRB-
RIAO
'
00
-RRB-
,
Paris
,
France
.
''
>
</td>
pp
.
''
>
</td>
737746
.
''
>
</td>
Michiels
,
A.
,
Dufour
,
N.
,
1998
.
''
>
</td>
DEFI
,
a
tool
for
automatic
multi-word
unit
recognition
,
meaning
assignment
and
translation
selection
.
''
>
</td>
In
:
Proceedings
of
the
First
International
Conference
on
Language
Resources
&
Evaluation
,
Granada
,
Spain
.
''
>
</td>
pp
.
''
>
</td>
1179-1186
.
''
>
</td>
Moon
,
R.
1998
.
''
>
</td>
Fixed
expressions
and
idioms
in
English
:
a
corpus-based
approach
.
''
>
</td>
Clarendon
Press
:
Oxford
.
''
>
</td>
Nivre
,
J.
,
Nilsson
,
J.
,
2004
.
''
>
</td>
Multiword
units
in
syntactic
parsing
.
''
>
</td>
In
:
Proceedings
of
LREC-04
Workshop
on
Methodologies
&
Evaluation
of
Multiword
Units
in
Real-world
Applications
,
Lisbon
,
Portugal
.
''
>
</td>
pp
.
''
>
</td>
37-46
.
''
>
</td>
Pereira
,
R.
,
Crocker
,
P.
,
Dias
,
G.
,
2004
.
''
>
</td>
A
parallel
multikey
quicksort
algorithm
for
mining
multiword
units
.
''
>
</td>
In
:
Proceedings
of
LREC-04
Workshop
on
Methodologies
&
Evaluation
of
Multiword
Units
in
Real-world
Applications
,
Lisbon
,
Portugal
.
''
>
</td>
pp
.
''
>
</td>
1723
.
''
>
</td>
Piao
,
S.
L.
,
Rayson
,
P.
,
Archer
,
D.
and
McEnery
,
T.
2005
.
''
>
</td>
Comparing
and
Combining
A
Semantic
Tagger
and
A
Statistical
Tool
for
MWE
Extraction
.
''
>
</td>
Computer
Speech
&
Language
Volume
19
,
Issue
4
,
pp
.
''
>
</td>
378-397
.
''
>
</td>
Piao
,
S.L
,
Rayson
,
P.
,
Archer
,
D.
,
Wilson
,
A.
and
McEnery
,
T.
2003
.
''
>
</td>
Extracting
multiword
expressions
with
a
semantic
tagger
.
''
>
</td>
In
Proceedings
of
the
Workshop
on
Multiword
Expressions
:
Analysis
,
Acquisition
and
Treatment
,
at
ACL
'
03
,
Sapporo
,
Japan
,
pp
.
''
>
</td>
49-56
.
''
>
</td>
Piao
,
S.
,
McEnery
,
T.
,
2001
.
''
>
</td>
Multi-word
unit
alignment
in
English-Chinese
parallel
corpora
.
''
>
</td>
In
:
Proceedings
of
the
Corpus
Linguistics
2001
,
Lancaster
,
UK
.
''
>
</td>
pp
.
''
>
</td>
466-475
.
''
>
</td>
Rayson
,
P.
,
Archer
,
D.
,
Piao
,
S.
L.
,
McEnery
,
T.
2004
.
''
>
</td>
The
UCREL
semantic
analysis
system
.
''
>
</td>
In
proceedings
of
the
workshop
on
Beyond
Named
Entity
Recognition
Semantic
labelling
for
NLP
tasks
in
association
with
LREC
2004
,
Lisbon
,
Portugal
,
pp
.
''
>
</td>
7-12
.
''
>
</td>
Rayson
,
P.
,
Berridge
,
D.
and
Francis
,
B.
2004
.
''
>
</td>
Extending
the
Cochran
rule
for
the
comparison
of
word
frequencies
between
corpora
.
''
>
</td>
In
Proceedings
of
the
7th
International
Conference
on
Statistical
analysis
of
textual
data
-LRB-
JADT
2004
-RRB-
,
Louvain-laNeuve
,
Belgium
.
''
>
</td>
pp
.
''
>
</td>
926-936
.
''
>
</td>
Sag
,
I.
,
Baldwin
,
T.
,
Bond
,
F.
,
Copestake
,
A.
,
Dan
,
F.
,
2001
.
''
>
</td>
Multiword
expressions
:
a
pain
in
the
neck
for
NLP
.
''
>
</td>
LinGO
Working
Paper
No.
2001-03
,
Stanford
University
,
CA
.
''
>
</td>
Scott
,
M.
,
2001
.
''
>
</td>
Mapping
key
words
to
problem
and
solution
.
''
>
</td>
In
:
Scott
,
M.
,
Thompson
,
G.
''
>
</td>
-LRB-
Eds
.
-RRB-
,
Patterns
of
Text
:
in
Honour
of
Michael
Hoey
.
''
>
</td>
Benjamins
,
Amsterdam
.
''
>
</td>
pp
.
''
>
</td>
109
127
.
''
>
</td>
Smadja
,
F.
,
1993
.
''
>
</td>
Retrieving
collocations
from
text
:
Xtract
.
''
>
</td>
Computational
Linguistics
19
-LRB-
1
-RRB-
,
143-177
.
''
>
</td>
Sun
,
G.
2004
.
''
>
</td>
Design
of
an
Interlingua-Based
Chinese-English
Machine
Translation
System
.
''
>
</td>
In
Proceedings
of
the
5th
China-Korea
Joint
Symposium
on
Oriental
Language
Processing
and
Pattern
Recognition
,
Qingdao
,
China
.
''
>
</td>
pp
.
''
>
</td>
129-134
.
''
>
</td>
Tanaka
,
T.
,
Baldwin
,
T.
,
2003
.
''
>
</td>
Noun-noun
compound
machine
translation
:
a
feasibility
study
on
shallow
processing
.
''
>
</td>
In
:
Proceedings
of
the
ACL-03
Workshop
on
Multiword
Expressions
:
Analysis
,
Acquisition
and
Treatment
,
Sapporo
,
Japan
.
''
>
</td>
pp
.
''
>
</td>
17-24
.
''
>
</td>
Wu
,
D.
,
1997
.
''
>
</td>
Stochastic
inversion
transduction
grammars
and
bilingual
parsing
of
parallel
corpora
.
''
>
</td>
Computational
Linguistics
23
-LRB-
3
-RRB-
,
377-401
.
''
>
</td>
Retrieving
Collocations
From
Text
:
Xtract
