<html><body><head><link rel="stylesheet" type="text/css" href="style.css" /><script src="map.js"></script><script src="jquery-1.7.1.min.js"></script></head>
<div class="dstPaperData">
N03-1003 <div class="dstPaperTitle">Learning To Paraphrase: An Unsupervised Approach Using Multiple-Sequence Alignment</div><div class="dstPaperAuthors">Barzilay, Regina;Lee, Lillian;</div>
</div>
<table cellspacing="0" cellpadding="0"><tr>
	<td class="srcData" >Source Paper</td>
	<td class="pp legend" ><input type="checkbox" id="cbIPositive" checked="true"/><label for="cbIPositive">Informal +<label></td>
	<td class="nn legend" ><input type="checkbox" id="cbINegative" checked="true"/><label for="cbINegative">Informal -<label></td>
	<td class="oo legend" ><input type="checkbox" id="cbIObjective" checked="true"/><label for="cbIObjective">Informal Neutral<label></td>
	<td class="ppc legend" ><input type="checkbox" id="cbEPositive" checked="true"/><label for="cbEPositive">Formal +</label></td>
	<td class="nnc legend" ><input type="checkbox" id="cbENegative" checked="true"/><label for="cbENegative">Formal -</label></td>
	<td class="ooc legend" ><input type="checkbox" id="cbEObjective" checked="true"/><label for="cbEObjective">Formal Neutral</label></td>
	<td class="lb"><input type="checkbox" id="cbSentenceBoundary"/><label for="cbSentenceBoundary">Sentence Boundary</label></td>
</tr></table>
<div class="dstPaper">
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N03-1024
Syntax-Based Alignment Of Multiple Translations: Extracting Paraphrases And Generating New Sentences
Pang, Bo;Knight, Kevin;Marcu, Daniel;"></td>
	<td class="line x" title="1:235	Syntax-based Alignment of Multiple Translations: Extracting Paraphrases and Generating New Sentences Bo Pang Department of Computer Science Cornell University Ithaca, NY 14853 USA pabo@cs.cornell.edu Kevin Knight and Daniel Marcu Information Sciences Institute University of Southern California Marina Del Rey, CA 90292 USA {knight,marcu}@isi.edu Abstract We describe a syntax-based algorithm that automatically builds Finite State Automata (word lattices) from semantically equivalent translation sets." ></td>
	<td class="line x" title="2:235	These FSAs are good representations of paraphrases." ></td>
	<td class="line x" title="3:235	They can be used to extract lexical and syntactic paraphrase pairs and to generate new, unseen sentences that express the same meaning as the sentences in the input sets." ></td>
	<td class="line x" title="4:235	Our FSAs can also predict the correctness of alternative semantic renderings, which may be used to evaluate the quality of translations." ></td>
	<td class="line x" title="5:235	1 Introduction In the past, paraphrases have come under the scrutiny of many research communities." ></td>
	<td class="line x" title="6:235	Information retrieval researchers have used paraphrasing techniques for query reformulation in order to increase the recall of information retrieval engines (Sparck Jones and Tait, 1984)." ></td>
	<td class="line x" title="7:235	Natural language generation researchers have used paraphrasing to increase the expressive power of generation systems (Iordanskaja et al. , 1991; Lenke, 1994; Stede, 1999)." ></td>
	<td class="line x" title="8:235	And researchers in multi-document text summarization (Barzilay et al. , 1999), information extraction (Shinyama et al. , 2002), and question answering (Lin and Pantel, 2001; Hermjakob et al. , 2002) have focused on identifying and exploiting paraphrases in the context of recognizing redundancies, alternative formulations of the same meaning, and improving the performance of question answering systems." ></td>
	<td class="line x" title="9:235	In previous work (Barzilay and McKeown, 2001; Lin and Pantel, 2001; Shinyama et al. , 2002), paraphrases are represented as sets or pairs of semantically equivalent words, phrases, and patterns." ></td>
	<td class="line x" title="10:235	Although this is adequate in the context of some applications, it is clearly too weak from a generative perspective." ></td>
	<td class="line x" title="11:235	Assume, for example, that we know that text pairs (stock market rose, stock market gained) and (stock market rose, stock prices rose) have the same meaning." ></td>
	<td class="line x" title="12:235	If we memorized only these two pairs, it would be impossible to infer that, in fact, consistent with our intuition, any of the following sets of phrases are also semantically equivalent: {stock market rose, stock market gained, stock prices rose, stock prices gained } and {stock market, stock prices } in the context of rose or gained; {market rose }, {market gained }, {prices rose } and {prices gained } in the context of stock; and so on." ></td>
	<td class="line x" title="13:235	In this paper, we propose solutions for two problems: the problem of paraphrase representation and the problem of paraphrase induction." ></td>
	<td class="line x" title="14:235	We propose a new, finite-statebased representation of paraphrases that enables one to encode compactly large numbers of paraphrases." ></td>
	<td class="line x" title="15:235	We also propose algorithms that automatically derive such representations from inputs that are now routinely released in conjunction with large scale machine translation evaluations (DARPA, 2002): multiple English translations of many foreign language texts." ></td>
	<td class="line x" title="16:235	For instance, when given as input the 11 semantically equivalent English translations in Figure 1, our algorithm automatically induces the FSA in Figure 2, which represents compactly 49 distinct renderings of the same semantic meaning." ></td>
	<td class="line x" title="17:235	Our FSAs capture both lexical paraphrases, such as {fighting, battle}, {died, were killed} and structural paraphrases such as {last weeks fighting, the battle of last week}." ></td>
	<td class="line x" title="18:235	The contexts in which these are correct paraphrases are also conveniently captured in the representation." ></td>
	<td class="line x" title="19:235	In previous work, Langkilde and Knight (1998) used word lattices for language generation, but their method involved hand-crafted rules." ></td>
	<td class="line x" title="20:235	Bangalore et al.(2001) and Barzilay and Lee (2002) both applied the technique of multi-sequence alignment (MSA) to align parallel corpora and produced similar FSAs." ></td>
	<td class="line x" title="22:235	For their purposes, they mainly need to ensure the correctness of consensus among different translations, so that different constituent orderings in input sentences do not pose a serious probEdmonton, May-June 2003 Main Papers, pp." ></td>
	<td class="line x" title="23:235	102-109 Proceedings of HLT-NAACL 2003 1." ></td>
	<td class="line x" title="24:235	At least 12 people were killed in the battle last week." ></td>
	<td class="line x" title="25:235	2." ></td>
	<td class="line x" title="26:235	At least 12 people lost their lives in last weeks fighting." ></td>
	<td class="line x" title="27:235	3." ></td>
	<td class="line x" title="28:235	Last weeks fight took at least 12 lives." ></td>
	<td class="line x" title="29:235	4." ></td>
	<td class="line x" title="30:235	The fighting last week killed at least 12." ></td>
	<td class="line x" title="31:235	5." ></td>
	<td class="line x" title="32:235	The battle of last week killed at least 12 persons." ></td>
	<td class="line x" title="33:235	6." ></td>
	<td class="line x" title="34:235	At least 12 persons died in the fighting last week." ></td>
	<td class="line x" title="35:235	7." ></td>
	<td class="line x" title="36:235	At least 12 died in the battle last week." ></td>
	<td class="line x" title="37:235	8." ></td>
	<td class="line x" title="38:235	At least 12 people were killed in the fighting last week." ></td>
	<td class="line x" title="39:235	9." ></td>
	<td class="line x" title="40:235	During last weeks fighting, at least 12 people died." ></td>
	<td class="line x" title="41:235	10." ></td>
	<td class="line x" title="42:235	Last week at least twelve people died in the fighting." ></td>
	<td class="line x" title="43:235	11." ></td>
	<td class="line x" title="44:235	Last weeks fighting took the lives of twelve people." ></td>
	<td class="line x" title="45:235	Figure 1: Sample Sentence Group from the Chinese-English DARPA Evaluation Corpus: 11 English translations of the same Chinese sentence." ></td>
	<td class="line x" title="46:235	at during last the least last week battle fighting were died lost killed in their 12 persons *e* people the last weekbattle fighting lives in last week fighting s at s least fighting fight died in peopletwelve the at least died week fightings people12 killed took the at of last week lives least of twelve people 12 lives persons *e* Figure 2: FSA produced by our syntax-based alignment algorithm from the input in Figure 1." ></td>
	<td class="line x" title="47:235	*e* the during *e* fighting battle last *e* week weeks fight fighting *e* killed of took *e* the at lives least of twelve 12 people persons *e* lives died *e* in *e* the *e* battle fighting *e* last weeks week fighting *e* *e* people lost were their killed Figure 3: FSA produced by a Multi-Sequence Alignment algorithm from the input in Figure 1." ></td>
	<td class="line x" title="48:235	lem." ></td>
	<td class="line x" title="49:235	In contrast, we want to ensure the correctness of all paths represented by the FSAs, and direct application of MSA in the presence of different constituent orderings can be problematic." ></td>
	<td class="line x" title="50:235	For example, when given as input the same sentences in Figure 1, one instantiation of the MSA algorithm produces the FSA in Figure 3, which contains many bad paths such as the battle of last weeks fighting took at least 12 people lost their people died in the fighting last weeks fighting (See Section 4.2.2 for a more quantitative analysis.)." ></td>
	<td class="line oc" title="51:235	Its still possible to use MSA if, for example, the input is pre-clustered to have the same ASDF constituent ordering (Barzilay and Lee (2003))." ></td>
	<td class="line x" title="52:235	But we chose to approach this problem from another direction." ></td>
	<td class="line x" title="53:235	As a result, we propose a new syntax-based algorithm to produce FSAs." ></td>
	<td class="line x" title="54:235	In this paper, we first introduce the multiple translation corpus that we use in our experiments (see Section 2)." ></td>
	<td class="line x" title="55:235	We then present the algorithms that we developed to induce finite-state paraphrase representations from such data (see Section 3)." ></td>
	<td class="line x" title="56:235	An important part of the paper is dedicated to evaluating the quality of the finite-state representations that we derive (see Section 4)." ></td>
	<td class="line x" title="57:235	Since our representations encode thousands and sometimes millions of equivalent verbalizations of the same meaning, we use both manual and automatic evaluation techniques." ></td>
	<td class="line x" title="58:235	Some of the automatic evaluations we perform are novel as well." ></td>
	<td class="line x" title="59:235	2 Data The data we use in this work is the LDC-available Multiple-Translation Chinese (MTC) Corpus1 developed for machine translation evaluation, which contains 105 news stories (993 sentences) from three sources of journalistic Mandarin Chinese text." ></td>
	<td class="line x" title="60:235	These stories were independently translated into English by 11 translation agencies." ></td>
	<td class="line x" title="61:235	Each sentence group, which consists of 11 semantically equivalent translations, is a rich source for learning lexical and structural paraphrases." ></td>
	<td class="line x" title="62:235	In our experiments, we use 899 of the sentence groups  the sentence groups with sentences longer than 45 words were dropped." ></td>
	<td class="line x" title="63:235	3 A Syntax-Based Alignment Algorithm Our syntax-based alignment algorithm, whose pseudocode is shown in Figure 4, works in three steps." ></td>
	<td class="line x" title="64:235	In the first step (lines 1-5 in Figure 4), we parse every sentence in a sentence group and merge all resulting parse trees into a parse forest." ></td>
	<td class="line x" title="65:235	In the second step (line 6), we extract 1Linguistic Data Consortium (LDC) Catalog Number LDC2002T01, ISBN 1-58563-217-1." ></td>
	<td class="line x" title="66:235	1." ></td>
	<td class="line x" title="67:235	ParseForest = epsilon1 2." ></td>
	<td class="line x" title="68:235	foreach s  SentenceGroup 3." ></td>
	<td class="line x" title="69:235	t = parseTree(s); 4." ></td>
	<td class="line x" title="70:235	ParseForest = Merge(ParseForest, t); 5." ></td>
	<td class="line x" title="71:235	endfor 6." ></td>
	<td class="line x" title="72:235	Extract FSA from ParseForest; 7." ></td>
	<td class="line x" title="73:235	Squeeze FSA; Figure 4: The Syntax-Based Alignment Algorithm." ></td>
	<td class="line x" title="74:235	an FSA from the parse forest and then we compact it further using a limited form of bottom-up alignment, which we call squeezing (line 7)." ></td>
	<td class="line x" title="75:235	In what follows, we describe each step in turn." ></td>
	<td class="line x" title="76:235	Top-down merging." ></td>
	<td class="line x" title="77:235	Given a sentence group, we pass each of the 11 sentences to Charniaks (2000) parser to get 11 parse trees." ></td>
	<td class="line x" title="78:235	The first step in the algorithm is to merge these parse trees into one parse-forest-like structure using a top-down process." ></td>
	<td class="line x" title="79:235	Lets consider a simple case in which the parse forest contains one single tree, Tree 1 in Figure 5, and we are adding Tree 2 to it." ></td>
	<td class="line x" title="80:235	Since the two trees correspond to sentences that have the same meaning and since both trees expand an S node into an NP and a VP, it is reasonable to assume that NP1 is a paraphrase of NP2 and VP1 is a paraphrase of VP2." ></td>
	<td class="line x" title="81:235	We merge NP1 with NP2 and VP1 with VP2 and continue the merging process on each of the subtrees recursively, until we either reach the leaves of the trees or the two nodes that we examine are expanded using different syntactic rules." ></td>
	<td class="line x" title="82:235	When we apply this process to the trees in Figure 5, the NP nodes are merged all the way down to the leaves, and we get 12 as a paraphrase of twelve and people as a paraphrase of persons; in contrast, the two VPs are expanded in different ways, so no merging is done beyond this level, and we are left with the information that were killed is a paraphrase of died." ></td>
	<td class="line x" title="83:235	We repeat this top-down merging procedure with each of the 11 parse trees in a sentence group." ></td>
	<td class="line x" title="84:235	So far, only constituents with same syntactic type are treated as paraphrases." ></td>
	<td class="line x" title="85:235	However, later we shall see that we can match word spans whose syntactic types differ." ></td>
	<td class="line x" title="86:235	Keyword checking." ></td>
	<td class="line x" title="87:235	The matching process described above appears quite strict  the expansions must match exactly for two nodes to be merged." ></td>
	<td class="line x" title="88:235	But consider the following parse trees: 1.(S (NP1 people)(VP1 were killed in this battle)) 2.(S (NP2 this battle)(VP2 killed people)) If we applied the algorithm described above, we would mistakenly align NP1 with NP2 and VP1 with VP2  the algorithm described so far makes no use of lexical 12 twelve people personswere killed died Merge Linearization Tree 1 Tree 2 Parse Forest FSA / Word Lattice BEG END +SNP VP CD12 NNpersons AUXwere VP VBkilled S NP VP CDtwelve NNpeople VBdied NP VP CD NN AUXVPVB 12twelve peoplepersonswere killeddied Figure 5: Top-down merging of parse trees and FSA extraction." ></td>
	<td class="line x" title="89:235	information." ></td>
	<td class="line x" title="90:235	To prevent such erroneous alignments, we also implement a simple keyword checking procedure." ></td>
	<td class="line x" title="91:235	We note that since the word battle appears in both VP1 and NP2, this can serve as an evidence against the merging of (NP1, NP2) and (VP1, VP2)." ></td>
	<td class="line x" title="92:235	A similar argument can be constructed for the word people." ></td>
	<td class="line x" title="93:235	So in this example we actually have double evidence against merging; in general, one such clue suffices to stop the merging." ></td>
	<td class="line x" title="94:235	Our keyword checking procedure acts as a filter." ></td>
	<td class="line x" title="95:235	A list of keywords is maintained for each node in a syntactic tree." ></td>
	<td class="line x" title="96:235	This list contains all the nouns, verbs, and adjectives that are spanned by a syntactic node." ></td>
	<td class="line x" title="97:235	Before merging two nodes, we check to see whether the keyword lists associated with them share words with other nodes." ></td>
	<td class="line x" title="98:235	That is, supposed we just merged nodes A and B, and they are expanded with the same syntactic rule into A1A2An and B1B2Bn respectively; before we merge each Ai with Bi, we check for each Bi if its keyword list shares common words with any Aj (j negationslash= i)." ></td>
	<td class="line x" title="99:235	If they do not, we continue the top-down merging process; otherwise we stop." ></td>
	<td class="line x" title="100:235	detroit a building detroit detroit a building building in s building building reduced to rubble flattened razed was blasted leveledrazed razed leveled into to detroitbuilding to down the ground ashesground the ground levelled to in detroit ground a. Before squeezing detroit a *e* s*e* building building reduced *e* was flattened blastedleveled levelled to razed leveled *e* into to to rubble in detroit downashes the*e* ground b. After squeezing Figure 6: Squeezing effect In our current implementation, a pair of synonyms can not stop an otherwise legitimate merging, but its possible to extend our keyword checking process with the help of lexical resources such as WordNet in future work." ></td>
	<td class="line x" title="101:235	Mapping Parse Forests into Finite State Automata." ></td>
	<td class="line x" title="102:235	The process of mapping Parse Forests into Finite State Automata is simple." ></td>
	<td class="line x" title="103:235	We simply traverse the parse forest top-down and create alternative paths for every merged node." ></td>
	<td class="line x" title="104:235	For example, the parse forest in Figure 5 is mapped into the FSA shown at the bottom of the same figure." ></td>
	<td class="line x" title="105:235	In the FSA, there is a word associated with each edge." ></td>
	<td class="line x" title="106:235	Different paths between any two nodes are assumed to be paraphrases of each other." ></td>
	<td class="line x" title="107:235	Each path that starts from the BEGIN node and ends at the END node corresponds to either an original input sentence or a paraphrase sentence." ></td>
	<td class="line x" title="108:235	Squeezing." ></td>
	<td class="line x" title="109:235	Since we adopted a very strict matching criterion in top-down merging, a small difference in the syntactic structure of two trees prevents some legitimate mergings from taking place." ></td>
	<td class="line x" title="110:235	This behavior is also exacerbated by errors in syntactic parsing." ></td>
	<td class="line x" title="111:235	Hence, for instance, three edges labeled detroit at the leftmost of the top FSA in Figure 6 were kept apart." ></td>
	<td class="line x" title="112:235	To compensate for this effect, our algorithm implements an additional step, which we call squeezing." ></td>
	<td class="line x" title="113:235	If two different edges that go into (or out of) the same node in an FSA are labeled with the same word, the nodes on the other end of the edges are merged." ></td>
	<td class="line x" title="114:235	We apply this operation exhaustively over the FSAs produced by the top-down merging procedure." ></td>
	<td class="line x" title="115:235	Figure 6 illustrates the effect of this operation: the FSA at the top of this figure is compressed into the more compact FSA shown at the bottom of it." ></td>
	<td class="line x" title="116:235	Note that in addition to reducing the redundant edges, this also gives us paraphrases not available in the FSA before squeezing (e.g. {reduced to rubble, blasted to ground})." ></td>
	<td class="line x" title="117:235	Therefore, the squeezing operation, which implements a limited form of lexically driven alignment similar to that exploited by MSA algorithms, leads to FSAs that have a larger number of paths and paraphrases." ></td>
	<td class="line x" title="118:235	4 Evaluation The evaluation for our finite state representations and algorithm requires careful examination." ></td>
	<td class="line x" title="119:235	Obviously, what counts as a good result largely depends on the application one has in mind." ></td>
	<td class="line x" title="120:235	If we are extracting paraphrases for question-reformulation, it doesnt really matter if we output a few syntactically incorrect paraphrases, as long as we produce a large number of semantically correct ones." ></td>
	<td class="line x" title="121:235	If we want to use the FSA for MT evaluation (for example, comparing a sentence to be evaluated with the possible paths in FSA), we would want all paths to be relatively good (which we will focus on in this paper), while in some other applications, we may only care about the quality of the best path (not addressed in this paper)." ></td>
	<td class="line x" title="122:235	Section 4.1 concentrates on evaluating the paraphrase pairs that can be extracted from the FSAs built by our system, while Section 4.2 is dedicated to evaluating the FSAs directly." ></td>
	<td class="line x" title="123:235	4.1 Evaluating paraphrase pairs 4.1.1 Human-based evaluation of paraphrases By construction, different paths between any two nodes in the FSA representations that we derive are paraphrases (in the context in which the nodes occur)." ></td>
	<td class="line x" title="124:235	To evaluate our algorithm, we extract paraphrases from our FSAs and ask human judges to evaluate their correctness." ></td>
	<td class="line x" title="125:235	We compare the paraphrases we collect with paraphrases that are derivable from the same corpus using a cotraining-based paraphrase extraction algorithm (Barzilay and McKeown, 2001)." ></td>
	<td class="line x" title="126:235	To the best of our knowledge, this is the most relevant work to compare against since it aims at extracting paraphrase pairs from parallel corpus." ></td>
	<td class="line x" title="127:235	Unlike our syntax-based algorithm which treats a sentence as a tree structure and uses this hierarchical structural information to guide the merging process, their algorithm treats a sentence as a sequence of phrases with surrounding contexts (no hierarchical structure involved) and cotrains classifiers to detect paraphrases and contexts for paraphrases." ></td>
	<td class="line x" title="128:235	It would be interesting to compare the results from two algorithms so different from each other." ></td>
	<td class="line x" title="129:235	For the purpose of this experiment, we randomly selected 300 paraphrase pairs (Ssyn) from the FSAs produced by our system." ></td>
	<td class="line x" title="130:235	Since the co-training-based algorithm of Barzilay and McKeown (2001) takes parallel corpus as input, we created out of the MTC corpus 55  993 sentence pairs (Each equivalent translation set of cardinality 11 was mapped into parenleftbig112 parenrightbig equivalent translation pairs.)." ></td>
	<td class="line x" title="131:235	Regina Barzilay kindly provided us the list of paraphrases extracted by their algorithm from this parallel corpus, from which we randomly selected another set of 300 paraphrases (Scotr)." ></td>
	<td class="line x" title="132:235	Correct Partial Incorrect Ssyn 85% 12% 3% Judge 1 Scotr 68% 13% 19% Ssyn 80% 13% 7% Judge 2 Scotr 63% 13% 24% Ssyn 81% 5% 13% Judge 3 Scotr 68% 3% 29% Ssyn 77% 17% 5% Judge 4 Scotr 68% 16% 16% Average of Ssyn 81% 12% 7% All Judges Scotr 66% 11% 22% Table 1: A comparison of the correctness of the paraphrases produced by the syntax-based alignment (Ssyn) and co-training-based (Scotr) algorithms." ></td>
	<td class="line x" title="133:235	The resulting 600 paraphrase pairs were mixed and presented in random order to four human judges." ></td>
	<td class="line x" title="134:235	Each judge was asked to assess the correctness of 150 paraphrase pairs (75 pairs from each system) based on the context, i.e., the sentence group, from which the paraphrase pair was extracted." ></td>
	<td class="line x" title="135:235	Judges were given three choices: Correct, for perfect paraphrases, Partially correct, for paraphrases in which there is only a partial overlap between the meaning of two paraphrases (e.g. while {saving set, aid package} is a correct paraphrase pair in the given context, {set, aide package} is considered partially correct), and Incorrect." ></td>
	<td class="line x" title="136:235	The results of the evaluation are presented in Table 1." ></td>
	<td class="line x" title="137:235	Although the four evaluators were judging four different sets, each clearly rated a higher percentage of the outputs produced by the syntax-based alignment algorithm as Correct." ></td>
	<td class="line x" title="138:235	We should note that there are parameters specific to the co-training algorithm that we did not tune to work for this particular corpus." ></td>
	<td class="line x" title="139:235	In addition, the cotraining algorithm recovered more paraphrase pairs: the syntax-based algorithm extracted 8666 pairs in total with 1051 of them extracted at least twice (i.e. more or less reliable), while the numbers for the co-training algorithm is 2934 out of a total of 16993 pairs." ></td>
	<td class="line x" title="140:235	This means we are not comparing the accuracy on the same recall level." ></td>
	<td class="line x" title="141:235	Aside from evaluating the correctness of the paraphrases, we are also interested in the degree of overlap between the paraphrase pairs discovered by the two algorithms so different from each other." ></td>
	<td class="line x" title="142:235	We find that out of the 1051 paraphrase pairs that were extracted from more than one sentence group by the syntax-based algorithm, 62.3% were also extracted by the co-training algorithm; and out of the 2934 paraphrase pairs from the results of co-training algorithm, 33.4% were also extracted by the syntax-based algorithm." ></td>
	<td class="line x" title="143:235	This shows that in spite of the very different cues the two different algorithms rely on, range of ASL 1-10 10-20 20-30 30-45 recall 30.7% 16.3% 7.8% 3.8% Table 2: Recall of WordNet-consistent synonyms." ></td>
	<td class="line x" title="144:235	they do discover a lot of common pairs." ></td>
	<td class="line x" title="145:235	4.1.2 WordNet-based analysis of paraphrases In order to (roughly) estimate the recall (of lexical synonyms) of our algorithm, we use the synonymy relation in WordNet to extract all the synonym pairs present in our corpus." ></td>
	<td class="line x" title="146:235	This extraction process yields the list of all WordNet-consistent synonym pairs that are present in our data." ></td>
	<td class="line x" title="147:235	(Note that some of the pairs identified as synonyms by WordNet, like follow/be, are not really synonyms in the contexts defined in our data set, which may lead to artificial deflation of our recall estimate)." ></td>
	<td class="line x" title="148:235	Once we have the list of WordNet-consistent paraphrases, we can check how many of them are recovered by our method." ></td>
	<td class="line x" title="149:235	Table 2 gives the percentage of pairs recovered for each range of average sentence length (ASL) in the group." ></td>
	<td class="line x" title="150:235	Not surprisingly, we get higher recall with shorter sentences, since long sentences tend to differ in their syntactic structures fairly high up in the parse trees, which leads to fewer mergings at the lexical level." ></td>
	<td class="line x" title="151:235	The recall on the task of extracting lexical synonyms, as defined by WordNet, is not high." ></td>
	<td class="line x" title="152:235	But after all, this is not what our algorithm has been designed for." ></td>
	<td class="line x" title="153:235	Its worth noticing that the syntax-based algorithm also picks up many paraphrases that are not identified as synonyms in WordNet." ></td>
	<td class="line x" title="154:235	Out of 3217 lexical paraphrases that are learned by our system, only 493 (15.3%) are WordNet synonyms, which suggests that paraphrasing is a much richer and looser relation than synonymy." ></td>
	<td class="line x" title="155:235	However, the WordNetbased recall figures suggest that WordNet can be used as an additional source of information to be exploited by our algorithm." ></td>
	<td class="line x" title="156:235	4.2 Evaluating the FSA directly We noted before that apart from being a natural representation of paraphrases, the FSAs that we build have their own merit and deserve to be evaluated directly." ></td>
	<td class="line x" title="157:235	Since our FSAs contain large numbers of paths, we design automatic evaluation metrics to assess their qualities." ></td>
	<td class="line x" title="158:235	4.2.1 Language Model-based evaluation If we take our claims seriously, each path in our FSAs that connects the start and end nodes should correspond to a well-formed sentence." ></td>
	<td class="line x" title="159:235	We are interested in both quantity (how many sentences our automata are able to produce) and quality (how good these sentences are)." ></td>
	<td class="line x" title="160:235	To answer the first question, we simply count the number of paths produced by our FSAs." ></td>
	<td class="line x" title="161:235	average N (# of paths) logN length max ave max ave 1 10 22749 775 10.0 5.2 10 20 172386 4468 12.1 6.2 20 30 3479544 29202 15.1 5.8 30 45 684589 4135 13.4 4.5 Table 3: Statistics on Number of Paths in FSAs random variable mean std." ></td>
	<td class="line x" title="162:235	dev ent(FSA)ent(SG) 0.11586 1.25162 ent(MTS)ent(SG) 1.74259 1.05749 Table 4: Quality judged by LM Table 3 gives the statistics on the number of paths produced by our FSAs, reported by the average length of sentences in the input sentence groups." ></td>
	<td class="line x" title="163:235	For example, the sentence groups that have between 10 and 20 words produce, on average, automata that can yield 4468 alternative, semantically equivalent formulations." ></td>
	<td class="line x" title="164:235	Note that if we always get the same degree of merging per word across all sentence groups, the number of paths would tend to increase with the sentence length." ></td>
	<td class="line x" title="165:235	This is not the case here." ></td>
	<td class="line x" title="166:235	Apparently we are getting less merging with longer sentences." ></td>
	<td class="line x" title="167:235	But still, given 11 sentences, we are capable of generating hundreds, thousands, and in some cases even millions of sentences." ></td>
	<td class="line x" title="168:235	Obviously, we should not get too happy with our ability to boost the number of equivalent meanings if they are incorrect." ></td>
	<td class="line x" title="169:235	To assess the quality of the FSAs generated by our algorithm, we use a language model-based metric." ></td>
	<td class="line x" title="170:235	We train a 4-gram model over one year of the Wall Street Journal using the CMU-Cambridge Statistical Language Modeling toolkit (v2)." ></td>
	<td class="line x" title="171:235	For each sentence group SG, we use this language model to estimate the average entropy of the 11 original sentences in that group (ent(SG))." ></td>
	<td class="line x" title="172:235	We also compute the average entropy of all the sentences in the corresponding FSA built by our syntax-based algorithm (ent(FSA))." ></td>
	<td class="line x" title="173:235	As the statistics in Table 4 show, there is little difference between the average entropy of the original sentences and the average entropy of the paraphrase sentences we produce." ></td>
	<td class="line x" title="174:235	To better calibrate this result, we compare it with the average entropy of 6 corresponding machine translation outputs (ent(MTS)), which were also made available by LDC in conjunction with the same corpus." ></td>
	<td class="line x" title="175:235	As one can see, the difference between the average entropy of the machine produced output and the average entropy of the original 11 sentences is much higher than the difference between the average entropy of the FSA-produced outputs and the average entropy of the original 11 sentences." ></td>
	<td class="line x" title="176:235	Obviously, this does not mean that our FSAs only produce well-formed sentences." ></td>
	<td class="line x" title="177:235	But it does mean that our FSAs produce sentences that look more like human produced sentences than machine produced ones according to a language model." ></td>
	<td class="line x" title="178:235	4.2.2 Word repetition analysis Not surprisingly, the language model we used in Section 4.2.1 is far from being a perfect judge of sentence quality." ></td>
	<td class="line x" title="179:235	Recall the example of bad path we gave in Section 1: the battle of last weeks fighting took at least 12 people lost their people died in the fighting last weeks fighting." ></td>
	<td class="line x" title="180:235	Our 4-gram based language model will not find any fault with this sentence." ></td>
	<td class="line x" title="181:235	Notice, however, that some words (such as fighting and people) appear at least twice in this path, although they are not repeated in any of the source sentences." ></td>
	<td class="line x" title="182:235	These erroneous repetitions indicate mis-alignment." ></td>
	<td class="line x" title="183:235	By measuring the frequency of words that are mistakenly repeated, we can now examine quantitatively whether a direct application of the MSA algorithm suffers from different constituent orderings as we expected." ></td>
	<td class="line x" title="184:235	For each sentence group, we get a list of words that never appear more than once in any sentence in this group." ></td>
	<td class="line x" title="185:235	Given a word from this list and the FSA built from this group, we count the total number of paths that contain this word (C) and the number of paths in which this word appears at least twice (Cr, i.e. number of erroneous repetitions)." ></td>
	<td class="line x" title="186:235	We define the repetition ratio to be Cr/C, which is the proportion of bad paths in this FSA according to this word." ></td>
	<td class="line x" title="187:235	If we compute this ratio for all the words in the lists of the first 499 groups2 and the corresponding FSAs produced by an instantiation of the MSA algorithm3, the average repetition ratio is 0.0304992 (14.76% of the words have a non-zero repetition ratio, and the average ratio for these words is 0.206671)." ></td>
	<td class="line x" title="188:235	In comparison, the average repetition ratio for our algorithm is 0.0035074 (2.16% of the words have a non-zero repetition ratio4, and the average ratio for these words is 0.162309)." ></td>
	<td class="line x" title="189:235	The presence of different constituent orderings does pose a more serious problem to the MSA algorithm." ></td>
	<td class="line x" title="190:235	4.2.3 MT-based evaluation Recently, Papineni et al.(2002) have proposed an automatic MT system evaluation technique (the BLEU score)." ></td>
	<td class="line x" title="192:235	Given an MT system output and a set of refer2MSA runs very slow for longer sentences, and we believe using the first 499 groups should be enough to make our point." ></td>
	<td class="line x" title="193:235	3We thank Regina Barzilay for providing us this set of results 4Note that FSAs produced right after keyword checking will not yield any non-zero repetition ratio." ></td>
	<td class="line x" title="194:235	However, if there are mis-alignment not prevented by keyword checking in an FSA, it may contain paths with erroneous repetition of words after squeezing." ></td>
	<td class="line x" title="195:235	range 0-1 1-2 2-3 3-4 4-5 count 546 256 80 15 2 Table 5: Statistics for edgain ence translations, one can estimate the goodness of the MT output by measuring the n-gram overlap between the output and the reference set." ></td>
	<td class="line x" title="196:235	The higher the overlap, i.e., the closer an output string is to a set of reference translations, the better a translation it is. We hypothesize that our FSAs provide a better representation against which the outputs of MT systems can be evaluated because they encode not just a few but thousands of equivalent semantic formulations of the desired meaning." ></td>
	<td class="line x" title="197:235	Ideally, if the FSAs we build accept all and only the correct renderings of a given meaning, we can just give a test sentence to the reference FSA and see if it is accepted by it." ></td>
	<td class="line x" title="198:235	Since this is not a realistic expectation, we measure the edit distance between a string and an FSA instead: the smaller this distance is, the closer it is to the meaning represented by the FSA." ></td>
	<td class="line x" title="199:235	To assess whether our FSAs are more appropriate representations for evaluating the output of MT systems, we perform the following experiment." ></td>
	<td class="line x" title="200:235	For each sentence group, we hold out one sentence as test sentence, and try to evaluate how much of it can be predicted from the other 10 sentences." ></td>
	<td class="line x" title="201:235	We compare two different ways of estimating the predictive power." ></td>
	<td class="line x" title="202:235	(a) we compute the edit distance between the test sentence and the other 10 sentences in the set." ></td>
	<td class="line x" title="203:235	The minimum of this distance is ed(input)." ></td>
	<td class="line x" title="204:235	(b) we use dynamic programming to efficiently compute the minimum distance (ed(FSA)) between the test sentence and all the paths in the FSA built from the other 10 sentences." ></td>
	<td class="line x" title="205:235	The smaller the edit distance is, the better we are predicting a test sentence." ></td>
	<td class="line x" title="206:235	Mathematically, the difference between these two measures ed(input)ed(FSA) characterizes how much is gained in predictive power by building the FSA." ></td>
	<td class="line x" title="207:235	We carry out the experiment described above in a leave-one-out fashion (i.e. each sentence serves as a test sentence once)." ></td>
	<td class="line x" title="208:235	Now let edgain be the average of ed(input)  ed(FSA) over the 11 runs for a given group." ></td>
	<td class="line x" title="209:235	We compute this for all 899 groups and find the mean for edgain to be 0.91 (std." ></td>
	<td class="line x" title="210:235	dev = 0.78)." ></td>
	<td class="line x" title="211:235	Table 5 gives the count for groups whose edgain falls into the specified range." ></td>
	<td class="line x" title="212:235	We can see that the majority of edgain falls under 2." ></td>
	<td class="line x" title="213:235	We are also interested in the relation between the predictive power of the FSAs and the number of reference translations they are derived from." ></td>
	<td class="line x" title="214:235	For a given group, we randomly order the sentences in it, set the last one as the test sentence, and try to predict it with the first 1, 2, 3,  10 sentences." ></td>
	<td class="line x" title="215:235	We investigate whether more sentences ed(FSAn) ed(inputn) ed(FSA10) ed(FSAn) n mean std." ></td>
	<td class="line x" title="216:235	dev mean std." ></td>
	<td class="line x" title="217:235	dev 1 5.65 3.86 0 0 2 3.66 3.02 0.19 0.60 3 2.71 2.55 0.33 0.76 4 2.10 2.33 0.46 0.90 5 1.56 2.01 0.56 0.95 6 1.18 1.79 0.65 1.02 7 0.79 1.48 0.75 1.09 8 0.49 1.10 0.81 1.11 9 0.21 0.74 0.89 1.16 10 0 0 0.93 1.21 Table 6: Effect of monotonically increasing the number of reference sentences yield an increase in the predictive power." ></td>
	<td class="line x" title="218:235	Let ed(FSAn) be the edit distance from the test sentence to the FSA built on the first n sentences; similarly, let ed(inputn) be the minimum edit distance from the test sentence to an input set that consists of only the first n sentences." ></td>
	<td class="line x" title="219:235	Table 6 reports the effect of using different number of reference translations." ></td>
	<td class="line x" title="220:235	The first column shows that each translation is contributing to the predictive power of our FSA." ></td>
	<td class="line x" title="221:235	Even when we add the tenth translation to our FSA, we still improve its predictive power." ></td>
	<td class="line x" title="222:235	The second column shows that the more sentences we add to the FSA the larger the difference between its predictive power and that of a simple set." ></td>
	<td class="line x" title="223:235	The results in Table 6 suggest that our FSA may be used in order to refine the BLEU metric (Papineni et al. , 2002)." ></td>
	<td class="line x" title="224:235	5 Conclusion & Future Work In this paper, we presented a new syntax-based algorithm that learns paraphrases from a newly available dataset." ></td>
	<td class="line x" title="225:235	The multiple translation corpus that we use in this paper is the first instance in a series of similar corpora that are built and made publicly available by LDC in the context of a series of DARPA-sponsored MT evaluations." ></td>
	<td class="line x" title="226:235	The algorithm we proposed constructs finite state representations of paraphrases that are useful in many contexts: to induce large lists of lexical and structural paraphrases; to generate semantically equivalent renderings of a given meaning; and to estimate the quality of machine translation systems." ></td>
	<td class="line x" title="227:235	More experiments need to be carried out in order to assess extrinsically whether the FSAs we produce can be used to yield higher agreement scores between human and automatic assessments of translation quality." ></td>
	<td class="line x" title="228:235	In our future work, we wish to experiment with more flexible merging algorithms and to integrate better the top-down and bottom-up processes that are used to induce FSAs." ></td>
	<td class="line x" title="229:235	We also wish to extract more abstract paraphrase patterns from the current representation." ></td>
	<td class="line x" title="230:235	Such patterns are more likely to get reused  which would help us get reliable statistics for them in the extraction phase, and also have a better chance of being applicable to unseen data." ></td>
	<td class="line x" title="231:235	Acknowledgments We thank Hal Daume III, Ulrich Germann, and Ulf Hermjakob for help and discussions; Eric Breck, Hubert Chen, Stephen Chong, Dan Kifer, and Kevin ONeill for participating in the human evaluation; and the Cornell NLP group and the reviewers for their comments on this paper." ></td>
	<td class="line x" title="232:235	We especially want to thank Regina Barzilay and Lillian Lee for many valuable suggestions and help at various stages of this work." ></td>
	<td class="line x" title="233:235	Portions of this work were done while the first author was visiting Information Sciences Institute." ></td>
	<td class="line x" title="234:235	This work was supported by the Advanced Research and Development Activity (ARDA)s Advance Question Answering for Intelligence (AQUAINT) Program under contract number MDA908-02-C-0007, the National Science Foundation under ITR/IM grant IIS0081334 and a Sloan Research Fellowship to Lillian Lee." ></td>
	<td class="line x" title="235:235	Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the National Science Foundation or the Sloan Foundation." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W03-1602
Text Simplification For Reading Assistance: A Project Note
Inui, Kentaro;Fujita, Atsushi;Takahashi, Tetsuro;Iida, Ryu;Iwakura, Tomoya;"></td>
	<td class="line x" title="1:182	Text Simplification for Reading Assistance: A Project Note Kentaro Inui Atsushi Fujita Tetsuro Takahashi Ryu Iida Nara Advanced Institute of Science and Technology Takayama, Ikoma, Nara, 630-0192, Japan CUinui,atsush-f,tetsu-ta,ryu-iCV@is.aist-nara.ac.jp Tomoya Iwakura Fujitsu Laboratories Ltd. Kamikodanaka, Nakahara, Kawasaki, Kanagawa, 211-8588, Japan iwakura.tomoya@jp.fujitsu.com Abstract This paper describes our ongoing research project on text simplification for congenitally deaf people." ></td>
	<td class="line x" title="2:182	Text simplification we are aiming at is the task of offering a deaf reader a syntactic and lexical paraphrase of a given text for assisting her/him to understand what it means." ></td>
	<td class="line x" title="3:182	In this paper, we discuss the issues we should address to realize text simplification and report on the present results in three different aspects of this task: readability assessment, paraphrase representation and post-transfer error detection." ></td>
	<td class="line x" title="4:182	1 Introduction This paper reports on our ongoing research into text simplification for reading assistance." ></td>
	<td class="line x" title="5:182	Potential users targeted in this research are congenitally deaf people (more specifically, students at (junior-)high schools for the deaf), who tend to have difficulties in reading and writing text." ></td>
	<td class="line x" title="6:182	We are aiming at the development of the technology of text simplification with which a reading assistance system lexically and structurally paraphrases a given text into a simpler and plainer one that is thus more comprehensible." ></td>
	<td class="line x" title="7:182	The idea of using paraphrases for reading assistance is not necessarily novel." ></td>
	<td class="line x" title="8:182	For example, Carroll et al.(1998) and Canning and Taito (1999) report on their project in which they address syntactic transforms aiming at making newspaper text accessible to aphasics." ></td>
	<td class="line x" title="10:182	Following this trend of research, in this project, we address four unexplored issues as below besides the userand task-oriented evaluation of the overall system." ></td>
	<td class="line x" title="11:182	Before going to the detail, we first clarify the four issues we have addressed in the next section." ></td>
	<td class="line x" title="12:182	We then reported on the present results on three of the four, readability assessment, paraphrase representation and post-transfer error detection, in the subsequent sections." ></td>
	<td class="line x" title="13:182	2 Research issues and our approach 2.1 Readability assessment The process of text simplification for reading assistance can be decomposed into the following three subprocesses: a. Problem identification: identify which portions of a given text will be difficult for a given user to read, b. Paraphrase generation: generate possible candidate paraphrases from the identified portions, and c. Evaluation: re-assess the resultant texts to choose the one in which the problems have been resolved." ></td>
	<td class="line x" title="14:182	Given this decomposition, it is clear that one of the key issues in reading assistance is the problem of assessing the readability or comprehensibility 1 of text because it is involved in subprocesses (a) and (c)." ></td>
	<td class="line x" title="15:182	Readability assessment is doubtlessly a tough issue (Williams et al. , 2003)." ></td>
	<td class="line x" title="16:182	In this project, however, we argue that, if one targets only a particular population segment and if an adequate collection of data is available, then corpus-based empirical approaches may well be feasible." ></td>
	<td class="line x" title="17:182	We have already proven that one can collect such readability assessment data by conducting survey questionnaires targeting teachers at schools for the deaf." ></td>
	<td class="line x" title="18:182	1 In this paper, we use the terms readability and comprehensibility interchangeably, while strictly distinguishing them from legibility of each fragment (typically, a sentence or paragraph) of a given text." ></td>
	<td class="line x" title="19:182	2.2 Paraphrase acquisition One of the good findings that we obtained through the aforementioned surveys is that there are a broad range of paraphrases that can improve the readability of text." ></td>
	<td class="line x" title="20:182	A reading assistance system is, therefore, hoped to be able to generate sufficient varieties of paraphrases of a given input." ></td>
	<td class="line x" title="21:182	To create such a system, one needs to feed it with a large collection of paraphrase patterns." ></td>
	<td class="line oc" title="22:182	Very timely, the acquisition of paraphrase patterns has been actively studied in recent years: AF Manual collection of paraphrases in the context of language generation, e.g.(Robin and McKeown, 1996), AF Derivation of paraphrases through existing lexical resources, e.g.(Kurohashi et al. , 1999), AF Corpus-based statistical methods inspired by the work on information extraction, e.g.(Jacquemin, 1999; Lin and Pantel, 2001), and AF Alignment-based acquisition of paraphrases from comparable corpora, e.g.(Barzilay and McKeown, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003)." ></td>
	<td class="line n" title="27:182	One remaining issue is how effectively these methods contribute to the generation of paraphrases in our application-oriented context." ></td>
	<td class="line x" title="28:182	2.3 Paraphrase representation One of the findings obtained in the previous studies for paraphrase acquisition is that the automatic acquisition of candidates of paraphrases is quite realizable for various types of source data but acquired collections tend to be rather noisy and need manual cleaning as reported in, for example, (Lin and Pantel, 2001)." ></td>
	<td class="line x" title="29:182	Given that, it turns out to be important to devise an effective way of facilitating manual correction and a standardized scheme for representing and storing paraphrase patterns as shared resources." ></td>
	<td class="line x" title="30:182	Our approach is (a) to define first a fully expressible formalism for representing paraphrases at the level of tree-to-tree transformation and (b) devise an additional layer of representation on its top that is designed to facilitate handcoding transformation rules." ></td>
	<td class="line x" title="31:182	2.4 Post-transfer text revision In paraphrasing, the morpho-syntactic information of a source sentence should be accessible throughout the transfer process since a morphosyntactic transformation in itself can often be a motivation or goal of paraphrasing." ></td>
	<td class="line x" title="32:182	Therefore, such an approach as semantic transfer, where morphosyntactic information is highly abstracted away as in (Dorna et al. , 1998; Richardson et al. , 2001), does not suit this task." ></td>
	<td class="line x" title="33:182	Provided that the morphosyntactic stratum be an optimal level of abstraction for representing paraphrasing/transfer patterns, one must recall that semantic-transfer approaches such as those cited above were motivated mainly by the need for reducing the complexity of transfer knowledge, which could be unmanageable in morpho-syntactic transfer." ></td>
	<td class="line x" title="34:182	Our approach to this problem is to (a) leave the description of each transfer pattern underspecified and (b) implement the knowledge about linguistic constraints that are independent of a particular transfer pattern separately from the transfer knowledge." ></td>
	<td class="line x" title="35:182	There are a wide range of such transfer-independent linguistic constraints." ></td>
	<td class="line x" title="36:182	Constraints on morpheme connectivity, verb conjugation, word collocation, and tense and aspect forms in relative clauses are typical examples of such constraints." ></td>
	<td class="line x" title="37:182	These four issues can be considered as different aspects of the overall question how one can make the development and maintenance of a gigantic resource for paraphrasing tractable." ></td>
	<td class="line x" title="38:182	(1) The introduction of readability assessment would free us from cares about the purposiveness of each paraphrasing rule in paraphrase acquisition." ></td>
	<td class="line x" title="39:182	(2) Paraphrase acquisition is obviously indispensable for scaling up the resource." ></td>
	<td class="line x" title="40:182	(3) A good formalism for representing paraphrasing rules would facilitate the manual refinement and maintenance of them." ></td>
	<td class="line x" title="41:182	(4) Post-transfer error detection and revision would make the system tolerant to flows in paraphrasing rules." ></td>
	<td class="line x" title="42:182	While many researchers have addressed the issue of paraphrase acquisition reporting promising results as cited above, the other three issues have been left relatively unexplored in spite of their significance in the above sense." ></td>
	<td class="line x" title="43:182	Motivated by this context, in the rest of this paper, we address these remaining three." ></td>
	<td class="line x" title="44:182	3 Readability assessment To the best of our knowledge, there have never been no reports on research to build a computational model of the language proficiency of deaf people, except for the remarkable reports by Michaud and McCoy (2001)." ></td>
	<td class="line x" title="45:182	As a subpart of their research aimed at developing the ICICLE system (McCoy and Masterman, 1997), a language-tutoring application for deaf learners of written English, Michaud and McCoy developed an architecture for modeling the writing proficiency of a user called SLALOM." ></td>
	<td class="line x" title="46:182	SLALOM is designed to capture the stereotypic linear order of acquisition within certain categories of morphological and/or syntactic features of language." ></td>
	<td class="line x" title="47:182	Unfortunately, the modeling method used in SLALOM cannot be directly applied to our domain for three reasons." ></td>
	<td class="line x" title="48:182	AF Unlike writing tutoring, in reading assistance, target sentences are in principle unlimited." ></td>
	<td class="line x" title="49:182	We therefore need to take a wider range of morphosyntactic features into account." ></td>
	<td class="line x" title="50:182	AF SLALOM is not designed to capture the difficulty of any combination of morpho-syntactic features, which it is essential to take into account in reading assistance." ></td>
	<td class="line x" title="51:182	AF Given the need to consider feature combinations, a simple linear order model that is assumed in SLALOM is unsuitable." ></td>
	<td class="line x" title="52:182	3.1 Our approach: We ask teachers To overcome these deficiencies, we took yet another approach where we designed a survey questionnaire targeting teachers at schools for the deaf, and have been collecting readability assessment data." ></td>
	<td class="line x" title="53:182	In this questionnaire, we ask the teachers to compare the readability of a given sentence with paraphrases of it." ></td>
	<td class="line x" title="54:182	The use of paraphrases is of critical importance in our questionnaire since it makes manual readability assessment significantly easier and more reliable." ></td>
	<td class="line x" title="55:182	3.1.1 Targets We targeted teachers of Japanese or English literacy at schools for the deaf for the following reasons." ></td>
	<td class="line x" title="56:182	Ideally, this sort of survey would be carried out by targeting the population segment in question, i.e., deaf students in our study." ></td>
	<td class="line x" title="57:182	In fact, pedagogists and psycholinguists have made tremendous efforts to examine the language proficiency of deaf students by giving them proficiency tests." ></td>
	<td class="line x" title="58:182	Such efforts are very important, but they have had difficulty in capturing enough of the picture to develop a comprehensive and implementable reading proficiency model of the population due to the expense of extensive language proficiency testing." ></td>
	<td class="line x" title="59:182	In contrast, our approach is an attempt to model the knowledge of experts in this field (i.e. , teaching deaf students)." ></td>
	<td class="line x" title="60:182	The targeted teachers have not only rich experiential knowledge about the language proficiency of their students but are also highly skilled in paraphrasing to help their students comprehension." ></td>
	<td class="line x" title="61:182	Since such knowledge gleaned from individual experiences already has some generality, extracting it through a survey should be less costly and thus more comprehensive than investigation based on language proficiency testing." ></td>
	<td class="line x" title="62:182	3.1.2 Questionnaire In the questionnaire, each question consists of several paraphrases, as shown in Figure 1 (a), where (A) is a source sentence, and (B) and (C) are paraphrases of (A)." ></td>
	<td class="line x" title="63:182	Each respondent was asked to assess the relative readability of the paraphrases given for each source sentence, as shown in Figure 1 (b)." ></td>
	<td class="line x" title="64:182	The respondent judged sentence (A) to be the most difficult and judged (B) and (C) to be comparable." ></td>
	<td class="line x" title="65:182	A judgment that sentence D7 CX is easier than sentence D7 CY means that D7 CX is judged likely to be understood by a larger subset of students than D7 CY." ></td>
	<td class="line x" title="66:182	We asked the respondents to annotate the paraphrases with format-free comments, giving the reasons for their judgments, alternative paraphrases, etc. , as shown in Figure 1 (b)." ></td>
	<td class="line x" title="67:182	To make our questionnaire efficient for model acquisition, we had to carefully control the variation in paraphrases." ></td>
	<td class="line x" title="68:182	To do that, we first selected around 50 morpho-syntactic features that are considered influential in sentence readability for deaf people." ></td>
	<td class="line x" title="69:182	For each of those features, we collected several simple example sentences from various sources (literacy textbooks, grammar references, etc.)." ></td>
	<td class="line x" title="70:182	We then manually produced several paraphrases from each of the collected sentences so as to remove the feature that characterized the source sentence from each paraphrase." ></td>
	<td class="line x" title="71:182	For example, in Figure 1, the feature characterizing sentence (A) is a non-restrictive relative clause (i.e. , sentence (A) was selected as an example of this feature)." ></td>
	<td class="line x" title="72:182	Neither (B) nor (C) has this feature." ></td>
	<td class="line x" title="73:182	We also controlled the lexical variety to minimize the effect of lexical factors on readability; we also restricted the vocabulary to a top-2000 basic word set (NIJL, 1991)." ></td>
	<td class="line x" title="74:182	3.1.3 Administration We administrated a preliminary survey targeting three teachers." ></td>
	<td class="line x" title="75:182	Through the survey, we observed that (a) the teachers largely agreed in their assessments of relative readability, (b) their format-free comments indicated that the observed differences in readability were largely explainable in terms of the morphosyntactic features we had prepared, and (c) a largerscaled survey was needed to obtain a statistically reliable model." ></td>
	<td class="line x" title="76:182	Based on these observations, we conducted a more comprehensive survey, in which we prepared 770 questions and sent questionnaires with a random set of 240 of them to teachers of Japanese or English literacy at 50 schools for the deaf." ></td>
	<td class="line x" title="77:182	We Figure 1: Sample question and response asked them to evaluate as many as possible anonymously." ></td>
	<td class="line x" title="78:182	We obtained 4080 responses in total (8.0 responses per question)." ></td>
	<td class="line x" title="79:182	3.2 Readability ranking model The task of ranking a set of paraphrases can be decomposed into comparisons between two elements combinatorially selected from the set." ></td>
	<td class="line x" title="80:182	We consider the problem of judging which of a given pair of paraphrase sentences is more readable/comprehensible for deaf students." ></td>
	<td class="line x" title="81:182	More specifically, given paraphrase pair B4D7 CX BND7 CY B5, our problem is to classify it into either left (D7 CX is easier), right (D7 CY is easier), or comparable (D7 CX and D7 CY are comparable)." ></td>
	<td class="line x" title="82:182	Once the problem is formulated this way, we can use various existing techniques for classifier learning." ></td>
	<td class="line x" title="83:182	So far, we have examined a method of using the support vector machine (SVM) classification technique." ></td>
	<td class="line x" title="84:182	A training/testing example is paraphrase pair B4D7 CX BND7 CY B5 coupled with its quantified class label BWB4D7 CX BND7 CY B5 BE CJA0BDBNBDCL." ></td>
	<td class="line x" title="85:182	Each sentence D7 CX is characterized by a binary feature vector BY D7 CX, and each pair B4D7 CX BND7 CY B5 is characterized by a triple of feature vectors CWBY BV D7 CX D7 CY BNBY C4 D7 CX D7 CY BNBY CA D7 CX D7 CY CX, where AF BY BV D7 CX D7 CY BP BY D7 CX CMBY D7 CY (features shared by D7 CX and D7 CY ), AF BY C4 D7 CX D7 CY BP BY D7 CX CMBY D7 CY (features belonging only to D7 CX ), AF BY CA D7 CX D7 CY BP BY D7 CX CMBY D7 CY (features belonging only to D7 CY )." ></td>
	<td class="line x" title="86:182	BWB4D7 CX BND7 CY B5 represents the difference in readability between D7 CX and D7 CY ; it is computed in the following way." ></td>
	<td class="line x" title="87:182	1." ></td>
	<td class="line x" title="88:182	Let CC D7 CX D7 CY be the set of respondents who assessed B4D7 CX BND7 CY B5." ></td>
	<td class="line x" title="89:182	2." ></td>
	<td class="line x" title="90:182	Given the degree of readability respondent D8 assigned to D7 CX (D7 CY ), map it to real value CSD3D6B4D8BND7B5 BE CJBCBNBDCL so that the lowest degree maps to 0 and the highest degree maps to 1." ></td>
	<td class="line x" title="91:182	For example, the degree of readability assigned to (A) in Figure 1 (b) maps to around 0.1, whereas that assigned to (B) maps to around 0.9." ></td>
	<td class="line x" title="92:182	3. BWB4D7 CX BND7 CY B5BP BD CYCC D7 CX D7 CY CY C8 D8BECC D7 CX D7 CY CSD3D6B4D8BND7 CX B5A0CSD3D6B4D8BND7 CY B5BM Output score CBCR C5 B4D7 CX BND7 CY B5 BE CJA0BDBNBDCL for input B4D7 CX BND7 CY B5 was given by the normalized distance between B4D7 CX BND7 CY B5 and the hyperplane." ></td>
	<td class="line x" title="93:182	3.3 Evaluation and discussion To evaluate the two modeling methods, we conducted a ten-fold cross validation on the set of 4055 paraphrase pairs derived from the 770 questions used in the survey." ></td>
	<td class="line x" title="94:182	To create a feature vector space, we used 355 morpho-syntactic features." ></td>
	<td class="line x" title="95:182	Feature annotation was done semi-automatically with the help of a morphological analyzer and dependency parser." ></td>
	<td class="line x" title="96:182	The task was to classify a given paraphrase pair into either left, right,orcomparable." ></td>
	<td class="line x" title="97:182	Model C5s output class for B4D7 CX BND7 CY B5 was given by BVD0D7 C5 B4D7 CX BND7 CY B5BP B4 D0CTCUD8 (CBCR C5 B4D7 CX BND7 CY B5 AKA0AI D1 ) D6CXCVCWD8 (CBCR C5 B4D7 CX BND7 CY B5 AL AI D1 ) CRD3D1D4CPD6CPCQD0CT (otherwise) BN where AI D1 BE CJA0BDBNBDCL is a variable threshold used to balance precision with recall." ></td>
	<td class="line x" title="98:182	We used the 473 paraphrase pairs that satisfied the following conditions: AFCYBWB4D7 CX BND7 CY B5CY was not less than threshold AI CP (AI CP BP BCBMBH)." ></td>
	<td class="line x" title="99:182	The answer of B4D7 CX BND7 CY B5 is given by BVD0D7 BTD2D7 B4D7 CX BND7 CY B5BP D2 D0CTCUD8 (BWB4D7 CX BND7 CY B5 AKA0AI CP ) D6CXCVCWD8 (BWB4D7 CX BND7 CY B5 AL AI CP ) BM AF B4D7 CX BND7 CY B5 must have been assessed by more then one respondent, i.e., CYCC D7 CX D7 CY CY BQ BDBM AF Agreement ratio BTCVD6B4D7 CX BND7 CY B5 must be sufficiently high, i.e., BTCVD6B4D7 CX BND7 CY B5 AL BCBMBL, where BTCVD6B4D7 CX BND7 CY B5BPB4CUD3D6B4D7 CX BND7 CY B5 A0CPCVD7D8B4D7 CX BND7 CY B5B5BP CYCC D7 CX D7 CY CY, and CUD3D6B4D7 CX BND7 CY B5 and CPCVD7D8B4D7 CX BND7 CY B5 are the number of respondents who agreed and disagreed with BVD0D7 BTD2D7 B4D7 CX BND7 CY B5, respectively." ></td>
	<td class="line x" title="100:182	We judged output class BVD0D7 C5 B4D7 CX BND7 CY B5 correct if and only if BVD0D7 C5 B4D7 CX BND7 CY B5 BP BVD0D7 BTD2D7 B4D7 CX BND7 CY B5." ></td>
	<td class="line x" title="101:182	The overall performance was evaluated based on recall CACR and precision C8D6: CACR BP CYCUB4D7 CX BND7 CY B5CY BVD0D7 C5 B4D7 CX BND7 CY B5 is correctCVCY CYCUB4D7 CX BND7 CY B5CY BVD0D7 BTD2D7 B4D7 CX BND7 CY B5BECUD0CTCUD8BND6CXCVCWD8CVCVCY C8D6BP CYCUB4D7 CX BND7 CY B5CY BVD0D7 C5 B4D7 CX BND7 CY B5 is correctCVCY CYCUB4D7 CX BND7 CY B5CY BVD0D7 C5 B4D7 CX BND7 CY B5BECUD0CTCUD8BND6CXCVCWD8CVCY . The model achieved 95% precision with 89% recall." ></td>
	<td class="line x" title="102:182	This result confirmed that the data we collected through the questionnaires were reasonably noiseless and thus generalizable." ></td>
	<td class="line x" title="103:182	Furthermore, both models exhibited a clear trade-off between recall and precision, indicating that their output scores can be used as a confidence measure." ></td>
	<td class="line x" title="104:182	4 Paraphrase representation We represent paraphrases as transfer patterns between dependency trees." ></td>
	<td class="line x" title="105:182	In this section, we propose a three-layered formalism for representing transfer patterns." ></td>
	<td class="line x" title="106:182	4.1 Types of paraphrases of concern There are various levels of paraphrases as the following examples demonstrate: (1) a. She burst into tears, and he tried to comfort her." ></td>
	<td class="line x" title="107:182	b. She cried, and he tried to console her." ></td>
	<td class="line x" title="108:182	(2) a. It was a Honda that John sold to Tom." ></td>
	<td class="line x" title="109:182	b. John sold a Honda to Tom." ></td>
	<td class="line x" title="110:182	c. Tom bought a Honda from John." ></td>
	<td class="line x" title="111:182	(3) a. They got married three years ago." ></td>
	<td class="line x" title="112:182	b. They got married in 2000." ></td>
	<td class="line x" title="113:182	Lexical vs. structural paraphrases Example (1) includes paraphrases of the single word comfort and the canned phrase burst into tears." ></td>
	<td class="line x" title="114:182	The sentences in (2), on the other hand, exhibit structural and thus more general patterns of paraphrasing." ></td>
	<td class="line x" title="115:182	Both types of paraphrases, lexical and structural paraphrases, are considered useful for many applications including reading assistance and thus should be in the scope our discussion." ></td>
	<td class="line x" title="116:182	Atomic vs. compositional paraphrases The process of paraphrasing (2a) into (2c) is compositional because it can be decomposed into two subprocesses, (2a) to (2b) and (2b) to (2c)." ></td>
	<td class="line x" title="117:182	In developing a resource for paraphrasing, we have only to cover non-compositional (i.e. , atomic) paraphrases." ></td>
	<td class="line x" title="118:182	Compositional paraphrases can be handled if an additional computational mechanism for combining atomic paraphrases is devised." ></td>
	<td class="line x" title="119:182	Meaning-preserving vs. reference-preserving paraphrases It is also useful to distinguish reference-preserving paraphrases from meaningpreserving ones." ></td>
	<td class="line x" title="120:182	The above example in (3) is of the reference-preserving type." ></td>
	<td class="line x" title="121:182	This types of paraphrasing requires the computation of reference to objects outside discourse and thus should be excluded from our scope for the present purpose." ></td>
	<td class="line x" title="122:182	4.2 Dependency trees (MDSs) Previous work on transfer-based machine translation (MT) suggests that the dependency-based representation has the advantage of facilitating syntactic transforming operations (Meyers et al. , 1996; Lavoie et al. , 2000)." ></td>
	<td class="line x" title="123:182	Following this, we adopt dependency trees as the internal representations of target texts." ></td>
	<td class="line x" title="124:182	We suppose that a dependency tree consists of a set of nodes each of which corresponds to a lexeme or compound and a set of edges each of which represents the dependency relation between its ends." ></td>
	<td class="line x" title="125:182	We call such a dependency tree a morpheme-based dependency structure (MDS)." ></td>
	<td class="line x" title="126:182	Each node in an MDS is supposed to be annotated with an open set of typed features that indicate morpho-syntactic and semantic information." ></td>
	<td class="line x" title="127:182	We also assume a type hierarchy in dependency relations that consists of an open set of dependency classes including dependency, compound, parallel, appositive and insertion." ></td>
	<td class="line x" title="128:182	4.3 Three-layered representation Previous work on transfer-based MT systems (Lavoie et al. , 2000; Dorna et al. , 1998) and alignment-based transfer knowledge acquisition (Meyers et al. , 1996; Richardson et al. , 2001) have proven that transfer knowledge can be best represented by declarative structure mapping (transforming) rules each of which typically consists of a pair of source and target partial structures as in the middle of Figure 2." ></td>
	<td class="line x" title="129:182	Adopting such a tree-to-tree style of representation, however, one has to address the issue of the trade-off between expressibility and comprehensibility." ></td>
	<td class="line x" title="130:182	One may want a formalism of structural rule editing translation compilation simplified MDS transfer rule N shika Vnai -> V no wa N dake da." ></td>
	<td class="line x" title="131:182	(someone does not V to nothing but N) (it is only to N that someone does V) MDS transfer rule sp_rule(108, negation, RefNode) :match(RefNode, X4=[pos:postp,lex: shika]), depend(X3=[pos:verb], empty, X4), depend(X1=[pos:aux_verb,lex: nai], X2=[pos:aux_verb*], X3), depend(X4, empty, X5=[pos:noun]), replace(X1, X6=[pos:aux_verb,lex: da]), substitute(X5, X12=[pos:noun]), move_dtrs(X5, X12), substitute(X3, X10=[pos:verb]), : pos: postp lex: shika (except) pos: aux_verb lex: da (copula) pos: postp lex: wa (TOP) X6 X11 X12 pos: noun lex: no (thing) pos: postp lex: dake (only) pos: noun pos: noun aux_verb* pos: aux_verb lex: nai (not) pos: verbX3 X4 X1 X5 X2 X7 X8 X10 pos: verb X9 vws MDS processing operators (=X5) (=X2) (=X3) Figure 2: Three-layered rule representation transformation patterns that is powerful enough to represent a sufficiently broad range of paraphrase patterns." ></td>
	<td class="line x" title="132:182	However, highly expressible formalisms would make it difficult to create and maintain rules manually." ></td>
	<td class="line x" title="133:182	To mediate this trade-off, we devised a new layer of representation to add on the top of the layer of tree-to-tree pattern representation as illustrated in Figure 2." ></td>
	<td class="line x" title="134:182	At this new layer, we use an extended natural language to specify transformation patterns." ></td>
	<td class="line x" title="135:182	The language is designed to facilitate the task of handcoding transformation rules." ></td>
	<td class="line x" title="136:182	For example, to define the tree-to-tree transformation pattern given in the middle of Figure 2, a rule editor needs only to specify its simplified form: (4) N shika Vnai AX V no ha N dake da." ></td>
	<td class="line x" title="137:182	(Someone does V to nothing but N AX It is only to N that someone does V) A rule of this form is then automatically translated into a fully-specified tree-to-tree transformation rule." ></td>
	<td class="line x" title="138:182	We call a rule of the latter form an MDS rewriting rule (SR rule), and a rule of the former form a simplified SR rule (SSR rule)." ></td>
	<td class="line x" title="139:182	The idea is that most of the specifications of an SR rule can usually be abbreviated if a means to automatically complement it is provided." ></td>
	<td class="line x" title="140:182	We use a parser and macros to do so; namely, the rule translator complements an SSR rule by macro expansion and parsing to produce the corresponding SR rule specifications." ></td>
	<td class="line x" title="141:182	The advantages of introducing the SSR rule layer are the following: AF The SSR rule formalism allows a rule writer to edit rules with an ordinary text editor, which makes the task of rule editing much more efficient than providing her/him with a GUI-based complex tool for editing SR rules directly." ></td>
	<td class="line x" title="142:182	AF The use of the extended natural language also has the advantage in improving the readability of rules for rule writers, which is particularly important in group work." ></td>
	<td class="line x" title="143:182	AF To parse SSR rules, one can use the same parser as that used to parse input texts." ></td>
	<td class="line x" title="144:182	This also improves the efficiency of rule development because it significantly reduces the burden of maintaining the consistency between the POS-tag set used for parsing input and that used for rule specifications." ></td>
	<td class="line x" title="145:182	The SSR rule layer shares underlying motivations with the formalism reported by Hermjakob et al.(2002)." ></td>
	<td class="line x" title="147:182	Our formalism is, however, considerably extended so as to be licensed by the expressibility of the SR rule representation and to be annotated with various types of rule applicability conditions including constraints on arbitrary features of nodes, structural constraints, logical specifications such as disjunction and negation, closures of dependency relations, optional constituents, etc. The two layers for paraphrase representation are fully implemented on our paraphrasing engine KURA (Takahashi et al. , 2001) coupled with another layer for processing MDSs (the bottom layer illustrated in Figure 2)." ></td>
	<td class="line x" title="148:182	The whole system of KURA and part of the transer rules implemented on it (see Section 5 below) are available at http://cl.aistnara.ac.jp/lab/kura/doc/." ></td>
	<td class="line x" title="149:182	5 Post-transfer error detection What kinds of transfer errors tend to occur in lexical and structural paraphrasing?" ></td>
	<td class="line x" title="150:182	To find it out, we conducted a preliminary investigation." ></td>
	<td class="line x" title="151:182	This section reports a summary of the results." ></td>
	<td class="line x" title="152:182	See (Fujita and Inui, 2002) for further details." ></td>
	<td class="line x" title="153:182	We implemented over 28,000 transfer rules for Japanese paraphrases on the KURA paraphrasing engine based on the rules previously reported in (Sato, 1999; Kondo et al. , 1999; Kondo et al. , 2001; Iida et al. , 2001) and existing lexical resources such as thesauri and case frame dictionaries." ></td>
	<td class="line x" title="154:182	The implemented rules ranged from such lexical paraphrases as those that replace a word with its synonym to such syntactic/structural paraphrases as those that remove a cleft construction from a sentence, devide a sentence, etc. We then fed KURA with a set of 1,220 sentences randomly sampled from newspaper articles and obtained 630 transferred output sentences." ></td>
	<td class="line x" title="155:182	The following are the tendencies we observed: AF The transfer errors observed in the experiment exhibited a wide range of variety from morphological errors to semantic and discourse-related ones." ></td>
	<td class="line x" title="156:182	AF Most types of errors tended to occur regardless of the types of transfer." ></td>
	<td class="line x" title="157:182	This suggests that if one creates an error detection module specialized for a particular error type, it works across different types of transfer." ></td>
	<td class="line x" title="158:182	AF The most frequent error type involved inappropriate conjugation forms of verbs." ></td>
	<td class="line x" title="159:182	It is, however, a matter of morphological generation and can be easily resolved." ></td>
	<td class="line x" title="160:182	AF Errors in regard to verb valency and selectional restriction also tended to be frequent and fatal, and thus should have preference as a research topic." ></td>
	<td class="line x" title="161:182	AF The next frequent error type was related to the difference of meaning between near synonyms." ></td>
	<td class="line x" title="162:182	However, this type of errors could often be detected by a model that could detect errors of verb valency and selectional restriction." ></td>
	<td class="line x" title="163:182	Based on these observations, we concluded that the detection of incorrect verb valences and verbcomplement cooccurrence was one of the most serious problems that should have preference as a research topic." ></td>
	<td class="line x" title="164:182	We are now conducting experiments on empirical methods for detecting this type of errors (Fujita et al. , 2003)." ></td>
	<td class="line x" title="165:182	6 Conclusion This paper reported on the present results of our ongoing research on text simplification for reading assistance targeting congenitally deaf people." ></td>
	<td class="line x" title="166:182	We raised four interrelated issues that we needed address to realize this application and presented our previous activities focuing on three of them: readability assessment, paraphrase representation and posttransfer error detection." ></td>
	<td class="line x" title="167:182	Regarding readability assessment, we proposed a novel approach in which we conducted questionnaire surveys to collect readability assessment data and took a corpus-based empirical method to obtain a readability ranking model." ></td>
	<td class="line x" title="168:182	The results of the surveys show the potential impact of text simplification on reading assistance." ></td>
	<td class="line x" title="169:182	We conducted experiments on the task of comparing the readability of a given paraphrase pair and obtained promising results by SVMbased classifier induction (95% precision with 89% recall)." ></td>
	<td class="line x" title="170:182	Our approach should be equally applicable to other population segments such as aphasic readers and second-language learners." ></td>
	<td class="line x" title="171:182	Our next steps includes the investigation of the drawbacks of the present bag-of-features modeling approach." ></td>
	<td class="line x" title="172:182	We also need to consider a method to introduce the notion of user classes (e.g. beginner, intermediate and advanced)." ></td>
	<td class="line x" title="173:182	Textual aspects of readability will also need to be considered, as discussed in (Inui and Nogami, 2001; Siddahrthan, 2003)." ></td>
	<td class="line x" title="174:182	Regarding paraphrase representation, we presented our revision-based lexico-structural paraphrasing engine." ></td>
	<td class="line x" title="175:182	It provides a fully expressible scheme for representating paraphrases, while preserving the easiness of handcraft paraphrasing rules by providing an extended natural language as a means of pattern editting." ></td>
	<td class="line x" title="176:182	We have handcrafted over a thousand transfer rules that implement a broad range of lexical and structural paraphrasing." ></td>
	<td class="line x" title="177:182	The problem of error detection is also critical." ></td>
	<td class="line x" title="178:182	When we find a effective solution to it, we will be ready to integrate the technologies into an application system of text simplification and conduct userand task-oriented evaluations." ></td>
	<td class="line x" title="179:182	Acknowledgments The research presented in this paper was partly funded by PREST, Japan Science and Technology Corporation." ></td>
	<td class="line x" title="180:182	We thank all the teachers at the schools for the deaf who cooperated in our questionnaire survey and Toshihiro Agatsuma (Joetsu University of Education) for his generous and valuable cooperation in the survey." ></td>
	<td class="line x" title="181:182	We also thank Yuji Matsumoto and his colleagues (Nara Advanced Institute of Science and Technology) for allowing us to use their NLP tools ChaSen and CaboCha, Taku Kudo (Nara Advanced Institute of Science and Technology) for allowing us to use his SVM tool, and Takaki Makino and his colleagues (Tokyo University) for allowing us to use LiLFeS, with which we implemented KURA." ></td>
	<td class="line x" title="182:182	We also thank the anonymous reviewers for their suggestive and encouraging comments." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W03-1605
Interrogative Reformulation Patterns And Acquisition Of Question Paraphrases
Tomuro, Noriko;"></td>
	<td class="line x" title="1:187	Interrogative Reformulation Patterns and Acquisition of Question Paraphrases Noriko Tomuro DePaul University School of Computer Science, Telecommunications and Information Systems 243 S. Wabash Ave. Chicago, IL 60604 U.S.A. tomuro@cs.depaul.edu Abstract We describe a set of paraphrase patterns for questions which we derived from a corpus of questions, and report the result of using them in the automatic recognition of question paraphrases." ></td>
	<td class="line x" title="2:187	The aim of our paraphrase patterns is to factor out different syntactic variations of interrogative words, since the interrogative part of a question adds a syntactic superstructure on the sentence part (i.e. , the rest of the question), thereby making it difficult for an automatic system to analyze the question." ></td>
	<td class="line x" title="3:187	The patterns we derived are rules which map surface syntactic structures to semantic case frames, which serve as the canonical representation of questions." ></td>
	<td class="line x" title="4:187	We also describe the process in which we acquired question paraphrases, which we used as the test data." ></td>
	<td class="line x" title="5:187	The results obtained by using the patterns in paraphrase recognition were quite promising." ></td>
	<td class="line x" title="6:187	1 Introduction The phenomenon of paraphrase in human languages is essentially the inverse of ambiguity  a given sentence could ambiguously have several meanings, while any given meaning could be formulated into several paraphrases using various words and syntactic constructions." ></td>
	<td class="line oc" title="7:187	For this reason, paraphrase poses a great challenge for many Natural Language Processing (NLP) tasks, just as ambiguity does, notably in text summarization and NL generation (Barzilay and Lee, 2003; Pang et al. , 2003)." ></td>
	<td class="line x" title="8:187	The problem of paraphrase is important in Question-Answering systems as well, because the systems must return the same answer to questions which ask for the same thing but are expressed in different ways." ></td>
	<td class="line x" title="9:187	Recently there have been several work which utilized reformulations of questions as a way to fill the chasm between words in a question and those in a potential answer sentence (Hermjakob et al. , 2002; Murata and Isahara, 2001; Agichtei et al. , 2001)." ></td>
	<td class="line x" title="10:187	In general, paraphrasing a question, be it for recognition or generation, is more difficult than a declarative sentence, because interrogative words carry a meaning of their own, which is subject to reformulation, in addition to the rest (or the sentence part) of the question." ></td>
	<td class="line x" title="11:187	Reformulations of the interrogative part of questions have some interesting characteristics which are distinct from reformulations of the sentence part or declarative sentences." ></td>
	<td class="line x" title="12:187	First, paraphrases of interrogatives are strongly lexical and idiosyncratic, containing many keywords, idioms or fixed expressions." ></td>
	<td class="line x" title="13:187	For example, for a question How can I clean teapots? one can easily think of some variations of the how part while fixing the sentence part: In what way should I clean teapots? What do I have to do to clean teapots? What is the best way to clean teapots? What method is used for cleaning teapots? How do I go about cleaning teapots? What is involved in cleaning teapots?" ></td>
	<td class="line x" title="14:187	What should I do if I want to clean teapots?" ></td>
	<td class="line x" title="15:187	Second, reformulation patterns of interrogatives seem to be governed by question types." ></td>
	<td class="line x" title="16:187	For example, the variation patterns above apply to almost all how-to questions, while why questions undergo a different set of transformations (e.g. Why, For what reason , What was the reason why  etc.)." ></td>
	<td class="line x" title="17:187	Also, further observations suggest that questions of the same question type have the same semantic empty category: something (or some things) which a question is asking." ></td>
	<td class="line x" title="18:187	In this paper, we describe the set of paraphrase/reformulation patterns we derived from a corpus of questions, and report the result of using them in the automatic recognition of question paraphrases." ></td>
	<td class="line x" title="19:187	We also describe the process in which we acquired paraphrases, which we used as the test data." ></td>
	<td class="line x" title="20:187	Our approaches to constructing those resources were manual  the transformation patterns were derived by inspecting an existing large corpus of questions, and the paraphrases were collected by asking web users to type in reformulations of sample questions." ></td>
	<td class="line x" title="21:187	Our work here is focused on the reformulations of the interrogative part of questions in contrast to other work in question-answering where major emphases are placed on the reformulations of phrases or words in the sentence part (Lin and Pantel, 2001; Hermjakob et al. , 2002)." ></td>
	<td class="line x" title="22:187	The patterns we derived are essentially rules which map surface syntactic structures to semantic case frame representations." ></td>
	<td class="line x" title="23:187	We use those case frame representations when we compare questions for similarity." ></td>
	<td class="line x" title="24:187	The results obtained by the use of the patterns in paraphrase recognition were quite promising." ></td>
	<td class="line x" title="25:187	The motivation behind the work we present here is to improve the retrieval accuracy of our system called FAQFinder (Burke et al. , 1997)." ></td>
	<td class="line x" title="26:187	FAQFinder is a web-based, natural language question-answering system which uses Usenet Frequently Asked Questions (FAQ) files to answer users questions." ></td>
	<td class="line x" title="27:187	Each FAQ file contains a list of question-and-answer (Q&A) pairs on a particular subject." ></td>
	<td class="line x" title="28:187	Given a users question as a query, FAQFinder tries to find an answer by matching the users question against the question part of each Q&A pair, and displays 5 FAQ questions which are ranked the highest by the systems similarity measure." ></td>
	<td class="line x" title="29:187	Thus, FAQFinders task is to identify FAQ questions which are the best paraphrases of the users question." ></td>
	<td class="line x" title="30:187	Figure 1 shows a screen snapshot of FAQFinder where a users query Figure 1: The 5 best-matching FAQ questions returned by FAQFinder What do I have to do to clean teapots? is matched against the Q&A pairs in drink tea faq." ></td>
	<td class="line x" title="31:187	The current similarity measure used in the system is a combination of four independent metrics: term vector similarity, coverage, semantic similarity, and question type similarity (Lytinen and Tomuro, 2002)." ></td>
	<td class="line x" title="32:187	Although those metrics are additive and complemental to each other, they cannot capture the relations and interactions between them." ></td>
	<td class="line x" title="33:187	The idea of paraphrase patterns proposed in this paper is a first step in developing an alternative, integrated similarity measure for question sentences." ></td>
	<td class="line x" title="34:187	2 Paraphrasing Patterns for Questions 2.1 Training Data Paraphrasing patterns were extracted from a large corpus of question sentences which we had used in our previous work (Tomuro and Lytinen, 2001; Lytinen and Tomuro, 2002)." ></td>
	<td class="line x" title="35:187	It consisted of 12938 example questions taken from 485 Usenet FAQ files." ></td>
	<td class="line x" title="36:187	In the current work, we used a subset of that corpus consisting of examples whose question types were PRC (procedure), RSN (reason) or ATR (atrans)." ></td>
	<td class="line x" title="37:187	Those question types are members of the 12 question types we had defined in our previous work (Tomuro and Lytinen, 2001)." ></td>
	<td class="line x" title="38:187	As described in that paper, PRC questions are typical how-to questions and RSN questions are why questions." ></td>
	<td class="line x" title="39:187	The type ATR ;(1) how can/do  anyVerb (defpattern prc-how 1 (:WH how) (:S <NPS>) (:V <V>) (:O <NPO>) => (:proc )?" ></td>
	<td class="line x" title="40:187	(:actor <NPS>) (:verb <V>) (:theme <NPO>)) ;(2) how can/do  obtain (defpattern atr-1-how-obtainV 3 (:WH how) (:S <NPS>) (:V <obtainV>) (:O <NPO>) => (:source )?" ></td>
	<td class="line x" title="41:187	(:proc )?" ></td>
	<td class="line x" title="42:187	(:actor <NPS>) (:verb <obtainV>) (:theme <NPO>)) ;(3) what is the  method for obtaining (defpattern atr-1-what-is-method 4 (:WH what) (:S NIL) (:V <beV>) (:O <methodN>) (:VG <obtainV>) (:NP <NPO>) => (:source )?" ></td>
	<td class="line x" title="43:187	(:proc )?" ></td>
	<td class="line x" title="44:187	(:actor I) (:verb <obtainV>) (:theme <NPO>)) ;(4) who sells (defpattern atr-who-sourceNP 4 (:WH who) (:S NIL) (:V <sellV>) (:O <NPO>) => (:source )?" ></td>
	<td class="line x" title="45:187	(:proc )?" ></td>
	<td class="line x" title="46:187	(:actor I) (:verb obtain) (:theme <NPO>)) Figure 2: Example Paraphrase Patterns (for ATRANS in Conceptual Dependency (Schank, 1973)) is essentially a special case of PRC, where the (desire for the) transfer of possession is strongly implied." ></td>
	<td class="line x" title="47:187	An example question of this type would be How can I get tickets for the Indy 500?." ></td>
	<td class="line x" title="48:187	Not only do ATR questions undergo the paraphrasing patterns of PRC questions, they also allow reformulations which ask for the (source or destination) location or entity of the thing(s) being sought, for instance, Where can I get tickets for the Indy 500? and Who sells tickets for the Indy 500?." ></td>
	<td class="line x" title="49:187	We had observed that such ATR questions were in fact asked quite frequently in question-answering systems." ></td>
	<td class="line x" title="50:187	1 Also those question types seem to have a richer set of paraphrasing patterns than other types (such as definition or simple reference questions given in TREC competitions (Voorhees, 2000)) with regard to the interrogative reformulation." ></td>
	<td class="line x" title="51:187	In the corpus, there were 2417, 1022 and 968 questions of type PRC, RSN, ATR respectively, and they constituted the training data in the current work." ></td>
	<td class="line x" title="52:187	1 Although we did not use it in the current work, we also had access to the user log of AskJeeves system (http://www.askjeeves.com)." ></td>
	<td class="line x" title="53:187	We observed that a large portion of the user questions were ATR questions." ></td>
	<td class="line x" title="54:187	2.2 Paraphrase Patterns The aim of our paraphrasing patterns is to account for different syntactic variations of interrogative words." ></td>
	<td class="line x" title="55:187	As we showed examples in section 1, the interrogative part of a question adds a syntactic superstructure to the sentence part, thereby making it difficult for an automatic system to get to the core of the question." ></td>
	<td class="line x" title="56:187	By removing this syntactic overhead, we can derive the canonical representations of questions, and by using them we can perform a manyto-one matching instead of many-to-many when we compare questions for similarity." ></td>
	<td class="line x" title="57:187	In the pre-processing stage, we first applied a shallow parser to each question in the training data and extracted its phrase structure." ></td>
	<td class="line x" title="58:187	The parser we used is customized for interrogative sentences, and its complexity is equivalent to a finite-state machine." ></td>
	<td class="line x" title="59:187	The output of the parser is a list of phrases in which each phrase is labeled with its syntactic function in the question (subject, verb, object etc.)." ></td>
	<td class="line x" title="60:187	Passive questions are converted to active voice in the last step of the parser by inverting the subject and object noun phrases." ></td>
	<td class="line x" title="61:187	Then using the pre-processed data, we manually inspected all questions and defined patterns which seemed to apply to more than two instances." ></td>
	<td class="line x" title="62:187	By this enumeration process, we derived a total of 127 patterns, consisting of 18, 23 and 86 patterns for PRC, RSN and ATR respectively." ></td>
	<td class="line x" title="63:187	Each pattern is expressed in the form of a rule, where the left-hand side (LHS) expresses the phrase structure of a question, and the right-hand side (RHS) expresses the semantic case frame representation of the question." ></td>
	<td class="line x" title="64:187	When a rule is matched against a question, the LHS of the rule is compared with the question first, and if they match, the RHS is generated using the variable binding obtained from the LHS." ></td>
	<td class="line x" title="65:187	Figure 2 shows some example patterns." ></td>
	<td class="line x" title="66:187	In a pattern, both LHS and RHS are a set of slotvalue tuples." ></td>
	<td class="line x" title="67:187	In each tuple, the first element, which is always prefixed with :, is the slot name and the remaining elements are the values." ></td>
	<td class="line x" title="68:187	Slots names which appear on the LHS (:S, :V, :O, etc)." ></td>
	<td class="line x" title="69:187	relate to syntactic phrases, while those on the RHS (:actor, :theme, :source etc)." ></td>
	<td class="line x" title="70:187	indicate semantic cases." ></td>
	<td class="line x" title="71:187	A slot value could be either a variable, indicated by a symbol enclosed in <> (e.g. <NPS>), or a constant (e.g. how)." ></td>
	<td class="line x" title="72:187	A variable could be either constrained (e.g. <obtainV>) or unconstrained (e.g. <NPS>, <NPO>)." ></td>
	<td class="line x" title="73:187	Constrained variables are defined separately, and they specify that a phrase to be matched must satisfy certain conditions." ></td>
	<td class="line x" title="74:187	Most of the conditions are lexical constraints  a phrase must contain a word of a certain class." ></td>
	<td class="line x" title="75:187	For instance, <obtainV> denotes a word class obtainV and it includes words such as obtain, get, buy and purchase." ></td>
	<td class="line x" title="76:187	Word classes are groupings of words appeared in the training data which have similar meanings (i.e. , synonyms), and they were developed in tandem with the paraphrase patterns." ></td>
	<td class="line x" title="77:187	Whether constrained or unconstrained, a variable gets bound with one or more words in the matched question (if possible for constrained variables)." ></td>
	<td class="line x" title="78:187	A constant indicates a word and requires the word to exist in the tuple." ></td>
	<td class="line x" title="79:187	NIL and ? are special constants where NIL requires the tuple (phrase in the matched question) to be empty, and ? indicates that the slot is an empty category." ></td>
	<td class="line x" title="80:187	Each rule is also given a priority level (e.g. 3 in pattern (2)), with a large number indicating a high priority." ></td>
	<td class="line x" title="81:187	In the example patterns shown in Figure 2, pattern (1) matches a typical how-to question such as How do I make beer?." ></td>
	<td class="line x" title="82:187	Its meaning, according to the case frame generated by the RHS, would be I for the actor, make for the verb, beer for the theme, and the empty category is :proc (for proFigure 3: Paraphrase Entry Site cedure)." ></td>
	<td class="line x" title="83:187	Patterns (2) through (4) are rules for ATR questions." ></td>
	<td class="line x" title="84:187	Notice they all have two empty categories  :proc and :source  as consistent with our definition of type ATR." ></td>
	<td class="line x" title="85:187	Also notice the semantic case roles are taken from various syntactic phrases: pattern (2) takes the actor and theme from syntactic subject and object straight-forwardly, while pattern (3), which matches a question such as What is a good way to buy tickets for the Indy 500, takes the theme from the object in the infinitival phrase (:NP) and fills the actor with I which is implicit in the question." ></td>
	<td class="line x" title="86:187	Pattern (4), which matches a question such as Who sells tickets for the Indy 500, changes the verb to obtain as well as filling the implicit actor with I." ></td>
	<td class="line x" title="87:187	This way, ATR paraphrases are mapped to identical case frames (modulo variable binding)." ></td>
	<td class="line x" title="88:187	3 Acquisition of Question Paraphrases To evaluate the question paraphrase patterns, we used the set of question paraphrases which we had acquired in our previous work (Tomuro and Lytinen, 2001) for the test data." ></td>
	<td class="line x" title="89:187	In that work, we obtained question paraphrases in the following way." ></td>
	<td class="line x" title="90:187	First we selected a total of 35 questions from 5 FAQ categories: astronomy, copyright, gasoline, mutualfund and tea." ></td>
	<td class="line x" title="91:187	Then we created a web site where users could enter paraphrases for any of the 35 questions." ></td>
	<td class="line x" title="92:187	Figure 3 shows a snapshot of the site when the astronomyFAQ is displayed." ></td>
	<td class="line x" title="93:187	2 After keeping the site public for two weeks, a total of 1000 paraphrases were entered." ></td>
	<td class="line x" title="94:187	Then we inspected each entry and discarded ill-formed ones (such as keywords or boolean queries) and incorrect paraphrases." ></td>
	<td class="line x" title="95:187	This process left us with 714 correct paraphrases (including the original 35 questions)." ></td>
	<td class="line x" title="96:187	Figure 4 shows two sets of example paraphrases entered by the site visitors." ></td>
	<td class="line x" title="97:187	In each set, the first sentence in bold-face is the original question (and its question type)." ></td>
	<td class="line x" title="98:187	In the paraphrases of the first question, we see more variations of the interrogative part of ATR questions." ></td>
	<td class="line x" title="99:187	For instance, 1c explicitly refers to the source location/entity as store and 1d uses place." ></td>
	<td class="line x" title="100:187	Those words are essentially hyponyms/specializations of the concept location." ></td>
	<td class="line x" title="101:187	Paraphrases of the second question, on the other hand, show variations in the sentence part of the questions." ></td>
	<td class="line x" title="102:187	The expression same face in the original question is rephrased as one side (2a), same side (2b), not  other side (2c) and dark side (2f)." ></td>
	<td class="line x" title="103:187	The verb is changed from show to face (2b), see (2c, 2d) and look (2e)." ></td>
	<td class="line x" title="104:187	Those rephrasings are rather subtle, requiring deep semantic knowledge and inference beyond lexical semantics, that is, the common-sense knowledge." ></td>
	<td class="line x" title="105:187	To see the kinds of rephrasing the web users entered, we categorized the 679 (= 714 35) paraphrased questions roughly into the following 6 categories." ></td>
	<td class="line x" title="106:187	3 (1) Lexical substitution  synonyms; involves no or minimal sentence transformation (2) Passivization (3) Verb denominalization  e.g. destroy vs. destruction (4) Lexical semantics & inference  e.g. show vs. see (5) Interrogative reformation  variations in the interrogative part (6) Common-sense  e.g. dark side of the Moon Table 1 shows the breakdown by those categories." ></td>
	<td class="line x" title="107:187	As you see, interrogative transformation had the 2 In order to give a context to a question, we put a link (wanna know the answer?) to the actual Q&A pair in the FAQ file for each sample question." ></td>
	<td class="line x" title="108:187	3 If a paraphrase fell under two or more categories, the one with the highest number was chosen." ></td>
	<td class="line x" title="109:187	Table 1: Breakdown of the paraphrases by paraphrase category Category # of paraphrases (1) Lexical substitution 168 (25 %) (2) Passivization 37 (5 %) (3) Verb denominalization 18 (3 %) (4) Lexical semantics & inference 107 (16 %) (5) Interrogative reformation 339 (50 %) (6) Common-sense 10 (1 %) Total 679 (100 %) largest proportion." ></td>
	<td class="line x" title="110:187	This was partly because all transformations to questions that start with What were classified as this category." ></td>
	<td class="line x" title="111:187	But the data indeed contained many instances of transformation between different interrogatives (why $ how $ where $ who etc.)." ></td>
	<td class="line x" title="112:187	From the statistics above, we can thus see the importance of understanding the reformulations of the interrogatives." ></td>
	<td class="line x" title="113:187	As for other categories, lexical substitution had the next largest proportion." ></td>
	<td class="line x" title="114:187	This means a fair number of users entered relatively simple transformations." ></td>
	<td class="line x" title="115:187	On this, (Lin and Pantel, 2001) makes a comment on manually generated paraphrases (as versus automatically extracted paraphrases): It is difficult for humans to generate a diverse list of paraphrases, given a starting formulation and no context." ></td>
	<td class="line x" title="116:187	Our data is in agreement with their observations indeed." ></td>
	<td class="line x" title="117:187	4 Evaluation Using the paraphrase data described in the previous section, we evaluated our question reformulation patterns on coverage and in the paraphrase recognition task." ></td>
	<td class="line x" title="118:187	From the data, we selected all paraphrases derived from the original questions of type PRC, RSN and ATR." ></td>
	<td class="line x" title="119:187	There were 306 such examples, and they constituted the testset for the evaluation." ></td>
	<td class="line x" title="120:187	4.1 Coverage We first applied the transformation patterns to all examples in the testset and generated their case frame representations." ></td>
	<td class="line x" title="121:187	In the 306 examples, 289 of them found at least one pattern." ></td>
	<td class="line x" title="122:187	If an example matched with two or more patterns, the one with the highest priority was selected." ></td>
	<td class="line x" title="123:187	Thus the coverage was 94%." ></td>
	<td class="line x" title="124:187	However after inspecting the results, we observed that in some successful matches, the syntactic structure of the question did not exactly correspond to 1." ></td>
	<td class="line x" title="125:187	Where can I get British tea in the United States?" ></td>
	<td class="line x" title="126:187	[ATR] a. How can I locate some British tea in the United States?" ></td>
	<td class="line x" title="127:187	b. Who sells English tea in the U.S.?" ></td>
	<td class="line x" title="128:187	c. What stores carry British tea in the United States?" ></td>
	<td class="line x" title="129:187	d. Where is the best place to find English tea in the U.S.?" ></td>
	<td class="line x" title="130:187	e. Where exactly should I go to buy British tea in the U.S.?" ></td>
	<td class="line x" title="131:187	f. How can an American find British tea?" ></td>
	<td class="line x" title="132:187	2." ></td>
	<td class="line x" title="133:187	Why does the Moon always show the same face to the Earth?" ></td>
	<td class="line x" title="134:187	[RSN] a. What is the reason why the Moon show only one side to the Earth?" ></td>
	<td class="line x" title="135:187	b. Why is the same side of the Moon facing the Earth all the time?" ></td>
	<td class="line x" title="136:187	c. How come we do not see the other side of the Moon from Earth?" ></td>
	<td class="line x" title="137:187	d. Why do we always see the same side of the Moon?" ></td>
	<td class="line x" title="138:187	e. Why do the Moon always look the same from here?" ></td>
	<td class="line x" title="139:187	f. Why is there the dark side of Moon?" ></td>
	<td class="line x" title="140:187	Figure 4: Examples of question paraphrases entered by the web users the pattern as intended." ></td>
	<td class="line x" title="141:187	For example, How can I learn to drink less tea and coffee? 4 matched the pattern (1) shown in Figure 2 and produced a frame where I was the actor, learn was the verb and the theme was null (because the shallow parser analyzed to drink less tea and coffee to be a verb modifier)." ></td>
	<td class="line x" title="142:187	Although the difficulty with this example was incurred by inadequate pre-processing or inherent difficulty in shallow parsing, the end result was a spurious match nonetheless." ></td>
	<td class="line x" title="143:187	In the 289 matches, 15 of them were such false matches." ></td>
	<td class="line x" title="144:187	As for the 17 examples which failed to match with any patterns, one example is What internet resources exist regarding copyright? 5  there were patterns that matched the interrogative part (What internet resources), but all of them had constrained variables for the verb which did not match exist." ></td>
	<td class="line x" title="145:187	Other failed matches were because of elusive paraphrasing." ></td>
	<td class="line x" title="146:187	For example, for an original question Why is evaporative emissions a problem?, web users entered Whats up with evaporative emissions? and What is wrong with evaporative emissions?." ></td>
	<td class="line x" title="147:187	Those paraphrases seem to be keyed off from problem rather than why." ></td>
	<td class="line x" title="148:187	4 The original question for this paraphrase was How can I get rid of a caffeine habit?." ></td>
	<td class="line x" title="149:187	5 This question can be paraphrased as Where can I find information about copyright on the internet? 4.2 Paraphrase Recognition Using the case frame representations derived from the first experiment, we applied a frame similarity measure for all pairs of frames." ></td>
	<td class="line x" title="150:187	This measure is rather rudimentary, and we are planning to fine-tune it in the future work." ></td>
	<td class="line x" title="151:187	This measure focuses on the effect of paraphrase patterns  how much the canonical representations, after the variations of interrogatives are factored out, can bring closer the (true) paraphrases (i.e. , questions generated from the same original question), thereby possibly improving the recognition of paraphrases." ></td>
	<td class="line x" title="152:187	The frame similarity between a pair of frames is defined as a weighted sum of two similarity scores: one for the interrogative part (which we call interrogative similarity) and another for the sentence part (which we call case role similarity)." ></td>
	<td class="line x" title="153:187	The interrogative similarity is obtained by computing the average slot-wise correspondence of the empty categories (slots whose value is ?), where the correspondence value of a slot is 1 if both frames have ? for the slot or 0 otherwise." ></td>
	<td class="line x" title="154:187	The case role similarity, on the other hand, is obtained by computing the distance between two term vectors, where terms are the union of words that appeared in the remaining slots (i.e. , non-empty category slots) of the two frames." ></td>
	<td class="line x" title="155:187	Those terms/words are considered as a bag of words (as in Information Retrieval), irrespective of the order or the slots in which they appeared." ></td>
	<td class="line x" title="156:187	We 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Rejection R eca ll FrSim_0.5 FrSim_0.0 Sent Figure 5: Recall vs. Rejection chose this scheme for the non-empty category slots because our current work does not address the issue of paraphrases in the sentence part of the questions (as we mentioned earlier)." ></td>
	<td class="line x" title="157:187	Value of each term in a frame is either 1 if the word is present in the frame or 0 otherwise, and the cosine of the two vectors is returned as the distance." ></td>
	<td class="line x" title="158:187	The final frame similarity value, after applying weights which sum to 1, would be between 0 and 1, where 1 indicates the strongest similarity." ></td>
	<td class="line x" title="159:187	6 Using the frame similarity measure, we computed two versions  one with 0.5 for the weight of the interrogative similarity and another with 0.0." ></td>
	<td class="line x" title="160:187	In addition, we also computed a baseline metric, sentence similarity." ></td>
	<td class="line x" title="161:187	It was computed as the term vector similarity where terms in the vectors were taken from the phrase representation of the questions (i.e. , syntactic phrases generated by the shallow parser)." ></td>
	<td class="line x" title="162:187	Thus the terms here included various wh-interrogative words as well as words that were dropped or changed in the paraphrase patterns (e.g. words instantiated with <methodN> in pattern (3) in Figure 2)." ></td>
	<td class="line x" title="163:187	This metric produces a value between 0 and 1, thus it is comparable to the frame similarity." ></td>
	<td class="line x" title="164:187	The determination of whether or not two frames (or questions) are paraphrase of each other depends on the threshold value  if the similarity value is above a certain threshold, the two frames/questions are determined to be paraphrases." ></td>
	<td class="line x" title="165:187	With the 306 case frames in the testset, there were a total of 46665 (= 306305 2 ) distinct combinations of frames, and 3811 6 If either one of the frames is null (for which the patternmatching failed), the frame similarity is 0." ></td>
	<td class="line x" title="166:187	of them were (true) paraphrases." ></td>
	<td class="line x" title="167:187	After computing the three metrics (two versions of frame similarity, plus sentence similarity) for all pairs, we evaluated their performance by examining the trade-off between recall and rejection for varying threshold values." ></td>
	<td class="line x" title="168:187	Recall is defined in the usual way, as the ratio of true positives (= # classified as paraphrase # true paraphrases ), and rejection is defined as the ratio of true negatives (= # classified as non-paraphrase # true non-paraphrases )." ></td>
	<td class="line x" title="169:187	We chose to use rejection instead of precision or accuracy because those measures are not normalized for the number of instances in the classification category (# true paraphrases vs. # true non-paraphrases); since our testset had a skewed distribution (8% paraphrases, 92% non-paraphrases), those measures would have only given scores in which the results for paraphrases was overshadowed by those for non-paraphrases." ></td>
	<td class="line x" title="170:187	Figure 5 shows the recall vs. rejection curves for the three metrics." ></td>
	<td class="line x" title="171:187	As you see, both versions of the frame similarity (FrSim 0.5 and FrSim 0.0 in the figure) outperformed the sentence similarity (Sent), suggesting that the use of semantic representation was very effective in recognizing paraphrases compared to syntactic representation." ></td>
	<td class="line x" title="172:187	For example, FrSim 0.5 correctly recognized 90% of the true paraphrases while making only a 10% error in recognizing false positives, whereas Sent made a slightly over 20% error in achieving the same 90% recall level." ></td>
	<td class="line x" title="173:187	This is a quite encouraging result." ></td>
	<td class="line x" title="174:187	The figure also shows that FrSim 0.5 performed much better than FrSim 0.0." ></td>
	<td class="line x" title="175:187	This means that explicit representation of empty categories (or question types) contributed significantly to the paraphrase recognition." ></td>
	<td class="line x" title="176:187	This also underscores the importance of considering the formulations of interrogatives in analyzing question sentences." ></td>
	<td class="line x" title="177:187	5 Conclusions and Future Work In this paper, we showed that automatic recognition of question paraphrases can benefit from understanding the various formulations of the interrogative part." ></td>
	<td class="line x" title="178:187	Our paraphrase patterns remove those variations and produce canonical forms which reflect the meaning of the questions (i.e. , case frames)." ></td>
	<td class="line x" title="179:187	Not only does this semantic representation facilitates simple and straight-forward ways to compute the similarity of questions, it also produces more accurate results than syntactic phrase representation." ></td>
	<td class="line x" title="180:187	Our immediate future work is to define paraphrase patterns for other question types." ></td>
	<td class="line x" title="181:187	While doing so, we would also like to look into ways to automatically extract patterns." ></td>
	<td class="line x" title="182:187	A good starting point would be (Agichtei et al. , 2001), which looked for common n-grams anchored at the beginning of questions." ></td>
	<td class="line x" title="183:187	Once the syntactic superstructure of the interrogative part is factored out, the next task is to tackle reformulations of the sentence part of questions." ></td>
	<td class="line x" title="184:187	Lately several interesting efforts have been made to extract paraphrase expressions automatically, for instance (Lin and Pantel, 2001; Shinyama et al. , 2002)." ></td>
	<td class="line x" title="185:187	We would like to experiment doing the same with the web as the resource." ></td>
	<td class="line x" title="186:187	Finally, we would like to synthesize the reformulation patterns of the two parts of questions and develop unified paraphrase patterns." ></td>
	<td class="line x" title="187:187	Then we will incorporate this new approach in FAQFinder and conduct end-to-end question-answering experiments in order to see how much the use of paraphrase patterns can improve the performance of the system." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W03-1608
Extracting Structural Paraphrases From Aligned Monolingual Corpora
Ibrahim, Ali;Katz, Boris;Lin, Jimmy;"></td>
	<td class="line x" title="1:181	Extracting Structural Paraphrases from Aligned Monolingual Corpora Ali Ibrahim Boris Katz Jimmy Lin MIT Artificial Intelligence Laboratory 200 Technology Square Cambridge, MA 02139 {aibrahim,boris,jimmylin}@ai.mit.edu Abstract We present an approach for automatically learning paraphrases from aligned monolingual corpora." ></td>
	<td class="line x" title="2:181	Our algorithm works by generalizing the syntactic paths between corresponding anchors in aligned sentence pairs." ></td>
	<td class="line x" title="3:181	Compared to previous work, structural paraphrases generated by our algorithm tend to be much longer on average, and are capable of capturing long-distance dependencies." ></td>
	<td class="line x" title="4:181	In addition to a standalone evaluation of our paraphrases, we also describe a question answering application currently under development that could immensely benefit from automatically-learned structural paraphrases." ></td>
	<td class="line x" title="5:181	1 Introduction The richness of human language allows people to express the same idea in many different ways; they may use different words to refer to the same entity or employ different phrases to describe the same concept." ></td>
	<td class="line x" title="6:181	Acquisition of paraphrases, or alternative ways to convey the same information, is critical to many natural language applications." ></td>
	<td class="line x" title="7:181	For example, an effective question answering system must be equipped to handle these variations, because it should be able to respond to differently phrased natural language questions." ></td>
	<td class="line x" title="8:181	While there are many resources that help systems deal with single-word synonyms, e.g., WordNet, there are few resources for multiple-word or domain-specific paraphrases." ></td>
	<td class="line x" title="9:181	Because manually collecting paraphrases is time-consuming and impractical for large-scale applications, attention has recently focused on techniques for automatically acquiring paraphrases." ></td>
	<td class="line x" title="10:181	We present an unsupervised method for acquiring structural paraphrases, or fragments of syntactic trees that are roughly semantically equivalent, from aligned monolingual corpora." ></td>
	<td class="line x" title="11:181	The structural paraphrases produced by our algorithm are similar to the S-rules advocated by Katz and Levin for question answering (1988), except that our paraphrases are automatically generated." ></td>
	<td class="line x" title="12:181	Because there is disagreement regarding the exact definition of paraphrases (Dras, 1999), we employ that operating definition that structural paraphrases are roughly interchangeable within the specific configuration of syntactic structures that they specify." ></td>
	<td class="line x" title="13:181	Our approach is a synthesis of techniques developed by Barzilay and McKeown (2001) and Lin and Pantel (2001), designed to overcome the limitations of both." ></td>
	<td class="line x" title="14:181	In addition to the evaluation of paraphrases generated by our method, we also describe a novel information retrieval system under development that is designed to take advantage of structural paraphrases." ></td>
	<td class="line x" title="15:181	2 Previous Work There has been a rich body of research on automatically deriving paraphrases, including equating morphological and syntactic variants of technical terms (Jacquemin et al. , 1997), and identifying equivalent adjective-noun phrases (Lapata, 2001)." ></td>
	<td class="line x" title="16:181	Unfortunately, both are limited in types of paraphrases that they can extract." ></td>
	<td class="line x" title="17:181	Other researchers have explored distributional clustering of similar words (Pereira et al. , 1993; Lin, 1998), but it is unclear to what extent such techniques produce paraphrases." ></td>
	<td class="line x" title="18:181	1 Most relevant to this paper is the work of Barzilay and McKeown and the work of Lin and Pantel." ></td>
	<td class="line x" title="19:181	Barzilay and McKeown (2001) extracted both singleand multiple-word paraphrases from a sentence-aligned corpus for use in multi-document summarization." ></td>
	<td class="line x" title="20:181	They constructed an aligned corpus from multiple translations of foreign novels." ></td>
	<td class="line x" title="21:181	From this, they co-trained a classifier that decided whether or not two phrases were paraphrases of each other based on their surrounding context." ></td>
	<td class="line x" title="22:181	Barzilay and McKeown collected 9483 paraphrases with an average precision of 85.5%." ></td>
	<td class="line x" title="23:181	However, 70.8% of the paraphrases were single words." ></td>
	<td class="line x" title="24:181	In addition, the paraphrases were required to be contiguous." ></td>
	<td class="line x" title="25:181	Lin and Pantel (2001) used a general text corpus to extract what they called inference rules, which we can take to be paraphrases." ></td>
	<td class="line x" title="26:181	In their algorithm, rules are represented as dependency tree paths between two words." ></td>
	<td class="line x" title="27:181	The words at the ends of a path are considered to be features of that path." ></td>
	<td class="line x" title="28:181	For each path, they recorded the different features (words) that were associated with the path and their respective frequencies." ></td>
	<td class="line x" title="29:181	Lin and Pantel calculated the similarity of two paths by looking at the similarity of their features." ></td>
	<td class="line x" title="30:181	This method allowed them to extract inference rules of moderate length from general corpora." ></td>
	<td class="line x" title="31:181	However, the technique is computationally expensive, and furthermore can give misleading results, i.e., paths having the opposite meaning often share similar features." ></td>
	<td class="line x" title="32:181	3 Approach Our approach, like Barzilay and McKeowns, is built on the application of sentence-alignment techniques used in machine translation to generate paraphrases." ></td>
	<td class="line x" title="33:181	The insight is simple: if we have pairs of sentences with the same semantic content, then the difference in lexical content can be attributed to variations in the surface form." ></td>
	<td class="line x" title="34:181	By generalizing these differences we can automatically derive paraphrases." ></td>
	<td class="line x" title="35:181	Barzilay and McKeown perform this learning process by only 1 For example, dog and cat are recognized to be similar, but they are obviously not paraphrases of one another." ></td>
	<td class="line x" title="36:181	considering the local context of words and their frequencies; as a result, paraphrases must be contiguous, and in the majority of cases, are only one word long." ></td>
	<td class="line x" title="37:181	We believe that disregarding the rich syntactic structure of language is an oversimplification, and that structural paraphrases offer several distinct advantages over lexical paraphrases." ></td>
	<td class="line x" title="38:181	Long distance relations can be captured by syntactic trees, so that words in the paraphrases do not need to be contiguous." ></td>
	<td class="line x" title="39:181	Use of syntactic trees also buffers against morphological variants (e.g. , different inflections) and some syntactic variants (e.g. , active vs. passive)." ></td>
	<td class="line x" title="40:181	Finally, because paraphrases are context-dependent, we believe that syntactic structures can encapsulate a richer context than lexical phrases." ></td>
	<td class="line x" title="41:181	Based on aligned monolingual corpora, our technique for extracting paraphrases builds on Lin and Pantels insight of using dependency paths (derived from parsing) as the fundamental unit of learning and using parts of those paths as features." ></td>
	<td class="line x" title="42:181	Based on the hypothesis that paths between identical words in aligned sentences are semantically equivalent, we can extract paraphrases by scoring the path frequency and context." ></td>
	<td class="line x" title="43:181	Our approach addresses the limitations of both Barzilay and McKeowns and Lin and Pantels work: using syntactic structures allows us to generate structural paraphrases, and using aligned corpora renders the process more computationally tractable." ></td>
	<td class="line x" title="44:181	The following sections describe our approach in greater detail." ></td>
	<td class="line x" title="45:181	3.1 Corpus Alignment Multiple English translations of foreign novels, e.g., Twenty Thousand Leagues Under the Sea by Jules Verne, were used for extraction of paraphrases." ></td>
	<td class="line x" title="46:181	Although translations by different authors differ slightly in their literary interpretation of the original text, it was usually possible to find corresponding sentences that have the same semantic content." ></td>
	<td class="line x" title="47:181	Sentence alignment was performed using the Gale and Church algorithm (1991) with the following cost function: cost of substitution =1 ncw anw ncw: number of common words anw: average number of words in two strings Here is a sample from two different translations of Twenty Thousand Leagues Under the Sea: Ned Land tried the soil with his feet, as if to take possession of it." ></td>
	<td class="line x" title="48:181	Ned Land tested the soil with his foot, as if he were laying claim to it." ></td>
	<td class="line x" title="49:181	To test the accuracy of our alignment, we manually aligned 454 sentences from two different versions of Chapter 21 from Twenty Thousand Leagues Under the Sea and compared the results of our automatic alignment algorithm against the manually generated gold standard. We obtained a precision of 0.93 and recall of 0.88, which is comparable to the numbers (P.94/R.85) reported by Barzilay and McKeown, who used a different cost function for the alignment process." ></td>
	<td class="line x" title="50:181	3.2 Parsing and Postprocessing The sentence pairs produced by the alignment algorithm are then parsed by the Link Parser (Sleator and Temperly, 1993), a dependency-based parser developed at CMU." ></td>
	<td class="line x" title="51:181	The resulting parse structures are post-processed to render the links more consistent: Because the Link Parser does not directly identify the subject of a passive sentence, our postprocessor takes the object of the by-phrase as the subject by default." ></td>
	<td class="line x" title="52:181	For our purposes, auxiliary verbs are ignored; the postprocessor connects verbs directly to their subjects, discarding links through any auxiliary verbs." ></td>
	<td class="line x" title="53:181	In addition, subjects and objects within relative clauses are appropriately modified so that the linkages remained consistent with subject and object linkages in the matrix clause." ></td>
	<td class="line x" title="54:181	For sentences involving verbs that have particles, the Link Parser connects the object of the verb directly to the verb itself, attaching the particle separately." ></td>
	<td class="line x" title="55:181	Our postprocessor modifies the link structure so that the object is connected to the particle in order to form a continuous path." ></td>
	<td class="line x" title="56:181	Predicate adjectives are converted into an adjective-noun modification link instead of a complete verb-argument structure." ></td>
	<td class="line x" title="57:181	Also, common nouns denoting places and people are marked by consulting WordNet." ></td>
	<td class="line x" title="58:181	3.3 Paraphrase Extraction The paraphrase extraction process starts by finding anchors within the aligned sentence pairs." ></td>
	<td class="line x" title="59:181	In our approach, only nouns and pronouns serve as possible anchors." ></td>
	<td class="line x" title="60:181	The anchor words from the sentence pairs are brought into alignment and scored by a simple set of ordered heuristics:  Exact string matches denote correspondence." ></td>
	<td class="line x" title="61:181	 Noun and matching pronoun (same gender and number) denote correspondence." ></td>
	<td class="line x" title="62:181	Such a match penalizes the score by 50%." ></td>
	<td class="line x" title="63:181	 Unique semantic class (e.g. , places and people) denotes correspondence." ></td>
	<td class="line x" title="64:181	Such a match penalizes the score by 50%." ></td>
	<td class="line x" title="65:181	 Unique part of speech (i.e. , the only noun pair in the sentences) denotes correspondence." ></td>
	<td class="line x" title="66:181	Such a match penalizes the score by 50%." ></td>
	<td class="line x" title="67:181	 Otherwise, attempt to find correspondence by finding longest common substrings." ></td>
	<td class="line x" title="68:181	Such a match penalizes the score by 50%." ></td>
	<td class="line x" title="69:181	 If a word occurs more than once in the aligned sentence pairs, all possible combinations are considered, but the score for such a corresponding anchor pair is further penalized by 50%." ></td>
	<td class="line x" title="70:181	For each pair of anchors, a breadth-first search is used to find the shortest path between the anchor words." ></td>
	<td class="line x" title="71:181	The search algorithm explicitly rejects paths that contain conjunctions and punctuation." ></td>
	<td class="line x" title="72:181	If valid paths are found between anchor pairs in both of the aligned sentences, the resulting paths are considered candidate paraphrases, with a default score of one (subjected to penalties imposed by imperfect anchor matching)." ></td>
	<td class="line x" title="73:181	Scores of candidate paraphrases take into account two factors: the frequency of anchors with respect to a particular candidate paraphrase and the variety of different anchors from which the paraphrase was produced." ></td>
	<td class="line x" title="74:181	The initial default score of any paraphrase is one (assuming perfect anchor matches), but for each additional occurrence the score is incremented by 1 2 n, where n is the number of times the current set of anchors has been seen." ></td>
	<td class="line x" title="75:181	Therefore, the effect of seeing new sets of anchors has a big initial impact on the score, but the additional increase in score is subjected to diminishing returns as more occurrences of the same anchor are encountered." ></td>
	<td class="line x" title="76:181	count aligned sentences 27479 parsed aligned sentences 25292 anchor pairs 43974 paraphrases 5925 unique paraphrases 5502 gathered paraphrases (score  1.0) 2886 Table 1: Summary of the paraphrase generation process Figure 1: Distribution of paraphrase length 4 Results Using the approach described in previous sections, we were able to extract nearly six thousand different paraphrases (see Table 1) from our corpus, which consisted of two translations of 20,000 Leagues Under the Sea, two translations of The Kreutzer Sonata, and three translations of Madame Bouvary." ></td>
	<td class="line x" title="77:181	Our corpus was essentially the same as the one used by Barzilay and McKeown, with the exception of some short fairy tale translations that we found to be unsuitable." ></td>
	<td class="line x" title="78:181	Due to the length of sentences (some translations were noted for their paragraph-length sentences), the Link Parser was unable to produce a parse for approximately eight percent of the sentences." ></td>
	<td class="line x" title="79:181	Although the Link Parser is capable of producing partial linkages, accuracy deteriorated significantly as the length of the input string increased." ></td>
	<td class="line x" title="80:181	The distribution of paraphrase length is shown in Figure 1." ></td>
	<td class="line x" title="81:181	The length of paraphrases is measured by the number of words that it contains (discounting the anchors on both sides)." ></td>
	<td class="line x" title="82:181	To evaluate the accuracy of our results, 130 Evaluator Precision Evaluator 1 36.2% Evaluator 2 40.0% Evaluator 3 44.6% Average 41.2% Table 2: Summary of judgments by human evaluators for 130 unique paraphrases unique paraphrases were randomly chosen to be assessed by human judges." ></td>
	<td class="line x" title="83:181	The human assessors were specifically asked whether they thought the paraphrases were roughly interchangeable with each other, given the context of the genre." ></td>
	<td class="line x" title="84:181	We believe that the genre constraint was important because some paraphrases captured literary or archaic uses of particular words that were not generally useful." ></td>
	<td class="line x" title="85:181	This should not be viewed as a shortcoming of our approach, but rather an artifact of our corpus." ></td>
	<td class="line x" title="86:181	In addition, sample sentences containing the structural paraphrases were presented as context to the judges; structural paraphrases are difficult to comprehend without this information." ></td>
	<td class="line x" title="87:181	A summary of the judgments provided by human evaluators is shown in Table 2." ></td>
	<td class="line x" title="88:181	The average precision of our approach stands at just over forty percent; the average length of the paraphrases learned was 3.26 words long." ></td>
	<td class="line x" title="89:181	Our results also show that judging structural paraphrases is a difficult task and inter-assessor agreement is rather low." ></td>
	<td class="line x" title="90:181	All of the evaluators agreed on the judgments (either positive or negative) only 75.4% of the time." ></td>
	<td class="line x" title="91:181	The average correlation constant of the judgments is only 0.66." ></td>
	<td class="line x" title="92:181	The highest scoring paraphrase was the equivalence of the possessive morpheme s with the preposition of." ></td>
	<td class="line x" title="93:181	We found it encouraging that our algorithm was able to induce this structural paraphrase, complete with co-indexed anchors on the ends of the paths, i.e., As B  B of A. Some other interesting examples include: 2 A 1   liked O  A 2  A 1   fond OF  of J  A 2 Example: The clerk liked Monsieur Bovary." ></td>
	<td class="line x" title="94:181	 2 Brief description of link labels: S: subject to verb; O: object to verb; OF: certain verbs to of; K: verbs to particles; MV: verbs to certain modifying phrases." ></td>
	<td class="line x" title="95:181	See Link Parser documentation for full descriptions." ></td>
	<td class="line x" title="96:181	Score Threshold Avg." ></td>
	<td class="line x" title="97:181	Precision Avg." ></td>
	<td class="line x" title="98:181	Length Count  1.0 40.2% 3.24 130  1.25 46.0% 2.88 58  1.5 47.8% 2.22 23  1.75 38.9% 1.67 12 Table 3: Breakdown of our evaluation results The clerk was fond of Monsieur Bovary." ></td>
	<td class="line x" title="99:181	A 1 s  rush K  over MV  to J  A 2  A 1 s  run MV  to J  A 2 Example: And he rushed over to his son, who had just jumped into a heap of lime to whiten his shoes." ></td>
	<td class="line x" title="100:181	 And he ran to his son, who had just precipitated himself into a heap of lime in order to whiten his boots." ></td>
	<td class="line x" title="101:181	A 1 s  put K  on O  A 2  A 1 s  wear O  A 2 Example: That is why he puts on his best waistcoat and risks spoiling it in the rain." ></td>
	<td class="line x" title="102:181	 Thats why he wears his new waistcoat, even in the rain!" ></td>
	<td class="line x" title="103:181	A 1   fit MV  to I  give O  A 2  A 1   appropriate MV  to I  supply O  A 2 Example: He thought fit, after the first few mouthfuls, to give some details as to the catastrophe." ></td>
	<td class="line x" title="104:181	 After the first few mouthfuls he considered it appropriate to supply a few details concerning the catastrophe." ></td>
	<td class="line x" title="105:181	A more detailed breakdown of the evaluation results can be seen in Table 3." ></td>
	<td class="line x" title="106:181	Increasing the threshold for generating paraphrases tends to increase their precision, up to a certain point." ></td>
	<td class="line x" title="107:181	In general, the highest ranking structural paraphrases consisted of single word paraphrases of prepositions, e.g., at  in." ></td>
	<td class="line x" title="108:181	Our algorithm noticed that different prepositions were often interchangeable, which is something that our human assessors disagreed widely on." ></td>
	<td class="line x" title="109:181	Beyond a certain threshold, the accuracy of our approach actually decreases." ></td>
	<td class="line x" title="110:181	5 Discussion An obvious first observation about our algorithm is the dependence on parse quality; bad parses lead to many bogus paraphrases." ></td>
	<td class="line x" title="111:181	Although the parse results from the Link Parser are far from perfect, it is unclear whether other purely statistical parsers would fare any better, since they are generally trained on corpora containing a totally different genre of text." ></td>
	<td class="line x" title="112:181	However, future work will most likely include a comparison of different parsers." ></td>
	<td class="line x" title="113:181	Examination of our results show that a better notion of constituency would increase the accuracy of our results." ></td>
	<td class="line x" title="114:181	Our algorithm occasionally generates non-sensical paraphrases that cross constituent boundaries, for example, including the verb of a subordinate clause with elements from the matrix clause." ></td>
	<td class="line x" title="115:181	Other problems arise because our current algorithm has no notion of verb phrases; it often generates near misses such as fail  succeed, neglecting to include not as part of the paraphrase." ></td>
	<td class="line x" title="116:181	However, there are problems inherent in paraphrase generation that simple knowledge of constituency alone cannot solve." ></td>
	<td class="line x" title="117:181	Consider the following two sentences: John made out gold at the bottom of the well." ></td>
	<td class="line x" title="118:181	John discovered gold near the bottom of the well." ></td>
	<td class="line x" title="119:181	Which structural paraphrases should we be able to extract?" ></td>
	<td class="line x" title="120:181	made out X at Y discovered X near Y made out X discovered X at X near X Arguably, all three paraphrases are valid, although opinions vary more regarding the last paraphrase." ></td>
	<td class="line x" title="121:181	What is the optimal level of structure for paraphrases?" ></td>
	<td class="line x" title="122:181	Obviously, this represents a tradeoff between specificity and accuracy, but the ability of structural paraphrases to capture long-distance relationships across large numbers of lexical items complicates the problem." ></td>
	<td class="line x" title="123:181	Due to the sparseness of our data, our algorithm cannot make a good decision on what constituents to generalize as variables; naturally, greater amounts of data would alleviate this problem." ></td>
	<td class="line x" title="124:181	This current inability to decide on a good scope for paraphrasing was a primary reason why we were unable to perform a strict evaluation of recall." ></td>
	<td class="line x" title="125:181	Our initial attempts at generating a gold standard for estimating recall failed because human judges could not agree on the boundaries of paraphrases." ></td>
	<td class="line x" title="126:181	The accuracy of our structural paraphrases is highly dependent on the corpus size." ></td>
	<td class="line x" title="127:181	As can be seen from the numbers in Table 1, paraphrases are rather sparsenearly 93% of them are unique." ></td>
	<td class="line x" title="128:181	Without adequate statistical evidence, validating candidate paraphrases can be very difficult." ></td>
	<td class="line x" title="129:181	Although our data spareness problem can be alleviated simply by gathering a larger corpus, the type of parallel text our algorithm requires is rather hard to obtain, i.e., there are only so many translations of so many foreign novels." ></td>
	<td class="line x" title="130:181	Furthermore, since our paraphrases are arguably genre-specific, different applications may require different training corpora." ></td>
	<td class="line oc" title="131:181	Similar to the work of Barzilay and Lee (2003), who have applied paraphrase generation techniques to comparable corpora consisting of different newspaper articles about the same event, we are currently attempting to solve the data sparseness problem by extending our approach to non-parallel corpora." ></td>
	<td class="line x" title="132:181	We believe that generating paraphrases at the structural level holds several key advantages over lexical paraphrases, from the capturing of longdistance relationships to the more accurate modeling of context." ></td>
	<td class="line x" title="133:181	The paraphrases generated by our approach could prove to be useful in any natural language application where understanding of linguistic variations is important." ></td>
	<td class="line x" title="134:181	In particular, we are attempting to apply our results to improve the performance of question answering system, which we will describe in the following section." ></td>
	<td class="line x" title="135:181	6 Paraphrases and Question Answering The ultimate goal of our work on paraphrases is to enable the development of high-precision question answering system (cf.(Katz and Levin, 1988; Soubbotin and Soubbotin, 2001; Hermjakob et al. , 2002))." ></td>
	<td class="line x" title="137:181	We believe that a knowledge base of paraphrases is the key to overcoming challenges presented by the expressiveness of natural languages." ></td>
	<td class="line x" title="138:181	Because the same semantic content can be expressed in many different ways, a question answering system must be able to cope with a variety of alternative phrasings." ></td>
	<td class="line x" title="139:181	In particular, an answer stated in a form that differs from the form of the question presents significant problems: When did Colorado become a state?" ></td>
	<td class="line x" title="140:181	(1a) Colorado became a state in 1876." ></td>
	<td class="line x" title="141:181	(1b) Colorado was admitted to the Union in 1876." ></td>
	<td class="line x" title="142:181	Who killed Abraham Lincoln?" ></td>
	<td class="line x" title="143:181	(2a) John Wilkes Booth killed Abraham Lincoln." ></td>
	<td class="line x" title="144:181	(2b) John Wilkes Booth ended Abraham Lincolns life with a bullet." ></td>
	<td class="line x" title="145:181	In the above examples, question answering systems have little difficulty extracting answers if the answers are stated in a form directly derived from the question, e.g., (1a) and (2a); simple keyword matching techniques with primitive named-entity detection technology will suffice." ></td>
	<td class="line x" title="146:181	However, question answering systems will have a much harder time extracting answers from sentences where they are not obviously stated, e.g., (1b) and (2b)." ></td>
	<td class="line x" title="147:181	To relate question to answers in those examples, a system would need access to rules like the following: X became a state in Y X was admitted to the Union in Y X killed Y X ended Ys life We believe that such rules are best formulated at the syntactic level: structural paraphrases represent a good level of generality and provide much more accurate results than keyword-based approaches." ></td>
	<td class="line x" title="148:181	The simplest approach to overcoming the paraphrase problem in question answering is via keyword query expansion when searching for candidate answers: (AND X became state) (AND X admitted Union) (AND X killed) (AND X ended life) The major drawback of such techniques is overgeneration of bogus answer candidates." ></td>
	<td class="line x" title="149:181	For example, it is a well-known result that query expansion based on synonymy, hyponymy, etc. may actually degrade performance if done in an uncontrolled manner (Voorhees, 1994)." ></td>
	<td class="line x" title="150:181	Typically, keywordbased query expansion techniques sacrifice significant amounts of precision for little (if any) increase in recall." ></td>
	<td class="line x" title="151:181	The problems associated with keyword query expansion techniques stem from the fundamental deficiencies of bag-of-words approaches; in short, they simply cannot accurately model the semantic content of text, as illustrated by the following pairs of sentences and phrases that have the same word content, but dramatically different meaning: (3a) The bird ate the snake." ></td>
	<td class="line x" title="152:181	(3b) The snake ate the bird." ></td>
	<td class="line x" title="153:181	(4a) the largest planets volcanoes (4b) the planets largest volcanoes (5a) the house by the river (5b) the river by the house (6a) The Germans defeated the French." ></td>
	<td class="line x" title="154:181	(6b) The Germans were defeated by the French." ></td>
	<td class="line x" title="155:181	The above examples are nearly indistinguishable in terms of lexical content, yet their meanings are vastly different." ></td>
	<td class="line x" title="156:181	Naturally, because one text fragment might be an appropriate answer to a question while the other fragment may not be, a question answering system seeking to achieve high precision must provide mechanisms for differentiating the semantic content of the pairs." ></td>
	<td class="line x" title="157:181	While paraphrase techniques at the keyword-level vastly overgenerate, paraphrase techniques at the phrase-level undergenerate, that is, they are often too specific." ></td>
	<td class="line x" title="158:181	Although paraphrase rules can easily be formulated at the string-level, e.g., using regular expression matching and substitution techniques (Soubbotin and Soubbotin, 2001; Hermjakob et al. , 2002), such a treatment fails to capture important linguistic generalizations." ></td>
	<td class="line x" title="159:181	For example, the addition of an adverb typically does not alter the validity of a paraphrase; thus, a phrase-level rule X killed Y  X ended Ys life would not be able to match an answer like John Wilkes Booth suddenly ended Abraham Lincolns life with a bullet." ></td>
	<td class="line x" title="160:181	String-level paraphrases are also unable to handle syntactic phenomenona like passivization, which are easily captured at the syntactic level." ></td>
	<td class="line x" title="161:181	We believe that answering questions at level of syntactic relations, that is, matching parsed representations of questions with parsed representations of candidates, addresses the issues presented above." ></td>
	<td class="line x" title="162:181	Syntactic relations, basically simplified versions of dependency structures derived from the Link Parser, can capture significant portions of the meaning present in text documents, while providing a flexible foundation on which to build machinery for paraphrases." ></td>
	<td class="line x" title="163:181	Our position is that question answering should be performed at the level of key relations in addition to keywords." ></td>
	<td class="line x" title="164:181	We have begun to experiment with relations indexing and matching techniques described above using an electronic encyclopedia as the test corpus." ></td>
	<td class="line x" title="165:181	We identified a particular set of linguistic phenomena where relation-based indexing can dramatically boost the precision of a question answering system (Katz and Lin, 2003)." ></td>
	<td class="line x" title="166:181	As an example, consider a sample output from a baseline keywordbased IR system: What do frogs eat?" ></td>
	<td class="line x" title="167:181	(R1) Alligators eat many kinds of small animals that live in or near the water, including fish, snakes, frogs, turtles, small mammals, and birds." ></td>
	<td class="line x" title="168:181	(R2) Some bats catch fish with their claws, and a few species eat lizards, rodents, birds, and frogs." ></td>
	<td class="line x" title="169:181	(R3) Bowfins eat mainly other fish, frogs, and crayfish." ></td>
	<td class="line x" title="170:181	(R4) Adult frogs eat mainly insects and other small animals, including earthworms, minnows, and spiders." ></td>
	<td class="line x" title="171:181	(R32) Kookaburras eat caterpillars, fish, frogs, insects, small mammals, snakes, worms, and even small birds." ></td>
	<td class="line x" title="172:181	Of the 32 sentences returned, only (R4) correctly answers the user query; the other results answer a different questionWhat eats frogs? A bag-ofwords approach fundamentally cannot differentiate between a query in which the frog is in the subject position and a query in which the frog is in the object position." ></td>
	<td class="line x" title="173:181	Compare this to the results produced by our relations matcher: What do frogs eat?" ></td>
	<td class="line x" title="174:181	(R4) Adult frogs eat mainly insects and other small animals, including earthworms, minnows, and spiders." ></td>
	<td class="line x" title="175:181	By examining subject-verb-object relations, our system can filter out irrelevant results and return only the correct responses." ></td>
	<td class="line x" title="176:181	We are currently working on combining this relations-indexing technology with the automatic paraphrase generation technology described earlier." ></td>
	<td class="line x" title="177:181	For example, our approach would be capable of automatically learning a paraphrase like X eat Y  Y is a prey of X; a large collection of such paraphrases would go a long way in overcoming the brittleness associated with a relations-based indexing scheme." ></td>
	<td class="line x" title="178:181	7 Contributions We have presented a method for automatically learning structural paraphrases from aligned monolingual corpora that overcomes the limitation of previous approaches." ></td>
	<td class="line x" title="179:181	In addition, we have sketched how this technology can be applied to enhance the performance of a question answering system based on indexing relations." ></td>
	<td class="line x" title="180:181	Although we have not completed a task-based evaluation, we believe that the ability to handle variations in language is key to building better question answering systems." ></td>
	<td class="line x" title="181:181	8 Acknowledgements This research was funded by DARPA under contract number F30602-00-1-0545 and administered by the Air Force Research Laboratory." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C04-1051
Unsupervised Construction Of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources
Dolan, William B.;Quirk, Chris;Brockett, Chris;"></td>
	<td class="line x" title="1:175	Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources Bill DOLAN, Chris QUIRK, and Chris BROCKETT Natural Language Processing Group, Microsoft Research One Microsoft Way Redmond, WA 90852, USA {billdol,chrisq,chrisbkt}@microsoft.com Abstract We investigate unsupervised techniques for acquiring monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web-based news sources." ></td>
	<td class="line x" title="2:175	Two techniques are employed: (1) simple string edit distance, and (2) a heuristic strategy that pairs initial (presumably summary) sentences from different news stories in the same cluster." ></td>
	<td class="line x" title="3:175	We evaluate both datasets using a word alignment algorithm and a metric borrowed from machine translation." ></td>
	<td class="line x" title="4:175	Results show that edit distance data is cleaner and more easily-aligned than the heuristic data, with an overall alignment error rate (AER) of 11.58% on a similarly-extracted test set." ></td>
	<td class="line x" title="5:175	On test data extracted by the heuristic strategy, however, performance of the two training sets is similar, with AERs of 13.2% and 14.7% respectively." ></td>
	<td class="line x" title="6:175	Analysis of 100 pairs of sentences from each set reveals that the edit distance data lacks many of the complex lexical and syntactic alternations that characterize monolingual paraphrase." ></td>
	<td class="line x" title="7:175	The summary sentences, while less readily alignable, retain more of the non-trivial alternations that are of greatest interest learning paraphrase relationships." ></td>
	<td class="line oc" title="8:175	1 Introduction The importance of learning to manipulate monolingual paraphrase relationships for applications like summarization, search, and dialog has been highlighted by a number of recent efforts (Barzilay & McKeown 2001; Shinyama et al. 2002; Lee & Barzilay 2003; Lin & Pantel 2001)." ></td>
	<td class="line n" title="9:175	While several different learning methods have been applied to this problem, all share a need for large amounts of data in the form of pairs or sets of strings that are likely to exhibit lexical and/or structural paraphrase alternations." ></td>
	<td class="line x" title="10:175	One approach 1 1 An alternative approach involves identifying anchor points--pairs of words linked in a known way--and collecting the strings that intervene." ></td>
	<td class="line x" title="11:175	(Shinyama, et al. 2002; Lin & Pantel 2001)." ></td>
	<td class="line x" title="12:175	Since our interest is in that has been successfully used is edit distance, a measure of similarity between strings." ></td>
	<td class="line x" title="13:175	The assumption is that strings separated by a small edit distance will tend to be similar in meaning: The leading indicators measure the economy The leading index measures the economy." ></td>
	<td class="line oc" title="14:175	Lee & Barzilay (2003), for example, use MultiSequence Alignment (MSA) to build a corpus of paraphrases involving terrorist acts." ></td>
	<td class="line o" title="15:175	Their goal is to extract sentential templates that can be used in high-precision generation of paraphrase alternations within a limited domain." ></td>
	<td class="line x" title="16:175	Our goal here is rather different: our interest lies in constructing a monolingual broad-domain corpus of pairwise aligned sentences." ></td>
	<td class="line x" title="17:175	Such data would be amenable to conventional statistical machine translation (SMT) techniques (e.g. , those discussed in Och & Ney 2003)." ></td>
	<td class="line x" title="18:175	2 In what follows we compare two strategies for unsupervised construction of such a corpus, one employing string similarity and the other associating sentences that may overlap very little at the string level." ></td>
	<td class="line x" title="19:175	We measure the relative utility of the two derived monolingual corpora in the context of word alignment techniques developed originally for bilingual text." ></td>
	<td class="line x" title="20:175	We show that although the edit distance corpus is well-suited as training data for the alignment algorithms currently used in SMT, it is an incomplete source of information about paraphrase relations, which exhibit many of the characteristics of comparable bilingual corpora or free translations." ></td>
	<td class="line x" title="21:175	Many of the more complex alternations that characterize monolingual paraphrase, such as large-scale lexical alternations and constituent reorderings, are not readily learning sentence level paraphrases, including major constituent reorganizations, we do not address this approach here." ></td>
	<td class="line x" title="22:175	2 Barzilay & McKeown (2001) consider the possibility of using SMT machinery, but reject the idea because of the noisy, comparable nature of their dataset." ></td>
	<td class="line x" title="23:175	captured by edit distance techniques, which conflate semantic similarity with formal similarity." ></td>
	<td class="line x" title="24:175	We conclude that paraphrase research would benefit by identifying richer data sources and developing appropriate learning techniques." ></td>
	<td class="line x" title="25:175	2 Data/Methodology Our two paraphrase datasets are distilled from a corpus of news articles gathered from thousands of news sources over an extended period." ></td>
	<td class="line nc" title="26:175	While the idea of exploiting multiple news reports for paraphrase acquisition is not new, previous efforts (for example, Shinyama et al. 2002; Barzilay and Lee 2003) have been restricted to at most two news sources." ></td>
	<td class="line x" title="27:175	Our work represents what we believe to be the first attempt to exploit the explosion of news coverage on the Web, where a single event can generate scores or hundreds of different articles within a brief period of time." ></td>
	<td class="line x" title="28:175	Some of these articles represent minor rewrites of an original AP or Reuters story, while others represent truly distinct descriptions of the same basic facts." ></td>
	<td class="line x" title="29:175	The massive redundancy of information conveyed with widely varying surface strings is a resource begging to be exploited." ></td>
	<td class="line x" title="30:175	Figure 1 shows the flow of our data collection process." ></td>
	<td class="line x" title="31:175	We begin with sets of pre-clustered URLs which point to news articles on the Web, representing thousands of different news sources." ></td>
	<td class="line x" title="32:175	The clustering algorithm takes into account the full text of each news article, in addition to temporal cues, to produce a set of topically and temporally related articles." ></td>
	<td class="line x" title="33:175	Our method is believed to be independent of the specific clustering technology used." ></td>
	<td class="line x" title="34:175	The story text is isolated from a sea of advertisements and other miscellaneous text through use of a supervised HMM." ></td>
	<td class="line x" title="35:175	Altogether we collected 11,162 clusters in an 8month period, assembling 177,095 articles with an average of 15.8 articles per cluster." ></td>
	<td class="line x" title="36:175	The clusters are generally coherent in topic and focus." ></td>
	<td class="line x" title="37:175	Discrete events like disasters, business announcements, and deaths tend to yield tightly focused clusters, while ongoing stories like the SARS crisis tend to produce less focused clusters." ></td>
	<td class="line x" title="38:175	While exact duplicate articles are filtered out of the clusters, many slightly-rewritten variants remain." ></td>
	<td class="line x" title="39:175	2.1 Extracting Sentential Paraphrases Two separate techniques were employed to extract likely pairs of sentential paraphrases from these clusters." ></td>
	<td class="line x" title="40:175	The first used string edit distance, counting the number of lexical deletions and insertions needed to transform one string into another." ></td>
	<td class="line x" title="41:175	The second relied on a discourse-based heuristic, specific to the news genre, to identify likely paraphrase pairs even when they have little superficial similarity." ></td>
	<td class="line x" title="42:175	3 Levenshtein Distance A simple edit distance metric (Levenshtein 1966) was used to identify pairs of sentences within a cluster that are similar at the string level." ></td>
	<td class="line x" title="43:175	First, each sentence was normalized to lower case and paired with every other sentence in the cluster." ></td>
	<td class="line x" title="44:175	Pairings that were identical or differing only by punctuation were rejected, as were those where the shorter sentence in the pair was less than two thirds the length of the longer, this latter constraint in effect placing an upper bound on edit distance relative to the length of the sentence." ></td>
	<td class="line x" title="45:175	Pairs that had been seen before in either order were also rejected." ></td>
	<td class="line x" title="46:175	Filtered in this way, our dataset yields 139K nonidentical sentence pairs at a Levenshtein distance of n  12." ></td>
	<td class="line x" title="47:175	3 Mean Levenshtein distance was 5.17, and mean sentence length was 18.6 words." ></td>
	<td class="line x" title="48:175	We will refer to this dataset as L12." ></td>
	<td class="line x" title="49:175	3.1.1 First sentences The second extraction technique was specifically intended to capture paraphrases which might contain very different sets of content words, word order, and so on." ></td>
	<td class="line x" title="50:175	Such pairs are typically used to illustrate the phenomenon of paraphrase, but precisely because their surface dissimilarity renders automatic discovery difficult, they have generally not been the focus of previous computational approaches." ></td>
	<td class="line x" title="51:175	In order to automatically identify sentence pairs of this type, we have attempted to take advantage of some of the unique characteristics of the dataset." ></td>
	<td class="line x" title="52:175	The topical clustering is sufficiently precise to ensure that, in general, articles in the same cluster overlap significantly in overall semantic content." ></td>
	<td class="line x" title="53:175	Even so, any arbitrary pair of sentences from different articles within a cluster is unlikely to exhibit a paraphrase relationship: The Phi-X174 genome is short and compact." ></td>
	<td class="line x" title="54:175	This is a robust new step that allows us to make much larger pieces." ></td>
	<td class="line x" title="55:175	To isolate just those sentence pairs that represent likely paraphrases without requiring significant string similarity, we exploited a common journalistic convention: the first sentence or two of 3 A maximum Levenshtein distance of 12 was selected for the purposes of this paper on the basis of experiments with corpora extracted at various edit distances." ></td>
	<td class="line x" title="56:175	a newspaper article typically summarize its content." ></td>
	<td class="line x" title="57:175	One might reasonably expect, therefore, that initial sentences from one article in a cluster will be paraphrases of the initial sentences in other articles in that cluster." ></td>
	<td class="line x" title="58:175	This heuristic turns out to be a powerful one, often correctly associating sentences that are very different at the string level: In only 14 days, US researchers have created an artificial bacteria-eating virus from synthetic genes." ></td>
	<td class="line x" title="59:175	An artificial bacteria-eating virus has been made from synthetic genes in the record time of just two weeks." ></td>
	<td class="line x" title="60:175	Also consider the following example, in which related words are obscured by different parts of speech: Chosun Ilbo, one of South Korea's leading newspapers, said North Korea had finished developing a new ballistic missile last year and was planning to deploy it." ></td>
	<td class="line x" title="61:175	The Chosun Ilbo said development of the new missile, with a range of up to %%number%% kilometres (%%number%% miles), had been completed and deployment was imminent." ></td>
	<td class="line x" title="62:175	A corpus was produced by extracting the first two sentences of each article, then pairing these across documents within each cluster." ></td>
	<td class="line x" title="63:175	We will refer to this collection as the F2 corpus." ></td>
	<td class="line x" title="64:175	The combination of the first-two sentences heuristic plus topical article clusters allows us to take advantage of meta-information implicit in our corpus, since clustering exploits lexical information from the entire document, not just the few sentences that are our focus." ></td>
	<td class="line x" title="65:175	The assumption that two first sentences are semantically related is thus based in part on linguistic information that is external to the sentences themselves." ></td>
	<td class="line x" title="66:175	Sometimes, however, the strategy of pairing sentences based on their cluster and position goes astray." ></td>
	<td class="line x" title="67:175	This would lead us to posit a paraphrase relationship where there is none: Terence Hope should have spent most of yesterday in hospital performing brain surgery." ></td>
	<td class="line x" title="68:175	A leading brain surgeon has been suspended from work following a dispute over a bowl of soup." ></td>
	<td class="line x" title="69:175	To prevent too high an incidence of unrelated sentences, one string-based heuristic filter was found useful: a pair is discarded if the sentences do not share at least 3 words of 4+ characters." ></td>
	<td class="line x" title="70:175	This constraint succeeds in filtering out many unrelated pairs, although it can sometimes be too restrictive, excluding completely legitimate paraphrases: There was no chance it would endanger our planet, astronomers said." ></td>
	<td class="line x" title="71:175	NASA emphasized that there was never danger of a collision." ></td>
	<td class="line x" title="72:175	An additional filter ensured that the word count of the shorter sentence is at least one-half that of the longer sentence." ></td>
	<td class="line x" title="73:175	Given the relatively long sentences in our corpus (average length 18.6 words), these filters allowed us to maintain a degree of semantic relatedness between sentences." ></td>
	<td class="line x" title="74:175	Accordingly, the dataset encompasses many paraphrases that would have been excluded under a more stringent edit-distance threshold, for example, the following non-paraphrase pair that contain an element of paraphrase: A staggering %%number%% million Americans have been victims of identity theft in the last five years, according to federal trade commission survey out this week." ></td>
	<td class="line x" title="75:175	In the last year alone, %%number%% million people have had their identity purloined." ></td>
	<td class="line x" title="76:175	Nevertheless, even after filtering in these ways, a significant amount of unfiltered noise remains in the F2 corpus, which consisted of 214K sentence pairs." ></td>
	<td class="line x" title="77:175	Out of a sample of 448 held-out sentence pairs, 118 (26.3%) were rated by two independent human evaluators as sentence-level paraphrases, while 151 (33.7%) were rated as partial paraphrases." ></td>
	<td class="line x" title="78:175	The remaining ~40% were assessed as News article clusters: URLs Download URLs, Isolate content (HMM), Sentence separate Textual content of articles Select and filter first sentence pairs Approximately parallel monolingual corpus Figure 1." ></td>
	<td class="line x" title="79:175	Data collection unrelated." ></td>
	<td class="line x" title="80:175	4 Thus, although the F2 data set is nominally larger than the L12 data set, when the noise factor is taken into account, the actual number of full paraphrase sentences in this data set is estimated to be in the region of 56K sentences, with a further estimated 72K sentences containing some paraphrase material that might be a potential source of alignment." ></td>
	<td class="line x" title="81:175	Some of these relations captured in this data can be complex." ></td>
	<td class="line x" title="82:175	The following pair, for example, would be unlikely to pass muster on edit distance grounds, but nonetheless contains an inversion of deep semantic roles, employing different lexical items." ></td>
	<td class="line x" title="83:175	The Hartford Courant reported %%day%% that Tony Bryant said two friends were the killers." ></td>
	<td class="line x" title="84:175	A lawyer for Skakel says there is a claim that the murder was carried out by two friends of one of Skakel's school classmates, Tony Bryan." ></td>
	<td class="line x" title="85:175	The F2 data also retains pairs like the following that involve both high-level semantic alternations and long distance dependencies: Two men who robbed a jeweller's shop to raise funds for the Bali bombings were each jailed for %%number%% years by Indonesian courts today." ></td>
	<td class="line x" title="86:175	An Indonesian court today sentenced two men to %%number%% years in prison for helping finance last year's terrorist bombings in Bali by robbing a jewelry store." ></td>
	<td class="line x" title="87:175	These examples do not by any means exhaust the inventory of complex paraphrase types that are commonly encountered in the F2 data." ></td>
	<td class="line x" title="88:175	We encounter, among other things, polarity alternations, including those involving longdistance dependencies, and a variety of distributed paraphrases, with alignments spanning widely separated elements." ></td>
	<td class="line x" title="89:175	3.2 Word Error Alignment Rate An objective scoring function was needed to compare the relative success of the two data collection strategies sketched in 2.1.1 and 2.1.2." ></td>
	<td class="line x" title="90:175	Which technique produces more data?" ></td>
	<td class="line x" title="91:175	Are the types of data significantly different in character or utility?" ></td>
	<td class="line x" title="92:175	In order to address such questions, we used word Alignment Error Rate (AER), a metric borrowed from the field of statistical machine translation (Och & Ney 2003)." ></td>
	<td class="line x" title="93:175	AER measures how accurately an automatic algorithm can align words in corpus of parallel sentence pairs, with a human4 This contrasts with 16.7% pairs assessed as unrelated in a 10,000 pair sampling of the L12 data." ></td>
	<td class="line x" title="94:175	tagged corpus of alignments serving as the gold standard." ></td>
	<td class="line x" title="95:175	Paraphrase data is of course monolingual, but otherwise the task is very similar to the MT alignment problem, posing the same issues with one-to-many, many-to-many, and one/many-tonull word mappings." ></td>
	<td class="line x" title="96:175	Our a priori assumption was that the lower the AER for a corpus, the more likely it would be to yield learnable information about paraphrase alternations." ></td>
	<td class="line x" title="97:175	We closely followed the evaluation standards established in Melamed (2001) and Och & Ney (2000, 2003)." ></td>
	<td class="line x" title="98:175	Following Och & Neys methodology, two annotators each created an initial annotation for each dataset, subcategorizing alignments as either SURE (necessary) or POSSIBLE (allowed, but not required)." ></td>
	<td class="line x" title="99:175	Differences were then highlighted and the annotators were asked to review these cases." ></td>
	<td class="line x" title="100:175	Finally we combined the two annotations into a single gold standard in the following manner: if both annotators agreed that an alignment should be SURE, then the alignment was marked as sure in the gold-standard; otherwise the alignment was marked as POSSIBLE." ></td>
	<td class="line x" title="101:175	To compute Precision, Recall, and Alignment Error Rate (AER) for the twin datasets, we used exactly the formulae listed in Och & Ney (2003)." ></td>
	<td class="line x" title="102:175	Let A be the set of alignments in the comparison, S be the set of SURE alignments in the gold standard, and P be the union of the SURE and POSSIBLE alignments in the gold standard." ></td>
	<td class="line x" title="103:175	Then we have: || || precision A PA  = || || recall S SA  = || || AER SA SAPA + + = We held out a set of news clusters from our training data and randomly extracted two sets of sentence pairs for blind evaluation." ></td>
	<td class="line x" title="104:175	The first is a set of 250 sentence pairs extracted on the basis of an edit distance of 5  n  20, arbitrarily chosen to allow a range of reasonably divergent candidate pairs." ></td>
	<td class="line x" title="105:175	These sentence pairs were checked by an independent human evaluator to ensure that they contained paraphrases before they were tagged for alignments." ></td>
	<td class="line x" title="106:175	The second set comprised 116 sentence pairs randomly selected from the set of first-two sentence pairs." ></td>
	<td class="line x" title="107:175	These were likewise handvetted by independent human evaluators." ></td>
	<td class="line x" title="108:175	After an initial training pass and refinement of the linking specification, interrater agreement measured in terms of AER 5 was 93.1% for the edit distance test set versus 83.7% for the F2 test set, suggestive of the greater variability in the latter data set." ></td>
	<td class="line x" title="109:175	3.3 Data Alignment Each corpus was used as input to the word alignment algorithms available in Giza++ (Och & Ney 2000)." ></td>
	<td class="line x" title="110:175	Giza++ is a freely available implementation of IBM Models 1-5 (Brown et al. 1993) and the HMM alignment (Vogel et al. 1996), along with various improvements and modifications motivated by experimentation by Och & Ney (2000)." ></td>
	<td class="line x" title="111:175	Giza++ accepts as input a corpus of sentence pairs and produces as output a Viterbi alignment of that corpus as well as the parameters for the model that produced those alignments." ></td>
	<td class="line x" title="112:175	While these models have proven effective at the word alignment task (Mihalcea & Pedersen 2003), there are significant practical limitations in their output." ></td>
	<td class="line x" title="113:175	Most fundamentally, all alignments have either zero or one connection to each target word." ></td>
	<td class="line x" title="114:175	Hence they are unable to produce the many-tomany alignments required to identify correspondences with idioms and other phrasal chunks." ></td>
	<td class="line x" title="115:175	To mitigate this limitation on final mappings, we follow the approach of Och (2000): we align once in the forward direction and again in the backward direction." ></td>
	<td class="line x" title="116:175	These alignments can subsequently be recombined in a variety of ways, 5 The formula for AER given here and in Och & Ney (2003) is intended to compare an automatic alignment against a gold standard alignment." ></td>
	<td class="line x" title="117:175	However, when comparing one human against another, both comparison and reference distinguish between SURE and POSSIBLE links." ></td>
	<td class="line x" title="118:175	Because the AER is asymmetric (though each direction differs by less than 5%), we have presented the average of the directional AERs." ></td>
	<td class="line x" title="119:175	such as union to maximize recall or intersection to maximize precision." ></td>
	<td class="line x" title="120:175	Och also documents a method for heuristically recombining the unidirectional alignments intended to balance precision and recall." ></td>
	<td class="line x" title="121:175	In our experience, many alignment errors are present in one side but not the other, hence this recombination also serves to filter noise from the process." ></td>
	<td class="line x" title="122:175	4 Evaluation Table 1 shows the results of training translation models on data extracted by both methods and then tested on the blind data." ></td>
	<td class="line x" title="123:175	The best overall performance, irrespective of test data type, is achieved by the L12 training set, with an 11.58% overall AER on the 250 sentence pair edit distance test set (20.88% AER for non-identical words)." ></td>
	<td class="line x" title="124:175	The F2 training data is probably too sparse and, with 40% unrelated sentence pairs, too noisy to achieve equally good results; nevertheless the gap between the results for the two training data types is dramatically narrower on the F2 test data." ></td>
	<td class="line x" title="125:175	The nearly comparable numbers for the two training data sets, at 13.2% and 14.7% respectively, suggest that the L12 training corpus provides no substantive advantage over the F2 data when tested on the more complex test data." ></td>
	<td class="line x" title="126:175	This is particularly striking given the noise inherent in the F2 training data." ></td>
	<td class="line x" title="127:175	5 Analysis/Discussion To explore some of the differences between the training sets, we hand-examined a random sample of sentence pairs from each corpus type." ></td>
	<td class="line x" title="128:175	The most common paraphrase alternations that we observed fell into the following broad categories:  Elaboration: Sentence pairs can differ in total information content, with an added word, phrase or clause in one sentence that has no Training Data Type: L12 F2 L12 F2 Test Data Type: 250 Edit Dist 250 Edit Dist 116 F2 Heuristic 116 F2 Heuristic Precision 87.46% 86.44% 85.07% 84.16% Recall 89.52% 82.64% 88.70% 86.55% AER 11.58% 15.41% 13.24% 14.71% Identical word precision 89.36% 88.79% 92.92% 93.41% Identical word recall 89.50% 83.10% 93.49% 92.47% Identical word AER 10.57% 14.14% 6.80% 7.06% Non-Identical word precision 76.99% 71.86% 60.54% 53.69% Non-Identical word recall 90.22% 69.57% 59.50% 50.41% Non-Identical word AER 20.88% 28.57% 39.81% 47.46% Table 1." ></td>
	<td class="line x" title="129:175	Precision, recall, and alignment error rates (AER) for F2 and L12 counterpart in the other (e.g. the NASDAQ / the tech-heavy NASDAQ)." ></td>
	<td class="line x" title="130:175	 Phrasal: An entire group of words in one sentence alternates with one word or a phrase in the other." ></td>
	<td class="line x" title="131:175	Some are non-compositional idioms (has pulled the plug on / is dropping plans for); others involve different phrasing (electronically / in electronic form, more than a million people / a massive crowd)." ></td>
	<td class="line x" title="132:175	 Spelling: British/American sources systematically differ in spellings of common words (colour / color); other variants also appear (email / e-mail)." ></td>
	<td class="line x" title="133:175	 Synonymy: Sentence pairs differ only in one or two words (e.g. charges / accusations), suggesting an editors hand in modifying a single source sentence." ></td>
	<td class="line x" title="134:175	 Anaphora: A full NP in one sentence corresponds to an anaphor in the other (Prime Minister Blair / He)." ></td>
	<td class="line x" title="135:175	Cases of NP anaphora (ISS / the Atlanta-based security company) are also common in the data, but in quantifying paraphrase types we restricted our attention to the simpler case of pronominal anaphora." ></td>
	<td class="line x" title="136:175	 Reordering: Words, phrases, or entire constituents occur in different order in two related sentences, either because of major syntactic differences (e.g. topicalization, voice alternations) or more local pragmatic choices (e.g. adverb or prepositional phrase placement)." ></td>
	<td class="line x" title="137:175	These categories do not cover all possible alternations between pairs of paraphrased sentences; moreover, categories often overlap in the same sequence of words." ></td>
	<td class="line x" title="138:175	It is common, for example, to find instances of clausal Reordering combined with Synonymy." ></td>
	<td class="line x" title="139:175	Figure 2 shows a hand-aligned paraphrase pair taken from the F2 data." ></td>
	<td class="line x" title="140:175	This pair displays one Spelling alternation (defence / defense), one Reordering (position of the since phrase), and one example of Elaboration (terror attacks occurs in only one sentence)." ></td>
	<td class="line x" title="141:175	To quantify the differences between L12 and F2, we randomly chose 100 sentence pairs from each dataset and counted the number of times each phenomenon was encountered." ></td>
	<td class="line x" title="142:175	A given sentence pair might exhibit multiple instances of a single phenomenon, such as two phrasal paraphrase changes or two synonym replacements." ></td>
	<td class="line x" title="143:175	In this case all instances were counted." ></td>
	<td class="line x" title="144:175	Lower-frequency changes that fell outside of the above categories were not tallied: for example, the presence or absence of a definite article (had authority / had the authority) in Figure 2 was ignored." ></td>
	<td class="line x" title="145:175	After summing all alternations in each sentence pair, we calculated the average number of occurrences of each paraphrase type in each data set." ></td>
	<td class="line x" title="146:175	The results are shown in Table 2." ></td>
	<td class="line x" title="147:175	Several major differences stand out between the two data sets." ></td>
	<td class="line x" title="148:175	First, the F2 data is less parallel, as evidenced by the higher percentage of Elaborations found in those sentence pairs." ></td>
	<td class="line x" title="149:175	Loss of parallelism, however, is offset by greater diversity of paraphrase types encountered in the F2 data." ></td>
	<td class="line x" title="150:175	Phrasal alternations are more than 4x more common, and Reorderings occur over 20x more frequently." ></td>
	<td class="line x" title="151:175	Thus while string difference methods may produce relatively clean training data, this is achieved at the cost of filtering out common (and interesting) paraphrase relationships." ></td>
	<td class="line x" title="152:175	6 Conclusions and Future Work Edit distance identifies sentence pairs that exhibit lexical and short phrasal alternations that can be aligned with considerable success." ></td>
	<td class="line x" title="153:175	Given a large dataset and a well-motivated clustering of documents, useful datasets can be gleaned even without resorting to more sophisticated techniques Figure 2." ></td>
	<td class="line x" title="154:175	Sample human-aligned paraphrase L12 F2 Elaboration 0.83 1.3 Phrasal 0.14 0.69 Spelling 0.12 0.01 Synonym 0.18 0.25 Anaphora 0.1 0.13 Reordering 0.02 0.41 Table 2." ></td>
	<td class="line oc" title="155:175	Mean number of instances of paraphrase phenomena per sentence (such as Multiple Sequence Alignment, as employed by Barzilay & Lee 2003)." ></td>
	<td class="line n" title="156:175	However, there is a disparity between the kinds of paraphrase alternations that we need to be able to align and those that we can already align well using current SMT techniques." ></td>
	<td class="line x" title="157:175	Based solely on the criterion of word AER, the L12 data would seem to be superior to the F2 data as a source of paraphrase knowledge." ></td>
	<td class="line x" title="158:175	Hand evaluation, though, indicates that many of the phenomena that we are interested in learning may be absent from this L12 data." ></td>
	<td class="line x" title="159:175	String edit distance extraction techniques involve assumptions about the data that are inadequate, but achieve high precision." ></td>
	<td class="line x" title="160:175	Techniques like our F2 extraction strategies appear to extract a more diverse variety of data, but yield more noise." ></td>
	<td class="line x" title="161:175	We believe that an approach with the strengths of both methods would lead to significant improvement in paraphrase identification and generation." ></td>
	<td class="line x" title="162:175	In the near term, however, the relatively similar performances of F2 and L12-trained models on the F2 test data suggest that with further refinements, this more complex type of data can achieve good results." ></td>
	<td class="line x" title="163:175	More data will surely help." ></td>
	<td class="line x" title="164:175	One focus of future work is to build a classifier to predict whether two sentences are related through paraphrase." ></td>
	<td class="line x" title="165:175	Features might include edit distance, temporal/topical clustering information, information about cross-document discourse structure, relative sentence length, and synonymy information." ></td>
	<td class="line x" title="166:175	We believe that this work has potential impact on the fields of summarization, information retrieval, and question answering." ></td>
	<td class="line x" title="167:175	Our ultimate goal is to apply current SMT techniques to the problems of paraphrase recognition and generation." ></td>
	<td class="line x" title="168:175	We feel that this is a natural extension of the body of recent developments in SMT; perhaps explorations in monolingual data may have a reciprocal impact." ></td>
	<td class="line x" title="169:175	The field of SMT, long focused on closely aligned data, is only now beginning to address the kinds of problems immediately encountered in monolingual paraphrase (including phrasal translations and large scale reorderings)." ></td>
	<td class="line x" title="170:175	Algorithms to address these phenomena will be equally applicable to both fields." ></td>
	<td class="line x" title="171:175	Of course a broad-domain SMT-influenced paraphrase solution will require very large corpora of sentential paraphrases." ></td>
	<td class="line x" title="172:175	In this paper we have described just one example of a class of data extraction techniques that we hope will scale to this task." ></td>
	<td class="line x" title="173:175	Acknowledgements We are grateful to the Mo Corston-Oliver, Jeff Stevenson and Amy Muia of the Butler Hill Group for their work in annotating the data used in the experiments." ></td>
	<td class="line x" title="174:175	We have also benefited from discussions with Ken Church, Mark Johnson, Daniel Marcu and Franz Och." ></td>
	<td class="line x" title="175:175	We remain, however, responsible for all content." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N04-1015
Catching The Drift: Probabilistic Content Models, With Applications To Generation And Summarization
Barzilay, Regina;Lee, Lillian;"></td>
	<td class="line x" title="1:174	Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization Regina Barzilay Computer Science and AI Lab MIT regina@csail.mit.edu Lillian Lee Department of Computer Science Cornell University llee@cs.cornell.edu Abstract We consider the problem of modeling the content structure of texts within a specific domain, in terms of the topics the texts address and the order in which these topics appear." ></td>
	<td class="line x" title="2:174	We first present an effective knowledge-lean method for learning content models from unannotated documents, utilizing a novel adaptation of algorithms for Hidden Markov Models." ></td>
	<td class="line x" title="3:174	We then apply our method to two complementary tasks: information ordering and extractive summarization." ></td>
	<td class="line x" title="4:174	Our experiments show that incorporating content models in these applications yields substantial improvement over previously-proposed methods." ></td>
	<td class="line x" title="5:174	1 Introduction The development and application of computational models of text structure is a central concern in natural language processing." ></td>
	<td class="line x" title="6:174	Document-level analysis of text structure is an important instance of such work." ></td>
	<td class="line x" title="7:174	Previous research has sought to characterize texts in terms of domain-independent rhetorical elements, such as schema items (McKeown, 1985) or rhetorical relations (Mann and Thompson, 1988; Marcu, 1997)." ></td>
	<td class="line x" title="8:174	The focus of our work, however, is on an equally fundamental but domaindependent dimension of the structure of text: content." ></td>
	<td class="line x" title="9:174	Our use of the term content corresponds roughly to the notions of topic and topic change." ></td>
	<td class="line x" title="10:174	We desire models that can specify, for example, that articles about earthquakes typically contain information about quake strength, location, and casualties, and that descriptions of casualties usually precede those of rescue efforts." ></td>
	<td class="line x" title="11:174	But rather than manually determine the topics for a given domain, we take a distributional view, learning them directly from un-annotated texts via analysis of word distribution patterns." ></td>
	<td class="line x" title="12:174	This idea dates back at least to Harris (1982), who claimed that various types of [word] recurrence patterns seem to characterize various types of discourse." ></td>
	<td class="line x" title="13:174	Advantages of a distributional perspective include both drastic reduction in human effort and recognition of topics that might not occur to a human expert and yet, when explicitly modeled, aid in applications." ></td>
	<td class="line x" title="14:174	Of course, the success of the distributional approach depends on the existence of recurrent patterns." ></td>
	<td class="line x" title="15:174	In arbitrary document collections, such patterns might be too variable to be easily detected by statistical means." ></td>
	<td class="line x" title="16:174	However, research has shown that texts from the same domain tend to exhibit high similarity (Wray, 2002)." ></td>
	<td class="line x" title="17:174	Cognitive psychologists have long posited that this similarity is not accidental, arguing that formulaic text structure facilitates readers comprehension and recall (Bartlett, 1932).1 In this paper, we investigate the utility of domainspecific content models for representing topics and topic shifts." ></td>
	<td class="line x" title="18:174	Content models are Hidden Markov Models (HMMs) wherein states correspond to types of information characteristic to the domain of interest (e.g. , earthquake magnitude or previous earthquake occurrences), and state transitions capture possible information-presentation orderings within that domain." ></td>
	<td class="line x" title="19:174	We first describe an efficient, knowledge-lean method for learning both a set of topics and the relations between topics directly from un-annotated documents." ></td>
	<td class="line x" title="20:174	Our technique incorporates a novel adaptation of the standard HMM induction algorithm that is tailored to the task of modeling content." ></td>
	<td class="line x" title="21:174	Then, we apply techniques based on content models to two complex text-processing tasks." ></td>
	<td class="line x" title="22:174	First, we consider information ordering, that is, choosing a sequence in which to present a pre-selected set of items; this is an essential step in concept-to-text generation, multi-document summarization, and other text-synthesis problems." ></td>
	<td class="line x" title="23:174	In our experiments, content models outperform Lapatas (2003) state-of-the-art ordering method by a wide margin  for one domain and performance metric, the gap was 78 percentage points." ></td>
	<td class="line x" title="24:174	Second, we consider extractive summa1But formulaic is not necessarily equivalent to simple, so automated approaches still offer advantages over manual techniques, especially if one needs to model several domains." ></td>
	<td class="line x" title="25:174	rization: the compression of a document by choosing a subsequence of its sentences." ></td>
	<td class="line x" title="26:174	For this task, we develop a new content-model-based learning algorithm for sentence selection." ></td>
	<td class="line x" title="27:174	The resulting summaries yield 88% match with human-written output, which compares favorably to the 69% achieved by the standard leading a0 sentences baseline." ></td>
	<td class="line x" title="28:174	The success of content models in these two complementary tasks demonstrates their flexibility and effectiveness, and indicates that they are sufficiently expressive to represent important text properties." ></td>
	<td class="line x" title="29:174	These observations, taken together with the fact that content models are conceptually intuitive and efficiently learnable from raw document collections, suggest that the formalism can prove useful in an even broader range of applications than we have considered here; exploring the options is an appealing line of future research." ></td>
	<td class="line x" title="30:174	2 Related Work Knowledge-rich methods Models employing manual crafting of (typically complex) representations of content have generally captured one of three types of knowledge (Rambow, 1990; Kittredge et al. , 1991): domain knowledge [e.g. , that earthquakes have magnitudes], domainindependent communication knowledge [e.g. , that describing an event usually entails specifying its location]; and domain communication knowledge [e.g. , that Reuters earthquake reports often conclude by listing previous quakes2]." ></td>
	<td class="line x" title="31:174	Formalisms exemplifying each of these knowledge types are DeJongs (1982) scripts, McKeowns (1985) schemas, and Rambows (1990) domain-specific schemas, respectively." ></td>
	<td class="line x" title="32:174	In contrast, because our models are based on a distributional view of content, they will freely incorporate information from all three categories as long as such information is manifested as a recurrent pattern." ></td>
	<td class="line x" title="33:174	Also, in comparison to the formalisms mentioned above, content models constitute a relatively impoverished representation; but this actually contributes to the ease with which they can be learned, and our empirical results show that they are quite effective despite their simplicity." ></td>
	<td class="line x" title="34:174	In recent work, Duboue and McKeown (2003) propose a method for learning a content planner from a collection of texts together with a domain-specific knowledge base, but our method applies to domains in which no such knowledge base has been supplied." ></td>
	<td class="line x" title="35:174	Knowledge-lean approaches Distributional models of content have appeared with some frequency in research on text segmentation and topic-based language modeling (Hearst, 1994; Beeferman et al. , 1997; Chen et al. , 1998; Florian and Yarowsky, 1999; Gildea and Hofmann, 1999; 2This does not qualify as domain knowledge because it is not about earthquakes per se." ></td>
	<td class="line x" title="36:174	Iyer and Ostendorf, 1996; Wu and Khudanpur, 2002)." ></td>
	<td class="line x" title="37:174	In fact, the methods we employ for learning content models are quite closely related to techniques proposed in that literature (see Section 3 for more details)." ></td>
	<td class="line x" title="38:174	However, language-modeling research  whose goal is to predict text probabilities  tends to treat topic as a useful auxiliary variable rather than a central concern; for example, topic-based distributional information is generally interpolated with standard, non-topic-based a0 -gram models to improve probability estimates." ></td>
	<td class="line x" title="39:174	Our work, in contrast, treats content as a primary entity." ></td>
	<td class="line x" title="40:174	In particular, our induction algorithms are designed with the explicit goal of modeling document content, which is why they differ from the standard Baum-Welch (or EM) algorithm for learning Hidden Markov Models even though content models are instances of HMMs." ></td>
	<td class="line x" title="41:174	3 Model Construction We employ an iterative re-estimation procedure that alternates between (1) creating clusters of text spans with similar word distributions to serve as representatives of within-document topics, and (2) computing models of word distributions and topic changes from the clusters so derived.3 Formalism preliminaries We treat texts as sequences of pre-defined text spans, each presumed to convey information about a single topic." ></td>
	<td class="line x" title="42:174	Specifying text-span length thus defines the granularity of the induced topics." ></td>
	<td class="line x" title="43:174	For concreteness, in what follows we will refer to sentences rather than text spans since that is what we used in our experiments, but paragraphs or clauses could potentially have been employed instead." ></td>
	<td class="line x" title="44:174	Our working assumption is that all texts from a given domain are generated by a single content model." ></td>
	<td class="line x" title="45:174	A content model is an HMM in which each state a1 corresponds to a distinct topic and generates sentences relevant to that topic according to a state-specific language model a2a4a3  note that standard a0 -gram language models can therefore be considered to be degenerate (single-state) content models." ></td>
	<td class="line x" title="46:174	State transition probabilities give the probability of changing from a given topic to another, thereby capturing constraints on topic shifts." ></td>
	<td class="line x" title="47:174	We can use the forward algorithm to efficiently compute the generation probability assigned to a document by a content model and the Viterbi algorithm to quickly find the most likely contentmodel state sequence to have generated a given document; see Rabiner (1989) for details." ></td>
	<td class="line x" title="48:174	In our implementation, we use bigram language models, so that the probability of an a0 -word sentence a5a7a6 a8a10a9a11a8a13a12a15a14a16a14a17a14a18a8a20a19 being generated by a state a1 is a2a4a3a22a21a23a5a25a24a27a26a11a28a30a29a6 3For clarity, we omit minor technical details, such as the use of dummy initial and final states." ></td>
	<td class="line x" title="49:174	Section 5.2 describes how the free parameters a31, a32, a33a22a34, and a33a36a35 are chosen." ></td>
	<td class="line x" title="50:174	The Athens seismological institute said the temblors epicenter was located 380 kilometers (238 miles) south of the capital." ></td>
	<td class="line x" title="51:174	Seismologists in Pakistans Northwest Frontier Province said the temblors epicenter was about 250 kilometers (155 miles) north of the provincial capital Peshawar." ></td>
	<td class="line x" title="52:174	The temblor was centered 60 kilometers (35 miles) northwest of the provincial capital of Kunming, about 2,200 kilometers (1,300 miles) southwest of Beijing, a bureau seismologist said." ></td>
	<td class="line x" title="53:174	Figure 1: Samples from an earthquake-articles sentence cluster, corresponding to descriptions of location." ></td>
	<td class="line x" title="54:174	a0 a19a1a3a2 a9 a2 a3a22a21 a8 a1a5a4 a8 a1a7a6 a9 a24." ></td>
	<td class="line x" title="55:174	Estimating the state bigram probabilities a2 a3 a21 a8a9a8 a4 a8 a24 is described below." ></td>
	<td class="line x" title="56:174	Initial topic induction As in previous work (Florian and Yarowsky, 1999; Iyer and Ostendorf, 1996; Wu and Khudanpur, 2002), we initialize the set of topics, distributionally construed, by partitioning all of the sentences from the documents in a given domain-specific collection into clusters." ></td>
	<td class="line x" title="57:174	First, we create a10 clusters via complete-link clustering, measuring sentence similarity by the cosine metric using word bigrams as features (Figure 1 shows example output).4 Then, given our knowledge that documents may sometimes discuss new and/or irrelevant content as well, we create an etcetera cluster by merging together all clusters containing fewer than a11 sentences, on the assumption that such clusters consist of outlier sentences." ></td>
	<td class="line x" title="58:174	We use a12 to denote the number of clusters that results." ></td>
	<td class="line x" title="59:174	Determining states, emission probabilities, and transition probabilities Given a set a13 a9a15a14 a13 a12a16a14a18a17a19a17a18a17a19a14 a13a21a20 of a12 clusters, where a13a18a20 is the etcetera cluster, we construct a content model with corresponding states a1 a9 a14 a1 a12 a14a18a17a19a17a18a17a19a14 a1 a20 ; we refer to a1 a20 as the insertion state." ></td>
	<td class="line x" title="60:174	For each state a1 a1, a22a24a23a25a12, bigram probabilities (which induce the states sentence-emission probabilities) are estimated using smoothed counts from the corresponding cluster: a2 a3a27a26a36a21 a8 a8 a4 a8 a24 a26a11a28 a29a6 a28a16a29 a26a11a21 a8a10a8a9a8 a24a31a30a33a32 a9 a28a16a29 a26a11a21 a8 a24a34a30a33a32 a9 a4a35a36a4 a14 where a28 a29 a26 a21a7a37 a24 is the frequency with which word sequence a37 occurs within the sentences in cluster a13 a1, and a35 is the vocabulary." ></td>
	<td class="line oc" title="61:174	But because we want the insertion state a1a16a20 to model digressions or unseen topics, we take the novel step of forcing its language model to be complementary to those of the other states by setting a2 a3a27a38 a21 a8 a8 a4 a8 a24 a26a11a28a30a29a6 a39a41a40a43a42a45a44a16a46 a1a48a47a1a50a49 a20 a2 a3 a26a17a21 a8a9a8 a4 a8 a24 a51a53a52a55a54a57a56 a21 a39a58a40a43a42a45a44a16a46 a1a59a47a1a50a49 a20 a2 a3a27a26a11a21a50a60 a4 a8 a24a30a24 a17 4Following Barzilay and Lee (2003), proper names, numbers and dates are (temporarily) replaced with generic tokens to help ensure that clusters contain sentences describing the same event type, rather than same actual event." ></td>
	<td class="line x" title="62:174	Note that the contents of the etcetera cluster are ignored at this stage." ></td>
	<td class="line x" title="63:174	Our state-transition probability estimates arise from considering how sentences from the same article are distributed across the clusters." ></td>
	<td class="line x" title="64:174	More specifically, for two clusters a13 and a13 a8, let a61 a21a62a13 a14 a13 a8 a24 be the number of documents in which a sentence from a13 immediately precedes one from a13 a8, and let a61 a21a50a13a16a24 be the number of documents containing sentences from a13 . Then, for any two states a1 a1 and a1a21a63, a22 a14a27a64a66a65 a12, we use the following smoothed estimate of the probability of transitioning from a1 a1 to a1a5a63 : a2 a21 a1a21a63 a4 a1 a1 a24 a6 a61 a21a50a13 a1 a14 a13 a63 a24a34a30a67a32 a12 a61 a21a62a13 a1 a24a34a30a67a32 a12 a12 a17 Viterbi re-estimation Our initial clustering ignores sentence order; however, contextual clues may indicate that sentences with high lexical similarity are actually on different topics." ></td>
	<td class="line x" title="65:174	For instance, Reuters articles about earthquakes frequently finish by mentioning previous quakes." ></td>
	<td class="line x" title="66:174	This means that while the sentence The temblor injured dozens at the beginning of a report is probably highly salient and should be included in a summary of it, the same sentence at the end of the piece probably refers to a different event, and so should be omitted." ></td>
	<td class="line x" title="67:174	A natural way to incorporate ordering information is iterative re-estimation of the model parameters, since the content model itself provides such information through its transition structure." ></td>
	<td class="line x" title="68:174	We take an EM-like Viterbi approach (Iyer and Ostendorf, 1996): we re-cluster the sentences by placing each one in the (new) cluster a13 a1, a22 a65 a12, that corresponds to the state a1 a1 most likely to have generated it according to the Viterbi decoding of the training data." ></td>
	<td class="line x" title="69:174	We then use this new clustering as the input to the procedure for estimating HMM parameters described above." ></td>
	<td class="line x" title="70:174	The cluster/estimate cycle is repeated until the clusterings stabilize or we reach a predefined number of iterations." ></td>
	<td class="line x" title="71:174	4 Evaluation Tasks We apply the techniques just described to two tasks that stand to benefit from models of content and changes in topic: information ordering for text generation and information selection for single-document summarization." ></td>
	<td class="line x" title="72:174	These are two complementary tasks that rely on disjoint model functionalities: the ability to order a set of pre-selected information-bearing items, and the ability to do the selection itself, extracting from an ordered sequence of information-bearingitems a representative subsequence." ></td>
	<td class="line x" title="73:174	4.1 Information Ordering The information-ordering task is essential to many textsynthesis applications, including concept-to-text generation and multi-document summarization; While accounting for the full range of discourse and stylistic factors that influence the ordering process is infeasible in many domains, probabilistic content models provide a means for handling important aspects of this problem." ></td>
	<td class="line x" title="74:174	We demonstrate this point by utilizing content models to select appropriate sentence orderings: we simply use a content model trained on documents from the domain of interest, selecting the ordering among all the presented candidates that the content model assigns the highest probability to." ></td>
	<td class="line x" title="75:174	4.2 Extractive Summarization Content models can also be used for single-document summarization." ></td>
	<td class="line x" title="76:174	Because ordering is not an issue in this application5, this task tests the ability of content models to adequately represent domain topics independently of whether they do well at ordering these topics." ></td>
	<td class="line x" title="77:174	The usual strategy employed by domain-specific summarizers is for humans to determine a priori what types of information from the originating documents should be included (e.g. , in stories about earthquakes, the number of victims) (Radev and McKeown, 1998; White et al. , 2001)." ></td>
	<td class="line x" title="78:174	Some systems avoid the need for manual analysis by learning content-selection rules from a collection of articles paired with human-authored summaries, but their learning algorithms typically focus on withinsentence features or very coarse structural features (such as position within a paragraph) (Kupiec et al. , 1999)." ></td>
	<td class="line x" title="79:174	Our content-model-based summarization algorithm combines the advantages of both approaches; on the one hand, it learns all required information from un-annotated document-summary pairs; on the other hand, it operates on a more abstract and global level, making use of the topical structure of the entire document." ></td>
	<td class="line x" title="80:174	Our algorithm is trained as follows." ></td>
	<td class="line x" title="81:174	Given a content model acquired from the full articles using the method described in Section 3, we need to learn which topics (represented by the content models states) should appear in our summaries." ></td>
	<td class="line x" title="82:174	Our first step is to employ the Viterbi algorithm to tag all of the summary sentences and all of the sentences from the original articles with a Viterbi topic label, or V-topic  the name of the state most likely to have generated them." ></td>
	<td class="line x" title="83:174	Next, for each state a1 such that at least three full training-set articles contained V-topic a1, we compute the probability that the state generates sentences that should appear in a summary." ></td>
	<td class="line x" title="84:174	This probability is estimated by simply (1) counting the number of document-summary pairs in the parallel training data such that both the originating document and the summary contain sentences assigned V-topic a1, and then (2) normalizing this count by the number of full articles containing sentences with V-topic a1 . 5Typically, sentences in a single-document summary follow the order of appearance in the original document." ></td>
	<td class="line x" title="85:174	Domain Average Standard Vocabulary Token/ Length Deviation Size type Earthquakes 10.4 5.2 1182 13.2 Clashes 14.0 2.6 1302 4.5 Drugs 10.3 7.5 1566 4.1 Finance 13.7 1.6 1378 12.8 Accidents 11.5 6.3 2003 5.6 Table 1: Corpus statistics." ></td>
	<td class="line x" title="86:174	Length is in sentences." ></td>
	<td class="line x" title="87:174	Vocabulary size and type/token ratio are computed after replacement of proper names, numbers and dates." ></td>
	<td class="line x" title="88:174	To produce a length-a0 summary of a new article, the algorithm first uses the content model and Viterbi decoding to assign each of the articles sentences a V-topic." ></td>
	<td class="line x" title="89:174	Next, the algorithm selects those a0 states, chosen from among those that appear as the V-topic of one of the articles sentences, that have the highest probability of generating a summary sentence, as estimated above." ></td>
	<td class="line x" title="90:174	Sentences from the input article corresponding to these states are placed in the output summary.6 5 Evaluation Experiments 5.1 Data For evaluation purposes, we created corpora from five domains: earthquakes, clashes between armies and rebel groups, drug-related criminal offenses, financial reports, and summaries of aviation accidents.7 Specifically, the first four collections consist of AP articles from the North American News Corpus gathered via a TDT-style document clustering system." ></td>
	<td class="line x" title="91:174	The fifth consists of narratives from the National Transportation Safety Boards database previously employed by Jones and Thompson (2003) for event-identification experiments." ></td>
	<td class="line x" title="92:174	For each such set, 100 articles were used for training a content model, 100 articles for testing, and 20 for the development set used for parameter tuning." ></td>
	<td class="line x" title="93:174	Table 1 presents information about article length (measured in sentences, as determined by the sentence separator of Reynar and Ratnaparkhi (1997)), vocabulary size, and token/type ratio for each domain." ></td>
	<td class="line x" title="94:174	5.2 Parameter Estimation Our training algorithm has four free parameters: two that indirectly control the number of states in the induced content model, and two parameters for smoothing bigram probabilities." ></td>
	<td class="line x" title="95:174	All were tuned separately for each domain on the corresponding held-out development set using Powells grid search (Press et al. , 1997)." ></td>
	<td class="line x" title="96:174	The parameter values were selected to optimize system performance 6If there are more than a1 sentences, we prioritize them by the summarization probability of their V-topics state; we break any further ties by order of appearance in the document." ></td>
	<td class="line x" title="97:174	7http://www.sls.csail.mit.edu/regina/struct on the information-ordering task8." ></td>
	<td class="line x" title="98:174	We found that across all domains, the optimal models were based on sharper language models (e.g. , a32 a9 a23a1a0 a17a0a2a0a3a0a2a0a3a0a2a0 a39 )." ></td>
	<td class="line x" title="99:174	The optimal number of states ranged from 32 to 95." ></td>
	<td class="line x" title="100:174	5.3 Ordering Experiments 5.3.1 Metrics The intent behind our ordering experiments is to test whether content models assign high probability to acceptable sentence arrangements." ></td>
	<td class="line x" title="101:174	However, one stumbling block to performing this kind of evaluation is that we do not have data on ordering quality: the set of sentences from an a4 -sentence document can be sequenced in a4a6a5 different ways, which even for a single text of moderate length is too many to ask humans to evaluate." ></td>
	<td class="line x" title="102:174	Fortunately, we do know that at least the original sentence order (OSO) in the source document must be acceptable, and so we should prefer algorithms that assign it high probability relative to the bulk of all the other possible permutations." ></td>
	<td class="line x" title="103:174	This observation motivates our first evaluation metric: the rank received by the OSO when all permutations of a given documents sentences are sorted by the probabilities that the model under consideration assigns to them." ></td>
	<td class="line x" title="104:174	The best possible rank is 0, and the worst is a4a6a5 a40 a39 . An additional difficulty we encountered in setting up our evaluation is that while we wanted to compare our algorithms against Lapatas (2003) state-of-the-art system, her method doesnt consider all permutations (see below), and so the rank metric cannot be computed for it." ></td>
	<td class="line x" title="105:174	To compensate, we report the OSO prediction rate, which measures the percentage of test cases in which the model under consideration gives highest probability to the OSO from among all possible permutations; we expect that a good model should predict the OSO a fair fraction of the time." ></td>
	<td class="line x" title="106:174	Furthermore, to provide some assessment of the quality of the predicted orderings themselves, we follow Lapata (2003) in employing Kendalls a7, which is a measure of how much an ordering differs from the OSO the underlying assumption is that most reasonable sentence orderings should be fairly similar to it." ></td>
	<td class="line x" title="107:174	Specifically, for a permutation a8 of the sentences in an a4 -sentence document, a7 a21a9a8 a24 is computed as a7 a21a10a8 a24 a6 a39a41a40a12a11a14a13 a21a10a8 a24 a15a17a16 a12a19a18 a14 where a13a13a21a9a8 a24 is the number of swaps of adjacent sentences necessary to re-arrangea8 into the OSO." ></td>
	<td class="line x" title="108:174	The metric ranges from -1 (inverse orders) to 1 (identical orders)." ></td>
	<td class="line x" title="109:174	8See Section 5.5 for discussion of the relation between the ordering and the summarization task." ></td>
	<td class="line x" title="110:174	5.3.2 Results For each of the 500 unseen test texts, we exhaustively enumerated all sentence permutations and ranked them using a content model from the corresponding domain." ></td>
	<td class="line x" title="111:174	We compared our results against those of a bigram language model (the baseline) and an improved version of the state-of-the-art probabilistic ordering method of Lapata (2003), both trained on the same data we used." ></td>
	<td class="line x" title="112:174	Lapatas method first learns a set of pairwise sentenceordering preferences based on features such as noun-verb dependencies." ></td>
	<td class="line x" title="113:174	Given a new set of sentences, the latest version of her method applies a Viterbi-style approximation algorithm to choose a permutation satisfying many preferences (Lapata, personal communication).9 Table 2 gives the results of our ordering-test comparison experiments." ></td>
	<td class="line x" title="114:174	Content models outperform the alternatives almost universally, and often by a very wide margin." ></td>
	<td class="line x" title="115:174	We conjecture that this difference in performance stems from the ability of content models to capture global document structure." ></td>
	<td class="line x" title="116:174	In contrast, the other two algorithms are local, taking into account only the relationships between adjacent word pairs and adjacent sentence pairs, respectively." ></td>
	<td class="line x" title="117:174	It is interesting to observe that our method achieves better results despite not having access to the linguistic information incorporated by Lapatas method." ></td>
	<td class="line x" title="118:174	To be fair, though, her techniques were designed for a larger corpus than ours, which may aggravate data sparseness problems for such a feature-rich method." ></td>
	<td class="line x" title="119:174	Table 3 gives further details on the rank results for our content models, showing how the rank scores were distributed; for instance, we see that on the Earthquakes domain, the OSO was one of the top five permutations in 95% of the test documents." ></td>
	<td class="line x" title="120:174	Even in Drugs and Accidents  the domains that proved relatively challenging to our method  in more than 55% of the cases the OSOs rank did not exceed ten." ></td>
	<td class="line x" title="121:174	Given that the maximal possible rank in these domains exceeds three million, we believe that our model has done a good job in the ordering task." ></td>
	<td class="line x" title="122:174	We also computed learning curves for the different domains; these are shown in Figure 2." ></td>
	<td class="line x" title="123:174	Not surprisingly, performance improves with the size of the training set for all domains." ></td>
	<td class="line x" title="124:174	The figure also shows that the relative difficulty (from the content-model point of view) of the different domains remains mostly constant across varying trainingset sizes." ></td>
	<td class="line x" title="125:174	Interestingly, the two easiest domains, Finance and Earthquakes, can be thought of as being more formulaic or at least more redundant, in that they have the highest token/type ratios (see Table 1)  that is, in these domains, words are repeated much more frequently on average." ></td>
	<td class="line x" title="126:174	9Finding the optimal such permutation is NP-complete." ></td>
	<td class="line x" title="127:174	Domain System Rank OSO a7 pred." ></td>
	<td class="line x" title="128:174	Content 2.67 72% 0.81 Earthquakes Lapata (N/A) 24% 0.48 Bigram 485.16 4% 0.27 Content 3.05 48% 0.64 Clashes Lapata (N/A) 27% 0.41 Bigram 635.15 12% 0.25 Content 15.38 38% 0.45 Drugs Lapata (N/A) 27% 0.49 Bigram 712.03 11% 0.24 Content 0.05 96% 0.98 Finance Lapata (N/A) 18% 0.75 Bigram 7.44 66% 0.74 Content 10.96 41% 0.44 Accidents Lapata (N/A) 10% 0.07 Bigram 973.75 2% 0.19 Table 2: Ordering results (averages over the test cases)." ></td>
	<td class="line x" title="129:174	Domain Rank range [0-4] [5-10] a0 a39 a0 Earthquakes 95% 1% 4% Clashes 75% 18% 7% Drugs 47% 8% 45% Finance 100% 0% 0% Accidents 52% 7% 41% Table 3: Percentage of cases for which the content model assigned to the OSO a rank within a given range." ></td>
	<td class="line x" title="130:174	5.4 Summarization Experiments The evaluation of our summarization algorithm was driven by two questions: (1) Are the summaries produced of acceptable quality, in terms of selected content?" ></td>
	<td class="line x" title="131:174	and (2) Does the content-model representation provide additional advantages over more locally-focused methods?" ></td>
	<td class="line x" title="132:174	To address the first question, we compare summaries created by our system against the lead baseline, which extracts the first a0 sentences of the original text  despite its simplicity, the results from the annual Document Understanding Conference (DUC) evaluation suggest that most single-document summarization systems cannot beat this baseline." ></td>
	<td class="line x" title="133:174	To address question (2), we consider a summarization system that learns extraction rules directly from a parallel corpus of full texts and their summaries (Kupiec et al. , 1999)." ></td>
	<td class="line x" title="134:174	In this system, summarization is framed as a sentence-level binary classification problem: each sentence is labeled by the publiclyavailable BoosTexter system (Schapire and Singer, 2000) as being either in or out of the summary." ></td>
	<td class="line x" title="135:174	The features considered for each sentence are its unigrams and 0 10 20 30 40 50 60 70 80 90 100 0 20 40 60 80 100 OSO prediction rate Training-set size earthquake clashes drugs finance accidents Figure 2: Ordering-task performance, in terms of OSO prediction rate, as a function of the number of documents in the training set." ></td>
	<td class="line x" title="136:174	its location within the text, namely beginning third, middle third and end third.10 Hence, relationships between sentences are not explicitly modeled, making this system a good basis for comparison." ></td>
	<td class="line x" title="137:174	We evaluated our summarization system on the Earthquakes domain, since for some of the texts in this domain there is a condensed version written by AP journalists." ></td>
	<td class="line x" title="138:174	These summaries are mostly extractive11; consequently, they can be easily aligned with sentences in the original articles." ></td>
	<td class="line x" title="139:174	From sixty document-summary pairs, half were randomly selected to be used for training and the other half for testing." ></td>
	<td class="line x" title="140:174	(While thirty documents may not seem like a large number, it is comparable to the size of the training corpora used in the competitive summarizationsystem evaluations mentioned above)." ></td>
	<td class="line x" title="141:174	The average number of sentences in the full texts and summaries was 15 and 6, respectively, for a total of 450 sentences in each of the test and (full documents of the) training sets." ></td>
	<td class="line x" title="142:174	At runtime, we provided the systems with a full document and the desired output length, namely, the length in sentences of the corresponding shortened version." ></td>
	<td class="line x" title="143:174	The resulting summaries were judged as a whole by the fraction of their component sentences that appeared in the human-written summary of the input text." ></td>
	<td class="line x" title="144:174	The results in Table 4 confirm our hypothesis about the benefits of content models for text summarization  our model outperforms both the sentence-level, locallyfocused classifier and the lead baseline." ></td>
	<td class="line x" title="145:174	Furthermore, as the learning curves shown in Figure 3 indicate, our method achieves good performance on a small subset of parallel training data: in fact, the accuracy of our method on one third of the training data is higher than that of the 10This feature set yielded the best results among the several possibilities we tried." ></td>
	<td class="line x" title="146:174	11Occasionally, one or two phrases or, more rarely, a clause were dropped." ></td>
	<td class="line x" title="147:174	System Extraction accuracy Content-based 88% Sentence classifier 76% (words + location) Leading a0 sentences 69% Table 4: Summarization-task results." ></td>
	<td class="line x" title="148:174	0 10 20 30 40 50 60 70 80 90 0 5 10 15 20 25 30 Summarization accuracy Training-set size (number of summary/source pairs) content-model word+loc lead Figure 3: Summarization performance (extraction accuracy) on Earthquakes as a function of training-set size." ></td>
	<td class="line x" title="149:174	sentence-level classifier on the full training set." ></td>
	<td class="line x" title="150:174	Clearly, this performance gain demonstrates the effectiveness of content models for the summarization task." ></td>
	<td class="line x" title="151:174	5.5 Relation Between Ordering and Summarization Methods Since we used two somewhat orthogonal tasks, ordering and summarization, to evaluate the quality of the contentmodel paradigm, it is interesting to ask whether the same parameterization of the model does well in both cases." ></td>
	<td class="line x" title="152:174	Specifically, we looked at the results for different model topologies, induced by varying the number of contentmodel states." ></td>
	<td class="line x" title="153:174	For these tests, we experimented with the Earthquakes data (the only domain for which we could evaluate summarization performance), and exerted direct control over the number of states, rather than utilizing the cluster-size threshold; that is, in order to create exactly a12 states for a specific value of a12, we merged the smallest clusters until a12 clusters remained." ></td>
	<td class="line x" title="154:174	Table 5 shows the performance of the different-sized content models with respect to the summarization task and the ordering task (using OSO prediction rate)." ></td>
	<td class="line x" title="155:174	While the ordering results seem to be more sensitive to the number of states, both metrics induce similar ranking on the models." ></td>
	<td class="line x" title="156:174	In fact, the same-size model yields top performance on both tasks." ></td>
	<td class="line x" title="157:174	While our experiments are limited to only one domain, the correlation in results is encouraging: optimizing parameters on one task promises to yield Model size 10 20 40 60 64 80 Ordering 11% 28% 52% 50% 72% 57% Summarization 54% 70% 79% 79% 88% 83% Table 5: Content-model performance on Earthquakes as a function of model size." ></td>
	<td class="line x" title="158:174	Ordering: OSO prediction rate; Summarization: extraction accuracy." ></td>
	<td class="line x" title="159:174	good performance on the other." ></td>
	<td class="line x" title="160:174	These findings provide support for the hypothesis that content models are not only helpful for specific tasks, but can serve as effective representations of text structure in general." ></td>
	<td class="line x" title="161:174	6 Conclusions In this paper, we present an unsupervised method for the induction of content models, which capture constraints on topic selection and organization for texts in a particular domain." ></td>
	<td class="line x" title="162:174	Incorporation of these models in ordering and summarization applications yields substantial improvement over previously-proposed methods." ></td>
	<td class="line x" title="163:174	These results indicate that distributional approaches widely used to model various inter-sentential phenomena can be successfully applied to capture text-level relations, empirically validating the long-standing hypothesis that word distribution patterns strongly correlate with discourse patterns within a text, at least within specific domains." ></td>
	<td class="line x" title="164:174	An important future direction lies in studying the correspondence between our domain-specific model and domain-independent formalisms, such as RST." ></td>
	<td class="line x" title="165:174	By automatically annotating a large corpus of texts with discourse relations via a rhetorical parser (Marcu, 1997; Soricut and Marcu, 2003), we may be able to incorporate domain-independent relationships into the transition structure of our content models." ></td>
	<td class="line x" title="166:174	This study could uncover interesting connections between domain-specific stylistic constraints and generic principles of text organization." ></td>
	<td class="line x" title="167:174	In the literature, discourse is frequently modeled using a hierarchical structure, which suggests that probabilistic context-free grammars or hierarchical Hidden Markov Models (Fine et al. , 1998) may also be applied for modeling content structure." ></td>
	<td class="line x" title="168:174	In the future, we plan to investigate how to bootstrap the induction of hierarchical models using labeled data derived from our content models." ></td>
	<td class="line x" title="169:174	We would also like to explore how domain-independent discourse constraints can be used to guide the construction of the hierarchical models." ></td>
	<td class="line x" title="170:174	Acknowledgments We are grateful to Mirella Lapata for providing us the results of her system on our data, and to Dominic Jones and Cindi Thompson for supplying us with their document collection." ></td>
	<td class="line x" title="171:174	We also thank Eli Barzilay, Sasha Blair-Goldensohn, Eric Breck, Claire Cardie, Yejin Choi, Marcia Davidson, Pablo Duboue, Noemie Elhadad, Luis Gravano, Julia Hirschberg, Sanjeev Khudanpur, Jon Kleinberg, Oren Kurland, Kathy McKeown, Daniel Marcu, Art Munson, Smaranda Muresan, Vincent Ng, Bo Pang, Becky Passoneau, Owen Rambow, Ves Stoyanov, Chao Wang and the anonymous reviewers for helpful comments and conversations." ></td>
	<td class="line x" title="172:174	Portions of this work were done while the first author was a postdoctoral fellow at Cornell University." ></td>
	<td class="line x" title="173:174	This paper is based upon work supported in part by the National Science Foundation under grants ITR/IM IIS-0081334 and IIS-0329064 and by an Alfred P. Sloan Research Fellowship." ></td>
	<td class="line x" title="174:174	Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the National Science Foundation or Sloan Foundation." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N04-1031
Paraphrasing Predicates From Written Language To Spoken Language Using The Web
Kaji, Nobuhiro;Okamoto, Masashi;Kurohashi, Sadao;"></td>
	<td class="line x" title="1:210	Paraphrasing Predicates from Written Language to Spoken Language Using the Web Nobuhiro Kaji and Masashi Okamoto and Sadao Kurohashi Graduate School of Information Science and Technology, the University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan CUkaji,okamoto,kuroCV@kc.t.u-tokyo.ac.jp Abstract There are a lot of differences between expressions used in written language and spoken language." ></td>
	<td class="line x" title="2:210	It is one of the reasons why speech synthesis applications are prone to produce unnatural speech." ></td>
	<td class="line x" title="3:210	This paper represents a method of paraphrasing unsuitable expressions for spoken language into suitable ones." ></td>
	<td class="line x" title="4:210	Those two expressions can be distinguished based on the occurrence probability in written and spoken language corpora which are automatically collected from the Web." ></td>
	<td class="line x" title="5:210	Experimental results indicated the effectiveness of our method." ></td>
	<td class="line x" title="6:210	The precision of the collected corpora was 94%, and the accuracy of learning paraphrases was 76 %." ></td>
	<td class="line x" title="7:210	1 Introduction Information can be provided in various forms, and one of them is speech form." ></td>
	<td class="line x" title="8:210	Speech form is familiar to humans, and can convey information effectively (Nadamoto et al. , 2001; Hayashi et al. , 1999)." ></td>
	<td class="line x" title="9:210	However, little electronic information is provided in speech form so far." ></td>
	<td class="line x" title="10:210	On the other hand, there is a lot of information in text form, and it can be transformed into speech by a speech synthesis." ></td>
	<td class="line x" title="11:210	Therefore, a lot of attention has been given to applications which uses speech synthesis, for example (Fukuhara et al. , 2001)." ></td>
	<td class="line x" title="12:210	In order to enhance such applications, two problems need to be resolved." ></td>
	<td class="line x" title="13:210	The first is that current speech synthesis technology is still insufficient and many applications often produce speech with unnatural accents and intonations." ></td>
	<td class="line x" title="14:210	The second one is that there are a lot of differences between expressions used in written language and spoken language." ></td>
	<td class="line x" title="15:210	For example, Ohishi indicated that difficult words and compound nouns are more often used in written language than in spoken language (Ohishi, 1970)." ></td>
	<td class="line x" title="16:210	Therefore, the applications are prone to produce unnatural speech, if their input is in written language." ></td>
	<td class="line x" title="17:210	Although the first problem is well-known, little attention has been given to the second one." ></td>
	<td class="line x" title="18:210	The reason why the second problem arises is that the input text contains Unsuitable Expressions for Spoken language (UES)." ></td>
	<td class="line x" title="19:210	Therefore, the problem can be resolved by paraphrasing UES into Suitable Expression for Spoken language (SES)." ></td>
	<td class="line x" title="20:210	This is a new application of paraphrasing." ></td>
	<td class="line x" title="21:210	There are no similar attempts, although a variety of applications have been discussed so far, for example question-answering (Lin and Pantel, 2001; Hermjakob et al. , 2002; Duclaye and Yvon, 2003) or text-simplification (Inui et al. , 2003)." ></td>
	<td class="line x" title="22:210	(1) Written (2) Spoken (3) Unnatural Figure 1: Paraphrasing UES into SES Figure 1 illustrates paraphrasing UES into SES." ></td>
	<td class="line x" title="23:210	In the figure, three types of expressions are shown: (1) expressions used in written language, (2) expressions used in spoken language, and (3) unnatural expressions." ></td>
	<td class="line x" title="24:210	The overlap between two circles represents expressions used both in written language and spoken language." ></td>
	<td class="line x" title="25:210	UES is the shaded portion: unnatural expressions, and expressions used only in written language." ></td>
	<td class="line x" title="26:210	SES is the nonshaded portion." ></td>
	<td class="line x" title="27:210	The arrows represent paraphrasing UES into SES, and other paraphrasing is represented by broken arrows." ></td>
	<td class="line x" title="28:210	Paraphrasing unnatural expressions is not considered, since such expressions are not included in the input text." ></td>
	<td class="line x" title="29:210	The reason why unnatural expressions are taken into consideration is that paraphrasing into such expressions should be avoided." ></td>
	<td class="line x" title="30:210	In order to paraphrase UES into SES, this paper proposes a method of learning paraphrase pairs in the form of UES AX SES." ></td>
	<td class="line x" title="31:210	The key notion of the method is to distinguish UES and SES based on the occurrence probability in written and spoken language corpora which are automatically collected from the Web." ></td>
	<td class="line x" title="32:210	The procedure of the method is as follows: 1 (step 1) Paraphrase pairs of predicates 2 are learned from a dictionary using a method proposed by (Kaji et al. , 2002)." ></td>
	<td class="line x" title="33:210	(step 2) Written and spoken language corpora are automatically collected from the Web." ></td>
	<td class="line x" title="34:210	(step 3) From the paraphrase pairs learned in step 1, those in the form of UESAXSES are selected using the corpora." ></td>
	<td class="line x" title="35:210	This paper deals with only paraphrase pairs of predicates, although UES includes not only predicates but also other categories such as nouns." ></td>
	<td class="line x" title="36:210	This paper is organized as follows." ></td>
	<td class="line x" title="37:210	In Section 2 related works are illustrated." ></td>
	<td class="line x" title="38:210	Section 3 summarizes the method of Kaji et al. In Section 4, we describe the method of collecting corpora form the Web and report the experimental result." ></td>
	<td class="line x" title="39:210	In Section 5, we describe the method of selecting suitable paraphrases pairs and the experimental result." ></td>
	<td class="line x" title="40:210	Our future work is described in Section 6, and we conclude in Section 7." ></td>
	<td class="line x" title="41:210	2 Related Work Paraphrases are different expressions which convey the same or almost the same meaning." ></td>
	<td class="line x" title="42:210	However, there are few paraphrases that have exactly the same meaning, and almost all have subtle differences such as style or formality etc. Such a difference is called a connotational difference." ></td>
	<td class="line x" title="43:210	This paper addresses one of the connotational differences, that is, the difference of whether an expression is suitable or unsuitable for spoken language." ></td>
	<td class="line nc" title="44:210	Although a large number of studies have been made on learning paraphrases, for example (Barzilay and Lee, 2003), there are only a few studies which address the connotational difference of paraphrases." ></td>
	<td class="line x" title="45:210	One of the studies is a series of works by Edmonds et al. and Inkpen et al (Edmonds and Hirst, 2002; Inkpen and Hirst, 2001)." ></td>
	<td class="line x" title="46:210	Edmonds et al. proposed a computational model which represents the connotational difference, and Inkpen et al. showed that the parameters of the model can be learned from a synonym dictionary." ></td>
	<td class="line x" title="47:210	However, it is doubtful whether the connotational difference between paraphrases is sufficiently described in such a lexical resource." ></td>
	<td class="line x" title="48:210	On the other hand, Inui et al. discussed read1 Note that this paper deals with Japanese." ></td>
	<td class="line x" title="49:210	2 A predicate is a verb or an adjective." ></td>
	<td class="line x" title="50:210	ability, which is one of the connotational differences, and proposed a method of learning readability ranking model of paraphrases from a tagged corpus (Inui and Yamamoto, 2001)." ></td>
	<td class="line x" title="51:210	The tagged corpus was built as follows: a large amount of paraphrase pairs were prepared and annotators tagged them according to their readability." ></td>
	<td class="line x" title="52:210	However, they focused only on syntactic paraphrases." ></td>
	<td class="line x" title="53:210	This paper deals with lexical paraphrases." ></td>
	<td class="line oc" title="54:210	There are several works that try to learn paraphrase pairs from parallel or comparable corpora (Barzilay and McKeown, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003; Pang et al. , 2003)." ></td>
	<td class="line x" title="55:210	In our work, paraphrase pairs are not learned from corpora but learned from a dictionary." ></td>
	<td class="line x" title="56:210	Our corpora are neither parallel nor comparable, and are used to distinguish UES and SES." ></td>
	<td class="line x" title="57:210	There are several studies that compare two corpora which have different styles, for example, written and spoken corpora or British and American English corpora, and try to find expressions unique to either of the styles (Kilgarriff, 2001)." ></td>
	<td class="line x" title="58:210	However, those studies did not deal with paraphrases." ></td>
	<td class="line x" title="59:210	Bulyko et al. also collected spoken language corpora from the Web (Bulyko et al. , 2003)." ></td>
	<td class="line x" title="60:210	The method of Bulyko et al. used N-grams in a training corpus and is different from ours (the detail of our method is described in Section 4)." ></td>
	<td class="line x" title="61:210	In respect of automatically collecting corpora which have a desired style, Tambouratzis et al. proposed a method of dividing Modern Greek corpus into Demokiti and Katharevoua, which are variations of Modern Greek (Tambouratzis et al. , 2000)." ></td>
	<td class="line x" title="62:210	3 Learning Predicate Paraphrase Pairs Kaji et al. proposed a method of paraphrasing predicates using a dictionary (Kaji et al. , 2002)." ></td>
	<td class="line x" title="63:210	For example, when a definition sentence of chiratsuku (to shimmer) is yowaku hikaru (to shine faintly), his method paraphrases (1a) into (1b)." ></td>
	<td class="line x" title="64:210	(1) a. ranpu-ga chiratsuku a lamp to shimmer b. ranpu-ga yowaku hikaru a lamp faintly to shine As Kaji et al. discussed, this dictionary-based paraphrasing involves three difficulties: word sense ambiguity, extraction of the appropriate paraphrase from a definition sentence, transformation of postposition 3." ></td>
	<td class="line x" title="65:210	In order to solve those difficulties, he proposed a method based on case frame alignment." ></td>
	<td class="line x" title="66:210	If paraphrases can be extracted from the definition sentences appropriately, paraphrase pairs can be learned." ></td>
	<td class="line x" title="67:210	We extracted paraphrases from definition sentences using the 3 Japanese noun is attached with a postposition." ></td>
	<td class="line x" title="68:210	method of Kaji et al. However, it is beyond the scope of this paper to describe his method as a whole." ></td>
	<td class="line x" title="69:210	Instead, we represent an overview and show examples." ></td>
	<td class="line x" title="70:210	(predicate) (definition sentence) (2) a. chiratsuku [ kasukani hikaru ] to shimmer faintly to shine to shine faintly b. chokinsuru [ okane-wo tameru ] to save money money to save to save money c. kansensuru byouki-ga [ utsuru ] to be infected disease to be infected to be infected with a disease In almost all cases, a headword of a definition sentence of a predicate is also a predicate, and the definition sentence sometimes has adverbs and nouns which modify the head word." ></td>
	<td class="line x" title="71:210	In the examples, headwords are hikaru (to shine), tameru (to save), and utsuru (to be infected)." ></td>
	<td class="line x" title="72:210	The adverbs are underlined, the nouns are underlined doubly, paraphrases of the predicates are in brackets." ></td>
	<td class="line x" title="73:210	The headword and the adverbs can be considered to be always included in the paraphrase." ></td>
	<td class="line x" title="74:210	On the other hand, the nouns are not, for example money in (2b) is included but disease in (2c) is not." ></td>
	<td class="line x" title="75:210	It is decided by the method of Kaji et al. whether they are included or not." ></td>
	<td class="line x" title="76:210	The paraphrase includes one noun at most, and is in the form of adverbA3 noun+ predicate 4 . Hereafter, it is assumed that a paraphrase pair which is learned is in the form of predicate AX adverbA3 noun+ predicate." ></td>
	<td class="line x" title="77:210	The predicate is called source, the adverbA3 noun+ predicate is called target." ></td>
	<td class="line x" title="78:210	We used reikai-shougaku-dictionary (Tadika, 1997), and 5,836 paraphrase pairs were learned." ></td>
	<td class="line x" title="79:210	The main problem dealt with in this paper is to select paraphrase pairs in the form of UES AX SES from those 5,836 ones." ></td>
	<td class="line x" title="80:210	4 Collecting Written and Spoken Language Corpora from the Web We distinguish UES and SES (see Figure 1) using the occurrence probability in written and spoken language corpora." ></td>
	<td class="line x" title="81:210	Therefore, large written and spoken corpora are necessary." ></td>
	<td class="line x" title="82:210	We cannot use existing Japanese spoken language corpora, such as (Maekawa et al. , 2000; Takezawa et al. , 2002), because they are small." ></td>
	<td class="line x" title="83:210	Our solution is to automatically collect written and spoken language corpora from the Web." ></td>
	<td class="line x" title="84:210	The Web contains various texts in different styles." ></td>
	<td class="line x" title="85:210	Such texts as news articles can be regarded as written language corpora, and such texts as chat logs can be regarded as spoken language corpora." ></td>
	<td class="line x" title="86:210	Since we do not need information such as 4 A3 means zero or more, and + means one or more." ></td>
	<td class="line x" title="87:210	accents or intonations, speech data of real conversations is not always required." ></td>
	<td class="line x" title="88:210	This papepr proposes a method of collecting written and spoken language corpora from the Web using interpersonal expressions (Figure 2)." ></td>
	<td class="line x" title="89:210	Our method is as follows." ></td>
	<td class="line x" title="90:210	First, a corpus is created by removing useless parts such as html tags from the Web." ></td>
	<td class="line x" title="91:210	It is called Web corpus." ></td>
	<td class="line x" title="92:210	Note that the Web corpus consist of Web pages (hereafter page)." ></td>
	<td class="line x" title="93:210	Secondly, the pages are classified into three types (written language corpus, spoken language corpus, and ambiguous corpus) based on interpersonal expressions." ></td>
	<td class="line x" title="94:210	And then, only written and spoken language copora are used, and the ambiguous corpus is abandoned." ></td>
	<td class="line x" title="95:210	This is because: AF Texts in the same page tend to be described in the same style." ></td>
	<td class="line x" title="96:210	AF The boundary between written and spoken language is not clear even for humans, and it is almost impossible to precisely classify all pages into written language or spoken language." ></td>
	<td class="line x" title="97:210	written language corpus spoken language corpus The Web corpus   ambiguous corpus pages Figure 2: Collecting written and spoken language corpora 4.1 Interpersonal expressions Each page in the Web corpus is classified based on interpersonal expressions." ></td>
	<td class="line x" title="98:210	Spoken language is often used as a medium of information which is directed to a specific listener." ></td>
	<td class="line x" title="99:210	For example, face-to-face communication is one of the typical situations in which spoken language is used." ></td>
	<td class="line x" title="100:210	Due to this fact, spoken language tends to contain expressions which imply an certain attitude of a speaker toward listeners, such as familiarity, politeness, honor or contempt etc. Such an expression is called interpersonal expression." ></td>
	<td class="line x" title="101:210	On the other hand, written language is mostly directed to unspecific readers." ></td>
	<td class="line x" title="102:210	For example, written language is often used in news articles or books or papers etc. Therefore, interpersonal expressions are not used so frequently in written language as in spoken language." ></td>
	<td class="line x" title="103:210	Among interpersonal expressions, we utilized familiarity and politeness expressions." ></td>
	<td class="line x" title="104:210	The familiarity expression is one kind of interpersonal expressions, which implies the speakers familiarity toward the listener." ></td>
	<td class="line x" title="105:210	It is represented by a postpositional particle such as neoryo etc. The following is an example: (3) watashi-wa ureshikatta yo I was happy (familiarity) I was happy (3) implies familiarity using the postpositional particle yo." ></td>
	<td class="line x" title="106:210	The politeness expression is also one kind of interpersonal expressions, which implies politeness to the listener." ></td>
	<td class="line x" title="107:210	It is represented by a postpositional particle." ></td>
	<td class="line x" title="108:210	For example: (4) watashi-wa eiga-wo mi masu I a movie to watch (politeness) I watch a movie (4) implies politeness using the postpositional particle masu." ></td>
	<td class="line x" title="109:210	Those two interpersonal expressions often appear in spoken language, and are easily recognized as such by a morphological analyzer and simple rules." ></td>
	<td class="line x" title="110:210	Therefore, a page in the Web corpus can be classified into the three types based the following two ratios." ></td>
	<td class="line x" title="111:210	AF Familiarity ratio (F-ratio): # of sentences which include familiarity expressions # of all the sentences in the page AF Politeness ratio (P-ratio): # of sentences which include politeness expressions # of all the sentences in the page." ></td>
	<td class="line x" title="112:210	4.2 Algorithm After the Web corpus is processed by a Japanese morphological analyzer (JUMAN) 5, sentences which include familiarity or politeness expressions are recognized in the following manner in order to calculate F-ratio and P-ratio." ></td>
	<td class="line x" title="113:210	If a sentence has one of the following six postpositional particles, it is considered to include the familiarly expression." ></td>
	<td class="line x" title="114:210	ne, yo, wa, sa, ze, na A sentence is considered to include the politeness expression, if it has one of the following four postpositional particles." ></td>
	<td class="line x" title="115:210	desu, masu, kudasai, gozaimasu 5 http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman-e.html If F-ratio and P-ratio of a page are very low, the page is in written language, and vice versa." ></td>
	<td class="line x" title="116:210	We observed a part of the Web corpus, and empirically decided the rules illustrated in Table 1." ></td>
	<td class="line x" title="117:210	If F-ratio and P-ratio are equal to 0, the page is classified as written language." ></td>
	<td class="line x" title="118:210	If F-ratio is more than 0.2, or if F-ratio is more than 0.1 and P-ratio is more than 0.2, the page is classified as spoken language." ></td>
	<td class="line x" title="119:210	The other pages are regarded as ambiguous." ></td>
	<td class="line x" title="120:210	Table 1: Page classification rules F-ratio BPBC AX Written language P-ratio BPBC F-ratio BQ BCBMBE AX Spoken language or F-ratio BQ BCBMBD P-ratio BQ BCBMBE Otherwise AX Ambiguous 4.3 Evaluation The Web corpus we prepared consists of 660,062 pages and contains 733M words." ></td>
	<td class="line x" title="121:210	Table 2 shows the size of the written and spoken language corpora which were collected from the Web corpus." ></td>
	<td class="line x" title="122:210	Table 2: The size of the corpora # of pages # of words The Web corpus 660,062 733M Written language corpus 80,685 77M Spoken language corpus 73,977 113M Size comparison The reason why written and spoken language corpora were collected from the Web is that Japanese spoken language corpora available are too small." ></td>
	<td class="line x" title="123:210	As far as we know, the biggest Japanese one is Spontaneous Speech Corpus of Japanese, which contains 7M words (Maekawa et al. , 2000)." ></td>
	<td class="line x" title="124:210	Our corpus is about ten times as big as Spontaneous Speech Corpus of Japanese." ></td>
	<td class="line x" title="125:210	Precision of our method What is important for our method is not recall but precision." ></td>
	<td class="line x" title="126:210	Even if the recall is not high we can collect large corpora, because the Web corpus is very huge." ></td>
	<td class="line x" title="127:210	However, if the precision is low, it is impossible to collect corpora with high quality." ></td>
	<td class="line x" title="128:210	240 pages of the written and spoken language corpora were extracted at random, and the precision of our method was evaluated." ></td>
	<td class="line x" title="129:210	The 240 pages consist of 125 pages collected as written language corpus and 115 pages collected as spoken language corpus." ></td>
	<td class="line x" title="130:210	Two judges (hereafter judge 1 and 2) respectively assessed how many of the 240 pages were classified properly." ></td>
	<td class="line x" title="131:210	The result is shown in Table 3." ></td>
	<td class="line x" title="132:210	The judge 1 identified 228 pages as properly classified ones; the judge 2 identified 221 pages as properly classified ones." ></td>
	<td class="line x" title="133:210	The average precision of the total was 94% (=228+221/240+240) and we can say that our corpora have sufficient quality." ></td>
	<td class="line x" title="134:210	Table 3: # of pages properly collected Judge 1 Judge 2 Written language corpus 119/125 110/125 Spoken language corpus 109/115 111/115 Total 228/240 221/240 Discussion Pages which were inappropriately collected were examined, and it was found that lexical information is useful in order to properly classify them." ></td>
	<td class="line x" title="135:210	(5) is an example which means A new software is exciting." ></td>
	<td class="line x" title="136:210	(5) atarashii new sohuto-ha software wakuwakusuru exiting (5) is in spoken language, although it does not include any familiarity and politeness expressions." ></td>
	<td class="line x" title="137:210	This is because of the word wakuwakusuru, which is informal and means exiting." ></td>
	<td class="line x" title="138:210	On way to deal with such pages is to use words characteristic of written or spoken language." ></td>
	<td class="line x" title="139:210	Such words will be able to be gathered form our written and spoken language corpora." ></td>
	<td class="line x" title="140:210	It is our future work to improve the quality of our corpora in an iterative way." ></td>
	<td class="line x" title="141:210	5 Paraphrase Pair Selection A paraphrase pair we want is one in which the source is UES and the target is SES." ></td>
	<td class="line x" title="142:210	From the paraphrase pairs learned in Section 3, such paraphrase pairs are selected using the written and spoken language corpora." ></td>
	<td class="line x" title="143:210	Occurrence probabilities (OPs) of expressions in the written and spoken language corpora can be used to distinguish UES and SES." ></td>
	<td class="line x" title="144:210	This is because: AF An expression is likely to be UES if its OP in spoken language corpora is very low." ></td>
	<td class="line x" title="145:210	AF An expression is likely to be UES, if its OP in written language corpora is much higher than that in spoken language corpora." ></td>
	<td class="line x" title="146:210	For example, Table 4 shows OP of jikaisuru." ></td>
	<td class="line x" title="147:210	It is a difficult verb which means to admonish oneself, and rarely used in a conversation." ></td>
	<td class="line x" title="148:210	The verb jikaisuru appeared 14 times in the written language corpus, which contains 6.1M predicates, and 7 times in the spoken language corpus, which contains 11.7M predicates." ></td>
	<td class="line x" title="149:210	The OP of jikaisuru in spoken language corpus is low, compared Table 4: Occurrence probability of jikaisuru written language spoken language corpus corpus #ofjikaisuru 14 7 # of predicates 6.1M 11.7M OP of jikaisuru 14BP6.1M 7BP11.7M with that in written language corpus." ></td>
	<td class="line x" title="150:210	Therefore, we can say that jikaisuru is UES." ></td>
	<td class="line x" title="151:210	The paraphrase pair we want can be selected based on the following four OPs." ></td>
	<td class="line x" title="152:210	(1) OP of source in the written language corpus (2) OP of source in the spoken language corpus (3) OP of target in the written language corpus (4) OP of target in the spoken language corpus The selection can be considered as a binary classification task: paraphrase pairs in which source is UES and target is SES are treated as positive, and others are negative." ></td>
	<td class="line x" title="153:210	We propose a method based on Support Vector Machine (Vapnik, 1995)." ></td>
	<td class="line x" title="154:210	The four OPs above are used as features." ></td>
	<td class="line x" title="155:210	5.1 Feature calculation The method of calculating OP of an expression CT (BP C7C8B4CTB5) in a corpus is described." ></td>
	<td class="line x" title="156:210	According to the method, those four features can be calculated." ></td>
	<td class="line x" title="157:210	The method is broken down into two steps: counting the frequency of CT, and calculation of C7C8B4CTB5 using the frequency." ></td>
	<td class="line x" title="158:210	Frequency After a corpus is processed by the Japanese morphological analyzer (JUMAN) and the parser (KNP) 6, the frequency of e (BYB4CTB5) is counted." ></td>
	<td class="line x" title="159:210	Although the frequency is often obvious from the analysis result, there are several issues to be discussed." ></td>
	<td class="line x" title="160:210	The frequency of a predicate is sometimes quite different from that of the same predicate in the different voice." ></td>
	<td class="line x" title="161:210	Therefore, the same predicates which have different voice should be treated as different predicates." ></td>
	<td class="line x" title="162:210	As already mentioned in Section 3, the form of source is predicate and that of target is adjectiveA3 noun+ predicate." ></td>
	<td class="line x" title="163:210	If e is target and contains adverbs and nouns, it is difficult to count the frequency because of the sparse data problem." ></td>
	<td class="line x" title="164:210	In order to avoid the problem, an approximation that the adverbs are ignored is used." ></td>
	<td class="line x" title="165:210	For example, the frequency of run fast is approximated by that of run." ></td>
	<td class="line x" title="166:210	We did not ignore the noun because of the following reason." ></td>
	<td class="line x" title="167:210	As a noun and a predicate forms an idiomatic phrase more often than an adverb and a predicate, the meaning of such idiomatic phrase completely changes without the noun." ></td>
	<td class="line x" title="168:210	6 http://www.kc.t.u-tokyo.ac.jp/nl-resource/knp-e.html If the form of target is adverbA3 noun predicate, the frequency is approximated by that of noun predicate, which is counted based on the parse result." ></td>
	<td class="line x" title="169:210	However, generally speaking, the accuracy of Japanese parser is low compared with that of Japanese morphological analyzer; the former is about 90% while the latter about 99%." ></td>
	<td class="line x" title="170:210	Therefore, only reliable part of the parse result is used in the same way as Kawahara et al. did." ></td>
	<td class="line x" title="171:210	See (Kawahara and Kurohashi, 2001) for the details." ></td>
	<td class="line x" title="172:210	Kawahara et al. reported that 97% accuracy is achieved in the reliable part." ></td>
	<td class="line x" title="173:210	Occurrence probability In general, C7C8B4CTB5 is defined as: C7C8B4CTB5BPBYB4CTB5BP # of expressions in a corpus." ></td>
	<td class="line x" title="174:210	BYB4CTB5 tends to be small when CT contains a noun, because only a reliable part of the parsed corpus is used to count BYB4CTB5." ></td>
	<td class="line x" title="175:210	Therefore, the value of the denominator # of expressions in a corpus should be changed depending on whether CT contains a noun or not." ></td>
	<td class="line x" title="176:210	The occurrence probability is defined as follows: if CT does not contain any nouns C7C8B4CTB5BPBYB4CTB5BP # of predicates in a corpus." ></td>
	<td class="line x" title="177:210	otherwise C7C8B4CTB5BPBYB4CTB5BP # of noun-predicates in a corpus." ></td>
	<td class="line x" title="178:210	Table 5 illustrates # of predicates and # of nounpredicates in our corpora." ></td>
	<td class="line x" title="179:210	Table 5: # of predicates, and # of noun-predicates # of predicates # of noun-predicates written language corpus 6.1M 1.5M spoken language corpus 11.7M 1.9M 5.2 Evaluation The two judges built a data set, and 20-hold cross validation was used." ></td>
	<td class="line x" title="180:210	Data set 267 paraphrase pairs were extracted at random form the 5,836 paraphrase pairs learned in section 3." ></td>
	<td class="line x" title="181:210	Two judges independently tagged each of the 267 paraphrase pairs as positive or negative." ></td>
	<td class="line x" title="182:210	Then, only such paraphrase pairs that were agreed upon by both of them were used as data set." ></td>
	<td class="line x" title="183:210	The data set consists of 200 paraphrase pairs (70 positive pairs and 130 negative pairs)." ></td>
	<td class="line x" title="184:210	Experimental result We implemented the system using Tiny SVM package 7 .The Kernel function explored was the polynomial function of degree 2." ></td>
	<td class="line x" title="185:210	Using 20-hold cross validation, two types of feature sets (F-set1 and F-set2) were evaluated." ></td>
	<td class="line x" title="186:210	F-set1 is a feature set of all the four features, and F-set2 is that of only two features: OP of source in the spoken language corpus, and OP of target in the spoken language corpus." ></td>
	<td class="line x" title="187:210	The results were evaluated through three measures: accuracy of the classification (positive or negative), precision of positive paraphrase pairs, and recall of positive paraphrase pairs." ></td>
	<td class="line x" title="188:210	Table 6 shows the result." ></td>
	<td class="line x" title="189:210	The accuracy, precision and recall of F-set1 were 76 %, 70 % and 73 % respectively." ></td>
	<td class="line x" title="190:210	Those of F-set2 were 75 %, 67 %, and 69 %." ></td>
	<td class="line x" title="191:210	Table 6: Accuracy, precision and recall F-set1 F-set2 Accuracy 76% 75% Precision 70% 67% Recall 73% 69% Table 7 shows examples of classification." ></td>
	<td class="line x" title="192:210	The paraphrase pair (1) is positive example and the paraphrase pair (2) is negative, and both of them were successfully classified." ></td>
	<td class="line x" title="193:210	The source of (1) appears only 10 times in the spoken language corpus, on the other hand, the source of (2) does 67 times." ></td>
	<td class="line x" title="194:210	Discussion It is challenging to detect the connotational difference between lexical paraphrases, and all the features were not explicitly given but estimated using the corpora which were prepared in the unsupervised manner." ></td>
	<td class="line x" title="195:210	Therefore, we think that the accuracy of 76 % is very high." ></td>
	<td class="line x" title="196:210	The result of F-set1 exceeds that of F-set2." ></td>
	<td class="line x" title="197:210	This indicates that comparing C7C8B4CTB5 in the written and spoken language corpus is effective." ></td>
	<td class="line x" title="198:210	Calculated C7C8B4CTB5 was occasionally quite far from our intuition." ></td>
	<td class="line x" title="199:210	One example is that of kangekisuru, which is a very difficult verb that means to watch a drama." ></td>
	<td class="line x" title="200:210	Although the verb is rarely used in real spoken language, its occurrence probability in the spoken language corpus was very high: the verb appeared 9 times in the written language corpus and 69 times in the spoken language corpus." ></td>
	<td class="line x" title="201:210	We examined those corpora, and found that the spoken language corpus happens to contain a lot of texts about dramas." ></td>
	<td class="line x" title="202:210	Such problems caused by biased topics will be resolved by collecting corpora form larger Web corpus." ></td>
	<td class="line x" title="203:210	7 http://cl.aist-nara.ac.jp/taku-ku/software/TinySVM/ Table 7: Successfully classified paraphrase pairs Occurrence probabilities Paraphrase pair source target written language spoken language written language spoken language (1) denraisuru AX tsutawaru 43/6.1M 10/11.7M 1,927/6.1M 4,213/11.7M to descend to be transmitted (2) hebaru AX hetohetoni tsukareru 18/6.1M 67/11.7M 1,026/6.1M 7,829/11.7M to be tired out to be exhausted 6 Future Work In order to estimate more reliable features, we are going to increase the size of our corpora by preparing larger Web corpus." ></td>
	<td class="line x" title="204:210	Although the paper has discussed paraphrasing from the point of view that an expression is UES or SES, there are a variety of SESs such as slang or male/female speech etc. One of our future work is to examine what kind of spoken language is suitable for such a kind of application that was illustrated in the introduction." ></td>
	<td class="line x" title="205:210	This paper has focused only on paraphrasing predicates." ></td>
	<td class="line x" title="206:210	However, there are other kinds of paraphrasing which are necessary in order to paraphrase written language text into spoken language." ></td>
	<td class="line x" title="207:210	For example, paraphrasing compound nouns or complex syntactic structure is the task to be tackled." ></td>
	<td class="line x" title="208:210	7 Conclusion This paper represented the method of learning paraphrase pairs in which source is UES and target is SES." ></td>
	<td class="line x" title="209:210	The key notion of the method is to identify UES and SES based on the occurrence probability in the written and spoken language corpora which are automatically collected from the Web." ></td>
	<td class="line x" title="210:210	The experimental result indicated that reliable corpora can be collected sufficiently, and the occurrence probability calculated from the corpora is useful to identify UES and SES." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P04-1077
Automatic Evaluation Of Machine Translation Quality Using Longest Common Subsequence And Skip-Bigram Statistics
Lin, Chin Yew;Och, Franz Josef;"></td>
	<td class="line x" title="1:211	Automatic Evaluation of Machine Translation Quality Using Longest Common Subsequence and Skip-Bigram Statistics Chin-Yew Lin and Franz Josef Och Information Sciences Institute University of Southern California 4676 Admiralty Way Marina del Rey, CA 90292, USA {cyl,och}@isi.edu Abstract In this paper we describe two new objective automatic evaluation methods for machine translation." ></td>
	<td class="line x" title="2:211	The first method is based on longest common subsequence between a candidate translation and a set of reference translations." ></td>
	<td class="line x" title="3:211	Longest common subsequence takes into account sentence level structure similarity naturally and identifies longest co-occurring insequence n-grams automatically." ></td>
	<td class="line x" title="4:211	The second method relaxes strict n-gram matching to skipbigram matching." ></td>
	<td class="line x" title="5:211	Skip-bigram is any pair of words in their sentence order." ></td>
	<td class="line x" title="6:211	Skip-bigram cooccurrence statistics measure the overlap of skip-bigrams between a candidate translation and a set of reference translations." ></td>
	<td class="line x" title="7:211	The empirical results show that both methods correlate with human judgments very well in both adequacy and fluency." ></td>
	<td class="line x" title="8:211	1 Introduction Using objective functions to automatically evaluate machine translation quality is not new." ></td>
	<td class="line x" title="9:211	Su et al.(1992) proposed a method based on measuring edit distance (Levenshtein 1966) between candidate and reference translations." ></td>
	<td class="line x" title="11:211	Akiba et al.(2001) extended the idea to accommodate multiple references." ></td>
	<td class="line x" title="13:211	Nieen et al.(2000) calculated the lengthnormalized edit distance, called word error rate (WER), between a candidate and multiple reference translations." ></td>
	<td class="line x" title="15:211	Leusch et al.(2003) proposed a related measure called position-independent word error rate (PER) that did not consider word position, i.e. using bag-of-words instead." ></td>
	<td class="line x" title="17:211	Instead of error measures, we can also use accuracy measures that compute similarity between candidate and reference translations in proportion to the number of common words between them as suggested by Melamed (1995)." ></td>
	<td class="line x" title="18:211	An n-gram co-occurrence measure, BLEU, proposed by Papineni et al.(2001) that calculates co-occurrence statistics based on n-gram overlaps have shown great potential." ></td>
	<td class="line x" title="20:211	A variant of BLEU developed by NIST (2002) has been used in two recent large-scale machine translation evaluations." ></td>
	<td class="line x" title="21:211	Recently, Turian et al.(2003) indicated that standard accuracy measures such as recall, precision, and the F-measure can also be used in evaluation of machine translation." ></td>
	<td class="line x" title="23:211	However, results based on their method, General Text Matcher (GTM), showed that unigram F-measure correlated best with human judgments while assigning more weight to higher n-gram (n > 1) matches achieved similar performance as Bleu." ></td>
	<td class="line x" title="24:211	Since unigram matches do not distinguish words in consecutive positions from words in the wrong order, measures based on position-independent unigram matches are not sensitive to word order and sentence level structure." ></td>
	<td class="line x" title="25:211	Therefore, systems optimized for these unigram-based measures might generate adequate but not fluent target language." ></td>
	<td class="line x" title="26:211	Since BLEU has been used to report the performance of many machine translation systems and it has been shown to correlate well with human judgments, we will explain BLEU in more detail and point out its limitations in the next section." ></td>
	<td class="line x" title="27:211	We then introduce a new evaluation method called ROUGE-L that measures sentence-to-sentence similarity based on the longest common subsequence statistics between a candidate translation and a set of reference translations in Section 3." ></td>
	<td class="line x" title="28:211	Section 4 describes another automatic evaluation method called ROUGE-S that computes skipbigram co-occurrence statistics." ></td>
	<td class="line x" title="29:211	Section 5 presents the evaluation results of ROUGE-L, and ROUGES and compare them with BLEU, GTM, NIST, PER, and WER in correlation with human judgments in terms of adequacy and fluency." ></td>
	<td class="line x" title="30:211	We conclude this paper and discuss extensions of the current work in Section 6." ></td>
	<td class="line x" title="31:211	2 BLEU and N-gram Co-Occurrence To automatically evaluate machine translations the machine translation community recently adopted an n-gram co-occurrence scoring procedure BLEU (Papineni et al. 2001)." ></td>
	<td class="line x" title="32:211	In two recent large-scale machine translation evaluations sponsored by NIST, a closely related automatic evaluation method, simply called NIST score, was used." ></td>
	<td class="line x" title="33:211	The NIST (NIST 2002) scoring method is based on BLEU." ></td>
	<td class="line x" title="34:211	The main idea of BLEU is to measure the similarity between a candidate translation and a set of reference translations with a numerical metric." ></td>
	<td class="line x" title="35:211	They used a weighted average of variable length ngram matches between system translations and a set of human reference translations and showed that the weighted average metric correlating highly with human assessments." ></td>
	<td class="line x" title="36:211	BLEU measures how well a machine translation overlaps with multiple human translations using ngram co-occurrence statistics." ></td>
	<td class="line x" title="37:211	N-gram precision in BLEU is computed as follows:       = }{ }{ )( )( CandidatesCCgramn CandidatesCCgramn clip n gramnCount gramnCount p (1) Where Count clip (n-gram) is the maximum number of n-grams co-occurring in a candidate translation and a reference translation, and Count(ngram) is the number of n-grams in the candidate translation." ></td>
	<td class="line x" title="38:211	To prevent very short translations that try to maximize their precision scores, BLEU adds a brevity penalty, BP, to the formula: )2( 1 |)|/||1(        > =  rcife rcif BP cr Where |c| is the length of the candidate translation and |r| is the length of the reference translation." ></td>
	<td class="line x" title="39:211	The BLEU formula is then written as follows: )3(logexp 1       =  = N n nn pwBPBLEU The weighting factor, w n, is set at 1/N. Although BLEU has been shown to correlate well with human assessments, it has a few things that can be improved." ></td>
	<td class="line x" title="40:211	First the subjective application of the brevity penalty can be replaced with a recall related parameter that is sensitive to reference length." ></td>
	<td class="line x" title="41:211	Although brevity penalty will penalize candidate translations with low recall by a factor of e (1|r|/|c|), it would be nice if we can use the traditional recall measure that has been a well known measure in NLP as suggested by Melamed (2003)." ></td>
	<td class="line x" title="42:211	Of course we have to make sure the resulting composite function of precision and recall is still correlates highly with human judgments." ></td>
	<td class="line x" title="43:211	Second, although BLEU uses high order n-gram (n>1) matches to favor candidate sentences with consecutive word matches and to estimate their fluency, it does not consider sentence level structure." ></td>
	<td class="line x" title="44:211	For example, given the following sentences: S1." ></td>
	<td class="line x" title="45:211	police killed the gunman S2." ></td>
	<td class="line x" title="46:211	police kill the gunman 1 S3." ></td>
	<td class="line x" title="47:211	the gunman kill police We only consider BLEU with unigram and bigram, i.e. N=2, for the purpose of explanation and call this BLEU-2." ></td>
	<td class="line x" title="48:211	Using S1 as the reference and S2 and S3 as the candidate translations, S2 and S3 would have the same BLEU-2 score, since they both have one bigram and three unigram matches 2." ></td>
	<td class="line x" title="49:211	However, S2 and S3 have very different meanings." ></td>
	<td class="line x" title="50:211	Third, BLEU is a geometric mean of unigram to N-gram precisions." ></td>
	<td class="line x" title="51:211	Any candidate translation without a N-gram match has a per-sentence BLEU score of zero." ></td>
	<td class="line x" title="52:211	Although BLEU is usually calculated over the whole test corpus, it is still desirable to have a measure that works reliably at sentence level for diagnostic and introspection purpose." ></td>
	<td class="line x" title="53:211	To address these issues, we propose three new automatic evaluation measures based on longest common subsequence statistics and skip bigram co-occurrence statistics in the following sections." ></td>
	<td class="line x" title="54:211	3 Longest Common Subsequence 3.1 ROUGE-L A sequence Z = [z 1, z 2,  , z n ] is a subsequence of another sequence X = [x 1, x 2,  , x m ], if there exists a strict increasing sequence [i 1, i 2,  , i k ] of indices of X such that for all j = 1, 2,  , k, we have x ij = z j (Cormen et al. 1989)." ></td>
	<td class="line x" title="55:211	Given two sequences X and Y, the longest common subsequence (LCS) of X and Y is a common subsequence with maximum length." ></td>
	<td class="line x" title="56:211	We can find the LCS of two sequences of length m and n using standard dynamic programming technique in O(mn) time." ></td>
	<td class="line x" title="57:211	LCS has been used to identify cognate candidates during construction of N-best translation lexicons from parallel text." ></td>
	<td class="line x" title="58:211	Melamed (1995) used the ratio (LCSR) between the length of the LCS of two words and the length of the longer word of the two words to measure the cognateness between them." ></td>
	<td class="line x" title="59:211	He used as an approximate string matching algorithm." ></td>
	<td class="line x" title="60:211	Saggion et al.(2002) used normalized pairwise LCS (NP-LCS) to compare similarity between two texts in automatic summarization evaluation." ></td>
	<td class="line x" title="62:211	NP-LCS can be shown as a special case of Equation (6) with  = 1." ></td>
	<td class="line x" title="63:211	However, they did not provide the correlation analysis of NP-LCS with 1 This is a real machine translation output." ></td>
	<td class="line x" title="64:211	2 The kill in S2 or S3 does not match with killed in S1 in strict word-to-word comparison." ></td>
	<td class="line x" title="65:211	human judgments and its effectiveness as an automatic evaluation measure." ></td>
	<td class="line x" title="66:211	To apply LCS in machine translation evaluation, we view a translation as a sequence of words." ></td>
	<td class="line x" title="67:211	The intuition is that the longer the LCS of two translations is, the more similar the two translations are." ></td>
	<td class="line x" title="68:211	We propose using LCS-based F-measure to estimate the similarity between two translations X of length m and Y of length n, assuming X is a reference translation and Y is a candidate translation, as follows: R lcs m YXLCS ),( = (4) P lcs n YXLCS ),( = (5) F lcs lcslcs lcslcs PR PR 2 2 )1(   + + = (6) Where LCS(X,Y) is the length of a longest common subsequence of X and Y, and  = P lcs /R lcs when F lcs /R lcs _=_F lcs /P lcs . We call the LCS-based Fmeasure, i.e. Equation 6, ROUGE-L." ></td>
	<td class="line x" title="69:211	Notice that ROUGE-L is 1 when X = Y since LCS(X,Y) = m or n; while ROUGE-L is zero when LCS(X,Y) = 0, i.e. there is nothing in common between X and Y. Fmeasure or its equivalents has been shown to have met several theoretical criteria in measuring accuracy involving more than one factor (Van Rijsbergen 1979)." ></td>
	<td class="line x" title="70:211	The composite factors are LCS-based recall and precision in this case." ></td>
	<td class="line x" title="71:211	Melamed et al.(2003) used unigram F-measure to estimate machine translation quality and showed that unigram F-measure was as good as BLEU." ></td>
	<td class="line x" title="73:211	One advantage of using LCS is that it does not require consecutive matches but in-sequence matches that reflect sentence level word order as ngrams." ></td>
	<td class="line x" title="74:211	The other advantage is that it automatically includes longest in-sequence common n-grams, therefore no predefined n-gram length is necessary." ></td>
	<td class="line x" title="75:211	ROUGE-L as defined in Equation 6 has the property that its value is less than or equal to the minimum of unigram F-measure of X and Y. Unigram recall reflects the proportion of words in X (reference translation) that are also present in Y (candidate translation); while unigram precision is the proportion of words in Y that are also in X. Unigram recall and precision count all co-occurring words regardless their orders; while ROUGE-L counts only in-sequence co-occurrences." ></td>
	<td class="line x" title="76:211	By only awarding credit to in-sequence unigram matches, ROUGE-L also captures sentence level structure in a natural way." ></td>
	<td class="line x" title="77:211	Consider again the example given in Section 2 that is copied here for convenience: S1." ></td>
	<td class="line x" title="78:211	police killed the gunman S2." ></td>
	<td class="line x" title="79:211	police kill the gunman S3." ></td>
	<td class="line x" title="80:211	the gunman kill police As we have shown earlier, BLEU-2 cannot differentiate S2 from S3." ></td>
	<td class="line x" title="81:211	However, S2 has a ROUGE-L score of 3/4 = 0.75 and S3 has a ROUGE-L score of 2/4 = 0.5, with  = 1." ></td>
	<td class="line x" title="82:211	Therefore S2 is better than S3 according to ROUGE-L." ></td>
	<td class="line x" title="83:211	This example also illustrated that ROUGE-L can work reliably at sentence level." ></td>
	<td class="line x" title="84:211	However, LCS only counts the main in-sequence words; therefore, other longest common subsequences and shorter sequences are not reflected in the final score." ></td>
	<td class="line x" title="85:211	For example, consider the following candidate sentence: S4." ></td>
	<td class="line x" title="86:211	the gunman police killed Using S1 as its reference, LCS counts either the gunman or police killed, but not both; therefore, S4 has the same ROUGE-L score as S3." ></td>
	<td class="line x" title="87:211	BLEU-2 would prefer S4 over S3." ></td>
	<td class="line x" title="88:211	In Section 4, we will introduce skip-bigram co-occurrence statistics that do not have this problem while still keeping the advantage of in-sequence (not necessary consecutive) matching that reflects sentence level word order." ></td>
	<td class="line x" title="89:211	3.2 Multiple References So far, we only demonstrated how to compute ROUGE-L using a single reference." ></td>
	<td class="line x" title="90:211	When multiple references are used, we take the maximum LCS matches between a candidate translation, c, of n words and a set of u reference translations of m j words." ></td>
	<td class="line x" title="91:211	The LCS-based F-measure can be computed as follows: R lcs-multi         = = j ju j m crLCS ),( max 1 (7) P lcs-multi         = = n crLCS ju j ),( max 1 (8) F lcs-multi multilcsmultilcs multilcsmultilcs PR PR   + + = 2 2 )1(   (9) where  = P lcs-multi /R lcs-multi when F lcs-multi /R lcsmulti _=_F lcs-multi /P lcs-multi." ></td>
	<td class="line x" title="92:211	This procedure is also applied to computation of ROUGE-S when multiple references are used." ></td>
	<td class="line x" title="93:211	In the next section, we introduce the skip-bigram cooccurrence statistics." ></td>
	<td class="line x" title="94:211	In the next section, we describe how to extend ROUGE-L to assign more credits to longest common subsequences with consecutive words." ></td>
	<td class="line x" title="95:211	3.3 ROUGE-W: Weighted Longest Common Subsequence LCS has many nice properties as we have described in the previous sections." ></td>
	<td class="line x" title="96:211	Unfortunately, the basic LCS also has a problem that it does not differentiate LCSes of different spatial relations within their embedding sequences." ></td>
	<td class="line x" title="97:211	For example, given a reference sequence X and two candidate sequences Y 1 and Y 2 as follows: X: [A B C D E F G] Y 1 : [A B C D H I K] Y 2 : [A H B K C I D] Y 1 and Y 2 have the same ROUGE-L score." ></td>
	<td class="line x" title="98:211	However, in this case, Y 1 should be the better choice than Y 2 because Y 1 has consecutive matches." ></td>
	<td class="line x" title="99:211	To improve the basic LCS method, we can simply remember the length of consecutive matches encountered so far to a regular two dimensional dynamic program table computing LCS." ></td>
	<td class="line x" title="100:211	We call this weighted LCS (WLCS) and use k to indicate the length of the current consecutive matches ending at words x i and y j . Given two sentences X and Y, the WLCS score of X and Y can be computed using the following dynamic programming procedure: (1) For (i = 0; i <=m; i++) c(i,j) = 0 // initialize c-table w(i,j) = 0 // initialize w-table (2) For (i = 1; i <= m; i++) For (j = 1; j <= n; j++) If x i = y j Then // the length of consecutive matches at // position i-1 and j-1 k = w(i-1,j-1) c(i,j) = c(i-1,j-1) + f(k+1)  f(k) // remember the length of consecutive // matches at position i, j w(i,j) = k+1 Otherwise If c(i-1,j) > c(i,j-1) Then c(i,j) = c(i-1,j) w(i,j) = 0 // no match at i, j Else c(i,j) = c(i,j-1) w(i,j) = 0 // no match at i, j (3) WLCS(X,Y) = c(m,n) Where c is the dynamic programming table, c(i,j) stores the WLCS score ending at word x i of X and y j of Y, w is the table storing the length of consecutive matches ended at c table position i and j, and f is a function of consecutive matches at the table position, c(i,j)." ></td>
	<td class="line x" title="101:211	Notice that by providing different weighting function f, we can parameterize the WLCS algorithm to assign different credit to consecutive in-sequence matches." ></td>
	<td class="line x" title="102:211	The weighting function f must have the property that f(x+y) > f(x) + f(y) for any positive integers x and y. In other words, consecutive matches are awarded more scores than non-consecutive matches." ></td>
	<td class="line x" title="103:211	For example, f(k)-=-k   when k >= 0, and ,  > 0." ></td>
	<td class="line x" title="104:211	This function charges a gap penalty of  for each non-consecutive n-gram sequences." ></td>
	<td class="line x" title="105:211	Another possible function family is the polynomial family of the form k  where - > 1." ></td>
	<td class="line x" title="106:211	However, in order to normalize the final ROUGE-W score, we also prefer to have a function that has a close form inverse function." ></td>
	<td class="line x" title="107:211	For example, f(k)-=-k 2 has a close form inverse function f -1 (k)-=-k 1/2 . F-measure based on WLCS can be computed as follows, given two sequences X of length m and Y of length n: R wlcs         =  )( ),( 1 mf YXWLCS f (10) P wlcs         =  )( ),( 1 nf YXWLCS f (11) F wlcs wlcswlcs wlcswlcs PR PR 2 2 )1(   + + = (12) Where f -1 is the inverse function of f. We call the WLCS-based F-measure, i.e. Equation 12, ROUGE-W." ></td>
	<td class="line x" title="108:211	Using Equation 12 and f(k)-=-k 2 as the weighting function, the ROUGE-W scores for sequences Y 1 and Y 2 are 0.571 and 0.286 respectively." ></td>
	<td class="line x" title="109:211	Therefore, Y 1 would be ranked higher than Y 2 using WLCS." ></td>
	<td class="line x" title="110:211	We use the polynomial function of the form k  in the ROUGE evaluation package." ></td>
	<td class="line x" title="111:211	In the next section, we introduce the skip-bigram cooccurrence statistics." ></td>
	<td class="line x" title="112:211	4 ROUGE-S: Skip-Bigram Co-Occurrence Statistics Skip-bigram is any pair of words in their sentence order, allowing for arbitrary gaps." ></td>
	<td class="line x" title="113:211	Skipbigram co-occurrence statistics measure the overlap of skip-bigrams between a candidate translation and a set of reference translations." ></td>
	<td class="line x" title="114:211	Using the example given in Section 3.1: S1." ></td>
	<td class="line x" title="115:211	police killed the gunman S2." ></td>
	<td class="line x" title="116:211	police kill the gunman S3." ></td>
	<td class="line x" title="117:211	the gunman kill police S4." ></td>
	<td class="line x" title="118:211	the gunman police killed Each sentence has C(4,2) 3 = 6 skip-bigrams." ></td>
	<td class="line x" title="119:211	For example, S1 has the following skip-bigrams: 3 Combination: C(4,2) = 4!/(2!*2)!" ></td>
	<td class="line x" title="120:211	= 6." ></td>
	<td class="line x" title="121:211	(police killed, police the, police gunman, killed the, killed gunman, the gunman) S2 has three skip-bigram matches with S1 (police the, police gunman, the gunman), S3 has one skip-bigram match with S1 (the gunman), and S4 has two skip-bigram matches with S1 (police killed, the gunman)." ></td>
	<td class="line x" title="122:211	Given translations X of length m and Y of length n, assuming X is a reference translation and Y is a candidate translation, we compute skip-bigram-based F-measure as follows: R skip2 )2,( ),(2 mC YXSKIP = (13) P skip2 )2,( ),(2 nC YXSKIP = (14) F skip2 2 2 2 22 2 )1( skipskip skipskip PR PR   + + = (15) Where SKIP2(X,Y) is the number of skip-bigram matches between X and Y,  = P skip2 /R skip2 when F skip2 /R skip2 _=_F skip2 /P skip2, and C is the combination function." ></td>
	<td class="line x" title="123:211	We call the skip-bigram-based Fmeasure, i.e. Equation 15, ROUGE-S." ></td>
	<td class="line x" title="124:211	Using Equation 15 with  = 1 and S1 as the reference, S2s ROUGE-S score is 0.5, S3 is 0.167, and S4 is 0.333." ></td>
	<td class="line x" title="125:211	Therefore, S2 is better than S3 and S4, and S4 is better than S3." ></td>
	<td class="line x" title="126:211	This result is more intuitive than using BLEU-2 and ROUGE-L." ></td>
	<td class="line x" title="127:211	One advantage of skip-bigram vs. BLEU is that it does not require consecutive matches but is still sensitive to word order." ></td>
	<td class="line x" title="128:211	Comparing skip-bigram with LCS, skip-bigram counts all in-order matching word pairs while LCS only counts one longest common subsequence." ></td>
	<td class="line x" title="129:211	We can limit the maximum skip distance, d skip, between two in-order words that is allowed to form a skip-bigram." ></td>
	<td class="line x" title="130:211	Applying such constraint, we limit skip-bigram formation to a fix window size." ></td>
	<td class="line x" title="131:211	Therefore, computation time can be reduced and hopefully performance can be as good as the version without such constraint." ></td>
	<td class="line x" title="132:211	For example, if we set d skip to 0 then ROUGE-S is equivalent to bigram overlap." ></td>
	<td class="line x" title="133:211	If we set d skip to 4 then only word pairs of at most 4 words apart can form skip-bigrams." ></td>
	<td class="line x" title="134:211	Adjusting Equations 13, 14, and 15 to use maximum skip distance limit is straightforward: we only count the skip-bigram matches, SKIP2(X,Y), within the maximum skip distance and replace denominators of Equations 13, C(m,2), and 14, C(n,2), with the actual numbers of within distance skip-bigrams from the reference and the candidate respectively." ></td>
	<td class="line x" title="135:211	In the next section, we present the evaluations of ROUGE-L, ROUGE-S, and compare their performance with other automatic evaluation measures." ></td>
	<td class="line x" title="136:211	5 Evaluations One of the goals of developing automatic evaluation measures is to replace labor-intensive human evaluations." ></td>
	<td class="line x" title="137:211	Therefore the first criterion to assess the usefulness of an automatic evaluation measure is to show that it correlates highly with human judgments in different evaluation settings." ></td>
	<td class="line x" title="138:211	However, high quality large-scale human judgments are hard to come by." ></td>
	<td class="line x" title="139:211	Fortunately, we have access to eight MT systems outputs, their human assessment data, and the reference translations from 2003 NIST Chinese MT evaluation (NIST 2002a)." ></td>
	<td class="line x" title="140:211	There were 919 sentence segments in the corpus." ></td>
	<td class="line x" title="141:211	We first computed averages of the adequacy and fluency scores of each system assigned by human evaluators." ></td>
	<td class="line x" title="142:211	For the input of automatic evaluation methods, we created three evaluation sets from the MT outputs: 1." ></td>
	<td class="line x" title="143:211	Case set: The original system outputs with case information." ></td>
	<td class="line x" title="144:211	2." ></td>
	<td class="line x" title="145:211	NoCase set: All words were converted into lower case, i.e. no case information was used." ></td>
	<td class="line x" title="146:211	This set was used to examine whether human assessments were affected by case information since not all MT systems generate properly cased output." ></td>
	<td class="line x" title="147:211	3." ></td>
	<td class="line x" title="148:211	Stem set: All words were converted into lower case and stemmed using the Porter stemmer (Porter 1980)." ></td>
	<td class="line x" title="149:211	Since ROUGE computed similarity on surface word level, stemmed version allowed ROUGE to perform more lenient matches." ></td>
	<td class="line x" title="150:211	To accommodate multiple references, we use a Jackknifing procedure." ></td>
	<td class="line x" title="151:211	Given N references, we compute the best score over N sets of N-1 references." ></td>
	<td class="line x" title="152:211	The final score is the average of the N best scores using N different sets of N-1 references." ></td>
	<td class="line x" title="153:211	The Jackknifing procedure is adopted since we often need to compare system and human performance and the reference translations are usually the only human translations available." ></td>
	<td class="line x" title="154:211	Using this procedure, we are able to estimate average human performance by averaging N best scores of one reference vs. the rest N-1 references." ></td>
	<td class="line x" title="155:211	We then computed average BLEU1-12 4, GTM with exponents of 1.0, 2.0, and 3.0, NIST, WER, and PER scores over these three sets." ></td>
	<td class="line x" title="156:211	Finally we applied ROUGE-L, ROUGE-W with weighting function k 1.2, and ROUGE-S without skip distance 4 BLEUN computes BLEU over n-grams up to length N. Only BLEU1, BLEU4, and BLEU12 are shown in Table 1." ></td>
	<td class="line x" title="157:211	limit and with skip distant limits of 0, 4, and 9." ></td>
	<td class="line x" title="158:211	Correlation analysis based on two different correlation statistics, Pearsons  and Spearmans , with respect to adequacy and fluency are shown in Table 1." ></td>
	<td class="line x" title="159:211	The Pearsons correlation coefficient 5 measures the strength and direction of a linear relationship between any two variables, i.e. automatic metric score and human assigned mean coverage score in our case." ></td>
	<td class="line x" title="160:211	It ranges from +1 to -1." ></td>
	<td class="line x" title="161:211	A correlation of 1 means that there is a perfect positive linear relationship between the two variables, a correlation of -1 means that there is a perfect negative linear relationship between them, and a correlation of 0 means that there is no linear relationship between them." ></td>
	<td class="line x" title="162:211	Since we would like to use automatic evaluation metric not only in comparing systems 5 For a quick overview of the Pearsons coefficient, see: http://davidmlane.com/hyperstat/A34739.html." ></td>
	<td class="line x" title="163:211	but also in in-house system development, a good linear correlation with human judgment would enable us to use automatic scores to predict corresponding human judgment scores." ></td>
	<td class="line x" title="164:211	Therefore, Pearsons correlation coefficient is a good measure to look at." ></td>
	<td class="line x" title="165:211	Spearmans correlation coefficient 6 is also a measure of correlation between two variables." ></td>
	<td class="line x" title="166:211	It is a non-parametric measure and is a special case of the Pearsons correlation coefficient when the values of data are converted into ranks before computing the coefficient." ></td>
	<td class="line x" title="167:211	Spearmans correlation coefficient does not assume the correlation between the variables is linear." ></td>
	<td class="line x" title="168:211	Therefore it is a useful correlation indicator even when good linear correlation, for example, according to Pearsons correlation coefficient between two variables could 6 For a quick overview of the Spearmans coefficient, see: http://davidmlane.com/hyperstat/A62436.html." ></td>
	<td class="line x" title="169:211	Adequacy Method P 95%L 95%U S 95%L 95%U P 95%L 95%U S 95%L 95%U P 95%L 95%U S 95%L 95%U BLEU1 0.86 0.83 0.89 0.80 0.71 0.90 0.87 0.84 0.90 0.76 0.67 0.89 0.91 0.89 0.93 0.85 0.76 0.95 BLEU4 0.77 0.72 0.81 0.77 0.71 0.89 0.79 0.75 0.82 0.67 0.55 0.83 0.82 0.78 0.85 0.76 0.67 0.89 BLEU12 0.66 0.60 0.72 0.53 0.44 0.65 0.72 0.57 0.81 0.65 0.25 0.88 0.72 0.58 0.81 0.66 0.28 0.88 NIST 0.89 0.86 0.92 0.78 0.71 0.89 0.87 0.85 0.90 0.80 0.74 0.92 0.90 0.88 0.93 0.88 0.83 0.97 WER 0.47 0.41 0.53 0.56 0.45 0.74 0.43 0.37 0.49 0.66 0.60 0.82 0.48 0.42 0.54 0.66 0.60 0.81 PER 0.67 0.62 0.72 0.56 0.48 0.75 0.63 0.58 0.68 0.67 0.60 0.83 0.72 0.68 0.76 0.69 0.62 0.86 ROUGE-L 0.87 0.84 0.90 0.84 0.79 0.93 0.89 0.86 0.92 0.84 0.71 0.94 0.92 0.90 0.94 0.87 0.76 0.95 ROUGE-W 0.84 0.81 0.87 0.83 0.74 0.90 0.85 0.82 0.88 0.77 0.67 0.90 0.89 0.86 0.91 0.86 0.76 0.95 ROUGE-S* 0.85 0.81 0.88 0.83 0.76 0.90 0.90 0.88 0.93 0.82 0.70 0.92 0.95 0.93 0.97 0.85 0.76 0.94 ROUGE-S0 0.82 0.78 0.85 0.82 0.71 0.90 0.84 0.81 0.87 0.76 0.67 0.90 0.87 0.84 0.90 0.82 0.68 0.90 ROUGE-S4 0.82 0.78 0.85 0.84 0.79 0.93 0.87 0.85 0.90 0.83 0.71 0.90 0.92 0.90 0.94 0.84 0.74 0.93 ROUGE-S9 0.84 0.80 0.87 0.84 0.79 0.92 0.89 0.86 0.92 0.84 0.76 0.93 0.94 0.92 0.96 0.84 0.76 0.94 GTM10 0.82 0.79 0.85 0.79 0.74 0.83 0.91 0.89 0.94 0.84 0.79 0.93 0.94 0.92 0.96 0.84 0.79 0.92 GTM20 0.77 0.73 0.81 0.76 0.69 0.88 0.79 0.76 0.83 0.70 0.55 0.83 0.83 0.79 0.86 0.80 0.67 0.90 GTM30 0.74 0.70 0.78 0.73 0.60 0.86 0.74 0.70 0.78 0.63 0.52 0.79 0.77 0.73 0.81 0.64 0.52 0.80 Fluency Method P 95%L 95%U S 95%L 95%U P 95%L 95%U S 95%L 95%U P 95%L 95%U S 95%L 95%U BLEU1 0.81 0.75 0.86 0.76 0.62 0.90 0.73 0.67 0.79 0.70 0.62 0.81 0.70 0.63 0.77 0.79 0.67 0.90 BLEU4 0.86 0.81 0.90 0.74 0.62 0.86 0.83 0.78 0.88 0.68 0.60 0.81 0.83 0.78 0.88 0.70 0.62 0.81 BLEU12 0.87 0.76 0.93 0.66 0.33 0.79 0.93 0.81 0.97 0.78 0.44 0.94 0.93 0.84 0.97 0.80 0.49 0.94 NIST 0.81 0.75 0.87 0.74 0.62 0.86 0.70 0.64 0.77 0.68 0.60 0.79 0.68 0.61 0.75 0.77 0.67 0.88 WER 0.69 0.62 0.75 0.68 0.57 0.85 0.59 0.51 0.66 0.70 0.57 0.82 0.60 0.52 0.68 0.69 0.57 0.81 PER 0.79 0.74 0.85 0.67 0.57 0.82 0.68 0.60 0.73 0.69 0.60 0.81 0.70 0.63 0.76 0.65 0.57 0.79 ROUGE-L 0.83 0.77 0.88 0.80 0.67 0.90 0.76 0.69 0.82 0.79 0.64 0.90 0.73 0.66 0.80 0.78 0.67 0.90 ROUGE-W 0.85 0.80 0.90 0.79 0.63 0.90 0.78 0.73 0.84 0.72 0.62 0.83 0.77 0.71 0.83 0.78 0.67 0.90 ROUGE-S* 0.84 0.78 0.89 0.79 0.62 0.90 0.80 0.74 0.86 0.77 0.64 0.90 0.78 0.71 0.84 0.79 0.69 0.90 ROUGE-S0 0.87 0.81 0.91 0.78 0.62 0.90 0.83 0.78 0.88 0.71 0.62 0.82 0.82 0.77 0.88 0.76 0.62 0.90 ROUGE-S4 0.84 0.79 0.89 0.80 0.67 0.90 0.82 0.77 0.87 0.78 0.64 0.90 0.81 0.75 0.86 0.79 0.67 0.90 ROUGE-S9 0.84 0.79 0.89 0.80 0.67 0.90 0.81 0.76 0.87 0.79 0.69 0.90 0.79 0.73 0.85 0.79 0.69 0.90 GTM10 0.73 0.66 0.79 0.76 0.60 0.87 0.71 0.64 0.78 0.80 0.67 0.90 0.66 0.58 0.74 0.80 0.64 0.90 GTM20 0.86 0.81 0.90 0.80 0.67 0.90 0.83 0.77 0.88 0.69 0.62 0.81 0.83 0.77 0.87 0.74 0.62 0.89 GTM30 0.87 0.81 0.91 0.79 0.67 0.90 0.83 0.77 0.87 0.73 0.62 0.83 0.83 0.77 0.88 0.71 0.60 0.83 With Case Information (Case) Lower Case (NoCase) Lower Case & Stemmed (Stem) With Case Information (Case) Lower Case (NoCase) Lower Case & Stemmed (Stem) Table 1." ></td>
	<td class="line x" title="170:211	Pearsons  and Spearmans  correlations of automatic evaluation measures vs. adequacy and fluency: BLEU1, 4, and 12 are BLEU with maximum of 1, 4, and 12 grams, NIST is the NIST score, ROUGE-L is LCS-based F-measure ( = 1), ROUGE-W is weighted LCS-based F-measure ( = 1)." ></td>
	<td class="line x" title="171:211	ROUGE-S* is skip-bigram-based co-occurrence statistics with any skip distance limit, ROUGESN is skip-bigram-based F-measure ( = 1) with maximum skip distance of N, PER is position independent word error rate, and WER is word error rate." ></td>
	<td class="line x" title="172:211	GTM 10, 20, and 30 are general text matcher with exponents of 1.0, 2.0, and 3.0." ></td>
	<td class="line x" title="173:211	(Note, only BLEU1, 4, and 12 are shown here to preserve space)." ></td>
	<td class="line x" title="174:211	not be found." ></td>
	<td class="line x" title="175:211	It also suits the NIST MT evaluation scenario where multiple systems are ranked according to some performance metrics." ></td>
	<td class="line x" title="176:211	To estimate the significance of these correlation statistics, we applied bootstrap resampling, generating random samples of the 919 different sentence segments." ></td>
	<td class="line x" title="177:211	The lower and upper values of 95% confidence interval are also shown in the table." ></td>
	<td class="line x" title="178:211	Dark (green) cells are the best correlation numbers in their categories and light gray cells are statistically equivalent to the best numbers in their categories." ></td>
	<td class="line x" title="179:211	Analyzing all runs according to the adequacy and fluency table, we make the following observations: Applying the stemmer achieves higher correlation with adequacy but keeping case information achieves higher correlation with fluency except for BLEU7-12 (only BLEU12 is shown)." ></td>
	<td class="line x" title="180:211	For example, the Pearsons  (P) correlation of ROUGE-S* with adequacy increases from 0.85 (Case) to 0.95 (Stem) while its Pearsons  correlation with fluency drops from 0.84 (Case) to 0.78 (Stem)." ></td>
	<td class="line x" title="181:211	We will focus our discussions on the Stem set in adequacy and Case set in fluency." ></td>
	<td class="line x" title="182:211	The Pearson's  correlation values in the Stem set of the Adequacy Table, indicates that ROUGEL and ROUGE-S with a skip distance longer than 0 correlate highly and linearly with adequacy and outperform BLEU and NIST." ></td>
	<td class="line x" title="183:211	ROUGE-S* achieves that best correlation with a Pearsons  of 0.95." ></td>
	<td class="line x" title="184:211	Measures favoring consecutive matches, i.e. BLEU4 and 12, ROUGE-W, GTM20 and 30, ROUGE-S0 (bigram), and WER have lower Pearsons  . Among them WER (0.48) that tends to penalize small word movement is the worst performer." ></td>
	<td class="line x" title="185:211	One interesting observation is that longer BLEU has lower correlation with adequacy." ></td>
	<td class="line x" title="186:211	Spearmans  values generally agree with Pearson's  but have more equivalents." ></td>
	<td class="line x" title="187:211	The Pearson's  correlation values in the Stem set of the Fluency Table, indicates that BLEU12 has the highest correlation (0.93) with fluency." ></td>
	<td class="line x" title="188:211	However, it is statistically indistinguishable with 95% confidence from all other metrics shown in the Case set of the Fluency Table except for WER and GTM10." ></td>
	<td class="line x" title="189:211	GTM10 has good correlation with human judgments in adequacy but not fluency; while GTM20 and GTM30, i.e. GTM with exponent larger than 1.0, has good correlation with human judgment in fluency but not adequacy." ></td>
	<td class="line x" title="190:211	ROUGE-L and ROUGE-S*, 4, and 9 are good automatic evaluation metric candidates since they perform as well as BLEU in fluency correlation analysis and outperform BLEU4 and 12 significantly in adequacy." ></td>
	<td class="line x" title="191:211	Among them, ROUGE-L is the best metric in both adequacy and fluency correlation with human judgment according to Spearmans correlation coefficient and is statistically indistinguishable from the best metrics in both adequacy and fluency correlation with human judgment according to Pearsons correlation coefficient." ></td>
	<td class="line x" title="192:211	6 Conclusion In this paper we presented two new objective automatic evaluation methods for machine translation, ROUGE-L based on longest common subsequence (LCS) statistics between a candidate translation and a set of reference translations." ></td>
	<td class="line x" title="193:211	Longest common subsequence takes into account sentence level structure similarity naturally and identifies longest co-occurring in-sequence ngrams automatically while this is a free parameter in BLEU." ></td>
	<td class="line x" title="194:211	To give proper credit to shorter common sequences that are ignored by LCS but still retain the flexibility of non-consecutive matches, we proposed counting skip bigram co-occurrence." ></td>
	<td class="line x" title="195:211	The skip-bigram-based ROUGE-S* (without skip distance restriction) had the best Pearson's  correlation of 0.95 in adequacy when all words were lower case and stemmed." ></td>
	<td class="line x" title="196:211	ROUGE-L, ROUGE-W, ROUGE-S*, ROUGE-S4, and ROUGE-S9 were equal performers to BLEU in measuring fluency." ></td>
	<td class="line x" title="197:211	However, they have the advantage that we can apply them on sentence level while longer BLEU such as BLEU12 would not differentiate any sentences with length shorter than 12 words (i.e. no 12-gram matches)." ></td>
	<td class="line x" title="198:211	We plan to explore their correlation with human judgments on sentence-level in the future." ></td>
	<td class="line x" title="199:211	We also confirmed empirically that adequacy and fluency focused on different aspects of machine translations." ></td>
	<td class="line x" title="200:211	Adequacy placed more emphasis on terms co-occurred in candidate and reference translations as shown in the higher correlations in Stem set than Case set in Table 1; while the reverse was true in the terms of fluency." ></td>
	<td class="line x" title="201:211	The evaluation results of ROUGE-L, ROUGEW, and ROUGE-S in machine translation evaluation are very encouraging." ></td>
	<td class="line x" title="202:211	However, these measures in their current forms are still only applying string-to-string matching." ></td>
	<td class="line x" title="203:211	We have shown that better correlation with adequacy can be reached by applying stemmer." ></td>
	<td class="line x" title="204:211	In the next step, we plan to extend them to accommodate synonyms and paraphrases." ></td>
	<td class="line x" title="205:211	For example, we can use an existing thesaurus such as WordNet (Miller 1990) or creating a customized one by applying automated synonym set discovery methods (Pantel and Lin 2002) to identify potential synonyms." ></td>
	<td class="line oc" title="206:211	Paraphrases can also be automatically acquired using statistical methods as shown by Barzilay and Lee (2003)." ></td>
	<td class="line x" title="207:211	Once we have acquired synonym and paraphrase data, we then need to design a soft matching function that assigns partial credits to these approximate matches." ></td>
	<td class="line x" title="208:211	In this scenario, statistically generated data has the advantage of being able to provide scores reflecting the strength of similarity between synonyms and paraphrased." ></td>
	<td class="line x" title="209:211	ROUGE-L, ROUGE-W, and ROUGE-S have also been applied in automatic evaluation of summarization and achieved very promising results (Lin 2004)." ></td>
	<td class="line x" title="210:211	In Lin and Och (2004), we proposed a framework that automatically evaluated automatic MT evaluation metrics using only manual translations without further human involvement." ></td>
	<td class="line x" title="211:211	According to the results reported in that paper, ROUGE-L, ROUGE-W, and ROUGE-S also outperformed BLEU and NIST." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P04-2006
ISTART: Paraphrase Recognition
Boonthum, Chutima;"></td>
	<td class="line x" title="1:146	iSTART: Paraphrase Recognition Chutima Boonthum Computer Science Department Old Dominion University, Norfolk, VA-23508 USA cboont@cs.odu.edu Abstract Paraphrase recognition is used in a number of applications such as tutoring systems, question answering systems, and information retrieval systems." ></td>
	<td class="line x" title="2:146	The context of our research is the iSTART reading strategy trainer for science texts, which needs to understand and recognize the trainees input and respond appropriately." ></td>
	<td class="line x" title="3:146	This paper describes the motivation for paraphrase recognition and develops a definition of the strategy as well as a recognition model for paraphrasing." ></td>
	<td class="line x" title="4:146	Lastly, we discuss our preliminary implementation and research plan." ></td>
	<td class="line x" title="5:146	1 Introduction A web-based automated reading strategy trainer called iSTART (Interactive Strategy Trainer for Active Reading and Thinking) adaptively assigns individual students to appropriate reading training programs." ></td>
	<td class="line x" title="6:146	It follows the SERT (SelfExplanation Reading Training) methodology developed by McNamara (in press) as a way to improve high school students reading ability by teaching them to use active reading strategies in self-explaining difficult texts." ></td>
	<td class="line x" title="7:146	Details of the strategies can be found in McNamara (in press) and of iSTART in Levinstein et al.(2003) During iSTARTs practice module, the student self-explains a sentence." ></td>
	<td class="line x" title="9:146	Then the trainer analyzes the students explanation and responds." ></td>
	<td class="line x" title="10:146	The current system uses simple wordmatching algorithms to evaluate the students input that do not yield results that are sufficiently reliable or accurate." ></td>
	<td class="line x" title="11:146	We therefore propose a new system for handling the students explanation more effectively." ></td>
	<td class="line x" title="12:146	Two major tasks of this semantically-based system are to (1) construct an internal representation of sentences and explanations and (2) recognize the reading strategies the student uses beginning with paraphrasing." ></td>
	<td class="line x" title="13:146	Construct an Internal Representation: We transform the natural language explanation into a representation suitable for later analysis." ></td>
	<td class="line x" title="14:146	The Sentence Parser gives us a syntactically and morphologically tagged representation." ></td>
	<td class="line x" title="15:146	We transform the output of the Link Grammar parser (CMU, 2000) that generates syntactical and morphological information into an appropriate knowledge representation using the Representation Generator." ></td>
	<td class="line x" title="16:146	Recognize Paraphrasing: In what follows, we list the paraphrase patterns that we plan to cover and define a recognition model for each pattern." ></td>
	<td class="line x" title="17:146	This involves two steps: (1) recognizing paraphrasing patterns, and (2) reporting the result." ></td>
	<td class="line x" title="18:146	The Paraphrase Recognizer compares two internal representation (one is of a given sentence and another is of the students explanation) and finds paraphrase matches (concept-relationconcept triplet matches) according to a paraphrasing pattern." ></td>
	<td class="line x" title="19:146	The Reporter provides the final summary of the total paraphrase matches, noting unmatched information in either the sentence or the explanation." ></td>
	<td class="line x" title="20:146	Based on the similarity measure, the report will include whether the student has fully or partially paraphrased a given sentence and whether it contains any additional information." ></td>
	<td class="line x" title="21:146	2 Paraphrase When two expressions describe the same situation, each is considered to be a paraphrase of the other." ></td>
	<td class="line x" title="22:146	There is no precise paraphrase definition in general; instead there are frequently-accepted paraphrasing patterns to which various authorities refer." ></td>
	<td class="line x" title="23:146	Academic writing centers (ASU Writing Center, 2000; BAC Writing Center; USCA Writing Room; and Hawes, 2003) provide a number of characterizations, such as using synonyms, changing part-of-speech, reordering ideas, breaking a sentence into smaller ones, using definitions, and using examples." ></td>
	<td class="line x" title="24:146	McNamara (in press), on the other hand, does not consider using definitions or examples to be part of paraphrasing, but rather considers them elaboration." ></td>
	<td class="line x" title="25:146	Stede (1996) considers different aspects or intentions to be paraphrases if they mention the same content or situation." ></td>
	<td class="line x" title="26:146	Instead of attempting to find a single paraphrase definition, we will start with six commonly mentioned paraphrasing patterns: 1." ></td>
	<td class="line x" title="27:146	Synonym: substitute a word with its synonym, e.g. help, assist, aid; 2." ></td>
	<td class="line x" title="28:146	Voice: change the voice of sentence from active to passive or vice versa; 3." ></td>
	<td class="line x" title="29:146	Word-Form/Part-of-speech: change a word into a different form, e.g. change a noun to a verb, adverb, or adjective; 4." ></td>
	<td class="line x" title="30:146	Break down Sentence: break a long sentence down into small sentences; 5." ></td>
	<td class="line x" title="31:146	Definition/Meaning: substitute a word with its definition or meaning; 6." ></td>
	<td class="line x" title="32:146	Sentence Structure: use different sentence structures to express the same thing." ></td>
	<td class="line x" title="33:146	If the explanation has any additional information or misses some information that appeared in the original sentence, we should be able to detect this as well for use in discovering additional strategies employed." ></td>
	<td class="line x" title="34:146	3 Recognition Model To recognize paraphrasing, we convert natural language sentences into Conceptual Graphs (CG, Sowa, 1983; 1992) and then compare two CGs for matching according to paraphrasing patterns." ></td>
	<td class="line x" title="35:146	The matching process is to find as many concept-relation-concept triplet matches as possible." ></td>
	<td class="line x" title="36:146	A triplet match means that a triplet from the students input matches with a triplet from the given sentence." ></td>
	<td class="line x" title="37:146	In particular, the left-concept, right-concept, and relation of both sub-graphs have to be exactly the same, or the same under a transformation based on a relationship of synonymy (or other relation defined in WordNet), or the same because of idiomatic usage." ></td>
	<td class="line x" title="38:146	It is also possible that several triplets of one sentence together match a single triplet of the other." ></td>
	<td class="line x" title="39:146	At the end of this pattern matching, a summary result is provided: total paraphrasing matches, unparaphrased information and additional information (not appearing in the given sentence)." ></td>
	<td class="line x" title="40:146	3.1 Conceptual Graph Generation A natural language sentence is converted into a conceptual graph using the Link Grammar parser." ></td>
	<td class="line x" title="41:146	This process mainly requires mapping one or more Link connector types into a relation of the conceptual graph." ></td>
	<td class="line x" title="42:146	A parse from the Link Grammar consists of triplets: starting word, an ending word, and a connector type between these two words." ></td>
	<td class="line x" title="43:146	For example, [1 2 (Sp)] means word-1 connects to word-2 with a subject connector or that word-1 is the subject of word-2." ></td>
	<td class="line x" title="44:146	The sentence A walnut is eaten by a monkey is parsed as follows: [(0=LEFT-WALL)(1=a)(2=walnut.n)(3=is.v) (4=eaten.v)(5=by)(6=a)(7=monkey.n)(8=.)] [[0 8 (Xp)][0 2 (Wd)][1 2 (Dsu)][2 3 (Ss)] [3 4 (Pv)][4 5 (MVp)][5 7 (Js)][6 7 (Ds)]] We then convert each Link triplet into a corresponding CG triplet." ></td>
	<td class="line x" title="45:146	Two words in the Link triplet can be converted into two concepts of the CG." ></td>
	<td class="line x" title="46:146	To decide whether to put a word on the left or the right side of the CG triplet, we define a mapping rule for each Link connector type." ></td>
	<td class="line x" title="47:146	For example, a Link triplet [1 2 (S*)] will be mapped to the Agent relation, with word-2 as the left-concept and word-1 as the right-concept: [Word-2] fi (Agent) fi [Word-1]." ></td>
	<td class="line x" title="48:146	Sometimes it is necessary to consider several Link triplets in generating a single CG triplet." ></td>
	<td class="line x" title="49:146	A CG of previous example is shown below: 0 [0 8 (Xp)] -> #S# -> N/A 1 [0 2 (Wd)] -> #S# -> N/A 2 [1 2 (Dsu)] -> #S# -> [walnut.n]->(Article)->[a] 3 [2 3 (Ss)] -> #M# S + Pv (4) # -> [eaten.v]->(Patient)->[walnut.n] 4 [3 4 (Pv)] -> #M# Pv +MV(5)+O(6)# -> [eaten.v] -> (Agent) -> [monkey.n] 5 [4 5 (MVp)] -> #S# eaten.v by 6 [5 7 (Js)] -> #S# monkey.n by 7 [6 7 (Ds)] -> #S# -> [monkey.n] -> (Article) -> [a] Each line (numbered 0-7) shows a Link triplet and its corresponding CG triplet." ></td>
	<td class="line x" title="50:146	These will be used in the recognition process." ></td>
	<td class="line x" title="51:146	The #S# and #M indicate single and multiple mapping rules." ></td>
	<td class="line x" title="52:146	3.2 Paraphrase Recognition We illustrate our approach to paraphrase pattern recognition on single sentences: using synonyms (single or compound-word synonyms and idiomatic expressions), changing the voice, using a different word form, breaking a long sentence into smaller sentences, substituting a definition for a word, and changing the sentence structure." ></td>
	<td class="line x" title="53:146	Preliminaries: Before we start the recognition process, we need to assume that we have all the information about the text: each sentence has various content words (excluding such stop words as a, an, the, etc.); each content word has a definition together with a list of synonyms, antonyms, and other relations provided by WordNet (Fellbaum, 1998)." ></td>
	<td class="line x" title="54:146	To prepare a given text and a sentence, we plan to have an automated process that generates necessary information as well as manual intervention to verify and rectify the automated result, if necessary." ></td>
	<td class="line x" title="55:146	Single-Word Synonyms: First we discover that both CGs have the same pattern and then we check whether words in the same position are synonyms." ></td>
	<td class="line x" title="56:146	Example: Jenny helps Kay [Help] fi (Agent) fi [Person: Jenny] + fi (Patient) fi [Person: Kay] vs. Jenny assists Kay [Assist] fi (Agent) fi [Person: Jenny] + fi (Patient) fi [Person: Kay] Compound-Word Synonyms: In this case, we need to be able to match a word and its compound-word synonym." ></td>
	<td class="line x" title="57:146	For example, install has set up and put in as its compound-word synonyms." ></td>
	<td class="line x" title="58:146	The compound words are declared by the parser program." ></td>
	<td class="line x" title="59:146	During the preliminary processing CGs are pre-generated." ></td>
	<td class="line x" title="60:146	[Install] fi (Object) fi [Thing]  [Set-Up] fi (Object) fi [Thing]  [Put-In] fi (Object) fi [Thing] Then, this case will be treated like the singleword synonym." ></td>
	<td class="line x" title="61:146	Jenny installs a computer [Install] fi (Agent) fi [Person: Jenny] + fi (Object) fi [Computer] vs. Jenny sets up a computer [Set-Up] fi (Agent) fi [Person: Jenny] + fi (Object) fi [Computer] Idiomatic Clause/Phrase: For each idiom, a CG will be generated and used in the comparison process." ></td>
	<td class="line x" title="62:146	For example, the phrase give someone a hand means help." ></td>
	<td class="line x" title="63:146	The preliminary process will generate the following conceptual graph: [Help] fi (Patient) fi [Person: x]  [Give] fi (Patient) fi [Person: x] + fi (Object) fi [Hand] which gives us Jenny gives Kay a hand [Give] fi (Agent) fi [Person: Jenny] + fi (Patient) fi [Person: Kay] + fi (Object) fi [Hand] In this example, one might say that a hand might be an actual (physical) hand rather than a synonym phrase for help." ></td>
	<td class="line x" title="64:146	To reduce this particular ambiguity, the analysis of the context may be necessary." ></td>
	<td class="line x" title="65:146	Voice: Even if the voice of a sentence is changed, it will have the same CG." ></td>
	<td class="line x" title="66:146	For example, both Jenny helps Kay and Kay is helped by Jenny have the same graphs as follows: [Help] fi (Agent) fi [Person: Jenny] + fi (Patient) fi [Person: Kay] At this time we are assuming that if two CGs are exactly the same, it means paraphrasing by changing voice pattern." ></td>
	<td class="line x" title="67:146	However, we plan to introduce a modified conceptual graph that retains the original sentence structure so that we can verify that it was paraphrasing by change of voice and not simple copying." ></td>
	<td class="line x" title="68:146	Part-of-speech: A paraphrase can be generated by changing the part-of-speech of some keywords." ></td>
	<td class="line x" title="69:146	In the following example, the student uses a historical life story instead of life history, and similarity instead of similar." ></td>
	<td class="line x" title="70:146	Original sentence: All thunderstorms have a similar life history. Students Explanation: All thunderstorms have similarity in their historical life story. To find this paraphrasing pattern, we look for the same word, or a word that has the same baseform." ></td>
	<td class="line x" title="71:146	In this example, the sentences share the same base-form for similar and similarity as well as for history and historical." ></td>
	<td class="line x" title="72:146	Breaking long sentence: A sentence can be explained by small sentences coupled up together in such a way that each covers a part of the original sentence." ></td>
	<td class="line x" title="73:146	We integrate CGs of all sentences in the students input together before comparing it with the original sentence." ></td>
	<td class="line x" title="74:146	Original sentence: All thunderstorms have a similar life history. [Thunderstorm: ']  (Feature) fi [History]  (Attribute) fi [Life] (Attribute) fi [Similar] Students Explanation: Thunderstorms have life history." ></td>
	<td class="line x" title="75:146	It is similar among all thunderstorms [Thunderstorm]  (Feature) fi [History]  (Attribute) fi [Life] [It] (pronoun) (Attribute) fi [Similar] (Mod) fi [Thunderstorm: '] (among) We will provisionally assume that the student uses only the words that appear in the sentence in this breaking down process." ></td>
	<td class="line x" title="76:146	One solution is to combine graphs from all sentences together." ></td>
	<td class="line x" title="77:146	This can be done by merging graphs of the same concept." ></td>
	<td class="line x" title="78:146	This process involves pronoun resolution." ></td>
	<td class="line x" title="79:146	In this example, it could refer to life or history." ></td>
	<td class="line x" title="80:146	Our plan is to exercise all possible pronoun references and select one that gives the best paraphrasing recognition result." ></td>
	<td class="line x" title="81:146	Definition/Meaning: A CG is pre-generated for a definition of each word and its associations (synonyms, idiomatic expressions, etc.)." ></td>
	<td class="line x" title="82:146	To find a paraphrasing pattern of using the definition, for example, a history means the continuum of events occurring in succession leading from the past to the present and even into the future, we build a CG for this as shown below: [Continuum]  (Attribute) fi [Event: $] [Occur]  (Patient) fi [Event: $] (Mod) fi [Succession] (in) [Lead]  (Initiator) fi [Succession] (Source) fi [Time: Past] (from) (Path) fi [Time: Present] (to) (Path) fi [Time: Future] (into) We refine this CG by incorporating CGs of the definition into a single integrated CG, if possible." ></td>
	<td class="line x" title="83:146	(Patient) fi [Event: $] (Mod) fi [Succession] (in) (Source) fi [Time: Past] (from) (Path) fi [Time: Present] (to) (Path) fi [Time: Future] (into) From WordNet 2.0, the synonyms of past, present, and future found to be begin, start, beginning process, middle, go though, middle process, and end, last, ending process, respectively." ></td>
	<td class="line x" title="84:146	The following example shows how they can be used in recognizing paraphrases." ></td>
	<td class="line x" title="85:146	Original sentence: All thunderstorms have a similar life history. [Thunderstorm: ']  (Feature) fi [History]  (Attribute) fi [Life] (Attribute) fi [Similar] Students Explanation: Thunderstorms go through similar cycles." ></td>
	<td class="line x" title="86:146	They will begin the same, go through the same things, and end the same way. [Go]  (Agent) fi [Thunderstorm: #] (Path) fi [Cycle] fi (Attribute) fi [Similar] [Begin]  (Agent) fi [Thunderstorm: #] (Attribute) fi [Same] [Go-Through]  (Agent) fi [Thunderstorm: #] (Path) fi [Thing: $ ] fi (Attribute) fi [Same] [End]  (Agent) fi [Thunderstorm: #] (Path) fi [Way: $ ] fi (Attribute) fi [Same] From this CG, we found the use of begin, gothrough, and end, which are parts of the CG of historys definition." ></td>
	<td class="line x" title="87:146	These together with the correspondence of words in the sentences show that the student has used paraphrasing by using a definition of history in the self-explanation." ></td>
	<td class="line x" title="88:146	Sentence Structure: The same thing can be said in a number of different ways." ></td>
	<td class="line x" title="89:146	For example, to say There is someone happy, we can say Someone is happy, A person is happy, or There is a person who is happy, etc. As can be easily seen, all sentences have a similar CG triplet of [Person: $] fi (Char) fi [Happy] in their CGs." ></td>
	<td class="line x" title="90:146	But, we cannot simply say that they are paraphrases of each other; therefore, need to study more on possible solutions." ></td>
	<td class="line x" title="91:146	3.3 Similarity Measure The similarity between the students input and the given sentence can be categorized into one of these four cases: 1." ></td>
	<td class="line x" title="92:146	Complete paraphrase without extra info." ></td>
	<td class="line x" title="93:146	2." ></td>
	<td class="line x" title="94:146	Complete paraphrase with extra info." ></td>
	<td class="line x" title="95:146	3." ></td>
	<td class="line x" title="96:146	Partial paraphrase without extra info." ></td>
	<td class="line x" title="97:146	4." ></td>
	<td class="line x" title="98:146	Partial paraphrase with extra info." ></td>
	<td class="line x" title="99:146	To distinguish between complete and partial paraphrasing, we will use the triplet matching result." ></td>
	<td class="line x" title="100:146	What counts as complete depends on the context in which the paraphrasing occurs." ></td>
	<td class="line x" title="101:146	If we consider the paraphrasing as a writing technique, the complete paraphrasing would mean that all triplets of the given sentence are matched to those in the students input." ></td>
	<td class="line x" title="102:146	Similarly, if any triplets in the given sentence do not have a match, it means that the student is partially paraphrasing at best." ></td>
	<td class="line x" title="103:146	On the other hand, if we consider the paraphrasing as a reading behavior or strategy, the complete paraphrasing may not need all triplets of the given sentence to be matched." ></td>
	<td class="line x" title="104:146	Hence, recognizing which part of the students input is a paraphrase of which part of the given sentence is significant." ></td>
	<td class="line x" title="105:146	How can we tell that this explanation is an adequate paraphrase?" ></td>
	<td class="line x" title="106:146	Can we use information provided in the given sentence as a measurement?" ></td>
	<td class="line x" title="107:146	If so, how can we use it?" ></td>
	<td class="line x" title="108:146	These questions still need to be answered." ></td>
	<td class="line x" title="109:146	4 Related Work A number of people have worked on paraphrasing such as the multilingual-translation recognition by Smith (2003), the multilingual sentence generation by Stede (1996), universal model paraphrasing using transformation by Murata and Isahara (2001), DIRT  using inference rules in question answering and information retrieval by Lin and Pantel (2001)." ></td>
	<td class="line x" title="110:146	Due to the space limitation we will mention only a few related works." ></td>
	<td class="line x" title="111:146	ExtrAns (Extracting answers from technical texts) by (Molla et al, 2003) and (Rinaldi et al, 2003) uses minimal logical forms (MLF) to represent both texts and questions." ></td>
	<td class="line x" title="112:146	They identify terminological paraphrases by using a term-based hierarchy with their synonyms and variations; and syntactic paraphrases by constructing a common representation for different types of syntactic variation via meaning postulates." ></td>
	<td class="line x" title="113:146	Absent a paraphrase, they loosen the criteria by using hyponyms, finding highest overlap of predicates, and simple keyword matching." ></td>
	<td class="line oc" title="114:146	Barzilay & Lee (2003) also identify paraphrases in their paraphrased sentence generation system." ></td>
	<td class="line o" title="115:146	They first find different paraphrasing rules by clustering sentences in comparable corpora using n-gram word-overlap." ></td>
	<td class="line o" title="116:146	Then for each cluster, they use multi-sequence alignment to find intra-cluster paraphrasing rules: either morphosyntactic or lexical patterns." ></td>
	<td class="line o" title="117:146	To identify intercluster paraphrasing, they compare the slot values without considering word ordering." ></td>
	<td class="line x" title="118:146	In our system sentences are represented by conceptual graphs." ></td>
	<td class="line x" title="119:146	Paraphrases are recognized through idiomatic expressions, definition, and sentence break up." ></td>
	<td class="line x" title="120:146	Morpho-syntatic variations are also used but in more general way than the term hierarchy-based approach of ExtrAns." ></td>
	<td class="line x" title="121:146	5 Preliminary Implementation We have implemented two components to recognize paraphrasing with the CG for a single simple sentence: Automated Conceptual Graph Generator and Automated Paraphrasing Recognizer." ></td>
	<td class="line x" title="122:146	Automated Conceptual Graph Generator: is a C++ program that calls the Link Grammar API to get the parse result for the input sentence, and generates a CG." ></td>
	<td class="line x" title="123:146	We can generate a CG for a simple sentence using the first linkage result." ></td>
	<td class="line x" title="124:146	Future versions will deal with complex sentence structure as well as multiple linkages, so that we can cover most paraphrases." ></td>
	<td class="line x" title="125:146	Automated Paraphrasing Recognizer: The input to the Recognizer is a pair of CGs: one from the original sentence and another from the students explanation." ></td>
	<td class="line x" title="126:146	Our goal is to recognize whether any paraphrasing was used and, if so, what was the paraphrasing pattern." ></td>
	<td class="line x" title="127:146	Our first implementation is able to recognize paraphrasing on a single sentence for exact match, direct synonym match, first level antonyms match, hyponyms and hypernyms match." ></td>
	<td class="line x" title="128:146	We plan to cover more relationships available in WordNet as well as definitions, idioms, and logically equivalent expressions." ></td>
	<td class="line x" title="129:146	Currently, voice difference is treated as an exact match because both active voices have the same CGs and we have not yet modified the conceptual graph as indicated above." ></td>
	<td class="line x" title="130:146	6 Discussion and Remaining Work Our preliminary implementation shows us that paraphrase recognition is feasible and allows us to recognize different types of paraphrases." ></td>
	<td class="line x" title="131:146	We continue to work on this and improve our recognizer so that it can handle more word relations and more types of paraphrases." ></td>
	<td class="line x" title="132:146	During the testing, we will use data gathered during our previous iSTART trainer experiments." ></td>
	<td class="line x" title="133:146	These are the actual explanations entered by students who were given the task of explaining sentences." ></td>
	<td class="line x" title="134:146	Fortunately, quite a bit of these data have been evaluated by human experts for quality of explanation." ></td>
	<td class="line x" title="135:146	Therefore, we can validate our paraphrasing recognition result against the human evaluation." ></td>
	<td class="line x" title="136:146	Besides implementing the recognizer to cover all paraphrasing patterns addressed above, there are many issues that need to be solved and implemented during this course of research." ></td>
	<td class="line x" title="137:146	The Representation for a simple sentence is the Conceptual Graph, which is not powerful enough to represent complex, compound sentences, multiple sentences, paragraphs, or entire texts." ></td>
	<td class="line x" title="138:146	We will use Rhetorical Structure Theory (RST) to represent the relations among the CGs of these components of these more complex structures." ></td>
	<td class="line x" title="139:146	This will also involve Pronoun Resolution as well as Discourse Chunking." ></td>
	<td class="line x" title="140:146	Once a representation has been selected, we will implement an automated generator for such representation." ></td>
	<td class="line x" title="141:146	The Recognizer and Paraphrase Reporter have to be completed." ></td>
	<td class="line x" title="142:146	The similarity measures for writing technique and reading behavior must still be defined." ></td>
	<td class="line x" title="143:146	Once all processes have been implemented, we need to verify that they are correct and validate the results." ></td>
	<td class="line x" title="144:146	Finally, we can integrate this recognition process into the iSTART trainer in order to improve the existing evaluation system." ></td>
	<td class="line x" title="145:146	Acknowledgements This dissertation work is under the supervision of Dr. Shunichi Toida and Dr. Irwin Levinstein." ></td>
	<td class="line x" title="146:146	iSTART is supported by National Science Foundation grant REC-0089271." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W04-0910
Paraphrastic Grammars
Gardent, Claire;Amoia, Marilisa;Jacquey, Evelyne;"></td>
	<td class="line x" title="1:298	Paraphrastic Grammars Claire Gardent CNRS-LORIA, Nancy France Claire.Gardent@loria.fr Marilisa Amoia Computational Linguistics University of Saarbruecken Germany amoia@coli.uni-sb.de Evelyne Jacquey CNRS-ATILF, Nancy France Evelyne.Jacquey@atilf.fr Abstract Arguably, grammars which associate natural language expressions not only with a syntactic but also with a semantic representation, should do so in a way that capture paraphrasing relations between sentences whose core semantics are equivalent." ></td>
	<td class="line x" title="2:298	Yet existing semantic grammars fail to do so." ></td>
	<td class="line x" title="3:298	In this paper, we describe an ongoing project whose aim is the production of a paraphrastic grammar that is, a grammar which associates paraphrases with identical semantic representations." ></td>
	<td class="line x" title="4:298	We begin by proposing a typology of paraphrases." ></td>
	<td class="line x" title="5:298	We then show how this typology can be used to simultaneously guide the development of a grammar and of a testsuite designed to support the evaluation of this grammar." ></td>
	<td class="line x" title="6:298	1 Introduction A salient feature of natural language is that it allows paraphrases that is, it allows different verbalisations of the same content." ></td>
	<td class="line x" title="7:298	Thus although the various verbalisations in (1) may have different pragmatic or communicative values (with respect for instance to topicalisation, presuppositions or focus/ground partitioning), they all share a core semantic content, the content approximated by a traditional montagovian compositional semantics." ></td>
	<td class="line x" title="8:298	(1) a. La croisi`ere coute cher." ></td>
	<td class="line x" title="9:298	Lit." ></td>
	<td class="line x" title="10:298	the cruse is expensive b. Le cout de la croisi`ere est eleve. Lit." ></td>
	<td class="line x" title="11:298	the cost of the cruse is high c. La croisi`ere a un cout eleve Lit." ></td>
	<td class="line x" title="12:298	the cruse has a high cost Linguists have long noticed the pervasiveness of paraphrases in natural language and attempted to caracterise it." ></td>
	<td class="line x" title="13:298	Thus for instance Chomskys transformations capture the relation between one core meaning (a deep structure in Chomskys terms) and several surface realisations (for instance, between the passive and the active form of the same sentence) while (Melcuk, 1988) presents sixty paraphrastic rules designed to account for paraphrastic relations between sentences." ></td>
	<td class="line x" title="14:298	More recently, work in information extraction (IE) and question answering (QA) has triggered a renewed research interest in paraphrases as IE and QA systems typically need to be able to recognise various verbalisations of the content." ></td>
	<td class="line x" title="15:298	Because of the large, open domain corpora these systems deal with, coverage and robustness are key issues and much on the work on paraphrases in that domain is based on automatic learning techniques." ></td>
	<td class="line x" title="16:298	For instance, (Lin and Pantel, 2001) acquire two-argument templates (inference rules) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning." ></td>
	<td class="line oc" title="17:298	Similarly, (Barzilay and Lee, 2003) and (Shinyanma et al. , 2002) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source." ></td>
	<td class="line x" title="18:298	And (Glickman and Dagan, 2003) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts." ></td>
	<td class="line n" title="19:298	Such machine learning approaches have known pros and cons." ></td>
	<td class="line p" title="20:298	On the one hand, they produce large scale resources at little man labour cost." ></td>
	<td class="line n" title="21:298	On the other hand, the degree of descriptive abstraction offered by the list of inference or paraphrase rules they output is low." ></td>
	<td class="line x" title="22:298	We chose to investigate an alternative research direction by aiming to develop a paraphrastic grammar that is, a grammar which captures the paraphrastic relations between linguistic structures1." ></td>
	<td class="line x" title="23:298	Based on a computational grammar that associates natural language expressions with both a syntactic and a semantic representation, a paraphrastic gram1As we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar (Candito, 1999) thus ensuring an additional level of abstraction." ></td>
	<td class="line x" title="24:298	The metagrammar is an abstract specification of the linguistic properties (phrase structure, valency, realisation of grammatical functions etc.) encoded in the grammar basic units." ></td>
	<td class="line x" title="25:298	This specification is then compiled to automatically produce a specific grammar." ></td>
	<td class="line x" title="26:298	mar is a grammar that moreover associates paraphrases with the same semantic representation." ></td>
	<td class="line x" title="27:298	That is, contrary to machine learning based approaches which relate paraphrases via sentence patterns, the paraphrastic grammar approach relates paraphrases via a common semantic representation." ></td>
	<td class="line x" title="28:298	In this way, the paraphrastic approach provides an interesting alternative basis for generation from conceptual representations and for the inference-based, deep semantic processing of the kind that is ultimately needed for high quality question answering." ></td>
	<td class="line x" title="29:298	Specifically, we aim at developing a paraphrastic grammar for French, based on the Tree Adjoining Grammar (TAG) developed for this language by Anne Abeille (Abeille, 2002)." ></td>
	<td class="line x" title="30:298	The paper is structured as follows." ></td>
	<td class="line x" title="31:298	We start by proposing a typology of the paraphrastic means made available by natural language." ></td>
	<td class="line x" title="32:298	We then show how this typology can be used to develop a testsuite for developing and evaluating a paraphrastic grammar. Finally, we highlight some of the issues arising when developing a paraphrastic grammar." ></td>
	<td class="line x" title="33:298	2 Classifying paraphrases A paraphrastic grammar should capture the various means made available by natural language to support paraphrasing." ></td>
	<td class="line x" title="34:298	But what are those means?" ></td>
	<td class="line x" title="35:298	We distinguish here between three main classes namely, parallel, shuffling and definitional paraphrastic means." ></td>
	<td class="line x" title="36:298	Parallel paraphrastic means." ></td>
	<td class="line x" title="37:298	A parallel paraphrase can hold either between two non predicative lexical units (words or multi word expressions) modulo negation or between two predicative units of identical arity." ></td>
	<td class="line x" title="38:298	If it holds between predicative units, the mapping linking grammatical functions (subject, objects, etc)." ></td>
	<td class="line x" title="39:298	and thematic roles (agent, theme, etc)." ></td>
	<td class="line x" title="40:298	must be the same." ></td>
	<td class="line x" title="41:298	Depending on whether or not negation is involved, semantic equivalence will futhermore obtain either through synonymy or through antonymy." ></td>
	<td class="line x" title="42:298	As illustrated in Figure 1, synonymy can be further divided in a number of cases depending on various morphological and syntactic criteria." ></td>
	<td class="line x" title="43:298	The classification criteria used involve : Syntactic category: Do the synonyms have the same syntactic category?" ></td>
	<td class="line x" title="44:298	Morphological relatedness: Do the synonyms contain words that are morphologically related?" ></td>
	<td class="line x" title="45:298	Form: Are the synonyms simple lexical units or multi word expressions?" ></td>
	<td class="line x" title="46:298	As for antonymy, we distinguish between trans and intracategorial antonymy: (2) Jean est lent/Jean nest pas rapide." ></td>
	<td class="line x" title="47:298	Jean is slow/Jean is not fast." ></td>
	<td class="line x" title="48:298	lent/rapide, intracategorial Jean a cesser de fumer/Jean ne fume plus." ></td>
	<td class="line x" title="49:298	Jean has stopped smoking/Jean smokes no more." ></td>
	<td class="line x" title="50:298	cesse de/ne : : : plus, transcategorial Shuffling paraphrastic means." ></td>
	<td class="line x" title="51:298	When a semantic equivalence holds between predicative units with distinct grammatical functions/thematic role linking, we speak of shuffling paraphrases." ></td>
	<td class="line x" title="52:298	Such paraphrases can be realised either by means of argument preserving alternations (in the sense of Beth Levin, cf.(4)) or using a converse construction (cf.3)2." ></td>
	<td class="line x" title="55:298	(3) a Jean donne un livre `a Marie." ></td>
	<td class="line x" title="56:298	Jean gives a book to Marie." ></td>
	<td class="line x" title="57:298	Marie recoit un livre de Jean Jean receives a book from Marie." ></td>
	<td class="line x" title="58:298	b Jean est le parent de Marie." ></td>
	<td class="line x" title="59:298	Jean is the parent of Marie." ></td>
	<td class="line x" title="60:298	Marie est lenfant de Jean." ></td>
	<td class="line x" title="61:298	Marie is the child of Jean." ></td>
	<td class="line x" title="62:298	(4) a. Cette cle ouvre le coffre fort This key opens the safe." ></td>
	<td class="line x" title="63:298	Le coffre fort souvre avec cette cle The safe opens with this key." ></td>
	<td class="line x" title="64:298	b. Jean mange une pomme Jean eats an apple." ></td>
	<td class="line x" title="65:298	une pomme est mangee par Jean An apple is eaten by Jean." ></td>
	<td class="line x" title="66:298	Il a ete mange une pomme par Jean." ></td>
	<td class="line x" title="67:298	There has been an apple eaten by Jean." ></td>
	<td class="line x" title="68:298	c. Leau remplit la cruche The water fills the jug." ></td>
	<td class="line x" title="69:298	La cruche se remplit deau The jug fills with water." ></td>
	<td class="line x" title="70:298	On remplit la cruche deau One fills the jug with water." ></td>
	<td class="line x" title="71:298	d. Le laboratoire fusionne avec lentreprise The laboratory merges with the firm." ></td>
	<td class="line x" title="72:298	le laboratoire et lentreprise fusionnent The laboratory and the firm merge." ></td>
	<td class="line x" title="73:298	e. Jean frappe le mur avec un baton Jean hit the wall with a stick." ></td>
	<td class="line x" title="74:298	2Obviously, the english translations do not reflect the acceptability of the french equivalent." ></td>
	<td class="line x" title="75:298	Same synt." ></td>
	<td class="line x" title="76:298	Same morph." ></td>
	<td class="line x" title="77:298	Form Example categories family yes no word/word policier, flic yes yes word/mwe conseiller, donner conseil yes no word/mwe sexprimer sur, donner son avis sur yes no mwe/mwe donner carte blanche `a, laisser tout pouvoir no yes word/word construire, construction no no word/word candidature `a, briguer Figure 1: Synonymy Jean frappe le baton sur le mur." ></td>
	<td class="line x" title="78:298	Jean hit the stick on the wall." ></td>
	<td class="line x" title="79:298	f. Je fournis des livres `a Jean I provide books to Jean." ></td>
	<td class="line x" title="80:298	Je fournis Jean en livre I provide Jean with books." ></td>
	<td class="line x" title="81:298	Definitional paraphrastic means." ></td>
	<td class="line x" title="82:298	Third, we call definitional paraphrases semantic equivalences that hold between a lexical unit and a phrase consisting of more than one lexical unit." ></td>
	<td class="line x" title="83:298	The phrase in this case, defines the meaning of the lexical unit." ></td>
	<td class="line x" title="84:298	Since definitions are notoriously difficult to decide upon, we restrict ourselves here to such definitions as can be given by derivational morphology that is, definitions based on a word that is morphologically linked to the definiendum (cf.5)." ></td>
	<td class="line x" title="86:298	(5) a. Le conducteur de la BMW est chauve The driver of the BMW is bald." ></td>
	<td class="line x" title="87:298	La personne qui conduit la BMW est chauve The person who drives the BMW is bald." ></td>
	<td class="line x" title="88:298	b. Cet outil est parametrable This tool is parameterisable." ></td>
	<td class="line x" title="89:298	Cet outil peut etre parametre This tool can be parameterised." ></td>
	<td class="line x" title="90:298	3 Developing a paraphrase testsuite Based on the above typology, we can systematically construct a testsuite for developing and evaluating a paraphrastic grammar." ></td>
	<td class="line x" title="91:298	Indeed, when developing a grammar, it is necessary to have some means of assessing both the coverage of the grammar (does it generate all the sentences of the described language)?" ></td>
	<td class="line x" title="92:298	and its degree of overgeneration (does it generate only the sentences of the described language)?" ></td>
	<td class="line x" title="93:298	While corpus driven efforts along the PARSEVAL lines (Black et al. , 1991) are good at giving some measure of a grammar coverage, they are not suitable for finer grained analysis and in particular, for progress evaluation, regression testing and comparative report generation." ></td>
	<td class="line x" title="94:298	Another known method consists in developing and using a test suite that is, a set of negative and positive items against which the grammar can be systematically tested." ></td>
	<td class="line x" title="95:298	For english, there is for instance the 15 year old HewlettPackard test suite, a simple text file listing test sentences and grouping them according to linguistics phenomena (Flickinger et al. , 1987); and more recently, the much more sophisticated TSNLP (Test Suite for Natural Language Processing) which includes some 9500 test items for English, French and German, each of them being annotated with syntactic and application related information (Oepen and Flickinger, 1998)." ></td>
	<td class="line x" title="96:298	Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar. To remedy this, we propose to develop a paraphrase test suite based on the paraphrase typology described in the previous section." ></td>
	<td class="line x" title="97:298	In such a testsuite, test items pair a semantic representation with a set of paraphrases verbalising this semantics." ></td>
	<td class="line x" title="98:298	The construction and annotation of the paraphrases reflects the paraphrase typology." ></td>
	<td class="line x" title="99:298	In a first phase, we concentrate on simple, non-recursive predicate/argument structure." ></td>
	<td class="line x" title="100:298	Given such a structure, the construction and annotation of a test item proceeds as follows." ></td>
	<td class="line x" title="101:298	First, a canonical verbalisation is produced in which the predicate is realised by the canonical verb for the given concept3 and the arguments by the canonical nouns." ></td>
	<td class="line x" title="102:298	Next variants are produced by systematically trying to create parallel, shuffling and definitional paraphrases." ></td>
	<td class="line x" title="103:298	Each of the variant is furthermore annotated with labels caracterising the type of paraphrasing involved." ></td>
	<td class="line x" title="104:298	Here is an example." ></td>
	<td class="line x" title="105:298	Suppose the input semantics is: apply(e), agent(e,jean), theme(e,job), failure(e) for which the canonical verbalisation is: (6) Jean a candidate sans succ`es sur le poste Jean has applied in vain for the job." ></td>
	<td class="line x" title="106:298	3Like in a thesaurus, we assume that amongst a set of synonyms, one lexical unit is canonical and the others not." ></td>
	<td class="line x" title="107:298	The canonical unit is sometimes called a descriptor." ></td>
	<td class="line x" title="108:298	The parallel synonyms4 that can be used are the following:5 candidater candidature +pred-N poser sa +pred-vsupV candidature briguer +pred-V sans succ`es echouer +mod-V etre sans succ`es +mod-beAdv ne pas etre retenu +mod-Vanton For shuffling synonymy, two alternations are available: the active/passive alternation for poser and the active/locative one for echouer." ></td>
	<td class="line x" title="109:298	There is no converse construction." ></td>
	<td class="line x" title="110:298	Neither is there any definition given by derivational morphology for any of the terms occurring in the canonical verbalisation." ></td>
	<td class="line x" title="111:298	Based on these facts, the following variants and annotations can be constructed." ></td>
	<td class="line x" title="112:298	(7) a. Jean a brigue le poste sans succ`es Jean has asked for the job in vain." ></td>
	<td class="line x" title="113:298	+pred-Vsyn b. Jean a pose sa candidature sur le poste sans succ`es Jean has submitted his application for the job in vain." ></td>
	<td class="line x" title="114:298	+pred-vsupN c. La candidature posee par Jean sur le poste a ete sans succ`es The application submitted by Jean for the job was in vain." ></td>
	<td class="line x" title="115:298	+pred-partAdj, +mod-beAdv d. La candidature posee par Jean sur le poste a echoue The application submitted by Jean for the job failed." ></td>
	<td class="line x" title="116:298	+pred-partAdj, +mod-V e. La candidature de Jean sur le poste a ete sans succ`es Jeans application for the job was in vain." ></td>
	<td class="line x" title="117:298	+pred-N, +mod-beAdv f. La candidature de Jean sur le poste na pas ete retenue 4As has been abundantly argued by linguists, real synonyms are extremely rare." ></td>
	<td class="line x" title="118:298	By synonyms, we in fact refer here to the notion of quasi-synonyms used for instance in WordNet that is, words that are interchangeable in a restricted set of contexts." ></td>
	<td class="line x" title="119:298	5The labels are the ones used for annotation." ></td>
	<td class="line x" title="120:298	They caracterise variations with respect to the canonical realisation." ></td>
	<td class="line x" title="121:298	For instance, +pref-N indicates that the main predicate (realised by a verb in the canonical verbalisation) is realised as a noun." ></td>
	<td class="line x" title="122:298	Jeans application for the job was not successful." ></td>
	<td class="line x" title="123:298	+pred-N, +mod-Vanton g. La candidature de Jean sur le poste a echoue Jeans application for the job failed." ></td>
	<td class="line x" title="124:298	+pred-N, +mod-V h. Jean a echoue dans sa candidature sur le poste." ></td>
	<td class="line x" title="125:298	Jean failed in his application for the job." ></td>
	<td class="line x" title="126:298	+pred-N, +mod-V-altLoc Thus the typology of paraphrastic means help guide the construction of the various paraphrases contained in a single item." ></td>
	<td class="line x" title="127:298	There remains the question of how to choose the particular items of the testsuite." ></td>
	<td class="line x" title="128:298	In other words: which semantic representations should we use to populate the test suite and on the basis of which criteria?" ></td>
	<td class="line x" title="129:298	The basic aim here is to cover the various types of possible semantic combinations and the constraints they are subject to at the syntactic (realisation) level." ></td>
	<td class="line x" title="130:298	If, as Beth Levin argues, syntax is a reflex of semantic properties, then different semantic contents should be subject to varying syntactic constraints and the test suite ought to cover these various types of interactions." ></td>
	<td class="line x" title="131:298	Accordingly test items are constructed whose main predicate vary along the following dimensions : (1) WordNet Verb Family; (2) Aspect; (3) Arite That is, items are constructed for each wordNet family (the french WordNet counts roughly 170 such families)." ></td>
	<td class="line x" title="132:298	Within a given family, we attempt to find examples with distinct aspectual categories (state, accomplishment and process)." ></td>
	<td class="line x" title="133:298	Finally, given a WN family and an aspectual category, items will vary with respect to the arity of the main predicate and the types of their arguments e.g., predicates of arity one (run, cost, sleep), of arity two with non propositional arguments (eat, hit, dug), of arity two with a propositional argument (say, promise etc.), etc. 4 A paraphrastic grammar Semantic grammars already exist which describe not only the syntax but also the semantics of natural language." ></td>
	<td class="line x" title="134:298	Thus for instance, (Copestake and Flickinger, 2000; Copestake et al. , 2001) describes a Head Driven Phrase Structure Grammar (HPSG) which supports the parallel construction of a phrase structure (or derived) tree and of a semantic representation and (Dalrymple, 1999) show how to equip Lexical Functional grammar (LFG) with a glue semantics." ></td>
	<td class="line x" title="135:298	These grammars are both efficient and large scale in that they cover an important fragment of the natural language they describe and can be processed by parsers and generators in almost real time." ></td>
	<td class="line x" title="136:298	For instance, the LFG grammar parses sentences from the Wall Street Journal and the ERG HPSG grammar will produce semantic representations for about 83 per cent of the utterances in a corpus of some 10 000 utterances varying in length between one and thirty words." ></td>
	<td class="line x" title="137:298	Parsing times vary between a few ms for short sentences and several tens of seconds for longer ones." ></td>
	<td class="line x" title="138:298	Nonetheless, from a semantics viewpoint, these grammars fail to yield a clear account of the paraphrastic relation." ></td>
	<td class="line x" title="139:298	Here is a simple example illustrating this shortcoming." ></td>
	<td class="line x" title="140:298	Suppose we parse the following paraphrases where a lexical definition (driver person who drives) is involved: (8) a. The person who drives the car is mad." ></td>
	<td class="line x" title="141:298	b. The driver of the car is mad." ></td>
	<td class="line x" title="142:298	When given these sentences, the LKB system based on the ERG HPSG grammar returns semantic representations which can be sketched as follows6: (9) a. the(x, person(x) ^ the(y, car(y) ^ drive(e,x,y) ^ mad(x))) a. the(y, car(y) ^ the(x, driver(x,y) ^ of(x,y)) ^ mad(x)) In other words, the grammar associates with these paraphrases semantic representations which are very different." ></td>
	<td class="line x" title="143:298	It could be argued of course that although these representations are syntactically distinct, they can be inferred, given the appropriate knowledge, to be semantically equivalent." ></td>
	<td class="line x" title="144:298	But a solution that avoids placing such extra burden on the inferencing component is obviously better." ></td>
	<td class="line x" title="145:298	In short, one important shortcoming of existing large scale semantic grammars is that they do not assign semantically equivalent sentences, the same semantic representation." ></td>
	<td class="line x" title="146:298	By contrast, we propose to develop a grammar which whereever possible assigns identical semantic representations to paraphrases and whose devel6These semantic representations have been simplified for better readibility." ></td>
	<td class="line x" title="147:298	The real representations output by the LKB are the following: prpstn(def(x,person(x)^prpstn(def(y,car(y), drive(e1,v1,x,y,v2),v3)), mad(e2,x,v4),v5) prpstn(def(x,person(x)^prpstn(def(y,car(y), drive(e1,v1,x,y,v2),v3)), mad(e2,x,v4),v5) prpstn(def(y,car(y)^prpstn(def(x, driver(x,y) ^ of(e1,x,y,v1), mad(e2,x,v2,v3))))) opment is based both on semantic and syntactic considerations." ></td>
	<td class="line x" title="148:298	4.1 Linguistic framework Our grammar is couched within the Feature-Based Tree Adjoining grammar (FTAG) formalism." ></td>
	<td class="line x" title="149:298	An FTAG consists of a set of (auxiliary or initial) elementary trees and two tree composition operations: substitution and adjunction." ></td>
	<td class="line x" title="150:298	Substitution is the standard tree operation used in phrase structure grammars while adjunction is an operation which inserts an auxiliary tree into a derived tree." ></td>
	<td class="line x" title="151:298	To account for the effect of these insertions, two feature structures (called top and bottom) are associated with each tree node in FTAG." ></td>
	<td class="line x" title="152:298	The top feature structure encodes information that needs to be percolated up the tree should an adjunction take place." ></td>
	<td class="line x" title="153:298	In contrast, the bottom feature structure encodes information that remains local to the node at which adjunction takes place." ></td>
	<td class="line x" title="154:298	The language chosen for semantic representation is a flat semantics along the line of (Bos, 1995; Copestake et al. , 1999; Copestake et al. , 2001)." ></td>
	<td class="line x" title="155:298	However because we are here focusing on paraphrases rather than fine grained semantic distinctions, the underspecification and the description of the scope relations permitted by these semantics will here be largely ignored and flat semantics will be principally used as a convenient way of describing predicate/arguments and modifiers/modified relationships." ></td>
	<td class="line x" title="156:298	Thus the semantic representations we assume are simply set of literals of the form P n(x1; : : : ; xn) where P n is a predicate of arity n and xi is either a constant or a unification variable whose value will be instantiated during processing." ></td>
	<td class="line x" title="157:298	Semantic construction proceeds from the derived tree (Gardent and Kallmeyer, 2003) rather than  as is more common in TAG  from the derivation tree." ></td>
	<td class="line x" title="158:298	This is done by associating each elementary tree with a semantic representation and by decorating relevant tree nodes with unification variables and constants occuring in associated semantic representation." ></td>
	<td class="line x" title="159:298	The association between tree nodes and unification variables encodes the syntax/semantics interface  it specifies which node in the tree provides the value for which variable in the final semantic representation." ></td>
	<td class="line x" title="160:298	As trees combine during derivation, (i) variables are unified  both in the tree and in the associated semantic representation  and (ii) the semantics of the derived tree is constructed from the conjunction of the semantics of the combined trees." ></td>
	<td class="line x" title="161:298	A simple example will illustrate this." ></td>
	<td class="line x" title="162:298	NPj John name(j,john) S NP#x1 VP V NP#x2 NPm loves Mary love(x1,x2) name(m,mary) Figure 2: John loves Mary Suppose the elementary trees for John, loves and Mary are as given in Fig." ></td>
	<td class="line x" title="163:298	2 where a downarrow (#) indicates a substitution node and Cx/Cx abbreviate a node with category C and a top/bottom feature structure including the feature-value pair f index : xg." ></td>
	<td class="line x" title="164:298	On substitution, the root node of the tree being substituted in is unified with the node at which substitution takes place." ></td>
	<td class="line x" title="165:298	Further, when derivation ends, the top and bottom feature structures of each node in the derived tree are unified." ></td>
	<td class="line x" title="166:298	Thus in this case, x1 is unified with j and x2 with m. Hence, the resulting semantics is: love(j; m); name(j; john); name(m; mary) 4.2 The signature of the semantic representation language Let us now come back to the paraphrases given in example 1." ></td>
	<td class="line x" title="167:298	To produce an identical semantic representation of these three sentences, we first need to ensure that synonyms be assigned the same concept." ></td>
	<td class="line x" title="168:298	That is, we need to fix a concept inventory and to use this inventory in a consistent way in particular, by assigning synonyms the same concept." ></td>
	<td class="line x" title="169:298	For non predicative units, we use WordNet synset numbers or when working within a restricted domain with a well defined thesaurus, the descriptors of that thesaurus." ></td>
	<td class="line x" title="170:298	To represent the semantics of predicative units, we use FrameNet inventory of frames and frame elements (C.Johnson et al. , 2002)." ></td>
	<td class="line x" title="171:298	FrameNet is an online lexical resource for English based on the principles of Frame Semantics." ></td>
	<td class="line x" title="172:298	In this approach, a word evokes a frame i.e., a simple or a complex event, and each frame is associated with a number of frame elements that is, a number of participants fulfilling a given role in the frame." ></td>
	<td class="line x" title="173:298	Finally each frame is associated with a set of target words, the words that evoke that frame." ></td>
	<td class="line x" title="174:298	Thus FrameNet associates synonyms with an identical concept namely, the frame evoked by those synonyms." ></td>
	<td class="line x" title="175:298	We make use of this feature and instead of choosing our own semantic predicates and relations, draw on FrameNet frames and frame elements." ></td>
	<td class="line x" title="176:298	For instance, the paraphrases in example 1 are taken to evoke the FrameNet COMMERCE frame and to instantiate two of its frame elements namely, GOODS and MONEY." ></td>
	<td class="line x" title="177:298	The semantic representation they will be assigned will therefore be the following: commerce(e,g,m), cruise(g), goods(e,g), high(m), money(e,m) 4.3 Capturing paraphrastic relations Given the basic signature provided by FrameNet (and any extension of it that will prove necessary to account for the data), the grammar must then specify a compositional semantics which will derive identical representations for the types of paraphrases captured by our typology." ></td>
	<td class="line x" title="178:298	In essence, this implies assigning the same semantic representations to synonyms, converses and alternations." ></td>
	<td class="line x" title="179:298	Concretely, this involves two different subtasks : first, a modeling of the synonymic relation between syntactically divergent constructs (e.g. , between a predicative noun, a support verb construction and a verb) and second, the identification of the synonymic sets (which are the words and multi word expressions that stand in a parallel, shuffling or definitional paraphrastic relation?)." ></td>
	<td class="line x" title="180:298	Modeling intercategorial synonymic links." ></td>
	<td class="line x" title="181:298	A first investigation of Anne Abeilles TAG for French suggests that modeling the synonymic relations across syntactic constructs is reasonably straightforward." ></td>
	<td class="line x" title="182:298	For instance, as Figures 3, 4 and 5 show, the FTAG trees assigned on syntactic grounds by Anne Abeille FTAG to predicative nouns, support verb constructions and transitive verbs can be equiped with a flat semantics in such a way as to assign the three sentences in 1 a unique semantic representation namely the one given above." ></td>
	<td class="line x" title="183:298	Generally, the problem is not so much to state the correspondances between synonymic but syntactically different constructs as to do this in a general way while not overgeneralising." ></td>
	<td class="line x" title="184:298	To address this problem, we are currently working on developing a metagrammar in the sense of (Candito, 1999)." ></td>
	<td class="line x" title="185:298	This metagrammar allows us to factorise both syntactic and semantic information." ></td>
	<td class="line x" title="186:298	Syntactic information is factorised in the usual way." ></td>
	<td class="line x" title="187:298	For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur." ></td>
	<td class="line x" title="188:298	But additionnally there will be semantic classes such as, binary predicate of semantic type X which will be associated with the relevant syntactic classes for instance, NOVN1 (the class of transitive verbs with nominal arguments), BINARY NPRED (the class of binary predicative nouns), NOVSUPNN1, the class of support verb constructions taking two nominal arguments." ></td>
	<td class="line x" title="189:298	By further associating semantic units (e.g. , cost) with the appropriate semantic classes (e.g. , binary predicate of semantic type X), we can in this way capture both intra and intercategorial paraphrasing links in a general way." ></td>
	<td class="line x" title="190:298	Constructing paraphrastic sets." ></td>
	<td class="line x" title="191:298	Depending on the type of paraphrastic means involved, constructing a paraphrastic set (the set of all lexical items related by a paraphrastic link be it parallel, shuffling or definitional) is more or less easy as resources for that specific means may or may not be readily available." ></td>
	<td class="line x" title="192:298	Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available (Ploux, 1997)." ></td>
	<td class="line x" title="193:298	Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries." ></td>
	<td class="line x" title="194:298	For these or for a specific domain, basic synonymic dictionaries can be complemented using learning methods based on distributional similarity (Pereira et al. , 1993; Lin, 1998)." ></td>
	<td class="line x" title="195:298	techniques." ></td>
	<td class="line x" title="196:298	For intercategorial synonymy involving a derivational morphology link, some resources are available which however are only partial in that they only store morphological families that is, sets of items that are morphologically related." ></td>
	<td class="line x" title="197:298	Lexical semantics information still need to be included." ></td>
	<td class="line x" title="198:298	Intercategorial synonymy not involving a derivational morphology link has been little studied and resources are lacking." ></td>
	<td class="line x" title="199:298	However as for other types of synonymy, distributional analysis and clustering techniques can be used to develop such resources." ></td>
	<td class="line x" title="200:298	For shuffling paraphrases, french alternations are partially described in (Saint-Dizier, 1999) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs." ></td>
	<td class="line x" title="201:298	For complementing this database and for converse constructions, the LADL tables (Gross, 1975) can furthermore be resorted to, which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions." ></td>
	<td class="line x" title="202:298	In particular, (Gross, 1989) lists the converses of some 3 500 predicative nouns." ></td>
	<td class="line x" title="203:298	S GNG # V GAdvM # coute GNX S:Commerce GAdvY D NX # (S,G):goods cher la (S,M):money Y:High NX croisiere X:Cruise Figure 3: La croisi`ere coute cher S GNG # VSup# GN a D# NGMGNX cout D NX # D S:Commerce la un (S,M):money NX (S,G):goods croisiere N X:Cruise ? NY Adj eleve Y:High Figure 4: La croisi`ere a un cout eleve 5 Conclusion Besides the development and evaluation of a core paraphrastic testsuite and grammar for French, we plan to investigate two main issues." ></td>
	<td class="line x" title="204:298	First, how precisely should a metagrammar be structured to best describe a paraphrastic grammar?" ></td>
	<td class="line x" title="205:298	And second: is it possible to extract from the kind of inference rules automatically derived in machine learning approach, information that can be used to specify this metagrammar?" ></td>
	<td class="line x" title="206:298	6 Acknowledgments." ></td>
	<td class="line x" title="207:298	This paper is based upon work suppported in part by the project Des connaissances `a leurs realisation en langue within the CNRS funded TCAN program." ></td>
	<td class="line x" title="208:298	S GNY # Cop GAdjY # GNY est eleve D NY # Y:High le NM N GP cout P# GNG # S:Commerce (S,M):money P GNX (S,G):goods de D NX la croisiere X:Cruise Figure 5: Le cout de la croisi`ere est eleve References A. Abeille. 2002." ></td>
	<td class="line x" title="209:298	Une Grammaire Electronique du Franais." ></td>
	<td class="line x" title="210:298	CNRS Editions." ></td>
	<td class="line x" title="211:298	R. Barzilay and L. Lee." ></td>
	<td class="line x" title="212:298	2003." ></td>
	<td class="line x" title="213:298	Learning to paraphrase: an unsupervised approahc using mutliple-sequence alignment." ></td>
	<td class="line x" title="214:298	In Proceedings of NAACL-HLT." ></td>
	<td class="line x" title="215:298	A. Black, S. Abney, D. Flickinger, C. Gdaniec, R. Grishman, P. Harrison, D. Hindel, R. INgria, F. Jelinek, F. Klaavans, M. Liberman, M. Marcus, S. Roukos, B. Santorini, and T. Strzalkowski." ></td>
	<td class="line x" title="216:298	1991." ></td>
	<td class="line x" title="217:298	A procedure for quantitatively comparing the syntactic coverage of english grammars." ></td>
	<td class="line x" title="218:298	In Proceedings of teh 4th DARPA Speech and Natural Language Workshop." ></td>
	<td class="line x" title="219:298	J. Bos." ></td>
	<td class="line x" title="220:298	1995." ></td>
	<td class="line x" title="221:298	Predicate logic unplugged." ></td>
	<td class="line x" title="222:298	In Paul Dekker and Martin Stokhof, editors, Proceedings of the 10th Amsterdam Colloquium, pages 133 142." ></td>
	<td class="line x" title="223:298	M.H Candito." ></td>
	<td class="line x" title="224:298	1999." ></td>
	<td class="line x" title="225:298	Un outil multilingue de generation de ltag : application au francais et a litalien." ></td>
	<td class="line x" title="226:298	TAL, 40(1)." ></td>
	<td class="line x" title="227:298	C.Johnson, C. Fillmore, M. Petruckand C. Baker, M. Ellsworth, and J. Ruppenhofer." ></td>
	<td class="line x" title="228:298	2002." ></td>
	<td class="line x" title="229:298	Framenet: Theory and practice." ></td>
	<td class="line x" title="230:298	Technical report, Berkeley." ></td>
	<td class="line x" title="231:298	Ann Copestake and Dan Flickinger." ></td>
	<td class="line x" title="232:298	2000." ></td>
	<td class="line x" title="233:298	An open source grammar development environment and broad-coverage English grammar using HPSG." ></td>
	<td class="line x" title="234:298	In Proceedings of the 2nd International Conference on Language Resources and Evaluation, Athens, Greece." ></td>
	<td class="line x" title="235:298	A. Copestake, D. Flickinger, I. Sag, and C. Pollard." ></td>
	<td class="line x" title="236:298	1999." ></td>
	<td class="line x" title="237:298	Minimal Recursion Semantics." ></td>
	<td class="line x" title="238:298	An Introduction." ></td>
	<td class="line x" title="239:298	Manuscript, Stanford University." ></td>
	<td class="line x" title="240:298	A. Copestake, A. Lascarides, and D. Flickinger." ></td>
	<td class="line x" title="241:298	2001." ></td>
	<td class="line x" title="242:298	An algebra for semantic construction in constraint-based grammars." ></td>
	<td class="line x" title="243:298	In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, Toulouse, France." ></td>
	<td class="line x" title="244:298	M. Dalrymple." ></td>
	<td class="line x" title="245:298	1999." ></td>
	<td class="line x" title="246:298	Semantics and syntax in lexical functional grammar." ></td>
	<td class="line x" title="247:298	MIT Press." ></td>
	<td class="line x" title="248:298	D. Flickinger, J. Nerbonne, I. Sag, and T. Wasow." ></td>
	<td class="line x" title="249:298	1987." ></td>
	<td class="line x" title="250:298	Towards evaluation of nlp systems." ></td>
	<td class="line x" title="251:298	Technical report, Hewlett-Packard Laboratories." ></td>
	<td class="line x" title="252:298	C. Gardent and L. Kallmeyer." ></td>
	<td class="line x" title="253:298	2003." ></td>
	<td class="line x" title="254:298	Semantic construction in ftag." ></td>
	<td class="line x" title="255:298	In Proceedings of EACL, Budapest, Hungary." ></td>
	<td class="line x" title="256:298	O. Glickman and I. Dagan." ></td>
	<td class="line x" title="257:298	2003." ></td>
	<td class="line x" title="258:298	Identifying lexical paraphrases from a single corpus: a case study for verbs." ></td>
	<td class="line x" title="259:298	In Proceedings of Recent Advances in Natural Language Processing." ></td>
	<td class="line x" title="260:298	M. Gross." ></td>
	<td class="line x" title="261:298	1975." ></td>
	<td class="line x" title="262:298	Methodes en syntase." ></td>
	<td class="line x" title="263:298	Masson, Paris." ></td>
	<td class="line x" title="264:298	G. Gross." ></td>
	<td class="line x" title="265:298	1989." ></td>
	<td class="line x" title="266:298	Les constructions converses du francais." ></td>
	<td class="line x" title="267:298	CNRS Editions." ></td>
	<td class="line x" title="268:298	Dekang Lin and Patrick Pantel." ></td>
	<td class="line x" title="269:298	2001." ></td>
	<td class="line x" title="270:298	Discovery of inference rules for question answering." ></td>
	<td class="line x" title="271:298	Natural Language Engineering." ></td>
	<td class="line x" title="272:298	D. Lin." ></td>
	<td class="line x" title="273:298	1998." ></td>
	<td class="line x" title="274:298	Automatic retrieval and clustering of similar words." ></td>
	<td class="line x" title="275:298	In Proceedings of ACL/COLING, pages 768774." ></td>
	<td class="line x" title="276:298	I. Melcuk." ></td>
	<td class="line x" title="277:298	1988." ></td>
	<td class="line x" title="278:298	Paraphrase et lexique dans la thorie linguistique sens-texte." ></td>
	<td class="line x" title="279:298	Lexique, 6:1354." ></td>
	<td class="line x" title="280:298	S. Oepen and D. Flickinger." ></td>
	<td class="line x" title="281:298	1998." ></td>
	<td class="line x" title="282:298	Towards systematic grammar profiling." ></td>
	<td class="line x" title="283:298	test suite technology 10 years after." ></td>
	<td class="line x" title="284:298	Computer Speech and Language, 12:411435." ></td>
	<td class="line x" title="285:298	F. Pereira, N. Tishby, and L. Lee." ></td>
	<td class="line x" title="286:298	1993." ></td>
	<td class="line x" title="287:298	Distributional clustering of english words." ></td>
	<td class="line x" title="288:298	In Proceedings of the ACL, pages 183190." ></td>
	<td class="line x" title="289:298	S. Ploux." ></td>
	<td class="line x" title="290:298	1997." ></td>
	<td class="line x" title="291:298	Modlisation et traitement informatique de la synonymi." ></td>
	<td class="line x" title="292:298	Linguisticae Investigationes, XXI(1)." ></td>
	<td class="line x" title="293:298	P. Saint-Dizier, 1999." ></td>
	<td class="line x" title="294:298	Alternations and Verb Semantic Classes for French: analysis and class formation, chapter 5." ></td>
	<td class="line x" title="295:298	Kluwer." ></td>
	<td class="line x" title="296:298	Y. Shinyanma, S. Sekine, K. Sudo, and R. Grishman. 2002." ></td>
	<td class="line x" title="297:298	Automatic paraphrase acquisition from news articles." ></td>
	<td class="line x" title="298:298	In Proceedings of HLT ." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I05-5001
Support Vector Machines for Paraphrase Identification and Corpus Construction
Brockett, Chris;Dolan, William B.;"></td>
	<td class="line x" title="1:155	Support Vector Machines for Paraphrase Identification and Corpus Construction Chris Brockett and William B. Dolan Natural Language Processing Group Microsoft Research One Microsoft Way, Redmond, WA 98502, U.S.A. {chrisbkt, billdol}@microsoft.com Abstract The lack of readily-available large corpora of aligned monolingual sentence pairs is a major obstacle to the development of Statistical Machine Translation-based paraphrase models." ></td>
	<td class="line x" title="2:155	In this paper, we describe the use of annotated datasets and Support Vector Machines to induce larger monolingual paraphrase corpora from a comparable corpus of news clusters found on the World Wide Web." ></td>
	<td class="line x" title="3:155	Features include: morphological variants; WordNet synonyms and hypernyms; loglikelihood-based word pairings dynamically obtained from baseline sentence alignments; and formal string features such as word-based edit distance." ></td>
	<td class="line x" title="4:155	Use of this technique dramatically reduces the Alignment Error Rate of the extracted corpora over heuristic methods based on position of the sentences in the text." ></td>
	<td class="line x" title="5:155	1 Introduction Paraphrase detectionthe ability to determine whether or not two formally distinct strings are similar in meaningis increasingly recognized as crucial to future applications in multiple fields including Information Retrieval, Question Answering, and Summarization." ></td>
	<td class="line oc" title="6:155	A growing body of recent research has focused on the problems of identifying and generating paraphrases, e.g., Barzilay & McKeown (2001), Lin & Pantel (2002), Shinyama et al, (2002), Barzilay & Lee (2003), and Pang et al.(2003)." ></td>
	<td class="line x" title="8:155	One promising approach extends standard Statistical Machine Translation (SMT) techniques (e.g. , Brown et al. , 1993; Och & Ney, 2000, 2003) to the problems of monolingual paraphrase identification and generation." ></td>
	<td class="line x" title="9:155	Finch et al.(2004) have described several MT based paraphrase systems within the context of improving machine translation output." ></td>
	<td class="line x" title="11:155	Quirk et al.(2004) describe an end-to-end paraphrase identification and generation system using GIZA++ (Och & Ney, 2003) and a monotone decoder to generate informationpreserving paraphrases." ></td>
	<td class="line x" title="13:155	As with conventional SMT systems, SMTbased paraphrase systems require extensive monolingual parallel training corpora." ></td>
	<td class="line x" title="14:155	However, while translation is a common human activity, resulting in large corpora of human-translated bilingual sentence pairs being relatively easy to obtain across multiple domains and language pairs, this is not the case in monolingual paraphrase, where naturally-occurring parallel data are hard to come by." ></td>
	<td class="line x" title="15:155	The paucity of readily available monolingual parallel training corpora poses a formidable obstacle to the development of SMT-based paraphrase systems." ></td>
	<td class="line x" title="16:155	The present paper describes the extraction of parallel corpora from clustered news articles using annotated seed corpora and an SVM classifier, demonstrating that large parallel corpora can be induced by a classifier that includes morphological and synonymy features derived from both static and dynamic resources." ></td>
	<td class="line x" title="17:155	2 Background Two broad approaches have dominated the literature on constructing paraphrase corpora." ></td>
	<td class="line xc" title="18:155	One 1 approach utilizes multiple translations of a single source language text, where the source language text guarantees semantic equivalence in the target language texts (e.g. , Barzilay & McKeown, 2001; Pang et al. , 2003)." ></td>
	<td class="line x" title="19:155	Such corpora are of limited availability, however, since multiple translations of the same document are uncommon in non-literary domains." ></td>
	<td class="line x" title="20:155	The second strain of corpora construction involves mining paraphrase strings or sentences from news articles, with document clustering typically providing the topical coherence necessary to boost the likelihood that any two arbitrary sentences in the cluster are paraphrases." ></td>
	<td class="line x" title="21:155	In this vein, Shinyama et al.(2002) use named entity anchors to extract paraphrases within a narrow domain." ></td>
	<td class="line oc" title="23:155	Barzilay & Lee (2003) employ Multiple Sequence Alignment (MSA, e.g., Durbin et al. , 1998) to align strings extracted from closely related news articles." ></td>
	<td class="line n" title="24:155	Although the MSA approach can produce dramatic results, it is chiefly effective in extracting highly templatic data, and appears to be of limited extensibility to broad domain application (Quirk et al. 2004)." ></td>
	<td class="line x" title="25:155	Recent work by Dolan, et al.(2004) describes the construction of broad-domain corpora of aligned paraphrase pairs extracted from newscluster data on the World Wide Web using two heuristic strategies: 1) pairing sentences based on a word-based edit distance heuristic; and 2) a naive text-feature-based heuristic in which the first two sentences of each article in a cluster are cross-matched with each other, their assumption being that the early sentences of a news article will tend to summarize the whole article and are thus likely to contain the same information as other early sentences of other articles in the cluster." ></td>
	<td class="line nc" title="27:155	The word-based edit distance heuristic yields pairs that are relatively clean but offer relatively minor rewrites in generation, especially when compared to the MSA model of (Barzilay & Lee, 2003)." ></td>
	<td class="line x" title="28:155	The text-based heuristic, on the other hand, results in a noisy comparable corpus: only 29.7% of sentence pairs are paraphrases, resulting in degraded performance on alignment metrics." ></td>
	<td class="line x" title="29:155	This latter technique, however, does afford large numbers of pairings that are widely divergent at the string level; capturing these is of primary interest to paraphrase research." ></td>
	<td class="line x" title="30:155	In this paper, we use an annotated corpus and an SVM classifier to refine the output of this second heuristic in an attempt to better identify sentence pairs containing richer paraphrase material, and minimize the noise generated by unwanted and irrelevant data." ></td>
	<td class="line x" title="31:155	3 Constructing a Classifier 3.1 Sequential Minimal Optimization Although any of a number of machine learning algorithms, including Decision Trees, might be equally applicable here, Support Vector Machines (Vapnik, 1995) have been extensively used in text classification problems and with considerable success (Dumais 1998; Dumais et al. , 1998; Joachims 2002)." ></td>
	<td class="line x" title="32:155	In particular, SVMs are known to be robust in the face of noisy training data." ></td>
	<td class="line x" title="33:155	Since they permit solutions in high dimensional space, SVMs lend themselves readily to bulk inclusion of lexical features such as morphological and synonymy information." ></td>
	<td class="line x" title="34:155	For our SVM, we employed an off-the-shelf implementation of the Sequential Minimal Optimization (SMO) algorithm described in Platt (1999)." ></td>
	<td class="line x" title="35:155	1 SMO offers the benefit of relatively short training times over very large feature sets, and in particular, appears well suited to handling the sparse features encountered in natural language classification tasks." ></td>
	<td class="line x" title="36:155	SMO has been de1 The pseudocode for SMO may be found in the appendix of Platt (1999) Edit Distance (e  12) San Jose Medical Center announced Wednesday that it would close its doors by Dec. 1, 2004." ></td>
	<td class="line x" title="37:155	San Jose Medical Center has announced that it will close its doors by Dec. 1, 2004." ></td>
	<td class="line x" title="38:155	First Two Sentences The genome of the fungal pathogen that causes Sudden Oak Death has been sequenced by US scientists Researchers announced Thursday they've completed the genetic blueprint of the blight-causing culprit responsible for Sudden Oak Death Table 1." ></td>
	<td class="line x" title="39:155	Paraphrase Examples Identified by Two Heuristics 2 ployed a variety of text classification tasks (e.g. , Dumais 1998; Dumais et al. , 1998)." ></td>
	<td class="line x" title="40:155	3.2 Datasets To construct our corpus, we collected news articles from news clusters on the World Wide Web." ></td>
	<td class="line x" title="41:155	A database of 13,127,938 candidate sentence pairs was assembled from 9,516,684 sentences in 32,408 clusters collected over a 2-year period, using simple heuristics to identify those sentence pairs that were most likely to be paraphrases, and thereby prune the overall search space." ></td>
	<td class="line x" title="42:155	Word-based Levenshtein edit distance of 1 < e  20; and a length ratio > 66%; OR Both sentences in the first three sentences of each file; and length ratio > 50%." ></td>
	<td class="line x" title="43:155	From this database, we extracted three datasets." ></td>
	<td class="line x" title="44:155	The extraction criteria, and characteristics of these datasets are given in Table 2." ></td>
	<td class="line x" title="45:155	The data sets are labled L(evenshtein) 12, F(irst) 2 and F(irst) 3 reflecting their primary selection characteristics." ></td>
	<td class="line x" title="46:155	The L12 dataset represents the best case achieved so far, with Alignment Error Rates beginning to approach those reported for alignment of closely parallel bilingual corpora." ></td>
	<td class="line x" title="47:155	The F2 dataset was constructed from the first two sentences of the corpus on the same assumptions as those used in Dolan et al.(2004)." ></td>
	<td class="line x" title="49:155	To avoid conflating the two data types, however, sentence pairs with an edit distance of 12 or less were excluded." ></td>
	<td class="line x" title="50:155	Since this resulted in a corpus that was significantly smaller than that desirable for exploring extraction techniques, we also created a third data set, F3 that consisted of the cross-pairings of the first three sentences of each article in each cluster, excluding those where the edit distance is e  12." ></td>
	<td class="line x" title="51:155	3.3 Training Data Our training data consisted of 10,000 sentence pairs extracted from randomly held-out clusters and hand-tagged by two annotators according to whether in their judgment (1 or 0) the sentence pairs constituted paraphrases." ></td>
	<td class="line x" title="52:155	The annotators were presented with the sentences pairs in isolation, but were informed that they came from related document sets (clusters)." ></td>
	<td class="line x" title="53:155	A conservative interpretation of valid paraphrase was adopted: if one sentence was a superstring of the other, e.g., if a clause had no counterpart in the other sentence, the pair was counted as a nonparaphrase." ></td>
	<td class="line x" title="54:155	Wherever the two annotators disagreed, the pairs were classed as nonparaphrases." ></td>
	<td class="line x" title="55:155	The resultant data set contains 2968 positive and 7032 negative examples." ></td>
	<td class="line x" title="56:155	3.4 Features Some 264,543 features, including overt lexical pairings, were in theory available to the classifier." ></td>
	<td class="line x" title="57:155	In practice, however, the number of dimensions used typically fell to less than 1000 after the lowest frequency features are eliminated (see Table 4)." ></td>
	<td class="line x" title="58:155	The main feature classes were: String Similarity Features: All sentence pairs were assigned string-based features, including absolute and relative length in words, number of shared words, word-based edit distance, and lexical distance, as measured by converting the sentences into alphabetized strings of unique words and applying word based edit distance." ></td>
	<td class="line x" title="59:155	Morphological Variants: Another class of features was co-ocurrence of morphological variants in sentence pairs." ></td>
	<td class="line x" title="60:155	Approximately 490,000 sentences in our primary datasets were stemmed using a rule-based stemmer, to yield a lexicon of 95,422 morphologically variant word pairs." ></td>
	<td class="line x" title="61:155	Each word pair was treated as a feature." ></td>
	<td class="line x" title="62:155	Examples are: orbit|orbital orbiter|orbiting WordNet Lexical Mappings: Synonyms and hypernyms were extracted from WordNet, L12 F2 F3 Corpus size 253,725 51,933 235,061 Levenshtein edit distance 1 < e  12 e > 12 e > 12 Sentence range in article All First two First three Length 5 < n < 30 5 < n < 30 5 < n < 30 Length ratio 66% 50% 50% Shared words 3 3 3 Table 2." ></td>
	<td class="line x" title="63:155	Characteristics of L(evenshtein) 12, F(irst) 2, and F(irst) 3 Data 3 (http://www.cogsci.princeton.edu/~wn/; Fellbaum, 1998), using the morphological variant lexicon from the 490,000 sentences as keywords." ></td>
	<td class="line x" title="64:155	The theory here is that as additional paraphrase pairs are identified by the classifier, new information will come along for the ride, thereby augmenting the range of paraphrases available to be learned." ></td>
	<td class="line x" title="65:155	A lexicon of 314,924 word pairs of the following form created." ></td>
	<td class="line x" title="66:155	Only those pairs identified as occurring in either training data or the corpus to be classified were included in the final classifier." ></td>
	<td class="line x" title="67:155	operation|procedure operation|work Word Association Pairs: To augment the above resources, we dynamically extracted from the L12 corpus a lexicon of 13001 possibly-synonymous word pairs using a log-likelihood algorithm described in Moore (2001) for machine translation." ></td>
	<td class="line x" title="68:155	To minimize the damping effect of the overwhelming number of identical words, these were deleted from each sentence pair prior to processing; the algorithm was then run on the non-identical residue as if it were a bilingual parallel corpus." ></td>
	<td class="line x" title="69:155	To deploy this data in the SVM feature set, a cutoff was arbitrarily selected that yielded 13001 word pairs." ></td>
	<td class="line x" title="70:155	Some exemplars (not found in WordNet) include: straight|consecutive vendors|suppliers Fig." ></td>
	<td class="line x" title="71:155	1 shows the distribution of word pairings obtained by this method on the L12 corpus in comparison with WordNet." ></td>
	<td class="line x" title="72:155	Examination of the top-ranked 1500 word pairs reveals that 46.53% are found in WordNet and of the remaining 53.47%, human judges rated 56% as good, yielding an overall goodness score of 76.47%." ></td>
	<td class="line x" title="73:155	Judgments were by two independent raters." ></td>
	<td class="line x" title="74:155	For the purposes of comparison, we automatically eliminated pairs containing trivial substring differences, e.g., spelling errors, British vs. American spellings, singular/plural alternations, and miscellaneous short abbreviations." ></td>
	<td class="line x" title="75:155	All pairs on which the raters disagreed were discarded." ></td>
	<td class="line x" title="76:155	Also discarded were a large number of partial phrasal matches of the reported|according and where|which type, where part of a phrase (according to, in which) was missing." ></td>
	<td class="line x" title="77:155	Although viewed in isolation these do not constitute valid synonym or hyperrnym pairs, the ability to identify these partial matchings is of central importance within an SMT-framework of paraphrase alignment and generation." ></td>
	<td class="line x" title="78:155	These results suggest, among other things, that dynamically-generated lexical data of this kind might be useful in increasing the coverage of hand-built synonymy resources." ></td>
	<td class="line x" title="79:155	Composite Features: From each of the lexical feature classes, we derived a set of more abstract features that summarized the frequency with which each feature or class of features occurred in the training data, both independently, and in correlation with others." ></td>
	<td class="line x" title="80:155	These had the effect of performing normalization for sentence length and other factors." ></td>
	<td class="line x" title="81:155	Some examples are: No_of_List_2_Words (i.e. , the count of Wordnet matches) 30.00% 35.00% 40.00% 45.00% 50.00% 55.00% 60.00% 500 100 0 150 0 200 0Word Pairs Not in Wordnet In WordNet Fig." ></td>
	<td class="line x" title="82:155	1." ></td>
	<td class="line x" title="83:155	WordNet Coverage in Word Association Output 4 External_Matches_2_LED (i.e,, the ratio of total lexical matches to Levenshtein edit distance)." ></td>
	<td class="line x" title="84:155	4 Evaluation 4.1 Methodology Evaluation of paraphrase recognition within an SMT framework is highly problematic, since no technique or data set is standardly recognized." ></td>
	<td class="line nc" title="85:155	Barzilay & Lee (2003) and Quirk et al.(2004) use human evaluations of end-to-end generation, but these are not very useful here, since they add an additional layer of uncertainty into the evaluation, and depend to a significant extent on the quality and functionality of the decoder." ></td>
	<td class="line x" title="87:155	Dolan & Brockett (2005) report extraction precision of 67% using a similar classifier, but with the explicit intention of creating a corpus that contained a significant number of naturallyoccuring paraphrase-like negative examples." ></td>
	<td class="line x" title="88:155	Since our purpose in the present work is nonapplication specific corpus construction, we apply an automated technique that is widely used for reporting intermediate results in the SMT community, and is being extended in other fields such as summarization (Daum and Marcu, forthcoming), namely word-level alignment using an off-the-shelf implementation of the SMT system GIZA++ (Och & Ney, 2003)." ></td>
	<td class="line x" title="89:155	Below, we use Alignment Error Rate (AER), which is indicative of how far the corpus is from providing a solution under a standard SMT tool." ></td>
	<td class="line x" title="90:155	This allows the effective coverage of an extracted corpus to be evaluated efficiently, repeatedly against a single standard, and at little cost after the initial tagging." ></td>
	<td class="line x" title="91:155	Further, if used as an objective function, the AER technique offers the prospect of using hillclimbing or other optimization techniques for non-application-specific corpus extraction." ></td>
	<td class="line x" title="92:155	To create the test set, two human annotators created a gold standard word alignment on held out data consisting of 1007 sentences pairs." ></td>
	<td class="line x" title="93:155	Following the practice of Och & Ney (2000, 2003), the annotators each created an initial annotation, categorizing alignments as either SURE (necessary) or POSSIBLE (allowed, but not required)." ></td>
	<td class="line x" title="94:155	In the event of differences, annotators were asked to review their choices." ></td>
	<td class="line x" title="95:155	First pass inter-rater agreement was 90.28%, climbing to 94.43% on the second pass." ></td>
	<td class="line x" title="96:155	Finally we combined the annotations into a single gold standard as follows: if both annotators agreed that an alignment was SURE, it was tagged as SURE in the goldstandard; otherwise it was tagged as POSSIBLE." ></td>
	<td class="line x" title="97:155	To compute Precision, Recall, and Alignment Error Rate (AER), we adhere to the formulae listed in Och & Ney (2003)." ></td>
	<td class="line x" title="98:155	Let A be the set of alignments in the comparison, S be the set of SURE alignments in the gold standard, and P be the union of the SURE and POSSIBLE alignments in the gold standard: || ||precision A PA= ; || ||recall S SA= || ||||AER SA SAPA + += 4.2 Baselines Evaluations were performed on the heuristically-derived L12, F2, and F3 datasets using the above formulation." ></td>
	<td class="line x" title="99:155	Results are shown in Table 3." ></td>
	<td class="line x" title="100:155	L12 represents the best case, followed respectively by F3 and F2." ></td>
	<td class="line x" title="101:155	AERs were also computed separately for identical (Id) and non-identical (Non-Id) word mappings in order to be able to Corpus Size (pairs) Precision Recall AER Id AER Non Id AER L12 ~254 K 87.42% 87.66% 12.46% 11.57% 21.25% F2 ~52 K 85.56% 83.31% 15.57% 13.19% 39.08% F3 ~235K 86.53% 81.57% 15.99% 14.24% 33.83% 10K Trained ~24 K 86.93% 87.24% 12.92% 11.69% 24.70% MSR Trained ~50 K 86.76% 86.39% 13.42% 11.92% 28.31% Table 3." ></td>
	<td class="line x" title="102:155	Precision, Recall and Alignment Error Rates 5 drill down on the extent to which new nonidentical mappings are being learned from the data." ></td>
	<td class="line x" title="103:155	A high Id error rate can be considered indicative of noise in the data." ></td>
	<td class="line x" title="104:155	The score that we are most interested in, however, is the Non-Id alignment error rate, which can be considered indicative of coverage as represented by the Giza++ alignment algorithms ability to learn new mappings from the training data." ></td>
	<td class="line x" title="105:155	It will be observed that the F3 dataset non-Id AER is smaller than that of the F2 dataset: it appears that more data is having the desired effect." ></td>
	<td class="line x" title="106:155	Following accepted SMT practice, we added a lexicon of identical word mappings to the training data, since Giza++ does not directly model word identity, and cannot easily capture the fact that many words in paraphrase sentence may translate as themselves." ></td>
	<td class="line x" title="107:155	We did not add in word pairs derived from word association data or other supplementary resources that might help resolve matches between unlike but semantically similar words." ></td>
	<td class="line x" title="108:155	4.3 Training on the 10K Data We trained an SVM on the 10 K training set employing 3-fold cross-validation on the training set itself." ></td>
	<td class="line x" title="109:155	Validation errors were typically in the region of 16-17%." ></td>
	<td class="line x" title="110:155	Linear kernels with default parameters (tolerance=1e-3; margin size computed automatically; error probability=0.5) were employed throughout." ></td>
	<td class="line x" title="111:155	Applying the SVM to the F3 data, using 946 features encountered in the training data with frequency > 4, this classifier yielded a set of 24588 sentence pairs, which were then aligned using Giza++." ></td>
	<td class="line x" title="112:155	The alignment result is shown in Table 3." ></td>
	<td class="line x" title="113:155	The 10K Trained row represents the results of applying Giza++ to the data extracted by the SVM." ></td>
	<td class="line x" title="114:155	Non-identical word AER, at 24.70%, shows a 36.9% reduction in the non-identical word AER over the F2 dataset (which is approximately double the size), and approximately 28% over the original F3 dataset." ></td>
	<td class="line x" title="115:155	This represents a huge improvement in the quality of the data collected by using the SVM and is within striking distance of the score associated with the L12 best case." ></td>
	<td class="line x" title="116:155	The difference is especially significant when it is considered that the newly constructed corpus is less than one-tenth the size of the best-case corpus." ></td>
	<td class="line x" title="117:155	Table 5 shows sample extracted sentences." ></td>
	<td class="line x" title="118:155	To develop insights into the relative contributions of the different feature classes, we omitted some feature classes from several runs." ></td>
	<td class="line x" title="119:155	The results were generally indistinguishable, except for non-Id AER, shown in Table 4, a fact that may be taken to indicate that string-based features such as edit distance still play a major role." ></td>
	<td class="line x" title="120:155	Eliminating information about morphological alternations has the largest overall impact, producing a degradation of a 0.94 in on Non-Id AER." ></td>
	<td class="line x" title="121:155	Of the three feature classes, removal of WordNet appears to have the least impact, showing the smallest change in Non-Id AER." ></td>
	<td class="line x" title="122:155	When the word association algorithm is applied to the extracted ~24K-sentence-pair set, degradation in word pair quality occurs significantly earlier than observed for the L12 data; after removing trivial matches, 22.63% of word pairs in the top ranked 800 were found in Wordnet, while 25.3% of the remainder were judged to be good matches." ></td>
	<td class="line x" title="123:155	This is equivalent to an overall goodness score of 38.25%." ></td>
	<td class="line x" title="124:155	The rapid degradation of goodness may be in part attributable to the smaller corpus size yielded by the classifier." ></td>
	<td class="line x" title="125:155	Nevertheless, the model learns many valid new word pairs." ></td>
	<td class="line x" title="126:155	Given enough data with which to bootstrap, it may be possible to do away with static resources such as Wordnet, and rely entirely on dynamically derived data." ></td>
	<td class="line x" title="127:155	4.4 Training on the MSR Training Set By way of comparison, we also explored application of the SVM to the training data in the MSR Paraphrase corpus." ></td>
	<td class="line x" title="128:155	For this purpose we used the 4076-sentence-pair training section of the MSR corpus, comprising 2753 positive and 1323 negative examples." ></td>
	<td class="line x" title="129:155	The results at default parameter settings are given in Table 3, with respect to all features that were observed to occur with frequency greater than 4." ></td>
	<td class="line x" title="130:155	Although the 49914 sentence pairs yielded by using the g14967 g14967 Dimensions Non Id AER All (fq > 4) 946 24.70 No Lexical Pairs 230 25.35 No Word Association 470 25.35 No WordNet 795 25.24 No Morphology 813 25.64 Table 4." ></td>
	<td class="line x" title="131:155	Effect of Eliminating Feature Classes on 10K Training Set 6 MSR Paraphrase Corpus is nearly twice that of the 10K training set, AER performance is measurably degraded." ></td>
	<td class="line x" title="132:155	Nevertheless, the MSR-trained corpus outperforms the similar-sized F12, yielding a reduction in Non-Id AER of a not insignificant 16%." ></td>
	<td class="line x" title="133:155	The fact that the MSR training data does not perform as well as the 10 K training set probably reflects its derivative nature, since it was originally constructed with data collected using the 10K training set, as described in Dolan & Brockett (2005)." ></td>
	<td class="line x" title="134:155	The performance of the MSR corpus is therefore skewed to reflect the biases inherent in its original training, and therefore exhibits the performance degradation commonly associated with bootstrapping." ></td>
	<td class="line x" title="135:155	It is also a significantly smaller training set, with a higher proportion of negative examples than in typical in real world data." ></td>
	<td class="line x" title="136:155	It will probably be necessary to augment the MSR training corpus with further negative examples before it can be utilized effectively for training classifiers." ></td>
	<td class="line x" title="137:155	5 Discussion and Future Work These results show that it is possible to use machine learning techniques to induce a corpus of likely sentential paraphrase pairs whose alignment properties measured in terms of AER approach those of a much larger, more homogeneous dataset collected using a stringedit distance heuristic." ></td>
	<td class="line x" title="138:155	This result supports the idea that an abstract notion of paraphrase can be captured in a high dimensional model." ></td>
	<td class="line x" title="139:155	Future work will revolve around optimizing classifiers for different domains, corpus types and training sets." ></td>
	<td class="line xc" title="140:155	It seems probable that the effect of the 10K training corpus can be greatly augmented by adding sentence pairs that have been aligned from multiple translations using the techniques described in, e.g., Barzilay & McKeown (2001) and Pang et al.(2003)." ></td>
	<td class="line x" title="142:155	6 Conclusions We have shown that supervised machine learning techniques such as SVMs can significantly expand available paraphrase corpora, and achieve a reduction of noise as measured by AER on non-identical words." ></td>
	<td class="line x" title="143:155	Although from the present research has focused on ready-made news clusters found on the web, nothing in this paper depends on the availability of such clusters." ></td>
	<td class="line x" title="144:155	Given standard clustering techniques, the approach that we have described for inductive classifier learning should in principle be applicable to any flat corpus which contains multiple sentences expressing similar content." ></td>
	<td class="line x" title="145:155	We expect also that the techniques described here could be extended to identify bilingual sentence pairs in comparable corpora, helping automate the construction of corpora for machine translation." ></td>
	<td class="line x" title="146:155	The ultimate test of paraphrase identification technologies lies in applications." ></td>
	<td class="line x" title="147:155	These are likely to be in fields such as extractive multidocument summarization where paraphrase detection might eliminate sentences with comparable content and Question Answering, for both identifying sentence pairs with comparable content and generating unique new text." ></td>
	<td class="line x" title="148:155	Such pracyoung female chimps learn skills earlier, spend more time studying and tend to do better than young male chimpanzees at least when it comes to catching termites." ></td>
	<td class="line x" title="149:155	young female chimpanzees are better students than males, at least when it comes to catching termites, according to a study of wild chimps in tanzania 's gombe national park . Paraphrase (accepted)g14967 a %%number%% -year-old girl was arrested, handcuffed and taken into custody on charges of stealing a rabbit and a small amount of money from a neighbor 's home . sheriff 's deputies in pasco county, ffla., this week handcuffed and questioned a %%number%% -year-old girl who was accused of stealing a rabbit and %%money%% from a neighbor 's home . NonParaphrase (rejected) roy moore, the chief justice of alabama, installed the two-ton sculpture in the rotunda of his courthouse in montgomery, and has refused to remove it . the eight associate justices of alabama 's supreme court voted unanimously %%day%% to overrule moore and comply with u.s. district judge myron thompson 's order to remove the monument . Table 5." ></td>
	<td class="line x" title="151:155	Sample Pairs Extracted and Rejected by the SVM Trained on the 10K Corpus 7 tical applications will only be possible once large corpora are available to permit the development of robust paraphrase models on the scale of the best SMT models." ></td>
	<td class="line x" title="152:155	We believe that the corpus construction techniques that we have described here represent an important contribution to this goal." ></td>
	<td class="line x" title="153:155	Acknowledgements We would like to thank Monica Corston-Oliver, Jeff Stevenson, Amy Muia and Margaret Salome of Butler Hill Group LLC for their assistance in annotating and evaluating our data." ></td>
	<td class="line x" title="154:155	This paper has also benefited from feedback from several anonymous reviewers." ></td>
	<td class="line x" title="155:155	All errors and omissions are our own." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I05-5002
Automatically Constructing a Corpus of Sentential Paraphrases
Dolan, William B.;Brockett, Chris;"></td>
	<td class="line x" title="1:264	Automatically Constructing a Corpus of Sentential Paraphrases William B. Dolan and Chris Brockett Natural Language Processing Group Microsoft Research Redmond, WA, 98052, USA {billdol,chrisbkt}@microsoft.com Abstract An obstacle to research in automatic paraphrase identification and generation is the lack of large-scale, publiclyavailable labeled corpora of sentential paraphrases." ></td>
	<td class="line x" title="2:264	This paper describes the creation of the recently-released Microsoft Research Paraphrase Corpus, which contains 5801 sentence pairs, each hand-labeled with a binary judgment as to whether the pair constitutes a paraphrase." ></td>
	<td class="line x" title="3:264	The corpus was created using heuristic extraction techniques in conjunction with an SVM-based classifier to select likely sentence-level paraphrases from a large corpus of topicclustered news data." ></td>
	<td class="line x" title="4:264	These pairs were then submitted to human judges, who confirmed that 67% were in fact semantically equivalent." ></td>
	<td class="line x" title="5:264	In addition to describing the corpus itself, we explore a number of issues that arose in defining guidelines for the human raters." ></td>
	<td class="line x" title="6:264	1 Introduction The Microsoft Research Paraphrase Corpus (MSRP), available for download at http://research.microsoft.com/research/nlp/msr_ paraphrase.htm, consists of 5801 pairs of sentences, each accompanied by a binary judgment indicating whether human raters considered the pair of sentences to be similar enough in meaning to be considered close paraphrases." ></td>
	<td class="line x" title="7:264	This data has been published for the purpose of encouraging research in areas relating to paraphrase and sentential synonymy and inference, and to help establish a discourse on the proper construction of paraphrase corpora for training and evaluation." ></td>
	<td class="line x" title="8:264	It is hoped that by releasing this corpus, we will stimulate the publication of similar corpora by others and help move the field toward adoption of a shared dataset that will permit useful comparisons of results across research efforts." ></td>
	<td class="line pc" title="9:264	g2 2 Motivation The success of Statistical Machine Translation (SMT) has sparked a successful line of investigation that treats paraphrase acquisition and generation essentially as a monolingual machine translation problem (e.g. , Barzilay & Lee, 2003; Pang et al. , 2003; Quirk et al. , 2004; Finch et al. , 2004)." ></td>
	<td class="line n" title="10:264	However, a lack of standardly-accepted corpora on which to train and evaluate models is a major stumbling block to the successful application of SMT models or other machine learning algorithms to paraphrase tasks." ></td>
	<td class="line x" title="11:264	Since paraphrase is not apparently a common natural taskunder normal circumstances people do not attempt to create extended paraphrase textsthe field lacks a large readily identifiable dataset comparable to, for example, the Canadian Hansard corpus in SMT that can serve as a standard against which algorithms can be trained and evaluated." ></td>
	<td class="line x" title="12:264	What paraphrase data is currently available is usually too small to be viable for either training or testing, or exhibits narrow topic coverage, limiting its broad-domain applicability." ></td>
	<td class="line x" title="13:264	One class of paraphrase data that is relatively widely available is multiple translations of sentences in a second language." ></td>
	<td class="line x" title="14:264	These, however, tend to be rather restricted in their domain (e.g. the ATR English-Chinese paraphrase corpus, which con9 sists of translations of travel phrases (Zhang & Yamamoto, 2002)), are limited to short handcrafted predicates (e.g. the ATR JapaneseEnglish corpus (Shirai, et al. , 2002)), or exhibit quality problems stemming from insufficient command of the target language by the translators of the documents in question, e.g. the Linguistic Data Consortiums Multiple-Translation Chinese Corpus (Huang et al. , 2002)." ></td>
	<td class="line x" title="15:264	Multiple translations of novels, such as those used in (Barzilay & McKeown, 2001) provide a relatively limited dataset to work with, and  since these usually involve works that are out of copyright  usually exhibit older styles of language that have little in common with modern language resources or application requirements." ></td>
	<td class="line nc" title="16:264	Likewise, the data made available by (Barzilay & Lee, 2003: http://www.cs.cornell.edu/ Info/Projects/NLP/statpar.html), while invaluable in understanding and evaluating their results, is too limited in size and domain coverage to serve as either training or test data." ></td>
	<td class="line x" title="17:264	Attempting to evaluate models of paraphrase acquisition and generation under limitations can thus be an exercise in frustration." ></td>
	<td class="line x" title="18:264	Accordingly, we have tried to create a reasonably large corpus of naturally-occurring, non-handcrafted sentence pairs, along with accompanying human judgments, that can be used as a resource for training or testing purposes." ></td>
	<td class="line x" title="19:264	Since the search space for identifying any two sentence pairs occurring in the wild is huge, and provides far too many negative examples for humans to wade through, clustered news articles were used to constrain the initial search space to data that was likely to yield paraphrase pairs." ></td>
	<td class="line x" title="20:264	3 Source Data The Microsoft Research Paraphrase Corpus (MSRP) is distilled from a database of 13,127,938 sentence pairs, extracted from 9,516,684 sentences in 32,408 news clusters collected from the World Wide Web over a 2year period, The methods and assumptions used in building this initial data set are discussed in Quirk et al.(2004) and Dolan et al.(2004)." ></td>
	<td class="line x" title="23:264	Two heuristics based on shared lexical properties and sentence position in the document were employed to construct the initial database: Word-based Levenshtein edit distance of 1 < e g1157 20; and a length ratio > 66%; OR Both sentences in the first three sentences of each file; and length ratio > 50%." ></td>
	<td class="line x" title="24:264	Within this initial dataset we were able to automatically identify the names of both authors and copyright holders of 61,618 articles.1 Limiting ourselves only to sentences found in those articles, we further narrowed the range of candidate pairs using the following criteria: The number of words in both sentences in words is 5  n  40; The two sentences shared at least three words in common; The length of the shorter of the two sentences, in words, is at least 66.6% that of the longer; and The two sentences had a bag-of-words lexical distance of e  8 edits." ></td>
	<td class="line x" title="25:264	This enabled us extract a set of 49,375 initial candidate sentence pairs whose author was known, The purpose of these heuristics was two-fold: 1) to narrow the search space for subsequent application of the classifier algorithm and human evaluation, and 2) to ensure at least some diversity among the sentences." ></td>
	<td class="line x" title="26:264	In particular, we sought to exclude the large number of sentence pairs whose differences might be attributable only to typographical errors, variance between British and American spellings, and minor editorial variations." ></td>
	<td class="line x" title="27:264	Lexical distance was computed by constructing an alphabetized list of unique vocabulary items from each of the sentences and measuring the number of insertions and deletions." ></td>
	<td class="line x" title="28:264	Note that the number of sentence pairs collected in this first pass was relatively small compared with the overall size of the dataset; the requirement of author identification significantly circumscribed the available dataset." ></td>
	<td class="line x" title="29:264	1 Author identification was performed on the basis of pattern matching datelines and other textual information." ></td>
	<td class="line x" title="30:264	We made a strong effort to ensure correct attribution." ></td>
	<td class="line x" title="31:264	10 4 Constructing a Classifier 4.1 Sequential Minimal Optimization To extract candidate pairs from this ~49K list, we used a Support Vector Machine." ></td>
	<td class="line x" title="32:264	(Vapnik, 1995), in this case an implementation of the Sequential Minimal Optimization (SMO) algorithm described in Platt (1999),2 which has been shown to be useful in text classification tasks (Dumais 1998; Dumais et al. , 1998)." ></td>
	<td class="line x" title="33:264	4.2 Training Set A separate set of 10,000 sentence pairs had previously been extracted from randomly heldout clusters and hand-tagged by two annotators according to whether the sentence pairs constituted paraphrases." ></td>
	<td class="line x" title="34:264	This yielded a set of 2968 positive examples and 7032 negative examples." ></td>
	<td class="line x" title="35:264	The sentences represented a random mixture of held out sentences; no attempt was made to match their characteristics to those of the candidate data set." ></td>
	<td class="line x" title="36:264	4.3 Classifiers In the classifier we restricted the feature set to a small set of feature classes." ></td>
	<td class="line x" title="37:264	The main classes are given below." ></td>
	<td class="line x" title="38:264	More details can be found in Brockett and Dolan (2005)." ></td>
	<td class="line x" title="39:264	String Similarity Features: Absolute and relative length in words, number of shared words, word-based edit distance, and bagof-words-based lexical distance." ></td>
	<td class="line x" title="40:264	Morphological Variants: A morphological variant lexicon consisting of 95,422 word pairs was created using a hand-crafted stemmer." ></td>
	<td class="line x" title="41:264	Each pair is then treated as a feature in the classifier." ></td>
	<td class="line x" title="42:264	WordNet Lexical Mappings: 314,924 word synonyms and hypernym pairs were extracted from WordNet, (Fellbaum, 1998; http://www.cogsci.princeton.edu/~wn/)." ></td>
	<td class="line x" title="43:264	Only pairs identified as occurring in either training data or the corpus to be classified were included in the final classifier." ></td>
	<td class="line x" title="44:264	2 The pseudocode for SMO may be found in the appendix of Platt (1999) Encarta Thesaurus: 125,054 word synonym pairs were extracted from the Encarta Thesaurus (Rooney, 2001)." ></td>
	<td class="line x" title="45:264	Composite Features: Additional, more abstract features summarized the frequency with which each feature or class of features occurred in the training data, both independently, and in correlation with other features or feature classes." ></td>
	<td class="line x" title="46:264	4.4 Results of Applying the Classifier Since our purpose was not to evaluate the potential effectiveness of the classifier itself, but to identify a reasonably large set of both positive and plausible near-miss negative examples, the classifier was applied with output probabilities deliberately skewed towards overidentification, i.e., towards Type 1 errors, assuming non-paraphrase (0) as null hypothesis." ></td>
	<td class="line x" title="47:264	This yielded 20,574 pairs out the initial 49,375pair data set, from which 5801 pairs were then further randomly selected for human assessment." ></td>
	<td class="line x" title="48:264	5 Human Evaluation The 5801 sentences selected by the classifier as likely paraphrase pairs were examined by two independent human judges." ></td>
	<td class="line x" title="49:264	Each judge was asked whether the two sentences could be considered semantically equivalent." ></td>
	<td class="line x" title="50:264	Disagreements were resolved by a 3rd judge, with the final binary judgment reflecting the majority vote.3 After resolving differences between raters, 3900 (67%) of the original pairs were judged semantically equivalent." ></td>
	<td class="line x" title="51:264	5.1 Semantic Divergence In many instances, the two sentences judged semantically equivalent in fact diverge semantically to at least some degree." ></td>
	<td class="line x" title="52:264	For instance, both judges considered the following two to be paraphrases: 3 This annotation task was carried out by an independent company, the Butler Hill Group, LLC." ></td>
	<td class="line x" title="53:264	Monica CorstonOliver directed the effort, with Jeff Stevenson, Amy Muia, and David Rojas acting as raters." ></td>
	<td class="line x" title="54:264	11 Charles O. Prince, 53, was named as Mr. Weills successor." ></td>
	<td class="line x" title="55:264	Mr. Weills longtime confidant, Charles O. Prince, 53, was named as his successor." ></td>
	<td class="line x" title="56:264	If a full paraphrase relationship can be described as bidirectional entailment, then the majority of the equivalent pairs in this dataset exhibit mostly bidirectional entailments, with one sentence containing information that differs from or is not contained in the other." ></td>
	<td class="line x" title="57:264	Our decision to adopt this relatively loose tagging criterion was ultimately a practical one: insisting on complete sets of bidirectional entailments would have limited the dataset to pairs of sentences that are practically identical at the string level, as in the following examples." ></td>
	<td class="line x" title="58:264	The euro rose above US$1.18, the highest price since its January 1999 launch." ></td>
	<td class="line x" title="59:264	The euro rose above $1.18 the highest level since its launch in January 1999." ></td>
	<td class="line x" title="60:264	However, without a carefully controlled study, there was little clear proof that the operation actually improves peoples lives." ></td>
	<td class="line x" title="61:264	But without a carefully controlled study, there was little clear proof that the operation improves peoples lives." ></td>
	<td class="line x" title="62:264	Such pairs are commonplace in the raw data, reflecting the tendency of news agencies to publish and republish the same articles, with editors introducing small and often inexplicable changes (is however really better than but)?" ></td>
	<td class="line x" title="63:264	along the way." ></td>
	<td class="line x" title="64:264	The resulting alternations are useful sources of information about synonymy and local syntactic changes, but our goal was to produce a richer type of corpus; one that provides information about the large-scale alternations that typify complex paraphrases.4 4 Recall that in an effort to focus on sentence pairs that are not simply trivial variants of some original single source, we restricted our original dataset by removing all pairs with a minimum word-based Levenshtein distance of  8." ></td>
	<td class="line x" title="65:264	5.2 Complex Alternations Some sentence pairs in the news data capture complex and full paraphrase alternations: Wynn paid $23.5 million for Renoirs In the Roses (Madame Leon Clapisson) at a Sotheby auction on Tuesday Wynn nabbed Renoirs In the Roses (Madame Leon Clapisson) for $23.5 on Tuesday at Sothebys Far more frequently, however, interesting paraphrases in the data are accompanied by at least minor differences in content: David Gest has sued his estranged wife Liza Minelli for %MONEY% million for beating him when she was drunk Liza Minellis estranged husband is taking her to court for %MONEY% million after saying she threw a lamp at him and beat him in drunken rages It quickly became clear, that in order to collect significant numbers of sentential paraphrase pairs, our standards for what constitutes semantic equivalence would have to be relaxed." ></td>
	<td class="line x" title="66:264	5.3 Rater Instructions Raters were told to use their best judgment in deciding whether 2 sentences, at a high level, mean the same thing." ></td>
	<td class="line x" title="67:264	Under our relatively loose definition of semantic equivalence, any 2 of the following sentences would have qualified as paraphrases, despite obvious differences in information content: The genome of the fungal pathogen that causes Sudden Oak Death has been sequenced by US scientists Researchers announced Thursday they've completed the genetic blueprint of the blight-causing culprit responsible for sudden oak death Scientists have figured out the complete genetic code of a virulent pathogen that has killed tens 12 of thousands of California native oaks The East Bay-based Joint Genome Institute said Thursday it has unraveled the genetic blueprint for the diseases that cause the sudden death of oak trees Several classes of named entities were replaced by generic tags in sentences presented to the raters, so that Tuesday became %%DAY%%, $10,000 became %%MONEY%%, and so on." ></td>
	<td class="line x" title="68:264	In the released version of the dataset, however, these placeholders were replaced by the original strings." ></td>
	<td class="line x" title="69:264	After a good deal of trial-and-error, some specific rating criteria were developed and included in a tagging specification." ></td>
	<td class="line x" title="70:264	For the most part, though, the degree of mismatch allowed before the pair was judged non-equivalent was left to the discretion of the individual rater: did a particular set of asymmetries alter the meanings of the sentences so much that they could not be regarded as paraphrases?" ></td>
	<td class="line x" title="71:264	The following sentences, for example, were judged not equivalent despite some significant content overlap: The Gerontology Research Group said Slough was born on %DATE%, making her %NUMBER% years old at the time of her death." ></td>
	<td class="line x" title="72:264	[Mrs. Slough] is the oldest living American as of the time she died, L. Stephen Coles, Executive Director of the Gerontology Research Group, said %DATE%." ></td>
	<td class="line x" title="73:264	The tagging task was ill-defined enough that we were surprised at how high inter-rater agreement was (averaging 84%)." ></td>
	<td class="line x" title="74:264	The Kappa score of 62 is good, but low enough to be indicative of the difficulty of the rating task." ></td>
	<td class="line x" title="75:264	We believe that with more practice and discussion between raters, agreement on the task could be improved." ></td>
	<td class="line x" title="76:264	Interestingly, a series of experiments aimed at making the judging task more concrete resulted in uniformly degraded inter-rater agreement." ></td>
	<td class="line x" title="77:264	Providing a checkbox to allow judges to specify that one sentence fully entailed another, for instance, left the raters frustrated, slowed down the tagging, and had a negative impact on agreement." ></td>
	<td class="line x" title="78:264	Similarly, efforts to identify classes of syntactic alternations that would not count against an equivalent judgment resulted, in most cases, in a collapse in inter-rater agreement." ></td>
	<td class="line x" title="79:264	After completing hundreds of judgments, the raters themselves were asked for suggestions as to what checkboxes or instructions might improve tagging speed and accuracy." ></td>
	<td class="line x" title="80:264	In the end, few generalizations seemed useful in streamlining the task; each pair is sufficiently idiosyncratic that that common sense has to take precedence over formal guidelines." ></td>
	<td class="line x" title="81:264	In a few cases, firm tagging guidelines were found to be useful." ></td>
	<td class="line x" title="82:264	One example was the treatment of pronominal and NP anaphora." ></td>
	<td class="line x" title="83:264	Raters were instructed to treat anaphors and their full forms as equivalent, regardless of how great the disparity in length or lexical content between the two sentences." ></td>
	<td class="line x" title="84:264	(Often these correspondences are extremely interesting, and in sufficient quantity would provide interesting fodder for learning models of anaphora)." ></td>
	<td class="line x" title="85:264	SCC argued that Lexmark was trying to shield itself from competition The company also argued that Lexmark was trying to squash competition But Secretary of State Colin Powell brushed off this possibility %%day%%." ></td>
	<td class="line x" title="86:264	Secretary of State Colin Powell last week ruled out a nonaggression treaty." ></td>
	<td class="line x" title="87:264	Note that many of the 33% of sentence pairs judged to be not equivalent still overlap significantly in information content and even wording." ></td>
	<td class="line x" title="88:264	These pairs reflect a range of relationships, from pairs that are completely unrelated semantically, to those that are partially overlapping, to those that are almost-but-not-quite semantically equivalent." ></td>
	<td class="line x" title="89:264	6 Discussion Given that MSRP reflects both the initial heuristics and the SVM methodology that was employed to identify paraphrase candidates for human evaluation, it is also limited by that technology." ></td>
	<td class="line x" title="90:264	The 67% ratio of positive to negative judgments is a reasonably reliable indicator of the precision of our technique--though it should 13 be recalled that parameters were deliberately distorted to yield imprecise results that included positive and a large number of near-miss negatives." ></td>
	<td class="line x" title="91:264	Coverage is hard to estimate reliably." ></td>
	<td class="line x" title="92:264	we calculate that fewer than 30% of the pairs in a set of matched first-two sentences extracted from clustered news data, after application of simple heuristics, are paraphrases (Dolan et al. , 2004)." ></td>
	<td class="line x" title="93:264	It seems reasonable to assume that the reduction to 10% seen in the initial data set still leaves many valid paraphrase pairs uncaptured in the corpus." ></td>
	<td class="line x" title="94:264	The need to limit the corpus to those sentences for which authorship can be verified, and more specifically." ></td>
	<td class="line x" title="95:264	to no more than a single sentence extracted from each article." ></td>
	<td class="line x" title="96:264	further constrains the coverage in ways whose consequences are not yet known." ></td>
	<td class="line x" title="97:264	In addition, the three-shared-words heuristic further guarantees that an entire class of paraphrases in which no words are shared in common have been excluded from the data." ></td>
	<td class="line x" title="98:264	It has been observed that the mean lexical overlap in the corpus is a relatively high 0.7 (Weeds et al, 2005), suggesting that more lexically divergent examples will be needed." ></td>
	<td class="line x" title="99:264	In these respects, as Wu (2005) points out, the corpus is far from distributionally neutral." ></td>
	<td class="line x" title="100:264	This is a matter that we hope to remedy in the future, since in many ways this excluded set of pairs is the most interesting of all." ></td>
	<td class="line x" title="101:264	The above limitations, together with its relatively small size, perhaps make the MRSP inappropriate for direct use as a training corpus." ></td>
	<td class="line x" title="102:264	We show separately that the results of training a classifier on the present corpus may be inferior to other training sets, though better than crude string or text-based heuristics (Brockett & Dolan, 2005)." ></td>
	<td class="line x" title="103:264	We expect that the utility of the corpus will stem primarily from its use as a tool for evaluating paraphrase recognition algorithms." ></td>
	<td class="line x" title="104:264	It has already been applied in this way by Corley & Mihalcea (2005) and Wu (2005)." ></td>
	<td class="line x" title="105:264	7 A Virtual Super Corpus?" ></td>
	<td class="line x" title="106:264	Although larger than any other non-translationbased labeled paraphrase corpus currently publicly available, MSRP is tiny compared with the huge bilingual parallel corpora publicly available within the Machine Translation community, for example, the Canadian Hansards, the Hong Kong Parliamentary corpus, or the United Nations documents." ></td>
	<td class="line x" title="107:264	It is improbable that we will ever encounter a naturally occurring paraphrase corpus on the scale of any of these bilingual corpora." ></td>
	<td class="line x" title="108:264	Moreover, whatever extraction technique is employed to identify paraphrases in other kinds of data will be apt to reflect the implicit biases of the methodology employed." ></td>
	<td class="line x" title="109:264	Here we would like to put forward a proposal." ></td>
	<td class="line x" title="110:264	The paraphrase research community might be able to construct a virtual paraphrase corpus that would be adequately large for both training and testing purposes and minimize selectional biases." ></td>
	<td class="line x" title="111:264	This could be achieved in something like the following manner." ></td>
	<td class="line x" title="112:264	Research groups could compile their own labeled paraphrase corpora, applying whatever learning techniques they choose to select their initial data." ></td>
	<td class="line x" title="113:264	If enough interested groups were to release a sufficiently large number of reasonably-sized corpora, it might be possible to achieve some sort consensus, in a manner analogous to the division of the Penn Treebank into sections, whereby classifiers and other tools are conventionally trained on one subset of corpora, and tested against another subset." ></td>
	<td class="line x" title="114:264	Though this would present issues of its own, it would obviate many of the problems of extraction bias inherent in automated extraction, and allow better cross comparison across systems." ></td>
	<td class="line x" title="115:264	8 Future Directions For our part we plan to expand the MSRP, both by extending the number of sentence pairs, and also improving the balance of positive and negative examples." ></td>
	<td class="line x" title="116:264	We anticipate using multiple classifiers to reduce inherent biases in candidate corpus selection, and with better author identification to ensure proper attribution, to be able to draw on a larger dataset for consideration by our judges." ></td>
	<td class="line x" title="117:264	In future releases we expect to make available more information about individual evaluator judgments." ></td>
	<td class="line x" title="118:264	Burger & Ferro (2005) have suggested that this data may allow researchers greater freedom to construct models based on the judgments of specific judges or combinations of judges, permitting more fine-grained use of the corpus." ></td>
	<td class="line x" title="119:264	One further issue that we will also be attempting to address is the need to provide a better metric for corpus coverage and quality." ></td>
	<td class="line x" title="120:264	Until reliable metrics can be established for end-to14 end paraphrase tasksthese will probably need to be application specificthe Alignment Error Rate strategy that was successfully applied in early development of machine translation systems (Och & Ney, 2000, 2003) offers a useful intermediate representation of the coverage and precision of a corpus and extraction techniques." ></td>
	<td class="line x" title="121:264	Though fullscale reliability studies have yet to be performed, the AER technique is already finding application in other fields such as summarization (Daum & Marcu, forthcoming)." ></td>
	<td class="line x" title="122:264	We expect to be able to provide a reasonably large corpus of word-aligned paraphrase sentences in the near future that we hope will serve as some sort of standard by which corpus extraction techniques can be measured and compared in a uniform fashion." ></td>
	<td class="line x" title="123:264	One other path that we are concurrently exploring is collection and validation of paraphrase data by volunteers on the web." ></td>
	<td class="line x" title="124:264	Some initial efforts using game formats for elicitation are presented in Chklovski (2005) and Brockett & Dolan (2005)." ></td>
	<td class="line x" title="125:264	It is our hope that web volunteers will prove a useful source of colloquial paraphrases of written text, andif paraphrase identification can be effectively embedded in the gameof paraphrase judgments." ></td>
	<td class="line x" title="126:264	9 Conclusion We have used heuristic techniques and a classifier to automatically create a corpus of 5801 naturally occurring (non-constructed) sentence pairs, labeled according to whether, in the judgment of our evaluators, the sentences mean the same thing or not." ></td>
	<td class="line x" title="127:264	To our knowledge, MSRP constitutes the largest currently-available broaddomain corpus of paraphrase pairs that does not have its origins in translations from another language." ></td>
	<td class="line x" title="128:264	We hope that others will utilize it, find it useful, and provide feedback when it is not." ></td>
	<td class="line x" title="129:264	The methodology that we have described for extracting this corpus is readily adaptable by others, and is not limited to news clusters, but can be readily extended to any flat corpus containing a large number of semantically similar sentences on which topic-based document clustering is possible." ></td>
	<td class="line x" title="130:264	We have shown that by allowing a statistical learning algorithm to constrain the search space, it is possible to identify a manageable-sized candidate corpus on the basis of which human judges can label sentence pairs for paraphrase content quickly and in a cost effective manner." ></td>
	<td class="line x" title="131:264	We hope that others will follow our example." ></td>
	<td class="line x" title="132:264	Acknowledgements We would like to thank Monica Corston-Oliver, Jeff Stevenson, Amy Muia and David Rojas of Butler Hill Group LLC for their assistance in annotating the Microsoft Research Paraphrase Corpus and in preparing the seed data used for training." ></td>
	<td class="line x" title="133:264	This paper has also benefited from feedback from several anonymous reviewers." ></td>
	<td class="line x" title="134:264	All errors and omissions are our own.g2 References Regina Barzilay and Katherine." ></td>
	<td class="line x" title="135:264	R. McKeown." ></td>
	<td class="line x" title="136:264	2001." ></td>
	<td class="line x" title="137:264	Extracting Paraphrases from a parallel corpus." ></td>
	<td class="line x" title="138:264	In Proceedings of the ACL/EACL." ></td>
	<td class="line x" title="139:264	Regina Barzilay and Lillian Lee." ></td>
	<td class="line x" title="140:264	2003." ></td>
	<td class="line x" title="141:264	Learning to Paraphrase; an unsupervised approach using multiple-sequence alignment." ></td>
	<td class="line x" title="142:264	In Proceedings of HLT/NAACL 2003." ></td>
	<td class="line x" title="143:264	Chris Brockett and William B. Dolan." ></td>
	<td class="line x" title="144:264	2005." ></td>
	<td class="line x" title="145:264	Support Vector Machines for Paraphrase Identification and Corpus Construction." ></td>
	<td class="line x" title="146:264	In Proceedings of The Third International Workshop on Paraphrasing (IWP2005), Jeju, Republic of Korea." ></td>
	<td class="line x" title="147:264	Chris Brockett and William B. Dolan." ></td>
	<td class="line x" title="148:264	2005." ></td>
	<td class="line x" title="149:264	Echo Chamber: A Game for Eliciting a Colloquial Paraphrase Corpus." ></td>
	<td class="line x" title="150:264	AAAI 2005 Spring Symposium, Knowledge Collection from Volunteer Contributors (KCVC05)." ></td>
	<td class="line x" title="151:264	Stanford, CA." ></td>
	<td class="line x" title="152:264	March 21-23, 2005." ></td>
	<td class="line x" title="153:264	P. Brown, S. A. Della Pietra, V.J. Della Pietra and R. L. Mercer." ></td>
	<td class="line x" title="154:264	1993." ></td>
	<td class="line x" title="155:264	The Mathematics of Statistical Machine Translation." ></td>
	<td class="line x" title="156:264	Computational Linguistics, Vol." ></td>
	<td class="line x" title="157:264	19(2): 263-311." ></td>
	<td class="line x" title="158:264	John Burger and Lisa Ferro." ></td>
	<td class="line x" title="159:264	2005." ></td>
	<td class="line x" title="160:264	Generating an Entailment Corpus from News Headlines." ></td>
	<td class="line x" title="161:264	In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment." ></td>
	<td class="line x" title="162:264	pp 49-54." ></td>
	<td class="line x" title="163:264	Timothy Chklovski." ></td>
	<td class="line x" title="164:264	2005 1001 Paraphrases: Incenting Responsible Contributions in Collecting Paraphrases from Volunteers." ></td>
	<td class="line x" title="165:264	AAAI 2005 Spring Symposium, Knowledge Collection from Volunteer Contributors (KCVC05)." ></td>
	<td class="line x" title="166:264	Stanford, CA." ></td>
	<td class="line x" title="167:264	March 2123, 2005." ></td>
	<td class="line x" title="168:264	Courtney Courley and Rada Mihalcea." ></td>
	<td class="line x" title="169:264	2005." ></td>
	<td class="line x" title="170:264	Measuring the Semantic Similarity of Texts." ></td>
	<td class="line x" title="171:264	In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment." ></td>
	<td class="line x" title="172:264	Pp 1318." ></td>
	<td class="line x" title="173:264	Hal Daum III and Daniel Marcu." ></td>
	<td class="line x" title="174:264	(forthcoming) Induction of Word and Phrase Alignments for 15 Automatic Document Summarization." ></td>
	<td class="line x" title="175:264	To appear in Computational Linguistics." ></td>
	<td class="line x" title="176:264	William." ></td>
	<td class="line x" title="177:264	B. Dolan, Chris Quirk, and Chris Brockett." ></td>
	<td class="line x" title="178:264	2004." ></td>
	<td class="line x" title="179:264	Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources." ></td>
	<td class="line x" title="180:264	Proceedings of COLING 2004, Geneva, Switzerland." ></td>
	<td class="line x" title="181:264	Susan Dumais." ></td>
	<td class="line x" title="182:264	1998." ></td>
	<td class="line x" title="183:264	Using SVMs for Text Categorization." ></td>
	<td class="line x" title="184:264	IEEE Intelligent Systems, Jul.-Aug. 1998: 21-23 Susan Dumais, John Platt, David Heckerman, Mehran Sahami." ></td>
	<td class="line x" title="185:264	1998." ></td>
	<td class="line x" title="186:264	Inductive learning algorithms and representations for text categorization." ></td>
	<td class="line x" title="187:264	In Proceedings of the Seventh International Conference on Information and Knowledge Management." ></td>
	<td class="line x" title="188:264	Christiane Fellbaum (ed.)." ></td>
	<td class="line x" title="189:264	1998." ></td>
	<td class="line x" title="190:264	WordNet: An Electronic Lexical Database." ></td>
	<td class="line x" title="191:264	The MIT Press." ></td>
	<td class="line x" title="192:264	Andrew Finch, Taro Watanabe, Yasuhiro Akiba and Eiichiro Sumita." ></td>
	<td class="line x" title="193:264	2004." ></td>
	<td class="line x" title="194:264	Paraphrasing as Machine Translation." ></td>
	<td class="line x" title="195:264	Journal of Natural Language Processing, 11(5), pp 87-111." ></td>
	<td class="line x" title="196:264	Pascale Fung and Percy Cheung." ></td>
	<td class="line x" title="197:264	2004." ></td>
	<td class="line x" title="198:264	Multi-level Bootstrapping for Extracting Parallel Sentences from a Quasi-Comparable Corpus." ></td>
	<td class="line x" title="199:264	In Proceedings of Coling 2004, 1051-1057." ></td>
	<td class="line x" title="200:264	Shudong Huang, David Graff, and George Doddington (eds)." ></td>
	<td class="line x" title="201:264	2002." ></td>
	<td class="line x" title="202:264	Multiple-Translation Chinese Corpus." ></td>
	<td class="line x" title="203:264	Linguistic Data Consortium." ></td>
	<td class="line x" title="204:264	Thorsten Joachims." ></td>
	<td class="line x" title="205:264	2002." ></td>
	<td class="line x" title="206:264	Learning to Classify Text Using Support Vector Machines: Methods, Theory, and Algorithms." ></td>
	<td class="line x" title="207:264	Kluwer Academic Publishers, Boston/Dordrecht/London." ></td>
	<td class="line x" title="208:264	V. Levenshtein." ></td>
	<td class="line x" title="209:264	1966." ></td>
	<td class="line x" title="210:264	Binary codes capable of correcting deletions, insertions, and reversals." ></td>
	<td class="line x" title="211:264	Soviet Physice-Doklady 10: 707-710." ></td>
	<td class="line x" title="212:264	Microsoft Research Paraphrase Corpus." ></td>
	<td class="line x" title="213:264	http://research.microsoft.com/research/downloads/ default.aspx Franz Joseph Och and H. Ney." ></td>
	<td class="line x" title="214:264	2000." ></td>
	<td class="line x" title="215:264	Improved Statistical Alignment Models." ></td>
	<td class="line x" title="216:264	In Proceedings of the 38th Annual Meeting of the ACL, Hong Kong, China, pp 440-447." ></td>
	<td class="line x" title="217:264	Franz Joseph Och and Hermann Ney." ></td>
	<td class="line x" title="218:264	2003." ></td>
	<td class="line x" title="219:264	A Systematic Comparison of Various Statistical Alignment Models." ></td>
	<td class="line x" title="220:264	Computational Linguistics, 29 (1): 19-52." ></td>
	<td class="line x" title="221:264	Bo Pang, Kevin Knight, and Daniel Marcu." ></td>
	<td class="line x" title="222:264	2003." ></td>
	<td class="line x" title="223:264	Syntax-based Alignment of Multiple Translations: Extracting Paraphrases and Generating New Sentences." ></td>
	<td class="line x" title="224:264	In Proceedings of NAACL-HLT." ></td>
	<td class="line x" title="225:264	John C. Platt." ></td>
	<td class="line x" title="226:264	1999." ></td>
	<td class="line x" title="227:264	Fast Training of Support Vector Machines Using Sequential Minimal Optimization." ></td>
	<td class="line x" title="228:264	In Bernhard Schlkopf, Christopher J. C. Burges and Alexander J. Smola (eds.)." ></td>
	<td class="line x" title="229:264	1999." ></td>
	<td class="line x" title="230:264	Advances in Kernel Methods: Support Vector Learning." ></td>
	<td class="line x" title="231:264	The MIT Press, Cambridge, MA." ></td>
	<td class="line x" title="232:264	185-208." ></td>
	<td class="line x" title="233:264	Chris Quirk, Chris Brockett, and William B. Dolan." ></td>
	<td class="line x" title="234:264	2004." ></td>
	<td class="line x" title="235:264	Monolingual Machine Translation for Paraphrase Generation, In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, 25-26 July 2004, Barcelona Spain, pp." ></td>
	<td class="line x" title="236:264	142-149." ></td>
	<td class="line x" title="237:264	Kathy Rooney (ed)." ></td>
	<td class="line x" title="238:264	2001." ></td>
	<td class="line x" title="239:264	Encarta Thesaurus." ></td>
	<td class="line x" title="240:264	Bloomsbury Publishing." ></td>
	<td class="line x" title="241:264	Satoshi Shirai, Kazuhide Yamamoto, Francis Bond & Hozumi Tanaka." ></td>
	<td class="line x" title="242:264	2002." ></td>
	<td class="line x" title="243:264	Towards a thesaurus of predicates." ></td>
	<td class="line x" title="244:264	In Proceedings of LREC 2002 (Third International Conference on Language Resources and Evaluation), (May 29-31, 2002)." ></td>
	<td class="line x" title="245:264	Vol.6, pp." ></td>
	<td class="line x" title="246:264	1965-1972." ></td>
	<td class="line x" title="247:264	Vladimir N. Vapnik." ></td>
	<td class="line x" title="248:264	1995." ></td>
	<td class="line x" title="249:264	The Nature of Statistical Learning Theory." ></td>
	<td class="line x" title="250:264	Springer-Verlag, New York." ></td>
	<td class="line x" title="251:264	Julie Weeds, David Weir and Bill Keller." ></td>
	<td class="line x" title="252:264	2005." ></td>
	<td class="line x" title="253:264	The Distributional Similarity of Subparses." ></td>
	<td class="line x" title="254:264	In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment." ></td>
	<td class="line x" title="255:264	pp 7-12." ></td>
	<td class="line x" title="256:264	Dekai Wu." ></td>
	<td class="line x" title="257:264	2005." ></td>
	<td class="line x" title="258:264	Recognizing Paraphrases and Textual Entailment using Inversion Transduction Grammars." ></td>
	<td class="line x" title="259:264	In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment." ></td>
	<td class="line x" title="260:264	Pp 25-30." ></td>
	<td class="line x" title="261:264	Yujie Zhang and Kazuhide Yamamoto." ></td>
	<td class="line x" title="262:264	2002 Paraphrasing of Chinese Utterances." ></td>
	<td class="line x" title="263:264	Proceedings of Coling 2002, pp.1163-1169." ></td>
	<td class="line x" title="264:264	16" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I05-5004
A Class-oriented Approach to Building a Paraphrase Corpus
Fujita, Atsushi;Inui, Kentaro;"></td>
	<td class="line x" title="1:184	A Class-oriented Approach to Building a Paraphrase Corpus Atsushi Fujita Graduate School of Informatics, Kyoto University fujita@pine.kuee.kyoto-u.ac.jp Kentaro Inui Graduate School of Information Science, Nara Institute of Science and Technology inui@is.naist.jp Abstract Towards deep analysis of compositional classes of paraphrases, we have examined a class-oriented framework for collecting paraphrase examples, in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement." ></td>
	<td class="line x" title="2:184	Our preliminary experiments on building a paraphrase corpus have so far been producing promising results, which we have evaluated according to cost-efficiency, exhaustiveness, and reliability." ></td>
	<td class="line x" title="3:184	1 Introduction Paraphrases are alternative ways of conveying the same content." ></td>
	<td class="line x" title="4:184	The technology for paraphrase generation and recognition has drawn the attention of an increasing number of researchers because of its potential contribution toabroadrange of natural language applications." ></td>
	<td class="line x" title="5:184	Paraphrases can be viewed as monolingual translations." ></td>
	<td class="line xc" title="6:184	From this viewpoint, research on paraphrasing has adapted techniques fostered in the literature of machine translation (MT), such as transformation algorithms (Lavoie et al. , 2000; Takahashi et al. , 2001), corpus-based techniques for paraphrase pattern acquisition (Barzilay and McKeown, 2001; Shinyama and Sekine, 2003; Quirk et al. , 2004), and fluency measurements (Lapata, 2001; Fujita et al. , 2004)." ></td>
	<td class="line x" title="7:184	One thing the paraphrasing community is still lacking is shared collections of paraphrase examples that could be used to analyze problems underlying the tasks and to evaluate the performance of systemsunder development." ></td>
	<td class="line x" title="8:184	Toour best knowledge, the paraphrase corpus developed by Dolan et al.(2004) is one of the very few collections available for free1." ></td>
	<td class="line x" title="10:184	Development of paraphrase corpora raises several issues: what sorts of paraphrases should be collected, where paraphrase examples can be obtained from, how the coverageandqualityof thecorpuscanbeensured, how manual annotation cost can be effectively reduced, and how collected examples should be organized and annotated." ></td>
	<td class="line x" title="11:184	Obviously these issues should be discussed with the purpose of each individual corpus taken into account." ></td>
	<td class="line x" title="12:184	In this paper, we address the issues of building a gold-standard corpus that is to be used to evaluate paraphrase generation models and report on our preliminary experiences taking Japanese as a target language." ></td>
	<td class="line x" title="13:184	Our approach is characterized by the following: We define a set of paraphrase classes based on the syntactic features of transformation patterns." ></td>
	<td class="line x" title="14:184	We separately collect paraphrase examples for each paraphrase class that are considered to be linguistically explainable." ></td>
	<td class="line x" title="15:184	We use a paraphrase generation system to exhaustively collect candidate paraphrases from a given text collection, which are then manually labeled." ></td>
	<td class="line x" title="16:184	15801 sentence pairs from their comparable corpus have been judged manually and available from http://research.microsoft.com/research/nlp/msr paraphrase.htm 25 2 Goal Paraphrases exhibit a wide variety of patterns ranging from lexical paraphrases to syntactic transformations and their combinations." ></td>
	<td class="line x" title="17:184	Some of them are highly inferential or idiomatic and do not seem easy to generate only with syntactic and semantic knowledge." ></td>
	<td class="line x" title="18:184	Such groups of paraphrasesrequireustopursuecorpus-basedacquisition methods such asthosedescribedin Section 3." ></td>
	<td class="line x" title="19:184	More importantly, however, we can also find quite a few patterns of paraphrases that exhibit a degree of regularity." ></td>
	<td class="line x" title="20:184	Those groups of paraphrases have a potential to be compositionally explained by combining syntactic and semantic properties of their constituent words." ></td>
	<td class="line x" title="21:184	For instance, the followingparaphrases2 inJapaneseareconsideredto be of these groups." ></td>
	<td class="line x" title="22:184	(1) s. eiga-ni shigeki-o uke-ta." ></td>
	<td class="line x" title="23:184	film-DAT inspiration-ACC to receive-PAST I received an inspiration from the film." ></td>
	<td class="line x" title="24:184	t. eiga-ni shigeki-s-are-ta." ></td>
	<td class="line x" title="25:184	film-DAT to inspire-PASS-PAST I was inspired by the film." ></td>
	<td class="line x" title="26:184	(2) s. sentakumono-ga soyokaze-ni yureru." ></td>
	<td class="line x" title="27:184	laundry-NOM breeze-DAT to sway-PRES The laundry sways in the breeze." ></td>
	<td class="line x" title="28:184	t. soyokaze-ga sentakumono-o yurasu." ></td>
	<td class="line x" title="29:184	breeze-NOM laundry-ACC to sway-PRES The breeze makes the laundry sways." ></td>
	<td class="line x" title="30:184	(3) s. glass-ni mizu-o mitashi-ta." ></td>
	<td class="line x" title="31:184	glass-DAT water-ACC to fill-PAST I filled water into the glass." ></td>
	<td class="line x" title="32:184	t. glass-o mizu-de mitashi-ta." ></td>
	<td class="line x" title="33:184	glass-ACC water-IMP to fill-PAST I filled the glass with water." ></td>
	<td class="line x" title="34:184	(4) s. kare-wa kikai-sousa-ga jouzu-da." ></td>
	<td class="line x" title="35:184	he-TOP machine operation-NOM be good-PRES He is good at machine operation." ></td>
	<td class="line x" title="36:184	t. kare-wa kikai-o jouzu-ni sousa-suru." ></td>
	<td class="line x" title="37:184	he-TOP machine-ACC well-ADV to operate-PRES He operates machines well." ></td>
	<td class="line x" title="38:184	(5) s. heya-wa mou atatamat-teiru." ></td>
	<td class="line x" title="39:184	room-TOP already to be warmed-PERF The room has already been warmed up." ></td>
	<td class="line x" title="40:184	t. heya-wa mou atatakai." ></td>
	<td class="line x" title="41:184	room-TOP already be warm-PRES The room is warm." ></td>
	<td class="line x" title="42:184	2For each example, s and t denote an original sentence and its paraphrase, respectively." ></td>
	<td class="line x" title="43:184	In example (1), a verb phrase, shigeki-o uketa (to receive an inspiration), is paraphrased into a verbalized form of the noun, shigeki-s-are-ta (to be inspired). We can find a number of paraphrases that exhibit a similar pattern of syntactic transformation in the same language and group such paraphrases into a single class, which is possibly labeled paraphrasing of light-verb construction. Likewise, paraphrases exemplified by (2) constitute another class, so-called transitivity alternation." ></td>
	<td class="line x" title="44:184	Example (3) is of the locative alternation class and example (4) the compound noun decomposition class." ></td>
	<td class="line x" title="45:184	In example (5), a verb atatamaru (to be warmed) is paraphrased into its adjective form, atatakai (be warm). Paraphrases involving such a lexical derivation are also in our concern." ></td>
	<td class="line x" title="46:184	One can learn the existence of such groups of paraphrases and the regularity each group exhibits from the linguistic literature (Melcuk and Polgu`ere, 1987; Jackendoff, 1990; Kageyama, 2001)." ></td>
	<td class="line x" title="47:184	According to Jackendoff and Kageyama, for instance, both transitivityalternation and locative alternation can be explained in terms of the syntactic and semantic properties of the verb involved, which are represented by what they call Lexical Conceptual Structure." ></td>
	<td class="line x" title="48:184	The systematicity underlying such linguistic accounts is intriguing also from the engineering point of view asit could enable us to take a more theoretically motivated but still practical approach to paraphrase generation." ></td>
	<td class="line x" title="49:184	Aiming at this goal leads us to consider building a paraphrase corpus which enables us to evaluate paraphrase generation systems and conduct error analysis for each paraphrase class separately." ></td>
	<td class="line x" title="50:184	Our paraphrase corpus should therefore be organized according to paraphrase classes." ></td>
	<td class="line x" title="51:184	More specifically, weconsider aparaphrasecorpussuch that: The corpus consists of a set of subcorpora." ></td>
	<td class="line x" title="52:184	Each subcorpus is a collection of paraphrase sentence pairs of a paraphrase class." ></td>
	<td class="line x" title="53:184	Paraphrases collected in a subcorpus sufficiently reflect the distribution of the occurrences in the real world." ></td>
	<td class="line x" title="54:184	Given a paraphrase class and a text collection, the goal of building a paraphrase corpus is to collect paraphrase examples belonging to the class 26 as exhaustively as possible from the text collection at a minimal human labor cost." ></td>
	<td class="line x" title="55:184	The resultant corpus should also be reliable." ></td>
	<td class="line x" title="56:184	3 Related work Previous work on building paraphrase corpus (collecting paraphraseexamples) canbeclassified into two directions: manual production of paraphrases and automatic paraphrase acquisition." ></td>
	<td class="line x" title="57:184	3.1 Manual production of paraphrases Manual production of paraphrase examples has been carried out in MT studies." ></td>
	<td class="line x" title="58:184	For example, Shirai et al.(2001) and Kinjo et al.(2003) use collections of JapaneseEnglish translation sentence pairs." ></td>
	<td class="line x" title="61:184	Given translation pairs, annotators are asked to produce new translations for each side of the languages." ></td>
	<td class="line x" title="62:184	Sentences that have an identical translation are collected as equivalents, i.e., paraphrases." ></td>
	<td class="line x" title="63:184	Shimohata (2004), on the other hand, takes a simpler approach in which he asks annotators to produce paraphrases of a given set of English sentences." ></td>
	<td class="line x" title="64:184	Obviously, if we simply asked human annotators to produce paraphrases of a given set of sentences, the labor cost would be expensive while the coverage not guaranteed." ></td>
	<td class="line x" title="65:184	Previous work, however, has averted their eyes from evaluating the cost-efficiency of the method and the coverage of the collected paraphrases supposedly because their primary concern was to enhance MT systems." ></td>
	<td class="line x" title="66:184	3.2 Automatic paraphrase acquisition Recently, paraphrase examples have been automatically collected as a source of acquiring paraphrase knowledge, such as pairs of synonymous phrases and syntactic transformation templates." ></td>
	<td class="line oc" title="67:184	Some studies exploit topically related articles derived from multiple news sources (Barzilay and Lee, 2003; Shinyama and Sekine, 2003; Quirk et al. , 2004; Dolan et al. , 2004)." ></td>
	<td class="line x" title="68:184	Sentence pairs that are likely to be paraphrases are automatically collected from the parallel or comparable corpora, using such clues as overlaps of content words and named entities, syntactic similarity, and reference description, such as date of the article and positions of sentences in the articles." ></td>
	<td class="line x" title="69:184	Automatic acquisition from parallel or comparable corpora, possibly in combination with manual correction, could be more cost-efficient than manual production." ></td>
	<td class="line x" title="70:184	However, it would not ensure coverage and quality, because sentence pairingalgorithms virtually limit the range of obtainable paraphrases and products tend to be noisy." ></td>
	<td class="line x" title="71:184	Nevertheless, automatic methods are useful to discover a variety of paraphrases that need further exploration." ></td>
	<td class="line x" title="72:184	We hope that our approach to corpus construction, which we present below, will work complementary to those directions of research." ></td>
	<td class="line x" title="73:184	4 Proposed method Recall that we require a corpus that reflects the distribution of the occurrences of potential paraphrases of each class because we aim to use it for linguistic analysis and quantitative evaluation of paraphrase generation models." ></td>
	<td class="line x" title="74:184	Since the issues weaddress here are highly empirical, we need to empirically examine a range of possible methods to gain useful methodological insights." ></td>
	<td class="line x" title="75:184	As an initial attempt, we have so far examined asimplemethod which falls in the middle of the aforementioned two approaches." ></td>
	<td class="line x" title="76:184	The method makes use of an existing paraphrase generation system to reduce human labor cost as well as to ensure coverage and quality: Step 1." ></td>
	<td class="line x" title="77:184	For a given paraphrase class, develop a set of morpho-syntactic paraphrasing patterns and lexical resources." ></td>
	<td class="line x" title="78:184	Step 2." ></td>
	<td class="line x" title="79:184	Apply the patterns to a given text collection using the paraphrasing system to generate a set of candidate paraphrases." ></td>
	<td class="line x" title="80:184	Step 3." ></td>
	<td class="line x" title="81:184	Annotate each candidate paraphrase with information of the appropriateness according to a set of judgement criteria." ></td>
	<td class="line x" title="82:184	Weusemorpho-syntacticparaphrasingpatterns derived from paraphrase samples in an analogous way to previous methods such as (Dras, 1999)." ></td>
	<td class="line x" title="83:184	For instance, from example (1), we derive a paraphrasing pattern for paraphrasing of light-verb constructions: (6) s. N-o(V ) V N-ACC V t. V (N) V (N) whereN is avariable which matcheswith a noun, V a verb, V (N) denotes the verbalized form of 27 (e) confirmed (revised) paraphrase ( ) fir (r i ) r r (c) annotators judge (correct / incorrect) ( ) t t r j ( rr t / i rr t) (d) error tags( ) rr r t (a) source sentence( ) r t (b) automatically generated paraphrase ( ) t ti ll r t r r (c) second opinion (correct / incorrect) ( ) i i ( rr t / i rr t) Given Obligatory Obligatory Optional (f) free comments(f) fr t Optional Figure 1: Annotation schema." ></td>
	<td class="line x" title="84:184	N, and the subscriptedarrowin (6s) indicates that N-o depends on V. To exhaustively collect paraphrase examples from a given text collection, we should not excessively constrain paraphrasing patterns." ></td>
	<td class="line x" title="85:184	To avoid overly generating anomalies, on the other hand, we make use of several lexical resources." ></td>
	<td class="line x" title="86:184	For instance, pairs of a deverbal noun and its transitive form are used to constrainN andV (N) in pattern (6)." ></td>
	<td class="line x" title="87:184	This way, we combine syntactic transformation patterns with lexical constraints to specify a paraphrase class." ></td>
	<td class="line x" title="88:184	This approach is practical given the recent advances of shallow parsers." ></td>
	<td class="line x" title="89:184	ForthejudgementonappropriatenessinStep3, we create a set of criteria separately for each paraphrase class." ></td>
	<td class="line x" title="90:184	When the paraphrase class in focus is specified, the range of potential errors in candidate generation tends to be predictable." ></td>
	<td class="line x" title="91:184	We therefore specify judgement criteria in terms of a typology of potential errors (Fujita and Inui, 2003); namely, we provide annotators with a set of conditions for ruling out inappropriate paraphrases." ></td>
	<td class="line x" title="92:184	Annotators judge each candidate paraphrase with a view of an RDB-based annotation tool (Figure 1)." ></td>
	<td class="line x" title="93:184	Given (a) a source sentence and (b) an automatically generated candidate paraphrase, human annotators are asked to (c) judge the appropriateness of it and, if it is inappropriate, they are also asked to (d) classify the underlying errors into a predefined taxonomy, and make (e) appropriate revisions (if possible) and (f) format-free comments." ></td>
	<td class="line x" title="94:184	5 Preliminary trials To examine how the proposed method actually work regarding the issues, we conducted preliminary trials, taking two classes of Japanese paraphrases: paraphrasing of light-verb constructions and transitivity alternation." ></td>
	<td class="line x" title="95:184	This section describes the settings for each paraphrase class." ></td>
	<td class="line x" title="96:184	We sampled a collection of source sentences from one year worth of newspaper articles: Nihon Keizai Shinbun3, 2000, where the average sentence length was 25.3 words." ></td>
	<td class="line x" title="97:184	The reason why we selected newspaper articles as a sample source was that most of the publicly available shallow parsers for Japanese were trained on a tree-bank sampled from newspaper articles, and a newspaper corpus was available in a considerably large scale." ></td>
	<td class="line x" title="98:184	We used for candidate generation the morphologicalanalyzer ChaSen4,thedependency structure analyzer CaboCha5, and the paraphrase generation system KURA6." ></td>
	<td class="line x" title="99:184	Two native speakers of Japanese, adults graduated from university, were employed as annotators." ></td>
	<td class="line x" title="100:184	The process of judging each candidate paraphrase is illustrated in Figure 2." ></td>
	<td class="line x" title="101:184	The first annotator was asked to make judgements on each candidate paraphrase." ></td>
	<td class="line x" title="102:184	The second annotator inspected all the candidates judged correct by the first an3http://sub.nikkeish.co.jp/gengo/zenbun.htm 4http://chasen.naist.jp/ 5http://chasen.org/taku/software/cabocha/ 6http://cl.naist.jp/kura/doc/ 28 Candidate paraphrase i t r r Correct Incorrect 1st annotator 2nd annotator Correct Incorrect Correct Incorrect Correct Deferred Incorrect Discussion Unseen Deferredf Correctt IncorrectI t Label Figure 2: Judgement procedure." ></td>
	<td class="line x" title="103:184	notator." ></td>
	<td class="line x" title="104:184	To reduce the labor cost, only a small subset of candidates that the first annotator judged incorrect were checked by the second annotator, leaving the rest labeled incorrect." ></td>
	<td class="line x" title="105:184	Once in several days,theannotatorsdiscussedcasesonwhich they disagreed, and if possible revised the annotation criteria." ></td>
	<td class="line x" title="106:184	When the discussion did not reach a consensus, the judgement was deferred." ></td>
	<td class="line x" title="107:184	5.1 Paraphrasing of light-verb constructions (LVC) An example of this class is given in (1)." ></td>
	<td class="line x" title="108:184	A lightverb construction consists of a deverbal noun (shigeki (inspiration) in example (1)) governed by a light-verb (ukeru (to receive))." ></td>
	<td class="line x" title="109:184	A paraphrase of this class is a pair of a light-verb construction and its unmarked form, which consists of the verbalized form of the deverbal noun where the light-verb is removed." ></td>
	<td class="line x" title="110:184	Let N, V be a deverbal noun and a verb, and V (N) be the verbalized form of N. Paraphrases of this class can be represented by the following paraphrasing pattern: (7) s. N-{ga, o, ni}(V ) V N-{NOM, ACC, DAT} V t. V (N) V (N) In the experiment, we used three more patterns to gain the coverage." ></td>
	<td class="line x" title="111:184	We then extracted 20,155 pairs of deverbal noun and its verbalized form (e.g. shigeki (inspiration) and shigeki-suru (to inspire)) from the Japanese word dictionary, IPADIC (version 2.6.3)3." ></td>
	<td class="line x" title="112:184	This set was used as a restriction on nouns that can match with N in a paraphrasing pattern." ></td>
	<td class="line x" title="113:184	On the other hand, we made no restriction on V, because we had no exhaustive list of light-verbs." ></td>
	<td class="line x" title="114:184	The patterns were automatically compiled into pairs of dependency trees with uninstantiated components, and were applied to source sentences with the paraphrase generation system, which carried out dependency structurebased pattern matching." ></td>
	<td class="line x" title="115:184	2,566 candidate paraphrases were generated from 10,000 source sentences." ></td>
	<td class="line x" title="116:184	In the judgement phase, the annotators were also asked to revise erroneous candidates if possible." ></td>
	<td class="line x" title="117:184	The following revision operations were allowed for LVC: Change of conjugations Change of case markers Insert adverbs Append verbal suffixes, such as voice, aspect, or mood devices When pattern (7) is applied to sentence (1s), for instance, weneedtoaddavoicedevice, are(passive), to correctly produce (1t)." ></td>
	<td class="line x" title="118:184	In example (8), on the other hand, an aspectual device, dasu (inchoative), is appended, and a case marker, no (GEN), is replaced with o (ACC). (8) s. concert-no ticket-no hanbai-o hajime-ta." ></td>
	<td class="line x" title="119:184	concert-GEN ticket-GEN sale-ACC to start-PAST We started to sale tickets for concerts." ></td>
	<td class="line x" title="120:184	t. concert-no ticket-o hanbai-shi-dashi-ta." ></td>
	<td class="line x" title="121:184	concert-GEN ticket-ACC to sell-INCHOATIVE-PAST We started selling tickets for concerts." ></td>
	<td class="line x" title="122:184	So far, 1,114 candidates have been judged7 with agreements on 1,067 candidates, and 591 paraphrase examples have been collected." ></td>
	<td class="line x" title="123:184	5.2 Transitivity alternation (TransAlt) This class of paraphrases requires a collection of pairs of intransitive and transitive verbs, such as yureru (to sway) and yurasu (to sway) in example (2)." ></td>
	<td class="line x" title="124:184	Since there was no available resource of such knowledge, we newly created a minimal set of intransitive-transitive pairs that were required to cover all the verbs appearing in the source sentence set (25,000 sentences)." ></td>
	<td class="line x" title="125:184	We first retrieved all the verbs from the source sentences using a set of extraction patterns implemented in the same manner as paraphrasing patterns." ></td>
	<td class="line x" title="126:184	Example (9) is one of the patterns used, where Nx matches with a noun, and V a verb." ></td>
	<td class="line x" title="127:184	7983 candidates for the first 4,500 sentences were fully judged, and 131 candidates were randomly sampled from the remaining portion." ></td>
	<td class="line x" title="128:184	29 (9) s. N1-ga(V ) N2-ni(V ) V N1-NOM N2-DAT V t. no change." ></td>
	<td class="line x" title="129:184	We then manually examined the transitivity of each of 800 verbs that matched with V, and collected212 pairsof intransitiveverbvi and itstransitive form vt. Using them as constraints, we implemented eight paraphrasing patterns as in (10)." ></td>
	<td class="line x" title="130:184	(10) s. N1-ga(Vi) N2-ni(Vi) Vi N1-NOM N2-DAT Vi t. N2-ga(Vt(Vi)) N1-o(Vt(Vi)) Vt(Vi) N2-NOM N1-ACC Vt(Vi) where Vi and Vt(Vi) are variables that match with vi and vt, respectively." ></td>
	<td class="line x" title="131:184	By applying the patterns to the same set of source sentences, we obtained 985 candidate paraphrases." ></td>
	<td class="line x" title="132:184	We created a set of criteria for judging appropriateness (an example will be given in Section 6.4) andrevisionexamplesfor the following operations allowed for this trial: Change of conjugations Change of case markers Change of voices 964 candidates have gained an agreement, and 484 paraphrase examples have been collected." ></td>
	<td class="line x" title="133:184	6 Results and discussion Table 1 gives some statistics of the resultant paraphrase corpora." ></td>
	<td class="line x" title="134:184	Figures 3 and 4 show the number of candidate paraphrases, where the horizontal axes denote the total working hours of two annotators, and the vertical axes the number of candidateparaphrases." ></td>
	<td class="line x" title="135:184	Thenumbers ofjudged, correct, incorrect, and deferred candidates are shown." ></td>
	<td class="line x" title="136:184	6.1 Efficiency 2,031 candidate paraphrases have so far been judged in total and 1,075 paraphrase examples have been collected in 287.5 hours." ></td>
	<td class="line x" title="137:184	The judgement was performed at a constant pace: 7.1 candidates (3.7 examples) in one hour." ></td>
	<td class="line x" title="138:184	It is hard to compare these results with other work because no previous study quantitatively evaluate the efficiency in terms of manual annotation cost." ></td>
	<td class="line x" title="139:184	However, we feel that the results have so far been satisfiable." ></td>
	<td class="line x" title="140:184	For each candidate paraphrase judged incorrect, the annotators were asked to classify the underlying errors into the fixed error types ((d) in Table 1: Statistics of the resultant corpora." ></td>
	<td class="line x" title="141:184	Paraphrase class LVC TransAlt # of source sentences 10,000 25,000 # of patterns 4 8 Type of lexical resources n, vn vi, vt Size of lexical resource 20,155 212 # of candidates 2,566 985 # of judged candidates 1,067 964 # of incorrect candidates 520 503 # of correct candidates 547 461 # of paraphrase examples 591 484 Working hours 118 169.5 Figure 1)." ></td>
	<td class="line x" title="142:184	This error classification consumed extra time because it required linguistic expertise which the annotators were not familiar with." ></td>
	<td class="line x" title="143:184	TransAlt was 1.75 times more time-consuming than LVC because the definition of TransAlt involved several delicate issues, which made the judgement process complicated." ></td>
	<td class="line x" title="144:184	We return to this issue in Section 6.4." ></td>
	<td class="line x" title="145:184	6.2 Exhaustiveness To estimate how exhaustively the proposed method collected paraphrase examples, we randomly sampled 750 sentences from the 4,500 sentences that were used in the trial for LVC, and manually checked whether the LVC paraphrasing could apply to each of them." ></td>
	<td class="line x" title="146:184	As a result, 206 examples were obtained, 158 of which were those already collected by the proposed method." ></td>
	<td class="line x" title="147:184	Thus, the estimated exhaustiveness was 77% (158/206)." ></td>
	<td class="line x" title="148:184	Our manual investigation into the missed examples has revealed that 47 misses could have been automatically generated by enhancing paraphrasing patterns and dictionaries, while only one example was missed due to an error in shallow parsing." ></td>
	<td class="line x" title="149:184	34 cases of the 48 misses could have been collected by adding a couple of paraphrasing patterns." ></td>
	<td class="line x" title="150:184	For example, pattern (11) verbalizes anounfollowedby anominalizing suffix, ka (-ize), as in (12)." ></td>
	<td class="line x" title="151:184	(11) s. N-ka-{ga, o, ni}(V ) V N-ize-{NOM, ACC, DAT} V t. V (N-ka) V (N-ize) (12) s. kore-wa kinyu-shijo-no kassei-ka-ni this-TOP financial market-GEN activation-DAT muke-ta kisei-kanwa-saku-da." ></td>
	<td class="line x" title="152:184	to address-PAST deregulation plan-COP This is a deregulation plan aiming at the activation of financial market." ></td>
	<td class="line x" title="153:184	30 0 200 400 600 800 1000 1200 0 20 40 60 80 100 120 # of judged candidates working hours Judged Correct Incorrect Deferred Figure 3: # of judged candidates (LVC)." ></td>
	<td class="line x" title="154:184	0 200 400 600 800 1000 0 20 40 60 80 100 120 140 160 180 # of judged candidates working hours Judged Correct Incorrect Deferred Figure 4: # of judged candidates (TransAlt)." ></td>
	<td class="line x" title="155:184	t. kore-wa kinyu-shijo-o this-TOP financial market-ACC kassei-ka-suru kisei-kanwa-saku-da." ></td>
	<td class="line x" title="156:184	to activate-PRES deregulation plan-COP This is a deregulation plan which activates financial market." ></td>
	<td class="line x" title="157:184	We cannot know if we have adequate paraphrasing patterns and resources before trials." ></td>
	<td class="line x" title="158:184	Therefore, manual examination isnecessary torefinethem tobridgegap between therangeof paraphrases that can be automatically generated and those of the specific class we consider." ></td>
	<td class="line x" title="159:184	6.3 Reliability Ideally, more annotators should be employed to ensure the reliability of the products, which, however, leads to a matter of balancing the trade-off." ></td>
	<td class="line x" title="160:184	Instead, we specified the detailed judgement criteria for each paraphrase class, and asked the annotators to reconsider marginal cases several days later and to make a discussion when judgements disagreed." ></td>
	<td class="line x" title="161:184	The agreement ratio for correct candidates between two annotators increased as they became used to the task." ></td>
	<td class="line x" title="162:184	In the trial for LVC, for example, the agreement ratio for each day changed from 74% (day 3) to 77% (day 6), 88% (day 9), and 93% (day 11)." ></td>
	<td class="line x" title="163:184	This indicates that the judgement criteria were effectively refined based on the feedback from inter-annotator discussions on marginal and disagreed cases." ></td>
	<td class="line x" title="164:184	To evaluate the reliability of our judgement procedure more precisely, we are planing to employ the third annotator who will be asked to judge all the cases independently of the others." ></td>
	<td class="line x" title="165:184	6.4 How we define paraphrase classes One of the motivations behind our class-basedapproach is an expectation that specifying the target classes of paraphrases would simplify the awkward problem of defining the boundary between paraphrasesan non-paraphrases." ></td>
	<td class="line x" title="166:184	Our trialsfor the two paraphrase classes, however, have revealed that it can still be difficult to create a clear criterion for judgement even when the paraphrase class in focus is specified." ></td>
	<td class="line x" title="167:184	As one of the criteria for TransAlt, we tested the agentivity of the nominative case of intransitive verbs." ></td>
	<td class="line x" title="168:184	The test used an adverb, muzukara (by itself), and classified a candidate paraphrase as incorrect if the adverb could be inserted immediately before the intransitive verb." ></td>
	<td class="line x" title="169:184	For example, we considered example (13) as a correct paraphrase of the TransAlt class whereas (14) incorrect because the agentivity exhibited by (14s) did not remain in (14t)." ></td>
	<td class="line x" title="170:184	(13) s. kare-ga soup-o atatame-ta." ></td>
	<td class="line x" title="171:184	he-NOM soup-ACC to warm up-PAST He warmed the soup up." ></td>
	<td class="line x" title="172:184	t. soup-ga atatamat-ta." ></td>
	<td class="line x" title="173:184	(correct) soup-NOM to be warmed up-PAST The soup was warmed up (by somebody)." ></td>
	<td class="line x" title="174:184	(14) s. kare-ga koori-o tokashi-ta." ></td>
	<td class="line x" title="175:184	he-NOM ice-ACC to melt (vt)-PAST He melted the ice." ></td>
	<td class="line x" title="176:184	t. koori-ga toke-ta." ></td>
	<td class="line x" title="177:184	(incorrect) ice-NOM to melt (vi)-PAST The ice melted (by itself)." ></td>
	<td class="line x" title="178:184	However, one might regard both paraphrases incorrect because the information given by the nominative argument of the source sentence is 31 dropped in the target in both cases." ></td>
	<td class="line x" title="179:184	Thus, the problem still remains." ></td>
	<td class="line x" title="180:184	Nevertheless, our approach will provide us with a considerable amounts of concrete data, which we hope will lead us to better understanding of the issue." ></td>
	<td class="line x" title="181:184	7 Conclusion Towardsdeepanalysisofcompositionalclassesof paraphrases, we have examined a class-oriented framework for collecting paraphrase examples, in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement." ></td>
	<td class="line x" title="182:184	Our preliminary experiments on building a paraphrase corpus have so far been producing promising results, which we have evaluated according to cost-efficiency, exhaustiveness, and reliability." ></td>
	<td class="line x" title="183:184	The resultant corpus and resources will be available for free shortly." ></td>
	<td class="line x" title="184:184	Our next step is directed to targeting a wider range of paraphrase classes." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I05-5007
Automated Generalization of Phrasal Paraphrases from the Web
Li, Weigang;Liu, Ting;Zhang, Yu;Li, Sheng;He, Wei;"></td>
	<td class="line x" title="1:203	Automated Generalization of Phrasal Paraphrases from the Web* Weigang Li School of Computer Science and Technology, Box 321, Harbin Institute of Technology, Harbin, P.R. China, 150001 lee@ir.hit.edu.cn Ting Liu School of Computer Science and Technology, Box 321, Harbin Institute of Technology, Harbin, P.R. China, 150001 tliu@ir.hit.ed u.cn Yu Zhang School of Computer Science and Technology, Box 321, Harbin Institute of Technology, Harbin, P.R. China, 150001 zhangyu@ir.hit .edu.cn Sheng Li School of Computer Science and Technology, Box 321, Harbin Institute of Technology, Harbin, P.R. China, 150001 lis@ir.hit.edu .cn Wei He School of Computer Science and Technology, Box 321, Harbin Institute of Technology, Harbin, P.R. China, 150001 truman@ir.hit." ></td>
	<td class="line x" title="2:203	edu.cn Abstract Rather than creating and storing thousands of paraphrase examples, paraphrase templates have strong representation capacity and can be used to generate many paraphrase examples." ></td>
	<td class="line x" title="3:203	This paper describes a new template representation and generalization method." ></td>
	<td class="line x" title="4:203	Combing a semantic dictionary, it uses multiple semantic codes to represent a paraphrase template." ></td>
	<td class="line x" title="5:203	Using an existing search engine to extend the word clusters and generalize the examples." ></td>
	<td class="line x" title="6:203	We also design three metrics to measure our generalized templates." ></td>
	<td class="line x" title="7:203	The experimental results show that the representation method is reasonable and the generalized templates have a higher precision and coverage." ></td>
	<td class="line x" title="8:203	1 Introduction Paraphrases are alternative ways to convey the same information (Barzilay and McKeown, 2001) and they have been applied in many fields of natural language processing." ></td>
	<td class="line oc" title="9:203	There are many previous work on paraphrase examples extraction or combining them with some applications such as information retrieval and question answering (Agichtein et al. , 2001; Florence et al. , 2003; Rinaldi et al. , 2003; Tomuro, 2003; Lin and Pantel, 2001;), information extraction (Shinyama et al. , 2002; Shinyama and Sekine, 2003), machine translation (Hiroshi et al. , 2003; Zhang and Yamamoto, 2003), multi-document (Barzilay et al. , 2003)." ></td>
	<td class="line x" title="10:203	There is also some other research about paraphrase." ></td>
	<td class="line x" title="11:203	(Wu and Zhou, 2003) just extract the synonymy collocation, such as <turn on, OBJ, light> and <switch on, OBJ, light> using both monolingual corpora and bilingual corpora to get an optimal result, but do not generalize them." ></td>
	<td class="line x" title="12:203	(Glickman and Dagan, 2003) detects verb paraphrases instances within a single corpus without relying on any priori structure and information." ></td>
	<td class="line oc" title="13:203	Generation of paraphrase examples was also investigated (Barzilay and Lee, 2003; Quirk et al. , 2004)." ></td>
	<td class="line x" title="14:203	Rather than creating and storing thousands of paraphrases, paraphrase templates have strong representation capacity and can be used to generate many paraphrase examples." ></td>
	<td class="line x" title="15:203	As (Hirst, 2003) said, for each aspect of paraphrase there are two main challenges: representation of knowledge and acquisition of knowledge." ></td>
	<td class="line x" title="16:203	Corresponding to the problem of generalization of paraphrase templates, there are also two problems: the first is the representation of paraphrase templates and the second is acquisition of paraphrase templates." ></td>
	<td class="line x" title="17:203	There are several methods about paraphrase templates representation." ></td>
	<td class="line xc" title="18:203	The first method is using the Part-of-Speech (Barzilay and McKeown, 2001; Daum and Marcu, 2003; Zhang and Yamamoto, 2003), the second uses name entity as the variable (Shinyama et al. , 2002; Shinyama and Sekine, 2003), the third method is similar to the second method which is called the inference rules extraction (Lin and Pantel, 2001)." ></td>
	<td class="line x" title="19:203	A paraphrases template is a pair of natural language phrases with variables standing in for certain grammatical constructs in (Daum and *: Supported by the Key Project of National Natural Science Foundation of China under Grant No. 60435020 49 Marcu, 2003)." ></td>
	<td class="line x" title="20:203	He used Part-of-Speech to represent templates." ></td>
	<td class="line x" title="21:203	But for some cases, the POS will be very limited and for some other cases will be over generalized." ></td>
	<td class="line x" title="22:203	For example: ,9?k  (In my view/mind ----I feel) The above pair of phrases is a paraphrase, it can be generalized using POS information:  [pronoun],9 (In [pronoun] view/mind) [pronoun] ?k ( [pronoun] feel) But for this template many noun words will be excluded." ></td>
	<td class="line x" title="23:203	From this point of view, the template representation capacity is limited." ></td>
	<td class="line x" title="24:203	But for other examples, the POS information will be over generally." ></td>
	<td class="line x" title="25:203	For example: 8p,X (What's the price for the apples?)" ></td>
	<td class="line x" title="26:203	8pJx (How much is the apples per Jin?)" ></td>
	<td class="line x" title="27:203	Here, we just generalize one variable 8p ." ></td>
	<td class="line x" title="28:203	Then, the template becomes: [noun],X (What's the price for the [noun]?)" ></td>
	<td class="line x" title="29:203	[noun] Jx (How much is the [noun] per Jin?)" ></td>
	<td class="line x" title="30:203	If there is a sentence 0A,X (What's the price for the notebook?), its paraphrase will be 0AJx (How much is the notebook per Jin?) according to this template." ></td>
	<td class="line x" title="31:203	Obviously, the result is unreasonable." ></td>
	<td class="line x" title="32:203	(Shinyama et al. , 2002) tried to find paraphrases assuming that two sentences sharing many Named Entities and a similar structure are likely to be paraphrases of each other." ></td>
	<td class="line x" title="33:203	But just name entities are limited, too." ></td>
	<td class="line x" title="34:203	And (Lin and Pantel, 2001) present an unsupervised algorithm for discovering inference rules from text such as X writes Y and X is the author of Y." ></td>
	<td class="line x" title="35:203	This generalized method has good ability." ></td>
	<td class="line x" title="36:203	But it also has some limited aspect." ></td>
	<td class="line x" title="37:203	For example: [Jack] writes [his homework]." ></td>
	<td class="line x" title="38:203	According to the paraphrase template, the target sentence will be transformed into [Jack] is the author of [his homework]." ></td>
	<td class="line x" title="39:203	Its obviously that the generated sentence is not standard." ></td>
	<td class="line x" title="40:203	So how to represent paraphrase templates and generalize the paraphrase examples is a very interesting task." ></td>
	<td class="line x" title="41:203	In this paper, we present a novel approach to represent paraphrase template with semantic code of words and using an existing search engine to get the paraphrase template." ></td>
	<td class="line x" title="42:203	The remainder of this paper is organized as follows." ></td>
	<td class="line x" title="43:203	In the next section, we give the overview of our method." ></td>
	<td class="line x" title="44:203	In section 3, we define the representation method in details." ></td>
	<td class="line x" title="45:203	Section 4 presents the generalization method." ></td>
	<td class="line x" title="46:203	Some experiments and discussions are shown in Section 5." ></td>
	<td class="line x" title="47:203	Finally, we draw a conclusion of this method and give some suggestions about future work." ></td>
	<td class="line x" title="48:203	2 Overview of Generalization Method The origin input of our system is a seed phrasal paraphrase example." ></td>
	<td class="line x" title="49:203	And the output is the generalized paraphrase templates from the given examples." ></td>
	<td class="line x" title="50:203	The overall architecture of our paraphrase generalization is represented on figure 1." ></td>
	<td class="line x" title="51:203	A seed phrasal paraphrase examples Getting the slot word Extend the slot word using Search Engine on every example Mapping two word sets to their semantic code sets Intersection operation on the two semantic code sets Generalizing a template Figure 1: Sketch Map of Paraphrase example Generalization We also use the example (1) to illustrate the representation." ></td>
	<td class="line x" title="52:203	Here a semantic dictionary called TongYiCiCiLin (Extension Version)1 is used." ></td>
	<td class="line x" title="53:203	The pair of phrases is a phrasal paraphrase." ></td>
	<td class="line x" title="54:203	At first, after preprocessing which includes word segment, POS tagging and word sense disambiguation, we get the slot word in the paraphrase." ></td>
	<td class="line x" title="55:203	In this example, the slot word is  (I)." ></td>
	<td class="line x" title="56:203	Then we search the web using the context of the slot word." ></td>
	<td class="line x" title="57:203	Every phrase in the phrasal pair derives a set of sentences which include the original phrase context." ></td>
	<td class="line x" title="58:203	A dependency parser on these sentences is used to extract the corresponding word with the slot word." ></td>
	<td class="line x" title="59:203	Two word sets can be obtained through the two sentence sets." ></td>
	<td class="line x" title="60:203	Then, we map word sets to their semantic code sets 1 TongYiCiCiLin (Extended Version) can be downloaded from the website of HIT-IRLab (Http://ir.hit.edu.cn)." ></td>
	<td class="line x" title="61:203	In the past section, we abbreviate the TongYiCiCiLin (Extended Version) to Cilin (EV) 50 according to Cilin(EV)." ></td>
	<td class="line x" title="62:203	Then an intersection operation is conducted on the two sets." ></td>
	<td class="line x" title="63:203	We use the intersection set to replace the slot word and generate the final paraphrase template." ></td>
	<td class="line x" title="64:203	In order to verify the validation of the generalized paraphrase template, we also design an automatic algorithm to confirm whether the template is reasonable using the existing search engine." ></td>
	<td class="line x" title="65:203	3 Representation of Template In the section of introduction, some representation methods of paraphrase template have been introduced." ></td>
	<td class="line x" title="66:203	And we proposed a new method using word semantic codes to represent the variable in a template." ></td>
	<td class="line x" title="67:203	Before we introduce the representation method, Firstly, we give some general introduction about the semantic dictionary of Cilin(EV)." ></td>
	<td class="line x" title="68:203	3.1 TongYiCiCiLin (Extended Version) Cilin (EV) is derived from original TongYiCiCilin in which word senses are decomposed to 12 large categories, 94 middle categories, 1,428 small categories." ></td>
	<td class="line x" title="69:203	Cilin (EV) removes some outdated words and updates many new words." ></td>
	<td class="line x" title="70:203	More fine-grained categories are added on the base of original classification system to satisfy the more complex natural language applications." ></td>
	<td class="line x" title="71:203	The encoding criterion is shown in the table 1: Table 1 Encoding table of dictionary Encoding bit 1 2 3 4 5 6 7 8 Example D a 1 5 B 0 2 = Attribute Big Middle Small groups Atom groups Layer 1 2 3 4 5 The encoding bits are arranged from left to right." ></td>
	<td class="line x" title="72:203	The first three layers are same with Cilin." ></td>
	<td class="line x" title="73:203	The fourth layer is represented by capital letters and the fifth layer is two-bit decimal digit." ></td>
	<td class="line x" title="74:203	The last bit is some more detailed information about the atom groups." ></td>
	<td class="line x" title="75:203	3.2 An Example of a Paraphrase Template For simplicity, we just select one slot word in every paraphrase." ></td>
	<td class="line x" title="76:203	And we stipulated that only content word can be slot word." ></td>
	<td class="line x" title="77:203	We also use the above paraphrase example (1).,9?k (In my view/mind ----I feel) Here, we get the slot word (I)." ></td>
	<td class="line x" title="79:203	Through the Word Sense Disambiguation processing, we get its semantic code Aa02A01= according to the fifth layer in Cilin(EV)." ></td>
	<td class="line x" title="80:203	If we just use the semantic code of the slot word, we can get a simple paraphrase template as follows:  [Aa02A01=],9 (In [Aa02A01=] view/mind) [Aa02A01=] ?k ([Aa02A01=] feel) But it is obviously that the template is very limited." ></td>
	<td class="line x" title="81:203	Its representation ability is also limited." ></td>
	<td class="line x" title="82:203	So how to extend the ability of a paraphrase template is a challenging work." ></td>
	<td class="line x" title="83:203	3.3 Extending the Template Abstract Ability According to the feature of Cilin(EV) architecture, we can use the higher layers semantic code instead of the slot word to generalize the paraphrase template naturally." ></td>
	<td class="line x" title="84:203	Of course its a very simple method to extend the template ability, but it also brings more redundancy of a paraphrase template and it will be proven in the later section." ></td>
	<td class="line x" title="85:203	So we use multiple semantic codes of the different layer instead of only one semantic code of slot word in Cilin (EV)." ></td>
	<td class="line x" title="86:203	The later experimental results prove this representation has a good performance with a good precision and coverage." ></td>
	<td class="line x" title="87:203	4 Generalizing to Templates As mentioned above, we can use multiple semantic codes to generalize paraphrase examples." ></td>
	<td class="line x" title="88:203	So the problem of how to generalize paraphrase examples is transformed into the problem of how to get the multiple semantic codes set." ></td>
	<td class="line x" title="89:203	We proposed a new method which uses the existing search engine to reach the target." ></td>
	<td class="line x" title="90:203	4.1 Getting the Candidate Sentences After we removed the slot word in the paraphrase examples, two phrasal contexts of the original paraphrase phrases were obtained." ></td>
	<td class="line x" title="91:203	Each phrase without slot word is used as a search query for an existing search engine and achieving many sentences which include the query word." ></td>
	<td class="line x" title="92:203	For this example, the two queries are  ,9 (inview) and ?k (feel)." ></td>
	<td class="line x" title="93:203	Each query gets one sentence set respectively." ></td>
	<td class="line x" title="94:203	Part of the two result sentence sets are shown in figure 2 and figure 3: 51 Figure 2." ></td>
	<td class="line x" title="95:203	Sentence Set 1 Figure 3." ></td>
	<td class="line x" title="96:203	Sentence Set 2 From the above two sentence sets, we can find that there is some noisy information in the sentences." ></td>
	<td class="line x" title="97:203	In order to extend the correspondent words of the slot word, it is not enough that we just use the position information or POS tagging information of the slot word." ></td>
	<td class="line x" title="98:203	Even if we extract these words, many of them cant be found in the dictionary because they are not simple words." ></td>
	<td class="line x" title="99:203	Benefiting from the idea of (Lin and Pantel, 2001), we use a dependency parser to determine the correspondent extended words." ></td>
	<td class="line x" title="100:203	4.2 Dependency Parser In this paper, we use a dependency parser (Ma et al. , 2004) to extract the candidate slot word." ></td>
	<td class="line x" title="101:203	For example, the dependency parsing result of the phrase of  ,9  is shown in figure 4." ></td>
	<td class="line x" title="102:203	Figure 4." ></td>
	<td class="line x" title="103:203	Dependency parsing result The arcs in the figure represent dependency relationships." ></td>
	<td class="line x" title="104:203	The direction of an arc is from the head to the modifier in the relationship." ></td>
	<td class="line x" title="105:203	Labels associated with the arcs represent types of dependency relations." ></td>
	<td class="line x" title="106:203	Table 2 lists a subset of the dependency relations in the HIT-IRLab dependency parser2." ></td>
	<td class="line x" title="107:203	Table 2." ></td>
	<td class="line x" title="108:203	A subset of the dependency relations Relation Description ATT n" ></td>
	<td class="line x" title="109:203	G2 (attribute) HEDm(head) SBJ A (subject) ADV (" ></td>
	<td class="line x" title="110:203	4X (adverbial) VOB |G2 (verb-object)  C G4), 9 Y  " ></td>
	<td class="line x" title="111:203	NL$" ></td>
	<td class="line x" title="112:203	  C{L 4l, 9  ?UCC.JPH (  , 9 TTo9& ,X ,7 AxA  6,, 9 G?U'  , 9 !4x5b ,X," ></td>
	<td class="line x" title="113:203	 2 More information about the dependency parser can be got from http://ir.hit.edu.cn/cuphelp.htm 4.3 Extracting the extended words We just use a very simple method to get the extended words from the parsed sentences." ></td>
	<td class="line x" title="114:203	At first, we record the relations of the original parsed phrasal examples." ></td>
	<td class="line x" title="115:203	And then we use these relations to matched similar part in the candidate parsed sentence except slot word." ></td>
	<td class="line x" title="116:203	And we omit these unseen relations and content words which dont appear in the original parsed phrasal examples." ></td>
	<td class="line x" title="117:203	Then we can get the extended words." ></td>
	<td class="line x" title="118:203	Fw{+= ? k 4\ ( Z4!" ></td>
	<td class="line x" title="119:203	? k 5b  ? k ,E $ eK  #\C 5 ? k DV/" ></td>
	<td class="line x" title="120:203	 D?S ? k 7CDk3!OZ B720 -6" ></td>
	<td class="line x" title="121:203	 Figure 5." ></td>
	<td class="line x" title="122:203	Dependency parsing result Figure 5 shows the dependency parsing result of the phrase of  C G4),9 (In foreign capital fund manager view)." ></td>
	<td class="line x" title="123:203	We can easily find that the extended word of the slot word   (I) is  4) (manager)." ></td>
	<td class="line x" title="124:203	Two extended word sets can be extracted from two sentence sets." ></td>
	<td class="line x" title="125:203	Then we map each word to their semantic code to get two semantic code sets." ></td>
	<td class="line x" title="126:203	Intersection operation is conducted on these two semantic code sets to obtain their intersection set." ></td>
	<td class="line x" title="127:203	Finally, we use the semantic code set instead of the slot word to generate the paraphrase template." ></td>
	<td class="line x" title="128:203	4.4 Some tricks Because the precision of the current dependency parser on Chinese is not very high, we just extract a part of the candidate sentences to parse." ></td>
	<td class="line x" title="129:203	There are three patterns to segment the long candidate sentences according to position of slot word in paraphrase examples." ></td>
	<td class="line x" title="130:203	They are called FRONT, MIDDLE and BACK." ></td>
	<td class="line x" title="131:203	Here we use an example to illustrate it as shown in table 3: Table 3 Examples of sentence segmentation Pattern Origin Phrase Segment examples FRONT (SW)?Fw   { + = ? k 4\ (" ></td>
	<td class="line x" title="132:203	 MIDDLE(SW)'   C  G 4 ), 9 Y  " ></td>
	<td class="line x" title="133:203	N L$" ></td>
	<td class="line x" title="134:203	 The bold section in the sentence will be extracted to parse." ></td>
	<td class="line x" title="135:203	Pattern type can be decided by 52 the position relation between slot word and context words." ></td>
	<td class="line x" title="136:203	And these patterns can reduce the relative error rate of the dependency parser." ></td>
	<td class="line x" title="137:203	That is to say, if the original phrase is parsed wrongly, the extracted segments may be parsed wrongly with the similar error." ></td>
	<td class="line x" title="138:203	But according to our method, this kind of parser error has little influence on the final extracting result." ></td>
	<td class="line x" title="139:203	5 Experiments and Discussions 5.1 Setting We extract about 510 valid paraphrase examples from a Chinese paraphrase corpus (Li et al. , 2004)." ></td>
	<td class="line x" title="140:203	For simplicity, we just select those phrasal paraphrase examples which own same word." ></td>
	<td class="line x" title="141:203	And we stipulate only content word can be as slot word." ></td>
	<td class="line x" title="142:203	We just use four seed phrasal paraphrases as the original paraphrases in this paper." ></td>
	<td class="line x" title="143:203	And the generalized paraphrase templates represented by semantic codes of the fifth layer in Cinlin (EV) are also shown in the Table 4: Table 4: Examples of the generalized template Origin Phrases Generalized Paraphrase templates ?k [Aa01A01=,Aa01A05=, Aa01C03=,Aa02A01=, ]?k1  , 9  [Aa01A01=,Aa01A05=, Aa01C03=,Aa02A01=, ],9 &Z  [Ac03A01=,Ah04A01=, Ah05A01=,Am03D01@,]Z2 &k\ [Ac03A01=,Ah04A01=, Ah05A01=,Am03D01@,]k\ F &  Z F [Fb01A01=,Gb07B01=, Hb06A01=,He15B01=, ]Z3 < & ` Z < [Fb01A01=,Gb07B01=, Hb06A01=,He15B01=, ]`Z 8 p,X     [Aa03A01=,Ac03A01=, Ba05A10#,Bb02A01=,],X   4 8 p  Jx [Aa03A01=,Ac03A01=,Ba05A10#, Bb02A01=,]Jx 5.2 Evaluation on Templates The goal of the evaluations is to confirm how reasonable this kind of representation method of paraphrase templates is and how well the template is. We evaluated the generalized paraphrase template in three ways." ></td>
	<td class="line x" title="144:203	They are listed in the following three categories: 1) Reasonability; 2) Precision; 3) Coverage." ></td>
	<td class="line x" title="145:203	1) Reasonability The reasonability of a paraphrase template aims to measure the reasonable extent of the presentation method with multiple semantic codes." ></td>
	<td class="line x" title="146:203	For example, if we use POS to generalize a paraphrase template, its reasonability is very lower; that is to say, POS is not suitable to represent paraphrase template in some extent." ></td>
	<td class="line x" title="147:203	We use an existing search engine to calculate the reasonability of every paraphrase template." ></td>
	<td class="line x" title="148:203	Firstly, we instantiate all paraphrase examples from a template." ></td>
	<td class="line x" title="149:203	Then all these examples are as the queries of the search engine." ></td>
	<td class="line x" title="150:203	If two phrases in one paraphrase can be matched completely from the search engine, it also means that one or more examples are found on the Web via search engine, we then consider this paraphrase is reasonable." ></td>
	<td class="line x" title="151:203	Using this method we can get the approximate evaluation of all the examples." ></td>
	<td class="line x" title="152:203	We define two metrics: Strict_Reasonability = S / N Loose_Reasonability = (L + S) / N Where N is the total number of the instantiated examples; S is the number of the paraphrase examples which two phrases in it can be matched all; L is the number of paraphrase examples only one phrase in a paraphrase can be matched." ></td>
	<td class="line x" title="153:203	2) Precision Every template is correspondent to the examples number with the semantic code of different layer in Cilin (EV) as shown in table 5." ></td>
	<td class="line x" title="154:203	Table 5 Templates and their correspond examples number Instantiated examples numberNumber of Paraphrase templates Cilin3 Cilin4 Cilin5 1 2696 1815 478 2 13032 6354 3011 3 1057 587 177 4 3004 2229 429 From the above table, we can find that every template can instantiate many examples." ></td>
	<td class="line x" title="155:203	If manually judging all of these examples will spend plenty of time." ></td>
	<td class="line x" title="156:203	So we just sample part of all instantiate examples, 200 paraphrase examples for each template in this paper." ></td>
	<td class="line x" title="157:203	For each 53 phrase in a sample paraphrase example, it is as search query to get the first two matched sentences." ></td>
	<td class="line x" title="158:203	Evaluators would be asked whether it is semantically okay to replace the query in the sentence by the correspondent phrase in a paraphrase." ></td>
	<td class="line x" title="159:203	They were given only two options: Yes or No." ></td>
	<td class="line x" title="160:203	If search query have no matched results, we consider that this phrase cannot be replace with its correspondent paraphrase." ></td>
	<td class="line x" title="161:203	According to the above regulations, we know that every paraphrase examples correspondent to 4 sentences." ></td>
	<td class="line x" title="162:203	If we sample n examples from a template, the precision of a paraphrase template can be calculated by: Precision = R / (4 * n) Where, R is the number of sentences which is considered to be correct by the evaluator." ></td>
	<td class="line x" title="163:203	3) Coverage Evaluating directly the coverage of a paraphrase template is difficult because humans cant enumerate all the words to be suitable to the template." ></td>
	<td class="line x" title="164:203	We use an approximate method to get the coverage of a template." ></td>
	<td class="line x" title="165:203	At first we use another search engine to get candidate sentences with similar method for generalization of a paraphrase template." ></td>
	<td class="line x" title="166:203	From these retrieved sentences we can get many different words with the known generalized words because more than 85% of search results from different search engine are different." ></td>
	<td class="line x" title="167:203	Evaluators extract every sentence which can be replaced with the correspondent phrase in a paraphrase and the new sentences retain the origin meaning." ></td>
	<td class="line x" title="168:203	We know each sentence is correspondent to a word." ></td>
	<td class="line x" title="169:203	Then we define two metrics: Surface_Coverage = M / NS Semantic_Coverage = Map(K) / (Map(NS-M) + Map(K)) Where, NS is the number of all manually tagged right words, M is the number of words which can be instantiated from a paraphrase template, K is the number of all the words that generalized the template at the front." ></td>
	<td class="line x" title="170:203	Map(X) is the total word number of the word clusters which derived from X word in the semantic dictionary of Cilin(EV)." ></td>
	<td class="line x" title="171:203	5.3 Result In order to exhibit the merit of our method, we conduct four groups of experiment." ></td>
	<td class="line x" title="172:203	They are POS-Tag, Cilin3, Cilin4 and Ciln5, respectively." ></td>
	<td class="line x" title="173:203	Especially, we just randomly select 400 words to satisfy the POS information." ></td>
	<td class="line x" title="174:203	Table 6: Experiment Results Reasonability (%) Coverage (%) St_R Lo_R Su_C Se_C Precision (%) POS 10.50 17.00 90.00 ---11.75 Cilin3 45.57 84.50 27.55 38.71 45.75 Cilin4 46.89 84.54 23.87 44.48 64.13 Cilin5 46.24 83.12 20.39 39.47 69.88 Every value in table 6 is a average value of four values correspondent to four templates." ></td>
	<td class="line x" title="175:203	From the table we can find that the reasonability of the Cilin-based representation template changes little, and that of POS-based representation is very lower." ></td>
	<td class="line x" title="176:203	We find that the longer original phrases are, the lower the coverage of the generalized template is. Although the average coverage of generalized template is relatively low, we can draw a conclusion that using multiple semantic codes to generalize phrasal paraphrase examples is reasonable." ></td>
	<td class="line x" title="177:203	The column of the coverage shows that the coverage rates of Cilin-based templates are all not more than 50%." ></td>
	<td class="line x" title="178:203	And the POS-based template has a very high coverage rate." ></td>
	<td class="line x" title="179:203	And we know that the extended information is not enough only depending on one search engine." ></td>
	<td class="line x" title="180:203	We will combine several different search engines with together to solve this problem in the future work." ></td>
	<td class="line x" title="181:203	1.0 1.5 2.0 2.5 3.0 3.5 4.0 0 10 20 30 40 50 60 70 80 90 100 strict_Reasonability loose_Reasonability surface_Coverage semantic_Coverage Precision Va lue s o f P erc en t Different Template Representation Method Figure 6." ></td>
	<td class="line x" title="182:203	Experimental Results The numbers from one to four on the X-axis are correspondent to POS, Cilin3, Cilin4 and Cilin5 in figure 6." ></td>
	<td class="line x" title="183:203	We can see the features clearly of different representation methods of template from the figure 6." ></td>
	<td class="line x" title="184:203	We can find that 54 Cilin5-based template has the highest precision, but its coverage is lower." ></td>
	<td class="line x" title="185:203	And Cilin3-based template has opposite feature." ></td>
	<td class="line x" title="186:203	This is because that one semantic code of Cilin3 includes more words than that of Cilin5." ></td>
	<td class="line x" title="187:203	At the same time, more words bring more redundant information." ></td>
	<td class="line x" title="188:203	And Cilin4-based template has a good tradeoff between coverage and precision." ></td>
	<td class="line x" title="189:203	So we conclude that the semantic code of fourth layer in Cilin (EV) is more suitable to represent paraphrase template." ></td>
	<td class="line x" title="190:203	Some additional information can be extracted from the generalized template." ></td>
	<td class="line x" title="191:203	Such as, the collocation information between the slot word and the context words can be extract." ></td>
	<td class="line x" title="192:203	For example, in the fourth template, we can get the information about which words can be collocated with x (Jin)." ></td>
	<td class="line x" title="193:203	Although this kind of representation of paraphrase template has a good performance, it is weak for those words or structures that dont exist in dictionary." ></td>
	<td class="line x" title="194:203	Also, this method is not suitable to the named entities representation." ></td>
	<td class="line x" title="195:203	6 Conclusion In this paper, a novel method for automated generalization of paraphrase examples is proposed." ></td>
	<td class="line x" title="196:203	This method is not dependent on the traditional limited texts instead it is based on the richness of the Web." ></td>
	<td class="line x" title="197:203	It uses the multiple semantic codes to generalize a paraphrase example combing a semantic dictionary (Cilin (EV))." ></td>
	<td class="line x" title="198:203	The experimental results proved that this representation method is reasonable and the generalized templates have a good precision and coverage." ></td>
	<td class="line x" title="199:203	But this is just the beginning of the paraphrase examples generalization." ></td>
	<td class="line x" title="200:203	And we simplify the problem in some aspects, such as we limited the number of the slot word in a paraphrase example, and we stipulate only the same word can be slot word." ></td>
	<td class="line x" title="201:203	Also, we find that our templates are weak for those words or structures that dont exist in dictionary." ></td>
	<td class="line x" title="202:203	Some methods in information extraction about named entities generalization can be used for reference in the future." ></td>
	<td class="line x" title="203:203	Moreover, how to combine the semantic code with other representation forms together is also an interesting work." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I05-5008
Automatic generation of paraphrases to be used as translation references in objective evaluation measures of machine translation
Lepage, Yves;Denoual, Etienne;"></td>
	<td class="line x" title="1:211	Automatic generation of paraphrases to be used as translation references in objective evaluation measures of machine translation Yves Lepage Etienne Denoual ATR  Spoken language communication research labs Keihanna gakken tosi, 619-0288 Kyoto, Japan {yves.lepage, etienne.denoual}@atr.jp Abstract We propose a method that automatically generates paraphrase sets from seed sentences to be used as reference sets in objective machine translation evaluation measures like BLEU and NIST." ></td>
	<td class="line x" title="2:211	We measured the quality of the paraphrases produced in an experiment, i.e., (i) their grammaticality: at least 99% correct sentences; (ii) their equivalence in meaning: at least 96% correct paraphrases either by meaning equivalence or entailment; and, (iii) the amount of internal lexical and syntactical variation in a set of paraphrases: slightly superior to that of hand-produced sets." ></td>
	<td class="line x" title="3:211	The paraphrase sets produced by this method thus seem adequate as reference sets to be used for MT evaluation." ></td>
	<td class="line x" title="4:211	1 Introduction We present and evaluate a method to automatically produce paraphrases from seed sentences, from a given linguistic resource." ></td>
	<td class="line x" title="5:211	Lexical and syntactical variation among paraphrases is handled through commutations exhibited in proportional analogies, while well-formedness is enforced by filtering with sequences of characters of a certain length." ></td>
	<td class="line x" title="6:211	In an experiment, the quality of the paraphrases produced, i.e., (i) their grammaticality, (ii) their equivalence in meaning with the seed sentence, and, (iii) the internal lexical and syntactical variation in a set of paraphrases, was assessed by sampling and objective measures." ></td>
	<td class="line x" title="7:211	2 Motivation Paraphrases are an important element in the evaluation of many natural language processing tasks." ></td>
	<td class="line x" title="8:211	Specifically, in the automatic evaluation of machine translation systems, the quality of translation candidates is judged against reference translations that are paraphrases in the target language." ></td>
	<td class="line x" title="9:211	Automatic measures like BLEU (PAPINENI et al. , 2001) or NIST (DODDINGTON, 2002) do so by counting sequences of words in such paraphrases." ></td>
	<td class="line x" title="10:211	It is expected that such reference sets contain synonymous sentences (i.e. , paraphrases) that explicit possible lexical and syntactical variations in order to cope with translation variations in terms and structures (BABYCH and HARTLEY, 2004)." ></td>
	<td class="line x" title="11:211	In order to produce such reference sets, we propose a method to generate paraphrases from a seed sentence where lexical and syntactical variations are handled by the use of commutations as captured by proportional analogies whereas Nsequences are used to enforce fluency of expression and adequacy of meaning." ></td>
	<td class="line x" title="12:211	3 The linguistic resource used The linguistic resource used in the experiment presented in this paper relies on the C-STAR collection of utterances called Basic Travelers Expressions1." ></td>
	<td class="line x" title="13:211	This is a multilingual resource of expressions from the travel and tourism domain that contains 162,318 aligned translations in several languages, among which English." ></td>
	<td class="line x" title="14:211	The items are quite short as the following examples show (one line is one item in the corpus), and as the figures in Table 1 show." ></td>
	<td class="line x" title="15:211	1http://www.c-star.org/." ></td>
	<td class="line x" title="16:211	57 Number of Avg." ></td>
	<td class="line x" title="17:211	size  std." ></td>
	<td class="line x" title="18:211	dev." ></td>
	<td class="line x" title="19:211	negationslash= sentences in characters in words 97,769 35.14  18.81 6.86  3.57 Table 1: Some statistics about the linguistic resource Number of Avg." ></td>
	<td class="line x" title="20:211	size  std." ></td>
	<td class="line x" title="21:211	dev." ></td>
	<td class="line x" title="22:211	negationslash= sentences in characters in words 42,249 33.15  9.31 6.44  1.90 Table 2: Some statistics about the paraphrases produced Thank you so much." ></td>
	<td class="line x" title="23:211	Keep the change." ></td>
	<td class="line x" title="24:211	Bring plenty of lemon, please." ></td>
	<td class="line x" title="25:211	Please tell me about some interesting places [near here." ></td>
	<td class="line x" title="26:211	Thank you." ></td>
	<td class="line x" title="27:211	Please sign here." ></td>
	<td class="line x" title="28:211	How do you spell your name?" ></td>
	<td class="line x" title="29:211	The quality of this resource is of at least 99% correct sentences (p-value = 1.92%)." ></td>
	<td class="line x" title="30:211	The few incorrect sentences contain spelling errors or slight syntactical mistakes." ></td>
	<td class="line x" title="31:211	4 Our paraphrasing methodology 4.1 Our algorithm The proposed method consists in two phases: firstly, paraphrase detection through equality of translation and secondly, paraphrase generation through linguistic commutations based on the data produced in the first phase:  Detection: find sentences which share a same translation in the multilingual resource (4.2);  Generation: produce new sentences by exploiting commutations (4.3); limit combinatorics by contiguity constraints (4.4)." ></td>
	<td class="line x" title="32:211	Each of the steps of the previous algorithm is explained in details in the following sections." ></td>
	<td class="line x" title="33:211	4.2 Initialisation by paraphrase detection In a first phase we initialise our data by paraphrase detection." ></td>
	<td class="line x" title="34:211	By definition, paraphrase is an equivalence in meaning, thus, different sentences having the same translation ought to be considered equivalent in meaning, i.e., they are paraphrases2." ></td>
	<td class="line x" title="35:211	As the linguistic resource used 2This is basically the same approach as (OHTAKE and YAMAMOTO, 2003, p. 3 and 4)." ></td>
	<td class="line x" title="36:211	in the present experiment is a multilingual corpus, we have at our disposal the corresponding translations in different languages for each of its sentences." ></td>
	<td class="line x" title="37:211	For instance, the following English sentences share a common Japanese translation shown in bold face below." ></td>
	<td class="line x" title="38:211	Therefore, they are paraphrases." ></td>
	<td class="line x" title="39:211	A beer, please.Xi^M{ { Xi^M{ Beer, please.{ S&M`b{ Xi^M{ <^M{  Xi^M{ Can I have a beer?Xi^M{ Give me a beer, please.Xi^M{ I would like beer.Xi^M{ Id like a beer, please.Xi^M{ 4.3 Commutation in proportional analogies for paraphrase generation In a second phase, we implement paraphrase generation." ></td>
	<td class="line x" title="40:211	Any given sentence may share commutations with other sentences of the corpus." ></td>
	<td class="line x" title="41:211	Such commutations are best seen in analogical relations that explicit syntagmatic and paradigmatic variations (de SAUSSURE, 1995, part 3, chap 4)." ></td>
	<td class="line x" title="42:211	For instance, the seed sentence A slice of pizza, please." ></td>
	<td class="line x" title="43:211	58 Id like a beer, please." ></td>
	<td class="line x" title="44:211	: A beer, please." ></td>
	<td class="line x" title="45:211	:: Id like a slice of pizza, please." ></td>
	<td class="line x" title="46:211	: A slice of pizza, please." ></td>
	<td class="line x" title="47:211	Id like a twin, please." ></td>
	<td class="line x" title="48:211	: A twin, please." ></td>
	<td class="line x" title="49:211	:: Id like a slice of pizza, please." ></td>
	<td class="line x" title="50:211	: A slice of pizza, please." ></td>
	<td class="line x" title="51:211	Id like a bottle of red wine, please." ></td>
	<td class="line x" title="52:211	: A bottle of red wine, please." ></td>
	<td class="line x" title="53:211	:: Id like a slice of pizza, please." ></td>
	<td class="line x" title="54:211	: A slice of pizza, please." ></td>
	<td class="line x" title="55:211	Table 3: Some analogies formed with sentences of the linguistic resource that show commutations with the sentence A slice of pizza, please." ></td>
	<td class="line x" title="56:211	(i) Id like a beer, please." ></td>
	<td class="line x" title="57:211	: A beer, please." ></td>
	<td class="line x" title="58:211	:: Id like a slice of pizza, please." ></td>
	<td class="line x" title="59:211	: A slice of pizza, please." ></td>
	<td class="line x" title="60:211	(ii) Id like a beer, please." ></td>
	<td class="line x" title="61:211	: Can I have a beer?" ></td>
	<td class="line x" title="62:211	:: Id like a slice of pizza, please." ></td>
	<td class="line x" title="63:211	: x (iii) Id like a beer, please." ></td>
	<td class="line x" title="64:211	: Can I have a beer?" ></td>
	<td class="line x" title="65:211	:: Id like a slice of pizza, please." ></td>
	<td class="line x" title="66:211	: Can I have a slice of pizza?" ></td>
	<td class="line x" title="67:211	Table 4: Generating a paraphrase for the seed sentence A slice of pizza, please." ></td>
	<td class="line x" title="68:211	using proportional analogies." ></td>
	<td class="line x" title="69:211	(i) The original proportional analogy taken from Table 3." ></td>
	<td class="line x" title="70:211	(ii) Replacing the sentence A beer, please." ></td>
	<td class="line x" title="71:211	with one of its paraphrases acquired during the detection phase: Can I have a beer?" ></td>
	<td class="line x" title="72:211	The last sentence of the proportional analogy becomes unknown." ></td>
	<td class="line x" title="73:211	(iii) Solving the analogical equation, i.e., generating a paraphrase of A slice of pizza, please." ></td>
	<td class="line x" title="74:211	enters in the analogies of Table 3." ></td>
	<td class="line x" title="75:211	The replacement of some sentences with known paraphrases in such analogies allows us to produce new sentences." ></td>
	<td class="line x" title="76:211	This explains why we needed some paraphrases to start with." ></td>
	<td class="line x" title="77:211	For instance, by replacing the sentence: A beer, please." ></td>
	<td class="line x" title="78:211	with the sentence: Can I have a beer?" ></td>
	<td class="line x" title="79:211	in the first analogy of Table 3, one gets the following analogical equation, that is solved as indicated." ></td>
	<td class="line x" title="80:211	Id like a beer, please." ></td>
	<td class="line x" title="81:211	: Can I have a beer?" ></td>
	<td class="line x" title="82:211	:: Id like a slice of pizza, please." ></td>
	<td class="line x" title="83:211	: x  x = Can I have a slice of pizza?" ></td>
	<td class="line x" title="84:211	It is then legitimate to say that the produced sentence: Can I have a slice of pizza?" ></td>
	<td class="line x" title="85:211	is a paraphrase of the seed sentence (see Table 4)." ></td>
	<td class="line o" title="86:211	Such a method alleviates the problem of creating templates from examples which would be used in an ulterior phase of generation (BARZILAY and LEE, 2003)." ></td>
	<td class="line x" title="87:211	Here, all examples in the corpus are potential templates in their actual raw form, with the advantage that the choice of the places where commutations may occur is left to proportional analogy." ></td>
	<td class="line x" title="88:211	4.4 Limitation of combinatorics by contiguity constraints During paraphrase generation, spurious sentences may be produced." ></td>
	<td class="line x" title="89:211	For instance, the replacement in the previous analogy, of the sentence: A beer, please." ></td>
	<td class="line x" title="90:211	by the following paraphrase detected during the first phase: A bottle of beer, please." ></td>
	<td class="line x" title="91:211	produces the unfortunate sentence: A bottle of slice of pizza, please." ></td>
	<td class="line x" title="92:211	Moreover, as no complete and valid formalisation of linguistic analogies has yet been proposed, the algorithm used (LEPAGE, 1998) may deliver such unacceptable strings as: 59 43 Could we have a table in the corner?" ></td>
	<td class="line x" title="93:211	43 Id like a table in the corner." ></td>
	<td class="line x" title="94:211	43 We would like a table in the corner." ></td>
	<td class="line x" title="95:211	28 Can we have a table in the corner?" ></td>
	<td class="line x" title="96:211	5 Can I get a table in the corner?" ></td>
	<td class="line x" title="97:211	5 In the corner, please." ></td>
	<td class="line x" title="98:211	4 Wed like to sit in the corner." ></td>
	<td class="line x" title="99:211	2 Id like to sit in the corner." ></td>
	<td class="line x" title="100:211	2 I would like a table in the corner." ></td>
	<td class="line x" title="101:211	2 Wed like a table in the corner." ></td>
	<td class="line x" title="102:211	1 Id prefer a table in the corner." ></td>
	<td class="line x" title="103:211	1 I prefer a table in the corner." ></td>
	<td class="line x" title="104:211	Table 5: Paraphrase candidates for Can we have a table in the corner?" ></td>
	<td class="line x" title="105:211	Candidates filtered out by unseen N-sequences (N = 20) are struck out." ></td>
	<td class="line x" title="106:211	Notice that the seed sentence itself has been generated again by the method (4th sentence from the top)." ></td>
	<td class="line x" title="107:211	The figures on the left are the frequencies with which the sentence has been generated." ></td>
	<td class="line x" title="108:211	A slice of pizzthe, pleaset for tha, please." ></td>
	<td class="line x" title="109:211	In order to ensure a very high rate of wellformedness among the sentences produced, we require a method that extracts well-formed sentences from the set of generated sentences with a very high precision (to the possible prejudice of the recall)." ></td>
	<td class="line x" title="110:211	To this end, we eliminate all sentences containing sequences of characters of a given length unseen in the original data3." ></td>
	<td class="line x" title="111:211	It is clear that, by adequately tuning the given length, such a method will be able to retain a satisfactory number of sentences that will be undoubtedly correct, at least in the sense of the linguistic resource." ></td>
	<td class="line x" title="112:211	5 Experiments During the first phase of paraphrase detection, 26,079 sentences (out of 97,769) got at least one possibly incorrect paraphrase candidate with an average of 5.35 paraphrases by sentence." ></td>
	<td class="line x" title="113:211	However, the distribution is not uniform: 60 sentences get more than 100 paraphrases." ></td>
	<td class="line x" title="114:211	The maximum is reached with 529 paraphrases for the sentence Sure." ></td>
	<td class="line x" title="115:211	Such a sentence has a variety of meanings depending on the context, which explains the high number of its possible paraphrases as illustrated below." ></td>
	<td class="line x" title="116:211	3This is conform to the trend of using N-sequences to assess the quality of outputs of various NLP systems like (LIN and HOVY, 2003) for summary generation, (DODDINGTON, 2002) for machine translation, etc Sure." ></td>
	<td class="line x" title="117:211	Here you are." ></td>
	<td class="line x" title="118:211	Sure." ></td>
	<td class="line x" title="119:211	This way, please." ></td>
	<td class="line x" title="120:211	Certainly, go ahead, please." ></td>
	<td class="line x" title="121:211	Im sure I will." ></td>
	<td class="line x" title="122:211	No, I dont mind a bit." ></td>
	<td class="line x" title="123:211	Okay." ></td>
	<td class="line x" title="124:211	I understand quite well, thank you." ></td>
	<td class="line x" title="125:211	Sounds fine to me. Yes, I do." ></td>
	<td class="line x" title="126:211	. However, such an example shows also that the more the paraphrases obtained by this method, the less reliable their quality." ></td>
	<td class="line x" title="127:211	During the second phase of paraphrase generation, the method generated 4,495,266 English sentences on our linguistic resource." ></td>
	<td class="line x" title="128:211	An inspection of a sample of 400 sentences shows that the quality lies around 23.6% of correct sentences (pvalue = 1.19%) in syntax and meaning." ></td>
	<td class="line x" title="129:211	The set of paraphrase candidates obtained on an example sentence are shown in Table 5." ></td>
	<td class="line x" title="130:211	To ensure fluency of expression and adequacy of meaning, the method then filtered out any sentence containing an N-sequence unseen in the corpus (see Section 4.4)." ></td>
	<td class="line x" title="131:211	The best value for N that allowed us to obtain a quality rate at the same level to that of the original linguistic resource was 20." ></td>
	<td class="line x" title="132:211	As a final result, the number of seed sentences for which we obtained at least one paraphrase is 16,153." ></td>
	<td class="line x" title="133:211	With a total number of 147,708 para60 phrases generated4, the average number of paraphrases per sentence is 8.65 with a standard deviation of 16.98 which means that the distribution is unbalanced." ></td>
	<td class="line x" title="134:211	The graph on the left of Figure 1 shows the number of seed sentences with the same number of paraphrases." ></td>
	<td class="line x" title="135:211	while the graph on the right shows the number of paraphrases against the length of the seed sentence in words." ></td>
	<td class="line x" title="136:211	6 Quality of the generated paraphrases 6.1 Well-formedness of the generated paraphrases The grammatical quality of the paraphrase candidates obtained was evaluated on a sample of 400 sentences: at least 99% of the paraphrases may be considered grammatically correct (p-value = 2.22%)." ></td>
	<td class="line x" title="137:211	This quality is approximately the same as that of the original resource: at least 99% (pvalue = 1.92%)." ></td>
	<td class="line x" title="138:211	An overview of the errors in the generated paraphrases suggests that they do not differ from the ones in the original data." ></td>
	<td class="line x" title="139:211	For instance, one notes that an article is lacking before the noun phrase tourist area in the following sentence: Where is tourist area?" ></td>
	<td class="line x" title="140:211	Although we are not able to trace the error back to its origin, such a mistake is certainly due to a commutation with a sentence like: Where is information office?" ></td>
	<td class="line x" title="141:211	that contains a similar mistake and that is found in the original linguistic resource." ></td>
	<td class="line x" title="142:211	6.2 Equivalence in content between generated paraphases and seed sentence The semantic quality of the paraphrases produced was also checked by hand on a sample of 470 paraphrases that were compared with their corresponding seed sentence." ></td>
	<td class="line x" title="143:211	We not only checked for strict equivalence, but also for meaning entailment5." ></td>
	<td class="line x" title="144:211	4The same sentence may have been generated several times for different seed sentences." ></td>
	<td class="line x" title="145:211	Overall there were 42,249 different sentences generated." ></td>
	<td class="line x" title="146:211	Their lengths in characters and words are given in Table 2." ></td>
	<td class="line x" title="147:211	5Bill Dolan, Chris Brockett, and Chris Quirk, Microsoft Research Paraphrase Corpus, http://research.microsoft.com/research/nlp/msr paraphrase.htm." ></td>
	<td class="line x" title="148:211	The following three paraphrases on the left with their corresponding seed sentences on the right are examples that were judged to be strict equivalences." ></td>
	<td class="line x" title="149:211	Can I see some ID? Could you show me some ID? Please exchange this." ></td>
	<td class="line x" title="150:211	Could you exchangethis, please." ></td>
	<td class="line x" title="151:211	Please send it to Japan." ></td>
	<td class="line x" title="152:211	Send it to Japan, please." ></td>
	<td class="line x" title="153:211	The following are examples in which there is a lack of information either in the paraphrase produced or in the seed sentence." ></td>
	<td class="line x" title="154:211	This is precisely what entailment is. Coke, please." ></td>
	<td class="line x" title="155:211	Miss, could I have acoke?" ></td>
	<td class="line x" title="156:211	I want to change money." ></td>
	<td class="line x" title="157:211	Please exchange this." ></td>
	<td class="line x" title="158:211	Sunny-side up, please." ></td>
	<td class="line x" title="159:211	Fried eggs, sunny-sideup, please." ></td>
	<td class="line x" title="160:211	The result of the sampling is that the paraphrase candidates can be considered valid paraphrases in at least 94% of the cases either by equivalence or entailment (p-value = 3.05%)." ></td>
	<td class="line x" title="161:211	The following sentences exemplify the remaining cases where two sentences were not judged valid paraphrases of one another." ></td>
	<td class="line x" title="162:211	Do you charge extra if I drop it off?" ></td>
	<td class="line x" title="163:211	There will be a drop off charge." ></td>
	<td class="line x" title="164:211	Heres one for you, sir." ></td>
	<td class="line x" title="165:211	You can get one here." ></td>
	<td class="line x" title="166:211	There it is. Yes, please sit down." ></td>
	<td class="line x" title="167:211	Table 6 summarises the distribution of paraphrase candidates according to the abovementionned classification." ></td>
	<td class="line x" title="168:211	61 0 50 100 150 200 250 300 350 1 10 100 1000 10000 number of paraphrases number of seed sentences (log scale) 0 50 100 150 200 250 300 350 0 2 4 6 8 10 12 14 16 18 number of paraphrases length of seed sentences in words Figure 1: Number of seed sentences with the same number of paraphrases (on the left)." ></td>
	<td class="line x" title="169:211	Number of paraphrases by length of seed sentence in words (on the right)." ></td>
	<td class="line x" title="170:211	0 0.2 0.4 0.6 0.8 1 0 2 4 6 8 10 12 14 average BLEU scores length of seed sentence in words 0 0.2 0.4 0.6 0.8 1 0 2 4 6 8 10 12 14 average NIST scores length of seed sentence in words 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 average BLEU scores number of paraphrases / seed sentence 0 0.2 0.4 0.6 0.8 1 0 20 40 60 80 100 120 average NIST scores number of paraphrases / seed sentence Figure 2: BLEU and NIST scores by length of seed sentence (upper graphs) and by number of paraphrases per seed sentence (lower graphs)." ></td>
	<td class="line x" title="171:211	In these graphs, each point is the score of a set of paraphrases against the seed sentence they were produced for." ></td>
	<td class="line x" title="172:211	Lower scores indicate a greater lexical and syntactical variation in paraphrases." ></td>
	<td class="line x" title="173:211	The connected points show mean values along the axis of abscissae." ></td>
	<td class="line x" title="174:211	62 Paraphrase Not a paraphrase Equivalence Entailment 346 104 20 Table 6: Equivalence or entailment in meaning of the paraphrases produced, on a sample of 470 paraphrases from various seed sentences." ></td>
	<td class="line x" title="175:211	7 Measure of lexical and syntactical variation in paraphrases 7.1 Objective measures We assessed the lexical and syntactical variation of our paraphrases on a sample of 400 seed sentences using BLEU and NIST." ></td>
	<td class="line x" title="176:211	On the contrary to evaluation of machine translation where the goal is to obtain high scores in BLEU and NIST, our goal here, when comparing a paraphrase to the seed sentence it has been produced for, is to get low scores." ></td>
	<td class="line x" title="177:211	Indeed, high scores reflect some high correlation with translation references that is a lesser variation." ></td>
	<td class="line x" title="178:211	As our goal is precisely to prepare data for evaluation with BLEU and NIST, it is thus to generate sets of paraphrases that would contain as much variation as possible to express the same meaning as the seed sentences, i.e. we look for low scores in BLEU and NIST." ></td>
	<td class="line x" title="179:211	Again, all this can be done safely as long as one is sure that the sentences compared are valid sentences and valid paraphrases." ></td>
	<td class="line x" title="180:211	This is the case of our data, as we have already shown that the paraphrases produced are 99% grammatically and semantically correct sentences and that they are paraphrases of their corresponding seed sentences in 94% of the cases." ></td>
	<td class="line x" title="181:211	As for the meaning of BLEU and NIST, they are supposed to measure complementary characteristics of translations: namely fluency and adequacy (AKIBA et al. , 2004, p. 7)." ></td>
	<td class="line x" title="182:211	BLEU tends to measure the quality in form of expression (fluency), while NIST6 tends to measure quality in meaning (adequacy)." ></td>
	<td class="line x" title="183:211	7.2 Results The scores in BLEU and NIST (both on a scale from 0 to 1) shown in Figure 2 are interpreted 6Formally, NIST is an open scale." ></td>
	<td class="line x" title="184:211	Hence, scores cannot be directly compared for different seed sentences." ></td>
	<td class="line x" title="185:211	We thus normalised them by the score of the seed sentence against itself." ></td>
	<td class="line x" title="186:211	In this way, NIST scores become comparable for different seed sentences." ></td>
	<td class="line x" title="187:211	as a measure of the lexical and syntactical variation among paraphrases." ></td>
	<td class="line x" title="188:211	The lower they are, the greater the variation." ></td>
	<td class="line x" title="189:211	The upper graphs show that this variation depends clearly on the lengths of the seed sentences." ></td>
	<td class="line x" title="190:211	The shorter the seed sentence, the greater the variation among the paraphrases produced by this method." ></td>
	<td class="line x" title="191:211	This is no surprise as the detection phase introduces a bias as was mentionned in Section 5 with the example sentence Sure." ></td>
	<td class="line x" title="192:211	The lower graphs show that the variation does not depend on the number of paraphrases per seed sentence." ></td>
	<td class="line x" title="193:211	Hence, on the contrary to a method that would produce more variations as more paraphrases are generated, in our method, the variation is not expected to change when one produces more and more paraphrases (however, the grammatical quality or the paraphrasing quality could change)." ></td>
	<td class="line x" title="194:211	In this sense, the method is scalable, i.e., one could tune the number of paraphrases wished without considerably altering the lexical and syntactical variation." ></td>
	<td class="line x" title="195:211	7.3 Comparison with reference sets produced by hand We compared the lexical and syntactical variation of our paraphrases with paraphrases created by hand for a past MT evaluation campaign (AKIBA et al. , 2004) in two language pairs: Japanese to English and Chinese to English." ></td>
	<td class="line x" title="196:211	For every reference set, we evaluated each sentence against one chosen at random and left out." ></td>
	<td class="line x" title="197:211	The mean of all these evaluation scores gives an indication on the overall internal lexical and syntactical variation inside the reference sets." ></td>
	<td class="line x" title="198:211	The lower the scores, the better the lexical and syntactical variation." ></td>
	<td class="line x" title="199:211	This scheme was applied to both reference sets created by hand, and to the one automatically produced by our method." ></td>
	<td class="line x" title="200:211	The scores obtained are shown on Figure 7." ></td>
	<td class="line x" title="201:211	Whereas BLEU scores are comparable for all reference sets, which indicates no notable difference in flu63 Average Average BLEU NIST Automatically produced set 0.11 0.39 Hand-produced set 1 0.10 0.49 Hand-produced set 2 0.11 0.49 Table 7: Measure of the lexical and syntactical variation of various reference sets produced by hand and automatically produced by our method." ></td>
	<td class="line x" title="202:211	The lower the scores, the better the lexical and syntactical variation." ></td>
	<td class="line x" title="203:211	ency, NIST scores are definitely better for the automatically produced reference set: this hints at a possibly richer lexical variation." ></td>
	<td class="line x" title="204:211	8 Conclusion We reported a technique to generate paraphrases in the view of constituting reference sets for machine translation evaluation measures like BLEU and NIST." ></td>
	<td class="line x" title="205:211	In an experiment with a linguistic resource of 97,769 sentences we generated 8,65 paraphrases in average for 16,153 seed sentences." ></td>
	<td class="line x" title="206:211	The grammaticality was evaluated by sampling and was shown to be of at least 99% grammatically and semantically correct sentences (p-value = 2.22%), a quality comparable to that of the original linguistic resource." ></td>
	<td class="line x" title="207:211	In addition, at least 96% of the candidates (p-value = 1.92%) were correct paraphrases either by meaning equivalence or entailment." ></td>
	<td class="line x" title="208:211	Finally, the lexical and syntactical variation within each paraphrase set was assessed using BLEU and NIST against the seed sentence." ></td>
	<td class="line x" title="209:211	It was found that the lexical and syntactical variation did not depend upon the number of paraphrases generated, but on the length of the seed sentence." ></td>
	<td class="line x" title="210:211	Going back to the view of constituting reference sets for machine translation evaluation, not only are the paraphrase sets produced by this method correct sentences and valid paraphrases, but they also exhibit an internal lexical and syntactical variation which was shown to be slightly superior to that of two evaluation campaign sets of paraphrases produced by hand." ></td>
	<td class="line x" title="211:211	Acknowledgements This research was supported in part by the National Institute of Information and Communications Technology." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P05-1074
Paraphrasing With Bilingual Parallel Corpora
Bannard, Colin;Callison-Burch, Chris;"></td>
	<td class="line x" title="1:147	Proceedings of the 43rd Annual Meeting of the ACL, pages 597604, Ann Arbor, June 2005." ></td>
	<td class="line x" title="2:147	c2005 Association for Computational Linguistics Paraphrasing with Bilingual Parallel Corpora Colin Bannard Chris Callison-Burch School of Informatics University of Edinburgh 2 Buccleuch Place Edinburgh, EH8 9LW {c.j.bannard, callison-burch}@ed.ac.uk Abstract Previous work has used monolingual parallel corpora to extract and generate paraphrases." ></td>
	<td class="line x" title="3:147	We show that this task can be done using bilingual parallel corpora, a much more commonly available resource." ></td>
	<td class="line x" title="4:147	Using alignment techniques from phrasebased statistical machine translation, we show how paraphrases in one language can be identified using a phrase in another language as a pivot." ></td>
	<td class="line x" title="5:147	We define a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities, and show how it can be refined to take contextual information into account." ></td>
	<td class="line x" title="6:147	We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments, and contrast the quality with paraphrases extracted from automatic alignments." ></td>
	<td class="line x" title="7:147	1 Introduction Paraphrases are alternative ways of conveying the same information." ></td>
	<td class="line x" title="8:147	Paraphrases are useful in a number of NLP applications." ></td>
	<td class="line x" title="9:147	In natural language generation the production of paraphrases allows for the creation of more varied and fluent text (Iordanskaja et al. , 1991)." ></td>
	<td class="line x" title="10:147	In multidocument summarization the identification of paraphrases allows information repeated across documents to be condensed (McKeown et al. , 2002)." ></td>
	<td class="line x" title="11:147	In the automatic evaluation of machine translation, paraphrases may help to alleviate problems presented by the fact that there are often alternative and equally valid ways of translating a text (Pang et al. , 2003)." ></td>
	<td class="line x" title="12:147	In question answering, discovering paraphrased answers may provide additional evidence that an answer is correct (Ibrahim et al. , 2003)." ></td>
	<td class="line x" title="13:147	In this paper we introduce a novel method for extracting paraphrases that uses bilingual parallel corpora." ></td>
	<td class="line oc" title="14:147	Past work (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al. , 2003; Ibrahim et al. , 2003) has examined the use of monolingual parallel corpora for paraphrase extraction." ></td>
	<td class="line o" title="15:147	Examples of monolingual parallel corpora that have been used are multiple translations of classical French novels into English, and data created for machine translation evaluation methods such as Bleu (Papineni et al. , 2002) which use multiple reference translations." ></td>
	<td class="line n" title="16:147	While the results reported for these methods are impressive, their usefulness is limited by the scarcity of monolingual parallel corpora." ></td>
	<td class="line n" title="17:147	Small data sets mean a limited number of paraphrases can be extracted." ></td>
	<td class="line n" title="18:147	Furthermore, the narrow range of text genres available for monolingual parallel corpora limits the range of contexts in which the paraphrases can be used." ></td>
	<td class="line x" title="19:147	Instead of relying on scarce monolingual parallel data, our method utilizes the abundance of bilingual parallel data that is available." ></td>
	<td class="line x" title="20:147	This allows us to create a much larger inventory of phrases that is applicable to a wider range of texts." ></td>
	<td class="line x" title="21:147	Our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (Koehn et al. , 2003)." ></td>
	<td class="line x" title="22:147	The essence of our method is to align phrases in a bilingual parallel corpus, and equate different English phrases that are aligned with the same phrase in the other language." ></td>
	<td class="line x" title="23:147	This assumption of similar mean597 Emma burst into tears and he tried to comfort her, saying things to make her smile." ></td>
	<td class="line x" title="24:147	Emma cried, and he tried to console her, adorning his words with puns." ></td>
	<td class="line x" title="25:147	Figure 1: Using a monolingal parallel corpus to extract paraphrases ing when multiple phrases map onto a single foreign language phrase is the converse of the assumption made in the word sense disambiguation work of Diab and Resnik (2002) which posits different word senses when a single English word maps onto different words in the foreign language (we return to this point in Section 4.4)." ></td>
	<td class="line x" title="26:147	The remainder of this paper is as follows: Section 2 contrasts our method for extracting paraphrases with the monolingual case, and describes how we rank the extracted paraphrases with a probability assignment." ></td>
	<td class="line x" title="27:147	Section 3 describes our experimental setup and includes information about how phrases were selected, how we manually aligned parts of the bilingual corpus, and how we evaluated the paraphrases." ></td>
	<td class="line x" title="28:147	Section 4 gives the results of our evaluation and gives a number of example paraphrases extracted with our technique." ></td>
	<td class="line x" title="29:147	Section 5 reviews related work, and Section 6 discusses future directions." ></td>
	<td class="line oc" title="30:147	2 Extracting paraphrases Much previous work on extracting paraphrases (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al. , 2003) has focused on finding identifying contexts within aligned monolingual sentences from which divergent text can be extracted, and treated as paraphrases." ></td>
	<td class="line x" title="31:147	Barzilay and McKeown (2001) gives the example shown in Figure 1 of how identical surrounding substrings can be used to extract the paraphrases of burst into tears as cried and comfort as console." ></td>
	<td class="line x" title="32:147	While monolingual parallel corpora often have identical contexts that can be used for identifying paraphrases, bilingual parallel corpora do not." ></td>
	<td class="line x" title="33:147	Instead, we use phrases in the other language as pivots: we look at what foreign language phrases the English translates to, find all occurrences of those foreign phrases, and then look back at what other English phrases they translate to." ></td>
	<td class="line x" title="34:147	We treat the other English phrases as potential paraphrases." ></td>
	<td class="line x" title="35:147	Figure 2 illustrates how a German phrase can be used as a point of identification for English paraphrases in this way." ></td>
	<td class="line x" title="36:147	Section 2.1 explains which statistical machine translation techniques are used to align phrases within sentence pairs in a bilingual corpus." ></td>
	<td class="line x" title="37:147	A significant difference between the present work and that employing monolingual parallel corpora, is that our method frequently extracts more than one possible paraphrase for each phrase." ></td>
	<td class="line x" title="38:147	We assign a probability to each of the possible paraphrases." ></td>
	<td class="line x" title="39:147	This is a mechanism for ranking paraphrases, which can be utilized when we come to select the correct paraphrase for a given context." ></td>
	<td class="line x" title="40:147	Section 2.2 explains how we calculate the probability of a paraphrase." ></td>
	<td class="line x" title="41:147	2.1 Aligning phrase pairs We use phrase alignments in a parallel corpus as pivots between English paraphrases." ></td>
	<td class="line x" title="42:147	We find these alignments using recent phrase-based approaches to statistical machine translation." ></td>
	<td class="line x" title="43:147	The original formulation of statistical machine translation (Brown et al. , 1993) was defined as a word-based operation." ></td>
	<td class="line x" title="44:147	The probability that a foreign sentence is the translation of an English sentence is calculated by summing over the probabilities of all possible word-level alignments, a, between the sentences: p(f|e) =summationdisplay a p(f,a|e) Thus Brown et al. decompose the problem of determining whether a sentence is a good translation of another into the problem of determining whether there is a sensible mapping between the words in the sentences." ></td>
	<td class="line x" title="45:147	More recent approaches to statistical translation calculate the translation probability using larger blocks of aligned text." ></td>
	<td class="line x" title="46:147	Koehn (2004), Tillmann (2003), and Vogel et al.(2003) describe various heuristics for extracting phrase alignments from the Viterbi word-level alignments that are estimated using Brown et al.(1993) models." ></td>
	<td class="line x" title="49:147	We use the heuristic for phrase alignment described in Och and Ney (2003) which aligns phrases by incrementally building longer phrases from words and phrases which have adjacent alignment points.1 1Note that while we induce the translations of phrases from 598 what is more, the relevant cost dynamic is completelyunder control im brigen ist die diesbezgliche kostenentwicklung vllig unter kontrolle we owe it to the taxpayers to keep in checkthe costs wir sind es den steuerzahlern die kosten zu habenschuldig unter kontrolle Figure 2: Using a bilingual parallel corpus to extract paraphrases 2.2 Assigning probabilities We define a paraphrase probability p(e2|e1) in terms of the translation model probabilities p(f|e1), that the original English phrase e1 translates as a particular phrase f in the other language, and p(e2|f), that the candidate paraphrase e2 translates as the foreign language phrase." ></td>
	<td class="line x" title="50:147	Since e1 can translate as multiple foreign language phrases, we sum over f: e2 = arg max e2negationslash=e1 p(e2|e1) (1) = arg max e2negationslash=e1 summationdisplay f p(f|e1)p(e2|f) (2) The translation model probabilities can be computed using any standard formulation from phrasebased machine translation." ></td>
	<td class="line x" title="51:147	For example, p(e|f) can be calculated straightforwardly using maximum likelihood estimation by counting how often the phrases e and f were aligned in the parallel corpus: p(e|f) = count(e,f)summationtext e count(e,f) (3) Note that the paraphrase probability defined in Equation 2 returns the single best paraphrase, e2, irrespective of the context in which e1 appears." ></td>
	<td class="line x" title="52:147	Since the best paraphrase may vary depending on information about the sentence that e1 appears in, we extend the paraphrase probability to include that sentence S: e2 = arg max e2negationslash=e1 p(e2|e1,S) (4) word-level alignments in this paper, direct estimation of phrasal translations (Marcu and Wong, 2002) would also suffice for extracting paraphrases from bilingual corpora." ></td>
	<td class="line x" title="53:147	a million, as far as possible, at work, big business, carbon dioxide, central america, close to, concentrate on, crystal clear, do justice to, driving force, first half, for the first time, global warming, great care, green light, hard core, horn of africa, last resort, long ago, long run, military action, military force, moment of truth, new world, noise pollution, not to mention, nuclear power, on average, only too, other than, pick up, president clinton, public transport, quest for, red cross, red tape, socialist party, sooner or later, step up, task force, turn to, under control, vocational training, western sahara, world bank Table 1: Phrases that were selected to paraphrase S allows us to re-rank the candidate paraphrases based on additional contextual information." ></td>
	<td class="line x" title="54:147	The experiments in this paper employ one variety of contextual information." ></td>
	<td class="line x" title="55:147	We include a simple language model probability, which would additionally rank e2 based on the probability of the sentence formed by substiuting e2 for e1 in S. A possible extension which we do not evaluate might be permitting only paraphrases that are the same syntactic type as the original phrase, which we could do by extending the translation model probabilities to count only phrase occurrences of that type." ></td>
	<td class="line x" title="56:147	3 Experimental Design We extracted 46 English phrases to paraphrase (shown in Table 1), randomly selected from those multi-word phrases in WordNet which also occured multiple times in the first 50,000 sentences of our bilingual corpus." ></td>
	<td class="line x" title="57:147	The bilingual corpus that we used 599 Alignment Tool . kontrolle unter vllig kostenentwickl diesbezgliche die ist brigen im .controlundercompletelyisdynamiccostrelevantthe,moreiswhat (a) Aligning the English phrase to be paraphrased haben zu kontrolle unter kosten die schuldig steuerzahlern den es sind wir .checkincoststhekeeptotaxpayersthetoitowewe Alignment Tool (b) Aligning occurrences of its German translation Figure 3: Phrases highlighted for manual alignment was the German-English section of the Europarl corpus, version 2 (Koehn, 2002)." ></td>
	<td class="line x" title="58:147	We produced automatic alignments for it with the Giza++ toolkit (Och and Ney, 2003)." ></td>
	<td class="line x" title="59:147	Because we wanted to test our method independently of the quality of word alignment algorithms, we also developed a gold standard of word alignments for the set of phrases that we wanted to paraphrase." ></td>
	<td class="line x" title="60:147	3.1 Manual alignment The gold standard alignments were created by highlighting all occurrences of the English phrase to paraphrase and manually aligning it with its German equivalent by correcting the automatic alignment, as shown in Figure 3a." ></td>
	<td class="line x" title="61:147	All occurrences of its German equivalents were then highlighted, and aligned with their English translations (Figure 3b)." ></td>
	<td class="line x" title="62:147	The other words in the sentences were left with their automatic alignments." ></td>
	<td class="line x" title="63:147	3.2 Paraphrase evaluation We evaluated the accuracy of each of the paraphrases that was extracted from the manually aligned data, as well as the top ranked paraphrases from the experimental conditions detailed below in Section 3.3." ></td>
	<td class="line x" title="64:147	Because the acccuracy of paraphrases can vary depending on context, we substituted each Under control This situation is in check in terms of security." ></td>
	<td class="line x" title="65:147	This situation is checked in terms of security." ></td>
	<td class="line x" title="66:147	This situation is curbed in terms of security." ></td>
	<td class="line x" title="67:147	This situation is curb in terms of security." ></td>
	<td class="line x" title="68:147	This situation is limit in terms of security." ></td>
	<td class="line x" title="69:147	This situation is slow down in terms of security." ></td>
	<td class="line x" title="70:147	Figure 4: Paraphrases substituted in for the original phrase set of candidate paraphrases into between 210 sentences which contained the original phrase." ></td>
	<td class="line x" title="71:147	Figure 4 shows the paraphrases for under control substituted into one of the sentences in which it occurred." ></td>
	<td class="line x" title="72:147	We created a total of 289 such evaluation sets, with a total of 1366 unique sentences created through substitution." ></td>
	<td class="line x" title="73:147	We had two native English speakers produce judgments as to whether the new sentences preserved the meaning of the original phrase and as to whether they remained grammatical." ></td>
	<td class="line x" title="74:147	Paraphrases that were judged to preserve both meaning and grammaticality were considered to be correct, and examples which failed on either judgment were considered to be incorrect." ></td>
	<td class="line x" title="75:147	In Figure 4 in check, checked, and curbed were 600 under control checked, curb, curbed, in check, limit, slow down sooner or later at some point, eventually military force armed forces, defence, force, forces, military forces, peace-keeping personnel long ago a little time ago, a long time, a long time ago, a lot of time, a while ago, a while back, far, for a long time, for some time, for such a long time, long, long period of time, long term, long time, long while, overdue, some time, some time ago green light approval, call, go-ahead, indication, message, sign, signal, signals, formal go-ahead great care a careful approach, greater emphasis, particular attention, special attention, specific attention, very careful first half first six months crystal clear absolutely clear, all clarity, clear, clearly, in great detail, no mistake, no uncertain, obvious, obviously, particularly clear, perfectly clear, quite clear, quite clearly, quite explicitly, quite openly, very clear, very clear and comprehensive, very clearly, very sure, very unclear, very well carbon dioxide co2 at work at the workplace, employment, held, holding, in the work sphere, operate, organised, taken place, took place, working Table 2: Paraphrases extracted from a manually word-aligned parallel corpus judged to be correct and curb, limit and slow down were judged to be incorrect." ></td>
	<td class="line x" title="76:147	The inter-annotator agreement for these judgements was measured at  = 0.605, which is conventionally interpreted as good agreement." ></td>
	<td class="line x" title="77:147	3.3 Experiments We evaluated the accuracy of top ranked paraphrases when the paraphrase probability was calculated using: 1." ></td>
	<td class="line x" title="78:147	The manual alignments, 2." ></td>
	<td class="line x" title="79:147	The automatic alignments, 3." ></td>
	<td class="line x" title="80:147	Automatic alignments produced over multiple corpora in different languages, 4." ></td>
	<td class="line x" title="81:147	All of the above with language model reranking." ></td>
	<td class="line x" title="82:147	5." ></td>
	<td class="line x" title="83:147	All of the above with the candidate paraphrases limited to the same sense as the original phrase." ></td>
	<td class="line x" title="84:147	4 Results We report the percentage of correct translations (accuracy) for each of these experimental conditions." ></td>
	<td class="line x" title="85:147	A summary of these can be seen in Table 3." ></td>
	<td class="line x" title="86:147	This section will describe each of the set-ups and the score reported in more detail." ></td>
	<td class="line x" title="87:147	4.1 Manual alignments Table 2 gives a set of example paraphrases extracted from the gold standard alignments." ></td>
	<td class="line x" title="88:147	The italicized paraphrases are those that were assigned the highest probability by Equation 2, which chooses a single best paraphrase without regard for context." ></td>
	<td class="line x" title="89:147	The 289 sentences created by substituting the italicized paraphrases in for the original phrase were judged to be correct an average of 74.9% of the time." ></td>
	<td class="line x" title="90:147	Ignoring the constraint that the new sentences remain grammatically correct, these paraphrases were judged to have the correct meaning 84.7% of the time." ></td>
	<td class="line x" title="91:147	This suggests that the context plays a more important role with respect to the grammaticality of substituted paraphrases than with respect to their meaning." ></td>
	<td class="line x" title="92:147	In order to allow the surrounding words in the sentence to have an influence on which paraphrase was selected, we re-ranked the paraphrase probabilities based on a trigram language model trained on the entire English portion of the Europarl corpus." ></td>
	<td class="line x" title="93:147	Paraphrases were selected from among all those in Table 2, and not constrained to the italicized phrases." ></td>
	<td class="line x" title="94:147	In the case of the paraphrases extracted from the manual word alignments, the language model re-ranking had virtually no influence, and resulted in a slight dip in accuracy to 71.7% 601 Paraphrase Prob Paraphrase Prob & LM Correct Meaning Manual Alignments 74.9 71.7 84.7 Automatic Alignments 48.9 55.3 64.5 Using Multiple Corpora 55.0 57.4 65.4 Word Sense Controlled 57.0 61.9 70.4 Table 3: Paraphrase accuracy and correct meaning for the different data conditions 4.2 Automatic alignments In this experimental condition paraphrases were extracted from a set of automatic alignments produced by running Giza++ over a set of 1,036,000 GermanEnglish sentence pairs (roughly 28,000,000 words in each language)." ></td>
	<td class="line x" title="95:147	When the single best paraphrase (irrespective of context) was used in place of the original phrase in the evaluation sentence the accuracy reached 48.9% which is quite low compared to the 74.9% of the manually aligned set." ></td>
	<td class="line x" title="96:147	As with the manual alignments it seems that we are selecting phrases which have the correct meaning but are not grammatical in context." ></td>
	<td class="line x" title="97:147	Indeed our judges thought the meaning of the paraphrases to be correct in 64.5% of cases." ></td>
	<td class="line x" title="98:147	Using a language model to select the best paraphrase given the context reduces the number of ungrammatical examples and gives an improvement in quality from 48.9% to 55.3% correct." ></td>
	<td class="line x" title="99:147	These results suggest two things: that improving the quality of automatic alignments would lead to more accurate paraphrases, and that there is room for improvement in limiting the paraphrases by their context." ></td>
	<td class="line x" title="100:147	We address these points below." ></td>
	<td class="line x" title="101:147	4.3 Using multiple corpora Work in statistical machine translation suggests that, like many other machine learning problems, performance increases as the amount of training data increases." ></td>
	<td class="line x" title="102:147	Och and Ney (2003) show that the accuracy of alignments produced by Giza++ improve as the size of the training corpus increases." ></td>
	<td class="line x" title="103:147	Since we used the whole of the German-English section of the Europarl corpus, we could not try improving the alignments by simply adding more German-English training data." ></td>
	<td class="line x" title="104:147	However, there is nothing that limits our paraphrase extraction method to drawing on candidate paraphrases from a single target language." ></td>
	<td class="line x" title="105:147	We therefore re-formulated the paraphrase probability to include multiple corpora, as follows: e2 = arg max e2negationslash=e1 summationdisplay C summationdisplay f in C p(f|e1)p(e2|f) (5) where C is a parallel corpus from a set of parallel corpora." ></td>
	<td class="line x" title="106:147	For this condition we used Giza++ to align the French-English, Spanish-English, and ItalianEnglish portions of the Europarl corpus in addition to the German-English portion, for a total of around 4,000,000 sentence pairs in the training data." ></td>
	<td class="line x" title="107:147	The accuracy of paraphrases extracted over multiple corpora increased to 55%, and further to 57.4% when the language model re-ranking was included." ></td>
	<td class="line x" title="108:147	4.4 Controlling for word sense As mentioned in Section 1, the way that we extract paraphrases is the converse of the methodology employed in word sense disambiguation work that uses parallel corpora (Diab and Resnik, 2002)." ></td>
	<td class="line x" title="109:147	The assumption made in the word sense disambiguation work is that if a source language word aligns with different target language words then those words may represent different word senses." ></td>
	<td class="line x" title="110:147	This can be observed in the paraphrases for at work in Table 2." ></td>
	<td class="line x" title="111:147	The paraphrases at the workplace, employment, and in the work sphere are a different sense of the phrase than operate, held, and holding, and they are aligned with different German phrases." ></td>
	<td class="line x" title="112:147	When we calculate the paraphrase probability we sum over different target language phrases." ></td>
	<td class="line x" title="113:147	Therefore the English phrases that are aligned with the different German phrases (which themselves maybe indicative of different word senses) are mingled." ></td>
	<td class="line x" title="114:147	Performance may be degraded since paraphrases that reflect different senses of the original phrase, and which therefore have a different meaning, are included in the same candidate set." ></td>
	<td class="line x" title="115:147	602 We therefore performed an experiment to see whether improvement could be had by limiting the candidate paraphrases to be the same sense as the original phrase in each test sentence." ></td>
	<td class="line x" title="116:147	To do this, we used the fact that our test sentences were drawn from a parallel corpus." ></td>
	<td class="line x" title="117:147	We limited phrases to the same word sense by constraining the candidate paraphrases to those that aligned with the same target language phrase." ></td>
	<td class="line x" title="118:147	Our basic paraphrase calculation was therefore: p(e2|e1,f) = p(f|e1)p(e2|f) (6) Using the foreign language phrase to identify the word sense is obviously not applicable in monolingual settings, but acts as a convenient stand-in for a proper word sense disambiguation algorithm here." ></td>
	<td class="line x" title="119:147	When word sense is controlled in this way, the accuracy of the paraphrases extracted from the automatic alignments raises dramatically from 48.9% to 57% without language model re-ranking, and further to 61.9% when language model re-ranking was included." ></td>
	<td class="line x" title="120:147	5 Related Work Barzilay and McKeown (2001) extract both singleand multiple-word paraphrases from a monolingual parallel corpus." ></td>
	<td class="line x" title="121:147	They co-train a classifier to identify whether two phrases were paraphrases of each other based on their surrounding context." ></td>
	<td class="line x" title="122:147	Two disadvantages of this method are that it requires identical bounding substrings, and has bias towards single words." ></td>
	<td class="line x" title="123:147	For an evaluation set of 500 paraphrases, they report an average precision of 86% at identifying paraphrases out of context, and of 91% when the paraphrases are substituted into the original context of the aligned sentence." ></td>
	<td class="line x" title="124:147	The results of our systems are not directly comparable, since Barzilay and McKeown (2001) evaluated their paraphrases with a different set of criteria (they asked judges whether to judge paraphrases based on approximate conceptual equivalence)." ></td>
	<td class="line x" title="125:147	Furthermore, their evaluation was carried out only by substituting the paraphrase in for the phrase with the identical context, and not in for arbitrary occurrences of the original phrase, as we have done." ></td>
	<td class="line x" title="126:147	Lin and Pantel (2001) use a standard (nonparallel) monolingual corpus to generate paraphrases, based on dependancy graphs and distributional similarity." ></td>
	<td class="line x" title="127:147	One strong disadvantage of this method is that their paraphrases can also have opposite meanings." ></td>
	<td class="line x" title="128:147	Ibrahim et al.(2003) combine the two approaches: aligned monolingual corpora and parsing." ></td>
	<td class="line x" title="130:147	They evaluated their system with human judges who were asked whether the paraphrases were roughly interchangeable given the genre, scored an average of 41% on a set of 130 paraphrases, with the judges all agreeing 75% of the time, and a correlation of 0.66." ></td>
	<td class="line x" title="131:147	The shortcomings of this method are that it is dependent upon parse quality, and is limited by the rareness of the data." ></td>
	<td class="line x" title="132:147	Pang et al.(2003) use parse trees over sentences in monolingual parallel corpus to identify paraphrases by grouping similar syntactic constituents." ></td>
	<td class="line x" title="134:147	They use heuristics such as keyword checking to limit the over-application of this method." ></td>
	<td class="line x" title="135:147	Our alignment method might be an improvement of their heuristics for choosing which constituents ought to be grouped." ></td>
	<td class="line x" title="136:147	6 Discussion and Future Work In this paper we have introduced a novel method for extracting paraphrases, which we believe greatly increases the usefulness of paraphrasing in NLP applications." ></td>
	<td class="line x" title="137:147	The advantages of our method are that it:  Produces a ranked list of high quality paraphrases with associated probabilities, from which the best paraphrase can be chosen according to the target context." ></td>
	<td class="line x" title="138:147	We have shown how a language model can be used to select the best paraphrase for a particular context from this list." ></td>
	<td class="line x" title="139:147	 Straightforwardly handles multi-word units." ></td>
	<td class="line x" title="140:147	Whereas for previous approaches the evaluation has been performed over mostly single word paraphrases, our results are reported exclusively over units of between 2 and 4 words." ></td>
	<td class="line x" title="141:147	 Because we use a much more abundant source of data, our method can be used for a much wider range of text genres than previous approaches, namely any for which parallel data is available." ></td>
	<td class="line x" title="142:147	603 One crucial thing to note is that we have demonstrated our paraphrases to be of higher quality when the alignments used to produce them are improved." ></td>
	<td class="line x" title="143:147	This means that our method will reap the benefits of research that improvements to automatic alignment techniques (Callison-Burch et al. , 2004), and will further improve as more parallel data becomes available." ></td>
	<td class="line x" title="144:147	In the future we plan to:  Investigate whether our re-ranking can be further improved by using a syntax-based language model." ></td>
	<td class="line x" title="145:147	 Formulate a paraphrase probability for sentential paraphrases, and use this to try to identify paraphrases across documents in order to condense information for multi-document summarization." ></td>
	<td class="line x" title="146:147	 See whether paraphrases can be used to increase coverage for statistical machine translation when translating into low-density languages which have small parallel corpora." ></td>
	<td class="line x" title="147:147	Acknowledgments The authors would like to thank Beatrice Alex, Marco Kuhlmann, and Josh Schroeder for their valuable input as well as their time spent annotating and contributing to the software." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W05-1210
Definition And Analysis Of Intermediate Entailment Levels
Bar-Haim, Roy;Szpektor, Idan;Glickman, Oren;"></td>
	<td class="line x" title="1:142	Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, pages 5560, Ann Arbor, June 2005." ></td>
	<td class="line x" title="2:142	c2005 Association for Computational Linguistics Definition and Analysis of Intermediate Entailment Levels Roy Bar-Haim, Idan Szpektor, Oren Glickman Computer Science Department Bar Ilan University Ramat-Gan 52900, Israel {barhair,szpekti,glikmao}@cs.biu.ac.il Abstract In this paper we define two intermediate models of textual entailment, which correspond to lexical and lexical-syntactic levels of representation." ></td>
	<td class="line x" title="3:142	We manually annotated a sample from the RTE dataset according to each model, compared the outcome for the two models, and explored how well they approximate the notion of entailment." ></td>
	<td class="line x" title="4:142	We show that the lexicalsyntactic model outperforms the lexical model, mainly due to a much lower rate of false-positives, but both models fail to achieve high recall." ></td>
	<td class="line x" title="5:142	Our analysis also shows that paraphrases stand out as a dominant contributor to the entailment task." ></td>
	<td class="line x" title="6:142	We suggest that our models and annotation methods can serve as an evaluation scheme for entailment at these levels." ></td>
	<td class="line x" title="7:142	1 Introduction Textual entailment has been proposed recently as a generic framework for modeling semantic variability in many Natural Language Processing applications, such as Question Answering, Information Extraction, Information Retrieval and Document Summarization." ></td>
	<td class="line x" title="8:142	The textual entailment relationship holds between two text fragments, termed text and hypothesis, if the truth of the hypothesis can be inferred from the text." ></td>
	<td class="line x" title="9:142	Identifying entailment is a complex task that incorporates many levels of linguistic knowledge and inference." ></td>
	<td class="line x" title="10:142	The complexity of modeling entailment was demonstrated in the first PASCAL Challenge Workshop on Recognizing Textual Entailment (RTE) (Dagan et al. , 2005)." ></td>
	<td class="line x" title="11:142	Systems that participated in the challenge used various combinations of NLP components in order to perform entailment inferences." ></td>
	<td class="line x" title="12:142	These components can largely be classified as operating at the lexical, syntactic and semantic levels (see Table 1 in (Dagan et al. , 2005))." ></td>
	<td class="line x" title="13:142	However, only little research was done to analyze the contribution of each inference level, and on the contribution of individual inference mechanisms within each level." ></td>
	<td class="line x" title="14:142	This paper suggests that decomposing the complex task of entailment into subtasks, and analyzing the contribution of individual NLP components for these subtasks would make a step towards better understanding of the problem, and for pursuing better entailment engines." ></td>
	<td class="line x" title="15:142	We set three goals in this paper." ></td>
	<td class="line x" title="16:142	First, we consider two modeling levels that employ only part of the inference mechanisms, but perform perfectly at each level." ></td>
	<td class="line x" title="17:142	We explore how well these models approximate the notion of entailment, and analyze the differences between the outcome of the different levels." ></td>
	<td class="line x" title="18:142	Second, for each of the presented levels, we evaluate the distribution (and contribution) of each of the inference mechanisms typically associated with that level." ></td>
	<td class="line x" title="19:142	Finally, we suggest that the definitions of entailment at different levels of inference, as proposed in this paper, can serve as guidelines for manual annotation of a gold standard for evaluating systems that operate at a particular level." ></td>
	<td class="line x" title="20:142	Altogether, we set forth a possible methodology for annotation and analysis of entail55 ment datasets." ></td>
	<td class="line x" title="21:142	We introduce two levels of entailment: Lexical and Lexical-Syntactic." ></td>
	<td class="line x" title="22:142	We propose these levels as intermediate stages towards a complete entailment model." ></td>
	<td class="line x" title="23:142	We define an entailment model for each level and manually evaluate its performance over a sample from the RTE test-set." ></td>
	<td class="line x" title="24:142	We focus on these two levels as they correspond to well-studied NLP tasks, for which robust tools and resources exist, e.g. parsers, part of speech taggers and lexicons." ></td>
	<td class="line x" title="25:142	At each level we included inference types that represent common practice in the field." ></td>
	<td class="line x" title="26:142	More advanced processing levels which involve logical/semantic inference are less mature and were left beyond the scope of this paper." ></td>
	<td class="line x" title="27:142	We found that the main difference between the lexical and lexical-syntactic levels is that the lexicalsyntactic level corrects many false-positive inferences done at the lexical level, while introducing only a few false-positives of its own." ></td>
	<td class="line x" title="28:142	As for identifying positive cases (recall), both systems exhibit similar performance, and were found to be complementary." ></td>
	<td class="line x" title="29:142	Neither of the levels was able to identify more than half of the positive cases, which emphasizes the need for deeper levels of analysis." ></td>
	<td class="line x" title="30:142	Among the different inference components, paraphrases stand out as a dominant contributor to the entailment task, while synonyms and derivational transformations were found to be the most frequent at the lexical level." ></td>
	<td class="line x" title="31:142	Using our definitions of entailment models as guidelines for manual annotation resulted in a high level of agreement between two annotators, suggesting that the proposed models are well-defined." ></td>
	<td class="line x" title="32:142	Our study follows on previous work (Vanderwende et al. , 2005), which analyzed the RTE Challenge test-set to find the percentage of cases in which syntactic analysis alone (with optional use of thesaurus for the lexical level) suffices to decide whether or not entailment holds." ></td>
	<td class="line x" title="33:142	Our study extends this work by considering a broader range of inference levels and inference mechanisms and providing a more detailed view." ></td>
	<td class="line x" title="34:142	A fundamental difference between the two works is that while Vanderwende et al. did not make judgements on cases where additional knowledge was required beyond syntax, our entailment models were evaluated over all of the cases, including those that require higher levels of inference." ></td>
	<td class="line x" title="35:142	This allows us to view the entailment model at each level as an idealized system approximating full entailment, and to evaluate its overall success." ></td>
	<td class="line x" title="36:142	The rest of the paper is organized as follows: section 2 provides definitions for the two entailment levels; section 3 describes the annotation experiment we performed, its results and analysis; section 4 concludes and presents planned future work." ></td>
	<td class="line x" title="37:142	2 Definition of Entailment Levels In this section we present definitions for two entailment models that correspond to the Lexical and Lexical-Syntactic levels." ></td>
	<td class="line x" title="38:142	For each level we describe the available inference mechanisms." ></td>
	<td class="line x" title="39:142	Table 1 presents several examples from the RTE test-set together with annotation of entailment at the different levels." ></td>
	<td class="line x" title="40:142	2.1 The Lexical entailment level At the lexical level we assume that the text T and hypothesis H are represented by a bag of (possibly multi-word) terms, ignoring function words." ></td>
	<td class="line x" title="41:142	At this level we define that entailment holds between T and H if every term h in H can be matched by a corresponding entailing term t in T. t is considered as entailing h if either h and t share the same lemma and part of speech, or t can be matched with h through a sequence of lexical transformations of the types described below." ></td>
	<td class="line x" title="42:142	Morphological derivations This inference mechanism considers two terms as equivalent if one can be obtained from the other by some morphological derivation." ></td>
	<td class="line x" title="43:142	Examples include nominalizations (e.g. acquisition  acquire), pertainyms (e.g. Afghanistan  Afghan), or nominal derivations like terrorist  terror." ></td>
	<td class="line x" title="44:142	Ontological relations This inference mechanism refers to ontological relations between terms." ></td>
	<td class="line x" title="45:142	A term is inferred from another term if a chain of valid ontological relations between the two terms exists (Andreevskaia et al. , 2005)." ></td>
	<td class="line x" title="46:142	In our experiment we regarded the following three ontological relations as providing entailment inferences: (1) synonyms (e.g. free  release in example 1361, Table 1); (2) hypernym (e.g. produce  make) and (3) meronym-holonym (e.g. executive  company)." ></td>
	<td class="line x" title="47:142	56 No." ></td>
	<td class="line x" title="48:142	Text Hypothesis Task Ent." ></td>
	<td class="line x" title="49:142	Lex." ></td>
	<td class="line x" title="50:142	Ent." ></td>
	<td class="line x" title="51:142	Syn." ></td>
	<td class="line x" title="52:142	Ent." ></td>
	<td class="line x" title="53:142	322 Turnout for the historic vote for the first time since the EU took in 10 new members in May has hit a record low of 45.3%." ></td>
	<td class="line x" title="54:142	New members joined the EU." ></td>
	<td class="line x" title="55:142	IR true false true 1361 A Filipino hostage in Iraq was released." ></td>
	<td class="line x" title="56:142	A Filipino hostage was freed in Iraq." ></td>
	<td class="line x" title="57:142	CD true true true 1584 Although a Roscommon man by birth, born in Rooskey in 1932, Albert The Slasher Reynolds will forever be a Longford man by association." ></td>
	<td class="line x" title="58:142	Albert Reynolds was born in Co. Roscommon." ></td>
	<td class="line x" title="59:142	QA true true true 1911 The SPD got just 21.5% of the vote in the European Parliament elections, while the conservative opposition parties polled 44.5%." ></td>
	<td class="line x" title="60:142	The SPD is defeated by the opposition parties." ></td>
	<td class="line x" title="61:142	IE true false false 2127 Coyote shot after biting girl in Vanier Park." ></td>
	<td class="line x" title="62:142	Girl shot in park." ></td>
	<td class="line x" title="63:142	IR false true false Table 1: Examples of text-hypothesis pairs, taken from the PASCAL RTE test-set." ></td>
	<td class="line x" title="64:142	Each line includes the example number at the RTE test-set, the text and hypothesis, the task within the test-set, whether entailment holds between the text and hypothesis (Ent.), whether Lexical entailment holds (Lex." ></td>
	<td class="line x" title="65:142	Ent)." ></td>
	<td class="line x" title="66:142	and whether Lexical-Syntactic entailment holds (Syn." ></td>
	<td class="line x" title="67:142	Ent.)." ></td>
	<td class="line x" title="68:142	Lexical World knowledge This inference mechanism refers to world knowledge reflected at the lexical level, by which the meaning of one term can be inferred from the other." ></td>
	<td class="line x" title="69:142	It includes both knowledge about named entities, such as Taliban  organization and Roscommon  Co. Roscommon (example 1584 in Table 1), and other lexical relations between words, such as WordNets relations cause (e.g. kill  die) and entail (e.g. snore  sleep)." ></td>
	<td class="line x" title="70:142	2.2 The Lexical-syntactic entailment level At the lexical-syntactic level we assume that the text and the hypothesis are represented by the set of syntactic dependency relations of their dependency parse." ></td>
	<td class="line x" title="71:142	At this level we ignore determiners and auxiliary verbs, but do include relations involving other function words." ></td>
	<td class="line x" title="72:142	We define that entailment holds between T and H if the relations within H can be covered by the relations in T. In the trivial case, lexical-syntactic entailment holds if all the relations composing H appear verbatim in T (while additional relations within T are allowed)." ></td>
	<td class="line x" title="73:142	Otherwise, such coverage can be obtained by a sequence of transformations applied to the relations in T, which should yield all the relations in H. One type of such transformations are the lexical transformations, which replace corresponding lexical items, as described in sub-section 2.1." ></td>
	<td class="line x" title="74:142	When applying morphological derivations it is assumed that the syntactic structure is appropriately adjusted." ></td>
	<td class="line x" title="75:142	For example, Mexico produces oil can be mapped to oil production by Mexico (the NOMLEX resource (Macleod et al. , 1998) provides a good example for systematic specification of such transformations)." ></td>
	<td class="line x" title="76:142	Additional types of transformations at this level are specified below." ></td>
	<td class="line x" title="77:142	Syntactic transformations This inference mechanism refers to transformations between syntactic structures that involve the same lexical elements and preserve the meaning of the relationships between them (as analyzed in (Vanderwende et al. , 2005))." ></td>
	<td class="line x" title="78:142	Typical transformations include passive-active and apposition (e.g. An Wang, a native of Shanghai  An Wang is a native of Shanghai)." ></td>
	<td class="line x" title="79:142	57 Entailment paraphrases This inference mechanism refers to transformations that modify the syntactic structure of a text fragment as well as some of its lexical elements, while holding an entailment relationship between the original text and the transformed one." ></td>
	<td class="line oc" title="80:142	Such transformations are typically denoted as paraphrases in the literature, where a wealth of methods for their automatic acquisition were proposed (Lin and Pantel, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003; Szpektor et al. , 2004)." ></td>
	<td class="line x" title="81:142	Following the same spirit, we focus here on transformations that are local in nature, which, according to the literature, may be amenable for large scale acquisition." ></td>
	<td class="line x" title="82:142	Examples include: X is Y man by birth  X was born in Y (example 1584 in Table 1), X take in Y  Y join X1 and X is holy book of Y  Y follow X2." ></td>
	<td class="line x" title="83:142	Co-reference Co-references provide equivalence relations between different terms in the text and thus induce transformations that replace one term in a text with any of its co-referenced terms." ></td>
	<td class="line x" title="84:142	For example, the sentence Italy and Germany have each played twice, and they havent beaten anybody yet.3 entails Neither Italy nor Germany have won yet, involving the co-reference transformation they  Italy and Germany." ></td>
	<td class="line x" title="85:142	Example 1584 in Table 1 demonstrates the need to combine different inference mechanisms to achieve lexical-syntactic entailment, requiring world-knowledge, paraphrases and syntactic transformations." ></td>
	<td class="line x" title="86:142	3 Empirical Analysis In this section we present the experiment that we conducted in order to analyze the two entailment levels, which are presented in section 2, in terms of relative performance and correlation with the notion of textual entailment." ></td>
	<td class="line x" title="87:142	3.1 Data and annotation procedure The RTE test-set4 contains 800 Text-Hypothesis pairs (usually single sentences), which are typical 1Example no 322 in the PASCAL RTE test-set." ></td>
	<td class="line x" title="88:142	2Example no 1575 in the PASCAL RTE test-set." ></td>
	<td class="line x" title="89:142	3Example no 298 in the PASCAL RTE test-set." ></td>
	<td class="line x" title="90:142	4The complete RTE dataset can be obtained at http://www.pascal-network.org/Challenges/RTE/Datasets/ to various NLP applications." ></td>
	<td class="line x" title="91:142	Each pair is annotated with a boolean value, indicating whether the hypothesis is entailed by the text or not, and the test-set is balanced in terms of positive and negative cases." ></td>
	<td class="line x" title="92:142	We shall henceforth refer to this annotation as the gold standard." ></td>
	<td class="line x" title="93:142	We constructed a sample of 240 pairs from four different tasks in the test-set, which correspond to the main applications that may benefit from entailment: information extraction (IE), information retrieval (IR), question answering (QA), and comparable documents (CD)." ></td>
	<td class="line x" title="94:142	We randomly picked 60 pairs from each task, and in total 118 of the cases were positive and 122 were negative." ></td>
	<td class="line x" title="95:142	In our experiment, two of the authors annotated, for each of the two levels, whether or not entailment can be established in each of the 240 pairs." ></td>
	<td class="line x" title="96:142	The annotators agreed on 89.6% of the cases at the lexical level, and 88.8% of the cases at the lexical-syntactic level, with Kappa statistics of 0.78 and 0.73, respectively, corresponding to substantial agreement (Landis and Koch, 1977)." ></td>
	<td class="line x" title="97:142	This relatively high level of agreement suggests that the notion of lexical and lexical-syntactic entailment we propose are indeed well-defined." ></td>
	<td class="line x" title="98:142	Finally, in order to establish statistics from the annotations, the annotators discussed all the examples they disagreed on and produced a final joint decision." ></td>
	<td class="line x" title="99:142	3.2 Evaluating the different levels of entailment L LS True positive (118) 52 59 False positive (122) 36 10 Recall 44% 50% Precision 59% 86% F1 0.5 0.63 Accuracy 58% 71% Table 2: Results per level of entailment." ></td>
	<td class="line x" title="100:142	Table 2 summarizes the results obtained from our annotated dataset for both lexical (L) and lexicalsyntactic (LS) levels." ></td>
	<td class="line x" title="101:142	Taking a system-oriented perspective, the annotations at each level can be viewed as the classifications made by an idealized system that includes a perfect implementation of the inference mechanisms in that level." ></td>
	<td class="line x" title="102:142	The first two 58 rows show for each level how the cases, which were recognized as positive by this level (i.e. the entailment holds), are distributed between true positive (i.e. positive according to the gold standard) and false positive (negative according to the gold standard)." ></td>
	<td class="line x" title="103:142	The total number of positive and negative pairs in the dataset is reported in parentheses." ></td>
	<td class="line x" title="104:142	The rest of the table details recall, precision, F1 and accuracy." ></td>
	<td class="line x" title="105:142	The distribution of the examples in the RTE testset cannot be considered representative of a realworld distribution (especially because of the controlled balance between positive and negative examples)." ></td>
	<td class="line x" title="106:142	Thus, our statistics are not appropriate for accurate prediction of application performance." ></td>
	<td class="line x" title="107:142	Instead, we analyze how well these simplified models of entailment succeed in approximating real entailment, and how they compare with each other." ></td>
	<td class="line x" title="108:142	The proportion between true and false positive cases at the lexical level indicates that the correlation between lexical match and entailment is quite low, reflected in the low precision achieved by this level (only 59%)." ></td>
	<td class="line x" title="109:142	This result can be partly attributed to the idiosyncracies of the RTE test-set: as reported in (Dagan et al. , 2005), samples with high lexical match were found to be biased towards the negative side." ></td>
	<td class="line x" title="110:142	Interestingly, our measured accuracy correlates well with the performance of systems at the PASCAL RTE Workshop, where the highest reported accuracy of a lexical system is 0.586 (Dagan et al. , 2005)." ></td>
	<td class="line x" title="111:142	As one can expect, adding syntax considerably reduces the number of false positives from 36 to only 10." ></td>
	<td class="line x" title="112:142	Surprisingly, at the same time the number of true positive cases grows from 52 to 59, and correspondingly, precision rise to 86%." ></td>
	<td class="line x" title="113:142	Interestingly, neither the lexical nor the lexical-syntactic level are able to cover more than half of the positive cases (e.g. example 1911 in Table 1)." ></td>
	<td class="line x" title="114:142	In order to better understand the differences between the two levels, we next analyze the overlap between them, presented in Table 3." ></td>
	<td class="line x" title="115:142	Looking at Table 3(a), which contains only the positive cases, we see that many examples were recognized only by one of the levels." ></td>
	<td class="line x" title="116:142	This interesting phenomenon can be explained on the one hand by lexical matches that could not be validated in the syntactic level, and on the other hand by the use of paraphrases, which are Lexical-Syntactic H  T HnotdblarrowrightT Lexical H  T 38 14HnotdblarrowrightT 21 45 (a) positive examples Lexical-Syntactic H  T HnotdblarrowrightT Lexical H  T 7 29HnotdblarrowrightT 3 83 (b) negative examples Table 3: Correlation between the entailment levels." ></td>
	<td class="line x" title="117:142	(a) includes only the positive examples from the RTE dataset sample, and (b) includes only the negative examples." ></td>
	<td class="line x" title="118:142	introduced only in the lexical-syntactic level." ></td>
	<td class="line x" title="119:142	(e.g. example 322 in Table 1)." ></td>
	<td class="line x" title="120:142	This relatively symmetric situation changes as we move to the negative cases, as shown in Table 3(b)." ></td>
	<td class="line x" title="121:142	By adding syntactic constraints, the lexical-syntactic level was able to fix 29 false positive errors, misclassified at the lexical level (as demonstrated in example 2127, Table 1), while introducing only 3 new false-positive errors." ></td>
	<td class="line x" title="122:142	This exemplifies the importance of syntactic matching for precision." ></td>
	<td class="line x" title="123:142	3.3 The contribution of various inference mechanisms Inference Mechanism f triangleR % Synonym 19 14.4% 16.1% Morphological 16 10.1% 13.5% Lexical World knowledge 12 8.4% 10.1% Hypernym 7 4.2% 5.9% Mernoym 1 0.8% 0.8% Entailment Paraphrases 37 26.2% 31.3% Syntactic transformations 22 16.9% 18.6% Coreference 10 5.0% 8.4% Table 4: The frequency (f), contribution to recall (triangleR) and percentage (%), within the gold standard positive examples, of the various inference mechanisms at each level, ordered by their significance." ></td>
	<td class="line x" title="124:142	59 In order to get a sense of the contribution of the various components at each level, statistics on the inference mechanisms that contributed to the coverage of the hypothesis by the text (either full or partial) were recorded by one annotator." ></td>
	<td class="line x" title="125:142	Only the positive cases in the gold standard were considered." ></td>
	<td class="line x" title="126:142	For each inference mechanism we measured its frequency, its contribution to the recall of the related level and the percentage of cases in which it is required for establishing entailment." ></td>
	<td class="line x" title="127:142	The latter also takes into account cases where only partial coverage could be achieved, and thus indicates the significance of each inference mechanism for any entailment system, regardless of the models presented in this paper." ></td>
	<td class="line x" title="128:142	The results are summarized in Table 4." ></td>
	<td class="line x" title="129:142	From Table 4 it stands that paraphrases are the most notable contributors to recall." ></td>
	<td class="line x" title="130:142	This result indicates the importance of paraphrases to the entailment task and the need for large-scale paraphrase collections." ></td>
	<td class="line x" title="131:142	Syntactic transformations are also shown to contribute considerably, indicating the need for collections of syntactic transformations as well." ></td>
	<td class="line x" title="132:142	In that perspective, we propose our annotation framework as means for evaluating collections of paraphrases or syntactic transformations in terms of recall." ></td>
	<td class="line x" title="133:142	Finally, we note that the co-reference moderate contribution can be partly attributed to the idiosyncracies of the RTE test-set: the annotators were guided to replace anaphors with the appropriate reference, as reported in (Dagan et al. , 2005)." ></td>
	<td class="line x" title="134:142	4 Conclusions In this paper we presented the definition of two entailment models, Lexical and Lexical-Syntactic, and analyzed their performance manually." ></td>
	<td class="line x" title="135:142	Our experiment shows that the lexical-syntactic level outperforms the lexical level in all measured aspects." ></td>
	<td class="line x" title="136:142	Furthermore, paraphrases and syntactic transformations emerged as the main contributors to recall." ></td>
	<td class="line x" title="137:142	These results suggest that a lexical-syntactic framework is a promising step towards a complete entailment model." ></td>
	<td class="line x" title="138:142	Beyond these empirical findings we suggest that the presented methodology can be used generically to annotate and analyze entailment datasets." ></td>
	<td class="line x" title="139:142	In future work, it would be interesting to analyze higher levels of entailment, such as logical inference and deep semantic understanding of the text." ></td>
	<td class="line x" title="140:142	Acknowledgements We would like to thank Ido Dagan for helpful discussions and for his scientific supervision." ></td>
	<td class="line x" title="141:142	This work was supported in part by the IST Programme of the European Community, under the PASCAL Network of Excellence, IST-2002-506778." ></td>
	<td class="line x" title="142:142	This publication only reflects the authors views." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N06-1008
Acquiring Inference Rules With Temporal Constraints By Using Japanese Coordinated Sentences And Noun-Verb Co-Occurrences
Torisawa, Kentaro;"></td>
	<td class="line x" title="1:225	Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 5764, New York, June 2006." ></td>
	<td class="line x" title="2:225	c2006 Association for Computational Linguistics Acquiring Inference Rules with TemporalConstraints by Using Japanese Coordinated Sentences and Noun-Verb Co-occurrences Kentaro Torisawa Japan Advanced Institute of Science and Technology 1-1Asahidai, Nomi-shi, Ishikawa-ken, 923-1211JAPAN torisawa@jaist.ac.jp Abstract This paper shows that inference rules with temporal constraints can be acquired by using verb-verb co-occurrences in Japanese coordinated sentences and verb-noun cooccurrences." ></td>
	<td class="line x" title="3:225	For example, our unsupervised acquisition method could obtain the inference rule If someone enforces a law, usually someone enacts the law at the same time as or before the enforcing of the law since the verbs enact and enforce frequently co-occurred in coordinated sentences and the verbs also frequently cooccurred with the noun law." ></td>
	<td class="line x" title="4:225	We also show that the accuracy of the acquisition is improved by using the occurrence frequency of a single verb, which we assume indicates how generic the meaning of the verb is. 1 Introduction Our goal is to develop an unsupervised method for acquiring inference rules that describe logical implications between event occurrences." ></td>
	<td class="line x" title="5:225	As clues to nd the rules, we chose Japanese coordinated sentences, which typically report two events that occur in a certain temporal order." ></td>
	<td class="line x" title="6:225	Of course, not every coordinatedsentence necessarily expresses implications." ></td>
	<td class="line x" title="7:225	We found, though, that reliable rules can be acquired by looking at co-occurrence frequencies between verbs in coordinated sentences and co-occurrences between verbs and nouns." ></td>
	<td class="line x" title="8:225	For example, our method could obtaintheruleIfsomeoneenforcesalaw,usuallysomeone enacts the law at the same time as or before the enforcing of the law." ></td>
	<td class="line x" title="9:225	In our experiments, when our method produced 400 rules for 1,000 given nouns, 70% of the rules were considered proper by at least three of fourhuman judges." ></td>
	<td class="line x" title="10:225	Note that the acquired inference rules pose temporal constraints on occurrences of the events described in the rules." ></td>
	<td class="line x" title="11:225	In the enacting-and-enforcing-law example, the constraints were expressed by the phrase at the same time as or beforethe event of." ></td>
	<td class="line x" title="12:225	We think suchtemporally constrained rulesshould bebenecial invarioustypesofNLPapplications." ></td>
	<td class="line x" title="13:225	Therulesshould allow Q&A systems to guess or restrict the time at which a certain event occurs even if they cannot directly nd the time in given documents." ></td>
	<td class="line x" title="14:225	In addition, we foundthat a large part of the acquired rules can be regarded as paraphrases, and many possible applicationsofparaphrases shouldalsobetarget applications." ></td>
	<td class="line x" title="15:225	To acquire rules, our method uses a score, which is basically an approximation ofthe probability that particular coordinated sentences will be observed." ></td>
	<td class="line x" title="16:225	However, it is weighted by a bias, which embodies our assumption that frequently observed verbs are likely to appear as the consequence of a proper inference rule." ></td>
	<td class="line x" title="17:225	This is based on our intuition that frequently appearingverbshave a generic meaningandtendto describe a wide range of situations, and that natural language expressions referring to a wide range of situations are more likely to be a consequence of a proper rule than specic expressions describing only a narrowrangeof events." ></td>
	<td class="line x" title="18:225	A similar idea relying on word co-occurrence was proposed by Geffet and Dagan (Geffet and Dagan, 2005)but ourmethodis simpler and we expect it to be applicable to a wider range of vocabularies." ></td>
	<td class="line x" title="19:225	Research on the automatic acquisition of inference rules, paraphrases and entailments has received much attention." ></td>
	<td class="line oc" title="20:225	Previous attempts have used, for instance, the similarities between case frames (Lin and Pan57 tel, 2001), anchor words (Barzilay and Lee, 2003; Shinyama et al. , 2002; Szepektor et al. , 2004), and a web-based method(Szepektor et al. , 2004;Geffet and Dagan, 2005)." ></td>
	<td class="line x" title="21:225	There is also a workshop devoted to thistask (Daganetal.,2005)." ></td>
	<td class="line x" title="23:225	Theobtained accuracies have still been low, however, and we think searching for other clues, such as coordinated sentences and the bias wehave just mentioned, isnecessary." ></td>
	<td class="line x" title="24:225	Inaddition, research has also been done on the acquisition of the temporal relations (Fujiki et al. , 2003; Chklovski and Pantel, 2004) by using coordinated sentences as we did, but these worksdid not consider the implications between events." ></td>
	<td class="line x" title="25:225	2 Algorithmwitha Simplied Score In the following, we begin by providing an overview of our algorithm." ></td>
	<td class="line x" title="26:225	We specify the basic steps in the algorithm and the form of the rules to be acquired." ></td>
	<td class="line x" title="27:225	We also examine the direction of implications andtemporal ordering described by the rules." ></td>
	<td class="line x" title="28:225	After that, we describe a simplied version of the scoring function that ouralgorithm uses and then discuss a problem related to it." ></td>
	<td class="line x" title="29:225	Thebias mechanism, which wementioned in the introduction, is described in the section after that." ></td>
	<td class="line x" title="30:225	2.1 Procedure andGenerated Inference Rules Our algorithm is given a noun as its input and produces a set of inference rules." ></td>
	<td class="line x" title="31:225	A produced rule expresses an implication relation between two descriptions including the noun." ></td>
	<td class="line x" title="32:225	Our basic assumptions for the acquisition can be stated as follows." ></td>
	<td class="line x" title="33:225	 If verbs v1 and v2 frequently co-occur in coordinatedsentences, theverbsrefer totwoevents that actually frequently co-occur in the real world, andasentence including v1 andanother sentence including v2 are good candidates to be descriptions that have an implication relation and a particular temporal order between them." ></td>
	<td class="line x" title="34:225	 The above tendency becomes stronger when the verbs frequently co-occur with a given noun n; i.e., if v1 and v2 frequently co-occur in coordinated sentences andthe verbs also frequently cooccur with a nounn, a sentence including v1 and n and another sentence including v2 and n are good candidates to be descriptions that have an implication relation between them." ></td>
	<td class="line x" title="35:225	Our procedure consists of the following steps." ></td>
	<td class="line x" title="36:225	Step1 Select M verbs that take a given noun n as their argument most frequently." ></td>
	<td class="line x" title="37:225	Step2 For each possible pair of the selected verbs, compute the value of a scoring function that embodies our assumptions, and select the N verb pairs that have the largest score values." ></td>
	<td class="line x" title="38:225	Note thatweexcludethecombinationofthesameverb fromthe pairs to be considered." ></td>
	<td class="line x" title="39:225	Step3 If the score value fora verb pair is higher than athreshold  andtheverbstake nastheir syntactic objects, generate an inference rule from the verb pair and the noun." ></td>
	<td class="line x" title="40:225	Note that we used 500 as the value of M. N was set to 4 and  was set to various values during our experiments." ></td>
	<td class="line x" title="41:225	Another important point is that, in Step 3, the argument positions at which the given noun can appear is restricted to syntactic objects." ></td>
	<td class="line x" title="42:225	This was because we empirically found that the rules generated fromsuch verb-nounpairs were relatively accurate." ></td>
	<td class="line x" title="43:225	Assume that a given noun is goods and the verb pair sell and manufacture is selected in Step 3." ></td>
	<td class="line x" title="44:225	Then, the following rule is generated." ></td>
	<td class="line x" title="45:225	 If someone sells goods, usually someone manufactures the goods at the same time as or before the event of the selling of the goods." ></td>
	<td class="line x" title="46:225	Although the word someone occurs twice, we do not demand that it refers to the same person in both instances." ></td>
	<td class="line x" title="47:225	It just works as a placeholder." ></td>
	<td class="line x" title="48:225	Also note that the adverb usually1 was inserted to prevent the rule frombeingregarded as invalid byconsidering situationsthat arelogically possible butunlikely inpractice." ></td>
	<td class="line x" title="49:225	The above rule is produced when manufacture and sell frequently co-occur in coordinated sentences such as The company manufactured goods and it sold them." ></td>
	<td class="line x" title="50:225	One might be puzzled because the order of the occurrences of the verbs in the coordinated sentences isreversed in therule." ></td>
	<td class="line x" title="51:225	Theverbsell in the second(embedded) sentence/clause in the coordinated sentence appears as a verb in the precondition of the rule, while manufacture in the rst (embedded) sentence/clause is the verb in the consequence." ></td>
	<td class="line x" title="52:225	A question then, is why we chose such an order, or such a direction of implication." ></td>
	<td class="line x" title="53:225	There is another possibility, which might seem more straightforward." ></td>
	<td class="line x" title="54:225	From the same coordinated sentences, we could produce the rule where the direction is reversed; i.e,., If someone manufactures goods, usually someone sells 1We used futsuu as a Japanese translation." ></td>
	<td class="line x" title="56:225	58 the goodsat the same time as or after the manufacturing." ></td>
	<td class="line x" title="57:225	The difference is that the rules generated by our procedure basically infer a past event from another event, while the rules with the opposite direction have to predict a future event." ></td>
	<td class="line x" title="58:225	In experiments using ourdevelopment set, we observed that the rules predicting future events were often unacceptable because of the uncertainty that weusually encounter inpredictingthe future or achieving a future goal." ></td>
	<td class="line x" title="59:225	For instance, people might do something (e.g. , manufacturing) with an intention to achieve some other goal (e.g. , selling) in thefuture." ></td>
	<td class="line x" title="60:225	Butthey sometimes fail to achieve their future goal for some reason." ></td>
	<td class="line x" title="61:225	Some manufactured goods are never sold because, forinstance, they are notgood enough." ></td>
	<td class="line x" title="62:225	In our experiments, we found that the precision rates of the rules with the direction we adopted were much higher than those of the rules with the opposite direction." ></td>
	<td class="line x" title="63:225	2.2 SimpliedScoring Function To be precise, a rule generated by our method has the following form, where vpre and vcon are verbs and n is a given noun." ></td>
	<td class="line x" title="64:225	 If someonevpre n, usually someonevcon thenat the same time as or before the vpre-ing of the n. We assume that all three occurrences of nounn in the rule refer to the same entity." ></td>
	<td class="line x" title="65:225	Now, we dene a simplied version of our scoring function as follows." ></td>
	<td class="line x" title="66:225	BasicS(n,vcon,vpre,arg,argprime) = Pcoord(vcon,vpre)Pargprime(n|vpre)Parg(n|vcon)/P(n)2 Here, Pcoord(vcon,vpre) is the probability that vcon and vpre are observed in coordinated sentences in a way that the event described by vcon temporally precedes or occurs at the same time as the event described by vpre." ></td>
	<td class="line x" title="67:225	(More precisely, vcon and vpre must be the main verbs of two conjuncts S1 and S2 in a Japanese coordinated sentence that is literally translated to the form S1 and S2)." ></td>
	<td class="line x" title="68:225	This means that in the coordinated sentences, vcon appears rst and vpre second." ></td>
	<td class="line x" title="69:225	Pargprime(n|vpre)andParg(n|vcon)aretheconditional probabilities that noccupies the argument positionsargprime ofvpre andarg ofvcon, respectively." ></td>
	<td class="line x" title="70:225	At the beginning, as possible argument positions, we specied ve argument positions, including the syntactic object and the subject." ></td>
	<td class="line x" title="71:225	Note that when vpre and vcon frequently co-occur in coordinated sentences and n often becomes arguments of vpre and vcon, the score has a large value." ></td>
	<td class="line x" title="72:225	This means that the score embodies our assumptions for acquiring rules." ></td>
	<td class="line x" title="73:225	Theterm Pcoord(vcon,vpre)Pargprime(n|vpre)Parg(n|vcon) in BasicS is actually an approximation of the probability P(vpre,argprime,n,vcon,arg,n) that we will observe the coordinated sentences such that the two sentences/clauses in the coordinated sentence are headed by vpre and vcon and n occupies the argument positions argprime of vpre and arg of vcon." ></td>
	<td class="line x" title="74:225	Another important point is that the score is divided byP(n)2." ></td>
	<td class="line x" title="75:225	This is because theprobabilities such asParg(n|vcon)tendtobe large for a frequently observed noun n. The division by P(n)2 is done to cancel such a tendency." ></td>
	<td class="line x" title="76:225	This division does not affect the ranking for the same noun, but, since we give a uniform threshold for selecting the verb pairs for distinct nouns, such normalization isdesirable, asweconrmed inexperiments usingour development set." ></td>
	<td class="line x" title="77:225	2.3 Paraphrases andCoordinated Sentences Thus, we have dened our algorithm and a simplied scoring function." ></td>
	<td class="line x" title="78:225	Now let us discuss a problem that is caused by the scoring function." ></td>
	<td class="line x" title="79:225	As mentioned in the introduction, a large portion of the acquired rules actually consists of paraphrases." ></td>
	<td class="line x" title="80:225	Here, by a paraphrase, we mean a rule consisting of two descriptions referring to an identical event." ></td>
	<td class="line x" title="81:225	The following example is an English translation of such paraphrases obtained by our method." ></td>
	<td class="line x" title="82:225	We think this rule is acceptable." ></td>
	<td class="line x" title="83:225	Note that we invented a new English verb clearly-write as a translation of a Japanese verbmeiki-suruwhile write is a translation of another Japanese verb kaku." ></td>
	<td class="line x" title="84:225	 If someone clearly-writes a phone number, usually someone writes the phone number at the same time as or before the clearly-writing of the phonenumber." ></td>
	<td class="line x" title="85:225	Note that clearly-write and write have almost the same meaning but the former is often used in texts related to legal matters." ></td>
	<td class="line x" title="86:225	Evidently, in the above rule, clearly-write and write describe the same event, and it can be seen as a paraphrase." ></td>
	<td class="line x" title="87:225	There are two types ofcoordinated sentence that ourmethodcan use as clues to generate the rule." ></td>
	<td class="line x" title="88:225	 He clearly-wrote a phone number and wrote the phonenumber." ></td>
	<td class="line x" title="89:225	 Heclearly-wrote aphonenumber, andalsowrote an address." ></td>
	<td class="line x" title="90:225	The rst sentence is more similar to the inference rule than the second in the sense that the two verbs 59 share the same object." ></td>
	<td class="line x" title="91:225	However, it is ridiculous because it describes the same event twice." ></td>
	<td class="line x" title="92:225	Such a sentence is not observed frequently in corpora, and will not be used as clues to generate rules in practice." ></td>
	<td class="line x" title="93:225	On the other hand, we frequently observe sentences of the second type in corpora, and our method generates the paraphrases from the verb-verb cooccurrences taken from such sentences." ></td>
	<td class="line x" title="94:225	However, there is a mismatch between the sentence and the acquired rule in the sense that the rule describes two events related to the same object (i.e. , a phone number), while the above sentence describes two events that are related to distinct objects (i.e. , a phone number and an address)." ></td>
	<td class="line x" title="95:225	Regarding this mismatch, two questions need to be addressed." ></td>
	<td class="line x" title="96:225	The rst question is why our method can acquire the rule despite the mismatch." ></td>
	<td class="line x" title="97:225	The answer is that ourmethodobtains theverb-verb co-occurrence probabilities (Pcoord(vcon,vpre)) and the verb-noun cooccurrence probabilities (e.g. ,Parg(n|vcon)) independently, and that the method does not check whether the two verbs share an argument." ></td>
	<td class="line x" title="98:225	Then the next question is why our method can acquire accurate paraphrases from such coordinated sentences." ></td>
	<td class="line x" title="99:225	Though we do not have a denite answer now, ourhypothesis is related to the strategy that people adoptin writing coordinated sentences." ></td>
	<td class="line x" title="100:225	When two similar but distinct events, which can be described by the same verb,occur successively or at the same time, people avoid repeating the same verb to describe the two events in a single sentence." ></td>
	<td class="line x" title="101:225	Instead they try to use distinct verbs that have similar meanings." ></td>
	<td class="line x" title="102:225	Suppose that a person wrote his name and address." ></td>
	<td class="line x" title="103:225	To report what she did, she may write I clearly-wrote my name and also wrote my address but will seldom writeIclearly-wrote mynameandalsoclearly-wrote my address." ></td>
	<td class="line x" title="104:225	Thus, we can expect to be able to nd in coordinated sentences a large number of verb pairs consisting of two verbs with similar meanings." ></td>
	<td class="line x" title="105:225	Note that our method tends to produce two verbs that frequently co-occur withagiven noun." ></td>
	<td class="line x" title="106:225	Thisalso helpsto produce the inference rules consisting of two semantically similar verbs." ></td>
	<td class="line x" title="107:225	3 BiasMechanism We now describe a bias used in our full scoring function, which signicantly improves the precision." ></td>
	<td class="line x" title="108:225	The full scoring function is dened as Score(n,vcon,vpre,arg,argprime) = Parg(vcon)BasicS(n,vcon,vpre,arg,argprime)." ></td>
	<td class="line x" title="109:225	The bias is denoted as Parg(vcon), which is the probability that we can observe the verb vcon, which is the verb in the consequence of the rule, and its argument position arg is occupied by a noun, no matter which nounactually occupies the position." ></td>
	<td class="line x" title="110:225	An intuitive explanation of the assumption behind this bias is that as the situation within which the descriptionoftheconsequence inaruleisvalid becomes wider, the rule becomes more likely to be a proper one." ></td>
	<td class="line x" title="111:225	Consider the following rules." ></td>
	<td class="line x" title="112:225	 If someone demands a compensation payment, someone orders the compensation payment." ></td>
	<td class="line x" title="113:225	 If someone demands a compensation payment, someone requests the compensation payment." ></td>
	<td class="line x" title="114:225	Weconsider therst rule to beunacceptable while the secondexpresses aproper implication." ></td>
	<td class="line x" title="115:225	Thedifference is the situations in which the descriptions in the consequences hold." ></td>
	<td class="line x" title="116:225	In our view, the situations described by order are more specic than those referred to by request." ></td>
	<td class="line x" title="117:225	In other words, order holds in a smaller range of situations than request." ></td>
	<td class="line x" title="118:225	Requesting something can happen in any situations where there exists someone who can demand something, but ordering can occur only ina situationswheresomeonein aparticular social positioncandemandsomething." ></td>
	<td class="line x" title="119:225	Thebasic assumption behind our bias is that rules with consequences that can be valid in a wider range of situations, such as requesting a compensation payment, are more likely to be proper ones than the rules with consequences that hold in a smaller range of situations, such as ordering a compensation payment." ></td>
	<td class="line x" title="120:225	Thebias Parg(vcon)wasintroduced tocapture variationsofthesituations in which event descriptions are valid." ></td>
	<td class="line x" title="121:225	Weassume that frequently observed verbsform generic descriptions that can be valid within a wide range of events, while less frequent verbs tend to describe events that can occur in a narrower rangeof situations and form more specic descriptions than the frequently observed verbs." ></td>
	<td class="line x" title="122:225	Regarding the requestorder example, (a Japanese translation of) request is observed more frequently than (a Japanese translationof)order incorporaandthis observation isconsistent with our assumption." ></td>
	<td class="line x" title="123:225	A similar idea by Geffet and Dagan (Geffet and Dagan, 2005) was proposed forcapturing lexical entailment." ></td>
	<td class="line x" title="124:225	Thedifference is that they relied on word co-occurrences rather than the frequency of words to measure the specicity of the semantic contents of lexical descriptions, and needed Web search to avoid data sparseness in co-occurrence 60 statistics." ></td>
	<td class="line x" title="125:225	On the other hand, our method needs only simpleoccurrence probabilities ofsingleverbsandwe expect our method to be applicable to wider vocabulary than Geffet and Dagans method." ></td>
	<td class="line x" title="126:225	The following is a more mathematical justication for the bias." ></td>
	<td class="line x" title="127:225	According to the following discussion, Parg(vcon) can be seen as a metric indicating how easily we can establish an interpretation of the rule, which is formalized as a mapping between events." ></td>
	<td class="line x" title="128:225	In our view, if we can establish the mapping easily, the rule tendstobeacceptable." ></td>
	<td class="line x" title="129:225	Thediscussion starts from a formalization of an interpretation of an inference rule." ></td>
	<td class="line x" title="130:225	Consider the rule If exp1 occurs, usually exp2 occurs at the same time or before the occurrence of exp1, where exp1 and exp2 are natural language expressions referring to events." ></td>
	<td class="line x" title="131:225	In the following, we call such expressions event descriptions and distinguish them from an actual event referred to by the expressions." ></td>
	<td class="line x" title="132:225	An actual event is called an event instance.A possible interpretation of the rule is that, for any event instance e1 that can be described by the event description exp1 in the precondition of the rule, there always exists an event instance e2 that can be described by the event description exp2 in the consequence and that occurs at the same time as or before e1 occurs." ></td>
	<td class="line x" title="133:225	Let us write e : exp if event instance e can be described by event description exp. The above interpretation can then be represented by the formula  : f(e1(e1 : exp1 e2(e2 = f(e1)e2 : exp2))." ></td>
	<td class="line x" title="134:225	Here, the mapping f represents a temporal relation betweenevents, andtheformulae2 = f(e1)expresses that e2 occurs at the same time as or beforee1." ></td>
	<td class="line x" title="135:225	The bias Parg(vcon) can be considered (an approximation of) a parameter required for computing the probability that a mapping frandom satises the requirements for f in  when we randomly construct frandom." ></td>
	<td class="line x" title="136:225	The probability is denoted as Pe2 : exp2  e2 = frandom(e1)|e1 : exp1}E1 where E1 denotes the number of events describable by exp1." ></td>
	<td class="line x" title="137:225	We assume that the larger this probability is, the more easily we can establish f. We can approximate Pe2 : exp2e2 = frandom(e1)|e1 : exp1}asP(exp2)by1) observing that theprobabilistic variables e1 ande2 are independent since frandom associates them in a completely random manner and by 2) assuming that the occurrence probability of the event instances describable by exp2 can be approximated by the probability that exp2 is observed in text corpora." ></td>
	<td class="line x" title="138:225	This means that P(exp2) is one of the metrics indicating how easily we can establish the mapping f in ." ></td>
	<td class="line x" title="139:225	Then, the next question is what kind of expressions should be regarded as the event description exp2." ></td>
	<td class="line x" title="140:225	A primary candidate will be the whole sentence appearingin theconsequence part oftherule to beproduced." ></td>
	<td class="line x" title="141:225	Since we specify only a verb vcon and its argument n in the consequence in a rule, P(exp2) can be denoted by Parg(n,vcon), which is the probability that we observe the expression such that vcon is a head verb and noccupies an argument position arg ofvcon." ></td>
	<td class="line x" title="142:225	Bymultiplying this probability to BasicS as a bias, we obtain the following scoring function." ></td>
	<td class="line x" title="143:225	Scorecooc(n,vcon,vpre,arg,argprime) = Parg(n,vcon)BasicS(n,vcon,vpre,arg,argprime) In our experiments, though, this score did not work well." ></td>
	<td class="line x" title="144:225	Since Parg(n,vcon) often has a small value, the problem of data sparseness seems to arise." ></td>
	<td class="line x" title="145:225	Then, we used Parg(vcon), which denotes the probability of observing sentences that contain vcon and its argument position arg, no matter which noun occupies arg, instead of Parg(n,vcon)." ></td>
	<td class="line x" title="146:225	We multiplied the probability to BasicS as a bias and obtained the following score, which is actually the scoring function we propose." ></td>
	<td class="line x" title="147:225	Score(n,vcon,vpre,arg,argprime) = Parg(vcon)BasicS(n,vcon,vpre,arg,argprime) 4 Experiments 4.1 Settings We parsed 35 years of newspaper articles (Yomiuri 87-01, Mainichi 91-99, Nikkei 90-00, 3.24GB in total) and 92.6GB of HTML documents downloaded from the WWW using an existing parser (Kanayama et al. , 2000) to obtain the word (co-occurrence) frequencies." ></td>
	<td class="line x" title="148:225	All the probabilities used in our method were estimated by maximum likelihood estimation from these frequencies." ></td>
	<td class="line x" title="149:225	We randomly picked 600 nouns as a development set." ></td>
	<td class="line x" title="150:225	We prepared three test sets, namely test sets A, B, and C, which consisted of 100 nouns, 250 nouns and 1,000 nouns respectively." ></td>
	<td class="line x" title="151:225	Note that all the nouns in the test sets were randomly picked and did not have any common items with the development set." ></td>
	<td class="line x" title="152:225	In all the experiments, four human judges checked ifeachproduced rulewasaproper one without knowing how each rule was produced." ></td>
	<td class="line x" title="153:225	4.2 Effects ofUsing Coordinated Sentences In the rst series of experiments, we compared a simplied version of our scoring function BasicS with some alternative scores." ></td>
	<td class="line x" title="154:225	This was mainly to check if coordinated sentences can improve accuracy." ></td>
	<td class="line x" title="155:225	The alternative scores we considered 61 0 20 40 60 80 100 0 50 100 150 200 250 300 350 400 Pre cisi on (% ) Number of inference rules BasicS S-VV S-NV MI Conditional Rand Figure1: Comparison with the alternatives (4 judges) 0 20 40 60 80 100 0 50 100 150 200 250 300 350 400 Pre cisi on (% ) Number of inference rules BasicS S-VV S-NV MI Conditional Rand Figure2: Comparison with the alternatives (3 judges) are presented below." ></td>
	<td class="line x" title="156:225	Note that we did not test our bias mechanism in this series of experiments." ></td>
	<td class="line x" title="157:225	S-VV(n,vcon,vpre,arg,argprime) = Parg(n,vcon)Pargprime(n,vpre)/P(n)2 S-NV(n,vcon,vpre) = Pcoord(vcon,vpre) MI(n,vcon,vpre) = Pcoord(vcon,vpre)/(P(vcon)P(vpre)) Cond(n,vcon,vpre,arg,argprime) = Pcoord(vcon,vpre,arg,argprime)Parg(n|vcon)Pargprime(n|vpre) /(Pargprime(n,vpre)P(n)) Rand(n,vcon,vpre,arg,argprime) = randomnumber S-VV was obtained by approximating the probabilities of coordinated sentences, as in the case of BasicS." ></td>
	<td class="line x" title="158:225	However, we assumed the occurrences of two verbs were independent." ></td>
	<td class="line x" title="159:225	The difference between the performance of this score and that of BasicS will indicate the effectiveness of using verb-verb co-occurrences in coordinated sentences." ></td>
	<td class="line x" title="160:225	The second alternative, S-NV, simply ignores the noun-verb co-occurrences in BasicS." ></td>
	<td class="line x" title="161:225	MI is a score based onmutual information androughly corresponds to the score used in a previous attempt to acquire temporal relations between events (Chklovski and Pantel, 2004)." ></td>
	<td class="line x" title="162:225	Cond is an approximation of the probability P(n,vcon|n,vpre); i.e., the conditional proba0 20 40 60 80 100 0 20 40 60 80 100 120 Pre cisi on (% ) Number of inference rules BasicS S-VV S-NV MI Cond Figure3: Comparison with the alternatives (3 judges) bility that the coordinated sentences consisting of n, vcon andvpre are observed given the precondition part consisting of vpre and n. Rand is a random number and generates rules by combining verbs that co-occur with the given n randomly." ></td>
	<td class="line x" title="163:225	This was used as a baseline method of our task Theresulting precisions areshown in Figures 1 and 2." ></td>
	<td class="line x" title="164:225	The gure captions specify (4 judges), as in Figure 1, when the acceptable rules included only those regarded as proper by all four judges; the captions specify (3 judges), as in Figure 2, when the acceptable rules include those considered proper by at least three of the fourjudges." ></td>
	<td class="line x" title="165:225	We used test set A (100 nouns) and produced the top four rule candidates for each noun according to each score." ></td>
	<td class="line x" title="166:225	As the nal results, all the produced rules for all the nouns were sorted according to each score, and a precision was obtained for top N rules in the sorted list." ></td>
	<td class="line x" title="167:225	This was thesameastheprecision achieved bysetting thescore valueofN-thruleinthesorted list asthreshold ." ></td>
	<td class="line x" title="168:225	Notice that BasicS outperformed all the alternatives2, though the difference between S-VV and BasicS was rather small." ></td>
	<td class="line x" title="169:225	Another important point is that the precisions obtained with the scores that ignored nounverb co-occurrences were quite low." ></td>
	<td class="line x" title="170:225	These ndings suggest that 1) coordinated sentences can be useful clues for obtaining temporally constrained rules and 2) noun-verb co-occurrences are also important clues." ></td>
	<td class="line x" title="171:225	Intheaboveexperiments, weactually allowednoun n to appear as argument types other than the syntactic objects of a verb." ></td>
	<td class="line x" title="172:225	When we restricted the argu2Actually, the experiments concerning Rand were conducted considerably after the experiments on the other scores, and only the two of the four judges for Rand were included in the judges for other scores." ></td>
	<td class="line x" title="173:225	However, we think that the superiority of our score BasicS over the baseline method was conrmed since the precision of Rand was drastically lower than that of BasicS 62 20 30 40 50 60 70 80 90 100 0 50 100 150 200 250 300 350 Pre cisi on (% ) Number of inference rules Proposed direction Reversed Figure4: Two directions of implications (3 judges) ment types to syntactic objects, as described in Section 2, the precision shown in Figure 3 was obtained." ></td>
	<td class="line x" title="174:225	In most cases, BasicS outperformed the alternatives." ></td>
	<td class="line x" title="175:225	Although the number of produced rules was reduced because of this restriction, the precision of all produced rules was improved." ></td>
	<td class="line x" title="176:225	Because of this, we decided to restrict the argument type to objects." ></td>
	<td class="line x" title="177:225	The kappa statistic for assessing the inter-rater agreement was 0.53,which indicates moderate agreement according to Landis and Koch, 1977." ></td>
	<td class="line x" title="178:225	The kappa value for only the judgments on rules produced by BasicS rose to 0.59." ></td>
	<td class="line x" title="179:225	After we restricted the verbnoun co-occurrences to verb-object co-occurrences, the kappa became 0.49, while that for the rules produced by BasicS was 0.543." ></td>
	<td class="line x" title="180:225	4.3 Direction of Implications Next, we examined the directions of implications and the temporal order between events." ></td>
	<td class="line x" title="181:225	We produced 1,000 rules for test set B (250 nouns) using the score BasicS, again without restricting the argument types of given nouns to syntactic objects." ></td>
	<td class="line x" title="182:225	When we restricted theargumentpositionstoobjects, weobtained 347rules." ></td>
	<td class="line x" title="183:225	Then, fromeach generated rule, we created a new rule having an opposite direction of implications." ></td>
	<td class="line x" title="184:225	We swapped the precondition and the consequence oftherule andreversed itstemporal order." ></td>
	<td class="line x" title="185:225	For instance, wecreated If someoneenacts alaw, usually someone enforces the law at the same time as or after the enacting of the law from If someone enforces a law, usually someone enacts the law at the same time as or before the enforcing of the law." ></td>
	<td class="line x" title="186:225	Figure 4 shows the results." ></td>
	<td class="line x" title="187:225	Proposed direction 3These kappa values were calculated for the results except for the ones obtained by the score Rand, which were assessed by different judges." ></td>
	<td class="line x" title="188:225	The kappa forRand was 0.33(fair agreement)." ></td>
	<td class="line x" title="189:225	40 50 60 70 80 90 100 0 50 100 150 200 250 300 350 400 Pre cisi on (% ) Number of inference rules Score reranked by Score reranked by ScoreCooc BasicS reranked by PreBias Figure 5: Effects of the bias (4 judges) 40 50 60 70 80 90 100 0 50 100 150 200 250 300 350 400 Pre cisi on (% ) Number of inference rules Score reranked by Score reranked by ScoreCooc BasicS reranked by PreBias Figure 6: Effects of the bias (3 judges) refers to the precision of the rules generated by our method." ></td>
	<td class="line x" title="190:225	The precision of the rules with the opposite direction is indicated by Reversed. The precision of Reversed was much lower than that of our method, and this justies our choice of direction." ></td>
	<td class="line x" title="191:225	The kappas values forBasicS andReversedwere0.54and0.46 respectively." ></td>
	<td class="line x" title="192:225	Both indicate moderate agreement." ></td>
	<td class="line x" title="193:225	4.4 Effects ofthe Bias Last, we compared Score and BasicS to see the effect of our bias." ></td>
	<td class="line x" title="194:225	This time, we used test set C (1,000 nouns)." ></td>
	<td class="line x" title="195:225	The rules were restricted to those in which the given nouns are syntactic objects of two verbs." ></td>
	<td class="line x" title="196:225	Theevaluation was doneforonly the top400rules for each score." ></td>
	<td class="line x" title="197:225	The results are shown in Figures 5 and 6." ></td>
	<td class="line x" title="198:225	Score refers to the precision obtained with Score, while BasicS indicates the precision with BasicS." ></td>
	<td class="line x" title="199:225	For most data points in both graphs, the Score precision was about 10% higher than the BasicS precision." ></td>
	<td class="line x" title="200:225	InFigure6,the precision reached 70%when the 400 rules were produced." ></td>
	<td class="line x" title="201:225	These results indicate the desirable effect of our bias for, at least, the top rules." ></td>
	<td class="line x" title="202:225	63 rank inference rules /judges 4/0 moshi yougi wo hininsuru naraba, yougi wo mitomeru (If someonedenies suspicions, usually someoneconrms the suspicions.)" ></td>
	<td class="line x" title="203:225	6/4 moshi jikokiroku wo uwamawaru naraba, jikokiroku wo koushinsuru (If someonebetters her best record,usually someonebreaks her best record.)" ></td>
	<td class="line x" title="204:225	21/3 moshi katakuriko wo mabusu naraba, katakuriko wo tsukeru (If someonecoats something with potato starch, usually someonecovers somethingwith the starch) 194/4 moshi sasshi wo haifusuru naraba, sasshi wo sakuseisuru (If someonedistributes a booklet, usually someonemakes the booklet.)" ></td>
	<td class="line x" title="205:225	303/4 moshi netsuzou wo kokuhakusuru naraba, netsuzou wo mitomeru (If someoneconfesses to a fabrication, usually someoneadmits the fabrication.)" ></td>
	<td class="line x" title="206:225	398/3 moshi ifuku wo kikaeru naraba, ifuku wo nugu (If someonechanges clothes, usually someonegets out of the clothes.)" ></td>
	<td class="line x" title="207:225	Figure7: Examples of acquired inference rules The 400 rules generated by Score included 175 distinct nouns and 272 distinct verb pairs." ></td>
	<td class="line x" title="208:225	Examples of the inference rules acquired by Score are shown in Figure 7 along with the positions in the ranking and the numbers of judges who judged the rule as being proper." ></td>
	<td class="line x" title="209:225	(We omitted the phrase the same time as or before in the examples)." ></td>
	<td class="line x" title="210:225	The kappa was 0.57 (moderate agreement)." ></td>
	<td class="line x" title="211:225	In addition, the graphs compare Score with some other alternatives." ></td>
	<td class="line x" title="212:225	This comparison was made to check the effectiveness of our bias more carefully." ></td>
	<td class="line x" title="213:225	The 400 rules generated by BasicS were re-ranked using Score and the alternative scores, and the precision for each was computed using the human judgments for the rules generated by BasicS." ></td>
	<td class="line x" title="214:225	(We did not evaluate the rules directly generated by the alternatives to reduce the workload of the judges.)" ></td>
	<td class="line x" title="215:225	The rst alternative was Scorecooc, which was presented in Section 3." ></td>
	<td class="line x" title="216:225	Here, reranked by ScoreCooc refers to the precision obtained by re-ranking with of Scorecooc." ></td>
	<td class="line x" title="217:225	The precision was below that obtained by the re-ranking with Score, (referred to as reranked by Score)." ></td>
	<td class="line x" title="218:225	As discussed in Section 3, this indicates the bias Parg(vcon) in Score works better than the bias Parg(n,vcon) in Scorecooc." ></td>
	<td class="line x" title="219:225	Thesecondalternative wasthe scoring function obtained by replacing the bias Parg(vcon) in Score with Pargprime(vpre), which is roughly the probability that the verb in the precondition will be observed." ></td>
	<td class="line x" title="220:225	The score is denoted as PreBias(n,vcon,vpre,arg,argprime) = Pargprime(vpre)BasicS(n,vcon,vpre,arg,argprime)." ></td>
	<td class="line x" title="221:225	The precision of this score is indicated by reranked by PreBias and is much lower than that of reranked by Score, indicating that only probability of the verbs in the consequences should be used as a bias." ></td>
	<td class="line x" title="222:225	This is consistent with our assumption behind the bias." ></td>
	<td class="line x" title="223:225	5 Conclusion We have presented an unsupervised method for acquiring inference rules with temporal constraints, such as If someone enforces a law, someone enacts the law at the same time as or before the enforcing of the law." ></td>
	<td class="line x" title="224:225	We used the probabilities of verb-verb cooccurrences in coordinated sentences and verb-noun co-occurrences." ></td>
	<td class="line x" title="225:225	We have also proposed a bias mechanism that can improve the precision of acquired rules." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N06-1058
Paraphrasing For Automatic Evaluation
Kauchak, David;Barzilay, Regina;"></td>
	<td class="line x" title="1:238	Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 455462, New York, June 2006." ></td>
	<td class="line x" title="2:238	c2006 Association for Computational Linguistics Paraphrasing for Automatic Evaluation David Kauchak Department of Computer Science University of California, San Diego dkauchak@cs.ucsd.edu Regina Barzilay CSAIL Massachusetts Institute of Technology regina@csail.mit.edu Abstract This paper studies the impact of paraphrases on the accuracy of automatic evaluation." ></td>
	<td class="line x" title="3:238	Given a reference sentence and a machine-generated sentence, we seek to nd a paraphrase of the reference sentence that is closer in wording to the machine output than the original reference." ></td>
	<td class="line x" title="4:238	We apply our paraphrasing method in the context of machine translation evaluation." ></td>
	<td class="line x" title="5:238	Our experiments show that the use of a paraphrased synthetic reference re nes the accuracy of automatic evaluation." ></td>
	<td class="line x" title="6:238	We also found a strong connection between the quality of automatic paraphrases as judged by humans and their contribution to automatic evaluation." ></td>
	<td class="line x" title="7:238	1 Introduction The use of automatic methods for evaluating machine-generated text is quickly becoming mainstream in natural language processing." ></td>
	<td class="line x" title="8:238	The most notable examples in this category include measures such as BLEU and ROUGE which drive research in the machine translation and text summarization communities." ></td>
	<td class="line x" title="9:238	These methods assess the quality of a machine-generated output by considering its similarity to a reference text written by a human." ></td>
	<td class="line x" title="10:238	Ideally, the similarity would re ect the semantic proximity between the two." ></td>
	<td class="line x" title="11:238	In practice, this comparison breaks down to n-gram overlap between the reference and the machine output." ></td>
	<td class="line x" title="12:238	1a." ></td>
	<td class="line x" title="13:238	However, Israels reply failed to completely clear the U.S. suspicions." ></td>
	<td class="line x" title="14:238	1b." ></td>
	<td class="line x" title="15:238	However, Israeli answer unable to fully remove the doubts." ></td>
	<td class="line x" title="16:238	Table 1: A reference sentence and corresponding machine translation from the NIST 2004 MT evaluation." ></td>
	<td class="line x" title="17:238	Consider the human-written translation and the machine translation of the same Chinese sentence shown in Table 1." ></td>
	<td class="line x" title="18:238	While the two translations convey the same meaning, they share only auxiliary words." ></td>
	<td class="line x" title="19:238	Clearly, any measure based on word overlap will penalize a system for generating such a sentence." ></td>
	<td class="line x" title="20:238	The question is whether such cases are common phenomena or infrequent exceptions." ></td>
	<td class="line x" title="21:238	Empirical evidence supports the former." ></td>
	<td class="line x" title="22:238	Analyzing 10,728 reference translation pairs1 used in the NIST 2004 machine translation evaluation, we found that only 21 (less than 0.2%) of them are identical." ></td>
	<td class="line x" title="23:238	Moreover, 60% of the pairs differ in at least 11 words." ></td>
	<td class="line x" title="24:238	These statistics suggest that without accounting for paraphrases, automatic evaluation measures may never reach the accuracy of human evaluation." ></td>
	<td class="line x" title="25:238	As a solution to this problem, researchers use multiple references to re ne automatic evaluation." ></td>
	<td class="line x" title="26:238	Papineni et al.(2002) shows that expanding the number of references reduces the gap between automatic and human evaluation." ></td>
	<td class="line x" title="28:238	However, very few human annotated sets are augmented with multiple references and those that are available are relatively 1Each pair included different translations of the same sentence, produced by two human translators." ></td>
	<td class="line x" title="29:238	455 small in size." ></td>
	<td class="line x" title="30:238	Moreover, access to several references does not guarantee that the references will include the same words that appear in machine-generated sentences." ></td>
	<td class="line x" title="31:238	In this paper, we explore the use of paraphrasing methods for re nement of automatic evaluation techniques." ></td>
	<td class="line x" title="32:238	Given a reference sentence and a machine-generated sentence, we seek to nd a paraphrase of the reference sentence that is closer in wording to the machine output than the original reference." ></td>
	<td class="line x" title="33:238	For instance, given the pair of sentences in Table 1, we automatically transform the reference sentence (1a)." ></td>
	<td class="line x" title="34:238	into However, Israels answer failed to completely remove the U.S. suspicions." ></td>
	<td class="line x" title="35:238	Thus, among many possible paraphrases of the reference, we are interested only in those that use words appearing in the system output." ></td>
	<td class="line x" title="36:238	Our paraphrasing algorithm is based on the substitute in context strategy." ></td>
	<td class="line x" title="37:238	First, the algorithm identi es pairs of words from the reference and the system output that could potentially form paraphrases." ></td>
	<td class="line x" title="38:238	We select these candidates using existing lexico-semantic resources such as WordNet." ></td>
	<td class="line x" title="39:238	Next, the algorithm tests whether the candidate paraphrase is admissible in the context of the reference sentence." ></td>
	<td class="line x" title="40:238	Since even synonyms cannot be substituted in any context (Edmonds and Hirst, 2002), this ltering step is necessary." ></td>
	<td class="line x" title="41:238	We predict whether a word is appropriate in a new context by analyzing its distributional properties in a large body of text." ></td>
	<td class="line x" title="42:238	Finally, paraphrases that pass the ltering stage are used to rewrite the reference sentence." ></td>
	<td class="line x" title="43:238	We apply our paraphrasing method in the context of machine translation evaluation." ></td>
	<td class="line x" title="44:238	Using this strategy, we generate a new sentence for every pair of human and machine translated sentences." ></td>
	<td class="line x" title="45:238	This synthetic reference then replaces the original human reference in automatic evaluation." ></td>
	<td class="line x" title="46:238	The key ndings of our work are as follows: (1) Automatically generated paraphrases improve the accuracy of the automatic evaluation methods." ></td>
	<td class="line x" title="47:238	Our experiments show that evaluation based on paraphrased references gives a better approximation of human judgments than evaluation that uses original references." ></td>
	<td class="line x" title="48:238	(2) The quality of automatic paraphrases determines their contribution to automatic evaluation." ></td>
	<td class="line x" title="49:238	By analyzing several paraphrasing resources, we found that the accuracy and coverage of a paraphrasing method correlate with its utility for automatic MT evaluation." ></td>
	<td class="line x" title="50:238	Our results suggest that researchers may nd it useful to augment standard measures such as BLEU and ROUGE with paraphrasing information thereby taking more semantic knowledge into account." ></td>
	<td class="line x" title="51:238	In the following section, we provide an overview of existing work on automatic paraphrasing." ></td>
	<td class="line x" title="52:238	We then describe our paraphrasing algorithm and explain how it can be used in an automatic evaluation setting." ></td>
	<td class="line x" title="53:238	Next, we present our experimental framework and data and conclude by presenting and discussing our results." ></td>
	<td class="line oc" title="54:238	2 Related Work Automatic Paraphrasing and Entailment Our work is closely related to research in automatic paraphrasing, in particular, to sentence level paraphrasing (Barzilay and Lee, 2003; Pang et al. , 2003; Quirk et al. , 2004)." ></td>
	<td class="line o" title="55:238	Most of these approaches learn paraphrases from a parallel or comparable monolingual corpora." ></td>
	<td class="line o" title="56:238	Instances of such corpora include multiple English translations of the same source text written in a foreign language, and different news articles about the same event." ></td>
	<td class="line x" title="57:238	For example, Pang et al.(2003) expand a set of reference translations using syntactic alignment, and generate new reference sentences that could be used in automatic evaluation." ></td>
	<td class="line o" title="59:238	Our approach differs from traditional work on automatic paraphrasing in goal and methodology." ></td>
	<td class="line o" title="60:238	Unlike previous approaches, we are not aiming to produce any paraphrase of a given sentence since paraphrases induced from a parallel corpus do not necessarily produce a rewriting that makes a reference closer to the system output." ></td>
	<td class="line x" title="61:238	Thus, we focus on words that appear in the system output and aim to determine whether they can be used to rewrite a reference sentence." ></td>
	<td class="line x" title="62:238	Our work also has interesting connections with research on automatic textual entailment (Dagan et al. , 2005), where the goal is to determine whether a given sentence can be inferred from text." ></td>
	<td class="line x" title="63:238	While we are not assessing an inference relation between a reference and a system output, the two tasks face similar challenges." ></td>
	<td class="line x" title="64:238	Methods for entailment 456 recognition extensively rely on lexico-semantic resources (Haghighi et al. , 2005; Harabagiu et al. , 2001), and we believe that our method for contextual substitution can be bene cial in that context." ></td>
	<td class="line x" title="65:238	Automatic Evaluation Measures A variety of automatic evaluation methods have been recently proposed in the machine translation community (NIST, 2002; Melamed et al. , 2003; Papineni et al. , 2002)." ></td>
	<td class="line x" title="66:238	All these metrics compute n-gram overlap between a reference and a system output, but measure the overlap in different ways." ></td>
	<td class="line x" title="67:238	Our method for reference paraphrasing can be combined with any of these metrics." ></td>
	<td class="line x" title="68:238	In this paper, we report experiments with BLEU due to its wide use in the machine translation community." ></td>
	<td class="line x" title="69:238	Recently, researchers have explored additional knowledge sources that could enhance automatic evaluation." ></td>
	<td class="line x" title="70:238	Examples of such knowledge sources include stemming and TF-IDF weighting (Babych and Hartley, 2004; Banerjee and Lavie, 2005)." ></td>
	<td class="line x" title="71:238	Our work complements these approaches: we focus on the impact of paraphrases, and study their contribution to the accuracy of automatic evaluation." ></td>
	<td class="line x" title="72:238	3 Methods The input to our method consists of a reference sentence R = r1." ></td>
	<td class="line x" title="73:238	rm and a system-generated sentence W = w1 . . ." ></td>
	<td class="line x" title="74:238	wp whose words form the sets R and W respectively." ></td>
	<td class="line x" title="75:238	The output of the model is a synthetic reference sentence SRW that preserves the meaning of R and has maximal word overlap with W. We generate such a sentence by substituting words from R with contextually equivalent words from W. Our algorithm rst selects pairs of candidate word paraphrases, and then checks the likelihood of their substitution in the context of the reference sentence." ></td>
	<td class="line x" title="76:238	Candidate Selection We assume that words from the reference sentence that already occur in the system generated sentence should not be considered for substitution." ></td>
	<td class="line x" title="77:238	Therefore, we focus on unmatched pairs of the form {(r, w)|r  RW, w  WR}." ></td>
	<td class="line x" title="78:238	From this pool, we select candidate pairs whose members exhibit high semantic proximity." ></td>
	<td class="line x" title="79:238	In our experiments we compute semantic similarity using WordNet, a large-scale lexico-semantic resource employed in many NLP applications for similar pur2a." ></td>
	<td class="line x" title="80:238	It is hard to believe that such tremendous changes have taken place for those people and lands that I have never stopped missing while living abroad." ></td>
	<td class="line x" title="81:238	2b." ></td>
	<td class="line x" title="82:238	For someone born here but has been sentimentally attached to a foreign country far from home, it is dif cult to believe this kind of changes." ></td>
	<td class="line x" title="83:238	Table 2: A reference sentence and a corresponding machine translation." ></td>
	<td class="line x" title="84:238	Candidate paraphrases are in bold." ></td>
	<td class="line x" title="85:238	poses." ></td>
	<td class="line x" title="86:238	We consider a pair as a substitution candidate if its members are synonyms in WordNet." ></td>
	<td class="line x" title="87:238	Applying this step to the two sentences in Table 2, we obtain two candidate pairs (home, place) and (dif cult, hard)." ></td>
	<td class="line x" title="88:238	Contextual Substitution The next step is to determine for each candidate pair (ri, wj) whether wj is a valid substitution for ri in the context of r1 . . ." ></td>
	<td class="line x" title="89:238	ri1a50ri+1 . . ." ></td>
	<td class="line x" title="90:238	rm." ></td>
	<td class="line x" title="91:238	This ltering step is essential because synonyms are not universally substitutable2." ></td>
	<td class="line x" title="92:238	Consider the candidate pair (home, place) from our example (see Table 2)." ></td>
	<td class="line x" title="93:238	Words home and place are paraphrases in the sense of habitat, but in the reference sentence place occurs in a different sense, being part of the collocation take place . In this case, the pair (home, place) cannot be used to rewrite the reference sentence." ></td>
	<td class="line x" title="94:238	We formulate contextual substitution as a binary classi cation task: given a context r1 . . ." ></td>
	<td class="line x" title="95:238	ri1a50ri+1 . . ." ></td>
	<td class="line x" title="96:238	rm, we aim to predict whether wj can occur in this context at position i. For each candidate word wj we train a classi er that models contextual preferences of wj." ></td>
	<td class="line x" title="97:238	To train such a classi er, we collect a large corpus of sentences that contain the word wj and an equal number of randomly extracted sentences that do not contain this word." ></td>
	<td class="line x" title="98:238	The former category forms positive instances, while the latter represents the negative." ></td>
	<td class="line x" title="99:238	For the negative examples, a random position in a sentence is selected for extracting the context." ></td>
	<td class="line x" title="100:238	This corpus is acquired automatically, and does not require any manual annotations." ></td>
	<td class="line nc" title="101:238	2This can explain why previous attempts to use WordNet for generating sentence-level paraphrases (Barzilay and Lee, 2003; Quirk et al. , 2004) were unsuccessful." ></td>
	<td class="line x" title="102:238	457 We represent context by n-grams and local collocations, features typically used in supervised word sense disambiguation." ></td>
	<td class="line x" title="103:238	Both n-grams and collocations exclude the word wj." ></td>
	<td class="line x" title="104:238	An n-gram is a sequence of n adjacent words appearing in r1 . . ." ></td>
	<td class="line x" title="105:238	ri1a50ri+1 . . ." ></td>
	<td class="line x" title="106:238	rm." ></td>
	<td class="line x" title="107:238	A local collocation also takes into account the position of an n-gram with respect to the target word." ></td>
	<td class="line x" title="108:238	To compute local collocations for a word at position i, we extract all n-grams (n = 1 . . ." ></td>
	<td class="line x" title="109:238	4) beginning at position i  2 and ending at position i + 2." ></td>
	<td class="line x" title="110:238	To make these position dependent, we prepend each of them with the length and starting position." ></td>
	<td class="line x" title="111:238	Once the classi er3 for wj is trained, we apply it to the context r1 . . ." ></td>
	<td class="line x" title="112:238	ri1a50ri+1 . . ." ></td>
	<td class="line x" title="113:238	rm." ></td>
	<td class="line x" title="114:238	For positive predictions, we rewrite the string as r1 . . ." ></td>
	<td class="line x" title="115:238	ri1wjri+1 . . ." ></td>
	<td class="line x" title="116:238	rm." ></td>
	<td class="line x" title="117:238	In this formulation, all substitutions are tested independently." ></td>
	<td class="line x" title="118:238	For the example from Table 2, only the pair (dif cult, hard) passes this lter, and thus the system produces the following synthetic reference: For someone born here but has been sentimentally attached to a foreign country far from home, it is hard to believe this kind of changes." ></td>
	<td class="line x" title="119:238	The synthetic reference keeps the meaning of the original reference, but has a higher word overlap with the system output." ></td>
	<td class="line x" title="120:238	One of the implications of this design is the need to develop a large number of classi ers to test contextual substitutions." ></td>
	<td class="line x" title="121:238	For each word to be inserted into a reference sentence, we need to train a separate classi er." ></td>
	<td class="line x" title="122:238	In practice, this requirement is not a signi cant burden." ></td>
	<td class="line x" title="123:238	The training is done off-line and only once, and testing for contextual substitution is instantaneous." ></td>
	<td class="line x" title="124:238	Moreover, the rst ltering step effectively reduces the number of potential candidates." ></td>
	<td class="line x" title="125:238	For example, to apply this approach to the 71,520 sentence pairs from the MT evaluation set (described in Section 4.1.2), we had to train 2,380 classi ers." ></td>
	<td class="line x" title="126:238	We also discovered that the key to the success of this approach is the size of the corpus used for training contextual classi ers." ></td>
	<td class="line x" title="127:238	We derived training corpora from the English Gigaword corpus, and the average size of a corpus for one classi er is 255,000 3In our experiments, we used the publicly available BoosTexter classi er (Schapire and Singer, 2000) for this task." ></td>
	<td class="line x" title="128:238	sentences." ></td>
	<td class="line x" title="129:238	We do not attempt to substitute any words that have less that 10,000 appearances in the Gigaword corpus." ></td>
	<td class="line x" title="130:238	4 Experiments Our primary goal is to investigate the impact of machine-generated paraphrases on the accuracy of automatic evaluation." ></td>
	<td class="line x" title="131:238	We focus on automatic evaluation of machine translation due to the availability of human annotated data in that domain." ></td>
	<td class="line x" title="132:238	The hypothesis is that by using a synthetic reference translation, automatic measures approximate better human evaluation." ></td>
	<td class="line x" title="133:238	In section 4.2, we test this hypothesis by comparing the performance of BLEU scores with and without synthetic references." ></td>
	<td class="line x" title="134:238	Our secondary goal is to study the relationship between the quality of paraphrases and their contribution to the performance of automatic machine translation evaluation." ></td>
	<td class="line x" title="135:238	In section 4.3, we present a manual evaluation of several paraphrasing methods and show a close connection between intrinsic and extrinsic assessments of these methods." ></td>
	<td class="line x" title="136:238	4.1 Experimental Set-Up We begin by describing relevant background information, including the BLEU evaluation method, the test data set, and the alternative paraphrasing methods considered in our experiments." ></td>
	<td class="line x" title="137:238	4.1.1 BLEU BLEU is the basic evaluation measure that we use in our experiments." ></td>
	<td class="line x" title="138:238	It is the geometric average of the n-gram precisions of candidate sentences with respect to the corresponding reference sentences, times a brevity penalty." ></td>
	<td class="line x" title="139:238	The BLEU score is computed as follows: BLEU = BP  4 radicaltpradicalvertex radicalvertexradicalbt 4productdisplay n=1 pn BP = min(1, e1r/c), where pn is the n-gram precision, c is the cardinality of the set of candidate sentences and r is the size of the smallest set of reference sentences." ></td>
	<td class="line x" title="140:238	To augment BLEU evaluation with paraphrasing information, we substitute each reference with the corresponding synthetic reference." ></td>
	<td class="line x" title="141:238	458 4.1.2 Data We use the Chinese portion of the 2004 NIST MT dataset." ></td>
	<td class="line x" title="142:238	This portion contains 200 Chinese documents, subdivided into a total of 1788 segments." ></td>
	<td class="line x" title="143:238	Each segment is translated by ten machine translation systems and by four human translators." ></td>
	<td class="line x" title="144:238	A quarter of the machine-translated segments are scored by human evaluators on a one-tove scale along two dimensions: adequacy and uency." ></td>
	<td class="line x" title="145:238	We use only adequacy scores, which measure how well content is preserved in the translation." ></td>
	<td class="line x" title="146:238	4.1.3 Alternative Paraphrasing Techniques To investigate the effect of paraphrase quality on automatic evaluation, we consider two alternative paraphrasing resources: Latent Semantic Analysis (LSA), and Brown clustering (Brown et al. , 1992)." ></td>
	<td class="line x" title="147:238	These techniques are widely used in NLP applications, including language modeling, information extraction, and dialogue processing (Haghighi et al. , 2005; Sera n and Eugenio, 2004; Miller et al. , 2004)." ></td>
	<td class="line x" title="148:238	Both techniques are based on distributional similarity." ></td>
	<td class="line x" title="149:238	The Brown clustering is computed by considering mutual information between adjacent words." ></td>
	<td class="line x" title="150:238	LSA is a dimensionality reduction technique that projects a word co-occurrence matrix to lower dimensions." ></td>
	<td class="line x" title="151:238	This lower dimensional representation is then used with standard similarity measures to cluster the data." ></td>
	<td class="line x" title="152:238	Two words are considered to be a paraphrase pair if they appear in the same cluster." ></td>
	<td class="line x" title="153:238	We construct 1000 clusters employing the Brown method on 112 million words from the North American New York Times corpus." ></td>
	<td class="line x" title="154:238	We keep the top 20 most frequent words for each cluster as paraphrases." ></td>
	<td class="line x" title="155:238	To generate LSA paraphrases, we used the Infomap software4 on a 34 million word collection of articles from the American News Text corpus." ></td>
	<td class="line x" title="156:238	We used the default parameter settings: a 20,000 word vocabulary, the 1000 most frequent words (minus a stoplist) for features, a 15 word context window on either side of a word, a 100 feature reduced representation, and the 20 most similar words as paraphrases." ></td>
	<td class="line x" title="157:238	While we experimented with several parameter settings for LSA and Brown methods, we do not claim that the selected settings are necessarily optimal." ></td>
	<td class="line x" title="158:238	However, these methods present sensible com4http://infomap-nlp.sourceforge.net Method 1 reference 2 references BLEU 0.9657 0.9743 WordNet 0.9674 0.9763 ContextWN 0.9677 0.9764 LSA 0.9652 0.9736 Brown 0.9662 0.9744 Table 4: Pearson adequacy correlation scores for rewriting using one and two references, averaged over ten runs." ></td>
	<td class="line x" title="159:238	Method vs. BLEU vs. ContextWN WordNet trianglelefttriangleleft triangletriangle ContextWN trianglelefttriangleleft LSA X triangletriangle Brown trianglelefttriangleleft triangle Table 5: Paired t-test signi cance for all methods compared to BLEU as well as our method for one reference." ></td>
	<td class="line x" title="160:238	Two triangles indicates signi cant at the 99% con dence level, one triangle at the 95% condence level and X not signi cant." ></td>
	<td class="line x" title="161:238	Triangles point towards the better method." ></td>
	<td class="line x" title="162:238	parison points for understanding the relationship between paraphrase quality and its impact on automatic evaluation." ></td>
	<td class="line x" title="163:238	Table 3 shows synthetic references produced by the different paraphrasing methods." ></td>
	<td class="line x" title="164:238	4.2 Impact of Paraphrases on Machine Translation Evaluation The standard way to analyze the performance of an evaluation metric in machine translation is to compute the Pearson correlation between the automatic metric and human scores (Papineni et al. , 2002; Koehn, 2004; Lin and Och, 2004; Stent et al. , 2005)." ></td>
	<td class="line x" title="165:238	Pearson correlation estimates how linearly dependent two sets of values are." ></td>
	<td class="line x" title="166:238	The Pearson correlation values range from 1, when the scores are perfectly linearly correlated, to -1, in the case of inversely correlated scores." ></td>
	<td class="line x" title="167:238	To calculate the Pearson correlation, we create a document by concatenating 300 segments." ></td>
	<td class="line x" title="168:238	This strategy is commonly used in MT evaluation, because of BLEUs well-known problems with documents of small size (Papineni et al. , 2002; Koehn, 2004)." ></td>
	<td class="line x" title="169:238	For each of the ten MT system translations, 459 Reference: The monthly magazine Choices has won the deep trust of the residents." ></td>
	<td class="line x" title="170:238	The current Internet edition of Choices will give full play to its functions and will help consumers get quick access to market information." ></td>
	<td class="line x" title="171:238	System: The public has a lot of faith in the Choice monthly magazine and the Council is now working on a web version." ></td>
	<td class="line x" title="172:238	This will enhance the magazines function and help consumer to acquire more up-to-date market information." ></td>
	<td class="line x" title="173:238	WordNet The monthly magazine Choices has won the deep faith of the residents." ></td>
	<td class="line x" title="174:238	The current Internet version of Choices will give full play to its functions and will help consumers acquire quick access to market information." ></td>
	<td class="line x" title="175:238	ContextWN The monthly magazine Choices has won the deep trust of the residents." ></td>
	<td class="line x" title="176:238	The current Internet version of Choices will give full play to its functions and will help consumers acquire quick access to market information." ></td>
	<td class="line x" title="177:238	LSA The monthly magazine Choice has won the deep trust of the residents." ></td>
	<td class="line x" title="178:238	The current web edition of Choice will give full play to its functions and will help consumer get quick access to market information." ></td>
	<td class="line x" title="179:238	Brown The monthly magazine Choices has won the deep trust of the residents." ></td>
	<td class="line x" title="180:238	The current Internet version of Choices will give full play to its functions and will help consumers get quick access to market information." ></td>
	<td class="line x" title="181:238	Table 3: Sample of paraphrasings produced by each method based on the corresponding system translation." ></td>
	<td class="line x" title="182:238	Paraphrased words are in bold and ltered words underlined." ></td>
	<td class="line x" title="183:238	the evaluation metric score is calculated on the document and the corresponding human adequacy score is calculated as the average human score over the segments." ></td>
	<td class="line x" title="184:238	The Pearson correlation is calculated over these ten pairs (Papineni et al. , 2002; Stent et al. , 2005)." ></td>
	<td class="line x" title="185:238	This process is repeated for ten different documents created by the same process." ></td>
	<td class="line x" title="186:238	Finally, a paired t-test is calculated over these ten different correlation scores to compute statistical signi cance." ></td>
	<td class="line x" title="187:238	Table 4 shows Pearson correlation scores for BLEU and the four paraphrased augmentations, averaged over ten runs.5 In all ten tests, our method based on contextual rewriting (ContextWN) improves the correlation with human scores over BLEU." ></td>
	<td class="line x" title="188:238	Moreover, in nine out of ten tests ContextWN outperforms the method based on WordNet." ></td>
	<td class="line x" title="189:238	The results of statistical signi cance testing are summarized in Table 5." ></td>
	<td class="line x" title="190:238	All the paraphrasing methods except LSA, exhibit higher correlation with human scores than plain BLEU." ></td>
	<td class="line x" title="191:238	Our method signi cantly outperforms BLEU, and all the other paraphrasebased metrics." ></td>
	<td class="line x" title="192:238	This consistent improvement conrms the importance of contextual ltering." ></td>
	<td class="line x" title="193:238	5Depending on the experimental setup, correlation values can vary widely." ></td>
	<td class="line x" title="194:238	Our scores fall within the range of previous researchers (Papineni et al. , 2002; Lin and Och, 2004)." ></td>
	<td class="line x" title="195:238	The third column in Table 4 shows that automatic paraphrasing continues to improve correlation scores even when two human references are paraphrased using our method." ></td>
	<td class="line x" title="196:238	4.3 Evaluation of Paraphrase Quality In the last section, we saw signi cant variations in MT evaluation performance when different paraphrasing methods were used to generate a synthetic reference." ></td>
	<td class="line x" title="197:238	In this section, we examine the correlation between the quality of automatically generated paraphrases and their contribution to automatic evaluation." ></td>
	<td class="line x" title="198:238	We analyze how the substitution frequency and the accuracy of those substitutions contributes to a methods performance." ></td>
	<td class="line x" title="199:238	We compute the substitution frequency of an automatic paraphrasing method by counting the number of words it rewrites in a set of reference sentences." ></td>
	<td class="line x" title="200:238	Table 6 shows the substitution frequency and the corresponding BLEU score." ></td>
	<td class="line x" title="201:238	The substitution frequency varies greatly across different methods LSA is by far the most proli c rewriter, while Brown produces very few substitutions." ></td>
	<td class="line x" title="202:238	As expected, the more paraphrases identi ed, the higher the BLEU score for the method." ></td>
	<td class="line x" title="203:238	However, this increase does 460 Method Score Substitutions BLEU 0.0913 WordNet 0.0969 994 ContextWN 0.0962 742 LSA 0.992 2080 Brown 0.921 117 Table 6: Scores and the number of substitutions made for all 1788 segments, averaged over the different MT system translations Method Judge 1 Judge 2 Kappa accuracy accuracy WordNet 63.5% 62.5% 0.74 ContextWN 75% 76.0% 0.69 LSA 30% 31.5% 0.73 Brown 56% 56% 0.72 Table 7: Accuracy scores by two human judges as well as the Kappa coef cient of agreement." ></td>
	<td class="line x" title="204:238	not translate into better evaluation performance." ></td>
	<td class="line x" title="205:238	For instance, our contextual ltering method removes approximately a quarter of the paraphrases suggested by WordNet and yields a better evaluation measure." ></td>
	<td class="line x" title="206:238	These results suggest that the substitution frequency cannot predict the utility value of the paraphrasing method." ></td>
	<td class="line x" title="207:238	Accuracy measures the correctness of the proposed substitutions in the context of a reference sentence." ></td>
	<td class="line x" title="208:238	To evaluate the accuracy of different paraphrasing methods, we randomly extracted 200 paraphrasing examples from each method." ></td>
	<td class="line x" title="209:238	A paraphrase example consists of a reference sentence, a reference word to be paraphrased and a proposed paraphrase of that reference (that actually occurred in a corresponding system translation)." ></td>
	<td class="line x" title="210:238	The judge was instructed to mark a substitution as correct only if the substitution was both semantically and grammatically correct in the context of the original reference sentence." ></td>
	<td class="line x" title="211:238	Paraphrases produced by the four methods were judged by two native English speakers." ></td>
	<td class="line x" title="212:238	The pairs were presented in random order, and the judges were not told which system produced a given pair." ></td>
	<td class="line x" title="213:238	We employ a commonly used measure, Kappa, to assess agreement between the judges." ></td>
	<td class="line x" title="214:238	We found that negative positive ltered 40 27 nonltered 33 100 Table 8: Confusion matrix for the context ltering method on a random sample of 200 examples labeled by the rst judge." ></td>
	<td class="line x" title="215:238	on all the four sets the Kappa value was around 0.7, which corresponds to substantial agreement (Landis and Koch, 1977)." ></td>
	<td class="line x" title="216:238	As Table 7 shows, the ranking between the accuracy of the different paraphrasing methods mirrors the ranking of the corresponding MT evaluation methods shown in Table 4." ></td>
	<td class="line x" title="217:238	The paraphrasing method with the highest accuracy, ContextWN, contributes most signi cantly to the evaluation performance of BLEU." ></td>
	<td class="line x" title="218:238	Interestingly, even methods with moderate accuracy, i.e. 63% for WordNet, have a positive in uence on the BLEU metric." ></td>
	<td class="line x" title="219:238	At the same time, poor paraphrasing accuracy, such as LSA with 30%, does hurt the performance of automatic evaluation." ></td>
	<td class="line x" title="220:238	To further understand the contribution of contextual ltering, we compare the substitutions made by WordNet and ContextWN on the same set of sentences." ></td>
	<td class="line x" title="221:238	Among the 200 paraphrases proposed by WordNet, 73 (36.5%) were identi ed as incorrect by human judges." ></td>
	<td class="line x" title="222:238	As the confusion matrix in Table 8 shows, 40 (54.5%) were eliminated during the ltering step." ></td>
	<td class="line x" title="223:238	At the same time, the ltering erroneously eliminates 27 positive examples (21%)." ></td>
	<td class="line x" title="224:238	Even at this level of false negatives, the ltering has an overall positive effect." ></td>
	<td class="line x" title="225:238	5 Conclusion and Future Work This paper presents a comprehensive study of the impact of paraphrases on the accuracy of automatic evaluation." ></td>
	<td class="line x" title="226:238	We found a strong connection between the quality of automatic paraphrases as judged by humans and their contribution to automatic evaluation." ></td>
	<td class="line x" title="227:238	These results have two important implications: (1) re ning standard measures such as BLEU with paraphrase information moves the automatic evaluation closer to human evaluation and (2) applying paraphrases to MT evaluation provides a task-based assessment for paraphrasing accuracy." ></td>
	<td class="line x" title="228:238	461 We also introduce a novel paraphrasing method based on contextual substitution." ></td>
	<td class="line x" title="229:238	By posing the paraphrasing problem as a discriminative task, we can incorporate a wide range of features that improve the paraphrasing accuracy." ></td>
	<td class="line x" title="230:238	Our experiments show improvement of the accuracy of WordNet paraphrasing and we believe that this method can similarly bene t other approaches that use lexicosemantic resources to obtain paraphrases." ></td>
	<td class="line x" title="231:238	Our ultimate goal is to develop a contextual ltering method that does not require candidate selection based on a lexico-semantic resource." ></td>
	<td class="line x" title="232:238	One source of possible improvement lies in exploring more powerful learning frameworks and more sophisticated linguistic representations." ></td>
	<td class="line x" title="233:238	Incorporating syntactic dependencies and class-based features into the context representation could also increase the accuracy and the coverage of the method." ></td>
	<td class="line x" title="234:238	Our current method only implements rewriting at the word level." ></td>
	<td class="line x" title="235:238	In the future, we would like to incorporate substitutions at the level of phrases and syntactic trees." ></td>
	<td class="line x" title="236:238	Acknowledgments The authors acknowledge the support of the National Science Foundation (Barzilay; CAREER grant IIS-0448168) and DARPA (Kauchak; grant HR0011-06-C-0023)." ></td>
	<td class="line x" title="237:238	Thanks to Michael Collins, Charles Elkan, Yoong Keok Lee, Philip Koehn, Igor Malioutov, Ben Snyder and the anonymous reviewers for helpful comments and suggestions." ></td>
	<td class="line x" title="238:238	Any opinions, ndings and conclusions expressed in this material are those of the author(s) and do not necessarily re ect the views of DARPA or NSF." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-1034
Learning To Generate Naturalistic Utterances Using Reviews In Spoken Dialogue Systems
Higashinaka, Ryuichiro;Prasad, Rashmi;Walker, Marilyn A.;"></td>
	<td class="line x" title="1:231	Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 265272, Sydney, July 2006." ></td>
	<td class="line x" title="2:231	c2006 Association for Computational Linguistics Learning to Generate Naturalistic Utterances Using Reviews in Spoken Dialogue Systems Ryuichiro Higashinaka NTT Corporation rh@cslab.kecl.ntt.co.jp Rashmi Prasad University of Pennsylvania rjprasad@linc.cis.upenn.edu Marilyn A. Walker University of Sheffield walker@dcs.shef.ac.uk Abstract Spoken language generation for dialogue systems requires a dictionary of mappings between semantic representations of concepts the system wants to express and realizations of those concepts." ></td>
	<td class="line x" title="3:231	Dictionary creation is a costly process; it is currently done by hand for each dialogue domain." ></td>
	<td class="line x" title="4:231	We propose a novel unsupervised method for learning such mappings from user reviews in the target domain, and test it on restaurant reviews." ></td>
	<td class="line x" title="5:231	We test the hypothesis that user reviews that provide individual ratings for distinguished attributes of the domain entity make it possible to map review sentences to their semantic representation with high precision." ></td>
	<td class="line x" title="6:231	Experimental analyses show that the mappings learned cover most of the domain ontology, and provide good linguistic variation." ></td>
	<td class="line x" title="7:231	A subjective user evaluation shows that the consistency between the semantic representations and the learned realizations is high and that the naturalness of the realizations is higher than a hand-crafted baseline." ></td>
	<td class="line x" title="8:231	1 Introduction One obstacle to the widespread deployment of spoken dialogue systems is the cost involved withhand-craftingthespoken languagegeneration module." ></td>
	<td class="line x" title="9:231	Spoken language generation requires a dictionary of mappings between semantic representations of concepts the system wants to express and realizations of those concepts." ></td>
	<td class="line x" title="10:231	Dictionary creation is a costly process: an automatic method for creating them would make dialogue technology more scalable." ></td>
	<td class="line x" title="11:231	A secondary benefit is that a learned dictionary may produce more natural and colloquial utterances." ></td>
	<td class="line x" title="12:231	We propose a novel method for mining user reviews to automatically acquire a domain specific generation dictionary for information presentation in a dialogue system." ></td>
	<td class="line x" title="13:231	Our hypothesis is that reviews that provide individual ratings for various distinguished attributes of review entities can be used to map review sentences to a semantic repAn example user review (we8there.com) Ratings Food=5, Service=5, Atmosphere=5, Value=5, Overall=5 Review comment The best Spanish food in New York." ></td>
	<td class="line x" title="14:231	I am from Spain and I had my 28th birthday there and we all had a great time." ></td>
	<td class="line x" title="15:231	Salud!" ></td>
	<td class="line x" title="16:231	 Review commentafter named entity recognition The best {NE=foodtype, string=Spanish}{NE=food, string=food, rating=5} in {NE=location, string=New York}  Mappingbetweena semantic representation(a set of relations) and a syntactic structure(DSyntS)  Relations: RESTAURANT has FOODTYPE RESTAURANT has foodquality=5 RESTAURANT has LOCATION ([foodtype,food=5, location] for shorthand.)" ></td>
	<td class="line x" title="17:231	 DSyntS:                     lexeme : food class : common noun number : sg article : def ATTR bracketleftBig lexeme : best class : adjective bracketrightBig ATTR   lexeme : FOODTYPE class : common noun number : sg article : no-art   ATTR      lexeme : in class : preposition II   lexeme : LOCATION class : proper noun number : sg article : no-art                            Figure 1: Example of procedure for acquiring a generation dictionary mapping." ></td>
	<td class="line x" title="18:231	resentation." ></td>
	<td class="line x" title="19:231	Figure 1 shows a user review in the restaurant domain, where we hypothesize that the user rating food=5 indicates that the semantic representation for the sentence The best Spanish food in New York includes the relation RESTAURANT has foodquality=5. We apply the method to extract 451 mappings from restaurant reviews." ></td>
	<td class="line x" title="20:231	Experimental analyses show that the mappings learned cover most of the domainontology,and providegoodlinguisticvariation." ></td>
	<td class="line x" title="21:231	A subjective user evaluation indicates that the consistency between the semantic representations and the learned realizations is high and that the naturalness of the realizations is significantly higher than a hand-crafted baseline." ></td>
	<td class="line x" title="22:231	265 Section 2 provides a step-by-step description of the method." ></td>
	<td class="line x" title="23:231	Sections 3 and 4 present the evaluation results." ></td>
	<td class="line x" title="24:231	Section 5 covers related work." ></td>
	<td class="line x" title="25:231	Section 6 summarizes and discusses future work." ></td>
	<td class="line x" title="26:231	2 Learning a Generation Dictionary Our automatically created generation dictionary consists of triples (U,R,S) representing a mapping between the original utterance U in the user review, its semantic representation R(U), and its syntactic structure S(U)." ></td>
	<td class="line x" title="27:231	Although templates are widely used in many practicalsystems (Seneff and Polifroni, 2000; Theune, 2003), we derive syntactic structures to represent the potential realizations, in order to allow aggregation, and other syntactic transformations of utterances, as well as contextspecificprosodyassignment(Walkeretal., 2003; Moore et al. , 2004)." ></td>
	<td class="line x" title="29:231	The method is outlined briefly in Fig." ></td>
	<td class="line x" title="30:231	1 and described below." ></td>
	<td class="line x" title="31:231	It comprises the following steps: 1." ></td>
	<td class="line x" title="32:231	Collect user reviews on the web to create a population of utterances U. 2." ></td>
	<td class="line x" title="33:231	To derive semantic representations R(U):  Identify distinguished attributes and construct a domain ontology;  Specify lexicalizations of attributes;  Scrape webpages structured data for named-entities;  Tag named-entities." ></td>
	<td class="line x" title="34:231	3." ></td>
	<td class="line x" title="35:231	Derive syntactic representations S(U)." ></td>
	<td class="line x" title="36:231	4." ></td>
	<td class="line x" title="37:231	Filter inappropriate mappings." ></td>
	<td class="line x" title="38:231	5." ></td>
	<td class="line x" title="39:231	Add mappings (U,R,S) to dictionary." ></td>
	<td class="line x" title="40:231	2.1 Creating the corpus We created a corpus of restaurant reviews by scraping 3,004 user reviews of 1,810 restaurants posted at we8there.com (http://www.we8there.com/), where each individual review includes a 1-to-5 Likert-scale rating of different restaurant attributes." ></td>
	<td class="line x" title="41:231	The corpus consists of 18,466 sentences." ></td>
	<td class="line x" title="42:231	2.2 Deriving semantic representations The distinguished attributes are extracted from the webpages for each restaurant entity." ></td>
	<td class="line x" title="43:231	They include attributes that the users are asked to rate, i.e. food, service, atmosphere, value,andoverall, which have scalar values." ></td>
	<td class="line x" title="44:231	In addition, other attributes are extracted from the webpage, such as the name, foodtype and location of the restaurant, which have categorical values." ></td>
	<td class="line x" title="45:231	The name attribute is assumed to correspond to the restaurant entity." ></td>
	<td class="line x" title="46:231	Given the distinguished attributes, a Dist. Attr." ></td>
	<td class="line x" title="47:231	Lexicalization food food, meal service service, staff, waitstaff, wait staff, server, waiter, waitress atmosphere atmosphere, decor, ambience, decoration value value, price, overprice, pricey, expensive, inexpensive, cheap, affordable, afford overall recommend, place, experience, establishment Table 1: Lexicalizations for distinguished attributes." ></td>
	<td class="line x" title="48:231	simple domain ontology can be automatically derived by assuming that a meronymy relation, represented by the predicate has, holds between the entity type (RESTAURANT) and the distinguished attributes." ></td>
	<td class="line x" title="49:231	Thus, the domain ontology consists of the relations:                RESTAURANT has foodquality RESTAURANT has servicequality RESTAURANT has valuequality RESTAURANT has atmospherequality RESTAURANT has overallquality RESTAURANT has foodtype RESTAURANT has location We assume that, although users may discuss other attributes of the entity, at least some of the utterancesin the reviewsrealizethe relations specified in the ontology." ></td>
	<td class="line x" title="50:231	Our problem then is to identify these utterances." ></td>
	<td class="line x" title="51:231	We test the hypothesis that, if an utterance U contains named-entities corresponding to the distinguished attributes, thatR for that utterance includes the relation concerning that attribute in the domain ontology." ></td>
	<td class="line x" title="52:231	We define named-entities for lexicalizations of the distinguished attributes, starting with the seed word for that attribute on the webpage (Table 1)." ></td>
	<td class="line x" title="53:231	1 Fornamed-entityrecognition, weuseGATE(Cunningham et al. , 2002), augmented with namedentity lists for locations, food types, restaurant names, and food subtypes (e.g. pizza), scraped from the we8there webpages." ></td>
	<td class="line x" title="54:231	We also hypothesizethat the rating givenfor the distinguished attribute specifies the scalar value of the relation." ></td>
	<td class="line x" title="55:231	For example, a sentence containing food or meal is assumed to realize the relation RESTAURANT has foodquality.,andthe value of the foodquality attribute is assumed to be the value specified in the user rating for that attribute, e.g. RESTAURANT has foodquality = 5 in Fig." ></td>
	<td class="line x" title="56:231	1." ></td>
	<td class="line x" title="57:231	Similarly, the other relations in Fig." ></td>
	<td class="line x" title="58:231	1 are assumed to be realized by the utterance The best Spanish food in New York because it contains 1 In future, we will investigate other techniques for bootstrapping these lexicalizations from the seed word on the webpage." ></td>
	<td class="line x" title="59:231	266 filter filtered retained No Relations Filter 7,947 10,519 Other Relations Filter 5,351 5,168 Contextual Filter 2,973 2,195 Unknown Words Filter 1,467 728 Parsing Filter 216 512 Table 2: Filtering statistics: the number of sentences filtered and retained by each filter." ></td>
	<td class="line x" title="60:231	one FOODTYPE named-entity and one LOCATION named-entity." ></td>
	<td class="line x" title="61:231	Values of categorical attributes are replaced by variables representing their type before the learned mappings are added to the dictionary, as shown in Fig." ></td>
	<td class="line x" title="62:231	1." ></td>
	<td class="line x" title="63:231	2.3 Parsing and DSyntS conversion We adopt Deep Syntactic Structures (DSyntSs) as a format for syntactic structures because they can be realized by the fast portable realizer RealPro (Lavoie and Rambow, 1997)." ></td>
	<td class="line x" title="64:231	Since DSyntSs are a type of dependency structure, we first process the sentences with Minipar (Lin, 1998), and then convert Minipars representation into DSyntS." ></td>
	<td class="line x" title="65:231	Since user reviews are different from the newspaper articles on which Minipar was trained, the output of Minipar can be inaccurate, leading to failure in conversion." ></td>
	<td class="line x" title="66:231	We check whether conversion is successful in the filtering stage." ></td>
	<td class="line x" title="67:231	2.4 Filtering The goal of filtering is to identify U that realize the distinguished attributes and to guarantee high precision for the learned mappings." ></td>
	<td class="line x" title="68:231	Recall is less important since systems need to convey requested information as accurately as possible." ></td>
	<td class="line x" title="69:231	Our procedurefor derivingsemanticrepresentationsis based on the hypothesisthat ifU containsnamed-entities that realizethe distinguishedattributes, thatRwill include the relevant relation in the domain ontology." ></td>
	<td class="line x" title="70:231	We also assume that if U contains namedentities that are not covered by the domain ontology, or words indicating that the meaning of U depends on the surrounding context, that R will not completely characterizesthe meaning ofU,andso U should be eliminated." ></td>
	<td class="line x" title="71:231	We also require an accurate S for U. Therefore, the filters described below eliminate U that (1) realize semantic relations not in the ontology; (2) contain words indicating that its meaning depends on the context; (3) contain unknown words; or (4) cannot be parsed accurately." ></td>
	<td class="line x" title="72:231	No Relations Filter: The sentence does not contain any named-entities for the distinguished attributes." ></td>
	<td class="line x" title="73:231	Other Relations Filter: The sentence contains named-entities for food subtypes, person Rating Dist.Attr." ></td>
	<td class="line x" title="74:231	1234 5Total food 5 8 6 18 57 94 service 15 3 6 17 56 97 atmosphere 033831 45 value 001812 21 overall 3 2 5 15 45 70 Total 23 15 21 64 201 327 Table 3: Domain coverage of single scalar-valued relation mappings." ></td>
	<td class="line x" title="75:231	names, country names, dates (e.g. , today, tomorrow, Aug. 26th) or prices (e.g. , 12 dollars), or POS tag CD for numerals." ></td>
	<td class="line x" title="76:231	These indicate relations not in the ontology." ></td>
	<td class="line x" title="77:231	Contextual Filter: The sentence contains indexicals such as I, you, that or cohesive markers of rhetorical relations that connect it to some part of the preceding text, which means that the sentence cannot be interpreted out of context." ></td>
	<td class="line x" title="78:231	These include discourse markers, such as list item markers with LS as the POS tag, that signal the organization structure of the text (Hirschberg and Litman, 1987), as well as discourse connectives that signal semantic and pragmatic relations of the sentence with other parts of the text (Knott, 1996), such as coordinatingconjunctions at the beginning of the utterance like and and but etc. , and conjunct adverbs such as however, also, then." ></td>
	<td class="line x" title="79:231	Unknown Words Filter: The sentence contains words not in WordNet (Fellbaum, 1998) (which includes typographical errors), or POS tags contain NN (Noun), which may indicate an unknown named-entity, or the sentence has more than a fixed length of words, 2 indicating that its meaning may not be estimated solely by named entities." ></td>
	<td class="line x" title="80:231	Parsing Filter: The sentence fails the parsing to DSyntS conversion." ></td>
	<td class="line x" title="81:231	Failures are automatically detected by comparing the original sentence with the one realized by RealPro taking the converted DSyntS as an input." ></td>
	<td class="line x" title="82:231	We apply the filters, in a cascading manner, to the 18,466 sentences with semantic representations." ></td>
	<td class="line x" title="83:231	As a result, we obtain 512 (2.8%) mappings of (U,R,S)." ></td>
	<td class="line x" title="84:231	After removing 61 duplicates, 451 distinct (2.4%) mappings remain." ></td>
	<td class="line x" title="85:231	Table 2 shows the number of sentences eliminated by each filter." ></td>
	<td class="line x" title="86:231	3 Objective Evaluation We evaluate the learned expressions with respect to domain coverage, linguistic variation and generativity." ></td>
	<td class="line x" title="87:231	2 We used 20 as a threshold." ></td>
	<td class="line x" title="88:231	267 # Combination of Dist. Attrs Count 1 food-service 39 2 food-value 21 3 atmosphere-food 14 4 atmosphere-service 10 5 atmosphere-food-service 7 6 food-foodtype 4 7 atmosphere-food-value 4 8 location-overall 3 9 food-foodtype-value 3 10 food-service-value 2 11 food-foodtype-location 2 12 food-overall 2 13 atmosphere-foodtype 2 14 atmosphere-overall 2 15 service-value 1 16 overall-service 1 17 overall-value 1 18 foodtype-overall 1 19 food-foodtype-location-overall 1 20 atmosphere-food-service-value 1 21 atmosphere-food-overallservice-value 1 Total 122 Table 4: Counts for multi-relation mappings." ></td>
	<td class="line x" title="89:231	3.1 Domain Coverage To be usable for a dialogue system, the mappings must have good domain coverage." ></td>
	<td class="line x" title="90:231	Table 3 shows the distribution of the 327 mappings realizing a single scalar-valued relation, categorized by the associatedrating score." ></td>
	<td class="line x" title="91:231	3 For example, there are 57 mappings with R of RESTAURANT has foodquality=5, and a large number of mappings for both the foodquality and servicequality relations." ></td>
	<td class="line x" title="92:231	Although we could not obtain mappings for some relations such as price={1,2}, coverage for expressing a single relation is fairly complete." ></td>
	<td class="line x" title="93:231	There are also mappings that express several relations." ></td>
	<td class="line x" title="94:231	Table 4 shows the counts of mappings for multi-relation mappings, with those containing a food or service relation occurring more frequentlyas inthesingle scalar-valuedrelationmappings." ></td>
	<td class="line x" title="95:231	We found only 21 combinations of relations, which is surprising given the large potential number of combinations (There are 50 combinations if we treat relations with different scalar values differently)." ></td>
	<td class="line x" title="96:231	We also find that most of the mappingshavetwo or threerelations, perhaps suggesting that system utterances should not express too many relations in a single sentence." ></td>
	<td class="line x" title="97:231	3.2 Linguistic Variation We also wish to assess whether the linguistic variation of the learned mappings was greater than what we could easily have generated with a hand-crafted dictionary, or a hand-crafted dictionary augmented with aggregation operators, as in 3 There are two other single-relation but not scalar-valued mappings that concern LOCATION in our mappings." ></td>
	<td class="line x" title="98:231	(Walker et al. , 2003)." ></td>
	<td class="line x" title="99:231	Thus, we first categorized the mappings by the patterns of the DSyntSs." ></td>
	<td class="line x" title="100:231	Table 5 shows the most common syntactic patterns (more than 10 occurrences), indicating that 30% of the learned patterns consist of the simple form X is ADJwhereADJ is an adjective, or X is RB ADJ, where RB is a degree modifier." ></td>
	<td class="line x" title="101:231	Furthermore, up to 55% of the learned mappings could be generated from these basic patterns by the application of a combination operator that coordinates multiple adjectives, or coordinates predications over distinct attributes." ></td>
	<td class="line x" title="102:231	However, there are 137 syntactic patterns in all, 97 with unique syntactic structures and 21 with two occurrences, accounting for 45% of the learned mappings." ></td>
	<td class="line x" title="103:231	Table 6 shows examplesof learned mappingswith distinctsyntactic structures." ></td>
	<td class="line x" title="104:231	It would be surprising to see this type of variety in a hand-crafted generation dictionary." ></td>
	<td class="line x" title="105:231	In addition, the learned mappings contain 275 distinct lexemes, with a minimum of 2, maximum of 15, and mean of 4.63 lexemes per DSyntS, indicating that the method extracts a wide variety of expressions of varying lengths." ></td>
	<td class="line x" title="106:231	Another interesting aspect of the learned mappings is the wide variety of adjectival phrases (APs)inthecommonpatterns." ></td>
	<td class="line x" title="107:231	Tables7and8 show the APs in singlescalar-valuedrelation mappings for food and service categorized by the associated ratings." ></td>
	<td class="line x" title="108:231	Tables for atmosphere, value and overall can be found in the Appendix." ></td>
	<td class="line x" title="109:231	Moreover, the meanings for some of the learned APs are very specific to the particular attribute, e.g. cold and burnt associated with foodquality of 1, attentive and prompt for servicequality of 5, silly and inattentive for servicequality of 1." ></td>
	<td class="line x" title="110:231	and mellow for atmosphere of 5." ></td>
	<td class="line x" title="111:231	In addition, our method places the adjectival phrases (APs) in the common patterns on a more fine-grained scale of 1 to 5, similar to the strengthclassificationsin (Wilsonet al. , 2004), in contrast to other automatic methods that classify expressions into a binary positive or negative polarity (e.g.(Turney, 2002))." ></td>
	<td class="line x" title="113:231	3.3 Generativity Our motivation for deriving syntactic representations for the learned expressions was the possibility of using an off-the-shelf sentence planner to derive new combinations of relations, and apply aggregation and other syntactic transformations." ></td>
	<td class="line x" title="114:231	We examined how many of the learned DSyntSs can be combined with each other, by taking every pair of DSyntSs in the mappings and applying the built-in merge operation in the SPaRKy generator (Walker et al. , 2003)." ></td>
	<td class="line x" title="115:231	We found that only 306 combinations out of a potential 81,318 268 # syntactic pattern example utterance count ratio accum." ></td>
	<td class="line x" title="116:231	1 NN VB JJ The atmosphere is wonderful." ></td>
	<td class="line x" title="117:231	92 20.4% 20.4% 2 NN VB RB JJ The atmosphere was very nice." ></td>
	<td class="line x" title="118:231	52 11.5% 31.9% 3 JJ NN Bad service." ></td>
	<td class="line x" title="119:231	36 8.0% 39.9% 4 NN VB JJ CC JJ The food was flavorful but cold." ></td>
	<td class="line x" title="120:231	25 5.5% 45.5% 5 RB JJ NN Very trendy ambience." ></td>
	<td class="line x" title="121:231	22 4.9% 50.3% 6 NN VB JJ CC NN VB JJ The food is excellent and the atmosphere is great." ></td>
	<td class="line x" title="122:231	13 2.9% 53.2% 7 NN CC NN VB JJ The food and service were fantastic." ></td>
	<td class="line x" title="123:231	10 2.2% 55.4% Table 5: Common syntactic patterns of DSyntSs, flattened to a POS sequence for readability." ></td>
	<td class="line x" title="124:231	NN, VB, JJ, RB, CC stand for noun, verb, adjective, adverb, and conjunction, respectively." ></td>
	<td class="line x" title="125:231	[overall=1, value=2] Very disappointing experience for the money charged." ></td>
	<td class="line x" title="126:231	[food=5, value=5] The food is excellent and plentiful at a reasonable price." ></td>
	<td class="line x" title="127:231	[food=5, service=5] The food is exquisite as well as the service and setting." ></td>
	<td class="line x" title="128:231	[food=5,service=5]The food was spectacular and so was the service." ></td>
	<td class="line x" title="129:231	[food=5, foodtype, value=5] Best FOODTYPE food with a great value for money." ></td>
	<td class="line x" title="130:231	[food=5, foodtype, value=5] An absolutely outstanding value with fantastic FOODTYPE food." ></td>
	<td class="line x" title="131:231	[food=5, foodtype, location, overall=5] This is the best place to eat FOODTYPE food in LOCATION." ></td>
	<td class="line x" title="132:231	[food=5, foodtype] Simply amazing FOODTYPE food." ></td>
	<td class="line x" title="133:231	[food=5, foodtype] RESTAURANTNAMEis the best of the best for FOODTYPE food." ></td>
	<td class="line x" title="134:231	[food=5] The food is to die for." ></td>
	<td class="line x" title="135:231	[food=5] What incredible food." ></td>
	<td class="line x" title="136:231	[food=4] Very pleasantly surprised by the food." ></td>
	<td class="line x" title="137:231	[food=1] The food has gone downhill." ></td>
	<td class="line x" title="138:231	[atmosphere=5, overall=5] This is a quiet little place with great atmosphere." ></td>
	<td class="line x" title="139:231	[atmosphere=5,food=5, overall=5, service=5, value=5] The food, service and ambience of the place are all fabulous and the prices are downright cheap." ></td>
	<td class="line x" title="140:231	Table 6: Acquired generation patterns (with shorthand for relations in square brackets) whose syntactic patterns occurred only once." ></td>
	<td class="line x" title="141:231	combinations (0.37%) were successful." ></td>
	<td class="line x" title="142:231	This is because the merge operation in SPaRKy requires that the subjects and the verbs of the two DSyntSs are identical, e.g. the subject is RESTAURANT and verb is has, whereas the learned DSyntSs often place the attribute in subject position as a definite noun phrase." ></td>
	<td class="line x" title="143:231	However, the learned DSyntS can be incorporated into SPaRKy using the semantic representations to substitute learned DSyntSs into nodes in the sentence plan tree." ></td>
	<td class="line x" title="144:231	Figure 2 shows some example utterances generated by SPaRKy with its originaldictionary and exampleutterances when the learned mappings are incorporated." ></td>
	<td class="line x" title="145:231	The resulting utterances seem more natural and colloquial; we examine whether this is true in the next section." ></td>
	<td class="line x" title="146:231	4 Subjective Evaluation We evaluate the obtained mappings in two respects: the consistency between the automatically derived semantic representation and the realizafood=1 awful, bad, burnt, cold, very ordinary food=2 acceptable, bad, flavored, not enough, very bland, very good food=3 adequate, bland and mediocre, flavorful but cold, pretty good, rather bland, very good food=4 absolutely wonderful, awesome, decent, excellent, good, good and generous, great, outstanding, rather good, really good, traditional, very fresh and tasty, very good, very very good food=5 absolutely delicious, absolutely fantastic, absolutely great, absolutely terrific, ample, well seasoned and hot, awesome, best, delectable and plentiful, delicious, delicious but simple, excellent, exquisite, fabulous, fancy but tasty, fantastic, fresh, good, great, hot, incredible, just fantastic, large and satisfying, outstanding, plentiful and outstanding, plentiful and tasty, quick and hot, simply great, so delicious, so very tasty, superb, terrific, tremendous, very good, wonderful Table 7: Adjectival phrases (APs) in single scalarvalued relation mappings for foodquality." ></td>
	<td class="line x" title="147:231	tion, and the naturalness of the realization." ></td>
	<td class="line x" title="148:231	For comparison, we used a baseline of handcrafted mappings from (Walker et al. , 2003) except that we changed the word decor to atmosphere and added five mappings for overall." ></td>
	<td class="line x" title="149:231	For scalar relations, this consists of the realization RESTAURANT has ADJ LEX where ADJ is mediocre, decent,good,very good,orexcellent for rating values 1-5, and LEX is food quality, service, atmosphere, value,oroverall depending on the relation." ></td>
	<td class="line x" title="150:231	RESTAURANT is filled with the name of a restaurant at runtime." ></td>
	<td class="line x" title="151:231	For example, RESTAURANT has foodquality=1 is realized as RESTAURANT has mediocre food quality. The location and food type relations are mapped to RESTAURANT is located in LOCATION and RESTAURANT is a FOODTYPE restaurant. The learned mappings include 23 distinct semantic representationsfor a single-relation (22 for scalar-valued relations and one for location) and 50 for multi-relations." ></td>
	<td class="line x" title="152:231	Therefore, using the handcrafted mappings, we first created 23 utterances for the single-relations." ></td>
	<td class="line x" title="153:231	We then created three utterancesforeachof50multi-relationsusingdifferent clause-combining operations from (Walker et al. , 2003)." ></td>
	<td class="line x" title="154:231	This gave a total of 173 baseline utterances, which together with 451 learned mappings, 269 service=1 awful, bad, great, horrendous, horrible, inattentive, forgetful and slow, marginal, really slow, silly and inattentive, still marginal, terrible, young service=2 overly slow, very slow and inattentive service=3 bad, bland and mediocre, friendly and knowledgeable, good, pleasant, prompt, very friendly service=4 all very warm and welcoming, attentive, extremely friendly and good, extremely pleasant, fantastic, friendly, friendly and helpful, good, great, great and courteous, prompt and friendly, really friendly, so nice, swift and friendly, very friendly, very friendly and accommodating service=5 all courteous, excellent, excellent and friendly, extremely friendly, fabulous, fantastic, friendly, friendly and helpful, friendly and very attentive, good, great, great, prompt and courteous, happy and friendly, impeccable, intrusive, legendary, outstanding, pleasant, polite, attentive and prompt, prompt and courteous, prompt and pleasant, quick and cheerful, stupendous, superb, the most attentive, unbelievable, very attentive, very congenial, very courteous, very friendly, very friendly and helpful, very friendly and pleasant, very friendly and totally personal, very friendly and welcoming, very good, very helpful, very timely, warm and friendly, wonderful Table 8: Adjectival phrases (APs) in single scalarvalued relation mappings for servicequality." ></td>
	<td class="line x" title="155:231	yielded 624 utterances for evaluation." ></td>
	<td class="line x" title="156:231	Ten subjects, all native English speakers, evaluated the mappings by reading them from a webpage." ></td>
	<td class="line x" title="157:231	For each system utterance, the subjects were asked to express their degree of agreement, on a scale of 1 (lowest) to 5 (highest), with the statement (a) The meaning of the utterance is consistent with the ratings expressing their semantics, and with the statement (b) The style of the utterance is very natural and colloquial.Theywere asked not to correct their decisions and also to rate each utterance on its own merit." ></td>
	<td class="line x" title="158:231	4.1 Results Table 9 shows the means and standard deviations of thescores forbaselinevs." ></td>
	<td class="line x" title="159:231	learned utterancesfor consistency and naturalness." ></td>
	<td class="line x" title="160:231	A t-test shows that theconsistencyofthe learnedexpressionis significantly lower than the baseline (df=4712, p <.001) but that their naturalness is significantly higher than the baseline (df=3107, p < .001)." ></td>
	<td class="line x" title="161:231	However, consistency is still high." ></td>
	<td class="line x" title="162:231	Only 14 of the learned utterances (shown in Tab." ></td>
	<td class="line x" title="163:231	10) have a mean consistency score lower than 3, which indicates that, by and large, the human judges felt that the inferred semantic representations were consistent with the meaning of the learned expressions." ></td>
	<td class="line x" title="164:231	The correlation coefficient between consistency and naturalness scores is 0.42, which indicates that consisOriginal SPaRKy utterances  Babbo has the best overall quality among the selected restaurants with excellent decor, excellent service and superb food quality." ></td>
	<td class="line x" title="165:231	 Babbo has excellent decor and superb food quality with excellent service." ></td>
	<td class="line x" title="166:231	It has the best overall quality among the selected restaurants." ></td>
	<td class="line x" title="167:231	 Combination of SPaRKy and learnedDSyntS  Because the food is excellent, the wait staff is professional and the decor is beautiful and very comfortable, Babbo has the best overall quality among the selected restaurants." ></td>
	<td class="line x" title="168:231	 Babbo has the best overall quality among the selected restaurants because atmosphere is exceptionally nice, food is excellent and the service is superb." ></td>
	<td class="line x" title="169:231	 Babbo has superb food quality, the service is exceptional and the atmosphere is very creative.Ithasthe best overall quality among the selected restaurants." ></td>
	<td class="line x" title="170:231	Figure 2: Utterances incorporating learned DSyntSs (Bold font) in SPaRKy." ></td>
	<td class="line x" title="171:231	baseline learned stat." ></td>
	<td class="line x" title="172:231	mean sd." ></td>
	<td class="line x" title="173:231	mean sd." ></td>
	<td class="line x" title="174:231	sig." ></td>
	<td class="line x" title="175:231	Consistency 4.714 0.588 4.459 0.890 + Naturalness 4.227 0.852 4.613 0.844 + Table 9: Consistency and naturalness scores averaged over 10 subjects." ></td>
	<td class="line x" title="176:231	tency does not greatly relate to naturalness." ></td>
	<td class="line x" title="177:231	We also performed an ANOVA (ANalysis Of VAriance) of the effect of each relation in R on naturalness and consistency." ></td>
	<td class="line x" title="178:231	There were no significant effects except that mappings combining food, service, and atmosphere were significantly worse (df=1, F=7.79, p=0.005)." ></td>
	<td class="line x" title="179:231	However, there is a trend for mappings to be rated higher for the food attribute (df=1, F=3.14, p=0.08) and the value attribute (df=1, F=3.55, p=0.06) for consistency, suggesting that perhaps it is easier to learn some mappings than others." ></td>
	<td class="line oc" title="180:231	5 Related Work Automatically finding sentences with the same meaning has been extensively studied in the field of automatic paraphrasing using parallel corpora and corporawith multiple descriptionsof the same events (Barzilay and McKeown, 2001; Barzilay and Lee, 2003)." ></td>
	<td class="line x" title="181:231	Other work finds predicates of similar meanings by using the similarity of contexts around the predicates (Lin and Pantel, 2001)." ></td>
	<td class="line x" title="182:231	However, these studies find a set of sentences with the same meaning, but do not associate a specific meaning with the sentences." ></td>
	<td class="line x" title="183:231	One exception is (Barzilay and Lee, 2002), which derives mappings between semantic representations and realizations using a parallel (but unaligned) corpus consisting of both complex semantic input and corresponding natural language verbalizations for mathemat270 shorthand for relations and utterance score [food=4] The food is delicious and beautifully prepared." ></td>
	<td class="line x" title="184:231	2.9 [overall=4] A wonderful experience." ></td>
	<td class="line x" title="185:231	2.9 [service=3]The service is bland and mediocre." ></td>
	<td class="line x" title="186:231	2.8 [atmosphere=2] The atmosphere here is eclectic." ></td>
	<td class="line x" title="187:231	2.6 [overall=3] Really fancy place." ></td>
	<td class="line x" title="188:231	2.6 [food=3, service=4] Wonderful service and great food." ></td>
	<td class="line x" title="189:231	2.5 [service=4]The service is fantastic." ></td>
	<td class="line x" title="190:231	2.5 [overall=2] The RESTAURANTNAME is once a great place to go and socialize." ></td>
	<td class="line x" title="191:231	2.2 [atmosphere=2] The atmosphere is unique and pleasant." ></td>
	<td class="line x" title="192:231	2.0 [food=5,foodtype] FOODTYPEand FOODTYPE food." ></td>
	<td class="line x" title="193:231	1.8 [service=3] Waitstaff is friendly and knowledgeable." ></td>
	<td class="line x" title="194:231	1.7 [atmosphere=5,food=5, service=5] The atmosphere, food and service." ></td>
	<td class="line x" title="195:231	1.6 [overall=3] Overall, a great experience." ></td>
	<td class="line x" title="196:231	1.4 [service=1]The waiter is great." ></td>
	<td class="line x" title="197:231	1.4 Table 10: The 14 utterances with consistency scores below 3." ></td>
	<td class="line x" title="198:231	ical proofs." ></td>
	<td class="line x" title="199:231	However, our technique does not require parallel corpora or previously existing semantictranscriptsor labeling, and userreviewsare widely available in many different domains (See http://www.epinions.com/)." ></td>
	<td class="line x" title="200:231	There is also significant previous work on mining user reviews." ></td>
	<td class="line x" title="201:231	For example, Hu and Liu (2005) use reviews to find adjectives to describeproducts, and Popescuand Etzioni(2005) automaticallyfind features of a product together with the polarity of adjectives used to describe them." ></td>
	<td class="line x" title="202:231	They both aim at summarizing reviews so that users can make decisions easily." ></td>
	<td class="line x" title="203:231	Our method is also capable of finding polarities of modifying expressions including adjectives, but on a more fine-grained scale of 1 to 5." ></td>
	<td class="line x" title="204:231	However, it might be possible to use their approach to create rating information for raw review texts as in (Pang and Lee, 2005), so that we can create mappings from reviews without ratings." ></td>
	<td class="line x" title="205:231	6 Summary and Future Work We proposed automatically obtaining mappings between semantic representations and realizations from reviews with individual ratings." ></td>
	<td class="line x" title="206:231	The results show that: (1) the learned mappings provide good coverage of the domain ontology and exhibit good linguistic variation; (2) the consistency between the semantic representations and realizations is high; and (3) the naturalnessof the realizations are significantly higher than the baseline." ></td>
	<td class="line x" title="207:231	There are also limitations in our method." ></td>
	<td class="line x" title="208:231	Even though consistency is rated highly by human subjects, this may actually be a judgement of whether the polarity of the learned mapping is correctly placed on the 1 to 5 rating scale." ></td>
	<td class="line x" title="209:231	Thus, alternate ways of expressing, for example foodquality=5, shown in Table 7, cannot be guaranteed to be synonymous, which may be required for use in spoken language generation." ></td>
	<td class="line x" title="210:231	Rather, an examination of the adjectival phrases in Table 7 shows that different aspects of the food are discussed." ></td>
	<td class="line x" title="211:231	For example ample and plentiful refer to the portion size, fancy may refer to the presentation, and delicious describes the flavors." ></td>
	<td class="line x" title="212:231	This suggests that perhaps the ontology would benefit from representing these sub-attributes of the food attribute, and sub-attributes in general." ></td>
	<td class="line x" title="213:231	Another problem with consistency is that the same AP, e.g. very good in Table 7 may appear with multiple ratings." ></td>
	<td class="line x" title="214:231	For example, very good is used for every foodquality rating from 2 to 5." ></td>
	<td class="line x" title="215:231	Thus some further automatic or by-hand analysis is required to refine what is learned before actual use in spoken language generation." ></td>
	<td class="line x" title="216:231	Still, our method could reduce the amount of time a system designer spends developing the spoken language generator, and increase the naturalness of spoken language generation." ></td>
	<td class="line x" title="217:231	Another issue is that the recall appears to be quite low given that all of the sentences concern the same domain: only 2.4% of the sentences could be used to create the mappings." ></td>
	<td class="line x" title="218:231	One way to increase recall might be to automatically augment the list of distinguished attribute lexicalizations, using WordNet or work on automatic identification of synonyms, such as (Lin and Pantel, 2001)." ></td>
	<td class="line x" title="219:231	However, the method here has high precision, and automatic techniques may introduce noise." ></td>
	<td class="line x" title="220:231	A related issue is that the filters are in some cases too strict." ></td>
	<td class="line x" title="221:231	For example the contextual filter is based on POS-tags, so that sentences that do not require the prior context for their interpretation are eliminated, such as sentences containing subordinating conjunctions like because, when, if, whose arguments are both given in the same sentence (Prasad et al. , 2005)." ></td>
	<td class="line x" title="222:231	In addition, recall is affected by the domain ontology, and the automatically constructed domain ontology from the review webpages may not cover all of the domain." ></td>
	<td class="line x" title="223:231	In some review domains, the attributes that get individual ratings are a limited subset of the domain ontology." ></td>
	<td class="line x" title="224:231	Techniques for automatic feature identification (Hu and Liu, 2005; Popescu and Etzioni, 2005) could possibly help here, although these techniques currently have the limitation that they do not automatically identify different lexicalizations of the same feature." ></td>
	<td class="line x" title="225:231	A different type of limitation is that dialogue systems need to generate utterances for information gathering whereas the mappings we obtained 271 can only be used for information presentation." ></td>
	<td class="line x" title="226:231	Thus these would have to be constructed by hand, as in current practice, or perhaps other types of corpora or resources could be utilized." ></td>
	<td class="line x" title="227:231	In addition, the utility of syntactic structures in the mappingsshouldbe furtherexamined, especiallygiven the failures in DSyntS conversion." ></td>
	<td class="line x" title="228:231	An alternative would be to leave some sentences unparsed and usethem astemplateswith hybridgenerationtechniques (White and Caldwell, 1998)." ></td>
	<td class="line x" title="229:231	Finally, while webelievethatthistechniquewillapplyacrossdomains, it wouldbe usefultotest iton domainssuch as movie reviews or product reviews, which have more complex domain ontologies." ></td>
	<td class="line x" title="230:231	Acknowledgments We thank the anonymous reviewers for their helpful comments." ></td>
	<td class="line x" title="231:231	This work was supported by a Royal Society Wolfson award to Marilyn Walker and a research collaboration grant from NTT to the Cognitive Systems Group at the University of Sheffield." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-1114
Methods For Using Textual Entailment In Open-Domain Question Answering
Harabagiu, Sanda M.;Hickl, Andrew;"></td>
	<td class="line x" title="1:248	Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 905912, Sydney, July 2006." ></td>
	<td class="line x" title="2:248	c2006 Association for Computational Linguistics Methods for Using Textual Entailment in Open-Domain Question Answering Sanda Harabagiu and Andrew Hickl Language Computer Corporation 1701 North Collins Boulevard Richardson, Texas 75080 USA sanda@languagecomputer.com Abstract Work on the semantics of questions has argued that the relation between a question and its answer(s) can be cast in terms of logical entailment." ></td>
	<td class="line x" title="3:248	In this paper, we demonstrate how computational systems designed to recognize textual entailment can be used to enhance the accuracy of current open-domain automatic question answering (Q/A) systems." ></td>
	<td class="line x" title="4:248	In our experiments, we show that when textual entailment information is used to either lter or rank answers returned by a Q/A system, accuracy can be increased by as much as 20% overall." ></td>
	<td class="line x" title="5:248	1 Introduction Open-Domain Question Answering (Q/A) systems return a textual expression, identi ed from a vast document collection, as a response to a question asked in natural language." ></td>
	<td class="line x" title="6:248	In the quest for producing accurate answers, the open-domain Q/A problem has been cast as: (1) a pipeline of linguistic processes pertaining to the processing of questions, relevant passages and candidate answers, interconnected by several types of lexicosemantic feedback (cf.(Harabagiu et al. , 2001; Moldovan et al. , 2002)); (2) a combination of language processes that transform questions and candidate answers in logic representations such that reasoning systems can select the correct answer based on their proofs (cf.(Moldovan et al. , 2003)); (3) a noisy-channel model which selects the most likely answer to a question (cf.(Echihabi and Marcu, 2003)); or (4) a constraint satisfaction problem, where sets of auxiliary questions are used to provide more information and better constrain the answers to individual questions (cf.(Prager et al. , 2004))." ></td>
	<td class="line x" title="11:248	While different in their approach, each of these frameworks seeks to approximate the forms of semantic inference that will allow them to identify valid textual answers to natural language questions." ></td>
	<td class="line x" title="12:248	Recently, the task of automatically recognizing one form of semantic inference textual entailment has received much attention from groups participating in the 2005 and 2006 PASCAL Recognizing Textual Entailment (RTE) Challenges (Dagan et al. , 2005)." ></td>
	<td class="line x" title="13:248	1 As currently de ned, the RTE task requires systems to determine whether, given two text fragments, the meaning of one text could be reasonably inferred, or textually entailed, from the meaning of the other text." ></td>
	<td class="line x" title="14:248	We believe that systems developed speci cally for this task can provide current question-answering systems with valuable semantic information that can be leveraged to identify exact answers from ranked lists of candidate answers." ></td>
	<td class="line x" title="15:248	By replacing the pairs of texts evaluated in the RTE Challenge with combinations of questions and candidate answers, we expect that textual entailment could provide yet another mechanism for approximating the types of inference needed in order answer questions accurately." ></td>
	<td class="line x" title="16:248	In this paper, we present three different methods for incorporating systems for textual entailment into the traditional Q/A architecture employed by many current systems." ></td>
	<td class="line x" title="17:248	Our experimental results indicate that (even at their current level of performance) textual entailment systems can substantially improve the accuracy of Q/A, even when no other form of semantic inference is employed." ></td>
	<td class="line x" title="18:248	The remainder of the paper is organized as fol1http://www.pascal-network.org/Challenges/RTE 905 Processing Question Module (QP) Passage Retrieval Module (PR) Answer Type Expected Keywords Module Answer Processing (AP) Ranked List of Answers TEXTUAL ENTAILMENT Method 1 TEXTUAL ENTAILMENT Method 2 List of Questions Generation AUTOQUAB Ranked List of Paragraphs TEXTUAL ENTAILMENT Method 3 Entailed Questions Entailed Paragraphs List of Entailed Paragraphs Question Documents Answers AnswersM1 AnswersM2 AnswersM3 QUESTION ANSWERING SYSTEM Figure 1: Integrating Textual Entailment in Q/A. lows." ></td>
	<td class="line x" title="19:248	Section 2 describes the three methods of using textual entailment in open-domain question answering that we have identi ed, while Section 3 presents the textual entailment system we have used." ></td>
	<td class="line x" title="20:248	Section 4 details our experimental methods and our evaluation results." ></td>
	<td class="line x" title="21:248	Finally, Section 5 provides a discussion of our ndings, and Section 6 summarizes our conclusions." ></td>
	<td class="line x" title="22:248	2 Integrating Textual Entailment in Question Answering In this section, we describe three different methods for integrating a textual entailment (TE) system into the architecture of an open-domain Q/A system." ></td>
	<td class="line x" title="23:248	Work on the semantics of questions (Groenendijk, 1999; Lewis, 1988) has argued that the formal answerhood relation found between a question and a set of (correct) answers can be cast in terms of logical entailment." ></td>
	<td class="line x" title="24:248	Under these approaches (referred to as licensing by (Groenendijk, 1999) and aboutness by (Lewis, 1988)), p is considered to be an answer to a question ?q iff ?q logically entails the set of worlds in which p is true(i.e. ?p)." ></td>
	<td class="line x" title="25:248	While the notion of textual entailment has been de ned far less rigorously than logical entailment, we believe that the recognition of textual entailment between a question and a set of candidate answers or between a question and questions generated from answers can enable Q/A systems to identify correct answers with greater precision than current keywordor pattern-based techniques." ></td>
	<td class="line x" title="26:248	As illustrated in Figure 1, most open-domain Q/A systems generally consist of a sequence of three modules: (1) a question processing (QP) module; (2) a passage retrieval (PR) module; and (3) an answer processing (AP) module." ></td>
	<td class="line x" title="27:248	Questions are rst submitted to a QP module, which extracts a set of relevant keywords from the text of the question and identi es the questions expected answer type (EAT)." ></td>
	<td class="line x" title="28:248	Keywords along with the questions EAT are then used by a PR module to retrieve a ranked list of paragraphs which may contain answers to the question." ></td>
	<td class="line x" title="29:248	These paragraphs are then sent to an AP module, which extracts an exact candidate answer from each passage and then ranks each candidate answer according to the likelihood that it is a correct answer to the original question." ></td>
	<td class="line x" title="30:248	Method 1." ></td>
	<td class="line x" title="31:248	In Method 1, each of a ranked list of answers that do not meet the minimum conditions for TE are removed from consideration and then re-ranked based on the entailment con dence (a real-valued number ranging from 0 to 1) assigned by the TE system to each remaining example." ></td>
	<td class="line x" title="32:248	The system then outputs a new set of ranked answers which do not contain any answers that are not entailed by the users question." ></td>
	<td class="line x" title="33:248	Table 1 provides an example where Method 1 could be used to make the right prediction for a set of answers." ></td>
	<td class="line x" title="34:248	Even though A1 was ranked in sixth position, the identi cation of a high-con dence positive entailment enabled it to be returned as the 906 top answer." ></td>
	<td class="line x" title="35:248	In contrast, the recognition of a negative entailment for A2 caused this answer to be dropped from consideration altogether." ></td>
	<td class="line x" title="36:248	Q1: What did Peter Minuit buy for the equivalent of $24.00?" ></td>
	<td class="line x" title="37:248	Rank1 TE Rank2 Answer Text A1 6th YES (0.89) 1st Everyone knows that, back in 1626, Peter Minuit bought Manhattan from the Indians for $24 worth of trinkets." ></td>
	<td class="line x" title="38:248	A2 1st NO (0.81) In 1626, an enterprising Peter Minuit agged down some passing locals, plied them with beads, cloth and trinkets worth an estimated $24, and walked away with the whole island." ></td>
	<td class="line x" title="39:248	Table 1: Re-ranking of answers by Method 1." ></td>
	<td class="line x" title="40:248	Method 2." ></td>
	<td class="line x" title="41:248	Since AP is often a resourceintensive process for most Q/A systems, we expect that TE information can be used to limit the number of passages considered during AP." ></td>
	<td class="line x" title="42:248	As illustrated in Method 2 in Figure 1, lists of passages retrieved by a PR module can either be ranked (or ltered) using TE information." ></td>
	<td class="line x" title="43:248	Once ranking is complete, answer extraction takes place only on the set of entailed passages that the system considers likely to contain a correct answer to the users question." ></td>
	<td class="line x" title="44:248	Method 3." ></td>
	<td class="line x" title="45:248	In previous work (Harabagiu et al. , 2005b), we have described techniques that can be used to automatically generate well-formed natural language questions from the text of paragraphs retrieved by a PR module." ></td>
	<td class="line x" title="46:248	In our current system, sets of automatically-generated questions (AGQ) are created using a stand-alone AutoQUAB generation module, which assembles question-answer pairs (known as QUABs) from the top-ranked passages returned in response to a question." ></td>
	<td class="line x" title="47:248	Table 2 lists some of the questions that this module has produced for the question Q2: How hot does the inside of an active volcano get?" ></td>
	<td class="line x" title="48:248	Q2: How hot does the inside of an active volcano get?" ></td>
	<td class="line x" title="49:248	A2 Tamagawa University volcano expert Takeyo Kosaka said lava fragments belched out of the mountain on January 31 were as hot as 300 degrees Fahrenheit." ></td>
	<td class="line x" title="50:248	The intense heat from a second eruption on Tuesday forced rescue operations to stop after 90 minutes." ></td>
	<td class="line x" title="51:248	Because of the high temperatures, the bodies of only ve of the volcanos initial victims were retrieved." ></td>
	<td class="line x" title="52:248	Positive Entailment AGQ1 What temperature were the lava fragments belched out of the mountain on January 31?" ></td>
	<td class="line x" title="53:248	AGQ2 How many degrees Fahrenheit were the lava fragments belched out of the mountain on January 31?" ></td>
	<td class="line x" title="54:248	Negative Entailment AGQ3 When did rescue operations have to stop?" ></td>
	<td class="line x" title="55:248	AGQ4 How many bodies of the volcanos initial victims were retrieved?" ></td>
	<td class="line x" title="56:248	Table 2: TE between AGQs and user question." ></td>
	<td class="line x" title="57:248	Following (Groenendijk, 1999), we expect that if a question ?q logically entails another question ?qprime, then some subset of the answers entailed by ?qprime should also be interpreted as valid answers to ?q. By establishing TE between a question and AGQs derived from passages identi ed by the Q/A system for that question, we expect we can identify a set of answer passages that contain correct answers to the original question." ></td>
	<td class="line x" title="58:248	For example, in Table 2, we nd that entailment between questions indicates the correctness of a candidate answer: here, establishing that Q2 entails AGQ1 and AGQ2 (but not AGQ3 or AGQ4) enables the system to select A2 as the correct answer." ></td>
	<td class="line x" title="59:248	When at least one of the AGQs generated by the AutoQUAB module is entailed by the original question, all AGQs that do not reach TE are ltered from consideration; remaining passages are assigned an entailment con dence score and are sent to the AP module in order to provide an exact answer to the question." ></td>
	<td class="line x" title="60:248	Following this process, candidate answers extracted from the AP module were then re-associated with their AGQs and resubmitted to the TE system (as in Method 1)." ></td>
	<td class="line x" title="61:248	Question-answer pairs deemed to be positive instances of entailment were then stored in a database and used as additional training data for the AutoQUAB module." ></td>
	<td class="line x" title="62:248	When no AGQs were found to be entailed by the original question, however, passages were ranked according to their entailment con dence and sent to AP for further processing and validation." ></td>
	<td class="line x" title="63:248	3 The Textual Entailment System Processing textual entailment, or recognizing whether the information expressed in a text can be inferred from the information expressed in another text, can be performed in four ways." ></td>
	<td class="line x" title="64:248	We can try to (1) derive linguistic information from the pair of texts, and cast the inference recognition as a classi cation problem; or (2) evaluate the probability that an entailment can exist between the two texts; (3) represent the knowledge from the pair of texts in some representation language that can be associated with an inferential mechanism; or (4) use the classical AI de nition of entailment and build models of the world in which the two texts are respectively true, and then check whether the models associated with one text are included in the models associated with the other text." ></td>
	<td class="line x" title="65:248	Although we believe that each of these methods should be investigated fully, we decided to focus only on the rst method, which allowed us to build the TE system illustrated in Figure 2." ></td>
	<td class="line x" title="66:248	Our TE system consists of (1) a Preprocessing Module, which derives linguistic knowledge from the text pair; (2) an Alignment Module, which takes advantage of the notions of lexical alignment 907 Classifier YES NOTextual Input 2 Textual Input 1 Preprocessing Training Corpora Features Alignment Dependency Features Paraphrase Features Semantic/ Pragmatic Features Coreference Coreference NEAliasing Concept Paraphrase Acquisition WWW Lexical Alignment Alignment Module Feature Extraction Classification Module LexicoSemantic PoS/ NER Synonyms/ Antonyms Normalization Syntactic Semantic Temporal Parsing Modality Detection Speech Act Recognition Pragmatics Factivity Detection Belief Recognition Figure 2: Textual Entailment Architecture." ></td>
	<td class="line x" title="67:248	and textual paraphrases; and (3) a Classi cation Module, which uses a machine learning classi er (based on decision trees) to make an entailment judgment for each pair of texts." ></td>
	<td class="line x" title="68:248	As described in (Hickl et al. , 2006), the Preprocessing module is used to syntactically parse texts, identify the semantic dependencies of predicates, label named entities, normalize temporal and spatial expressions, resolve instances of coreference, and annotate predicates with polarity, tense, and modality information." ></td>
	<td class="line x" title="69:248	Following preprocessing, texts are sent to an Alignment Module which uses a Maximum Entropy-based classi er in order to estimate the probability that pairs of constituents selected from texts encode corresponding information that could be used to inform an entailment judgment." ></td>
	<td class="line x" title="70:248	This module assumes that since sets of entailing texts necessarily predicate about the same set of individuals or events, systems should be able to identify elements from each text that convey similar types of presuppositions." ></td>
	<td class="line x" title="71:248	Examples of predicates and arguments aligned by this module are presented in Figure 3." ></td>
	<td class="line x" title="72:248	Pred: Pred: ArgMLOC the inside of an active volcano an active volcano How hot the mountain the lava fragments Original QuestionAutoQUAB What temperature get hotbe temperature Arg1 Answer Type Arg1 Figure 3: Alignment Graph Aligned constituents are then used to extract sets of phrase-level alternations (or paraphrases ) from the WWW that could be used to capture correspondences between texts longer than individual constituents." ></td>
	<td class="line x" title="73:248	The top 8 candidate paraphrases for two of the aligned elements from Figure 3 are presented in Table 3." ></td>
	<td class="line x" title="74:248	Finally, the Classi cation Module employs a Judgment Paraphrase YES lava fragments in pyroclastic ows can reach 400 degrees YES an active volcano can get up to 2000 degrees NO an active volcano above you are slopes of 30 degrees YES the active volcano with steam reaching 80 degrees YES lava fragments such as cinders may still be as hot as 300 degrees NO lava is a liquid at high temperature: typically from 700 degrees Table 3: Phrase-Level Alternations decision tree classi er in order to determine whether an entailment relationship exists for each pair of texts." ></td>
	<td class="line x" title="75:248	This classi er is learned using features extracted from the previous modules, including features derived from (1) the (lexical) alignment of the texts, (2) syntactic and semantic dependencies discovered in each text passage, (3) paraphrases derived from web documents, and (4) semantic and pragmatic annotations." ></td>
	<td class="line x" title="76:248	(A complete list of features can be found in Figure 4)." ></td>
	<td class="line x" title="77:248	Based on these features, the classi er outputs both an entailment judgment (either yes or no) and a con dence value, which is used to rank answers or paragraphs in the architecture illustrated in Figure 1." ></td>
	<td class="line x" title="78:248	3.1 Lexical Alignment Several approaches to the RTE task have argued that the recognition of textual entailment can be enhanced when systems are able to identify or align corresponding entities, predicates, or phrases found in a pair of texts." ></td>
	<td class="line x" title="79:248	In this section, we show that by using a machine learning-based classi er which combines lexico-semantic information from a wide range of sources, we are able to accurately identify aligned constituents in pairs of texts with over 90% accuracy." ></td>
	<td class="line x" title="80:248	We believe the alignment of corresponding entities can be cast as a classi cation problem which uses lexico-semantic features in order to compute an alignment probability p(a), which corresponds to the likelihood that a term selected from one text entails a term from another text." ></td>
	<td class="line x" title="81:248	We used constituency information from a chunk parser to decompose the pair of texts into a set of disjoint seg908 ALIGNMENT FEATURES: These three features are derived from the results of the lexical alignment classi cation." ></td>
	<td class="line x" title="82:248	diamondmath1diamondmath LONGEST COMMON STRING: This feature represents the longest contiguous string common to both texts." ></td>
	<td class="line x" title="83:248	diamondmath2diamondmath UNALIGNED CHUNK: This feature represents the number of chunks in one text that are not aligned with a chunk from the other diamondmath3diamondmath LEXICAL ENTAILMENT PROBABILITY: This feature is de ned in (Glickman and Dagan, 2005)." ></td>
	<td class="line x" title="84:248	DEPENDENCY FEATURES: These four features are computed from the PropBank-style annotations assigned by the semantic parser." ></td>
	<td class="line x" title="85:248	diamondmath1diamondmath ENTITY-ARG MATCH: This is a boolean feature which res when aligned entities were assigned the same argument role label." ></td>
	<td class="line x" title="86:248	diamondmath2diamondmath ENTITY-NEAR-ARG MATCH: This feature is collapsing the arguments Arg1 and Arg2 (as well as the ArgM subtypes) into single categories for the purpose of counting matches." ></td>
	<td class="line x" title="87:248	diamondmath3diamondmath PREDICATE-ARG MATCH: This boolean feature is agged when at least two aligned arguments have the same role." ></td>
	<td class="line x" title="88:248	diamondmath4diamondmath PREDICATE-NEAR-ARG MATCH: This feature is collapsing the arguments Arg1 and Arg2 (as well as the ArgM subtypes) into single categories for the purpose of counting matches." ></td>
	<td class="line x" title="89:248	PARAPHRASE FEATURES: These three features are derived from the paraphrases acquired for each pair." ></td>
	<td class="line x" title="90:248	diamondmath1diamondmath SINGLE PATTERN MATCH: This is a boolean feature which red when a paraphrase matched either of the texts." ></td>
	<td class="line x" title="91:248	diamondmath2diamondmath BOTH PATTERN MATCH: This is a boolean feature which red when paraphrases matched both texts." ></td>
	<td class="line x" title="92:248	diamondmath3diamondmath CATEGORY MATCH: This is a boolean feature which red when paraphrases could be found from the same paraphrase cluster that matched both texts." ></td>
	<td class="line x" title="93:248	SEMANTIC/PRAGMATIC FEATURES: These six features are extracted by the preprocessing module." ></td>
	<td class="line x" title="94:248	diamondmath1diamondmath NAMED ENTITY CLASS: This feature has a different value for each of the 150 named entity classes." ></td>
	<td class="line x" title="95:248	diamondmath2diamondmath TEMPORAL NORMALIZATION: This boolean feature is agged when the temporal expressions are normalized to the same ISO 9000 equivalents." ></td>
	<td class="line x" title="96:248	diamondmath3diamondmath MODALITY MARKER: This boolean feature is agged when the two texts use the same modal verbs." ></td>
	<td class="line x" title="97:248	diamondmath4diamondmath SPEECH-ACT: This boolean feature is agged when the lexicons indicate the same speech act in both texts." ></td>
	<td class="line x" title="98:248	diamondmath5diamondmath FACTIVITY MARKER: This boolean feature is agged when the factivity markers indicate either TRUE or FALSE in both texts simultaneously." ></td>
	<td class="line x" title="99:248	diamondmath6diamondmath BELIEF MARKER: This boolean feature is set when the belief markers indicate either TRUE or FALSE in both texts simultaneously." ></td>
	<td class="line x" title="100:248	CONTRAST FEATURES: These six features are derived from the opposing information provided by antonymy relations or chains." ></td>
	<td class="line x" title="101:248	diamondmath1diamondmath NUMBER OF LEXICAL ANTONYMY RELATIONS: This feature counts the number of antonyms from WordNet that are discovered between the two texts." ></td>
	<td class="line x" title="102:248	diamondmath2diamondmath NUMBER OF ANTONYMY CHAINS: This feature counts the number of antonymy chains that are discovered between the two texts." ></td>
	<td class="line x" title="103:248	diamondmath3diamondmath CHAIN LENGTH: This feature represents a vector with the lengths of the antonymy chains discovered between the two texts." ></td>
	<td class="line x" title="104:248	diamondmath4diamondmath NUMBER OF GLOSSES: This feature is a vector representing the number of Gloss relations used in each antonymy chain." ></td>
	<td class="line x" title="105:248	diamondmath5diamondmath NUMBER OF MORPHOLOGICAL CHANGES: This feature is a vector representing the number of Morphological-Derivation relations found in each antonymy chain." ></td>
	<td class="line x" title="106:248	diamondmath6diamondmath NUMBER OF NODES WITH DEPENDENCIES: This feature is a vector indexing the number of nodes in each antonymy chain that contain dependency relations." ></td>
	<td class="line x" title="107:248	diamondmath7diamondmath TRUTH-VALUE MISMATCH: This is a boolean feature which red when two aligned predicates differed in any truth value." ></td>
	<td class="line x" title="108:248	diamondmath8diamondmath POLARITY MISMATCH: This is a boolean feature which red when predicates were assigned opposite polarity values." ></td>
	<td class="line x" title="109:248	Figure 4: Features Used in Classifying Entailment ments known as alignable chunks." ></td>
	<td class="line x" title="110:248	Alignable chunks from one text (Ct) and the other text (Ch) are then assembled into an alignment matrix (Ct Ch)." ></td>
	<td class="line x" title="111:248	Each pair of chunks (p  Ct  Ch) is then submitted to a Maximum Entropy-based classier which determines whether or not the pair of chunks represents a case of lexical entailment." ></td>
	<td class="line x" title="112:248	Three classes of features were used in the Alignment Classi er: (1) a set of statistical features (e.g. cosine similarity), (2) a set of lexicosemantic features (including WordNet Similarity (Pedersen et al. , 2004), named entity class equality, and part-of-speech equality), and (3) a set of string-based features (such as Levenshtein edit distance and morphological stem equality)." ></td>
	<td class="line x" title="113:248	As in (Hickl et al. , 2006), we used a twostep approach to obtain suf cient training data for the Alignment Classi er." ></td>
	<td class="line x" title="114:248	First, humans were tasked with annotating a total of 10,000 alignment pairs (extracted from the 2006 PASCAL Development Set) as either positive or negative instances of alignment." ></td>
	<td class="line x" title="115:248	These annotations were then used to train a hillclimber that was used to annotate a larger set of 450,000 alignment pairs selected at random from the training corpora described in Section 3.3." ></td>
	<td class="line x" title="116:248	These machine-annotated examples were then used to train the Maximum Entropy-based classi er that was used in our TE system." ></td>
	<td class="line x" title="117:248	Table 4 presents results from TEs linearand Maximum Entropy-based Alignment Classiers on a sample of 1000 alignment pairs selected at random from the 2006 PASCAL Test Set." ></td>
	<td class="line oc" title="118:248	Classi er Training Set Precision Recall F-Measure Linear 10K pairs 0.837 0.774 0.804 Maximum Entropy 10K pairs 0.881 0.851 0.866 Maximum Entropy 450K pairs 0.902 0.944 0.922 Table 4: Performance of Alignment Classi er 3.2 Paraphrase Acquisition Much recent work on automatic paraphrasing (Barzilay and Lee, 2003) has used relatively simple statistical techniques to identify text passages that contain the same information from parallel corpora." ></td>
	<td class="line o" title="119:248	Since sentence-level paraphrases are generally assumed to contain information about the same event, these approaches have generally assumed that all of the available paraphrases for a given sentence will include at least one pair of entities which can be used to extract sets of paraphrases from text." ></td>
	<td class="line x" title="120:248	The TE system uses a similar approach to gather phrase-level alternations for each entailment pair." ></td>
	<td class="line x" title="121:248	In our system, the two highest-con dence entity alignments returned by the Lexical Alignment module were used to construct a query which was used to retrieve the top 500 documents from Google, as well as all matching instances from our training corpora described in Section 3.3." ></td>
	<td class="line x" title="122:248	This method did not always extract true paraphrases of either texts." ></td>
	<td class="line oc" title="123:248	In order increase the likelihood that 909 only true paraphrases were considered as phraselevel alternations for an example, extracted sentences were clustered using complete-link clustering using a technique proposed in (Barzilay and Lee, 2003)." ></td>
	<td class="line x" title="124:248	3.3 Creating New Sources of Training Data In order to obtain more training data for our TE system, we extracted more than 200,000 examples of textual entailment from large newswire corpora." ></td>
	<td class="line x" title="125:248	Positive Examples." ></td>
	<td class="line x" title="126:248	Following an idea proposed in (Burger and Ferro, 2005), we created a corpus of approximately 101,000 textual entailment examples by pairing the headline and rst sentence from newswire documents." ></td>
	<td class="line x" title="127:248	In order to increase the likelihood of including only positive examples, pairs were ltered that did not share an entity (or an NP) in common between the headline and the rst sentence Judgment Example YES Text-1: Sydney newspapers made a secret deal not to report on the fawning and spending during the citys successful bid for the 2000 Olympics, former Olympics Minister Bruce Baird said today." ></td>
	<td class="line x" title="128:248	Text-2: Papers Said To Protect Sydney Bid YES Text-1: An IOC member expelled in the Olympic bribery scandal was consistently drunk as he checked out Stockholms bid for the 2004 Games and got so offensive that he was thrown out of a dinner party, Swedish of cials said." ></td>
	<td class="line x" title="129:248	Text-2: Of cials Say IOC Member Was Drunk Table 5: Positive Examples Negative Examples." ></td>
	<td class="line x" title="130:248	Two approaches were used to gather negative examples for our training set." ></td>
	<td class="line x" title="131:248	First, we extracted 98,000 pairs of sequential sentences that included mentions of the same named entity from a large newswire corpus." ></td>
	<td class="line x" title="132:248	We also extracted 21,000 pairs of sentences linked by connectives such as even though, in contrast and but." ></td>
	<td class="line x" title="133:248	Judgment Example NO Text-1: One player losing a close friend is Japanese pitcher Hideki Irabu, who was befriended by Wells during spring training last year." ></td>
	<td class="line x" title="134:248	Text-2: Irabu said he would take Wells out to dinner when the Yankees visit Toronto." ></td>
	<td class="line x" title="135:248	NO Text-1: According to the professor, present methods of cleaning up oil slicks are extremely costly and are never completely ef cient." ></td>
	<td class="line x" title="136:248	Text-2: In contrast, he stressed, Clean Mag has a 100 percent pollution retrieval rate, is low cost and can be recycled." ></td>
	<td class="line x" title="137:248	Table 6: Negative Examples 4 Experimental Results In this section, we describe results from four sets of experiments designed to explore how textual entailment information can be used to enhance the quality of automatic Q/A systems." ></td>
	<td class="line x" title="138:248	We show that by incorporating features from TE into a Q/A system which employs no other form of textual inference, we can improve accuracy by more than 20% over a baseline." ></td>
	<td class="line x" title="139:248	We conducted our evaluations on a set of 500 factoid questions selected randomly from questions previously evaluated during the annual TREC Q/A evaluations." ></td>
	<td class="line x" title="140:248	2 Of these 500 questions, 335 (67.0%) were automatically assigned an answer type from our systems answer type hierarchy ; the remaining 165 (33.0%) questions were classi ed as having an unknown answer type." ></td>
	<td class="line x" title="141:248	In order to provide a baseline for our experiments, we ran a version of our Q/A system, known as FERRET (Harabagiu et al. , 2005a), that does not make use of textual entailment information when identifying answers to questions." ></td>
	<td class="line x" title="142:248	Results from this baseline are presented in Table 7." ></td>
	<td class="line x" title="143:248	Question Set Questions Correct Accuracy MRR Known Answer Types 335 107 32.0% 0.3001 Unknown Answer Types 265 81 30.6% 0.2987 Table 7: Q/A Accuracy without TE The performance of the TE system described in Section 3 was rst evaluated in the 2006 PASCAL RTE Challenge." ></td>
	<td class="line x" title="144:248	In this task, systems were tasked with determining whether the meaning of a sentence (referred to as a hypothesis) could be reasonably inferred from the meaning of another sentence (known as a text)." ></td>
	<td class="line x" title="145:248	Four types of sentence pairs were evaluated in the 2006 RTE Challenge, including: pairs derived from the output of (1) automatic question-answering (QA) systems, (2) information extraction systems (IE), (3) information retrieval (IR) systems, and (4) multidocument summarization (SUM) systems." ></td>
	<td class="line x" title="146:248	The accuracy of our TE system across these four tasks is presented in Table 8." ></td>
	<td class="line x" title="147:248	Training Data Development Set Additional Corpora Number of Examples 800 201,000 T ask QA-test 0.5750 0.6950 IE-test 0.6450 0.7300 IR-test 0.6200 0.7450 SUM-test 0.7700 0.8450 Overall Accuracy 0.6525 0.7538 Table 8: Accuracy on the 2006 RTE Test Set In previous work (Hickl et al. , 2006), we have found that the type and amount of training data available to our TE system signi cantly (p < 0.05) impacted its performance on the 2006 RTE Test Set." ></td>
	<td class="line x" title="148:248	When our system was trained on the training corpora described in Section 3.3, the overall accuracy of the system increased by more than 10%, 2Text Retrieval Conference (http://trec.nist.gov) 910 from 65.25% to 75.38%." ></td>
	<td class="line x" title="149:248	In order to provide training data that replicated the task of recognizing entailment between a question and an answer, we assembled a corpus of 5000 question-answer pairs selected from answers that our baseline Q/A system returned in response to a new set of 1000 questions selected from the TREC test sets." ></td>
	<td class="line x" title="150:248	2500 positive training examples were created from answers identi ed by human annotators to be correct answers to a question, while 2500 negative examples were created by pairing questions with incorrect answers returned by the Q/A system." ></td>
	<td class="line x" title="151:248	After training our TE system on this corpus, we performed the following four experiments: Method 1." ></td>
	<td class="line x" title="152:248	In the rst experiment, the ranked lists of answers produced by the Q/A system were submitted to the TE system for validation." ></td>
	<td class="line x" title="153:248	Under this method, answers that were not entailed by the question were removed from consideration; the top-ranked entailed answer was then returned as the systems answer to the question." ></td>
	<td class="line x" title="154:248	Results from this method are presented in Table 9." ></td>
	<td class="line x" title="155:248	Method 2." ></td>
	<td class="line x" title="156:248	In this experiment, entailment information was used to rank passages returned by the PR module." ></td>
	<td class="line x" title="157:248	After an initial relevance ranking was determined from the PR engine, the top 50 passages were paired with the original question and were submitted to the TE system." ></td>
	<td class="line x" title="158:248	Passages were re-ranked using the entailment judgment and the entailment con dence computed for each pair and then submitted to the AP module." ></td>
	<td class="line x" title="159:248	Features derived from the entailment con dence were then combined with the keywordand relation-based features described in (Harabagiu et al. , 2005a) in order to produce a nal ranking of candidate answers." ></td>
	<td class="line x" title="160:248	Results from this method are presented in Table 9." ></td>
	<td class="line x" title="161:248	Method 3." ></td>
	<td class="line x" title="162:248	In the third experiment, TE was used to select AGQs that were entailed by the question submitted to the Q/A system." ></td>
	<td class="line x" title="163:248	Here, AutoQUAB was used to generate questions for the top 50 candidate answers identi ed by the system." ></td>
	<td class="line x" title="164:248	When at least one of the top 50 AGQs were entailed by the original question, the answer passage associated with the top-ranked entailed question was returned as the answer." ></td>
	<td class="line x" title="165:248	When none of the top 50 AGQs were entailed by the question, questionanswer pairs were re-ranked based on the entailment con dence, and the top-ranked answer was returned." ></td>
	<td class="line x" title="166:248	Results for both of these conditions are presented in Table 9." ></td>
	<td class="line x" title="167:248	Hybrid Method." ></td>
	<td class="line x" title="168:248	Finally, we found that the best results could be obtained by combining aspects of each of these three strategies." ></td>
	<td class="line x" title="169:248	Under this approach, candidate answers were initially ranked using features derived from entailment classi cations performed between (1) the original question and each candidate answer and (2) the original question and the AGQ generated from each candidate answer." ></td>
	<td class="line x" title="170:248	Once a ranking was established, answers that were not judged to be entailed by the question were also removed from nal ranking." ></td>
	<td class="line x" title="171:248	Results from this hybrid method are provided in Table 9." ></td>
	<td class="line x" title="172:248	Known EAT Unknown EAT Acc MRR Acc MRR Baseline 32.0% 0.3001 30.6% 0.2978 Method 1 44.1% 0.4114 39.5% 0.3833 Method 2 52.4% 0.5558 42.7% 0.4135 Method 3 41.5% 0.4257 37.5% 0.3575 Hybrid 53.9% 0.5640 41.9% 0.4010 Table 9: Q/A Performance with TE 5 Discussion The experiments reported in this paper suggest that current TE systems may be able to provide open-domain Q/A systems with the forms of semantic inference needed to perform accurate answer validation." ></td>
	<td class="line x" title="173:248	While probabilistic or web-based methods for answer validation have been previously explored in the literature (Magnini et al. , 2002), these approaches have modeled the relationship between a question and a (correct) answer in terms of relevance and have not tried to approximate the deeper semantic phenomena that are involved in determining answerhood." ></td>
	<td class="line x" title="174:248	Our work suggests that considerable gains in performance can be obtained by incorporating TE during both answer processing and passage retrieval." ></td>
	<td class="line x" title="175:248	While best results were obtained using the Hybrid Method (which boosted performance by nearly 28% for questions with known EATs), each of the individual methods managed to boost the overall accuracy of the Q/A system by at least 7%." ></td>
	<td class="line x" title="176:248	When TE was used to lter non-entailed answers from consideration (Method 1), the overall accuracy of the Q/A system increased by 12% over the baseline (when an EAT could be identi ed) and by nearly 9% (when no EAT could be identi ed)." ></td>
	<td class="line x" title="177:248	In contrast, when entailment information was used to rank passages and candidate answers, performance increased by 22% and 10% respectively." ></td>
	<td class="line x" title="178:248	Somewhat smaller performance gains were achieved when TE was used to select 911 amongst AGQs generated by our Q/A systems AutoQUAB module (Method 3)." ></td>
	<td class="line x" title="179:248	We expect that by adding features to TE system speci cally designed to account for the semantic contributions of a questions EAT, we may be able to boost the performance of this method." ></td>
	<td class="line x" title="180:248	6 Conclusions In this paper, we discussed three different ways that a state-of-the-art textual entailment system could be used to enhance the performance of an open-domain Q/A system." ></td>
	<td class="line x" title="181:248	We have shown that when textual entailment information is used to either lter or rank candidate answers returned by a Q/A system, Q/A accuracy can be improved from 32% to 52% (when an answer type can be detected) and from 30% to 40% (when no answer type can be detected)." ></td>
	<td class="line x" title="182:248	We believe that these results suggest that current supervised machine learning approaches to the recognition of textual entailment may provide open-domain Q/A systems with the inferential information needed to develop viable answer validation systems." ></td>
	<td class="line x" title="183:248	7 Acknowledgments This material is based upon work funded in whole or in part by the U.S. Government and any opinions, ndings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily re ect the views of the U.S. Government." ></td>
	<td class="line x" title="184:248	References Regina Barzilay and Lillian Lee." ></td>
	<td class="line x" title="185:248	2003." ></td>
	<td class="line x" title="186:248	Learning to paraphrase: An unsupervised approach using multiple-sequence alignment." ></td>
	<td class="line x" title="187:248	In HLT-NAACL." ></td>
	<td class="line x" title="188:248	John Burger and Lisa Ferro." ></td>
	<td class="line x" title="189:248	2005." ></td>
	<td class="line x" title="190:248	Generating an Entailment Corpus from News Headlines." ></td>
	<td class="line x" title="191:248	In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, pages 49 54." ></td>
	<td class="line x" title="192:248	Ido Dagan, Oren Glickman, and Bernardo Magnini." ></td>
	<td class="line x" title="193:248	2005." ></td>
	<td class="line x" title="194:248	The PASCAL Recognizing Textual Entailment Challenge." ></td>
	<td class="line x" title="195:248	In Proceedings of the PASCAL Challenges Workshop." ></td>
	<td class="line x" title="196:248	Abdessamad Echihabi and Daniel Marcu." ></td>
	<td class="line x" title="197:248	2003." ></td>
	<td class="line x" title="198:248	A noisy-channel approach to question answering." ></td>
	<td class="line x" title="199:248	In Proceedings of the 41st Meeting of the Association for Computational Linguistics." ></td>
	<td class="line x" title="200:248	Oren Glickman and Ido Dagan." ></td>
	<td class="line x" title="201:248	2005." ></td>
	<td class="line x" title="202:248	A Probabilistic Setting and Lexical Co-occurrence Model for Textual Entailment." ></td>
	<td class="line x" title="203:248	In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, Ann Arbor, USA." ></td>
	<td class="line x" title="204:248	Jeroen Groenendijk." ></td>
	<td class="line x" title="205:248	1999." ></td>
	<td class="line x" title="206:248	The logic of interrogation: Classical version." ></td>
	<td class="line x" title="207:248	In Proceedings of the Ninth Semantics and Linguistics Theory Conference (SALT IX), Ithaca, NY." ></td>
	<td class="line x" title="208:248	Sanda Harabagiu, Dan Moldovan, Marius Pasca, Rada Mihalcea, Mihai Surdeanu, Razvan Bunsecu, Roxana Girju, Vasile Rus, and Paul Morarescu." ></td>
	<td class="line x" title="209:248	2001." ></td>
	<td class="line x" title="210:248	The Role of Lexico-Semantic Feedback in OpenDomain Textual Question-Answering." ></td>
	<td class="line x" title="211:248	In Proceedings of the 39th Meeting of the Association for Computational Linguistics." ></td>
	<td class="line x" title="212:248	S. Harabagiu, D. Moldovan, C. Clark, M. Bowden, A. Hickl, and P. Wang." ></td>
	<td class="line x" title="213:248	2005a." ></td>
	<td class="line x" title="214:248	Employing Two Question Answering Systems in TREC 2005." ></td>
	<td class="line x" title="215:248	In Proceedings of the Fourteenth Text REtrieval Conference." ></td>
	<td class="line x" title="216:248	Sanda Harabagiu, Andrew Hickl, John Lehmann, and Dan Moldovan." ></td>
	<td class="line x" title="217:248	2005b." ></td>
	<td class="line x" title="218:248	Experiments with Interactive Question-Answering." ></td>
	<td class="line x" title="219:248	In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL05)." ></td>
	<td class="line x" title="220:248	Andrew Hickl, John Williams, Jeremy Bensley, Kirk Roberts, Bryan Rink, and Ying Shi." ></td>
	<td class="line x" title="221:248	2006." ></td>
	<td class="line x" title="222:248	Recognizing Textual Entailment with LCCs Groundhog System." ></td>
	<td class="line x" title="223:248	In Proceedings of the Second PASCAL Challenges Workshop." ></td>
	<td class="line x" title="224:248	David Lewis." ></td>
	<td class="line x" title="225:248	1988." ></td>
	<td class="line x" title="226:248	Relevant Implication." ></td>
	<td class="line x" title="227:248	Theoria, 54(3):161 174." ></td>
	<td class="line x" title="228:248	Bernardo Magnini, Matteo Negri, Roberto Prevete, and Hristo Tanev." ></td>
	<td class="line x" title="229:248	2002." ></td>
	<td class="line x" title="230:248	Is it the right answer?" ></td>
	<td class="line x" title="231:248	exploiting web redundancy for answer validation." ></td>
	<td class="line x" title="232:248	In Proceedings of the Fortieth Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, PA. Dan Moldovan, Marius Pasca, Sanda Harabagiu, and Mihai Surdeanu." ></td>
	<td class="line x" title="233:248	2002." ></td>
	<td class="line x" title="234:248	Performance Issues and Error Analysis in an Open-Domain Question Answering System." ></td>
	<td class="line x" title="235:248	In Proceedings of the 4Oth Meeting of the Association for Computational Linguistics." ></td>
	<td class="line x" title="236:248	Dan Moldovan, Christine Clark, Sanda Harabagiu, and Steve Maiorano." ></td>
	<td class="line x" title="237:248	2003." ></td>
	<td class="line x" title="238:248	COGEX: A Logic Prover for Question Answering." ></td>
	<td class="line x" title="239:248	In Proceedings of HLT/NAACL-2003." ></td>
	<td class="line x" title="240:248	T. Pedersen, S. Patwardhan, and J. Michelizzi." ></td>
	<td class="line x" title="241:248	2004." ></td>
	<td class="line x" title="242:248	WordNet::Similarity Measuring the Relatedness of Concepts." ></td>
	<td class="line x" title="243:248	In Proceedings of the Nineteenth National Conference on Arti cial Intelligence (AAAI04), San Jose, CA." ></td>
	<td class="line x" title="244:248	John Prager, Jennifer Chu-Carroll, and Krzysztof Czuba." ></td>
	<td class="line x" title="245:248	2004." ></td>
	<td class="line x" title="246:248	Question answering using constraint satisfaction: Qa-by-dossier-with-contraints." ></td>
	<td class="line x" title="247:248	In Proceedings of the ACL-2004, pages 574 581, Barcelona, Spain, July." ></td>
	<td class="line x" title="248:248	912" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-2027
Automatic Creation Of Domain Templates
Filatova, Elena;Hatzivassiloglou, Vasileios;McKeown, Kathleen R.;"></td>
	<td class="line x" title="1:242	Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 207214, Sydney, July 2006." ></td>
	<td class="line x" title="2:242	c2006 Association for Computational Linguistics Automatic Creation of Domain Templates Elena Filatova*, Vasileios Hatzivassiloglou and Kathleen McKeown* *Department of Computer Science Columbia University {filatova,kathy}@cs.columbia.edu Department of Computer Science The University of Texas at Dallas vh@hlt.utdallas.edu Abstract Recently, many Natural Language Processing (NLP) applications have improved the quality of their output by using various machine learning techniques to mine Information Extraction (IE) patterns for capturing information from the input text." ></td>
	<td class="line x" title="3:242	Currently, to mine IE patterns one should know in advance the type of the information that should be captured by these patterns." ></td>
	<td class="line x" title="4:242	In this work we propose a novel methodology for corpus analysis based on cross-examination of several document collections representing different instances of the same domain." ></td>
	<td class="line x" title="5:242	We show that this methodology can be used for automatic domain template creation." ></td>
	<td class="line x" title="6:242	As the problem of automatic domain template creation is rather new, there is no well-defined procedure for the evaluation of the domain template quality." ></td>
	<td class="line x" title="7:242	Thus, we propose a methodology for identifying what information should be present in the template." ></td>
	<td class="line x" title="8:242	Using this information we evaluate the automatically created domain templates through the text snippets retrieved according to the created templates." ></td>
	<td class="line x" title="9:242	1 Introduction Open-ended question-answering (QA) systems typically produce a response containing a variety of specific facts proscribed by the question type." ></td>
	<td class="line x" title="10:242	A biography, for example, might contain the date of birth, occupation, or nationality of the person in question (Duboue and McKeown, 2003; Zhou et al. , 2004; Weischedel et al. , 2004; Filatova and Prager, 2005)." ></td>
	<td class="line x" title="11:242	A definition may contain the genus of the term and characteristic attributes (Blair-Goldensohn et al. , 2004)." ></td>
	<td class="line x" title="12:242	A response to a question about a terrorist attack might include the event, victims, perpetrator and date as the templates designed for the Message Understanding Conferences (Radev and McKeown, 1998; White et al. , 2001) predicted." ></td>
	<td class="line x" title="13:242	Furthermore, the type of information included varies depending on context." ></td>
	<td class="line x" title="14:242	A biography of an actor would include movie names, while a biography of an inventor would include the names of inventions." ></td>
	<td class="line x" title="15:242	A description of a terrorist event in Latin America in the eighties is different from the description of todays terrorist events." ></td>
	<td class="line x" title="16:242	How does one determine what facts are important for different kinds of responses?" ></td>
	<td class="line x" title="17:242	Often the types of facts that are important are hand encoded ahead of time by a human expert (e.g. , as in the case of MUC templates)." ></td>
	<td class="line x" title="18:242	In this paper, we present an approach that allows a system to learn the types of facts that are appropriate for a particular response." ></td>
	<td class="line x" title="19:242	We focus on acquiring fact-types for events, automatically producing a template that can guide the creation of responses to questions requiring a description of an event." ></td>
	<td class="line x" title="20:242	The template can be tailored to a specific time period or country simply by changing the document collections from which learning takes place." ></td>
	<td class="line x" title="21:242	In this work, a domain is a set of events of a particular type; earthquakes and presidential elections are two such domains." ></td>
	<td class="line x" title="22:242	Domains can be instantiated by several instances of events of that type (e.g. , the earthquake in Japan in October 2004, the earthquake in Afghanistan in March 2002, etc.).1 The granularity of domains and instances can be altered by examining data at different levels of detail, and domains can be hierarchically structured." ></td>
	<td class="line x" title="23:242	An ideal template is a set of attribute-value pairs, with the attributes specifying particular functional roles important for the domain events." ></td>
	<td class="line x" title="24:242	In this paper we present a method of domainindependent on-the-fly template creation." ></td>
	<td class="line x" title="25:242	Our method is completely automatic." ></td>
	<td class="line x" title="26:242	As input it requires several document collections describing domain instances." ></td>
	<td class="line x" title="27:242	We cross-examine the input instances, we identify verbs important for the majority of instances and relationships containing these verbs." ></td>
	<td class="line x" title="28:242	We generalize across multiple domain instances to automatically determine which of these relations should be used in the template." ></td>
	<td class="line x" title="29:242	We report on data collection efforts and results from four domains." ></td>
	<td class="line x" title="30:242	We assess how well the automatically produced templates satisfy users needs, as manifested by questions collected for these domains." ></td>
	<td class="line x" title="31:242	1Unfortunately, NLP terminology is not standardized across different tasks." ></td>
	<td class="line x" title="32:242	Two NLP tasks most close to our research are Topic Detection and Tracking (TDT) (Fiscus et al. , 1999) and Information Extraction (IE) (Marsh and Perzanowski, 1997)." ></td>
	<td class="line x" title="33:242	In TDT terminology, our domains are topics and our instances are events." ></td>
	<td class="line x" title="34:242	In IE terminology, our domains are scenarios and our domain templates are scenario templates." ></td>
	<td class="line x" title="35:242	207 2 Related Work Our system automatically generates a template that captures the generally most important information for a particular domain and is reusable across multiple instances of that domain." ></td>
	<td class="line x" title="36:242	Deciding what slots to include in the template, and what restrictions to place on their potential fillers, is a knowledge representation problem (Hobbs and Israel, 1994)." ></td>
	<td class="line x" title="37:242	Templates were used in the main IE competitions, the Message Understanding Conferences (Hobbs and Israel, 1994; Onyshkevych, 1994; Marsh and Perzanowski, 1997)." ></td>
	<td class="line x" title="38:242	One of the recent evaluations, ACE,2 uses pre-defined frames connecting event types (e.g. , arrest, release) to a set of attributes." ></td>
	<td class="line x" title="39:242	The template construction task was not addressed by the participating systems." ></td>
	<td class="line x" title="40:242	The domain templates were created manually by experts to capture the structure of the facts sought." ></td>
	<td class="line x" title="41:242	Although templates have been extensively used in information extraction, there has been little work on their automatic design." ></td>
	<td class="line x" title="42:242	In the Conceptual Case Frame Acquisition project (Riloff and Schmelzenbach, 1998), extraction patterns, a domain semantic lexicon, and a list of conceptual roles and associated semantic categories for the domain are used to produce multiple-slot case frames with selectional restrictions." ></td>
	<td class="line x" title="43:242	The system requires two sets of documents: those relevant to the domain and those irrelevant." ></td>
	<td class="line x" title="44:242	Our approach does not require any domain-specific knowledge and uses only corpus-based statistics." ></td>
	<td class="line x" title="45:242	The GISTexter summarization system (Harabagiu and Maiorano, 2002) used statistics over an arbitrary document collection together with semantic relations from WordNet." ></td>
	<td class="line x" title="46:242	The created templates heavily depend on the topical relations encoded in WordNet." ></td>
	<td class="line x" title="47:242	The template models an input collection of documents." ></td>
	<td class="line x" title="48:242	If there is only one domain instance described in the input than the template is created for this particular instance rather than for a domain." ></td>
	<td class="line x" title="49:242	In our work, we learn domain templates by cross-examining several collections of documents on the same topic, aiming for a general domain template." ></td>
	<td class="line x" title="50:242	We rely on relations cross-mentioned in different instances of the domain to automatically prioritize roles and relationships for selection." ></td>
	<td class="line x" title="51:242	Topic Themes (Harabagiu and Lacatusu, 2005) used for multi-document summarization merge various arguments corresponding to the same se2http://www.nist.gov/speech/tests/ace/index.htm mantic roles for the semantically identical verb phrases (e.g. , arrests and placed under arrest)." ></td>
	<td class="line x" title="52:242	Atomic events also model an input document collection (Filatova and Hatzivassiloglou, 2003) and are created according to the statistics collected for co-occurrences of named entity pairs linked through actions." ></td>
	<td class="line x" title="53:242	GISTexter, atomic events, and Topic Themes were used for modeling a collection of documents rather than a domain." ></td>
	<td class="line x" title="54:242	In other closely related work, Sudo et al.(2003) use frequent dependency subtrees as measured by TF*IDF to identify named entities and IE patterns important for a given domain." ></td>
	<td class="line x" title="56:242	The goal of their work is to show how the techniques improve IE pattern acquisition." ></td>
	<td class="line x" title="57:242	To do this, Sudo et al. constrain the retrieval of relevant documents for a MUC scenario and then use unsupervised learning over descriptions within these documents that match specific types of named entities (e.g. , Arresting Agency, Charge), thus enabling learning of patterns for specific templates (e.g. , the Arrest scenario)." ></td>
	<td class="line x" title="58:242	In contrast, the goal of our work is to show how similar techniques can be used to learn what information is important for a given domain or event and thus, should be included into the domain template." ></td>
	<td class="line x" title="59:242	Our approach allows, for example, learning that an arrest along with other events (e.g. , attack) is often part of a terrorist event." ></td>
	<td class="line x" title="60:242	We do not assume any prior knowledge about domains." ></td>
	<td class="line x" title="61:242	We demonstrate that frequent subtrees can be used not only to extract specific named entities for a given scenario but also to learn domain-important relations." ></td>
	<td class="line x" title="62:242	These relations link domain actions and named entities as well as general nouns and words belonging to other syntactic categories." ></td>
	<td class="line x" title="63:242	Collier (1998) proposed a fully automatic method for creating templates for information extraction." ></td>
	<td class="line x" title="64:242	The method relies on Luhns (1957) idea of locating statistically significant words in a corpus and uses those to locate the sentences in which they occur." ></td>
	<td class="line x" title="65:242	Then it extracts Subject-Verb-Object patterns in those sentences to identify the most important interactions in the input data." ></td>
	<td class="line x" title="66:242	The system was constructed to create MUC templates for terrorist attacks." ></td>
	<td class="line x" title="67:242	Our work also relies on corpus statistics, but we utilize arbitrary syntactic patterns and explicitly use multiple domain instances." ></td>
	<td class="line x" title="68:242	Keeping domain instances separated, we crossexamine them and estimate the importance of a particular information type in the domain." ></td>
	<td class="line x" title="69:242	208 3 Our Approach to Template Creation After reading about presidential elections in different countries on different years, a reader has a general picture of this process." ></td>
	<td class="line x" title="70:242	Later, when reading about a new presidential election, the reader already has in her mind a set of questions for which she expects answers." ></td>
	<td class="line x" title="71:242	This process can be called domain modeling." ></td>
	<td class="line x" title="72:242	The more instances of a particular domain a person has seen, the better understanding she has about what type of information should be expected in an unseen collection of documents discussing a new instance of this domain." ></td>
	<td class="line x" title="73:242	Thus, we propose to use a set of document collections describing different instances within one domain to learn the general characteristics of this domain." ></td>
	<td class="line x" title="74:242	These characteristics can be then used to create a domain template." ></td>
	<td class="line x" title="75:242	We test our system on four domains: airplane crashes, earthquakes, presidential elections, terrorist attacks." ></td>
	<td class="line x" title="76:242	4 Data Description 4.1 Training Data To create training document collections we used BBC Advanced Search3 and submitted queries of the type domain title + country." ></td>
	<td class="line x" title="77:242	For example, presidential election USA." ></td>
	<td class="line x" title="78:242	In addition, we used BBCs Advanced Search date filter to constrain the results to different date periods of interest." ></td>
	<td class="line x" title="79:242	For example, we used known dates of elections and allowed a search for articles published up to five days before or after each such date." ></td>
	<td class="line x" title="80:242	At the same time for the terrorist attacks or earthquakes domain the time constraints we submitted were the day of the event plus ten days." ></td>
	<td class="line x" title="81:242	Thus, we identify several instances for each of our four domains, obtaining a document collection for each instance." ></td>
	<td class="line x" title="82:242	E.g., for the earthquake domain we collected documents on the earthquakes in Afghanistan (March 25, 2002), India (January 26, 2001), Iran (December 26, 2003), Japan (October 26, 2004), and Peru (June 23, 2001)." ></td>
	<td class="line x" title="83:242	Using this procedure we retrieve training document collections for 9 instances of airplane crashes, 5 instances of earthquakes, 13 instances of presidential elections, and 6 instances of terrorist attacks." ></td>
	<td class="line x" title="84:242	4.2 Test Data To test our system, we used document clusters from the Topic Detection and Tracking (TDT) cor3http://news.bbc.co.uk/shared/bsp/search2/ advanced/news_ifs.stm pus (Fiscus et al. , 1999)." ></td>
	<td class="line x" title="85:242	Each TDT topic has a topic label, such as Accidents or Natural Disasters.4 These categories are broader than our domains." ></td>
	<td class="line x" title="86:242	Thus, we manually filtered the TDT topics relevant to our four training domains (e.g. , Accidents matching Airplane Crashes)." ></td>
	<td class="line x" title="87:242	In this way, we obtained TDT document clusters for 2 instances of airplane crashes, 3 instances of earthquakes, 6 instances of presidential elections and 3 instances of terrorist attacks." ></td>
	<td class="line x" title="88:242	The number of the documents corresponding to the instances varies greatly (from two documents for one of the earthquakes up to 156 documents for one of the terrorist attacks)." ></td>
	<td class="line x" title="89:242	This variation in the number of documents per topic is typical for the TDT corpus." ></td>
	<td class="line oc" title="90:242	Many of the current approaches of domain modeling collapse together different instances and make the decision on what information is important for a domain based on this generalized corpus (Collier, 1998; Barzilay and Lee, 2003; Sudo et al. , 2003)." ></td>
	<td class="line x" title="91:242	We, on the other hand, propose to cross-examine these instances keeping them separated." ></td>
	<td class="line x" title="92:242	Our goal is to eliminate dependence on how well the corpus is balanced and to avoid the possibility of greater impact on the domain template of those instances which have more documents." ></td>
	<td class="line x" title="93:242	5 Creating Templates In this work we build domain templates around verbs which are estimated to be important for the domains." ></td>
	<td class="line x" title="94:242	Using verbs as the starting point we identify semantic dependencies within sentences." ></td>
	<td class="line x" title="95:242	In contrast to deep semantic analysis (Fillmore and Baker, 2001; Gildea and Jurafsky, 2002; Pradhan et al. , 2004; Harabagiu and Lacatusu, 2005; Palmer et al. , 2005) we rely only on corpus statistics." ></td>
	<td class="line x" title="96:242	We extract the most frequent syntactic subtrees which connect verbs to the lexemes used in the same subtrees." ></td>
	<td class="line x" title="97:242	These subtrees are used to create domain templates." ></td>
	<td class="line x" title="98:242	For each of the four domains described in Section 4, we automatically create domain templates using the following algorithm." ></td>
	<td class="line x" title="99:242	Step 1: Estimate what verbs are important for the domain under investigation." ></td>
	<td class="line x" title="100:242	We initiate our algorithm by calculating the probabilities for all the verbs in the document collection for one domain  e.g., the collection containing all the instances in the domain of airplane crashes." ></td>
	<td class="line x" title="101:242	We 4In our experiments we analyze TDT topics used in TDT-2 and TDT-4 evaluations." ></td>
	<td class="line x" title="102:242	209 discard those verbs that are stop words (Salton, 1971)." ></td>
	<td class="line x" title="103:242	To take into consideration the distribution of a verb among different instances of the domain, we normalize this probability by its VIF value (verb instance frequency), specifying in how many domain instances this verb appears." ></td>
	<td class="line x" title="104:242	Score(vbi) = countvbisummationtext vbjcomb coll countvbj  VIF(vbi) (1) VIF(vbi) = # of domain instances containing vbi# of all domain instances (2) These verbs are estimated to be the most important for the combined document collection for all the domain instances." ></td>
	<td class="line x" title="105:242	Thus, we build the domain template around these verbs." ></td>
	<td class="line x" title="106:242	Here are the top ten verbs for the terrorist attack domain: killed, told, found, injured, reported, happened, blamed, arrested, died, linked." ></td>
	<td class="line x" title="107:242	Step 2: Parse those sentences which contain the top 50 verbs." ></td>
	<td class="line x" title="108:242	After we identify the 50 most important verbs for the domain under analysis, we parse all the sentences in the domain document collection containing these verbs with the Stanford syntactic parser (Klein and Manning, 2002)." ></td>
	<td class="line x" title="109:242	Step 3: Identify most frequent subtrees containing the top 50 verbs." ></td>
	<td class="line x" title="110:242	A domain template should contain not only the most important actions for the domain, but also the entities that are linked to these actions or to each other through these actions." ></td>
	<td class="line x" title="111:242	The lexemes referring to such entities can potentially be used within the domain template slots." ></td>
	<td class="line x" title="112:242	Thus, we analyze those portions of the syntactic trees which contain the verbs themselves plus other lexemes used in the same subtrees as the verbs." ></td>
	<td class="line x" title="113:242	To do this we use FREQuent Tree miner.5 This software is an implementation of the algorithm presented by (Abe et al. , 2002; Zaki, 2002), which extracts frequent ordered subtrees from a set of ordered trees." ></td>
	<td class="line x" title="114:242	Following (Sudo et al. , 2003) we are interested only in the lexemes which are near neighbors of the most frequent verbs." ></td>
	<td class="line x" title="115:242	Thus, we look only for those subtrees which contain the verbs themselves and from four to ten tree nodes, where a node is either a syntactic tag or a lexeme with its tag." ></td>
	<td class="line x" title="116:242	We analyze not only NPs which correspond to the subject or object of the verb, but other syntactic constituents as well." ></td>
	<td class="line x" title="117:242	For example, PPs can potentially link the verb to locations or dates, and we want to include this information into the template." ></td>
	<td class="line x" title="118:242	Table 1 contains a sample of subtrees for the terrorist attack domain mined from the sentences containing 5http://chasen.org/taku/software/freqt/ nodes subtree 8 (SBAR(S(VP(VBD killed)(NP(QP(IN at))(NNS people))))) 8 (SBAR(S(VP(VBD killed)(NP(QP(JJS least))(NNS people))))) 5 (VP(ADVP)(VBD killed)(NP(NNS people))) 6 (VP(VBD killed)(NP(ADJP(JJ many))(NNS people))) 5 (VP(VP(VBD killed)(NP(NNS people)))) 7 (VP(ADVP(NP))(VBD killed)(NP(CD 34)(NNS people))) 6 (VP(ADVP)(VBD killed)(NP(CD 34)(NNS people))) Table 1: Sample subtrees for the terrorist attack domain." ></td>
	<td class="line x" title="119:242	the verb killed." ></td>
	<td class="line x" title="120:242	The first column of Table 1 shows how many nodes are in the subtree." ></td>
	<td class="line x" title="121:242	Step 4: Substitute named entities with their respective tags." ></td>
	<td class="line x" title="122:242	We are interested in analyzing a whole domain, not just an instance of this domain." ></td>
	<td class="line x" title="123:242	Thus, we substitute all the named entities with their respective tags, and all the exact numbers with the tag NUMBER." ></td>
	<td class="line x" title="124:242	We speculate that subtrees similar to those presented in Table 1 can be extracted from a document collection representing any instance of a terrorist attack, with the only difference being the exact number of causalities." ></td>
	<td class="line x" title="125:242	Later, however, we analyze the domain instances separately to identity information typical for the domain." ></td>
	<td class="line oc" title="126:242	The procedure of substituting named entities with their respective tags previously proved to be useful for various tasks (Barzilay and Lee, 2003; Sudo et al. , 2003; Filatova and Prager, 2005)." ></td>
	<td class="line x" title="127:242	To get named entity tags we used BBNs IdentiFinder (Bikel et al. , 1999)." ></td>
	<td class="line x" title="128:242	Step 5: Merge together the frequent subtrees." ></td>
	<td class="line x" title="129:242	Finally, we merge together those subtrees which are identical according to the information encoded within them." ></td>
	<td class="line x" title="130:242	This is a key step in our algorithm which allows us to bring together subtrees from different instances of the same domain." ></td>
	<td class="line x" title="131:242	For example, the information rendered by all the subtrees from the bottom part of Table 1 is identical." ></td>
	<td class="line x" title="132:242	Thus, these subtrees can be merged into one which contains the longest common pattern: (VBD killed)(NP(NUMBER)(NNS people)) After this merging procedure we keep only those subtrees for which each of the domain instances has at least one of the subtrees from the initial set of subtrees." ></td>
	<td class="line x" title="133:242	This subtree should be used in the instance at least twice." ></td>
	<td class="line x" title="134:242	At this step, we make sure that we keep in the template only the information which is generally important for the domain rather than only for a fraction of instances in this domain." ></td>
	<td class="line x" title="135:242	We also remove all the syntactic tags as we want to make this pattern as general for the domain as possible." ></td>
	<td class="line x" title="136:242	A pattern without syntactic dependencies contains a verb together with a prospective tem210 plate slot corresponding to this verb: killed: (NUMBER) (NNS people) In the above example, the prospective template slots appear after the verb killed." ></td>
	<td class="line x" title="137:242	In other cases the domain slots appear in front of the verb." ></td>
	<td class="line x" title="138:242	Two examples of such slots, for the presidential election and earthquake domains, are shown below: (PERSON) won (NN earthquake) struck The above examples show that it is not enough to analyze only named entities, general nouns contain important information as well." ></td>
	<td class="line x" title="139:242	We term the structure consisting of a verb together with the associated slots a slot structure." ></td>
	<td class="line x" title="140:242	Here is a part of the slot structure we get for the verb killed after crossexamination of the terrorist attack instances: killed (NUMBER) (NNS people) (PERSON) killed (NN suicide) killed Slot structures are similar to verb frames, which are manually created for the PropBank annotation (Palmer et al. , 2005).6 An example of the PropBank frame for the verb to kill is: Roleset kill.01 cause to die: Arg0:killerArg1:corpse Arg2:instrument The difference between the slot structure extracted by our algorithm and the PropBank frame slots is that the frame slots assign a semantic role to each slot, while our algorithm gives either the type of the named entity that should fill in this slot or puts a particular noun into the slot (e.g. , ORGANIZATION, earthquake, people)." ></td>
	<td class="line x" title="141:242	An ideal domain template should include semantic information but this problem is outside of the scope of this paper." ></td>
	<td class="line x" title="142:242	Step 6: Creating domain templates." ></td>
	<td class="line x" title="143:242	After we get all the frequent subtrees containing the top 50 domain verbs, we merge all the subtrees corresponding to the same verb and create a slot structure for every verb as described in Step 5." ></td>
	<td class="line x" title="144:242	The union of such slot structures created for all the important verbs in the domain is called the domain template." ></td>
	<td class="line x" title="145:242	From the created templates we remove the slots which are used in all the domains." ></td>
	<td class="line x" title="146:242	For example, (PERSON) told.a50 The presented algorithm can be used to create a template for any domain." ></td>
	<td class="line x" title="147:242	It does not require predefined domain or world knowledge." ></td>
	<td class="line x" title="148:242	We learn domain templates from cross-examining document collections describing different instances of the domain of interest." ></td>
	<td class="line x" title="149:242	6http://www.cs.rochester.edu/gildea/Verbs/ 6 Evaluation The task we deal with is new and there is no welldefined and standardized evaluation procedure for it." ></td>
	<td class="line x" title="150:242	Sudo et al.(2003) evaluated how well their IE patterns captured named entities of three predefined types." ></td>
	<td class="line x" title="152:242	We are interested in evaluating how well we capture the major actions as well as their constituent parts." ></td>
	<td class="line x" title="153:242	There is no set of domain templates which are built according to a unique set of principles against which we could compare our automatically created templates." ></td>
	<td class="line x" title="154:242	Thus, we need to create a gold standard." ></td>
	<td class="line x" title="155:242	In Section 6.1, we describe how the gold standard is created." ></td>
	<td class="line x" title="156:242	Then, in Section 6.2, we evaluate the quality of the automatically created templates by extracting clauses corresponding to the templates and verifying how many answers from the questions in the gold standard are answered by the extracted clauses." ></td>
	<td class="line x" title="157:242	6.1 Stage 1." ></td>
	<td class="line x" title="158:242	Information Included into Templates: Interannotator Agreement To create a gold standard we asked people to create a list of questions which indicate what is important for the domain description." ></td>
	<td class="line x" title="159:242	Our decision to aim for the lists of questions and not for the templates themselves is based on the following considerations: first, not all of our subjects are familiar with the field of IE and thus, do not necessarily know what an IE template is; second, our goal for this evaluation is to estimate interannotator agreement for capturing the important aspects for the domain and not how well the subjects agree on the template structure." ></td>
	<td class="line x" title="160:242	We asked our subjects to think of their experience of reading newswire articles about various domains.7 Based on what they remember from this experience, we asked them to come up with a list of questions about a particular domain." ></td>
	<td class="line x" title="161:242	We asked them to come up with at most 20 questions covering the information they will be looking for given an unseen news article about a new event in the domain." ></td>
	<td class="line x" title="162:242	We did not give them any input information about the domain but allowed them to use any sources to learn more information about the domain." ></td>
	<td class="line x" title="163:242	We had ten subjects, each of which created one list of questions for one of the four domains under 7We thank Rod Adams, Cosmin-Adrian Bejan, Sasha Blair-Goldensohn, Cyril Cerovic, David Elson, David Evans, Ovidiu Fortu, Agustin Gravano, Lokesh Shresta, John YundtPacheco and Kapil Thadani for the submitted questions." ></td>
	<td class="line x" title="164:242	211 Jaccard metric Domain subj1 and subj1 and subj2 and subj2 (and subj3) MUC MUC Airplane crash 0.54 Earthquake 0.68 Presidential Election 0.32 Terrorist Attack 0.50 0.63 0.59 Table 2: Creating gold standard." ></td>
	<td class="line x" title="165:242	Jaccard metric values for interannotator agreement." ></td>
	<td class="line x" title="166:242	analysis." ></td>
	<td class="line x" title="167:242	Thus, for the earthquake and terrorist attack domains we got two lists of questions; for the airplane crash and presidential election domains we got three lists of questions." ></td>
	<td class="line x" title="168:242	After the questions lists were created we studied the agreement among annotators on what information they consider is important for the domain and thus, should be included in the template." ></td>
	<td class="line x" title="169:242	We matched the questions created by different annotators for the same domain." ></td>
	<td class="line x" title="170:242	For some of the questions we had to make a judgement call on whether it is a match or not." ></td>
	<td class="line x" title="171:242	For example, the following question created by one of the annotators for the earthquake domain was: Did the earthquake occur in a well-known area for earthquakes (e.g. along the San Andreas fault), or in an unexpected location?" ></td>
	<td class="line x" title="172:242	We matched this question to the following three questions created by the other annotator: What is the geological localization?" ></td>
	<td class="line x" title="173:242	Is it near a fault line?" ></td>
	<td class="line x" title="174:242	Is it near volcanoes?" ></td>
	<td class="line x" title="175:242	Usually, the degree of interannotator agreement is estimated using Kappa." ></td>
	<td class="line x" title="176:242	For this task, though, Kappa statistics cannot be used as they require knowledge of the expected or chance agreement, which is not applicable to this task (Fleiss et al. , 1981)." ></td>
	<td class="line x" title="177:242	To measure interannotator agreement we use the Jaccard metric, which does not require knowledge of the expected or chance agreement." ></td>
	<td class="line x" title="178:242	Table 2 shows the values of Jaccard metric for interannotator agreement calculated for all four domains." ></td>
	<td class="line x" title="179:242	Jaccard metric values are calculated as Jaccard(domaind) = |QS d i  QS d j| |QSdi  QSdj| (3) where QSdi and QSdj are the sets of questions created by subjects i and j for domain d. For the airplane crash and presidential election domains we averaged the three pairwise Jaccard metric values." ></td>
	<td class="line x" title="180:242	The scores in Table 2 show that for some domains the agreement is quite high (e.g. , earthquake), while for other domains (e.g. , presidential election) it is twice as low." ></td>
	<td class="line x" title="181:242	This difference in scores can be explained by the complexity of the domains and by the differences in understanding of these domains by different subjects." ></td>
	<td class="line x" title="182:242	The scores for the presidential election domain are predictably low as in different countries the roles of presidents are very different: in some countries the president is the head of the government with a lot of power, while in other countries the president is merely a ceremonial figure." ></td>
	<td class="line x" title="183:242	In some countries the presidents are elected by general voting while in other countries, the presidents are elected by parliaments." ></td>
	<td class="line x" title="184:242	These variations in the domain cause the subjects to be interested in different issues of the domain." ></td>
	<td class="line x" title="185:242	Another issue that might influence the interannotator agreement is the distribution of the presidential election process in time." ></td>
	<td class="line x" title="186:242	For example, one of our subjects was clearly interested in the pre-voting situation, such as debates between the candidates, while another subject was interested only in the outcome of the presidential election." ></td>
	<td class="line x" title="187:242	For the terrorist attack domain we also compared the lists of questions we got from our subjects with the terrorist attack template created by experts for the MUC competition." ></td>
	<td class="line x" title="188:242	In this template we treated every slot as a separate question, excluding the first two slots which captured information about the text from which the template fillers were extracted and not about the domain." ></td>
	<td class="line x" title="189:242	The results for this comparison are included in Table 2." ></td>
	<td class="line x" title="190:242	Differences in domain complexity were studied by IE researchers." ></td>
	<td class="line x" title="191:242	Bagga (1997) suggests a classification methodology to predict the syntactic complexity of the domain-related facts." ></td>
	<td class="line x" title="192:242	Huttunen et al.(2002) analyze how component subevents of the domain are linked together and discuss the factors which contribute to the domain complexity." ></td>
	<td class="line x" title="194:242	6.2 Stage 2." ></td>
	<td class="line x" title="195:242	Quality of the Automatically Created Templates In section 6.1 we showed that not all the domains are equal." ></td>
	<td class="line x" title="196:242	For some of the domains it is much easier to come to a consensus about what slots should be present in the domain template than for others." ></td>
	<td class="line x" title="197:242	In this section we describe the evaluation of the four automatically created templates." ></td>
	<td class="line x" title="198:242	Automatically created templates consist of slot structures and are not easily readable by human annotators." ></td>
	<td class="line x" title="199:242	Thus, instead of direct evaluation of the template quality, we evaluate the clauses extracted according to the created templates and 212 check whether these clauses contain the answers to the questions created by the subjects during the first stage of the evaluation." ></td>
	<td class="line x" title="200:242	We extract the clauses corresponding to the test instances according to the following procedure: 1." ></td>
	<td class="line x" title="201:242	Identify all the simple clauses in the documents corresponding to a particular test instance (respective TDT topic)." ></td>
	<td class="line x" title="202:242	For example, for the sentence Her husband, Robert, survived Thursdays explosion in a Yemeni harbor that killed at least six crew members and injured 35." ></td>
	<td class="line x" title="203:242	only one part is output: that killed at least six crew members and injured 35 2." ></td>
	<td class="line x" title="204:242	For every domain template slot check all the simple clauses in the instance (TDT topic) under analysis." ></td>
	<td class="line x" title="205:242	Find the shortest clause (or sequence of clauses) which includes both the verb and other words extracted for this slot in their respective order." ></td>
	<td class="line x" title="206:242	Add this clause to the list of extracted clauses unless this clause has been already added to this list." ></td>
	<td class="line x" title="207:242	3." ></td>
	<td class="line x" title="208:242	Keep adding clauses to the list of extracted clauses till all the template slots are analyzed or the size of the list exceeds 20 clauses." ></td>
	<td class="line x" title="209:242	The key step in the above algorithm is Step 2." ></td>
	<td class="line x" title="210:242	By choosing the shortest simple clause or sequence of simple clauses corresponding to a particular template slot, we reduce the possibility of adding more information to the output than is necessary to cover each particular slot." ></td>
	<td class="line x" title="211:242	In Step 3 we keep only the first twenty clauses so that the length of the output which potentially contains an answer to the question of interest is not larger than the number of questions provided by each subject." ></td>
	<td class="line x" title="212:242	The templates are created from the slot structures extracted for the top 50 verbs." ></td>
	<td class="line x" title="213:242	The higher the estimated score of the verb (Eq." ></td>
	<td class="line x" title="214:242	1) for the domain the closer to the top of the template the slot structure corresponding to this verb will be." ></td>
	<td class="line x" title="215:242	We assume that the important information is more likely to be covered by the slot structures that are placed near the top of the template." ></td>
	<td class="line x" title="216:242	The evaluation results for the automatically created templates are presented in Figure 1." ></td>
	<td class="line x" title="217:242	We calculate what average percentage of the questions is covered by the outputs created according to the domain templates." ></td>
	<td class="line x" title="218:242	For every domain, we present the percentage of the covered questions separately for each annotator and for the intersection of questions (Section 6.1)." ></td>
	<td class="line x" title="219:242	0." ></td>
	<td class="line x" title="220:242	0 0 %1 0 . 0 0 % 2 0 . 0 0 %3 0 . 0 0 % 4 0 . 0 0 %5 0 . 0 0 % 6 0 . 0 0 %7 0 . 0 0 % 8 0 . 0 0 % A t t a c k E a r t h q u a k e P r e s i d e n t i a le l e c t i o n P l a n e c r a s h I n t e r s e c tS u b j 1S u b j 2 S u b j 3 Figure 1: Evaluation results." ></td>
	<td class="line x" title="221:242	For the questions common for all the annotators we capture about 70% of the answers for three out of four domains." ></td>
	<td class="line x" title="222:242	After studying the results we noticed that for the earthquake domain some questions did not result in a template slot and thus, could not be covered by the extracted clauses." ></td>
	<td class="line x" title="223:242	Here are two of such questions: Is it near a fault line?Is it near volcanoes?" ></td>
	<td class="line x" title="224:242	According to the template creation procedure, which is centered around verbs, the chances that extracted clauses would contain answers to these questions are low." ></td>
	<td class="line x" title="225:242	Indeed, only one of the three sentence sets extracted for the three TDT earthquake topics contain an answer to one of these questions." ></td>
	<td class="line x" title="226:242	Poor results for the presidential election domain could be predicted from the Jaccard metric value for interannotator agreement (Table 2)." ></td>
	<td class="line x" title="227:242	There is considerable discrepancy in the questions created by human annotators which can be attributed to the great variation in the presidential election domain itself." ></td>
	<td class="line x" title="228:242	It must be also noted that most of the questions created for the presidential election domain were clearly referring to the democratic election procedure, while some of the TDT topics categorized as Elections were about either election fraud or about opposition taking over power without the formal resignation of the previous president." ></td>
	<td class="line x" title="229:242	Overall, this evaluation shows that using automatically created domain templates we extract sentences which contain a substantial part of the important information expressed in questions for that domain." ></td>
	<td class="line x" title="230:242	For those domains which have small diversity our coverage can be significantly higher." ></td>
	<td class="line x" title="231:242	7 Conclusions In this paper, we presented a robust method for data-driven discovery of the important fact-types 213 for a given domain." ></td>
	<td class="line x" title="232:242	In contrast to supervised methods, the fact-types are not pre-specified." ></td>
	<td class="line x" title="233:242	The resulting slot structures can subsequently be used to guide the generation of responses to questions about new instances of the same domain." ></td>
	<td class="line x" title="234:242	Our approach features the use of corpus statistics derived from both lexical and syntactic analysis across documents." ></td>
	<td class="line x" title="235:242	A comparison of our system output for four domains of interest shows that our approach can reliably predict the majority of information that humans have indicated are of interest." ></td>
	<td class="line x" title="236:242	Our method is flexible: analyzing document collections from different time periods or locations, we can learn domain descriptions that are tailored to those time periods and locations." ></td>
	<td class="line x" title="237:242	Acknowledgements." ></td>
	<td class="line x" title="238:242	We would like to thank Rebecca Passonneau and Julia Hirschberg for the fruitful discussions at the early stages of this work; Vasilis Vassalos for his suggestions on the evaluation instructions; Michel Galley, Agustin Gravano, Panagiotis Ipeirotis and Kapil Thadani for their enormous help with evaluation." ></td>
	<td class="line x" title="239:242	This material is based upon work supported in part by the Advanced Research Development Agency (ARDA) under Contract No." ></td>
	<td class="line x" title="240:242	NBCHC040040 and in part by the Defense Advanced Research Projects Agency (DARPA) under Contract No." ></td>
	<td class="line x" title="241:242	HR0011-06-C-0023." ></td>
	<td class="line x" title="242:242	Any opinions, findings and conclusions expressed in this material are those of the authors and do not necessarily reflect the views of ARDA and DARPA." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-2070
Stochastic Iterative Alignment For Machine Translation Evaluation
Liu, Ding;Gildea, Daniel;"></td>
	<td class="line x" title="1:155	Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 539546, Sydney, July 2006." ></td>
	<td class="line x" title="2:155	c2006 Association for Computational Linguistics Stochastic Iterative Alignment for Machine Translation Evaluation Ding Liu and Daniel Gildea Department of Computer Science University of Rochester Rochester, NY 14627 Abstract A number of metrics for automatic evaluation of machine translation have been proposed in recent years, with some metrics focusing on measuring the adequacy of MT output, and other metrics focusing on uency." ></td>
	<td class="line x" title="3:155	Adequacy-oriented metrics such as BLEU measure n-gram overlap of MT outputs and their references, but do not represent sentence-level information." ></td>
	<td class="line x" title="4:155	In contrast, uency-oriented metrics such as ROUGE-W compute longest common subsequences, but ignore words not aligned by the LCS." ></td>
	<td class="line x" title="5:155	We propose a metric based on stochastic iterative string alignment (SIA), which aims to combine the strengths of both approaches." ></td>
	<td class="line x" title="6:155	We compare SIA with existing metrics, and nd that it outperforms them in overall evaluation, and works specially well in uency evaluation." ></td>
	<td class="line x" title="7:155	1 Introduction Evaluation has long been a stumbling block in the development of machine translation systems, due to the simple fact that there are many correct translations for a given sentence." ></td>
	<td class="line x" title="8:155	Human evaluation of system output is costly in both time and money, leading to the rise of automatic evaluation metrics in recent years." ></td>
	<td class="line x" title="9:155	In the 2003 Johns Hopkins Workshop on Speech and Language Engineering, experiments on MT evaluation showed that BLEU and NIST do not correlate well with human judgments at the sentence level, even when they correlate well over large test sets (Blatz et al. , 2003)." ></td>
	<td class="line x" title="10:155	Liu and Gildea (2005) also pointed out that due to the limited references for every MT output, using the overlapping ratio of n-grams longer than 2 did not improve sentence level evaluation performance of BLEU." ></td>
	<td class="line x" title="11:155	The problem leads to an even worse result in BLEUS uency evaluation, which is supposed to rely on the long ngrams." ></td>
	<td class="line x" title="12:155	In order to improve sentence-level evaluation performance, several metrics have been proposed, including ROUGE-W, ROUGE-S (Lin and Och, 2004) and METEOR (Banerjee and Lavie, 2005)." ></td>
	<td class="line x" title="13:155	ROUGE-W differs from BLEU and NIST in that it doesnt require the common sequence between MT output and the references to be consecutive, and thus longer common sequences can be found." ></td>
	<td class="line x" title="14:155	There is a problem with loose-sequencebased metrics: the words outside the longest common sequence are not considered in the metric, even if they appear both in MT output and the reference." ></td>
	<td class="line x" title="15:155	ROUGE-S is meant to alleviate this problem by computing the common skipped bigrams instead of the LCS." ></td>
	<td class="line x" title="16:155	But the price ROUGES pays is falling back to the shorter sequences and losing the advantage of long common sequences." ></td>
	<td class="line x" title="17:155	METEOR is essentially a unigram based metric, which prefers the monotonic word alignment between MT output and the references by penalizing crossing word alignments." ></td>
	<td class="line x" title="18:155	There are two problems with METEOR." ></td>
	<td class="line x" title="19:155	First, it doesnt consider gaps in the aligned words, which is an important feature for evaluating the sentence uency; second, it cannot use multiple references simultaneously.1 ROUGE and METEOR both use WordNet and Porter Stemmer to increase the chance of the MT output words matching the reference words." ></td>
	<td class="line x" title="20:155	Such morphological processing and synonym extraction tools are available for English, but are not always available for other languages." ></td>
	<td class="line x" title="21:155	In order to take advantage of loose-sequence-based metrics and avoid the problems in ROUGE and METEOR, we propose a new metric SIA, which is based on loose sequence alignment but enhanced with the following features: 1METEOR and ROUGE both compute the score based on the best reference 539  Computing the string alignment score based on the gaps in the common sequence." ></td>
	<td class="line x" title="22:155	Though ROUGE-W also takes into consider the gaps in the common sequence between the MT output and the reference by giving more credits to the n-grams in the common sequence, our method is more exible in that not only do the strict n-grams get more credits, but also the tighter sequences." ></td>
	<td class="line x" title="23:155	 Stochastic word matching." ></td>
	<td class="line x" title="24:155	For the purpose of increasing hitting chance of MT outputs in references, we use a stochastic word matching in the string alignment instead of WORDSTEM and WORD-NET used in METEOR and ROUGE." ></td>
	<td class="line x" title="25:155	Instead of using exact matching, we use a soft matching based on the similarity between two words, which is trained in a bilingual corpus." ></td>
	<td class="line x" title="26:155	The corpus is aligned in the word level using IBM Model4 (Brown et al. , 1993)." ></td>
	<td class="line x" title="27:155	Stochastic word matching is a uniform replacement for both morphological processing and synonym matching." ></td>
	<td class="line x" title="28:155	More importantly, it can be easily adapted for different kinds of languages, as long as there are bilingual parallel corpora available (which is always true for statistical machine translation)." ></td>
	<td class="line x" title="29:155	 Iterative alignment scheme." ></td>
	<td class="line x" title="30:155	In this scheme, the string alignment will be continued until there are no more co-occuring words to be found between the MT output and any one of the references." ></td>
	<td class="line x" title="31:155	In this way, every co-occuring word between the MT output and the references can be considered and contribute to the nal score, and multiple references can be used simultaneously." ></td>
	<td class="line x" title="32:155	The remainder of the paper is organized as follows: section 2 gives a recap of BLEU, ROUGEW and METEOR; section 3 describes the three components of SIA; section 4 compares the performance of different metrics based on experimental results; section 5 presents our conclusion." ></td>
	<td class="line x" title="33:155	2 Recap of BLEU, ROUGE-W and METEOR The most commonly used automatic evaluation metrics, BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002), are based on the assumption that The closer a machine translation is to a promt1: Life is like one nice chocolate in box ref: Life is just like a box of tasty chocolate ref: Life is just like a box of tasty chocolate mt2: Life is of one nice chocolate in box Figure 1: Alignment Example for ROUGE-W fessional human translation, the better it is (Papineni et al. , 2002)." ></td>
	<td class="line x" title="34:155	For every hypothesis, BLEU computes the fraction of n-grams which also appear in the reference sentences, as well as a brevity penalty." ></td>
	<td class="line x" title="35:155	NIST uses a similar strategy to BLEU but further considers that n-grams with different frequency should be treated differently in the evaluation (Doddington, 2002)." ></td>
	<td class="line x" title="36:155	BLEU and NIST have been shown to correlate closely with human judgments in ranking MT systems with different qualities (Papineni et al. , 2002; Doddington, 2002)." ></td>
	<td class="line x" title="37:155	ROUGE-W is based on the weighted longest common subsequence (LCS) between the MT output and the reference." ></td>
	<td class="line x" title="38:155	The common subsequences in ROUGE-W are not necessarily strict n-grams, and gaps are allowed in both the MT output and the reference." ></td>
	<td class="line x" title="39:155	Because of the exibility, long common subsequences are feasible in ROUGEW and can help to re ect the sentence-wide similarity of MT output and references." ></td>
	<td class="line x" title="40:155	ROUGE-W uses a weighting strategy where the LCS containing strict n-grams is favored." ></td>
	<td class="line x" title="41:155	Figure 1 gives two examples that show how ROUGE-W searches for the LCS." ></td>
	<td class="line x" title="42:155	For mt1, ROUGE-W will choose either life is like chocolate or life is like box as the LCS, since neither of the sequences like box and like chocolate are strict n-grams and thus make no difference in ROUGE-W (the only strict n-grams in the two candidate LCS is life is)." ></td>
	<td class="line x" title="43:155	For mt2, there is only one choice of the LCS: life is of chocolate." ></td>
	<td class="line x" title="44:155	The LCS of mt1 and mt2 have the same length and the same number of strict n-grams, thus they get the same score in ROUGE-W." ></td>
	<td class="line x" title="45:155	But it is clear to us that mt1 is better than mt2." ></td>
	<td class="line x" title="46:155	It is easy to verify that mt1 and mt2 have the same number of common 1grams, 2-grams, and skipped 2-grams with the reference (they dont have common n-grams longer than 2 words), thus BLEU and ROUGE-S are also not able to differentiate them." ></td>
	<td class="line x" title="47:155	METEOR is a metric sitting in the middle of the n-gram based metrics and the loose se540 mt1: Life is like one nice chocolate in box ref: Life is just like a box of tasty chocolate ref: Life is just like a box of tasty chocolate mt2: Life is of one nice chocolate in box Figure 2: Alignment Example for METEOR quence based metrics." ></td>
	<td class="line x" title="48:155	It has several phases and in each phase different matching techniques (EXACT, PORTER-STEM, WORD-NET) are used to make an alignment for the MT output and the reference." ></td>
	<td class="line x" title="49:155	METEOR doesnt require the alignment to be monotonic, which means crossing word mappings (e.g. a b is mapped to b a) are allowed, though doing so will get a penalty." ></td>
	<td class="line x" title="50:155	Figure 2 shows the alignments of METEOR based on the same example as ROUGE." ></td>
	<td class="line x" title="51:155	Though the two alignments have the same number of word mappings, mt2 gets more crossed word mappings than mt1, thus it will get less credits in METEOR." ></td>
	<td class="line x" title="52:155	Both ROUGE and METEOR normalize their evaluation result based on the MT output length (precision) and the reference length (recall), and the nal score is computed as the F-mean of them." ></td>
	<td class="line x" title="53:155	3 Stochastic Iterative Alignment (SIA) for Machine Translation Evaluation We introduce three techniques to allow more sensitive scores to be computed." ></td>
	<td class="line x" title="54:155	3.1 Modified String Alignment This section introduces how to compute the string alignment based on the word gaps." ></td>
	<td class="line x" title="55:155	Given a pair of strings, the task of string alignment is to obtain the longest monotonic common sequence (where gaps are allowed)." ></td>
	<td class="line x" title="56:155	SIA uses a different weighting strategy from ROUGE-W, which is more exible." ></td>
	<td class="line x" title="57:155	In SIA, the alignments are evaluated based on the geometric mean of the gaps in the reference side and the MT output side." ></td>
	<td class="line x" title="58:155	Thus in the dynamic programming, the state not only includes the current covering length of the MT output and the reference, but also includes the last aligned positions in them." ></td>
	<td class="line x" title="59:155	The algorithm for computing the alignment score in SIA is described in Figure 3." ></td>
	<td class="line x" title="60:155	The subroutine COMPUTE SCORE, which computes the score gained from the current aligned positions, is shown in Figure 4." ></td>
	<td class="line x" title="61:155	From the algorithm, we can function GET ALIGN SCORE(mt, M, ref, N) triangleright Compute the alignment score of the MT output mt with length M and the reference ref with length N for i = 1; i  M; i = i +1 do for j = 1; j  N; j = j +1 do for k = 1; k  i; k = k +1 do for m = 1; m  j; m = m +1 do scorei,j,k,m = maxscorei1,j,k,m,scorei,j1,k,m } ; end for end for scorei,j,i,j = max n=1,M;p=1,N {scorei,j,i,j, scorei1,j1,n,p + COMPUTE SCORE(mt,ref, i, j, n, p)}; end for end for return scoreM,N,M,NM ; end function Figure 3: Alignment Algorithm Based on Gaps function COMPUTE SCORE(mt, ref, i, j, n, p) if mt[i] == ref [j] then return 1/p(i  n)  (j  p); else return 0; end if end function Figure 4: Compute Word Matching Score Based on Gaps see that not only will strict n-grams get higher scores than non-consecutive sequences, but also the non-consecutive sequences with smaller gaps will get higher scores than those with larger gaps." ></td>
	<td class="line x" title="62:155	This weighting method can help SIA capture more subtle difference of MT outputs than ROUGE-W does." ></td>
	<td class="line x" title="63:155	For example, if SIA is used to align mt1 and ref in Figure 1, it will choose life is like box instead of life is like chocolate, because the average distance of box-box to its previous mapping like-like is less than chocolate-chocolate." ></td>
	<td class="line x" title="64:155	Then the score SIA assigns to mt1 is: parenleftbigg 1 1  1 + 1 1  1 + 1 1  2 + 1 2  5 parenrightbigg 18 = 0.399 (1) For mt2, there is only one possible alignment, its score in SIA is computed as: parenleftbigg 1 1  1 + 1 1  1 + 1 1  5 + 1 2  3 parenrightbigg 18 = 0.357 (2) Thus, mt1 will be considered better than mt2 in SIA, which is reasonable." ></td>
	<td class="line x" title="65:155	As mentioned in section 1, though loose-sequence-based metrics give a better re ection of the sentence-wide similarity of the MT output and the reference, they cannot 541 make full use of word-level information." ></td>
	<td class="line x" title="66:155	This defect could potentially lead to a poor performance in adequacy evaluation, considering the case that the ignored words are crucial to the evaluation." ></td>
	<td class="line x" title="67:155	In the later part of this section, we will describe an iterative alignment scheme which is meant to compensate for this defect." ></td>
	<td class="line x" title="68:155	3.2 Stochastic Word Mapping In ROUGE and METEOR, PORTER-STEM and WORD-NET are used to increase the chance of the MT output words matching the references." ></td>
	<td class="line x" title="69:155	We use a different stochastic approach in SIA to achieve the same purpose." ></td>
	<td class="line x" title="70:155	The string alignment has a good dynamic framework which allows the stochastic word matching to be easily incorporated into it." ></td>
	<td class="line x" title="71:155	The stochastic string alignment can be implemented by simply replacing the function COMPUTE SCORE with the function of Figure 5." ></td>
	<td class="line x" title="72:155	The function similarity(word1, word2) returns a ratio which re ects how similar the two words are." ></td>
	<td class="line x" title="73:155	Now we consider how to compute the similarity ratio of two words." ></td>
	<td class="line x" title="74:155	Our method is motivated by the phrase extraction method of Bannard and Callison-Burch (2005), which computes the similarity ratio of two words by looking at their relationship with words in another language." ></td>
	<td class="line x" title="75:155	Given a bilingual parallel corpus with aligned sentences, say English and French, the probability of an English word given a French word can be computed by training word alignment models such as IBM Model4." ></td>
	<td class="line x" title="76:155	Then for every English word e, we have a set of conditional probabilities given each French word: p(e|f1), p(e|f2), , p(e|fN)." ></td>
	<td class="line nc" title="77:155	If we consider these probabilities as a vector, the similarities of two English words can be obtained by computing the dot product of their corresponding vectors.2 The formula is described below: similarity(ei, ej) = Nsummationdisplay k=1 p(ei|fk)p(ej|fk) (3) Paraphrasing methods based on monolingual parallel corpora such as (Pang et al. , 2003; Barzilay and Lee, 2003) can also be used to compute the similarity ratio of two words, but they dont have as rich training resources as the bilingual methods do." ></td>
	<td class="line x" title="78:155	2Although the marginalized probability (over all French words) of an English word given the other English word (PNk=1 p(ei|fk)p(fk|ej)) is a more intuitive way of measuring the similarity, the dot product of the vectors p(e|f) described above performed slightly better in our experiments." ></td>
	<td class="line x" title="79:155	function STO COMPUTE SCORE(mt, ref, i, j, n, p) if mt[i] == ref [j] then return 1/p(i  n)  (j  p); else return similarity(mt[i],ref [i])(in)(jp) ; end if end function Figure 5: Compute Stochastic Word Matching Score 3.3 Iterative Alignment Scheme ROUGE-W, METEOR, and WER all score MT output by rst computing a score based on each available reference, and then taking the highest score as the nal score for the MT output." ></td>
	<td class="line x" title="80:155	This scheme has the problem of not being able to use multiple references simultaneously." ></td>
	<td class="line x" title="81:155	The iterative alignment scheme proposed here is meant to alleviate this problem, by doing alignment between the MT output and one of the available references until no more words in the MT output can be found in the references." ></td>
	<td class="line x" title="82:155	In each alignment round, the score based on each reference is computed and the highest one is taken as the score for the round." ></td>
	<td class="line x" title="83:155	Then the words which have been aligned in best alignment will not be considered in the next round." ></td>
	<td class="line x" title="84:155	With the same number of aligned words, the MT output with fewer alignment rounds should be considered better than those requiring more rounds." ></td>
	<td class="line x" title="85:155	For this reason, a decay factor  is multiplied with the scores of each round." ></td>
	<td class="line x" title="86:155	The nal score of the MT output is then computed by summing the weighted scores of each alignment round." ></td>
	<td class="line x" title="87:155	The scheme is described in Figure 6." ></td>
	<td class="line x" title="88:155	The function GET ALIGN SCORE 1 used in GET ALIGN SCORE IN MULTIPLE REFS is slightly different from GET ALIGN SCORE described in the prior subsection." ></td>
	<td class="line x" title="89:155	The dynamic programming algorithm for getting the best alignment is the same, except that it has two more tables as input, which record the unavailable positions in the MT output and the reference." ></td>
	<td class="line x" title="90:155	These positions have already been used in the prior best alignments and should not be considered in the ongoing alignment." ></td>
	<td class="line x" title="91:155	It also returns the aligned positions of the best alignment." ></td>
	<td class="line x" title="92:155	The pseudocode for GET ALIGN SCORE 1 is shown in Figure 7." ></td>
	<td class="line x" title="93:155	The computation of the length penalty is similar to BLEU: it is set to 1 if length of the MT output is longer than the arithmetic mean of length of the 542 function GET ALIGN SCORE IN MULTIPLE REFS(mt, ref 1,  , ref N, ) triangleright Iteratively Compute the Alignment Score Based on Multiple References and the Decay Factor  final score = 0; while max score != 0 do for i = 1,  , N do (score, align) = GET ALIGN SCORE 1(mt, ref i, mt table, ref tablei); if score > max score then max score = score; max align = align; max ref = i; end if end for final score += max score ;   = ; Add the words in align to mt table and ref tablemax ref ; end while return final score length penalty; end function Figure 6: Iterative Alignment Scheme references, and otherwise is set to the ratio of the two." ></td>
	<td class="line x" title="94:155	Figure 8 shows how the iterative alignment scheme works with an evaluation set containing one MT output and two references." ></td>
	<td class="line x" title="95:155	The selected alignment in each round is shown, as well as the unavailable positions in MT output and references." ></td>
	<td class="line x" title="96:155	With the iterative scheme, every common word between the MT output and the reference set can make a contribution to the metric, and by such means SIA is able to make full use of the word-level information." ></td>
	<td class="line x" title="97:155	Furthermore, the order (alignment round) in which the words are aligned provides a way to weight them." ></td>
	<td class="line x" title="98:155	In BLEU, multiple references can be used simultaneously, but the common n-grams are treated equally." ></td>
	<td class="line x" title="99:155	4 Experiments Evaluation experiments were conducted to compare the performance of different metrics including BLEU, ROUGE, METEOR and SIA.3 The test data for the experiments are from the MT evaluation workshop at ACL05." ></td>
	<td class="line x" title="100:155	There are seven sets of MT outputs (E09 E11 E12 E14 E15 E17 E22), all of which contain 919 English sentences." ></td>
	<td class="line x" title="101:155	These sentences are the translation of the same Chinese input generated by seven different MT systems." ></td>
	<td class="line x" title="102:155	The uency and adequacy of each sentence are manually ranked from 1 to 5." ></td>
	<td class="line x" title="103:155	For each MT output, there are two sets of human scores available, and 3METEOR and ROUGE can be downloaded at http://www.cs.cmu.edu/ alavie/METEOR and http://www.isi.edu/licensed-sw/see/rouge function GET ALIGN SCORE1(mt, ref, mttable, reftable) triangleright Compute the alignment score of the MT output mt with length M and the reference ref with length N, without considering the positions in mttable and reftable M = |mt|; N = |ref|; for i = 1; i  M; i = i +1 do for j = 1; j  N; j = j +1 do for k = 1; k  i; k = k +1 do for m = 1; m  j; m = m +1 do scorei,j,k,m = maxscorei1,j,k,m, scorei,j1,k,m}; end for end for if i is not in mttable and j is not in reftable then scorei,j,i,j = max n=1,M;p=1,N {scorei,j,i,j, scorei1,j1,n,p + COMPUTE SCORE(mt, ref, i, j, n, p)}; end if end for end for return scoreM,N,M,NM and the corresponding alignment; end function Figure 7: Alignment Algorithm Based on Gaps Without Considering Aligned Positions m: England with France discussed this crisis in London r1: Britain and France consulted about this crisis in London with each other r2: England and France discussed the crisis in London m: England with France discussed this crisis in London r2: England and France discussed the crisis in London r1: Britain and France consulted about this crisis in London with each other m: England with France discussed this crisis in London r1: Britain and France consulted about this crisis in London with each other r2: England and France discussed the crisis in London Figure 8: Alignment Example for SIA 543 we randomly choose one as the score used in the experiments." ></td>
	<td class="line x" title="104:155	The human overall scores are calculated as the arithmetic means of the human uency scores and adequacy scores." ></td>
	<td class="line x" title="105:155	There are four sets of human translations (E01, E02, E03, E04) serving as references for those MT outputs." ></td>
	<td class="line x" title="106:155	The MT outputs and reference sentences are transformed to lower case." ></td>
	<td class="line x" title="107:155	Our experiments are carried out as follows: automatic metrics are used to evaluate the MT outputs based on the four sets of references, and the Pearsons correlation coef cient of the automatic scores and the human scores is computed to see how well they agree." ></td>
	<td class="line x" title="108:155	4.1 N-gram vs. Loose Sequence One of the problems addressed in this paper is the different performance of n-gram based metrics and loose-sequence-based metrics in sentencelevel evaluation." ></td>
	<td class="line x" title="109:155	To see how they really differ in experiments, we choose BLEU and ROUGEW as the representative metrics for the two types, and used them to evaluate the 6433 sentences in the 7 MT outputs." ></td>
	<td class="line x" title="110:155	The Pearson correlation coef cients are then computed based on the 6433 samples." ></td>
	<td class="line x" title="111:155	The experimental results are shown in Table 1." ></td>
	<td class="line x" title="112:155	BLEU-n denotes the BLEU metric with the longest n-gram of length n. F denotes uency, A denotes adequacy, and O denotes overall." ></td>
	<td class="line x" title="113:155	We see that with the increase of n-gram length, BLEUs performance does not increase monotonically." ></td>
	<td class="line x" title="114:155	The best result in adequacy evaluation is achieved at 2-gram and the best result in uency is achieved at 4-gram." ></td>
	<td class="line x" title="115:155	Using n-grams longer than 2 doesnt buy much improvement for BLEU in uency evaluation, and does not compensate for the loss in adequacy evaluation." ></td>
	<td class="line x" title="116:155	This con rms Liu and Gildea (2005)s nding that in sentence level evaluation, long n-grams in BLEU are not bene cial." ></td>
	<td class="line x" title="117:155	The loose-sequence-based ROUGE-W does much better than BLEU in uency evaluation, but it does poorly in adequacy evaluation and doesnt achieve a signi cant improvement in overall evaluation." ></td>
	<td class="line x" title="118:155	We speculate that the reason is that ROUGE-W doesnt make full use of the available word-level information." ></td>
	<td class="line x" title="119:155	4.2 METEOR vs. SIA SIA is designed to take the advantage of loosesequence-based metrics without losing word-level information." ></td>
	<td class="line x" title="120:155	To see how well it works, we choose E09 as the development set and the sentences in the other 6 sets as the test data." ></td>
	<td class="line x" title="121:155	The decay facB-3 R 1 R 2 M S F 0.167 0.152 0.192 0.167 0.202 A 0.306 0.304 0.287 0.332 0.322 O 0.265 0.256 0.266 0.280 0.292 Table 2: Sentence level evaluation results of BLEU, ROUGE, METEOR and SIA tor in SIA is determined by optimizing the overall evaluation for E09, and then used with SIA to evaluate the other 5514 sentences based on the four sets of references." ></td>
	<td class="line x" title="122:155	The similarity of English words is computed by training IBM Model 4 in an English-French parallel corpus which contains seven hundred thousand sentence pairs." ></td>
	<td class="line x" title="123:155	For every English word, only the entries of the top 100 most similar English words are kept and the similarity ratios of them are then re-normalized." ></td>
	<td class="line x" title="124:155	The words outside the training corpus will be considered as only having itself as its similar word." ></td>
	<td class="line x" title="125:155	To compare the performance of SIA with BLEU, ROUGE and METEOR, the evaluation results based on the same testing data is given in Table 2." ></td>
	<td class="line x" title="126:155	B3 denotes BLEU-3; R 1 denotes the skipped bigram based ROUGE metric which considers all skip distances and uses PORTER-STEM; R 2 denotes ROUGE-W with PORTER-STEM; M denotes the METEOR metric using PORTER-STEM and WORD-NET synonym; S denotes SIA." ></td>
	<td class="line x" title="127:155	We see that METEOR, as the other metric sitting in the middle of n-gram based metrics and loose sequence metrics, achieves improvement over BLEU in both adequacy and uency evaluation." ></td>
	<td class="line x" title="128:155	Though METEOR gets the best results in adequacy evaluation, in uency evaluation, it is worse than the loose-sequence-based metric ROUGE-W-STEM." ></td>
	<td class="line x" title="129:155	SIA is the only one among the 5 metrics which does well in both uency and adequacy evaluation." ></td>
	<td class="line x" title="130:155	It achieves the best results in uency evaluation and comparable results to METEOR in adequacy evaluation, and the balanced performance leads to the best overall evaluation results in the experiment." ></td>
	<td class="line x" title="131:155	To estimate the significance of the correlations, bootstrap resampling (Koehn, 2004) is used to randomly select 5514 sentences with replacement out of the whole test set of 5514 sentences, and then the correlation coef cients are computed based on the selected sentence set." ></td>
	<td class="line x" title="132:155	The resampling is repeated 5000 times, and the 95% con dence intervals are shown in Tables 3, 4, and 5." ></td>
	<td class="line x" title="133:155	We can see that it is very dif 544 BLEU-1 BLEU-2 BLEU-3 BLEU-4 BLEU-5 BLEU-6 ROUGE-W F 0.147 0.162 0.166 0.168 0.165 0.164 0.191 A 0.288 0.296 0.291 0.285 0.279 0.274 0.268 O 0.243 0.256 0.255 0.251 0.247 0.244 0.254 Table 1: Sentence level evaluation results of BLEU and ROUGE-W low mean high B-3 (-16.6%) 0.138 0.165 0.192 (+16.4%) R 1 (-17.8%) 0.124 0.151 0.177 (+17.3%) R 2 (-14.3%) 0.164 0.191 0.218 (+14.2%) M (-15.8%) 0.139 0.166 0.191 (+15.5%) S (-13.3%) 0.174 0.201 0.227 (+13.3%) Table 3: 95% signi cance intervals for sentencelevel uency evaluation low mean high B-3 (-08.2%) 0.280 0.306 0.330 (+08.1%) R 1 (-08.5%) 0.278 0.304 0.329 (+08.4%) R 2 (-09.2%) 0.259 0.285 0.312 (+09.5%) M (-07.3%) 0.307 0.332 0.355 (+07.0%) S (-07.9%) 0.295 0.321 0.346 (+07.8%) Table 4: 95% signi cance intervals for sentencelevel adequacy evaluation cult for one metric to signi cantly outperform another metric in sentence-level evaluation." ></td>
	<td class="line x" title="134:155	The results show that the mean of the correlation factors converges right to the value we computed based on the whole testing set, and the con dence intervals correlate with the means." ></td>
	<td class="line x" title="135:155	While sentence-level evaluation is useful if we are interested in a con dence measure on MT outputs, syste-x level evaluation is more useful for comparing MT systems and guiding their development." ></td>
	<td class="line x" title="136:155	Thus we also present the evaluation results based on the 7 MT output sets in Table 6." ></td>
	<td class="line x" title="137:155	SIA uses the same decay factor as in the sentence-level evaluation." ></td>
	<td class="line x" title="138:155	Its system-level score is computed as the arithmetic mean of the sentence level scores, and low mean high B-3 (-09.8%) 0.238 0.264 0.290 (+09.9%) R 1 (-10.2%) 0.229 0.255 0.281 (+10.0%) R 2 (-10.0%) 0.238 0.265 0.293 (+10.4%) M (-09.0%) 0.254 0.279 0.304 (+08.8%) S (-08.7%) 0.265 0.291 0.316 (+08.8%) Table 5: 95% signi cance intervals for sentencelevel overall evaluation WLS WLS WLS WLS PROB INCS PROB INCS F 0.189 0.202 0.188 0.202 A 0.295 0.310 0.311 0.322 O 0.270 0.285 0.278 0.292 Table 7: Results of different components in SIA WLS WLS WLS WLS INCS INCS INCS INCS STEM WN STEM WN F 0.188 0.188 0.187 0.191 A 0.311 0.313 0.310 0.317 O 0.278 0.280 0.277 0.284 Table 8: Results of SIA working with Porter-Stem and WordNet so are ROUGE, METEOR and the human judgments." ></td>
	<td class="line x" title="139:155	We can see that SIA achieves the best performance in both uency and adequacy evaluation of the 7 systems." ></td>
	<td class="line x" title="140:155	Though the 7-sample based results are not reliable, we can get a sense of how well SIA works in the system-level evaluation." ></td>
	<td class="line x" title="141:155	4.3 Components in SIA To see how the three components in SIA contribute to the nal performance, we conduct experiments where one or two components are removed in SIA, shown in Table 7." ></td>
	<td class="line x" title="142:155	The three components are denoted as WLS (weighted loose sequence alignment), PROB (stochastic word matching), and INCS (iterative alignment scheme) respectively." ></td>
	<td class="line x" title="143:155	WLS without INCS does only one round of alignment and chooses the best alignment score as the nal score." ></td>
	<td class="line x" title="144:155	This scheme is similar to ROUGE-W and METEOR." ></td>
	<td class="line x" title="145:155	We can see that INCS, as expected, improves the adequacy evaluation without hurting the uency evaluation." ></td>
	<td class="line x" title="146:155	PROB improves both adequacy and uency evaluation performance." ></td>
	<td class="line x" title="147:155	The result that SIA works with PORTER-STEM and WordNet is also shown in Table 8." ></td>
	<td class="line x" title="148:155	When PORTER-STEM and WordNet are 545 B-6 R 1 R 2 M S F 0.514 0.466 0.458 0.378 0.532 A 0.876 0.900 0.906 0.875 0.928 O 0.794 0.790 0.792 0.741 0.835 Table 6: Results of BLEU, ROUGE, METEOR and SIA in system level evaluation both used, PORTER-STEM is used rst." ></td>
	<td class="line x" title="149:155	We can see that they are not as good as using the stochastic word matching." ></td>
	<td class="line x" title="150:155	Since INCS and PROB are independent of WLS, we believe they can also be used to improve other metrics such as ROUGE-W and METEOR." ></td>
	<td class="line x" title="151:155	5 Conclusion This paper describes a new metric SIA for MT evaluation, which achieves good performance by combining the advantages of n-gram-based metrics and loose-sequence-based metrics." ></td>
	<td class="line x" title="152:155	SIA uses stochastic word mapping to allow soft or partial matches between the MT hypotheses and the references." ></td>
	<td class="line x" title="153:155	This stochastic component is shown to be better than PORTER-STEM and WordNet in our experiments." ></td>
	<td class="line x" title="154:155	We also analyzed the effect of other components in SIA and speculate that they can also be used in other metrics to improve their performance." ></td>
	<td class="line x" title="155:155	Acknowledgments This work was supported by NSF ITR IIS-09325646 and NSF ITR IIS0428020." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-2096
Adding Syntax To Dynamic Programming For Aligning Comparable Texts For The Generation Of Paraphrases
Shen, Siwei;Radev, Dragomir R.;Patel, Agam;Erkan, Gunes;"></td>
	<td class="line x" title="1:213	Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 747754, Sydney, July 2006." ></td>
	<td class="line x" title="2:213	c2006 Association for Computational Linguistics Adding Syntax to Dynamic Programming for Aligning Comparable Texts for the Generation of Paraphrases Siwei Shen1, Dragomir R. Radev1;2, Agam Patel1, Gunes Erkan1 Department of Electrical Engineering and Computer Science School of Information University of Michigan Ann Arbor, MI 48109 fshens, radev, agamrp, gerkang@umich.edu Abstract Multiple sequence alignment techniques have recently gained popularity in the Natural Language community, especially for tasks such as machine translation, text generation, and paraphrase identification." ></td>
	<td class="line x" title="3:213	Prior work falls into two categories, depending on the type of input used: (a) parallel corpora (e.g. , multiple translations of the same text) or (b) comparable texts (non-parallel but on the same topic)." ></td>
	<td class="line x" title="4:213	So far, only techniques based on parallel texts have successfully used syntactic information to guide alignments." ></td>
	<td class="line x" title="5:213	In this paper, we describe an algorithm for incorporating syntactic features in the alignment process for non-parallel texts with the goal of generating novel paraphrases of existing texts." ></td>
	<td class="line x" title="6:213	Our method uses dynamic programming with alignment decision based on the local syntactic similarity between two sentences." ></td>
	<td class="line x" title="7:213	Our results show that syntactic alignment outrivals syntax-free methods by 20% in both grammaticality and fidelity when computed over the novel sentences generated by alignment-induced finite state automata." ></td>
	<td class="line x" title="8:213	1 Introduction In real life, we often encounter comparable texts such as news on the same events reported by different sources and papers on the same topic authored by different people." ></td>
	<td class="line x" title="9:213	It is useful to recognize if one text cites another in cases like news sharing among media agencies or citations in academic work." ></td>
	<td class="line x" title="10:213	Applications of such recognition include machine translation, text generation, paraphrase identification, and question answering, all of which have recently drawn the attention of a number of researchers in natural language processing community." ></td>
	<td class="line x" title="11:213	Multiple sequence alignment (MSA) is the basis for accomplishing these tasks." ></td>
	<td class="line oc" title="12:213	Previous work aligns a group of sentences into a compact word lattice (Barzilay and Lee, 2003), a finite state automaton representation that can be used to identify commonality or variability among comparable texts and generate paraphrases." ></td>
	<td class="line n" title="13:213	Nevertheless, this approach has a drawback of over-generating ungrammatical sentences due to its almost-free alignment." ></td>
	<td class="line x" title="14:213	Pang et al. provide a remedy to this problem by performing alignment on the Charniak parse trees of the clustered sentences (Pang et al. , 2003)." ></td>
	<td class="line x" title="15:213	Although it is so far the most similar work to ours, Pangs solution assumes the input sentences to be semantically equivalent." ></td>
	<td class="line x" title="16:213	Two other important references for string-based alignments algorithms, mostly with applications in Biology, are (Gusfield, 1997) and (Durbin et al. , 1998)." ></td>
	<td class="line o" title="17:213	In our approach, we work on comparable texts (not necessarily equivalent in their semantic meanings) as Barzilay and Lee did." ></td>
	<td class="line o" title="18:213	However, we use local syntactic similarity (as opposed to lexical similarity) in doing the alignment on the raw sentences instead of on their parse trees." ></td>
	<td class="line n" title="19:213	Because of the semantic discrepancies among the inputs, applying syntactic features in the alignment has a larger impact on the grammaticality and fidelity of the generated unseen sentences." ></td>
	<td class="line o" title="20:213	While previous work positions the primary focus on the quality of paraphrases and/or translations, we are more interested in the relation between the use of syntactic features and the correctness of the sentences being generated, including those that are not paraphrases of the original input." ></td>
	<td class="line x" title="21:213	Figure 1 illustrates the difference between alignment based solely on lexical similarity and alignment with consideration of syntactic features." ></td>
	<td class="line x" title="22:213	Ignoring syntax, the word Milan in both sentences is aligned." ></td>
	<td class="line x" title="23:213	But it would unfortunately generate an ungrammatical sentence I went to Milan is beautiful." ></td>
	<td class="line x" title="24:213	Aligning according to syntac747 Start II Milan Milan wentwent isis AcceptAccept to to Milan beautifulbeautiful Accept Start II Milan Milan wentwent isis toto MilanMilan Accept Accept beautifulbeautiful Accept Figure 1: Alignment on lexical similarity and alignment with syntactic features of the sentences Milan is beautiful and I went to Milan." ></td>
	<td class="line x" title="25:213	tic features, on the other hand, would avoid this improper alignment by detecting that the syntactic feature values of the two Milan differ too much." ></td>
	<td class="line x" title="26:213	We shall explain syntactic features and their usages later." ></td>
	<td class="line x" title="27:213	In this small example, our syntax-based alignment will align nothing (the bottom FSA in Figure 1) since Milan is the only lexically common word in both sentences." ></td>
	<td class="line x" title="28:213	For much larger clusters in our experiments, we are able to produce a significant number of novel sentences from our alignment with such tightened syntactic conditions." ></td>
	<td class="line x" title="29:213	Figure 2 shows one of the actual clusters used in our work that has 18 unique sentences." ></td>
	<td class="line x" title="30:213	Two of the many automatically generated grammatical sentences are also shown." ></td>
	<td class="line x" title="31:213	Another piece of related work, (Quirk et al. , 2004), starts off with parallel inputs and uses monolingual Statistical Machine Translation techniques to align them and generate novel sentences." ></td>
	<td class="line x" title="32:213	In our work, the input text does not need to be nearly as parallel." ></td>
	<td class="line x" title="33:213	The main contribution of this paper is a syntaxbased alignment technique for generating novel paraphrases of sentences that describe a particular fact." ></td>
	<td class="line x" title="34:213	Such techniques can be potentially useful in multi-document summarizers such as Newsblaster (http://newsblaster.cs." ></td>
	<td class="line x" title="35:213	columbia.edu) and NewsInEssence (http: //www.newsinessence.com)." ></td>
	<td class="line x" title="36:213	Such systems are notorious for mostly reusing text from existing news stories." ></td>
	<td class="line x" title="37:213	We believe that allowing them to use novel formulations of known facts will make these systems much more successful." ></td>
	<td class="line oc" title="38:213	2 Related work Our work is closest in spirit to the two papers that inspired us (Barzilay and Lee, 2003) and (Pang et al. , 2003)." ></td>
	<td class="line o" title="39:213	Both of these papers describe how multiple sequence alignment can be used for extracting paraphrases from clustered texts." ></td>
	<td class="line x" title="40:213	Pang et al. use as their input the multiple human English translations of Chinese documents provided by the LDC as part of the NIST machine translation evaluation." ></td>
	<td class="line x" title="41:213	Their approach is to merge multiple parse trees into a single finite state automaton in which identical input subconstituents are merged while alternatives are converted to parallel paths in the output FSA." ></td>
	<td class="line o" title="42:213	Barzilay and Lee, on the other hand, make use of classic techniques in biological sequence analysis to identify paraphrases from comparable texts (news from different sources on the same event)." ></td>
	<td class="line n" title="43:213	In summary, Pang et al. use syntactic alignment of parallel texts while Barzilay and Lee use comparable (not parallel) input but ignore syntax." ></td>
	<td class="line o" title="44:213	Our work differs from the two in that we apply syntactic information on aligning comparable texts and that the syntactic clues we use are drawn from Chunklink ilk.uvt.nl/ sabine/homepage/software.html output, which is further analysis from the syntactic parse trees." ></td>
	<td class="line x" title="45:213	Another related paper using multiple sequence alignment for text generation was (Barzilay and Lee, 2002)." ></td>
	<td class="line x" title="46:213	In that work, the authors were able to automatically acquire different lexicalizations of the same concept from multiple-parallel corpora." ></td>
	<td class="line x" title="47:213	We also draw some ideas from the FitchMargoliash method for building evolutionary trees 748 1." ></td>
	<td class="line x" title="48:213	A police official said it was a Piper tourist plane and that the crash had set the top floors on fire." ></td>
	<td class="line x" title="49:213	2." ></td>
	<td class="line x" title="50:213	According to ABCNEWS aviation expert John Nance, Piper planes have no history of mechanical troubles or other problems that would lead a pilot to lose control." ></td>
	<td class="line x" title="51:213	3." ></td>
	<td class="line x" title="52:213	April 18, 2002 8212; A small Piper aircraft crashes into the 417-foot-tall Pirelli skyscraper in Milan, setting the top floors of the 32-story building on fire." ></td>
	<td class="line x" title="53:213	4." ></td>
	<td class="line x" title="54:213	Authorities said the pilot of a small Piper plane called in a problem with the landing gear to the Milans Linate airport at 5:54 p.m., the smaller airport that has a landing strip for private planes." ></td>
	<td class="line x" title="55:213	5." ></td>
	<td class="line x" title="56:213	Initial reports described the plane as a Piper, but did not note the specific model." ></td>
	<td class="line x" title="57:213	6." ></td>
	<td class="line x" title="58:213	Italian rescue officials reported that at least two people were killed after the Piper aircraft struck the 32-story Pirelli building, which is in the heart of the city s financial district." ></td>
	<td class="line x" title="59:213	7." ></td>
	<td class="line x" title="60:213	MILAN, Italy AP A small piper plane with only the pilot on board crashed Thursday into a 30-story landmark skyscraper, killing at least two people and injuring at least 30." ></td>
	<td class="line x" title="61:213	8." ></td>
	<td class="line x" title="62:213	Police officer Celerissimo De Simone said the pilot of the Piper Air Commander plane had sent out a distress call at 5:50 p.m. just before the crash near Milans main train station." ></td>
	<td class="line x" title="63:213	9." ></td>
	<td class="line x" title="64:213	Police officer Celerissimo De Simone said the pilot of the Piper aircraft had sent out a distress call at 5:50 p.m. 11:50 a.m. 10." ></td>
	<td class="line x" title="65:213	Police officer Celerissimo De Simone said the pilot of the Piper aircraft had sent out a distress call at 5:50 p.m. just before the crash near Milans main train station." ></td>
	<td class="line x" title="66:213	11." ></td>
	<td class="line x" title="67:213	Police officer Celerissimo De Simone said the pilot of the Piper aircraft sent out a distress call at 5:50 p.m. just before the crash near Milans main train station." ></td>
	<td class="line x" title="68:213	12." ></td>
	<td class="line x" title="69:213	Police officer Celerissimo De Simone told The AP the pilot of the Piper aircraft had sent out a distress call at 5:50 p.m. just before crashing." ></td>
	<td class="line x" title="70:213	13." ></td>
	<td class="line x" title="71:213	Police say the aircraft was a Piper tourism plane with only the pilot on board." ></td>
	<td class="line x" title="72:213	14." ></td>
	<td class="line x" title="73:213	Police say the plane was an Air Commando 8212; a small plane similar to a Piper." ></td>
	<td class="line x" title="74:213	15." ></td>
	<td class="line x" title="75:213	Rescue officials said that at least three people were killed, including the pilot, while dozens were injured after the Piper aircraft struck the Pirelli high-rise in the heart of the city s financial district." ></td>
	<td class="line x" title="76:213	16." ></td>
	<td class="line x" title="77:213	The crash by the Piper tourist plane into the 26th floor occurred at 5:50 p.m. 1450 GMT on Thursday, said journalist Desideria Cavina." ></td>
	<td class="line x" title="78:213	17." ></td>
	<td class="line x" title="79:213	The pilot of the Piper aircraft, en route from Switzerland, sent out a distress call at 5:54 p.m. just before the crash, said police officer Celerissimo De Simone." ></td>
	<td class="line x" title="80:213	18." ></td>
	<td class="line x" title="81:213	There were conflicting reports as to whether it was a terrorist attack or an accident after the pilot of the Piper tourist plane reported that he had lost control." ></td>
	<td class="line x" title="82:213	1." ></td>
	<td class="line x" title="83:213	Police officer Celerissimo De Simone said the pilot of the Piper aircraft, en route from Switzerland, sent out a distress call at 5:54 p.m. just before the crash near Milans main train station." ></td>
	<td class="line x" title="84:213	2." ></td>
	<td class="line x" title="85:213	Italian rescue officials reported that at least three people were killed, including the pilot, while dozens were injured after the Piper aircraft struck the 32-story Pirelli building, which is in the heart of the city s financial district." ></td>
	<td class="line x" title="86:213	Figure 2: A comparable cluster of size 18 and 2 novel sentences produced by syntax-based alignment." ></td>
	<td class="line x" title="87:213	described in (Fitch and Margoliash, 1967)." ></td>
	<td class="line x" title="88:213	That method and related techniques in Bioinformatics such as (Felsenstein, 1995) also make use of a similarity matrix for aligning a number of sequences." ></td>
	<td class="line x" title="89:213	3 Alignment Algorithms Our alignment algorithm can be described as modifying Levenshtein Edit Distance by assigning different scores to lexically matched words according to their syntactic similarity." ></td>
	<td class="line x" title="90:213	And the decision of whether to align a pair of words is based on such syntax scores." ></td>
	<td class="line x" title="91:213	3.1 Modified Levenshtein Edit Distance The Levenshtein Edit Distance (LED) is a measure of similarity between two strings named after the Russian scientist Vladimir Levenshtein, who devised the algorithm in 1965." ></td>
	<td class="line x" title="92:213	It is the number of substitutions, deletions or insertions (hence edits) needed to transform one string into the other." ></td>
	<td class="line x" title="93:213	We extend LED to sentence level by counting the substitutions, deletions and insertions of words necessary to transform a sentence into the other." ></td>
	<td class="line x" title="94:213	We abbreviate this sentence-level edit distance as MLED." ></td>
	<td class="line x" title="95:213	Similar to LED, MLED computation produces an M+1 by N+1 distance matrix, D, given two input sentences of length M and N respectively." ></td>
	<td class="line x" title="96:213	This matrix is constructed through dynamic programming as shown in Figure 3." ></td>
	<td class="line x" title="97:213	D[i][j] = 8 > > < > > : 0 if j = 0 0 if i = 0 max D[i ? 1][j ?1] + match; D[i ? 1][j] + gap; D[i][j ? 1] + gap ! otherwise Figure 3: Dynamic programming in computing MLED of two sentences of length M and N. match is 2 if the ith word in Sentence 1 and the jth word in Sentence 2 syntactically match, and is -1 otherwise." ></td>
	<td class="line x" title="98:213	gap represents the score for inserting a gap rather than aligning, and is set to -1." ></td>
	<td class="line x" title="99:213	The matching conditions of two words are far more complicated than lexical equality." ></td>
	<td class="line x" title="100:213	Rather, we judge whether two lexically equal words match based on a predefined set of syntactic features." ></td>
	<td class="line x" title="101:213	The output matrix is used to guide the alignment." ></td>
	<td class="line x" title="102:213	Starting from the bottom right entry of the matrix, we go to the matrix entry from which the value of the current cell is derived in the recursion of the dynamic programming." ></td>
	<td class="line x" title="103:213	Call the current entry D[i][j]." ></td>
	<td class="line x" title="104:213	If it gets its value from D[i?1][j?1], the ith word in Sentence 1 and the jth word in Sentence 2 are either aligned or both aligned to a gap depending on whether they syntactically match; if the value of D[i][j] is derived from D[i][j ? 1] + 749 gap, the i th word in Sentence 1 is aligned to a gap inserted into Sentence 2 (the jth word in Sentence 2 is not consumed); otherwise, the jth word in Sentence 2 is aligned to a gap inserted into Sentence 1." ></td>
	<td class="line x" title="105:213	Now that we know how to align two sentences, aligning a cluster of sentences is done progressively." ></td>
	<td class="line x" title="106:213	We start with the overall most similar pair and then respect the initial ordering of the cluster, aligning remaining sentences sequentially." ></td>
	<td class="line x" title="107:213	Each sentence is aligned against its best match in the pool of already-aligned ones." ></td>
	<td class="line x" title="108:213	This approach is a hybrid of the Feng-Doolittles Algorithm (Feng and Doolittle, 1987) and a variant described in (Fitch and Margoliash, 1967)." ></td>
	<td class="line x" title="109:213	3.2 Syntax-based Alignment As remarked earlier, our alignment scheme judges whether two words match according to their syntactic similarity on top of lexical equality." ></td>
	<td class="line x" title="110:213	The syntactic features are obtained from running Chunklink (Buchholz, 2000) on the Charniak parses of the clustered sentences." ></td>
	<td class="line x" title="111:213	3.2.1 Syntactic Features Among all the information Chunklink provides, we use in particular the part-of-speech tags, the Chunk tags, and the syntactic dependence traces." ></td>
	<td class="line x" title="112:213	The Chunk tag shows the constituent of a word and its relative position in that constituent." ></td>
	<td class="line x" title="113:213	It can take one of the three values,  O meaning that the word is outside of any chunk;  I-XP meaning that this word is inside an XP chunk where X = N, V, P, ADV,  B-XP meaning that the word is at the beginning of an XP chunk." ></td>
	<td class="line x" title="114:213	From now on, we shall refer to the Chunk tag of a word as its IOB value (IOB was named by Tjong Kim Sang and Jorn Veeenstra (Tjong Kim Sang and Veenstra, 1999) after Ratnaparkhi (Ratnaparkhi, 1998))." ></td>
	<td class="line x" title="115:213	For example, in the sentence I visited Milan Theater, the IOB value for I is B-NP since it marks the beginning of a nounphrase (NP)." ></td>
	<td class="line x" title="116:213	On the other hand, Theater has an IOB value of I-NP because it is inside a nounphrase (Milan Theater) and is not at the beginning of that constituent." ></td>
	<td class="line x" title="117:213	Finally, the syntactic dependence trace of a word is the path of IOB values from the root of the tree to the word itself." ></td>
	<td class="line x" title="118:213	The last element in the trace is hence the IOB of the word itself." ></td>
	<td class="line x" title="119:213	3.2.2 The Algorithm Lexically matched words but with different POS are considered not syntactically matched (e.g. , race VB vs. race NN)." ></td>
	<td class="line x" title="120:213	Hence, our focus is really on pairs of lexically matched words with the same POS." ></td>
	<td class="line x" title="121:213	We first compare their IOB values." ></td>
	<td class="line x" title="122:213	Two IOB values are exactly matched only if they are identical (same constituent and same position); they are partially matched if they share a common constituent but have different position (e.g. , B-PP vs. I-PP); and they are unmatched otherwise." ></td>
	<td class="line x" title="123:213	For a pair of words with exactly matched IOB values, we assign 1 as their IOB-score; for those with partially matched IOB values, 0; and -1 for those with unmatched IOB values." ></td>
	<td class="line x" title="124:213	The numeric values of the score are from experimental experience." ></td>
	<td class="line x" title="125:213	The next step is to compare syntactic dependence traces of the two words." ></td>
	<td class="line x" title="126:213	We start with the second last element in the traces and go backward because the last one is already taken care of by the previous step." ></td>
	<td class="line x" title="127:213	We also discard the front element of both traces since it is I-S for all words." ></td>
	<td class="line x" title="128:213	The corresponding elements in the two traces are checked by the IOB-comparison described above and the scores accumulated." ></td>
	<td class="line x" title="129:213	The process terminates as soon as one of the two traces is exhausted." ></td>
	<td class="line x" title="130:213	Last, we adjust down the cumulative score by the length difference between the two traces." ></td>
	<td class="line x" title="131:213	Such final score is named the trace-score of the two words." ></td>
	<td class="line x" title="132:213	We declare unmatched if the sum of the IOBscore and the trace-score falls below 0." ></td>
	<td class="line x" title="133:213	Otherwise, we perform one last measurement  the relative position of the two words in their respective sentences." ></td>
	<td class="line x" title="134:213	The relative position is defined to be the words absolute position divided by the length of the sentence it appears in (e.g. the 4th word of a 20-word sentence has a relative position of 0.2)." ></td>
	<td class="line x" title="135:213	If the difference between two relative positions is larger than 0.4 (empirically chosen before running the experiments), we consider the two words unmatched." ></td>
	<td class="line x" title="136:213	Otherwise, they are syntactically matched." ></td>
	<td class="line x" title="137:213	The pseudo-code of checking syntactic match is shown in Figure 4." ></td>
	<td class="line x" title="138:213	750 Algorithm Check Syntactic Match of Two Words For a pair of words W 1, W 2 if W 1 6= W 2 or pos(W 1 ) 6= pos(W 2 ) then return unmatched endif score := 0 iob 1 := iob(W 1 ) iob 2 := iob(W 2 ) score += compare iobs(iob 1 ;iob 2 ) trace 1 := trace(W 1 ) trace 2 := trace(W 2 ) score += compare traces(trace 1 ;trace 2 ) if score < 0 then return unmatched endif relpos 1 := pos(W 1 )/lengthOf(S 1 ) relpos 2 := pos(W 2 )/lengthOf(S 2 ) if jrelpos 1 ?relpos 2 j  0:4 then return unmatched endif return matched Function compare iobs(iob 1 ;iob 2 ) if iob 1 = iob 2 then return 1 endif if substring(iob 1 ;1) = substring(iob 2 ;1) then return 0 endif return ?1 Function compare traces(trace 1 ;trace 2 ) Remove first and last elements from both traces score := 0 i := lengthOf(trace 1 ) ? 1 j := lengthOf(trace 2 )?" ></td>
	<td class="line x" title="139:213	1 while i  0 and j  0 do next := compare iobs(trace 1 [i];trace 2 [j]) score += next 0:5 i ??" ></td>
	<td class="line x" title="140:213	j ??" ></td>
	<td class="line x" title="141:213	endwhile score ? = jlengthOf(trace 1 ) ? lengthOf(trace 2 )j 0:5 return score Figure 4: Algorithm for checking the syntactic match between two words." ></td>
	<td class="line x" title="142:213	4 Evaluation 4.1 Experimental Setup 4.1.1 Data The data we use in our experiment come from a number of sentence clusters on a variety of topics, but all related to the Milan plane crash event." ></td>
	<td class="line x" title="143:213	This cluster was collected manually from the Web of five different news agencies (ABC, CNN, Fox, MSNBC, and USAToday)." ></td>
	<td class="line x" title="144:213	It concerns the April 2002 crash of a small plane into a building in Milan, Italy and contains a total of 56 documents published over a period of 1.5 days." ></td>
	<td class="line x" title="145:213	To divide this corpus into representative smaller clusters, we had a colleague thoroughly read all 56 documents in the cluster and then create a list of important facts surrounding the story." ></td>
	<td class="line x" title="146:213	We then picked key terms related to these facts, such as names (Fasulo the pilot) and locations (Locarno the city from which the plane had departed)." ></td>
	<td class="line x" title="147:213	Finally, we automatically clustered sentences based on the presence of these key terms, resulting in 21 clusters of topically related (comparable) sentences." ></td>
	<td class="line x" title="148:213	The 21 clusters are grouped into three categories: 7 in training set, 3 in dev-testing set, and the remaining 11 in testing set." ></td>
	<td class="line x" title="149:213	Table 1 shows the name and size of each cluster." ></td>
	<td class="line x" title="150:213	Cluster Number of Sentences Training clusters ambulance 10 belie 14 built 6 malpensa 4 piper 18 president 17 route 11 Dev-test clusters hospital 17 rescue 12 witness 6 Test clusters accident 30 cause 18 fasulo 33 floor 79 government 22 injur 43 linate 21 rockwell 9 spokes 18 suicide 22 terror 62 Table 1: Experimental clusters." ></td>
	<td class="line x" title="151:213	751 4.1.2 Different Versions of Alignment To test the usefulness of our work, we ran 5 different alignments on the clusters." ></td>
	<td class="line x" title="152:213	The first three represent different levels of baseline performance (without syntax consideration) whereas the last two fully employ the syntactic features but treat stop words differently." ></td>
	<td class="line x" title="153:213	Table 2 describes the 5 versions of alignment." ></td>
	<td class="line x" title="154:213	Run Description V1 Lexical alignment on everything possible V2 Lexical alignment on everything but commas V3 Lexical alignment on everything but commas and stop words V4 Syntactic alignment on everything but commas and stop words V5 Syntactic alignment on everything but commas Table 2: Alignment techniques used in the experiments." ></td>
	<td class="line x" title="155:213	Alignment Grammaticality Fidelity V1 2.89 2.98 V2 3.00 2.95 V3 3.15 3.22 V4 3.68 3.59 V5 3.47 3.30 Table 3: Evaluation results on training and devtesting clusters." ></td>
	<td class="line x" title="156:213	For the results on the test clusters, see Table 6 The motivation of trying such variations is as follows." ></td>
	<td class="line x" title="157:213	Stop words often cause invalid alignment because of their high frequencies, and so do punctuations." ></td>
	<td class="line x" title="158:213	Aligning on commas, in particular, is likely to produce long sentences that contain multiple sentence segments ungrammatically patched together." ></td>
	<td class="line x" title="159:213	4.1.3 Training and Testing In order to get the best possible performance of the syntactic alignment versions, we use clusters in the training and dev-test sets to tune up the parameter values in our algorithm for checking syntactic match." ></td>
	<td class="line x" title="160:213	The parameters in our algorithm are not independent." ></td>
	<td class="line x" title="161:213	We pay special attention to the threshold of relative position difference, the discount factor of the trace length difference penalty, and the scores for exactly matched and partially matched IOB values." ></td>
	<td class="line x" title="162:213	We try different parameter settings on the training clusters, and apply the top ranking combinations (according to human judgments described later) on clusters in the devtesting set." ></td>
	<td class="line x" title="163:213	The values presented in this paper are the manually selected ones that yield the best performance on the training and dev-testing sets." ></td>
	<td class="line x" title="164:213	Experimenting on the testing data, we have two hypotheses to verify: 1) the 2 syntactic versions outperform the 3 baseline versions by both grammaticality and fidelity (discussed later) of the novel sentences produced by alignment; and 2) disallowing alignment on stop words and commas enhances the performance." ></td>
	<td class="line x" title="165:213	4.2 Experimental Results For each cluster, we ran the 5 alignment versions and produce 5 FSAs. From each FSA (corresponding to a cluster A and alignment version i), 100 sentences are randomly generated." ></td>
	<td class="line x" title="166:213	We removed those that appear in the original cluster." ></td>
	<td class="line x" title="167:213	The remaining ones are hence novel sentences, among which we randomly chose 10 to test the performance of alignment version i on cluster A. In the human evaluation, each sentence received two scores  grammaticality and fidelity." ></td>
	<td class="line x" title="168:213	These two properties are independent since a sentence could possibly score high on fidelity even if it is not fully grammatical." ></td>
	<td class="line x" title="169:213	Four different scores are possible for both criteria: (4) perfect (fully grammatical or faithful); (3) good (occasional errors or quite faithful); (2) bad (many grammar errors or unfaithful pieces); and (1) nonsense." ></td>
	<td class="line x" title="170:213	4.2.1 Results from the Training Phase Four judges help our evaluation in the training phase." ></td>
	<td class="line x" title="171:213	They are provided with the original clusters during the evaluation process, yet they are given the sentences in shuffled order so that they have no knowledge about from which alignment version each sentence is generated." ></td>
	<td class="line x" title="172:213	Table 3 shows the averages of their evaluation on the 10 clusters in training and dev-testing set." ></td>
	<td class="line x" title="173:213	Each cell corresponds to 400 data points as we presented 10 sentences per cluster per alignment version to each of the 4 judges (10 x 10 x 4 = 400)." ></td>
	<td class="line x" title="174:213	4.2.2 Results from the Testing Phase After we have optimized the parameter configuration for our syntactic alignment in the training phase, we ask another 6 human judges to evaluate our work on the testing data." ></td>
	<td class="line x" title="175:213	These 6 judges come from diverse background including Information, Computer Science, Linguistics, and Bioinformatics." ></td>
	<td class="line x" title="176:213	We distribute the 11 testing clusters among them so that each cluster gets evaluated by at least 3 judges." ></td>
	<td class="line x" title="177:213	The workload for each judge is 6 clusters x 5 versions/cluster x 10 sentences/clusterversion = 300 sentences." ></td>
	<td class="line x" title="178:213	Similar to the training phase, they receive the sentences in shuffled order without knowing the correspondence between 752 sentences and alignment versions." ></td>
	<td class="line x" title="179:213	Detailed average statistics are shown in Table 4 and Table 5 for grammaticality and fidelity, respectively." ></td>
	<td class="line x" title="180:213	Each cell is the average over 30 40 data points, and notice the last row is not the mean of the other rows since the number of sentences evaluated for each cluster varies." ></td>
	<td class="line x" title="181:213	Cluster V1 V2 V3 V4 V5 rockwell 2.27 2.93 3.00 3.60 3.03 cause 2.77 2.83 3.07 3.10 2.93 spokes 2.87 3.07 3.57 3.83 3.50 linate 2.93 3.14 3.26 3.64 3.77 government 2.75 2.83 3.27 3.80 3.20 suicide 2.19 2.51 3.29 3.57 3.11 accident 2.92 3.27 3.54 3.72 3.56 fasulo 2.52 2.52 3.15 3.54 3.32 injur 2.29 2.92 3.03 3.62 3.29 terror 3.04 3.11 3.61 3.23 3.63 floor 2.47 2.77 3.40 3.47 3.27 Overall 2.74 2.75 3.12 3.74 3.29 Table 4: Average grammaticality scores on testing clusters." ></td>
	<td class="line x" title="182:213	Cluster V1 V2 V3 V4 V5 rockwell 2.25 2.75 3.20 3.80 2.70 cause 2.42 3.04 2.92 3.48 3.17 spokes 2.65 2.50 3.20 3.00 3.05 linate 3.15 3.27 3.15 3.36 3.42 government 2.85 3.24 3.14 3.81 3.20 suicide 2.38 2.69 2.93 3.68 3.23 accident 3.14 3.42 3.56 3.91 3.57 fasulo 2.30 2.48 3.14 3.50 3.48 injur 2.56 2.28 2.29 3.18 3.22 terror 2.65 2.48 3.68 3.47 3.20 floor 2.80 2.90 3.10 3.70 3.30 Overall 2.67 2.69 3.07 3.77 3.23 Table 5: Average fidelity scores on testing clusters." ></td>
	<td class="line x" title="183:213	2.00 2.20 2.40 2.60 2.80 3.00 3.20 3.40 3.60 3.80 4.00 roc kw ell cau se spo kes linate gov ern me nt sui cid e acc ide nt fas ulo injur terror floor V 1 V 2 V 3 V 4 V 5 Figure 5: Performance of 5 alignment versions by grammaticality." ></td>
	<td class="line x" title="184:213	2.00 2.20 2.40 2.60 2.80 3.00 3.20 3.40 3.60 3.80 4.00 roc kw ell cau se spo kes linate gov ern me nt sui cid e acc ide nt fas ulo injur terror floor V 1 V 2 V 3 V 4 V 5 Figure 6: Performance of 5 alignment versions by fidelity." ></td>
	<td class="line x" title="185:213	4.3 Result Analysis The results support both our hypotheses." ></td>
	<td class="line x" title="186:213	For Hypothesis I, we see that the performance of the two syntactic alignments was higher than the nonsyntactic versions." ></td>
	<td class="line x" title="187:213	In particular, Version 4 outperforms the the best baseline version by 19.9% on grammaticality and by 22.8% on fidelity." ></td>
	<td class="line x" title="188:213	Our second hypothesis is also verified  disallowing alignment on stop words and commas yields better results." ></td>
	<td class="line x" title="189:213	This is reflected by the fact that Version 4 beats Version 5, and Version 3 wins over the other two baseline versions by both criteria." ></td>
	<td class="line x" title="190:213	At the level of individual clusters, the syntactic versions are also found to outrival the syntax-blind baselines." ></td>
	<td class="line x" title="191:213	Applying a t-test on the score sets for the 5 versions, we can reject the null hypothesis with 99.5% confidence to ensure that the syntactic alignment performs better." ></td>
	<td class="line x" title="192:213	Similarly, for hypothesis II, the same is true for the versions with and without stop word alignment." ></td>
	<td class="line x" title="193:213	Figures 5 and 6 provide a graphical view of how each alignment version performs on the testing clusters." ></td>
	<td class="line x" title="194:213	The clusters along the x-axis are listed in the order of increasing size." ></td>
	<td class="line x" title="195:213	We have also done an analysis on interjudge agreement in the evaluation." ></td>
	<td class="line x" title="196:213	The judges are instructed about the evaluation scheme individually, and do their work independently." ></td>
	<td class="line x" title="197:213	We do not enforce them to be mutually consistent, as long as they are self-consistent." ></td>
	<td class="line x" title="198:213	However, Table 6 shows the mean and standard deviation of human judgments (grammaticality and fidelity) on each version." ></td>
	<td class="line x" title="199:213	The small deviation values indicate a fairly high agreement." ></td>
	<td class="line x" title="200:213	Finally, because human evaluation is expensive, we additionally tried to use a language-model ap753 Alignment Gr." ></td>
	<td class="line x" title="201:213	Mean Gr." ></td>
	<td class="line x" title="202:213	StdDev Fi." ></td>
	<td class="line x" title="203:213	Mean Fi." ></td>
	<td class="line x" title="204:213	StdDev V1 2.74 0.11 2.67 0.43 V2 2.75 0.08 2.69 0.30 V3 3.12 0.07 3.07 0.27 V4 3.74 0.08 3.77 0.16 V5 3.29 0.16 3.23 0.33 Table 6: Mean and standard deviation of human judgments." ></td>
	<td class="line x" title="205:213	proach in the training phase for automatic evaluation of grammaticality." ></td>
	<td class="line x" title="206:213	We have used BLEU scores(Papineni et al. , 2001), but have observed that they are not consistent with those of human judges." ></td>
	<td class="line x" title="207:213	In particular, BLEU assigns too high scores to segmented sentences that are otherwise grammatical." ></td>
	<td class="line x" title="208:213	It has been noted in the literature that metrics like BLEU that are solely based on N-grams might not be suitable for checking grammaticality." ></td>
	<td class="line x" title="209:213	5 Conclusion In this paper, we presented a paraphrase generation method based on multiple sequence alignment which combines traditional dynamic programming techniques with linguistically motivated syntactic information." ></td>
	<td class="line x" title="210:213	We apply our work on comparable texts for which syntax has not been successfully explored in alignment by previous work." ></td>
	<td class="line x" title="211:213	We showed that using syntactic features improves the quality of the alignment-induced finite state automaton when it is used for generating novel sentences." ></td>
	<td class="line x" title="212:213	The strongest syntax guided alignment significantly outperformed all other versions in both grammaticality and fidelity of the novel sentences." ></td>
	<td class="line x" title="213:213	In this paper we showed the effectiveness of using syntax in the alignment of structurally diverse comparable texts as needed for text generation." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W06-1403
CCG Chart Realization From Disjunctive Inputs
White, Michael;"></td>
	<td class="line x" title="1:180	Proceedings of the Fourth International Natural Language Generation Conference, pages 1219, Sydney, July 2006." ></td>
	<td class="line x" title="2:180	c2006 Association for Computational Linguistics CCG Chart Realization from Disjunctive Inputs Michael White Department of Linguistics The Ohio State University Columbus, OH 43210 USA http://www.ling.ohio-state.edu/mwhite/ Abstract This paper presents a novel algorithm forefficientlygeneratingparaphrasesfrom disjunctive logical forms." ></td>
	<td class="line x" title="3:180	The algorithm is couched in the framework of Combinatory Categorial Grammar (CCG) and has been implemented as an extension to the OpenCCG surface realizer." ></td>
	<td class="line x" title="4:180	The algorithm makes use of packed representations similar to those initially proposed by Shemtov (1997), generalizing the approach in a more straightforward waythan in the algorithm ultimately adopted therein." ></td>
	<td class="line x" title="5:180	1 Introduction In recent years, the generate-and-select paradigm of natural language generation has attracted increasing attention, particularly for the task of surface realization." ></td>
	<td class="line x" title="6:180	In this paradigm, symbolic methods are used to generate a space of possible phrasings, and statistical methods are used to select one or more outputs from this space." ></td>
	<td class="line x" title="7:180	To specify the desired paraphrase space, one may either provide an input logical form that underspecifies certain realization choices, or include explicit disjunctions in the input LF (or both)." ></td>
	<td class="line oc" title="8:180	Our experience suggests that disjunctive LFs are an important capability, especially as one seeks to make grammars reusable across applications, and to employ domain-specific, sentence-level paraphrases (Barzilay and Lee, 2003)." ></td>
	<td class="line x" title="9:180	Prominent examples of surface realizers in the generate-and-select paradigm include Nitrogen/Halogen (Langkilde, 2000; Langkilde-Geary, 2002) and Fergus (Bangalore and Rambow, 2000)." ></td>
	<td class="line x" title="10:180	More recently, generate-and-select realizers in the chart realization tradition (Kay, 1996) have appeared, including the OpenCCG (White, 2004) and LinGO (Carroll and Oepen, 2005) realizers." ></td>
	<td class="line x" title="11:180	Chart realizers make it possible to use the same reversible grammar for both parsing and realization, and employ well-defined methods of semantic composition to construct semantic representations that can properly represent the scope of logical operators." ></td>
	<td class="line x" title="12:180	In the chart realization tradition, previous work has not generally supported disjunctive logical forms, with (Shemtov, 1997) as the only published exception (to the authors knowledge)." ></td>
	<td class="line x" title="13:180	Arguably, part of the reason that disjunctive LFs have not yet been embraced more broadly by those working on chart realization is that Shemtovs solution, while ingenious, is dauntingly complex." ></td>
	<td class="line x" title="14:180	Looking beyond chart realizers, both Nitrogen/Halogen and Fergus support some forms of disjunctive input; however, in comparison to Shemtovs inputs, theirs are less expressive, in that they do not allowdisjunctionsacrossdifferentlevelsoftheinput structure." ></td>
	<td class="line x" title="15:180	As an alternative to Shemtovs method, this paper presents a chart realization algorithm for generating paraphrases from disjunctive logical forms that is more straightforward to implement, together with an initial case study of the algorithms efficiency." ></td>
	<td class="line x" title="16:180	As discussed in Section 5, the algorithm makes use of packed representations similar to those initially proposed by Shemtov, generalizing the approach in a way that avoids the problems that led Shemtov to reject his preliminary method." ></td>
	<td class="line x" title="17:180	The algorithm is couched in the framework of Steedmans (2000) Combinatory Categorial Grammar (CCG) and has been implemented as an extension to the OpenCCG surface realizer." ></td>
	<td class="line x" title="18:180	Though the algorithm is well suited to CCG, it is expected to be applicable to other constraint-based grammatical frameworks as well." ></td>
	<td class="line x" title="19:180	12 be <TENSE>pres,<MOOD>dcl e <ARG> <PROP> based_on <DET>the,<NUM>sg design d p <SOURCE> <ARTIFACT> collection <DET>the,<NUM>sg c <HASPROP> <CREATOR> Funny_Day f v Villeroy_and_Boch (a) Semantic dependency graph for The design (is|s) based on the Funny Day collection by Villeroy and Boch." ></td>
	<td class="line x" title="20:180	be <TENSE>pres,<MOOD>dcl e <ARG> <PROP> based_on <DET>the,<NUM>sg design d p <SOURCE> <ARTIFACT> series <NUM>sg c <HASPROP> <GENOWNER> Funny_Day f v Villeroy_and_Boch (b) Semantic dependency graph for The design (is|s) based on Villeroy and Bochs Funny Day series." ></td>
	<td class="line x" title="21:180	(c) Disjunctive semantic dependency graph covering (a)(b), i.e. The design (is|s) based on (the Funny Day (collection|series) by Villeroy and Boch | Villeroy and Bochs Funny Day (collection|series))." ></td>
	<td class="line x" title="22:180	Figure 1: Example semantic dependency graphs from the COMIC dialogue system." ></td>
	<td class="line x" title="23:180	@e(be  TENSEpres  MOODdcl  ARG(d  design  DETthe  NUMsg)  PROP(p  based on  ARTIFACTd  SOURCE(c  collection  DETthe  NUMsg  HASPROP(f  Funny Day)  CREATOR(v  V&B)))) (a) @e(be  TENSEpres  MOODdcl  ARG(d  design  DETthe  NUMsg)  PROP(p  based on  ARTIFACTd  SOURCE(c  NUMsg  (DETthe)?" ></td>
	<td class="line x" title="24:180	 (collection  series)  HASPROP(f  Funny Day)  (CREATORv  GENOWNERv))))  @v(Villeroy and Boch) (c) Figure 2: HLDS for examples in Figure 1." ></td>
	<td class="line x" title="25:180	2 Disjunctive Logical Forms As an illustration of disjunctive logical forms, consider the semantic dependency graphs in Figure 1, which are taken from the COMIC1 multimodal dialogue system.2 Graphs such as these constitute the input to the OpenCCG realizer." ></td>
	<td class="line x" title="26:180	Each node has a lexical predication (e.g. design) and a set of semantic features (e.g. NUMsg); nodesareconnectedviadependencyrelations(e.g. ARTIFACT)." ></td>
	<td class="line x" title="27:180	Given the lexical categories in the COMIC grammar, the graphs in Figure 1(a) and (b) fully specify their respective realizations, with the exception of the choice of the full or contracted form of the copula." ></td>
	<td class="line x" title="28:180	To generalize over these alternatives, the disjunctive graph in (c) may be employed." ></td>
	<td class="line x" title="29:180	This graph allows a free choice between the domain synonyms collection and series, as indicated by the vertical bar between their respective predications." ></td>
	<td class="line x" title="30:180	The graph also allows a free choice between the CREATOR and GENOWNER relationslexicalized via by and the possessive, respectivelyconnecting the head c (collection or series) with the dependent v (for 1http://www.hcrc.ed.ac.uk/comic/ 2To simplify the exposition, the features specifying information structure and deictic gestures have been omitted, as have the semantic sorts of the discourse referents." ></td>
	<td class="line x" title="31:180	13 @e(see  ARG0(m  man)  ARG1(g  girl)  @o(onARG1(hhill))@w(withARG1(ttelescope)) ((MODo  @h(MODw))  (@g(MODo)  (@g(MODw)  @h(MODw)))  (MODw  (MODo @g(MODo))))) Figure 3: Disjunctive LF for 5-way ambiguity in A man saw a girl on the hill with a telescope." ></td>
	<td class="line x" title="32:180	Villeroy and Boch); this choice is indicated by an arcbetweenthetwodependencyrelations." ></td>
	<td class="line x" title="33:180	Finally, the determiner feature (DETthe) on c is indicated as optional, via the question mark." ></td>
	<td class="line x" title="34:180	It is worth pausing at this point to observe that in designing the COMIC grammar, the differences between(a) and (b) couldperhaps have been collapsed." ></td>
	<td class="line x" title="35:180	However, such a move would make it more difficult to reuse the grammar in other applicationsand indeed, the core of the grammarissharedwiththeFLIGHTSsystem(Mooreet al. , 2004)as it would presuppose that these paraphrases should always available in the same contexts." ></td>
	<td class="line x" title="36:180	An example of a sentence-level paraphrase, whose context of applicability is more clearly limited, appears in (1): (1) (This design | This one | This) (is|s) (classic | in the classic style) | Here we have a (classic design | design in the classic style)." ></td>
	<td class="line x" title="37:180	This example shows some of the phrasings that may be used in COMIC to describe the style of a design that has not been discussed previously." ></td>
	<td class="line x" title="38:180	The example includes a top-level disjunction between the use of a deictic NP this design | this one | this(withanaccompanyingpointinggesture)followed by the copula, or the use of the phrase here we have to introduce the design." ></td>
	<td class="line x" title="39:180	While these alternatives can function as paraphrases in this context, it is difficult to see how one might specify them in a single underspecified (and applicationneutral) logical form." ></td>
	<td class="line x" title="40:180	Graphs such as those in Figure 1 are represented internally using Hybrid Logic Dependency Semantics (HLDS), as in Figure 2." ></td>
	<td class="line x" title="41:180	HLDS is a dependency-based approach to representing linguistic meaning developed by Baldridge and Kruijff (2002)." ></td>
	<td class="line x" title="42:180	In HLDS, hybrid logic (Blackburn, 2000) terms3 are used to describe dependency 3Hybrid logic extends modal logic with nominals, a new sort of basic formula that explicitly names states/nodes." ></td>
	<td class="line x" title="43:180	Like propositions, nominals are first-class citizens of the object graphs." ></td>
	<td class="line x" title="44:180	These graphs have been suggested as representations for discourse structure, and have their own underlying semantics (White, 2006)." ></td>
	<td class="line x" title="45:180	In HLDS, as can be seen in Figure 2(a), each semantic head is associated with a nominal that identifies its discourse referent, and heads are connected to their dependents via dependency relations, which are modeled as modal relations." ></td>
	<td class="line x" title="46:180	Modal relations are also used to represent semantic features." ></td>
	<td class="line x" title="47:180	In (c), two new operators are introduced to represent periphrastic alternatives and optional parts of the meaning, namely  and ()?, for exclusive-or and optionality, respectively." ></td>
	<td class="line x" title="48:180	To indicate that a nominal represents a reference to a node that is considered a shared part of multiple alternatives, the nominal is annotated with a box, as exemplified by v. As will be discussed in Section 3.1, this notion of shared references is needed during the logical form flattening stage of the algorithm in order to determine which elementary predications are part of each alternative." ></td>
	<td class="line x" title="49:180	As mentioned earlier, disjunctive LFs may contain alternations that are not at the same level." ></td>
	<td class="line x" title="50:180	To illustrate, Figure 3 shows the representation (minus semantic features) for the 5-way ambiguity in A man saw a girl on the hill with a telescope (Shemtov, 1997, p. 45); in the figure, the nominal o (for on) can be a dependent of e (for see) or g (for girl), for example." ></td>
	<td class="line x" title="51:180	As Shemtov explains, such packed representations can be useful in machine translation for generating ambiguitypreserving target language sentences." ></td>
	<td class="line x" title="52:180	In a straight generation context, disjunctions that span levels enable one to compactly represent alternatives that differ in their head-dependent assumptions; for instance, to express contrast, one might employ the coordinate conjunction but as the sentence head, or the subordinate conjunction although as a dependent of the main clause head." ></td>
	<td class="line x" title="53:180	3 The Algorithm As with the other chart realizers cited in the introduction, the OpenCCG realizer makes use of a chart and an agenda to perform a bottom-up dynamic programming search for signs whose LFs language, and thus formulas can be formed using propositions, nominals, and standard boolean operators." ></td>
	<td class="line x" title="54:180	They may also employ the satisfaction operator, @." ></td>
	<td class="line x" title="55:180	A formula @i(pF(jq)) indicatesthattheformulas p and F(jq) hold at the state named by i, and that the state j, where q holds, is reachable via the modal relation F; equivalently, it states that node i is labeled by p, and that node j, labeled by q, is reachable from i via an arc labeled F. 14 completely cover the elementary predications in the input logical form." ></td>
	<td class="line x" title="56:180	The search for complete realizations proceeds in one of two modes, anytime or two-stage packing/unpacking." ></td>
	<td class="line x" title="57:180	This section focuses on how the two-stage mode has been extended to efficiently generate paraphrases from disjunctive logical forms." ></td>
	<td class="line x" title="58:180	3.1 LF Flattening In a preprocessing stage, the input logical form is flattened to an array of elementary predications (EPs), one for each lexical predication, semantic feature or dependency relation." ></td>
	<td class="line x" title="59:180	When the input LF contains no exclusive-or or optionality operators, the list of EPs, when conjoined, yields a graph description that is equivalent to the original one." ></td>
	<td class="line x" title="60:180	With disjunctive logical forms, however, moreneedstobesaid." ></td>
	<td class="line x" title="61:180	Ourstrategyistokeeptrack of the elementary predications that make up the alternatives and optional parts of the LF, as specified by the exclusive-or or optionality operators, and use these to enforce constraints on the elementary predications that may appear in any given realization." ></td>
	<td class="line x" title="62:180	These constraints ensure that only combinations of EPs that describe a graph that is also described by the original LF are allowed." ></td>
	<td class="line x" title="63:180	To illustrate, the results of flattening the LF in Figure 2(c) are given below: (2) 0: @e(be), 1: @e(TENSEpres), 2: @e(MOODdcl), 3: @e(ARGd), 4: @d(design), 5: @d(DETthe), 6: @d(NUMsg), 7: @e(PROPp), 8: @p(based on), 9: @p(ARTIFACTd), 10: @p(SOURCEc), 11: @c(NUMsg), 12: @c(DETthe), 13: @c(collection), 14: @c(series), 15: @c(HASPROPf), 16: @f(Funny Day), 17: @c(CREATORv),18: @c(GENOWNERv), 19: @v(Villeroy and Boch) (3) alt0,0 = {13}; alt0,1 = {14} alt1,0 = {17,19}; alt1,1 = {18,19} opt0 = {12} In (2), the EPs are shown together with their array positions." ></td>
	<td class="line x" title="64:180	SincetheEPsaretrackedpositionally, it is possible to use bit vectors to represent the alternatives and optional parts of the LF." ></td>
	<td class="line x" title="65:180	In (3), the first line shows the bit vectors4 for the choice between collection (EP 13) and series (EP 14), as alternatives 0 and 1 in alternative group 0." ></td>
	<td class="line x" title="66:180	On the sec4Only the positive bits are shown, via their indices." ></td>
	<td class="line x" title="67:180	ond line, the bit vectors for the CREATOR (EP 17) and GENOWNER (EP 18) alternatives appear; note that both of these options also involve the shared EP 19." ></td>
	<td class="line x" title="68:180	The bit vector for the optional determiner (EP 12) is shown on the third line." ></td>
	<td class="line x" title="69:180	The constraint associated with each group of alternatives is that in order to be valid, a collection ofEPsmustnotintersectwiththenon-overlapping parts of more than one alternative." ></td>
	<td class="line x" title="70:180	For example, for the second group of alternatives in (3), a valid collection could include EPs 17 and 19, or EPs 18 and 19, but it could not include EPs 17 and 18 together." ></td>
	<td class="line x" title="71:180	Flattening an LF to obtain the array of EPs, as in (2), just requires a relatively straightforward traversal of the HLDS formula." ></td>
	<td class="line x" title="72:180	Obtaining the alternatives and optional parts of the LF is a bit more involved." ></td>
	<td class="line x" title="73:180	To do so, during the traversal, the exclusive-or and optionality operators are handled by introducing a new alternative group or optional part, and then keeping track of which elementary predications fall under each alternative or under the optional part." ></td>
	<td class="line x" title="74:180	Subsequently, the alternatives and optional parts are recursively propagated throughanynominalsmarkedasshared,collecting any further EPs that turn up along the way.5 For example, with the second alternative group (second line) of (3), the initial traversal creates EPs 17 and 18 under alts alt1,0 and alt1,1, respectively." ></td>
	<td class="line x" title="75:180	Since EPs 17 and 18 both include a nominal dependent v marked as shared in Figure 2(c), both alternatives are propagated through this reference, and thus EP 19 ends up as part of both alt1,0 and alt1,1." ></td>
	<td class="line x" title="76:180	Determining which EPs have shared membership in multiple alternatives is essential for accurately tracking an edges coverage of the input LF, a topic which will be considered next." ></td>
	<td class="line x" title="77:180	3.2 Edges In the OpenCCG realizer, an edge is a data structure that wraps a CCG sign, which itself consists of a word sequence paired with a category (syntactic category plus logical form)." ></td>
	<td class="line x" title="78:180	An edge has bit vectors to record its coverage of the input LF and its indices, i.e. syntactically available nominals." ></td>
	<td class="line x" title="79:180	In packing mode, a representative edge also maintains a list of alternative edges whose signs have equivalent categories (but different word sequences), so that a representative edge may effec5Though space precludes discussion, it is worth noting that the same propagation of membership applies to the LF chunks described in (White, 2006)." ></td>
	<td class="line x" title="80:180	15 tively stand in for the others during chart construction." ></td>
	<td class="line x" title="81:180	To handle disjunctive inputs, an edge additionally maintains a list of active (i.e. , partially completed) LF alternatives." ></td>
	<td class="line x" title="82:180	It also makes use of a revised notion of input coverage and a revised equivalence relation." ></td>
	<td class="line x" title="83:180	As in Shemtovs (1997, Section 3.3.2) preliminary algorithm, an edge is considered to cover an entire disjunction (alternative group) if it covers all the EPs of one of its alternatives." ></td>
	<td class="line x" title="84:180	With optional parts of an LF, an edge that does not cover any EPs in the optional part can be extended to a new edge (using the same sign) that is additionally considered to cover all the EPs in the optional part." ></td>
	<td class="line x" title="85:180	In this way, an edge can be defined to be complete with respect to the input LF if it covers all its EPs." ></td>
	<td class="line x" title="86:180	For example, an edge for the sentence in Figure 1(b) would be considered complete, since (i) it would cover all the EPs in (2) except for 12, 13 and 17; (ii) 12 is optional; (iii) 14 completes alt0,1, and thus counts as covering 13, the other EP in the group; and (iv) 18 and 19 complete alt1,1, and thus count as covering EP 17." ></td>
	<td class="line x" title="87:180	As Shemtov points out, this extended notion of input coverage provides an appropriate way to form edge equivalence classes, as it can gather edges together that realize different alternatives in the same group." ></td>
	<td class="line x" title="88:180	Thus, in OpenCCG, edge equivalence classes have been modified to include edges with the same syntactic category and coverage bit vector, but different word sequences and/or logical forms (as the latter varies according to which alternative is realized)." ></td>
	<td class="line x" title="89:180	The appropriate equivalence checks are efficiently carried out using a hash map with a custom hash function and equals method." ></td>
	<td class="line x" title="90:180	3.3 Lexical Instantiation OncetheinputLFhasbeenflattened,andthealternatives and optional parts have been identified, the next step is to access and instantiate lexical items." ></td>
	<td class="line x" title="91:180	For each elementary predication, all lexical items indexed by the EPs lexical predicate or relation are retrieved from the lexicon.6 Each such lexical item is then instantiated against the input EPs, starting with the one that triggered its retrieval, and incrementally extending successful instantiations until all the lexical items EPs have been instantiated (otherwise failing)." ></td>
	<td class="line x" title="92:180	The lexical instanti6See (White, 2004; White, 2006) for discussion of how semantically null lexical items and unary type changing rules are handled." ></td>
	<td class="line x" title="93:180	ation routine returns all instantiations that satisfy the alternative exclusion constraints." ></td>
	<td class="line x" title="94:180	Associated with each instantiation is a bit vector that encodes the coverage of the input EPs." ></td>
	<td class="line x" title="95:180	From each bit vector, theactive(partiallycompleted)LFalternatives are determined, and the bit vector is updated to include the EPs in any completed disjunctions." ></td>
	<td class="line x" title="96:180	Finally, edges are created for the instantiated lexical items, whichincludetheactivealternativesandthe updated coverage vector." ></td>
	<td class="line x" title="97:180	Continuing with example (2)-(3), the selected lexical edges in (4) below illustrate how lexical instantiation interacts with disjunctions: (4) a. {11,13,14} collection turnstileleft nc : @c(collection)  @c(NUMsg) b. {11,13,14} series turnstileleft nc : @c(series)  @c(NUMsg) c. {17} alt1,0 by turnstileleft nc\nc/npv : @c(CREATORv) d. {18} alt1,1 s turnstileleft npc/nc\npv : @c(GENOWNERv) e. {19} alt1,0;alt1,1 Villeroy and Boch turnstileleft npv : @v(V&B) The nouns in (a) and (b) complete alt0,0 and alt0,1, respectively, and thus they each count as covering EPs 11, 13 and 14." ></td>
	<td class="line x" title="98:180	In (c) and (d), by and s partially cover alt1,0 and alt1,1, respectively, and thus these alternatives are active for their respective edges." ></td>
	<td class="line x" title="99:180	In (e), V&B partially covers both alt1,0 and alt1,1, and thus both alternatives are active." ></td>
	<td class="line x" title="100:180	3.4 Derivation Following lexical instantiation, the lexical edges are added to the agenda, as is usual practice with chart algorithms, and the main loop is initiated." ></td>
	<td class="line x" title="101:180	During each iteration of the main loop, an edge is moved from the agenda to the chart." ></td>
	<td class="line x" title="102:180	If the edge is in the same equivalence class as an edge already in the chart, it is added as an alternative to the existing representative edge." ></td>
	<td class="line x" title="103:180	Otherwise, it is combinedwithallapplicableedgesinthechart(viathe grammars combinatory rules), as well as with the grammars unary rules, where any newly created edges are added to the agenda." ></td>
	<td class="line x" title="104:180	The loop terminates when no edges remain on the agenda." ></td>
	<td class="line x" title="105:180	Before edge combinations are attempted, a number of constraints are checked, as detailed in (White, 2006)." ></td>
	<td class="line x" title="106:180	In particular, the edges coverage bit vectors are required to not intersect, which ensures that they cover disjoint parts of the input LF." ></td>
	<td class="line x" title="107:180	Since the coverage vectors are updated to cover all the EPs in a disjunction when one of the alternatives is completed, this check also ensures that the 16 1." ></td>
	<td class="line x" title="108:180	{8-10} based on turnstileleft sp\npd/npc 2." ></td>
	<td class="line x" title="109:180	{12} the turnstileleft npc/nc 3." ></td>
	<td class="line x" title="110:180	{15,16} Funny Day turnstileleft nc/nc 4." ></td>
	<td class="line x" title="111:180	{11,13,14} collection turnstileleft nc {11,13,14} series turnstileleft nc 5." ></td>
	<td class="line x" title="112:180	{17} alt1,0 by turnstileleft nc\nc/npv 6." ></td>
	<td class="line x" title="113:180	{18} alt1,1 s turnstileleft npc/nc\npv 7." ></td>
	<td class="line x" title="114:180	{19} alt1,0;alt1,1 Villeroy and Boch turnstileleft npv 8." ></td>
	<td class="line x" title="115:180	{11,13-16} FD [collection] turnstileleft nc (3 4 >) 9." ></td>
	<td class="line x" title="116:180	{17-19} by V&B turnstileleft nc\nc (5 7 >) 10." ></td>
	<td class="line x" title="117:180	{17-19} V&B s turnstileleft npc/nc (7 6 <) 11." ></td>
	<td class="line x" title="118:180	{11,13-19} FD [coll.]" ></td>
	<td class="line x" title="119:180	by V&B turnstileleft nc (8 9 <) 12." ></td>
	<td class="line x" title="120:180	{11,13-19} V&B s FD [coll.]" ></td>
	<td class="line x" title="121:180	turnstileleft npc (10 8 >) 13." ></td>
	<td class="line x" title="122:180	{11-19} the FD [coll.]" ></td>
	<td class="line x" title="123:180	by V&B turnstileleft npc (2 11 >) {11-19} V&B s FD [coll.]" ></td>
	<td class="line x" title="124:180	turnstileleft npc (12 optC) 14." ></td>
	<td class="line x" title="125:180	{8-19} b. on [the FD [coll.]" ></td>
	<td class="line x" title="126:180	] turnstileleft sp\npd (1 13 >) Figure 4: Part of realization chart for Figure 1(c)." ></td>
	<td class="line x" title="127:180	exclusion constraints for the disjunction continue to be enforced." ></td>
	<td class="line x" title="128:180	Thus, for example, no attempt will be made to combine the edges for collection and series in (4a) and (4b), since they both express EP 11 and since they contribute to different alternatives in group 0." ></td>
	<td class="line x" title="129:180	Toenforcetheconstraintsassociatedwithactive alternatives, a compatibility check is made to ensure that if the input edges have active alternatives in the same group, the intersection of these alternatives is non-empty." ></td>
	<td class="line x" title="130:180	To illustrate, consider the edges for by and the possessive s in (4c) and (4d)." ></td>
	<td class="line x" title="131:180	Since these edges have different alternatives active within group 1, the compatibility check fails, and thus their combination is not attempted." ></td>
	<td class="line x" title="132:180	By contrast, the edge for Villeroy and Boch in (4e) will pass the compatibility check with both (4c) and (4d), as it shares an active alternative in common with each of these." ></td>
	<td class="line x" title="133:180	When two edges succeed in combining, a new edge is constructed from the resulting sign by taking the union of the coverage bit vectors, determining the active alternatives, and updating the coverage vector to include the EPs in any completed disjunctions." ></td>
	<td class="line x" title="134:180	When the grammars unary rules are applied to an edge, an operation is also invoked for creating an edge (for the same sign) with one or more optional parts marked as completed." ></td>
	<td class="line x" title="135:180	This operation is invoked when it would complete the input LF, complete an alternative, or complete an LF chunk.7 A constraint on its application is that the optional parts must be wholly missing from the inputedge; additionally, inthecaseofcompletingan alternative or LF chunk, the optional parts must be part of the alternative or chunk in question." ></td>
	<td class="line x" title="136:180	Figure 4 demonstrates how the lexical edges in (4)arecombinedinthechart.8 Theselexicaledges appear on lines 4-7." ></td>
	<td class="line x" title="137:180	Note that the edge for series is added as an alternative edge to the one for collection, which acts as a representative for both; to highlight its role as a representative, collection is shown in square brackets from line 8 onwards." ></td>
	<td class="line x" title="138:180	At the end of each line, the derivation of each (nonlexical) edge is shown in parentheses, in terms of its input edges and combinatory rule." ></td>
	<td class="line x" title="139:180	On line 13, observe that the NP using the possessive is added as an alternative to the one using the by-phrase; the possessive version becomes part of the same equivalence class when the optional determiner is marked as covered, via the optional part completion operation." ></td>
	<td class="line x" title="140:180	3.5 Unpacking Once chart construction has finished, the complete realizationsarerecursivelyunpackedbottom-upin a way that generalizes the approach of (Langkilde, 2000)." ></td>
	<td class="line x" title="141:180	Unpackingproceedsbymultiplyingoutthe alternative edges stored with the representative input edges; filtering out any duplicate edges resulting from spurious ambiguities; scoring the new edges with the scoring method configured via the API; and pruning the results with the configured pruning strategy." ></td>
	<td class="line x" title="142:180	Note that since there is no need for checking grammatical or other constraints during the unpacking stage, new edges can be quickly and cheaply constructed using structure sharing." ></td>
	<td class="line x" title="143:180	To briefly illustrate the process, consider how the Funny Day collection edge in line 8 of Figure 4 is unpacked." ></td>
	<td class="line x" title="144:180	While the Funny Day input edge has no alternative edges, the collection input edge has the series edge as an alternative, and thus a new Funny Day series edge will be created and scored; as long as the pruning strategy keeps more than the single-best option, this edge will be added as an alternative, and both combinations will be propagated upwards through the edges in lines 11 7LF chunks serve to avoid propagating semantically incomplete phrases; see (White, 2006) for discussion." ></td>
	<td class="line x" title="145:180	8To save space, the figure only shows part of the normal form derivation, and the logical forms for the categories have been suppressed." ></td>
	<td class="line x" title="146:180	17 10-best two-stage 1-best anytime time edges time edges disjunctive 1.1 602 0.5 281 sequential 5.6 3550 4.1 2854 Table 1: Comparison of average run times (in seconds) and edges created vs. sequential realization and 12." ></td>
	<td class="line x" title="147:180	4 Case Study To examine the potential of the algorithm to efficiently generate paraphrases, this section presents a case study of its run times versus sequential realization of the equivalent top-level LF alternatives in disjunctive normal form." ></td>
	<td class="line x" title="148:180	The study used the COMIC grammar, a small but not trivial grammar that suffices for the purposes of the system." ></td>
	<td class="line x" title="149:180	In this grammar, there are relatively few categories per lexeme on average, but the boundary tone categories engender a great deal of non-determinism." ></td>
	<td class="line x" title="150:180	With other grammars, run times can be expected to vary." ></td>
	<td class="line x" title="151:180	In anticipation of the present work, Foster and White (2004) generated disjunctive logical forms during sentence planning, then (as a stopgap measure) multiplied out the disjunctions and sequentially realized the top-level alternatives until an overall time limit was reached." ></td>
	<td class="line x" title="152:180	Taking the previous logical forms as a starting point, 104 sentences from the evaluation in (Foster and White, 2005) were selected, and their LFs were manually augmented to cover a greater range of paraphrases allowed by the grammar.9 To obtain the corresponding top-level LF alternatives, 100-best realization was performed, and the unique LFs appearing in the top 100 realizations were gathered; on average, there were 29 such unique LFs." ></td>
	<td class="line x" title="153:180	We then compared the present algorithms performance against sequential realization in producing 10-best outputs and single-best outputs." ></td>
	<td class="line x" title="154:180	In the 10-best case, we used the two-stage packing/unpacking mode; for the single-best case, we used the anytime mode with 3-best pruning." ></td>
	<td class="line x" title="155:180	With both cases, the run times include scoring with a trigram language model, and were measured on a 2.8GHz Linux PC." ></td>
	<td class="line x" title="156:180	Realization quality was not assessed as part of the study, though manual inspection indicated that it was very high." ></td>
	<td class="line x" title="157:180	Table 1 shows the results of the comparison." ></td>
	<td class="line x" title="158:180	9ExtendingtheCOMICsentenceplannertoproducethese augmented LFs is left for future work." ></td>
	<td class="line x" title="159:180	The average run times of the present algorithm, with disjunctive LFs as input, appear on the first line, along with the average number of edges created; on the second line are the average aggregate run times and num." ></td>
	<td class="line x" title="160:180	edges created of sequentially realizing the top-level alternatives (not including the time taken to produce these alternatives)." ></td>
	<td class="line x" title="161:180	As can be seen, realization from disjunctive inputs yields a 5-fold and 8-fold speedup over the sequential approach in the two cases, with corresponding reductions in the number of edges created." ></td>
	<td class="line x" title="162:180	Additionally, the run times appear to be adequate for use in interactive dialogue systems (especially in the anytime, single-best case)." ></td>
	<td class="line x" title="163:180	5 Comparison to Shemtov (1997) The present approach differs from Shemtovs in two main ways." ></td>
	<td class="line x" title="164:180	First, since Shemtov developed his approach with the task of ambiguity preserving translation in mind, he framed the problem as one of generating from ambiguous semantic representations, such as one might find in a parse chart with unresolved ambiguities." ></td>
	<td class="line x" title="165:180	Consequently, he devised a method for converting the meanings in a packed parse chart into an encoding where each fact (here, EP) appears exactly once, together with an indication of the meaning alternatives it belongs to, expressed as propositional formulas." ></td>
	<td class="line x" title="166:180	While this contexted facts encoding may be suitable for MT, it is not very convenient as an input representation for systems which generate from non-linguistic data, as the formulas representing the contexts only make sense in reference to a parse chart." ></td>
	<td class="line x" title="167:180	By contrast, the present approach takes as input disjunctive logical forms that should be reasonably intuitive to construct in dialogue systems or other NLG applications, since they are straightforwardly related to their non-disjunctive counterparts." ></td>
	<td class="line x" title="168:180	The second way in which the approach differs concerns the relative simplicity of the algorithms ultimately adopted." ></td>
	<td class="line x" title="169:180	As part of his preliminary algorithm (Shemtov, 1997, Section 3.3.2), Shemtov proposed the extended use of coverage bit vectors that we embraced in Section 3.2." ></td>
	<td class="line x" title="170:180	He then developed a refined version to handle disjunctions with intersecting predicates." ></td>
	<td class="line x" title="171:180	However, he concluded that this refined version was arc-consistent but not path-consistent (p. 65, fn." ></td>
	<td class="line x" title="172:180	10), given that it checked combinations of contexted facts pairwise, without keeping track of which alternations such 18 combinations were committed to." ></td>
	<td class="line x" title="173:180	By contrast, the present approach does not suffer from this defect, because it checks the alternative exclusion constraints on all of a lexical edges EPs at once (using bit vectors for both edge coverage and alternative membership), and also ensures that the active alternatives are compatible before combining edges during derivations." ></td>
	<td class="line x" title="174:180	Shemtov does not appear to have considered a solution along the lines proposed here; instead, he went on to develop a sound but considerably more complex algorithm (his Section 3.4), where an edges coverage bit vector is replaced with a contexted coverage array (an array of boolean conditions)." ></td>
	<td class="line x" title="175:180	With these arrays, itisnolongereasytogroupedgesintoequivalence classes, and thus during chart construction Shemtov is forced to group together edges which are not derivationally equivalent." ></td>
	<td class="line x" title="176:180	Consequently, to prevent overgeneration, his algorithm has to solve during the enumeration phase a system of constraints (potentially exponential in size) formed from the conditions in the contexted coverage arraysa process which is far from straightforward." ></td>
	<td class="line x" title="177:180	6 Conclusions This paper has presented a new chart realization algorithm for efficiently generating surface realizations from disjunctive logical forms, and has argued that the approach represents an improvement over that of (Shemtov, 1997) in terms of both usability and simplicity." ></td>
	<td class="line x" title="178:180	The algorithm has been implemented as an extension to the OpenCCG hybrid symbolic/statistical realizer, and has recently been employed to generate n-best realization lists for reranking according to their predicted synthesis quality (Nakatsu and White, 2006), as well as to generate dialogues exhibiting individuality and alignment(Brockmann et al. , 2005; Isard et al. , 2005)." ></td>
	<td class="line x" title="179:180	An initial case study has shown that the algorithm works many times faster than sequential realization, with run times suitable for use in dialogue systems; a more comprehensive study of the algorithms efficiency is planned for future work." ></td>
	<td class="line x" title="180:180	Acknowledgements The author thanks Mary Ellen Foster, Amy Isard, Johanna Moore, Mark Steedman and the anonymous reviewers for helpful feedback and discussion, and the University of Edinburghs Institute for Communicating and Collaborative Systems for partially supporting this work." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W06-1603
Paraphrase Recognition Via Dissimilarity Significance Classification
Qiu, Long;Kan, Min-Yen;Chua, Tat-Seng;"></td>
	<td class="line x" title="1:249	Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 1826, Sydney, July 2006." ></td>
	<td class="line x" title="2:249	c2006 Association for Computational Linguistics Paraphrase Recognition via Dissimilarity Signi cance Classi cation Long Qiu, Min-Yen Kan and Tat-Seng Chua Department of Computer Science National University of Singapore Singapore, 117543 {qiul,kanmy,chuats}@comp.nus.edu.sg Abstract We propose a supervised, two-phase framework to address the problem of paraphrase recognition (PR)." ></td>
	<td class="line x" title="3:249	Unlike most PR systems that focus on sentence similarity, our framework detects dissimilarities between sentences and makes its paraphrase judgment based on the signi cance of such dissimilarities." ></td>
	<td class="line x" title="4:249	The ability to differentiate signi cant dissimilarities not only reveals what makes two sentences a nonparaphrase, but also helps to recall additional paraphrases that contain extra but insigni cant information." ></td>
	<td class="line x" title="5:249	Experimental results show that while being accurate at discerning non-paraphrasing dissimilarities, our implemented system is able to achieve higher paraphrase recall (93%), at an overall performance comparable to the alternatives." ></td>
	<td class="line x" title="6:249	1 Introduction The task of sentence-level paraphrase recognition (PR) is to identify whether a set of sentences (typically, a pair) are semantically equivalent." ></td>
	<td class="line x" title="7:249	In such a task, equivalence takes on a relaxed meaning, allowing sentence pairs with minor semantic differences to still be considered as paraphrases." ></td>
	<td class="line x" title="8:249	PR can be thought of as synonym detection extended for sentences, and it can play an equally important role in natural language applications." ></td>
	<td class="line x" title="9:249	As with synonym detection, applications such as summarization can bene t from the recognition and canonicalization of concepts and actions that are shared across multiple documents." ></td>
	<td class="line x" title="10:249	Automatic construction of large paraphrase corpora could mine alternative ways to express the same concept, aiding machine translation and natural language generation applications." ></td>
	<td class="line x" title="11:249	In our work on sentence-level PR, we have identi ed two main issues through observation of sample sentences." ></td>
	<td class="line x" title="12:249	The rst is to identify all discrete information nuggets, or individual semantic content units, shared by the sentences." ></td>
	<td class="line x" title="13:249	For a pair of sentences to be deemed a paraphrase, they must share a substantial amount of these nuggets." ></td>
	<td class="line x" title="14:249	A trivial case is when both sentences are identical, word for word." ></td>
	<td class="line x" title="15:249	However, paraphrases often employ different words or syntactic structures to express the same concept." ></td>
	<td class="line x" title="16:249	Figure 1 shows two sentence pairs, in which the rst pair is a paraphrase while the second is not." ></td>
	<td class="line x" title="17:249	The paraphrasing pair (also denoted Paraphrase (+pp): Authorities said a young man injured Richard Miller." ></td>
	<td class="line x" title="18:249	Richard Miller was hurt by a young man. Non-Paraphrase (-pp): The technology-laced Nasdaq Composite Index.IXIC added 1.92 points, or 0.12 percent, at 1,647.94." ></td>
	<td class="line x" title="19:249	The technology-laced Nasdaq Composite Index .IXIC dipped 0.08 of a point to 1,646." ></td>
	<td class="line x" title="20:249	Figure 1: Examples: Paraphrasing & Nonparaphrasing as the +pp class) use different words." ></td>
	<td class="line x" title="21:249	Focusing just on the matrix verbs, we note differences between injured and hurt . A paraphrase recognition system should be able to detect such semantic similarities (despite the different syntactic structures)." ></td>
	<td class="line x" title="22:249	Otherwise, the two sentences could look even less similar than two non-paraphrasing sentences, such as the two in the second pair." ></td>
	<td class="line x" title="23:249	Also in the paraphrasing pair, the rst sentence includes an extra phrase Authorities said . Human annotators tend to regard the pair as a paraphrase despite the presence of this extra information nugget." ></td>
	<td class="line x" title="24:249	18 This leads to the second issue: how to recognize when such extra information is extraneous with respect to the paraphrase judgment." ></td>
	<td class="line x" title="25:249	Such paraphrases are common in daily life." ></td>
	<td class="line x" title="26:249	In news articles describing the same event, paraphrases are widely used, possibly with extraneous information." ></td>
	<td class="line x" title="27:249	We equate PR with solving these two issues, presenting a natural two-phase architecture." ></td>
	<td class="line x" title="28:249	In the rst phase, the nuggets shared by the sentences are identi ed by a pairing process." ></td>
	<td class="line x" title="29:249	In the second phase, any unpaired nuggets are classi ed as signi cant or not (leading to pp and +pp classi cations, respectively)." ></td>
	<td class="line x" title="30:249	If the sentences do not contain unpaired nuggets, or if all unpaired nuggets are insigni cant, then the sentences are considered paraphrases." ></td>
	<td class="line x" title="31:249	Experiments on the widely-used MSR corpus (Dolan et al. , 2004) show favorable results." ></td>
	<td class="line x" title="32:249	We rst review related work in Section 2." ></td>
	<td class="line x" title="33:249	We then present the overall methodology and describe the implemented system in Section 3." ></td>
	<td class="line x" title="34:249	Sections 4 and 5 detail the algorithms for the two phases respectively." ></td>
	<td class="line x" title="35:249	This is followed with our evaluation and discussion of the results." ></td>
	<td class="line x" title="36:249	2 Related Work Possibly the simplest approach to PR is an information retrieval (IR) based bag-of-words strategy." ></td>
	<td class="line x" title="37:249	This strategy calculates a cosine similarity score for the given sentence set, and if the similarity exceeds a threshold (either empirically determined or learned from supervised training data), the sentences are paraphrases." ></td>
	<td class="line x" title="38:249	PR systems that can be broadly categorized as IR-based include (Corley and Mihalcea, 2005; Brockett and Dolan, 2005)." ></td>
	<td class="line x" title="39:249	In the former work, the authors de ned a directional similarity formula re ecting the semantic similarity of one text with respect to another." ></td>
	<td class="line x" title="40:249	A word contributes to the directional similarity only when its counterpart has been identi ed in the opposing sentence." ></td>
	<td class="line x" title="41:249	The associated word similarity scores, weighted by the words speci city (represented as inverted document frequency, idf ), sum to make up the directional similarity." ></td>
	<td class="line x" title="42:249	The mean of both directions is the overall similarity of the pair." ></td>
	<td class="line x" title="43:249	Brockett and Dolan (2005) represented sentence pairs as a feature vector, including features (among others) for sentence length, edit distance, number of shared words, morphologically similar word pairs, synonym pairs (as suggested by WordNet and a semi-automatically constructed thesaurus)." ></td>
	<td class="line x" title="44:249	A support vector machine is then trained to learn the f+pp, ppg classi er." ></td>
	<td class="line x" title="45:249	Strategies based on bags of words largely ignore the semantic interactions between words." ></td>
	<td class="line x" title="46:249	Weeds et al.(2005) addressed this problem by utilizing parses for PR." ></td>
	<td class="line x" title="48:249	Their system for phrasal paraphrases equates paraphrasing as distributional similarity of the partial sub-parses of a candidate text." ></td>
	<td class="line x" title="49:249	Wu (2005)s approach relies on the generative framework of Inversion Transduction Grammar (ITG) to measure how similar two sentences arrange their words based on edit distance." ></td>
	<td class="line oc" title="50:249	Barzilay and Lee (2003) proposed to apply multiple-sequence alignment (MSA) for traditional, sentence-level PR." ></td>
	<td class="line o" title="51:249	Given multiple articles on a certain type of event, sentence clusters are rst generated." ></td>
	<td class="line o" title="52:249	Sentences within the same cluster, presumably similar in structure and content, are then used to construct a lattice with backbone nodes corresponding to words shared by the majority and slots corresponding to different realization of arguments." ></td>
	<td class="line o" title="53:249	If sentences from different clusters have shared arguments, the associated lattices are claimed to be paraphrase." ></td>
	<td class="line x" title="54:249	Likewise, Shinyama et al.(2002) extracted paraphrases from similar news articles, but use shared named entities as an indication of paraphrasing." ></td>
	<td class="line n" title="56:249	It should be noted that the latter two approaches are geared towards acquiring paraphrases rather than detecting them, and as such have the disadvantage of requiring a certain level of repetition among candidates for paraphrases to be recognized." ></td>
	<td class="line o" title="57:249	All past approaches invariably aim at a proper similarity measure that accounts for all of the words in the sentences in order to make a judgment for PR." ></td>
	<td class="line o" title="58:249	This is suitable for PR where input sentences are precisely equivalent semantically." ></td>
	<td class="line o" title="59:249	However, for many people the notion of paraphrases also covers cases in which minor or irrelevant information is added or omitted in candidate sentences, as observed in the earlier example." ></td>
	<td class="line o" title="60:249	Such extraneous content should not be a barrier to PR if the main concepts are shared by the sentences." ></td>
	<td class="line n" title="61:249	Approaches that focus only on the similarity of shared contents may fail when the (human) criteria for PR include whether the unmatched content is signi cant or not." ></td>
	<td class="line o" title="62:249	Correctly addressing this problem should increase accuracy." ></td>
	<td class="line x" title="63:249	In addition, if extraneous portions of sentences can be identi ed, their confounding in uence on the sentence similarity judgment can be removed, 19 leading to more accurate modeling of semantic similarity for both recognition and acquisition." ></td>
	<td class="line x" title="64:249	3 Methodology As noted earlier, for a pair of sentences to be a paraphrase, they must possess two attributes: 1." ></td>
	<td class="line x" title="65:249	similarity: they share a substantial amount of information nuggets; 2." ></td>
	<td class="line x" title="66:249	dissimilarities are extraneous: if extra information in the sentences exists, the effect of its removal is not signi cant." ></td>
	<td class="line x" title="67:249	A key decision for our two-phase PR framework is to choose the representation of an information nugget." ></td>
	<td class="line x" title="68:249	A simple approach is to use representative words as information nuggets, as is done in the SimFinder system (Hatzivassiloglou et al. , 2001)." ></td>
	<td class="line x" title="69:249	Instead of using words, we choose to equate information nuggets with predicate argument tuples." ></td>
	<td class="line x" title="70:249	A predicate argument tuple is a structured representation of a verb predicate together with its arguments." ></td>
	<td class="line x" title="71:249	Given a sentence from the example in Figure 1, its predicate argument tuple form in PropBank (Kingsbury et al. , 2002) format is: target(predicate): hurt arg0: a young man arg1: Richard Miller We feel that this is a better choice for the representation of a nugget as it accounts for the action, concepts and their relationships as a single unit." ></td>
	<td class="line x" title="72:249	In comparison, using ne-grained units such as words, including nouns and verbs may result in inaccuracy (sentences that share vocabulary may not be paraphrases), while using coarser-grained units may cause key differences to be missed." ></td>
	<td class="line x" title="73:249	In the rest of this paper, we use the term tuple for conciseness when no ambiguity is introduced." ></td>
	<td class="line x" title="74:249	An overview of our paraphrase recognition system is shown in Figure 2." ></td>
	<td class="line x" title="75:249	A pair of sentences is rst fed to a syntactic parser (Charniak, 2000) and then passed to a semantic role labeler (ASSERT; (Pradhan et al. , 2004)), to label predicate argument tuples." ></td>
	<td class="line x" title="76:249	We then calculate normalized tuple similarity scores over the tuple pairs using a metric that accounts for similarities in both syntactic structure and content of each tuple." ></td>
	<td class="line x" title="77:249	A thesaurus constructed from corpus statistics (Lin, 1998) is utilized for the content similarity." ></td>
	<td class="line x" title="78:249	We utilize this metric to greedily pair together the most similar predicate argument tuples across Figure 2: System architecture sentences." ></td>
	<td class="line x" title="79:249	Any remaining unpaired tuples represent extra information and are passed to a dissimilarity classi er to decide whether such information is signi cant." ></td>
	<td class="line x" title="80:249	The dissimilarity classi er uses supervised machine learning to make such a decision." ></td>
	<td class="line x" title="81:249	4 Similarity Detection and Pairing We illustrate this advantage of using predicate argument tuples from our running example." ></td>
	<td class="line x" title="82:249	In Table 1, one of the model sentences is shown in the middle column." ></td>
	<td class="line x" title="83:249	Two edited versions are shown on the left and right columns." ></td>
	<td class="line x" title="84:249	While it is clear that the left modi cation is an example of a paraphrase and the right is not, the version on the left involves more changes in its syntactic structure and vocabulary." ></td>
	<td class="line x" title="85:249	Standard word or syntactic similarity measures would assign the right modi cation a higher similarity score, likely mislabeling one or both modi cations." ></td>
	<td class="line x" title="86:249	In contrast, semantic role labeling identi es the dependencies between predicates and their arguments, allowing a more precise measurement of sentence similarity." ></td>
	<td class="line x" title="87:249	Assuming that the arguments in predicate argument tuples are assigned the same role when their roles are comparable1, we de ne the similarity score of two tuples Ta and Tb as the weighted sum of the pairwise similarities of all their shared constituents C=f(ca,cb)g (c being either the target or one of the arguments that both 1ASSERT, which is trained on the Propbank, only guarantees consistency of arg0 and arg1 slots, but we have found in practice that aligning arg2 and above arguments do not cause problems." ></td>
	<td class="line x" title="88:249	20 Modi cation 1: paraphrase Model Sentence Modi cation 2: non-paraphrase Sentence Richard Miller was hurt by a young man. Authorities said a young man injured Richard Miller." ></td>
	<td class="line x" title="89:249	Authorities said Richard Miller injured a young man." ></td>
	<td class="line x" title="90:249	(Paired) Tuples target: said arg0: Authorities arg1: a young man injured Richard Miller target: said arg0: Authorities arg1: Richard Miller injured a young man target: hurt arg0: a young man arg1: Richard Miller target: injured arg0: a young man arg1: Richard Miller target: injured arg0: Richard Miller arg1: a young man Table 1: Similarity Detection: pairing of predicate argument tuples tuples have): Sim(Ta, Tb) = 1 X Sim(ca, cb) c={target,argshared} wc==targettarget (1) where normalization factor  is the sum of the weights of constituents in C, i.e.:  = bardblargshared}bardbl + wtarget (2) In our current implementation we reduce targets and their arguments to their syntactic headwords." ></td>
	<td class="line x" title="91:249	These headwords are then directly compared using a corpus-based similarity thesaurus." ></td>
	<td class="line x" title="92:249	As we hypothesized that targets are more important for predicate argument tuple similarity, we multiply the targets similarity by a weighting factor wtarget, whose value we have empirically determined as 1.7, based on a 300-pair development set from the MSR training set." ></td>
	<td class="line x" title="93:249	We then proceed to pair tuples in the two sentences using a greedy iterative algorithm." ></td>
	<td class="line x" title="94:249	The algorithm locates the two most similar tuples from each sentence, pairs them together and removes them from futher consideration." ></td>
	<td class="line x" title="95:249	The process stops when subsequent best pairings are below the similarity threshold or when all possible tuples are exhausted." ></td>
	<td class="line x" title="96:249	If unpaired tuples still exist in a given sentence pair, we further examine the copular constructions and noun phrases in the opposing sentence for possible pairings2." ></td>
	<td class="line x" title="97:249	This results in a one2Copular constructions are not handled by ASSERT." ></td>
	<td class="line x" title="98:249	Such constructions account for a large proportion of the semantic meaning in sentences." ></td>
	<td class="line x" title="99:249	Consider the pair Microsoft rose 50 cents and Microsoft was up 50 cents, in which the second is in copular form." ></td>
	<td class="line x" title="100:249	Similarly, NPs can often be equivalent to predicate argument tuples when actions are nominalized." ></td>
	<td class="line x" title="101:249	Consider an NP that reads (be blamed for) frequent attacks on soldiers and a predicate argument tuple: (be blamed for) attacking soldiers . Again, identical information is conveyed but not captured by semantic role labeling." ></td>
	<td class="line x" title="102:249	In such cases, they can be paired if we allow a candidate tuple to pair with the predicative argument (e.g. , 50 cents) of a copula, or (the head of) an NP in the opposing sentence." ></td>
	<td class="line x" title="103:249	As these heuristic matches may introduce errors, we resort to these methods of matching tuple only in the contingency when there are unpaired tuples." ></td>
	<td class="line x" title="104:249	to-one mapping with possibly some tuples left unpaired." ></td>
	<td class="line x" title="105:249	The curved arrows in Table 1 denote the correct results of similarity pairing: two tuples are paired up if their target and shared arguments are identical or similar respectively, otherwise they remain unpaired even if the bag of words they contain are the same." ></td>
	<td class="line x" title="106:249	5 Dissimilarity Signi cance Classi cation If some tuples remain unpaired, they are dissimilar parts of the sentence that need to be labeled by the dissimilarity classi er." ></td>
	<td class="line x" title="107:249	Such unpaired information could be extraneous or they could be semantically important, creating a barrier for paraphrase." ></td>
	<td class="line x" title="108:249	We frame this as a supervised machine learning problem in which a set of features are used to inform the classi er." ></td>
	<td class="line x" title="109:249	A support vector machine, SVMLight, was chosen as the learning model as it has shown to yield good performance over a wide application range." ></td>
	<td class="line x" title="110:249	We experimented with a wide set of features of unpaired tuples, including internal counts of numeric expressions, named entities, words, semantic roles, whether they are similar to other tuples in the same sentence, and contextual features like source/target sentence length and paired tuple count." ></td>
	<td class="line x" title="111:249	Currently, only two features are correlated in improved classi cation, which we detail now." ></td>
	<td class="line x" title="112:249	Syntactic Parse Tree Path: This is a series of features that re ect how the unpaired tuple connects with the context: the rest of the sentence." ></td>
	<td class="line x" title="113:249	It models the syntactic connection between the constituents on both ends of the path (Gildea and Palmer, 2002; Pradhan et al. , 2004)." ></td>
	<td class="line x" title="114:249	Here, we model the ends of the path as the unpaired tuple and the paired tuple with the closest shared ancestor, and model the path itself as a sequence of constituent category tags and directions to reach the destination (the paired target) from the source (the 21 unpaired target) via the the shared ancestor." ></td>
	<td class="line x" title="115:249	When no tuples have been paired in the sentence pair, the destination defaults to the root of the syntactic parse tree." ></td>
	<td class="line x" title="116:249	For example, the tuples with target injured are unpaired when the model sentence and the non-paraphrasing modi cation in Table 1 are being compared." ></td>
	<td class="line x" title="117:249	A path 'V BD,'V P,'S,'SBAR,'V P,#V BD links a target injured to the paired target said, as shown in Figure 3." ></td>
	<td class="line x" title="118:249	VPa96a96a96 a96a96a32a32a32a32a32VBD said SBAR Sa88a88 a88a88a24a24a24a24NP a97a97a33a33 NNP Richard NNP Miller VPa98 a98a34a34VBD injured NP Figure 3: Syntactic parse tree path The syntactic path can act as partial evidence in signi cance classi cation." ></td>
	<td class="line x" title="119:249	In the above example, the category tag V BD assigned to injured indicates that the verb is in its past tense." ></td>
	<td class="line x" title="120:249	Such a predicate argument tuple bears the main content of the sentence and generally can not be ignored if its meaning is missing in the opposing sentence." ></td>
	<td class="line x" title="121:249	Another example is shown in Figure 4." ></td>
	<td class="line x" title="122:249	The second sentence has one unpaired target proposed while the rest all nd their counterpart." ></td>
	<td class="line x" title="123:249	The path we get from the syntactic parse tree reads 'V BN,'NP,'S,,, showing that the unpaired tuple (consisting of a single predicate) is a modi er contained in an NP." ></td>
	<td class="line x" title="124:249	It can be ignored if there is no contradiction in the opposing sentence." ></td>
	<td class="line x" title="125:249	We represent a syntactic path by a set of n-gram (n 4) features of subsequences of category tags found in the path, along with the respective direction." ></td>
	<td class="line x" title="126:249	We require these n-gram features to be no more than four category tags away from the unpaired target, as our primary concern is to model what role the target plays in its sentence." ></td>
	<td class="line x" title="127:249	Sheena Young of Child, the national infertility support network, hoped the guidelines would lead to a more fair and equitable service for infertility sufferers." ></td>
	<td class="line x" title="128:249	Sheena Young, a spokesman for Child, the national infertility support network, said the proposed guidelines should lead to a more fair and equitable service for infertility sufferers." ></td>
	<td class="line x" title="129:249	Figure 4: Unpaired predicate argument tuple as modi er in a paraphrase Predicate: This is the lexical token of predicate argument tuples target, as a text feature." ></td>
	<td class="line x" title="130:249	As this feature is liable to run into sparse data problems, the semantic category of the target would be a more suitable feature." ></td>
	<td class="line x" title="131:249	However, verb similarity is generally regarded as dif cult to measure, both in terms of semantic relatedness as well as in nding a consistent granularity for verb categories." ></td>
	<td class="line x" title="132:249	We investigated using WordNet as well as Levins classi cation (Levin, 1993) as additional features on our validation data, but currently nd that using the lexical form of the target works best." ></td>
	<td class="line x" title="133:249	5.1 Classi er Training Set Acquisition Currently, no training corpus for predicate argument tuple signi cance exists." ></td>
	<td class="line x" title="134:249	Such a corpus is indispensable for training the classi er." ></td>
	<td class="line x" title="135:249	Rather than manually annotating training instances, we use an automatic method to construct instances from paraphrase corpora." ></td>
	<td class="line x" title="136:249	This is possible as the paraphrase judgments in the corpora can imply which portion of the sentence(s) are signi cant barriers to paraphrasing or not." ></td>
	<td class="line x" title="137:249	Here, we exploit the similarity detector implemented for the rst phase for this purpose." ></td>
	<td class="line x" title="138:249	If unpaired tuples exist after greedy pairing, we classify them along two dimensions: whether the sentence pair is a (non-)paraphrase, and the source of the unpaired tuples: 1." ></td>
	<td class="line x" title="139:249	[PS] paraphrasing pairs and unpaired predicate argument tuples are only from a single sentence; 2." ></td>
	<td class="line x" title="140:249	[NS] non-paraphrasing pairs and only one single unpaired predicate argument tuple exists; 3." ></td>
	<td class="line x" title="141:249	[PM] paraphrasing pairs and unpaired predicate argument tuples are from multiple (both) sentences; 4." ></td>
	<td class="line x" title="142:249	[NM] non-paraphrasing pairs and multiple unpaired predicate argument tuples (from either one or both sentences) exist." ></td>
	<td class="line x" title="143:249	Assuming that similarity detector pairs tuples correctly, for the rst two categories, the paraphrasing judgment is directly linked to the unpaired tuples." ></td>
	<td class="line x" title="144:249	PS tuple instances are therefore used as insignificant class instances, and NS as significant ones." ></td>
	<td class="line x" title="145:249	The last two categories cannot be used for training data, as it is unclear which of the unpaired tuples is responsible for the (non-) paraphrasing as the similarity measure may mistakenly leave some similar predicate argument tuples unpaired." ></td>
	<td class="line x" title="146:249	6 Evaluation The goal of our evaluation is to show that our system can reliably determine the cause(s) of non22 MSR Corpus Label +pp -pp system prediction correct?" ></td>
	<td class="line x" title="147:249	T F T F total # sentence pairs (s-ps) 85 23 55 37 200 # labelings (H&C agree) 80 19 53 35 187 # tuple pairs (t-ps) (S) 80 6 36 35 157 # correct t-ps (H&S agree) 74 6 34 30 144 # missed t-ps (H) 11 10 5 5 31 # sig." ></td>
	<td class="line x" title="148:249	unpaired tuples(H) 6 4 69 51 130 # sig." ></td>
	<td class="line x" title="149:249	unpaired tuples(S) 0 32 70 0 102 # sig." ></td>
	<td class="line x" title="150:249	unpaired tuples(H&S) 0 4 43 0 47 # -pp for other reasons 0 0 5 2 7 Table 2: (H)uman annotations vs." ></td>
	<td class="line x" title="151:249	(C)orpus annotations and (S)ystem output paraphrase examples, while maintaining the performance level of the state-of-the-art PR systems." ></td>
	<td class="line x" title="152:249	For evaluation, we conduct both component evaluations as well as a holistic one, resulting in three separate experiments." ></td>
	<td class="line x" title="153:249	In evaluating the rst tuple pairing component, we aim for high precision, so that sentences that have all tuples paired can be safely assumed to be paraphrases." ></td>
	<td class="line x" title="154:249	In evaluating the dissimilarity classi er, we simply aim for high accuracy." ></td>
	<td class="line x" title="155:249	In our overall system evaluation, we compare our system versus other PR systems on standard corpora." ></td>
	<td class="line x" title="156:249	Experimental Data Set." ></td>
	<td class="line x" title="157:249	For these experiments, we utilized two widely-used corpora for paraphrasing evaluation: the MSR and PASCAL RTE corpora." ></td>
	<td class="line x" title="158:249	The Microsoft Research Paraphrase coupus (Dolan et al. , 2004) consists of 5801 newswire sentence pairs, 3900 of which are annotated as semantically equivalent by human annotators." ></td>
	<td class="line x" title="159:249	It re ects ordinary paraphrases that people often encounter in news articles, and may be viewed as a typical domain-general paraphrase recognition task that downstream NLP systems will need to deal with." ></td>
	<td class="line x" title="160:249	The corpus comes divided into standard training (70%) and testing (30%) divisions, a partition we follow in our experiments." ></td>
	<td class="line x" title="161:249	ASSERT (the semantic role labeler) shows for this corpus a sentence contains 2.24 predicate argument tuples on average." ></td>
	<td class="line x" title="162:249	The second corpus is the paraphrase acquisition subset of the PASCAL Recognizing Textual Entailment (RTE) Challenge corpus (Dagan et al. , 2005)." ></td>
	<td class="line x" title="163:249	This is much smaller, consisting of 50 pairs, which we employ for testing only to show portability." ></td>
	<td class="line x" title="164:249	To assess the component performance, we need additional ground truth beyond the f+pp, ppg labels provided by the corpora." ></td>
	<td class="line x" title="165:249	For the rst evaluation, we need to ascertain whether a sentence pairs tuples are correctly paired, misidenti ed or mispaired." ></td>
	<td class="line x" title="166:249	For the second, which tuple(s) (if any) are responsible for a pp instance." ></td>
	<td class="line x" title="167:249	However, creating ground truth by manual annotation is expensive, and thus we only sampled the data set to get an indicative assessment of performance." ></td>
	<td class="line x" title="168:249	We sampled 200 random instances from the total MSR testing set, and rst processed them through our framework." ></td>
	<td class="line x" title="169:249	Then, ve human annotators (two authors and three volunteers) annotated the ground truth for tuple pairing and the semantic signi cance of the unpaired tuples, while checking system output." ></td>
	<td class="line x" title="170:249	They also independently came up with their own f+pp,-ppg judgment so we could assess the reliability of the provided annotations." ></td>
	<td class="line x" title="171:249	The results of this annotation is shown in Table 2." ></td>
	<td class="line x" title="172:249	Examining this data, we can see that the similarity detector performs well, despite its simplicity and assumption of a one-to-one mapping." ></td>
	<td class="line x" title="173:249	Out of the 157 predicate argument tuple pairs identi ed through similarity detection, annotators agreed that 144 (92%) are semantically similar or equivalent." ></td>
	<td class="line x" title="174:249	However, 31 similar pairs were missed by the system, resulting in 82% recall." ></td>
	<td class="line x" title="175:249	We defer discussion on the other details of this table to Section 7." ></td>
	<td class="line x" title="176:249	To assess the dissimilarity classi er, we focus on the pp subset of 55 instances recognized by the system." ></td>
	<td class="line x" title="177:249	For 43 unpaired tuples from 40 sentence pairs (73% of 55), the annotators judgments agree with the classi ers claim that they are signi cant." ></td>
	<td class="line x" title="178:249	For these cases, the system is able to both recognize that the sentence pair is not a paraphrase and further correctly establish a cause of the nonparaphrase." ></td>
	<td class="line x" title="179:249	In addition to this ground truth sampled evaluation, we also show the effectiveness of the classi er by examining its performance on PS and NS tuples in the MSR corpus as described in Section 5." ></td>
	<td class="line x" title="180:249	The test set consists of 413 randomly selected PS and NS instances among which 145 are significant (leading to non-paraphrases)." ></td>
	<td class="line x" title="181:249	The classi er predicts predicate argument tuple signi cance at an accuracy of 71%, outperforms a majority classi er (65%), a gain which is marginally statistically signi cant (p < .09)." ></td>
	<td class="line x" title="182:249	signi cant insigni cant 112 263 insigni cant by classi er 33 5 signi cant by classi er We can see the classi er classi es the majority of insigni cant tuples correctly (by outputting a 23 709 Sentence Pairs Without 1016 Sentence Pairs With Unpaired Tuples Unpaired Tuples Overall Algorithm (41.1% of Test set) (58.9% of Test set) (100% of Test set) Acc R P Acc R P Acc R P F1 Majority Classi er 79.5% 100% 79.5% 57.4% 100% 57.4% 66.5% 100% 66.5% 79.9% SimFinder 82.2% 92.2% 86.4% 66.3% 84.9% 66.1% 72.9% 88.5% 75.1% 81.3% CM05 71.5% 92.5% 72.3% 81.2% Our System 79.5% 100% 79.5% 66.7% 87.0% 66.0% 72.0% 93.4% 72.5% 81.6% Table 3: Results on MSR test set 17 Sentence Pairs Without 33 Sentence Pairs With Algorithm Unpaired Tuples Unpaired Tuples Overall (34% of Test set) (66% of Test set) (100% of Test set) Acc R P Acc R P Acc R P F1 Majority Classi er 65% 100% 65% 42% 100% 42% 50% 100% 50% 67% SimFinder 71% 91% 71% 42% 21% 27% 52% 52% 52% 52% Our System 65% 100% 65% 48% 64% 43% 54% 80% 53% 64% Table 4: Results on PASCAL PP test set score greater than zero), which is effectively a 98% recall of insigni cant tuples." ></td>
	<td class="line x" title="183:249	However, the precision is less satisfatory." ></td>
	<td class="line x" title="184:249	We suspect this is partially due the tuples that fail to be paired up with their counterpart." ></td>
	<td class="line x" title="185:249	Such noise is found among the automatically collected PS instances used in training." ></td>
	<td class="line x" title="186:249	0 20 40 60 80 100 120 140 160 180 > .5 -0." ></td>
	<td class="line x" title="187:249	5 -0 .25 -.2 5 0 0 .2 5 .25 . 5 .5 .7 5 .75 1 < 1 SVM Prediction F r e q u e n c y Insignificant Significant Figure 5: Dissimilarity classi er performance For the nal system-wide evaluation, we implemented two baseline systems: a majority classi er and SimFinder (Hatzivassiloglou et al. , 2001), a bag-of-words sentence similarity module incorporating lexical, syntactic and semantic features." ></td>
	<td class="line x" title="188:249	In Table 3, precision and recall are measured with respect to the paraphrasing class." ></td>
	<td class="line x" title="189:249	The table shows sentence pairs falling under the column pairs without unpaired tuples are more likely to be paraphrasing than an arbitrary pair (79.5% versus 66.5%), providing further validation for using predicate argument tuples as information nuggets." ></td>
	<td class="line x" title="190:249	The results for the experiment benchmarking the overall system performance are shown under the Overall column: our approach performs comparably to the baselines at both accuracy and paraphrase recall." ></td>
	<td class="line x" title="191:249	The system performance reported in (CM05; (Corley and Mihalcea, 2005)), which is among the best we are aware of, is also included for comparison." ></td>
	<td class="line x" title="192:249	We also ran our system (trained on the MSR corpus) on the 50 instances in the PASCAL paraphrase acquisition subset." ></td>
	<td class="line x" title="193:249	Again, the system performance (as shown in Table 4) is comparable to the baseline systems." ></td>
	<td class="line x" title="194:249	7 Discussion We have just shown that when two sentences have perfectly matched predicate argument tuples, they are more likely to be a paraphrase than a random sentence pair drawn from the corpus." ></td>
	<td class="line x" title="195:249	Furthermore, in the sampled human evaluation in Table 2, among the 88 non-paraphrasing instances with whose MSR corpus labels our annotators agreed (53 correctly and 35 incorrectly judged by our system), the cause of the pp is correctly attributed in 81 cases to one or more predicate argument tuples." ></td>
	<td class="line x" title="196:249	The remaining 7 cases (as shown in the last row) are caused by phenomenon that are not captured by our tuple representation." ></td>
	<td class="line x" title="197:249	We feel this justi es using predicate argument tuples as information nuggets, but we are currently considering expanding our representation to account for some of these cases." ></td>
	<td class="line x" title="198:249	The evaluation also con rms the dif culty of making paraphrase judgements." ></td>
	<td class="line x" title="199:249	Although the 24 MSR corpus used strict means of resolving interrater disagreements during its construction, the annotators agreed with the MSR corpus labels only 93.5% (187/200) of the time." ></td>
	<td class="line x" title="200:249	One weakness of our system is that we rely on a thesaurus (Lin, 1998) for word similarity information for predicate argument tuple pairing." ></td>
	<td class="line x" title="201:249	However, it is designed to provide similarity scores between pairs of individual words (rather than phrases)." ></td>
	<td class="line x" title="202:249	If a predicate argument tuples target or one argument is realized as a phrase (borrow ! check out, for instance), the thesaurus is unable to provide an accurate similarity score." ></td>
	<td class="line x" title="203:249	For similarity between predicate argument tuples, negation and modality have yet to be addressed, although they account for only a tiny fraction of the corpus." ></td>
	<td class="line x" title="204:249	We further estimated how the similarity detector can be affected when the semantic role labeler makes mistakes (by failing to identify arguments or assigning incorrect role names)." ></td>
	<td class="line x" title="205:249	Checking 94 pairs ground-truth similar tuples, we found that the system mislabels 43 of them." ></td>
	<td class="line x" title="206:249	The similarity detector failed to pair around 30% of them." ></td>
	<td class="line x" title="207:249	In comparsion, all the tuple pairs free of labeling errors are correctly paired." ></td>
	<td class="line x" title="208:249	A saving grace is that labeling errors rarely lead to incorrect pairing (one pairing in all the examined sentences)." ></td>
	<td class="line x" title="209:249	The labeling errors impact the whole system in two ways: 1) they caused similar tuples that should have been paired up to be added as noise in that dissimilarity classi ers training set and 2) paired tuples with labeling errors erroneously increase the target weight in Equation (1)." ></td>
	<td class="line x" title="210:249	Some example paraphrasing cases that are problematic for our current system are: 1." ></td>
	<td class="line x" title="211:249	Non-literal language issues such as implicature, idiom, metaphor, etc. are not addressed in our current system." ></td>
	<td class="line x" title="212:249	When predicate argument tuples imply each other, they are less similar than what our system currently is trained for, causing the pairing to fail: +pp, Later in the day, a standoff developed between French soldiers and a Hema battlewagon that attempted to pass the UN compound." ></td>
	<td class="line x" title="213:249	French soldiers later threatened to open re on a Hema battlewagon that tried to pass near the UN compound." ></td>
	<td class="line x" title="214:249	2." ></td>
	<td class="line x" title="215:249	A paraphrasing pair may exceed the systems threshold for syntactic difference: +pp, With the exception of dancing, physical activity did not decrease the risk." ></td>
	<td class="line x" title="216:249	Dancing was the only physical activity associated with a lower risk of dementia." ></td>
	<td class="line x" title="217:249	3." ></td>
	<td class="line x" title="218:249	One or more unpaired tuples exist, but their signi cance is not inferred correctly: +pp, Inhibited children tend to be timid with new people, objects, and situations, while uninhibited children spontaneously approach them." ></td>
	<td class="line x" title="219:249	Simply put, shy individuals tend to be more timid with new people and situations." ></td>
	<td class="line x" title="220:249	In the MSR corpus, the rst error case is more frequent than the other two." ></td>
	<td class="line x" title="221:249	We identify these as challenging cases where idiomatic processing is needed." ></td>
	<td class="line x" title="222:249	Below we show some unpaired predicate argument tuples (underlined) that are signi cant enough to be paraphrase barriers." ></td>
	<td class="line x" title="223:249	These examples give an indicative categorization of what signi cant tuples are and their corpus frequency (when predicate argument tuples are the reasons; we examined 40 such cases for this estimation)." ></td>
	<td class="line x" title="224:249	There is one thing in common: every case involves substantial information that is dif cult to infer from context." ></td>
	<td class="line x" title="225:249	Such tuples appear as: 1." ></td>
	<td class="line x" title="226:249	(40%) The nucleus of the sentence (often the matrix tuple): Michael Hill, a Sun reporter who is a member of the Washington-Baltimore Newspaper Guilds bargaining committee, estimated meetings to last late Sunday." ></td>
	<td class="line x" title="227:249	2." ></td>
	<td class="line x" title="228:249	(30%) A part of a coordination: Security lights have also been installed and police have swept the grounds for booby traps." ></td>
	<td class="line x" title="229:249	3." ></td>
	<td class="line x" title="230:249	(13%) A predicate of a modifying clause: Westermayer was 26 then, and a friend and former manager who knew she was unhappy in her job tipped her to another position." ></td>
	<td class="line x" title="231:249	4." ></td>
	<td class="line x" title="232:249	(7%) An adjunct: While waiting for a bomb squad to arrive, the bomb exploded, killing Wells." ></td>
	<td class="line x" title="233:249	5." ></td>
	<td class="line x" title="234:249	(7%) An embedded sentence: Dean told reporters traveling on his 10-city Sleepless Summer tour that he considered campaigning in Texas a challenge." ></td>
	<td class="line x" title="235:249	6." ></td>
	<td class="line x" title="236:249	(3%) Or factual content that con icts with the opposing sentence: Total sales for the period declined 8.0 percent to USD1.99 billion from a year earlier." ></td>
	<td class="line x" title="237:249	Wal-Mart said sales at stores open at least a year rose 4.6 percent from a year earlier." ></td>
	<td class="line x" title="238:249	8 Conclusions We have proposed a new approach to the paraphrase recognition (PR) problem: a supervised, 25 two-phase framework emphasizing dissimilarity classi cation." ></td>
	<td class="line x" title="239:249	To emulate human PR judgment in which insigni cant, extraneous information nuggets are generally allowed for a paraphrase, we estimate whether such additional information nuggets affect the nal paraphrasing status of a sentence pair." ></td>
	<td class="line x" title="240:249	This approach, unlike previous PR approaches, has the key bene t of explaining the cause of a non-paraphrase sentence pair." ></td>
	<td class="line x" title="241:249	In the rst, similarity detection module, using predicate argument tuples as the unit for comparison, we pair them up in a greedy manner." ></td>
	<td class="line x" title="242:249	Unpaired tuples thus represent additional information unrepresented in the opposing sentence." ></td>
	<td class="line x" title="243:249	A second, dissimilarity classi cation module uses the lexical head of the predicates and the tuples path of attachment as features to decide whether such tuples are barriers to paraphrase." ></td>
	<td class="line x" title="244:249	Our evaluations show that the system obtains 1) high accuracy for the similarity detector in pairing predicate argument tuples, 2) robust dissimilarity classi cation despite noisy training instances and 3) comparable overall performance to current state-of-the-art PR systems." ></td>
	<td class="line x" title="245:249	To our knowledge this is the rst work that tackles the problem of identifying what factors stop a sentence pair from being a paraphrase." ></td>
	<td class="line x" title="246:249	We also presented corpus examples that illustrate the categories of errors that our framework makes, suggesting future work in PR." ></td>
	<td class="line x" title="247:249	While we continue to explore more suitable representation of unpaired predicate argument tuples, we plan to augment the similarity measure for phrasal units to reduce the error rate in the rst component." ></td>
	<td class="line x" title="248:249	Another direction is to detect semantic redundancy in a sentence." ></td>
	<td class="line x" title="249:249	Unpaired tuples that are semantically redundant should also be regarded as insigni cant." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P07-1058
Instance-based Evaluation of Entailment Rule Acquisition
Szpektor, Idan;Shnarch, Eyal;Dagan, Ido;"></td>
	<td class="line x" title="1:205	Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 456463, Prague, Czech Republic, June 2007." ></td>
	<td class="line x" title="2:205	c2007 Association for Computational Linguistics Instance-based Evaluation of Entailment Rule Acquisition Idan Szpektor, Eyal Shnarch, Ido Dagan Dept. of Computer Science Bar Ilan University Ramat Gan, Israel {szpekti,shey,dagan}@cs.biu.ac.il Abstract Obtaining large volumes of inference knowledge, such as entailment rules, has become a major factor in achieving robust semantic processing." ></td>
	<td class="line x" title="3:205	While there has been substantial research on learning algorithms for such knowledge, their evaluation methodology has been problematic, hindering further research." ></td>
	<td class="line x" title="4:205	We propose a novel evaluation methodology for entailment rules which explicitly addresses their semantic properties and yields satisfactory human agreement levels." ></td>
	<td class="line x" title="5:205	The methodology is used to compare two state of the art learning algorithms, exposing critical issues for future progress." ></td>
	<td class="line x" title="6:205	1 Introduction In many NLP applications, such as Question Answering (QA) and Information Extraction (IE), it is crucial to recognize that a particular target meaning can be inferred from different text variants." ></td>
	<td class="line x" title="7:205	For example, a QA system needs to identify that Aspirin lowers the risk of heart attacks can be inferred from Aspirin prevents heart attacks in order to answer the question What lowers the risk of heart attacks?." ></td>
	<td class="line x" title="8:205	This type of reasoning has been recognized as a core semantic inference task by the generic textual entailment framework (Dagan et al. , 2006)." ></td>
	<td class="line x" title="9:205	A major obstacle for further progress in semantic inference is the lack of broad-scale knowledgebases for semantic variability patterns (Bar-Haim et al. , 2006)." ></td>
	<td class="line x" title="10:205	One prominent type of inference knowledge representation is inference rules such as paraphrases and entailment rules." ></td>
	<td class="line x" title="11:205	We define an entailment rule to be a directional relation between two templates, text patterns with variables, e.g. X prevent Y  X lower the risk of Y ." ></td>
	<td class="line x" title="12:205	The left-handside template is assumed to entail the right-handside template in certain contexts, under the same variable instantiation." ></td>
	<td class="line x" title="13:205	Paraphrases can be viewed as bidirectional entailment rules." ></td>
	<td class="line x" title="14:205	Such rules capture basic inferences and are used as building blocks for more complex entailment inference." ></td>
	<td class="line x" title="15:205	For example, given the above rule, the answer Aspirin can be identified in the example above." ></td>
	<td class="line x" title="16:205	The need for large-scale inference knowledgebases triggered extensive research on automatic acquisition of paraphrase and entailment rules." ></td>
	<td class="line x" title="17:205	Yet the current precision of acquisition algorithms is typically still mediocre, as illustrated in Table 1 for DIRT (Lin and Pantel, 2001) and TEASE (Szpektor et al. , 2004), two prominent acquisition algorithms whose outputs are publicly available." ></td>
	<td class="line x" title="18:205	The current performance level only stresses the obvious need for satisfactory evaluation methodologies that would drive future research." ></td>
	<td class="line x" title="19:205	The prominent approach in the literature for evaluating rules, termed here the rule-based approach, is to present the rules to human judges asking whether each rule is correct or not." ></td>
	<td class="line x" title="20:205	However, it is difficult to explicitly define when a learned rule should be considered correct under this methodology, and this was mainly left undefined in previous works." ></td>
	<td class="line x" title="21:205	As the criterion for evaluating a rule is not well defined, using this approach often caused low agreement between human judges." ></td>
	<td class="line x" title="22:205	Indeed, the standards for evaluation in this field are lower than other fields: many papers 456 dont report on human agreement at all and those that do report rather low agreement levels." ></td>
	<td class="line x" title="23:205	Yet it is crucial to reliably assess rule correctness in order to measure and compare the performance of different algorithms in a replicable manner." ></td>
	<td class="line x" title="24:205	Lacking a good evaluation methodology has become a barrier for further advances in the field." ></td>
	<td class="line x" title="25:205	In order to provide a well-defined evaluation methodology we first explicitly specify when entailment rules should be considered correct, following the spirit of their usage in applications." ></td>
	<td class="line x" title="26:205	We then propose a new instance-based evaluation approach." ></td>
	<td class="line x" title="27:205	Under this scheme, judges are not presented only with the rule but rather with a sample of sentences that match its left hand side." ></td>
	<td class="line x" title="28:205	The judges then assess whether the rule holds under each specific example." ></td>
	<td class="line x" title="29:205	A rule is considered correct only if the percentage of examples assessed as correct is sufficiently high." ></td>
	<td class="line x" title="30:205	We have experimented with a sample of input verbs for both DIRT and TEASE." ></td>
	<td class="line x" title="31:205	Our results show significant improvement in human agreement over the rule-based approach." ></td>
	<td class="line x" title="32:205	It is also the first comparison between such two state-of-the-art algorithms, which showed that they are comparable in precision but largely complementary in their coverage." ></td>
	<td class="line x" title="33:205	Additionally, the evaluation showed that both algorithms learn mostly one-directional rules rather than (symmetric) paraphrases." ></td>
	<td class="line x" title="34:205	While most NLP applications need directional inference, previous acquisition works typically expected that the learned rules would be paraphrases." ></td>
	<td class="line x" title="35:205	Under such an expectation, unidirectional rules were assessed as incorrect, underestimating the true potential of these algorithms." ></td>
	<td class="line x" title="36:205	In addition, we observed that many learned rules are context sensitive, stressing the need to learn contextual constraints for rule applications." ></td>
	<td class="line x" title="37:205	2 Background: Entailment Rules and their Evaluation 2.1 Entailment Rules An entailment rule LR is a directional relation between two templates, L and R. For example, X acquire Y X own Y  or X beat Y  X play against Y ." ></td>
	<td class="line x" title="38:205	Templates correspond to text fragments with variables, and are typically either linear phrases or parse sub-trees." ></td>
	<td class="line x" title="39:205	The goal of entailment rules is to help applicaInput Correct Incorrect () X modify Y X adopt Y X change Y () X amend Y X create Y (DIRT) () X revise Y X stick to Y () X alter Y X maintain Y X change Y () X affect Y X follow Y (TEASE) () X extend Y X use Y Table 1: Examples of templates suggested by DIRT and TEASE as having an entailment relation, in some direction, with the input template X change Y ." ></td>
	<td class="line x" title="40:205	The entailment direction arrows were judged manually and added for readability." ></td>
	<td class="line x" title="41:205	tions infer one text variant from another." ></td>
	<td class="line x" title="42:205	A rule can be applied to a given text only when L can be inferred from it, with appropriate variable instantiation." ></td>
	<td class="line x" title="43:205	Then, using the rule, the application deduces that R can also be inferred from the text under the same variable instantiation." ></td>
	<td class="line x" title="44:205	For example, the rule X lose to YY beat X can be used to infer Liverpool beat Chelsea from Chelsea lost to Liverpool in the semifinals." ></td>
	<td class="line x" title="45:205	Entailment rules should typically be applied only in specific contexts, which we term relevant contexts." ></td>
	<td class="line x" title="46:205	For example, the rule X acquire Y  X buy Y  can be used in the context of buying events." ></td>
	<td class="line x" title="47:205	However, it shouldnt be applied for Students acquired a new language." ></td>
	<td class="line x" title="48:205	In the same manner, the rule X acquire Y X learn Y  should be applied only when Y corresponds to some sort of knowledge, as in the latter example." ></td>
	<td class="line x" title="49:205	Some existing entailment acquisition algorithms can add contextual constraints to the learned rules (Sekine, 2005), but most dont. However, NLP applications usually implicitly incorporate some contextual constraints when applying a rule." ></td>
	<td class="line x" title="50:205	For example, when answering the question Which companies did IBM buy? a QA system would apply the rule X acquire Y X buy Y  correctly, since the phrase IBM acquire X is likely to be found mostly in relevant economic contexts." ></td>
	<td class="line x" title="51:205	We thus expect that an evaluation methodology should consider context relevance for entailment rules." ></td>
	<td class="line x" title="52:205	For example, we would like both X acquire Y X buy Y  and X acquire Y X learn Y  to be assessed as correct (the second rule should not be deemed incorrect 457 just because it is not applicable in frequent economic contexts)." ></td>
	<td class="line x" title="53:205	Finally, we highlight that the common notion of paraphrase rules can be viewed as a special case of entailment rules: a paraphrase LR holds if both templates entail each other." ></td>
	<td class="line x" title="54:205	Following the textual entailment formulation, we observe that many applied inference settings require only directional entailment, and a requirement for symmetric paraphrase is usually unnecessary." ></td>
	<td class="line x" title="55:205	For example, in order to answer the question Who owns Overture? it suffices to use a directional entailment rule whose right hand side is X own Y , such as X acquire YX own Y , which is clearly not a paraphrase." ></td>
	<td class="line oc" title="56:205	2.2 Evaluation of Acquisition Algorithms Many methods for automatic acquisition of rules have been suggested in recent years, ranging from distributional similarity to finding shared contexts (Lin and Pantel, 2001; Ravichandran and Hovy, 2002; Shinyama et al. , 2002; Barzilay and Lee, 2003; Szpektor et al. , 2004; Sekine, 2005)." ></td>
	<td class="line n" title="57:205	However, there is still no common accepted framework for their evaluation." ></td>
	<td class="line n" title="58:205	Furthermore, all these methods learn rules as pairs of templates {L,R} in a symmetric manner, without addressing rule directionality." ></td>
	<td class="line n" title="59:205	Accordingly, previous works (except (Szpektor et al. , 2004)) evaluated the learned rules under the paraphrase criterion, which underestimates the practical utility of the learned rules (see Section 2.1)." ></td>
	<td class="line x" title="60:205	One approach which was used for evaluating automatically acquired rules is to measure their contribution to the performance of specific systems, such as QA (Ravichandran and Hovy, 2002) or IE (Sudo et al. , 2003; Romano et al. , 2006)." ></td>
	<td class="line x" title="61:205	While measuring the impact of learned rules on applications is highly important, it cannot serve as the primary approach for evaluating acquisition algorithms for several reasons." ></td>
	<td class="line x" title="62:205	First, developers of acquisition algorithms often do not have access to the different applications that will later use the learned rules as generic modules." ></td>
	<td class="line x" title="63:205	Second, the learned rules may affect individual systems differently, thus making observations that are based on different systems incomparable." ></td>
	<td class="line x" title="64:205	Third, within a complex system it is difficult to assess the exact quality of entailment rules independently of effects of other system components." ></td>
	<td class="line x" title="65:205	Thus, as in many other NLP learning settings, a direct evaluation is needed." ></td>
	<td class="line oc" title="66:205	Indeed, the prominent approach for evaluating the quality of rule acquisition algorithms is by human judgment of the learned rules (Lin and Pantel, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003; Pang et al. , 2003; Szpektor et al. , 2004; Sekine, 2005)." ></td>
	<td class="line o" title="67:205	In this evaluation scheme, termed here the rule-based approach, a sample of the learned rules is presented to the judges who evaluate whether each rule is correct or not." ></td>
	<td class="line n" title="68:205	The criterion for correctness is not explicitly described in most previous works." ></td>
	<td class="line x" title="69:205	By the common view of context relevance for rules (see Section 2.1), a rule was considered correct if the judge could think of reasonable contexts under which it holds." ></td>
	<td class="line x" title="70:205	We have replicated the rule-based methodology but did not manage to reach a 0.6 Kappa agreement level between pairs of judges." ></td>
	<td class="line x" title="71:205	This approach turns out to be problematic because the rule correctness criterion is not sufficiently well defined and is hard to apply." ></td>
	<td class="line x" title="72:205	While some rules might obviously be judged as correct or incorrect (see Table 1), judgment is often more difficult due to context relevance." ></td>
	<td class="line x" title="73:205	One judge might come up with a certain context that, to her opinion, justifies the rule, while another judge might not imagine that context or think that it doesnt sufficiently support rule correctness." ></td>
	<td class="line x" title="74:205	For example, in our experiments one of the judges did not identify the valid religious holidays context for the correct rule X observe YX celebrate Y ." ></td>
	<td class="line nc" title="75:205	Indeed, only few earlier works reported inter-judge agreement level, and those that did reported rather low Kappa values, such as 0.54 (Barzilay and Lee, 2003) and 0.55 0.63 (Szpektor et al. , 2004)." ></td>
	<td class="line n" title="76:205	To conclude, the prominent rule-based methodology for entailment rule evaluation is not sufficiently well defined." ></td>
	<td class="line n" title="77:205	It results in low inter-judge agreement which prevents reliable and consistent assessments of different algorithms." ></td>
	<td class="line x" title="78:205	3 Instance-based Evaluation Methodology As discussed in Section 2.1, an evaluation methodology for entailment rules should reflect the expected validity of their application within NLP systems." ></td>
	<td class="line x" title="79:205	Following that line, an entailment rule L  R should be regarded as correct if in all (or at least most) relevant contexts in which the instantiated template L is inferred from the given text, the instan458 Rule Sentence Judgment 1 X seek YX disclose Y If he is arrested, he can immediately seek bail." ></td>
	<td class="line x" title="80:205	Left not entailed 2 X clarify YX prepare Y He didnt clarify his position on the subject." ></td>
	<td class="line x" title="81:205	Left not entailed 3 X hit YX approach Y Other earthquakes have hit Lebanon since 82." ></td>
	<td class="line x" title="82:205	Irrelevant context 4 X lose YX surrender Y Bread has recently lost its subsidy." ></td>
	<td class="line x" title="83:205	Irrelevant context 5 X regulate YX reform Y The SRA regulates the sale of sugar." ></td>
	<td class="line x" title="84:205	No entailment 6 X resign YX share Y Lopez resigned his post at VW last week." ></td>
	<td class="line x" title="85:205	No entailment 7 X set YX allow Y The committee set the following refunds." ></td>
	<td class="line x" title="86:205	Entailment holds 8 X stress YX state Y Ben Yahia also stressed the need for action." ></td>
	<td class="line x" title="87:205	Entailment holds Table 2: Rule evaluation examples and their judgment." ></td>
	<td class="line x" title="88:205	tiated template R is also inferred from the text." ></td>
	<td class="line x" title="89:205	This reasoning corresponds to the common definition of entailment in semantics, which specifies that a text L entails another text R if R is true in every circumstance (possible world) in which L is true (Chierchia and McConnell-Ginet, 2000)." ></td>
	<td class="line x" title="90:205	It follows that in order to assess if a rule is correct we should judge whether R is typically entailed from those sentences that entail L (within relevant contexts for the rule)." ></td>
	<td class="line x" title="91:205	We thus present a new evaluation scheme for entailment rules, termed the instance-based approach." ></td>
	<td class="line x" title="92:205	At the heart of this approach, human judges are presented not only with a rule but rather with a sample of examples of the rules usage." ></td>
	<td class="line x" title="93:205	Instead of thinking up valid contexts for the rule the judges need to assess the rules validity under the given context in each example." ></td>
	<td class="line x" title="94:205	The essence of our proposal is a (apparently non-trivial) protocol of a sequence of questions, which determines rule validity in a given sentence." ></td>
	<td class="line x" title="95:205	We shall next describe how we collect a sample of examples for evaluation and the evaluation process." ></td>
	<td class="line x" title="96:205	3.1 Sampling Examples Given a rule LR, our goal is to generate evaluation examples by finding a sample of sentences from which L is entailed." ></td>
	<td class="line x" title="97:205	We do that by automatically retrieving, from a given corpus, sentences that match L and are thus likely to entail it, as explained below." ></td>
	<td class="line x" title="98:205	For each example sentence, we automatically extract the arguments that instantiate L and generate two phrases, termed left phrase and right phrase, which are constructed by instantiating the left template L and the right template R with the extracted arguments." ></td>
	<td class="line x" title="99:205	For example, the left and right phrases generated for example 1 in Table 2 are he seek bail and he disclose bail, respectively." ></td>
	<td class="line x" title="100:205	Finding sentences that match L can be performed at different levels." ></td>
	<td class="line x" title="101:205	In this paper we match lexicalsyntactic templates by finding a sub-tree of the sentence parse that is identical to the template structure." ></td>
	<td class="line x" title="102:205	Of course, this matching method is not perfect and will sometimes retrieve sentences that do not entail the left phrase for various reasons, such as incorrect sentence analysis or semantic aspects like negation, modality and conditionals." ></td>
	<td class="line x" title="103:205	See examples 1-2 in Table 2 for sentences that syntactically match L but do not entail the instantiated left phrase." ></td>
	<td class="line x" title="104:205	Since we should assess Rs entailment only from sentences that entail L, such sentences should be ignored by the evaluation process." ></td>
	<td class="line x" title="105:205	3.2 Judgment Questions For each example generated for a rule, the judges are presented with the given sentence and the left and right phrases." ></td>
	<td class="line x" title="106:205	They primarily answer two questions that assess whether entailment holds in this example, following the semantics of entailment rule application as discussed above: Qle: Is the left phrase entailed from the sentence?" ></td>
	<td class="line x" title="107:205	A positive/negative answer corresponds to a Left entailed/not entailed judgment." ></td>
	<td class="line x" title="108:205	Qre: Is the right phrase entailed from the sentence?" ></td>
	<td class="line x" title="109:205	A positive/negative answer corresponds to an Entailment holds/No entailment judgment." ></td>
	<td class="line x" title="110:205	The first question identifies sentences that do not entail the left phrase, and thus should be ignored when evaluating the rules correctness." ></td>
	<td class="line x" title="111:205	While inappropriate matches of the rule left-hand-side may happen 459 and harm an overall system precision, such errors should be accounted for a systems rule matching module rather than for the rules precision." ></td>
	<td class="line x" title="112:205	The second question assesses whether the rule application is valid or not for the current example." ></td>
	<td class="line x" title="113:205	See examples 5-8 in Table 2 for cases where entailment does or doesnt hold." ></td>
	<td class="line x" title="114:205	Thus, the judges focus only on the given sentence in each example, so the task is actually to evaluate whether textual entailment holds between the sentence (text) and each of the left and right phrases (hypotheses)." ></td>
	<td class="line x" title="115:205	Following past experience in textual entailment evaluation (Dagan et al. , 2006) we expect a reasonable agreement level between judges." ></td>
	<td class="line x" title="116:205	As discussed in Section 2.1, we may want to ignore examples whose context is irrelevant for the rule." ></td>
	<td class="line x" title="117:205	To optionally capture this distinction, the judges are asked another question: Qrc: Is the right phrase a likely phrase in English?" ></td>
	<td class="line x" title="118:205	A positive/negative answer corresponds to a Relevant/Irrelevant context evaluation." ></td>
	<td class="line x" title="119:205	If the right phrase is not likely in English then the given context is probably irrelevant for the rule, because it seems inherently incorrect to infer an implausible phrase." ></td>
	<td class="line x" title="120:205	Examples 3-4 in Table 2 demonstrate cases of irrelevant contexts, which we may choose to ignore when assessing rule correctness." ></td>
	<td class="line x" title="121:205	3.3 Evaluation Process For each example, the judges are presented with the three questions above in the following order: (1) Qle (2) Qrc (3) Qre." ></td>
	<td class="line x" title="122:205	If the answer to a certain question is negative then we do not need to present the next questions to the judge: if the left phrase is not entailed then we ignore the sentence altogether; and if the context is irrelevant then the right phrase cannot be entailed from the sentence and so the answer to Qre is already known as negative." ></td>
	<td class="line x" title="123:205	The above entailment judgments assume that we can actually ask whether the left or right phrases are correct given the sentence, that is, we assume that a truth value can be assigned to both phrases." ></td>
	<td class="line x" title="124:205	This is the case when the left and right templates correspond, as expected, to semantic relations." ></td>
	<td class="line x" title="125:205	Yet sometimes learned templates are (erroneously) not relational, e.g. X, Y, IBM (representing a list)." ></td>
	<td class="line x" title="126:205	We therefore let the judges initially mark rules that include such templates as non-relational, in which case their examples are not evaluated at all." ></td>
	<td class="line x" title="127:205	3.4 Rule Precision We compute the precision of a rule by the percentage of examples for which entailment holds out of all relevant examples." ></td>
	<td class="line x" title="128:205	We can calculate the precision in two ways, as defined below, depending on whether we ignore irrelevant contexts or not (obtaining lower precision if we dont)." ></td>
	<td class="line x" title="129:205	When systems answer an information need, such as a query or question, irrelevant contexts are sometimes not encountered thanks to additional context which is present in the given input (see Section 2.1)." ></td>
	<td class="line x" title="130:205	Thus, the following two measures can be viewed as upper and lower bounds for the expected precision of the rule applications in actual systems: upper bound precision: #Entailment holds#Relevant context lower bound precision: #Entailment holds#Left entailed where # denotes the number of examples with the corresponding judgment." ></td>
	<td class="line x" title="131:205	Finally, we consider a rule to be correct only if its precision is at least 80%, which seems sensible for typical applied settings." ></td>
	<td class="line x" title="132:205	This yields two alternative sets of correct rules, corresponding to the upper bound and lower bound precision measures." ></td>
	<td class="line x" title="133:205	Even though judges may disagree on specific examples for a rule, their judgments may still agree overall on the rules correctness." ></td>
	<td class="line x" title="134:205	We therefore expect the agreement level on rule correctness to be higher than the agreement on individual examples." ></td>
	<td class="line x" title="135:205	4 Experimental Settings We applied the instance-based methodology to evaluate two state-of-the-art unsupervised acquisition algorithms, DIRT (Lin and Pantel, 2001) and TEASE (Szpektor et al. , 2004), whose output is publicly available." ></td>
	<td class="line x" title="136:205	DIRT identifies semantically related templates in a local corpus using distributional similarity over the templates variable instantiations." ></td>
	<td class="line x" title="137:205	TEASE acquires entailment relations from the Web for a given input template I by identifying characteristic variable instantiations shared by I and other templates." ></td>
	<td class="line x" title="138:205	460 For the experiment we used the published DIRT and TEASE knowledge-bases1." ></td>
	<td class="line x" title="139:205	For every given input template I, each knowledge-base provides a list of learned output templatesOj}nI1, where nI is the number of output templates learned for I. Each output template is suggested as holding an entailment relation with the input template I, but the algorithms do not specify the entailment direction(s)." ></td>
	<td class="line x" title="140:205	Thus, each pairI,Oj}induces two candidate directional entailment rules: IOj and OjI." ></td>
	<td class="line x" title="141:205	4.1 Test Set Construction The test set construction consists of three sampling steps: selecting a set of input templates for the two algorithms, selecting a sample of output rules to be evaluated, and selecting a sample of sentences to be judged for each rule." ></td>
	<td class="line x" title="142:205	First, we randomly selected 30 transitive verbs out of the 1000 most frequent verbs in the Reuters RCV1 corpus2." ></td>
	<td class="line x" title="143:205	For each verb we manually constructed a lexical-syntactic input template by adding subject and object variables." ></td>
	<td class="line x" title="144:205	For example, for the verb seek we constructed the template X subjseek obj Y ." ></td>
	<td class="line x" title="145:205	Next, for each input template I we considered the learned templatesOj}nI1 from each knowledgebase." ></td>
	<td class="line x" title="146:205	Since DIRT has a long tail of templates with a low score and very low precision, DIRT templates whose score is below a threshold of 0.1 were filtered out3." ></td>
	<td class="line x" title="147:205	We then sampled 10% of the templates in each output list, limiting the sample size to be between 5-20 templates for each list (thus balancing between sufficient evaluation data and judgment load)." ></td>
	<td class="line x" title="148:205	For each sampled template O we evaluated both directional rules, IO and OI." ></td>
	<td class="line x" title="149:205	In total, we sampled 380 templates, inducing 760 directional rules out of which 754 rules were unique." ></td>
	<td class="line x" title="150:205	Last, we randomly extracted a sample of example sentences for each rule LR by utilizing a search engine over the first CD of Reuters RCV1." ></td>
	<td class="line x" title="151:205	First, we retrieved all sentences containing all lexical terms within L. The retrieved sentences were parsed using the Minipar dependency parser (Lin, 1998), keeping only sentences that syntactically match L (as 1Available at http://aclweb.org/aclwiki/index.php?title=Textual Entailment Resource Pool 2http://about.reuters.com/researchandstandards/corpus/ 3Following advice by Patrick Pantel, DIRTs co-author." ></td>
	<td class="line x" title="152:205	explained in Section 3.1)." ></td>
	<td class="line x" title="153:205	A sample of 15 matching sentences was randomly selected, or all matching sentences if less than 15 were found." ></td>
	<td class="line x" title="154:205	Finally, an example for judgment was generated from each sampled sentence and its left and right phrases (see Section 3.1)." ></td>
	<td class="line x" title="155:205	We did not find sentences for 108 rules, and thus we ended up with 646 unique rules that could be evaluated (with 8945 examples to be judged)." ></td>
	<td class="line x" title="156:205	4.2 Evaluating the Test-Set Two human judges evaluated the examples." ></td>
	<td class="line x" title="157:205	We randomly split the examples between the judges." ></td>
	<td class="line x" title="158:205	100 rules (1287 examples) were cross annotated for agreement measurement." ></td>
	<td class="line x" title="159:205	The judges followed the procedure in Section 3.3 and the correctness of each rule was assessed based on both its upper and lower bound precision values (Section 3.4)." ></td>
	<td class="line x" title="160:205	5 Methodology Evaluation Results We assessed the instance-based methodology by measuring the agreement level between judges." ></td>
	<td class="line x" title="161:205	The judges agreed on 75% of the 1287 shared examples, corresponding to a reasonable Kappa value of 0.64." ></td>
	<td class="line x" title="162:205	A similar kappa value of 0.65 was obtained for the examples that were judged as either entailment holds/no entailment by both judges." ></td>
	<td class="line x" title="163:205	Yet, our evaluation target is to assess rules, and the Kappa values for the final correctness judgments of the shared rules were 0.74 and 0.68 for the lower and upper bound evaluations." ></td>
	<td class="line x" title="164:205	These Kappa scores are regarded as substantial agreement and are substantially higher than published agreement scores and those we managed to obtain using the standard rulebased approach." ></td>
	<td class="line x" title="165:205	As expected, the agreement on rules is higher than on examples, since judges may disagree on a certain example but their judgements would still yield the same rule assessment." ></td>
	<td class="line x" title="166:205	Table 3 illustrates some disagreements that were still exhibited within the instance-based evaluation." ></td>
	<td class="line x" title="167:205	The primary reason for disagreements was the difficulty to decide whether a context is relevant for a rule or not, resulting in some confusion between Irrelevant context and No entailment." ></td>
	<td class="line x" title="168:205	This may explain the lower agreement for the upper bound precision, for which examples judged as Irrelevant context are ignored, while for the lower bound both 461 Rule Sentence Judge 1 Judge 2 X sign YX set Y Iraq and Turkey sign agreement to increase trade cooperation Entailment holds Irrelevant context X worsen YX slow Y News of the strike worsened the situation Irrelevant context No entailment X get YX want Y He will get his parade on Tuesday Entailment holds No entailment Table 3: Examples for disagreement between the two judges." ></td>
	<td class="line x" title="169:205	judgments are conflated and represent no entailment." ></td>
	<td class="line x" title="170:205	Our findings suggest that better ways for distinguishing relevant contexts may be sought in future research for further refinement of the instance-based evaluation methodology." ></td>
	<td class="line x" title="171:205	About 43% of all examples were judged as Left not entailed." ></td>
	<td class="line x" title="172:205	The relatively low matching precision (57%) made us collect more examples than needed, since Left not entailed examples are ignored." ></td>
	<td class="line x" title="173:205	Better matching capabilities will allow collecting and judging fewer examples, thus improving the efficiency of the evaluation process." ></td>
	<td class="line x" title="174:205	6 DIRT and TEASE Evaluation Results DIRT TEASE P Y P Y Rules: Upper Bound 30.5% 33.5 28.4% 40.3 Lower Bound 18.6% 20.4 17% 24.1 Templates: Upper Bound 44% 22.6 38% 26.9 Lower Bound 27.3% 14.1 23.6% 16.8 Table 4: Average Precision (P) and Yield (Y) at the rule and template levels." ></td>
	<td class="line x" title="175:205	We evaluated the quality of the entailment rules produced by each algorithm using two scores: (1) micro average Precision, the percentage of correct rules out of all learned rules, and (2) average Yield, the average number of correct rules learned for each input template I, as extrapolated based on the sample4." ></td>
	<td class="line x" title="176:205	Since DIRT and TEASE do not identify rule directionality, we also measured these scores at the 4Since the rules are matched against the full corpus (as in IR evaluations), it is difficult to evaluate their true recall." ></td>
	<td class="line x" title="177:205	template level, where an output template O is considered correct if at least one of the rules IO or OI is correct." ></td>
	<td class="line x" title="178:205	The results are presented in Table 4." ></td>
	<td class="line x" title="179:205	The major finding is that the overall quality of DIRT and TEASE is very similar." ></td>
	<td class="line x" title="180:205	Under the specific DIRT cutoff threshold chosen, DIRT exhibits somewhat higher Precision while TEASE has somewhat higher Yield (recall that there is no particular natural cutoff point for DIRTs output)." ></td>
	<td class="line x" title="181:205	Since applications typically apply rules in a specific direction, the Precision for rules reflects their expected performance better than the Precision for templates." ></td>
	<td class="line x" title="182:205	Obviously, future improvement in precision is needed for rule learning algorithms." ></td>
	<td class="line x" title="183:205	Meanwhile, manual filtering of the learned rules can prove effective within limited domains, where our evaluation approach can be utilized for reliable filtering as well." ></td>
	<td class="line x" title="184:205	The substantial yield obtained by these algorithms suggest that they are indeed likely to be valuable for recall increase in semantic applications." ></td>
	<td class="line x" title="185:205	In addition, we found that only about 15% of the correct templates were learned by both algorithms, which implies that the two algorithms largely complement each other in terms of coverage." ></td>
	<td class="line x" title="186:205	One explanation may be that DIRT is focused on the domain of the local corpus used (news articles for the published DIRT knowledge-base), whereas TEASE learns from the Web, extracting rules from multiple domains." ></td>
	<td class="line x" title="187:205	Since Precision is comparable it may be best to use both algorithms in tandem." ></td>
	<td class="line x" title="188:205	We also measured whether O is a paraphrase of I, i.e. whether both IO and OI are correct." ></td>
	<td class="line x" title="189:205	Only 20-25% of all correct templates were assessed as paraphrases." ></td>
	<td class="line x" title="190:205	This stresses the significance of evaluating directional rules rather than only paraphrases." ></td>
	<td class="line x" title="191:205	Furthermore, it shows that in order to improve precision, acquisition algorithms must identify rule directionality." ></td>
	<td class="line x" title="192:205	462 About 28% of all Left entailed examples were evaluated as Irrelevant context, yielding the large difference in precision between the upper and lower precision bounds." ></td>
	<td class="line x" title="193:205	This result shows that in order to get closer to the upper bound precision, learning algorithms and applications need to identify the relevant contexts in which a rule should be applied." ></td>
	<td class="line x" title="194:205	Last, we note that the instance-based quality assessment corresponds to the corpus from which the example sentences were taken." ></td>
	<td class="line x" title="195:205	It is therefore best to evaluate the rules using a corpus of the same domain from which they were learned, or the target application domain for which the rules will be applied." ></td>
	<td class="line x" title="196:205	7 Conclusions Accurate learning of inference knowledge, such as entailment rules, has become critical for further progress of applied semantic systems." ></td>
	<td class="line x" title="197:205	However, evaluation of such knowledge has been problematic, hindering further developments." ></td>
	<td class="line x" title="198:205	The instance-based evaluation approach proposed in this paper obtained acceptable agreement levels, which are substantially higher than those obtained for the common rulebased approach." ></td>
	<td class="line x" title="199:205	We also conducted the first comparison between two state-of-the-art acquisition algorithms, DIRT and TEASE, using the new methodology." ></td>
	<td class="line x" title="200:205	We found that their quality is comparable but they effectively complement each other in terms of rule coverage." ></td>
	<td class="line x" title="201:205	Also, we found that most learned rules are not paraphrases but rather one-directional entailment rules, and that many of the rules are context sensitive." ></td>
	<td class="line x" title="202:205	These findings suggest interesting directions for future research, in particular learning rule directionality and relevant contexts, issues that were hardly explored till now." ></td>
	<td class="line x" title="203:205	Such developments can be then evaluated by the instance-based methodology, which was designed to capture these two important aspects of entailment rules." ></td>
	<td class="line x" title="204:205	Acknowledgements The authors would like to thank Ephi Sachs and Iddo Greental for their evaluation." ></td>
	<td class="line x" title="205:205	This work was partially supported by ISF grant 1095/05, the IST Programme of the European Community under the PASCAL Network of Excellence IST-2002-506778, and the ITC-irst/University of Haifa collaboration." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W07-0716
Using Paraphrases for Parameter Tuning in Statistical Machine Translation
Madnani, Nitin;Ayan, Necip Fazil;Resnik, Philip;Dorr, Bonnie Jean;"></td>
	<td class="line x" title="1:171	Proceedings of the Second Workshop on Statistical Machine Translation, pages 120??27, Prague, June 2007." ></td>
	<td class="line x" title="2:171	c2007 Association for Computational Linguistics Using Paraphrases for Parameter Tuning in Statistical Machine Translation Nitin Madnani, Necip Fazil Ayan, Philip Resnik & Bonnie J. Dorr Institute for Advanced Computer Studies University of Maryland College Park, MD, 20742 {nmadnani,nfa,resnik,bonnie}@umiacs.umd.edu Abstract Most state-of-the-art statistical machine translation systems use log-linear models, whicharedefinedintermsofhypothesisfeatures and weights for those features." ></td>
	<td class="line x" title="3:171	It is standard to tune the feature weights in order to maximize a translation quality metric, using held-out test sentences and their corresponding reference translations." ></td>
	<td class="line x" title="4:171	However, obtaining reference translations is expensive." ></td>
	<td class="line x" title="5:171	In this paper, we introduce a new full-sentence paraphrase technique, based on English-to-English decoding with an MT system, and we demonstrate that the resultingparaphrasescanbeusedtodrasticallyreducethenumberofhumanreferencetranslations needed for parameter tuning, without a significant decrease in translation quality." ></td>
	<td class="line x" title="6:171	1 Introduction Viewed at a very high level, statistical machine translationinvolvesfourphases: languageandtranslation model training, parameter tuning, decoding, and evaluation (Lopez, 2007; Koehn et al. , 2003)." ></td>
	<td class="line x" title="7:171	SincetheirintroductioninstatisticalMTbyOchand Ney (2002), log-linear models have been a standard way to combine sub-models in MT systems." ></td>
	<td class="line x" title="8:171	Typically such a model takes the form summationdisplay i i?i( f,e) (1) where ?i are features of the hypothesis e and i are weights associated with those features." ></td>
	<td class="line x" title="9:171	Selecting appropriate weights i is essential in order to obtain good translation performance." ></td>
	<td class="line x" title="10:171	Och (2003) introduced minimum error rate training (MERT), a technique for optimizing log-linear modelparametersrelativetoameasureoftranslation quality." ></td>
	<td class="line x" title="11:171	This has become much more standard than optimizing the conditional probability of the trainingdatagiventhemodel(i.e. ,amaximumlikelihood criterion), as was common previously." ></td>
	<td class="line x" title="12:171	Och showed thatsystemperformanceisbestwhenparametersare optimizedusingthesameobjectivefunctionthatwill be used for evaluation; BLEU (Papineni et al. , 2002) remains common for both purposes and is often retained for parameter optimization even when alternative evaluation measures are used, e.g., (Banerjee and Lavie, 2005; Snover et al. , 2006)." ></td>
	<td class="line x" title="13:171	Minimum error rate training?and more generally, optimization of parameters relative to a translation quality measure?relies on data sets in which source language sentences are paired with (sets of) reference translations." ></td>
	<td class="line x" title="14:171	It is widely agreed that, at least for the widely used BLEU criterion, which is based on n-gram overlap between hypotheses and reference translations, the criterion is most accurate when computed with as many distinct reference translationsaspossible." ></td>
	<td class="line x" title="15:171	Intuitivelythismakessense: if there are alternative ways to phrase the meaning of the source sentence in the target language, then the translation quality criterion should take as many of those variations into account as possible." ></td>
	<td class="line x" title="16:171	To do otherwise is to risk the possibility that the criterion might judge good translations to be poor when they fail to match the exact wording within the reference translations that have been provided." ></td>
	<td class="line x" title="17:171	This reliance on multiple reference translations createsaproblem, becausereferencetranslationsare labor intensive and expensive to obtain." ></td>
	<td class="line x" title="18:171	A common source of translated data for MT research is the Linguistic Data Consortium (LDC), where an elaborate process is undertaken that involves translation agencies, detailed translation guidelines, and quality control processes (Strassel et al. , 2006)." ></td>
	<td class="line x" title="19:171	Some 120 efforts have been made to develop alternative processes for eliciting translations, e.g., from users on the Web (Oard, 2003) or from informants in lowdensity languages (Probst et al. , 2002)." ></td>
	<td class="line x" title="20:171	However, reference translations for parameter tuning and evaluation remain a severe data bottleneck for such approaches." ></td>
	<td class="line x" title="21:171	Note, however, one crucial property of reference translations: they are paraphrases, i.e., multiple expressions of the same meaning." ></td>
	<td class="line x" title="22:171	Automatic techniques exist for generating paraphrases." ></td>
	<td class="line x" title="23:171	Although one would clearly like to retain human translations as the benchmark for evaluation of translation, might it be possible to usefully increase the number of reference translations for tuning by using automatic paraphrase techniques?" ></td>
	<td class="line x" title="24:171	In this paper, we demonstrate that it is, in fact, possible to do so." ></td>
	<td class="line x" title="25:171	Section 2 briefly describes our translation framework." ></td>
	<td class="line x" title="26:171	Section 3 lays out a novel technique for paraphrasing, designed with the application to parameter tuning in mind." ></td>
	<td class="line x" title="27:171	Section 4 presentsevaluationresultsusingastateoftheartstatistical MT system, demonstrating that half the human reference translations in a standard 4-reference tuning set can be replaced with automatically generated paraphrases, with nosignificant decrease inMT system performance." ></td>
	<td class="line x" title="28:171	In Section 5 we discuss related work, and in Section 6 we summarize the results and discuss plans for future research." ></td>
	<td class="line x" title="29:171	2 Translation Framework The work described in this paper makes use of the Hiero statistical MT framework (Chiang, 2007)." ></td>
	<td class="line x" title="30:171	Hiero is formally based on a weighted synchronous context-free grammar (CFG), containing synchronous rules of the form X ???e, f,?k1( f,e,X)??(2) where X is a symbol from the nonterminal alphabet, and e and f can contain both words (terminals) andvariables(nonterminals)thatserveasplaceholders for other phrases." ></td>
	<td class="line x" title="31:171	In the context of statistical MT,wherephrase-basedmodelsarefrequentlyused, these synchronous rules can be interpreted as pairs of hierarchical phrases." ></td>
	<td class="line x" title="32:171	The underlying strength of a hierarchical phrase is that it allows for effective learning of not only the lexical re-orderings, but phrasal re-orderings, as well." ></td>
	<td class="line x" title="33:171	Each ?(e, f,X) denotes a feature function defined on the pair of hierarchical phrases.1 Feature functions represent conditional and joint co-occurrence probabilities over the hierarchical paraphrase pair." ></td>
	<td class="line x" title="34:171	The Hiero framework includes methods to learn grammars and feature values from unannotated parallel corpora, without requiring syntactic annotation of the data." ></td>
	<td class="line x" title="35:171	Briefly, training a Hiero model proceeds as follows: ??GIZA++ (Och and Ney, 2000) is run on the parallel corpus in both directions, followed by an alignment refinement heuristic that yields a many-to-many alignment for each parallel sentence." ></td>
	<td class="line x" title="36:171	??Initial phrase pairs are identified following the procedure typically employed in phrase based systems (Koehn et al. , 2003; Och and Ney, 2004)." ></td>
	<td class="line x" title="37:171	??Grammar rules in the form of equation (2) are induced by ?subtracting??out hierarchical phrase pairs from these initial phrase pairs." ></td>
	<td class="line x" title="38:171	??Fractional counts are assigned to each produced rule: c(X ???e, f??" ></td>
	<td class="line x" title="39:171	= msummationdisplay j=1 1 njr (3) where m is the number of initial phrase pairs that give rise to this grammar rule and njr is the number of grammar rules produced by the jth initial phrase pair." ></td>
	<td class="line x" title="40:171	??Feature functions ?k1( f,e,X) are calculated for each rule using the accumulated counts." ></td>
	<td class="line x" title="41:171	Oncetraininghastakenplace,minimumerrorrate training (Och, 2003) is used to tune the parameters i. Finally, decoding in Hiero takes place using a CKY synchronous parser with beam search, augmented to permit efficient incorporation of language model scores (Chiang, 2007)." ></td>
	<td class="line x" title="42:171	Given a source language sentence f, the decoder parses the source language sentence using the grammar it has learned 1Currently only one nonterminal symbol is used in Hiero productions." ></td>
	<td class="line x" title="43:171	121 during training, with parser search guided by the model; a target-language hypothesis is generated simultaneously via the synchronous rules, and the yieldofthathypothesizedanalysisrepresentsthehypothesized string e in the target language." ></td>
	<td class="line x" title="44:171	3 Generating Paraphrases As discussed in Section 1, our goal is to make it possible to accomplish the parameter-tuning phase using fewer human reference translations." ></td>
	<td class="line x" title="45:171	We accomplish this by beginning with a small set of human reference translations for each sentence in the development set, and expanding that set by automatically paraphrasing each member of the set rather than by acquiring more human translations." ></td>
	<td class="line oc" title="46:171	Most previous work on paraphrase has focused on high quality rather than coverage (Barzilay and Lee, 2003; Quirk et al. , 2004), but generating artificial references for MT parameter tuning in our setting has two unique properties compared to other paraphrase applications." ></td>
	<td class="line x" title="47:171	First, we would like to obtain 100% coverage, in order to avoid modifications to our minimum error rate training infrastructure.2 Second, we prefer that paraphrases be as distinct as possible from the original sentences, while retaining as much of the original meaning as possible." ></td>
	<td class="line x" title="48:171	In order to satisfy these two properties, we approach sentence-level paraphrase for English as a problem of English-to-English translation, constructing the model using English-F translation, for a second language F, as a pivot." ></td>
	<td class="line x" title="49:171	Following Bannard and Callison-Burch (2005), we first identify English-to-F correspondences, then map from English to English by following translation units from English to F and back." ></td>
	<td class="line x" title="50:171	Then, generalizing their approach, we use those mappings to create a well defined English-to-English translation model." ></td>
	<td class="line x" title="51:171	The parameters of this model are tuned using MERT, and then the model is used in an the (unmodified) statistical MT system, yielding sentence-level English paraphrases by means of decoding input English sentences." ></td>
	<td class="line x" title="52:171	The remainder of this section presents this process in detail." ></td>
	<td class="line x" title="53:171	2Strictly speaking, this was not a requirement of the approach, but rather a concession to practical considerations." ></td>
	<td class="line x" title="54:171	3.1 Mapping and Backmapping We employ the following strategy for the induction oftherequiredmonolingualgrammar." ></td>
	<td class="line x" title="55:171	First,wetrain the Hiero system in standard fashion on a bilingual English-F training corpus." ></td>
	<td class="line x" title="56:171	Then, for each existing production in the resulting Hiero grammar, we create multiple new English-to-English productions by pivoting on the foreign hierarchical phrase in the rule." ></td>
	<td class="line x" title="57:171	For example, assume that we have the following toy grammar for English-F, as produced by Hiero: X ????e1, f1??" ></td>
	<td class="line x" title="58:171	X ????e3, f1??" ></td>
	<td class="line x" title="59:171	X ????e1, f2??" ></td>
	<td class="line x" title="60:171	X ????e2, f2??" ></td>
	<td class="line x" title="61:171	X ????e4, f2??" ></td>
	<td class="line x" title="62:171	If we use the foreign phrase f1 as a pivot and backmap, we can extract the two English-to-English rules: X ????e1, e3??and X ????e3, e1??" ></td>
	<td class="line x" title="63:171	Backmapping using both f1 and f2 produces the following new rules (ignoring duplicates and rules that map any English phrase to itself): X ????e1, e2??" ></td>
	<td class="line x" title="64:171	X ????e1, e3??" ></td>
	<td class="line x" title="65:171	X ????e1, e4??" ></td>
	<td class="line x" title="66:171	X ????e2, e1??" ></td>
	<td class="line x" title="67:171	X ????e2, e4??" ></td>
	<td class="line x" title="68:171	3.2 Feature values Each rule production in a Hiero grammar is weighted by several feature values defined on the rule themselves." ></td>
	<td class="line x" title="69:171	In order to perform accurate backmapping, we must recompute these feature functions for the newly created English-to-English grammar." ></td>
	<td class="line x" title="70:171	Rather than computing approximations based on feature values already existing in the bilingual Hiero grammar, we calculate these features in a more principled manner, by computing maximum likelihood estimates directly from the fractional counts that Hiero accumulates in the penultimate training step." ></td>
	<td class="line x" title="71:171	We use the following features in our induced English-to-English grammar:3 3Hiero also uses lexical weights (Koehn et al. , 2003) in both 122 ??The joint probability of the two English hierarchical paraphrases, conditioned on the nonterminal symbol, as defined by this formula: p(e1, e2|x) = c(X ???e1, e2??summationtext e1prime, e2prime c(X ???e1prime, e2prime??" ></td>
	<td class="line x" title="72:171	= c(X ???e1, e2??c(X) (4) where the numerator is the fractional count of the rule under consideration and the denominator represents the marginal count over all the English hierarchical phrase pairs." ></td>
	<td class="line x" title="73:171	??The conditionals p(e1,x|e2) and p(e2,x|e1) defined as follows: p(e1,x|e2) = c(X ???e1, e2??summationtext e1prime c(X ???e1prime, e2??" ></td>
	<td class="line x" title="74:171	(5) p(e2,x|e1) = c(X ???e1, e2??summationtext e2prime c(X ???e1, e2prime??" ></td>
	<td class="line x" title="75:171	(6) Finally, for all induced rules, we calculate a word penalty exp(?T(e2)), where T(e2) just counts the number of terminal symbols in e2." ></td>
	<td class="line x" title="76:171	This feature allows the model to learn whether it should produce shorter or longer paraphrases." ></td>
	<td class="line x" title="77:171	Inadditiontothefeaturesabovethatareestimated from the training data, we also use a trigram language model." ></td>
	<td class="line x" title="78:171	Since we are decoding to produce English sentences, we can use the same language model employed in a standard statistical MT setting." ></td>
	<td class="line x" title="79:171	Calculating the proposed features is complicated by the fact that we don?t actually have the counts for English-to-English rules because there is no English-to-English parallel corpus." ></td>
	<td class="line x" title="80:171	This is where the counts provided by Hiero come into the picture." ></td>
	<td class="line x" title="81:171	We estimate the counts that we need as follows: c(X ???e1, e2??" ></td>
	<td class="line x" title="82:171	= summationdisplay f c(X ???e1, f??c(X ???e2, f??" ></td>
	<td class="line x" title="83:171	(7) An intuitive way to think about the formula above is by using an example at the corpus level." ></td>
	<td class="line x" title="84:171	Assume that, in the given bilingual parallel corpus, there are m sentences in which the English phrase directions as features but we don?t use them for our grammar." ></td>
	<td class="line x" title="85:171	e1 co-occurs with the foreign phrase f and n sentences in which the same foreign phrase f co-occurs with the English phrase e2." ></td>
	<td class="line x" title="86:171	The problem can then be thought of as defining a function g(m,n) which computes the number of sentences in a hypothetical English-to-English parallel corpus wherein the phrases e1 and e1 co-occur." ></td>
	<td class="line x" title="87:171	For this paper, we define g(m,n) to be the upper bound mn." ></td>
	<td class="line x" title="88:171	Tables 1 and 2 show some examples of paraphrases generated by our system across a range of paraphrase quality for two different pivot languages." ></td>
	<td class="line x" title="89:171	3.3 Tuning Model Parameters Although the goal of the paraphrasing approach is to make it less data-intensive to tune log-linear model parameters for translation, our paraphrasing approach, since it is based on an English-to-English log-linear model, also requires its own parameter tuning." ></td>
	<td class="line x" title="90:171	This, however, is straightforward: regardless of how the paraphrasing model will be used in statistical MT, e.g., irrespective of source language,itispossibletouseanyexistingsetofEnglish paraphrases as the tuning set for English-to-English translation." ></td>
	<td class="line x" title="91:171	We used the 2002 NIST MT evaluation test set reference translations." ></td>
	<td class="line x" title="92:171	For every item in the set, we randomly chose one sentence as the source sentence, and the remainder as the ?reference translations?forpurposesofminimumerrorratetraining." ></td>
	<td class="line x" title="93:171	4 Evaluation Havingdevelopedaparaphrasingapproachbasedon English-to-English translation, we evaluated its use in improving minimum error rate training for translation from a second language into English." ></td>
	<td class="line x" title="94:171	Generating paraphrases via English-to-English translation makes use of a parallel corpus, from which a weighted synchronous grammar is automatically acquired." ></td>
	<td class="line x" title="95:171	Although nothing about our approachrequiresthattheparaphrasesystem?straining bitext be the same one used in the translation experiments (see Section 6), doing so is not precluded, either, and it is a particularly convenient choice when the paraphrasing is being done in support of MT.4 The training bitext comprised of Chinese-English 4The choice of the foreign language used as the pivot should not really matter but it is worth exploring this using other language pairs as our bitext." ></td>
	<td class="line x" title="96:171	123 O: we must bear in mind the community as a whole." ></td>
	<td class="line x" title="97:171	P: we must remember the wider community . O: thirdly, the implications of enlargement for the union ?s regional policy cannot be overlooked . P: finally, the impact of enlargement for eu regional policy cannot be ignored . O: how this works in practice will become clear when the authority has to act . P: how this operate in practice will emerge when the government has to play . O: this is an ill-advised policy . P: this is an unwelcome in europe . Table 1: Example paraphrases with French as the pivot language." ></td>
	<td class="line x" title="98:171	O = Original Sentence, P = Paraphrase." ></td>
	<td class="line x" title="99:171	O: alcatel added that the company?s whole year earnings would be announced on february 4 . P: alcatel said that the company?s total annual revenues would be released on february 4 . O: he was now preparing a speech concerning the us policy for the upcoming world economic forum . P: he was now ready to talk with regard to the us policies for the forthcoming international economic forum . O: tibet has entered an excellent phase of political stability, ethnic unity and people living in peace . P: tibetans have come to cordial political stability, national unity and lived in harmony . O: its ocean and blue-sky scenery and the mediterranean climate make it world?s famous scenic spot . P: its harbour and blue-sky appearance and the border situation decided it world?s renowned tourist attraction . Table 2: Example paraphrases with Chinese as the pivot language." ></td>
	<td class="line x" title="100:171	O = Original Sentence, P = Paraphrase." ></td>
	<td class="line x" title="101:171	Corpus # Sentences # Words HK News 542540 11171933 FBIS 240996 9121210 Xinhua 54022 1497562 News1 9916 314121 Treebank 3963 125848 Total 851437 22230674 Table 3: Chinese-English corpora used as training bitext both for paraphrasing and for evaluation." ></td>
	<td class="line x" title="102:171	parallelcorporacontaining850,000sentencepairs??" ></td>
	<td class="line x" title="103:171	approx." ></td>
	<td class="line x" title="104:171	22 million words (details shown in Table 3)." ></td>
	<td class="line x" title="105:171	As the source of development data for minimum error rate training, we used the 919 source sentences and human reference translations from the 2003 NIST Chinese-English MT evaluation exercise." ></td>
	<td class="line x" title="106:171	As raw material for experimentation, we generated a paraphrase for each reference sentence via 1-best decoding using the English-to-English translation approach of Section 3." ></td>
	<td class="line x" title="107:171	As our test data, we used the 1082 source sentences and human reference translations from the 2005 NIST Chinese-English MT evaluation." ></td>
	<td class="line x" title="108:171	Our core experiment involved three conditions where the only difference was the set of references for the development set used for tuning feature weights." ></td>
	<td class="line x" title="109:171	For each condition, once the weights were tuned, they were used to decode the test set." ></td>
	<td class="line x" title="110:171	Note that for all the conditions, the decoded test set was alwaysscoredagainstthesamefourhigh-qualityhuman reference translations included with the set." ></td>
	<td class="line x" title="111:171	The three experimental conditions were designed around the constraint that our development set contains a total of four human reference translations per sentence, and therefore a maximum of four human references with which to compute an upper bound: ??Baseline (2H): For each item in the development set, we randomly chose two of the four human-constructed reference translations as references for minimum error rate training." ></td>
	<td class="line x" title="112:171	??Expanded (2H + 2P): For each of the two human references in the baseline tuning set, we automatically generated a corresponding paraphrase using (1-best) English-to-English translation, decoding using the model developed in Section 3." ></td>
	<td class="line x" title="113:171	This condition represents the critical case in which you have a limited number of hu124 man references (two, in this case) and augment themwithartificiallygeneratedreferencetranslations." ></td>
	<td class="line x" title="114:171	This yields a set of four references for minimum error rate training (two human, two paraphrased), which permits a direct comparison against the upper bound of four humangenerated reference translations." ></td>
	<td class="line x" title="115:171	??Upper bound: 4H: We performed minimum error rate training using the four human references from the development set." ></td>
	<td class="line x" title="116:171	In addition to these core experimental conditions, we added a fourth condition to assess the effect on performance when all four human reference translations are used in expanding the reference set via paraphrase: ??Expanded(4H+4P): ThisisthesameasCondition 2, but using all four human references." ></td>
	<td class="line x" title="117:171	Note that since we have only four human references per item, this fourth condition does not permit comparison with an upper bound of eight human references." ></td>
	<td class="line x" title="118:171	Table 4 shows BLEU and TER scores on the test set for all four conditions.5 If only two human references were available (simulated by using only two of the available four), expanding to four using paraphrases would yield a clear improvement." ></td>
	<td class="line x" title="119:171	Using bootstrap resampling to compute confidence intervals (Koehn, 2004), we find that the improvement in BLEU score is statistically significant at p < .01." ></td>
	<td class="line x" title="120:171	Equally interesting, expanding the number of reference translations from two to four using paraphrases yields performance that approaches the upper bound obtained by doing MERT using all four human reference translations." ></td>
	<td class="line x" title="121:171	The difference in BLEU between conditions 2 and 3 is not significant." ></td>
	<td class="line x" title="122:171	Finally, our fourth condition asks whether it is possible to improve MT performance given the typical four human reference translations used for MERT in most statistical MT systems, by adding a paraphrase to each one for a total eight references per translation." ></td>
	<td class="line x" title="123:171	There is indeed further improvement, although the difference in BLEU score does not reach significance." ></td>
	<td class="line x" title="124:171	5We plan to include METEOR scores in future experiments." ></td>
	<td class="line x" title="125:171	Condition References used BLEU TER 1 2 H 30.43 59.82 2 2 H + 2 P 31.10 58.79 3 4 H 31.26 58.66 4 4 H + 4 P 31.68 58.24 Table 4: BLEU and TER scores showing utility of paraphrased reference translations." ></td>
	<td class="line x" title="126:171	H = human references, P = paraphrased references." ></td>
	<td class="line x" title="127:171	We also evaluated our test set using TER (Snover etal.,2006)andobservedthattheTERscoresfollow the same trend as the BLEU scores." ></td>
	<td class="line x" title="129:171	Specifically, the TER scores demonstrate that using paraphrases to artificially expand the reference set is better than using only 2 human reference translations and as good as using 4 human reference translations.6 5 Related Work The approach we have taken here arises from a typical situation in NLP systems: the lack of sufficient data to accurately estimate a model based on supervised training data." ></td>
	<td class="line x" title="130:171	In a structured prediction problem such as MT, we have an example input and a single labeled, correct output." ></td>
	<td class="line x" title="131:171	However, this output is chosen from a space in which the number of possible outputs is exponential in the input size, and in which there are many good outputs in this space (although they are vastly outnumbered by the bad outputs)." ></td>
	<td class="line x" title="132:171	Various discriminative learning methods have attempted to deal with the first of these issues, often by restricting the space of examples." ></td>
	<td class="line x" title="133:171	For instance, some max-margin methods restrict their computations to a set of examples from a ?feasible set,??" ></td>
	<td class="line x" title="134:171	where they are expected to be maximally discriminative (Tillmann and Zhang, 2006)." ></td>
	<td class="line x" title="135:171	The present approach deals with the second issue: in a learning problem where the use of a single positive example is likely to be highly biased, how can we produce a set of positive examples that is more representative of the space of correct outcomes?" ></td>
	<td class="line x" title="136:171	Our method exploits alternative sources of information to produce new positive examples that are, we hope, reasonably likely to represent a consensus of good examples." ></td>
	<td class="line x" title="137:171	Quite a bit of work has been done on paraphrase, 6We anticipate doing significance tests for differences in TER in future work." ></td>
	<td class="line x" title="138:171	125 some clearly related to our technique, although in general previous work has been focused on human readability rather than high coverage, noisy paraphrases for use downstream in an automatic process." ></td>
	<td class="line oc" title="139:171	At the sentence level, (Barzilay and Lee, 2003) employed an unsupervised learning approach to cluster sentences and extract lattice pairs from comparable monolingual corpora." ></td>
	<td class="line o" title="140:171	Their technique produces a paraphrase only if the input sentence matches any of the extracted lattice pairs, leading to a bias strongly favoring quality over coverage." ></td>
	<td class="line o" title="141:171	They were able to generate paraphrases for 59 sentences (12%) out of a 484-sentence test set, generating no paraphrases at all for the remainder." ></td>
	<td class="line x" title="142:171	Quirk et al.(2004) also generate sentential paraphrases using a monolingual corpus." ></td>
	<td class="line x" title="144:171	They use IBM Model-1 scores as the only feature, and employ a monotone decoder (i.e. , one that cannot produce phrase-level reordering)." ></td>
	<td class="line x" title="145:171	This approach emphasizes very simple ?substitutions of words and short phrases,??and, in fact, almost a third of their best sentential ?paraphrases??are identical to the input sentence." ></td>
	<td class="line x" title="146:171	A number of other approaches rely on parallel monolingual data and, additionally, require parsing of the training sentences (Ibrahim et al. , 2003; Pang et al. , 2003)." ></td>
	<td class="line x" title="147:171	Lin and Pantel (2001) use a non-parallelcorpusandemployadependencyparser and computation of distributional similarity to learn paraphrases." ></td>
	<td class="line x" title="148:171	There has also been recent work on using paraphrases to improve statistical machine translation." ></td>
	<td class="line x" title="149:171	Callison-Burch et al.(2006) extract phrase-level paraphrases by mapping input phrases into a phrase table and then mapping back to the source language." ></td>
	<td class="line x" title="151:171	However, they do not generate paraphrases of entire sentences,butinsteademployparaphrasestoaddentries to an existing phrase table solely for the purpose of increasing source-language coverage." ></td>
	<td class="line x" title="152:171	Other work has incorporated paraphrases into MT evaluation: Russo-Lassner et al.(2005) use a combination of paraphrase-based features to evaluate translation output; Zhou et al.(2006) propose a new metric that extends n-gram matching to include synonyms and paraphrases; and Lavie?s METEOR metric (Banerjee and Lavie, 2005) can be used with additionalknowledgesuchasWordNetinordertosupport inexact lexical matches." ></td>
	<td class="line x" title="155:171	6 Conclusions and Future Work We introduced an automatic paraphrasing technique based on English-to-English translation of full sentences using a statistical MT system, and demonstrated that, using this technique, it is possible to cut in half the usual number of reference translations used for minimum error rate training with no significant loss in translation quality." ></td>
	<td class="line x" title="156:171	Our method enables the generation of paraphrases for thousands of sentences in a very short amount of time (much shorter than creating other low-cost human references)." ></td>
	<td class="line x" title="157:171	This might prove beneficial for various discriminative training methods (Tillmann and Zhang, 2006)." ></td>
	<td class="line x" title="158:171	This has important implications for data acquisition strategies For example, it suggests that rather than obtaining four reference translations per sentence for development sets, it may be more worthwhile to obtain fewer translations for a wider range of sentences, e.g., expanding into new topics and genres." ></td>
	<td class="line x" title="159:171	In addition, this approach can significantly increase the utility of datasets which include only a single reference translation." ></td>
	<td class="line x" title="160:171	A number of future research directions are possible." ></td>
	<td class="line x" title="161:171	First, since we have already demonstrated that noisy paraphrases can nonetheless add value, it would be straightforward to explore the quantity/quality tradeoff by expanding the MERT reference translations with n-best paraphrases for n > 1." ></td>
	<td class="line x" title="162:171	We also plan to conduct an intrinsic evaluation of the quality of paraphrases that our technique generates." ></td>
	<td class="line x" title="163:171	It is important to note that a different tradeoff ratio may lead to even better results, e.g, using only the paraphrased references when they pass some goodness threshold, as used in Ueffing?s (2006) selftraining MT approach." ></td>
	<td class="line x" title="164:171	We have also observed that named entities are usually paraphrased incorrectly if there is a genre mismatchbetweenthetrainingandthetestdata." ></td>
	<td class="line x" title="165:171	The Hiero decoder allows spans of source text to be annotated with inline translations using XML." ></td>
	<td class="line x" title="166:171	We plan to identify and annotate named entities in the English source so that they are left unchanged." ></td>
	<td class="line x" title="167:171	Also,sincethelanguageF forEnglish-F pivoting is arbitrary, we plan to investigate using English-toEnglish grammars created using multiple English-F grammars based on different languages, both indi126 vidually and in combination, in order to improve paraphrase quality." ></td>
	<td class="line x" title="168:171	We also plan to explore a wider range of paraphrase-creation techniques, ranging from simple word substitutions (e.g. , based on WordNet) to usingthepivottechniquewithothertranslationssystems." ></td>
	<td class="line x" title="169:171	7 Acknowledgments We are indebted to David Chiang, Adam Lopez and Smaranda Muresan for insights and comments." ></td>
	<td class="line x" title="170:171	This work has been supported under the GALE program of the Defense Advaned Research Projects Agency, ContractNo.HR0011-06-2-001." ></td>
	<td class="line x" title="171:171	Anyopinions, findings, conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the view of DARPA." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W07-0909
Cross Lingual and Semantic Retrieval for Cultural Heritage Appreciation
Szpektor, Idan;Dagan, Ido;Lavie, Alon;Shacham, Danny;Wintner, Shuly;"></td>
	<td class="line x" title="1:167	Proceedings of the Workshop on Language Technology for Cultural Heritage Data (LaTeCH 2007), pages 6572, Prague, 28 June 2007." ></td>
	<td class="line x" title="2:167	c2007 Association for Computational Linguistics Cross Lingual and Semantic Retrieval for Cultural Heritage Appreciation Idan Szpektor, Ido Dagan Dept. of Computer Science Bar Ilan University szpekti@cs.biu.ac.il Alon Lavie Language Technologies Inst." ></td>
	<td class="line x" title="3:167	Carnegie Mellon University alavie+@cs.cmu.edu Danny Shacham, Shuly Wintner Dept. of Computer Science University of Haifa shuly@cs.haifa.ac.il Abstract We describe a system which enhances the experience of museum visits by providing users with language-technology-based information retrieval capabilities." ></td>
	<td class="line x" title="4:167	The system consists of a cross-lingual search engine, augmented by state of the art semantic expansion technology, specifically designed for the domain of the museum (history and archaeology of Israel)." ></td>
	<td class="line x" title="5:167	We discuss the technology incorporated in the system, its adaptation to the specific domain and its contribution to cultural heritage appreciation." ></td>
	<td class="line x" title="6:167	1 Introduction Museum visits are enriching experiences: they provide stimulation to the senses, and through them to the mind." ></td>
	<td class="line x" title="7:167	But the experience does not have to end when the visit ends: further exploration of the artifacts and their influence on the visitor is possible after the visit, either on location or elsewhere." ></td>
	<td class="line x" title="8:167	One common means of exploration is Information Retrieval (IR) via a Search Engine." ></td>
	<td class="line x" title="9:167	For example, a museum could implement a search engine over a collection of documents relating to the topics exhibited in the museum." ></td>
	<td class="line x" title="10:167	However, such document collections are usually much smaller than general collections, in particular the World Wide Web." ></td>
	<td class="line x" title="11:167	Consequently, phenomena inherent to natural languages may severely hamper the performance of human language technology when applied to small collections." ></td>
	<td class="line x" title="12:167	One such phenomenon is the semantic variability of natural languages, the ability to express a specific meaning in many different ways." ></td>
	<td class="line x" title="13:167	For example, the expression Archaeologists found a new tomb can be expressed also by Archaeologists discovered a tomb or A sarcophagus was dug up by Egyptian Researchers." ></td>
	<td class="line x" title="14:167	On top of monolingual variability, the same information can also be expressed in different languages." ></td>
	<td class="line x" title="15:167	Ignoring natural language variability may result in lower recall of relevant documents for a given query, especially in small document collections." ></td>
	<td class="line x" title="16:167	This paper describes a system that attempts to cope with semantic variability through the use of state of the art human language technology." ></td>
	<td class="line x" title="17:167	The system provides both semantic expansion and cross lingual IR (and presentation of information) in the domain of archaeology and history of Israel." ></td>
	<td class="line x" title="18:167	It was specifically developed for the Hecht Museum in Haifa, Israel, which contains a small but unique collection of artifacts in this domain." ></td>
	<td class="line x" title="19:167	The system provides different users with different capabilities, bridging over language divides; it addresses semantic variation in novel ways; and it thereby complements the visit to the museum with long-lasting instillation of information." ></td>
	<td class="line x" title="20:167	The main component of the system is a domainspecific search engine that enables users to specify queries and retrieve information pertaining to the domain of the museum." ></td>
	<td class="line x" title="21:167	The engine is enriched by linguistic capabilities which embody an array of means for addressing semantic variation." ></td>
	<td class="line x" title="22:167	Queries are expanded using two main techniques: semantic expansion based on textual entailment; and cross-lingual expansion based on translation of Hebrew queries to English and vice versa." ></td>
	<td class="line x" title="23:167	Retrieved documents are presented as links with associated snippets; the system also translates snippets from Hebrew to English." ></td>
	<td class="line x" title="24:167	The main contribution of this work is, of course, the system itself, which was recently demonstrated 65 successfully at the museum and which we believe could be useful to a variety of museum visitor types, from children to experts." ></td>
	<td class="line x" title="25:167	For example, the system provides Hebrew speakers access to English documents pertaining to the domain of the museum, and vice versa, thereby expanding the availability of multilingual material to museum visitors." ></td>
	<td class="line x" title="26:167	More generally, it is an instance of adaptation of state of the art human language technology to the domain of cultural heritage appreciation, demonstrating how general resources and tools are adapted to a specific domain, thereby improving their accuracy and usability." ></td>
	<td class="line x" title="27:167	Finally, it provides a test-bed for evaluating the contribution of language technology in general, as well as specific components and resources, to a large-scale natural language processing system." ></td>
	<td class="line x" title="28:167	2 Background and Motivation Internet search is hampered by the complexity of natural languages." ></td>
	<td class="line x" title="29:167	The two main characteristics of this complexity are ambiguity and variability: the former refers to the fact that a given text can be interpreted in more than one way; the latter indicates that the same meaning can be linguistically expressed in several ways." ></td>
	<td class="line x" title="30:167	The two phenomena make simple search techniques too weak for unsophisticated users, as existing search engines perform only direct keyword matching, with very limited linguistic processing of the texts they retrieve." ></td>
	<td class="line x" title="31:167	Specifically, IR systems that do not address the variability in languages may suffer from lower recall, especially in restricted domains and small document locations." ></td>
	<td class="line x" title="32:167	We next describe two prominent types of variability that we think should be addressed in IR systems." ></td>
	<td class="line x" title="33:167	2.1 Textual Entailment and Entailment Rules In many NLP applications, such as Question Answering (QA), Information Extraction (IE) and Information Retrieval (IR), it is crucial to recognize that a specific target meaning can be inferred from different text variants." ></td>
	<td class="line x" title="34:167	For example, a QA system needs to induce that Mendelssohn wrote incidental music can be inferred from Mendelssohn composed incidental music in order to answer the question Who wrote incidental music?." ></td>
	<td class="line x" title="35:167	This type of reasoning has been identified as a core semantic inference task by the generic textual entailment framework (Dagan et al. , 2006; Bar-Haim et al. , 2006)." ></td>
	<td class="line x" title="36:167	The typical way to address variability in IR is to use lexical query expansion (Lytinen et al. , 2000; Zukerman and Raskutti, 2002)." ></td>
	<td class="line x" title="37:167	However, there are variability patterns that cannot be described using just constant phrase to phrase entailment." ></td>
	<td class="line x" title="38:167	Another important type of knowledge representation is entailment rules and paraphrases." ></td>
	<td class="line x" title="39:167	An entailment rule is a directional relation between two templates, text patterns with variables, e.g., X compose Y  X write Y ." ></td>
	<td class="line x" title="40:167	The left hand side is assumed to entail the right hand side in certain contexts, under the same variable instantiation." ></td>
	<td class="line x" title="41:167	Paraphrases can be viewed as bidirectional entailment rules." ></td>
	<td class="line x" title="42:167	Such rules capture basic inferences in the language, and are used as building blocks for more complex entailment inference." ></td>
	<td class="line x" title="43:167	For example, given the above entailment rule, a QA system can identify the answer Mendelssohn in the above example." ></td>
	<td class="line x" title="44:167	This need sparked intensive research on automatic acquisition of paraphrase and entailment rules." ></td>
	<td class="line x" title="45:167	Although knowledge-bases of entailment-rules and paraphrases learned by acquisition algorithms were used in other NLP applications, such as QA (Lin and Pantel, 2001; Ravichandran and Hovy, 2002) and IE (Sudo et al. , 2003; Romano et al. , 2006), to the best of our knowledge the output of such algorithms was never applied to IR before." ></td>
	<td class="line x" title="46:167	2.2 Cross Lingual Information Retrieval The difficulties caused by variability are amplified when the user is not a native speaker of the language in which the retrieved texts are written." ></td>
	<td class="line x" title="47:167	For example, while most Israelis can read English documents, fewer are comfortable with the specification of English queries." ></td>
	<td class="line x" title="48:167	In a museum setting, some visitors may be able to read Hebrew documents but still be relatively poor at searching for them." ></td>
	<td class="line x" title="49:167	Other visitors may be unable to read Hebrew texts, but still benefit from non-textual information that are contained in Hebrew documents (e.g. , pictures, maps, audio and video files, external links, etc.) This problem is addressed by the paradigm of Cross-Lingual Information Retrieval (CLIR)." ></td>
	<td class="line x" title="50:167	This paradigm has become a very active research area in recent years, addressing the needs of multilingual and non-English speaking communities, such as the 66 European Union, East-Asian nations and Spanish speaking communities in the US (Hull and Grefenstette, 1996; Ballesteros and Croft, 1997; Carbonell et al. , 1997)." ></td>
	<td class="line x" title="51:167	The common approach for CLIR is to translate a query in a source language to another target language and then issue the translated query to retrieve target language documents." ></td>
	<td class="line x" title="52:167	As explained above, CLIR research has to address various generic problems caused by the variability and ambiguity of natural languages, as well as specific problems related to the particular languages being addressed." ></td>
	<td class="line x" title="53:167	3 Coping with Semantic Variability in IR We describe a search engine that is capable of performing: (a) semantic English information retrieval; and (b) cross-lingual (Hebrew-English and EnglishHebrew) information retrieval, allowing users to pose queries in either of the two languages and retrieve documents in both." ></td>
	<td class="line x" title="54:167	This is achieved by two sub-processes of the search engine: first, the engine performs shallow semantic linguistic inference and supports the retrieval of documents which contain phrases that imply the meaning of the translated query, even when no exact match of the translated keywords is found." ></td>
	<td class="line x" title="55:167	This is enabled by automatic acquisition of semantic variability patterns that are frequent in the language, which extend traditional lexical query expansion techniques." ></td>
	<td class="line x" title="56:167	Second, the engine translates the original or expanded query to the target language, based on several linguistic processes and a machine readable bilingual dictionary." ></td>
	<td class="line x" title="57:167	The result is a semantic expansion of a given query to a variety of alternative wordings in which an answer to this query may be expressed in the target language of the retrieved documents." ></td>
	<td class="line x" title="58:167	These enhancements are facilitated via a specification of the domain." ></td>
	<td class="line x" title="59:167	As our system is specifically designed to work in the domain of the history and archaeology, we could focus our attention on resources and tools that are dedicated to this domain." ></td>
	<td class="line x" title="60:167	Thus, for example, lexicons and dictionaries, whose preparation is always costly and time consuming, were developed with the specific domain in mind; and textual entailment and paraphrase patterns were extracted for the specific domain." ></td>
	<td class="line x" title="61:167	While the resulting system is focused on visiting the Hecht Museum, the methodology which we used and discuss here can be adapted to other areas of cultural heritage, as well as to other narrow domains, in the same way." ></td>
	<td class="line x" title="62:167	3.1 Setting Up a Basic Retrieval Application We created a basic retrieval system in two steps: first, we collected relevant documents; then, we implemented a search engine over the collected documents." ></td>
	<td class="line x" title="63:167	In order to construct a local corpus, an archaeology expert searched the Web for relevant sites and pages." ></td>
	<td class="line x" title="64:167	We then downloaded all the documents linked from those pages using a crawler." ></td>
	<td class="line x" title="65:167	The expert looked for documents in both English and Hebrew." ></td>
	<td class="line x" title="66:167	In total, we collected a non-comparable bilingual corpus for Archaeology containing several thousand documents in English and Hebrew." ></td>
	<td class="line x" title="67:167	We implemented our enhanced retrieval modules on top of the basic Jakarta Lucene indexing and search engine1." ></td>
	<td class="line x" title="68:167	All documents were indexed using Lucene, but instead of inflected words, we indexed the lemma of each word (see detailed description of our Hebrew lemmatization in Section 3.3)." ></td>
	<td class="line x" title="69:167	In order to match the indexed terms, query terms (either Hebrew or English) were also lemmatized before the index was searched, in a manner similar to lemmatizing the documents." ></td>
	<td class="line x" title="70:167	3.2 Query Expansion Using Entailment Rules As described in Section 2.1, entailment rules had not been used as a knowledge resource for expanding IR queries, prior to our work." ></td>
	<td class="line x" title="71:167	In this paper we use this resource instead of the typical lexical expansion in order to test its benefit." ></td>
	<td class="line x" title="72:167	Most entailment rules capture relations between different predicates." ></td>
	<td class="line x" title="73:167	We thus focus on documents retrieved for queries that contain a predicate over one or two entities, which we term here Relational IR." ></td>
	<td class="line x" title="74:167	We would like to retrieve only documents that describe an occurrence of that predicate, but possibly in words different than the ones used in the query." ></td>
	<td class="line x" title="75:167	In this section we describe in detail how we learn entailment rules and how we apply them in query expansion." ></td>
	<td class="line oc" title="76:167	Automatically Learning Entailment Rules from the Web Many algorithms for automatically learning paraphrases and entailment rules have been explored in recent years (Lin and Pantel, 2001; 1http://jakarta.apache.org/lucene/docs/index.html 67 Ravichandran and Hovy, 2002; Shinyama et al. , 2002; Barzilay and Lee, 2003; Sudo et al. , 2003; Szpektor et al. , 2004; Satoshi, 2005)." ></td>
	<td class="line x" title="77:167	In this paper we use TEASE (Szpektor et al. , 2004), a stateof-the-art unsupervised acquisition algorithm for lexical-syntactic entailment rules." ></td>
	<td class="line x" title="78:167	TEASE acquires entailment relations for a given input template from the Web." ></td>
	<td class="line x" title="79:167	It first retrieves from the Web sentences that match the input template." ></td>
	<td class="line x" title="80:167	From these sentences it extracts the variable instantiations, termed anchor-sets, which are identified as being characteristic for the input template based on statistical criteria." ></td>
	<td class="line x" title="81:167	Next, TEASE retrieves from the Web sentences that contain the extracted anchor-sets." ></td>
	<td class="line x" title="82:167	The retrieved sentences are parsed and the anchors found in each sentence are replaced with their corresponding variables." ></td>
	<td class="line x" title="83:167	Finally, from this retrieved corpus of parsed sentences, templates that are assumed to entail or be entailed by the input template are learned." ></td>
	<td class="line x" title="84:167	The learned templates are ranked by the number of occurrences they were learned from." ></td>
	<td class="line x" title="85:167	Entailment Rules for Domain Specific Query Expansion Our goal is to use the knowledge-base of entailment rules learned by TEASE in order to perform query expansion." ></td>
	<td class="line x" title="86:167	The two subtasks that arise are: (a) acquiring an appropriate knowledge-base of rules; and (b) expanding a query given such a knowledge-base." ></td>
	<td class="line x" title="87:167	TEASE learns entailment rules for a given input template." ></td>
	<td class="line x" title="88:167	As our document collection is domain specific, a list of such relevant input templates can be prepared." ></td>
	<td class="line x" title="89:167	In our case, we used an archaeology expert to generate a list of verbs and verb phrases that relate to archaeology, such as: excavate, invade, build, reconstruct, grow and be located in." ></td>
	<td class="line x" title="90:167	We then executed TEASE on each of the templates representing these verbs in order to learn from the Web rules in which the input templates participate." ></td>
	<td class="line x" title="91:167	An example for such rules is presented in Table 1." ></td>
	<td class="line x" title="92:167	We learned approximately 3900 rules for 80 input templates." ></td>
	<td class="line x" title="93:167	Since TEASE learns lexical-syntactic rules, we need a syntactic representation of the query." ></td>
	<td class="line x" title="94:167	We parse each query using the Minipar dependency parser (Lin, 1998)." ></td>
	<td class="line x" title="95:167	We next try to match the left hand side template of every rule in the learned knowledge-base." ></td>
	<td class="line x" title="96:167	Since TEASE does not identify the direction of the relation learned between two templates, we try both directional rules that are induced from a learned relation." ></td>
	<td class="line x" title="97:167	Whenever a match is found, a new query is generated, in which the constant terms of the matched left hand side template are replaced with the constant terms of the right hand side template." ></td>
	<td class="line x" title="98:167	For example, given the query excavations of Jerusalem by archaeologists and a learned rule excavation of Y by X X dig in Y, a new query is generated, containing the terms archaeologists dig in Jerusalem." ></td>
	<td class="line x" title="99:167	Finally, we retrieve all the documents that contain all the terms of at least one of the expanded queries (including the original query)." ></td>
	<td class="line x" title="100:167	The basic search engine provides a score for each document." ></td>
	<td class="line x" title="101:167	We re-score each document as the sum of scores it obtained from the different queries that it matched." ></td>
	<td class="line x" title="102:167	Figure 1 shows an example of our query expansion, where the first retrieved documents do not contain the words used to describe the predicate in the query, but other ways to describe it." ></td>
	<td class="line x" title="103:167	All the templates learned by TEASE contain two variables, and thus the rules that are learned can only be applied to queries that contain predicates over two terms." ></td>
	<td class="line x" title="104:167	In order to broaden the coverage of the learned rules, we automatically generate also all the partial templates of a learned template." ></td>
	<td class="line x" title="105:167	These are templates that contain just one of variables in the original template." ></td>
	<td class="line x" title="106:167	We then generate rules between these partial templates that correspond to the original rules." ></td>
	<td class="line x" title="107:167	With partial templates/rules, expansion for the query in Figure 1 becomes possible." ></td>
	<td class="line x" title="108:167	3.3 Cross-lingual IR Until very recently, linguistic resources for Hebrew were few and far between (Wintner, 2004)." ></td>
	<td class="line x" title="109:167	The last few years, however, have seen a proliferation of resources and tools for this language." ></td>
	<td class="line x" title="110:167	In this work we utilize a relatively large-scale lexicon of over 22,000 entries (Itai et al. , 2006); a finite-state based morphological analyzer of Hebrew that is directly linked to the lexicon (Yona and Wintner, 2007); a mediumsize bilingual dictionary of some 24,000 word pairs; and a rudimentary Hebrew to English machine translation system (Lavie et al. , 2004)." ></td>
	<td class="line x" title="111:167	All these resources had to be adapted to the domain of the Hecht museum." ></td>
	<td class="line x" title="112:167	Cross-lingual language technology is utilized in 68 Figure 1: Semantic expansion example." ></td>
	<td class="line x" title="113:167	Note that the expanded queries that were generated in the first two retrieved texts (listed under matched query) do not contain the original query." ></td>
	<td class="line x" title="114:167	three different components of the system: Hebrew documents are morphologically processed to provide better indexing; query terms in English are translated to Hebrew and vice versa; and Hebrew snippets are translated to English." ></td>
	<td class="line x" title="115:167	We discuss each of these components in this section." ></td>
	<td class="line x" title="116:167	Linguistically-aware indexing The correct level of indexing for morphologically-rich language has been a matter of some debate in the information retrieval literature." ></td>
	<td class="line x" title="117:167	When Arabic is concerned, Darwish and Oard (2002) conclude that Character ngrams or lightly stemmed words were found to typically yield near-optimal retrieval effectiveness." ></td>
	<td class="line x" title="118:167	Since Hebrew is even more morphologically (and orthographically) ambiguous than Arabic, and especially in light of the various prefix particles which can be attached to Hebrew words, we opted for full morphological analysis of Hebrew documents before they are indexed, followed by indexing on the lexeme." ></td>
	<td class="line x" title="119:167	We use the HAMSAH morphological analyzer (Yona and Wintner, 2007), which was recently rewritten in Java and is therefore more portable and efficient (Wintner, 2007)." ></td>
	<td class="line x" title="120:167	We processed the entire domain specific corpus described above and used the resulting lexemes to index documents." ></td>
	<td class="line x" title="121:167	This preprocessing brought to the foreground several omissions of the analyzer, mostly due to domain-specific terms missing in the lexicon." ></td>
	<td class="line x" title="122:167	We selected the one thousand most frequent words with no morphological analysis and added their lexemes to the lexicon." ></td>
	<td class="line x" title="123:167	While we do not have quantitative evaluation metrics, the coverage of the system improved in a very evident way." ></td>
	<td class="line x" title="124:167	Query translation When users submit a query in one language they are provided with the option to request a translation of the query to the other language, thereby retrieving documents in the other language." ></td>
	<td class="line x" title="125:167	The motivation behind this capability is that users who may be able to read documents in a language may find the specification of queries in that language too challenging; also, retrieving documents in a foreign language may be useful due to the non-textual information in the retrieved documents, especially in a museum environment." ></td>
	<td class="line x" title="126:167	In order to support cross-lingual query specification we capitalized on a medium-size bilingual dictionary that was already used for Hebrew to English machine translation." ></td>
	<td class="line x" title="127:167	Since the coverage of the dictionary was rather limited, and many domainspecific items were missing, we chose the one thousand most frequent lexemes which had no transla69 Input Template Learned Template X excavate Y X discover Y, X find Y, X uncover Y, X examine Y, X unearth Y, X explore Y X construct Y X build Y, X develop Y, X create Y, X establish Y X contribute to Y X cause Y, X linked to Y, X involve in Y date X to Y X built in Y, X began in Y, X go back to Y X cover Y X bury Y, X provide coverage for Y X invade Y X occupy Y, X attack Y, X raid Y, X move into Y X restore Y X protect Y, X preserve Y, X save Y, X conserve Y Table 1: Examples for correct templates that were learned by TEASE for input templates." ></td>
	<td class="line x" title="128:167	tions and translated them manually, augmenting the lexicon with missing Hebrew lexemes where necessary and expanding the bilingual dictionary to cover this domain." ></td>
	<td class="line x" title="129:167	In order to translate query terms we use the Hebrew English dictionary also as an English-Hebrew dictionary." ></td>
	<td class="line x" title="130:167	While this is known to be sub-optimal, our current results support such an adaptation in lieu of dedicated directional bilingual dictionaries." ></td>
	<td class="line x" title="131:167	Translating a query from one language to another may introduce ambiguity where none exists." ></td>
	<td class="line x" title="132:167	For example, the query term spinh vessel is unambiguous in Hebrew, but once translated into English will result in retrieving documents on both senses of the English word." ></td>
	<td class="line x" title="133:167	Usually, this problem is overcome since users tend to specify multi-term queries, and the terms disambiguate each other." ></td>
	<td class="line x" title="134:167	However, a more systematic solution can be offered since we have access to semantic expansion capabilities (in a single language)." ></td>
	<td class="line x" title="135:167	That is, expanding the query in the source language will result in more query terms which, when translated, are more likely to disambiguate the context." ></td>
	<td class="line x" title="136:167	We leave such an extension for future work." ></td>
	<td class="line x" title="137:167	Snippet translation When Hebrew documents are retrieved, we augment the (Hebrew) snippet which the system produces by an English translation." ></td>
	<td class="line x" title="138:167	We use an extended, improved version of a rudimentary Hebrew to English MT system developed by Lavie et al.(2004)." ></td>
	<td class="line x" title="140:167	Extensions include an improved morphological analysis of the input, an extended bilingual dictionary and a revised set of transfer rules, as well as a more modern transfer engine and a much larger language model for generating the target (English) sentences." ></td>
	<td class="line x" title="141:167	The MT system is transfer based: it performs linguistic pre-processing of the source language (in our case, morphological analysis) and post-processing of the target (generation of English word forms), and uses a small set of transfer rules to translate local structures from the source to the target and create translation hypotheses, which are stored in a lattice." ></td>
	<td class="line x" title="142:167	A statistical language model is used to decode the lattice and select the best hypotheses." ></td>
	<td class="line x" title="143:167	The benefit of this architecture is that domain specific adaptation of the system is relatively easy, and does not require a domain specific parallel corpus (which we do not have)." ></td>
	<td class="line x" title="144:167	The system has access to our domain-specific lexicon and bilingual dictionary, and we even refined some transfer rules due to peculiarities of the domain." ></td>
	<td class="line x" title="145:167	One advantage of the transfer-based approach is that it enables us to treat out-of-lexicon items in a unique way." ></td>
	<td class="line x" title="146:167	We consider such items proper names, and transfer rules process them as such." ></td>
	<td class="line x" title="147:167	As an example, Figure 2 depicts the translation of a Hebrew snippet meaning A jar from the early bronze period with seashells from the Nile." ></td>
	<td class="line x" title="148:167	The word nilws Nile is missing from the lexicon, but this does not prevent the system from producing a legible translation, using the transliterated form where an English equivalent is unavailable." ></td>
	<td class="line x" title="149:167	4 Conclusions We described a system for cross-lingual and semantically-enhanced retrieval of information in the cultural heritage domain, obtained by adapting existing state-of-the-art tools and resources to the domain." ></td>
	<td class="line x" title="150:167	The system enhances the experience of museum visits, using language technology as a vehicle for long-lasting instillation of information." ></td>
	<td class="line x" title="151:167	Due to the novelty of this application and the dearth of available multilingual annotated resources in this domain, we are unable to provide a robust, quan70 Figure 2: Translation example Query Without Expansion With Expansion Relevant Total Relevant Total in Top 10 Retrieved in Top 10 Retrieved discovering boats 2 2 5 86 growing vineyards 0 0 6 8 Persian invasions 5 5 8 22 excavations of the Byzantine period 10 37 10 100 restoring mosaics 0 0 3 69 Table 2: Analysis of the number of relevant documents out of the top 10 and the total number of retrieved documents (up to 100) for a sample of queries." ></td>
	<td class="line x" title="152:167	titative evaluation of the approach." ></td>
	<td class="line x" title="153:167	A preliminary analysis of a sample of queries is presented in Table 2." ></td>
	<td class="line x" title="154:167	It illustrates the potential of expansion for document collections of narrow domain." ></td>
	<td class="line x" title="155:167	In what follows we provide some qualitative impressions." ></td>
	<td class="line x" title="156:167	We observed that the system was able to learn many expansion rules that cannot be induced from manually constructed lexical resources, such as thesauri or WordNet (Fellbaum, 1998)." ></td>
	<td class="line x" title="157:167	This is especially true for rules that are specific for a narrow domain, e.g. X restore Y  X preserve Y ." ></td>
	<td class="line x" title="158:167	Furthermore, the system learned lexical syntactic rules that cannot be expressed by a mere lexical substitution, but include also a syntactic transformation." ></td>
	<td class="line x" title="159:167	For example, date X to Y X go back to Y ." ></td>
	<td class="line x" title="160:167	In addition, since rules are acquired by searching the Web, they are not necessarily restricted to learning from the target domain, but can be learned from similar terminology in other domains." ></td>
	<td class="line x" title="161:167	For example, the rule X discover Y  X find Y was learned from contexts such as {X=astronomers;Y =new planets} and {X=zoologists;Y =new species}." ></td>
	<td class="line x" title="162:167	The quality of the rules that were automatically acquired is mediocre." ></td>
	<td class="line x" title="163:167	We found that although many rules were useful for expansion, they had to be manually filtered in order to retain only rules that achieved high precision." ></td>
	<td class="line x" title="164:167	Finally, we note that applying semantic query expansion (using entailment rules), followed by English to Hebrew query translation, results in query expansion for Hebrew using techniques that were so far applicable only to resource-rich languages, such as English." ></td>
	<td class="line x" title="165:167	Acknowledgements This research was supported by the Israel Internet Association; by THE ISRAEL SCIENCE FOUNDATION (grant No. 137/06 and grant No. 1095/05); by the Caesarea Rothschild Institute for Interdisciplinary Application of Computer Science at the University of Haifa; by the ITC-irst/University of Haifa collaboration; and by the US National Science Foundation (grants IIS-0121631, IIS-0534217, and the Office of International Science and Engineering)." ></td>
	<td class="line x" title="166:167	71 We wish to thank the Hebrew Knowledge Center at the Technion for providing resources for Hebrew." ></td>
	<td class="line x" title="167:167	We are grateful to Oliviero Stock, Martin Golumbic, Alon Itai, Dalia Bojan, Erik Peterson, Nurit Melnik, Yaniv Eytani and Noam Ordan for their help and support." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W07-1424
Mutaphrase: Paraphrasing with FrameNet
Ellsworth, Michael;Janin, Adam;"></td>
	<td class="line x" title="1:170	Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 143??50, Prague, June 2007." ></td>
	<td class="line x" title="2:170	c2007 Association for Computational Linguistics Mutaphrase: Paraphrasing with FrameNet Michael Ellsworth and Adam Janin {infinity,janin}@icsi.berkeley.edu International Computer Science Institute 1947 Center Street, Suite 600 Berkeley, CA 94704-1105 USA Abstract We describe a preliminary version of Mutaphrase, a system that generates paraphrases of semantically labeled input sentences using the semantics and syntax encoded in FrameNet, a freely available lexicosemantic database." ></td>
	<td class="line x" title="3:170	The algorithm generates a large number of paraphrases with a wide range of syntactic and semantic distances from the input." ></td>
	<td class="line x" title="4:170	For example, given the input ?I like eating cheese??" ></td>
	<td class="line x" title="5:170	the system outputs the syntactically distant ?Eating cheese is liked by me??" ></td>
	<td class="line x" title="6:170	the semantically distant ?I fear sipping juice??" ></td>
	<td class="line x" title="7:170	and thousands of other sentences." ></td>
	<td class="line x" title="8:170	The wide range of generated paraphrases makes the algorithm ideal for a range of statistical machine learning problems such as machine translation and language modeling as well as other semanticsdependent tasks such as query and language generation." ></td>
	<td class="line x" title="9:170	1 Introduction A central tenet of statistical natural language processing (NLP) is ?there?s no data like more data??" ></td>
	<td class="line x" title="10:170	One method for generating more data is to restate each phrase in a corpus, keeping similar semantics while changing both the words and the word sequence." ></td>
	<td class="line xc" title="11:170	The efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al. , 2003), document retrieval (Zukerman and Raskutti, 2002), and many others." ></td>
	<td class="line oc" title="12:170	Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al. , 2006; Dolan et al. , 2004; Ibrahim et al. , 2003; Lin and Pantel, 2001; Pang et al. , 2003; Quirk et al. , 2004; Shinyama et al. , 2002)." ></td>
	<td class="line x" title="13:170	Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2)." ></td>
	<td class="line x" title="14:170	c33c59c4ec54c41c58c33c49c4dc49c4cc41c52 c24c49c46c46c45c52c45c4e c54 c33c45c4dc41c4e c54c49c43c53 c29c00c4cc49c4bc45c00c45c41c54c49c4ec47c00c43c48c45c45c53c45c0ec25c41c54c49c4ec47c00c43c48c45c45c53c45c00c49c53c00c4cc49c4bc45c44c00c42c59c00c4dc45c0e c29c00c4cc49c4bc45c00c54c4fc00c53c4ec41c43c4bc00c4fc4ec00c42c52c45c41c44c0e c29c00c46c45c41c52c00c53c49c50c50c49c4ec47c00c4ac55c49c43c45c0ec34c4fc00c53c49c50c00c4fc4ec00c4ac55c49c43c45c00c44c49c53c54c55c52c42c53c00c4dc45c0e Figure 1: Syntactic and semantic similarity to I like eating cheese." ></td>
	<td class="line x" title="15:170	Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic semantic parser such as Shalmaneser (Erk 143 and Pado, 2006), and recursively replaces each semantically parsed phrase with a semantically similar phrase." ></td>
	<td class="line x" title="16:170	To generate each new phrase, each of the semantic parts of the original phrase is mapped, using FrameNet data, onto a new word or phrase whose position and syntactic marking may be quite different." ></td>
	<td class="line x" title="17:170	The Mutaphrase algorithm outputs a large set of paraphrases with a variety of distances from the input in terms of both syntax and semantics; see Figure 1." ></td>
	<td class="line x" title="18:170	Depending on the needs of the application, filtering can be applied to limit the distance to a desired range." ></td>
	<td class="line x" title="19:170	For example, language modeling may benefit from a wider variety of semantic outputs, since if I like eating cheese is in-domain, then I like sipping juice is also likely in-domain." ></td>
	<td class="line x" title="20:170	Other applications, e.g. Question Answering, require more stringent limits on semantic distance." ></td>
	<td class="line x" title="21:170	See Section 4." ></td>
	<td class="line x" title="22:170	1.1 Current Limitations The current implementation of Mutaphrase suffers from several limitations." ></td>
	<td class="line x" title="23:170	Perhaps the most significant is that the input sentences must be semantically labeled using FrameNet annotations." ></td>
	<td class="line x" title="24:170	Since no automated systems for FrameNet-specific annotation are currently incorporated into our algorithm, input is limited to hand-annotated sentences." ></td>
	<td class="line x" title="25:170	Also, certain types of semantic ill-formedness are permitted (e.g. I like sipping meat), and some types of syntax are not well supported (e.g. conjunctions, relativeclauses)." ></td>
	<td class="line x" title="26:170	We believe all these factors can be addressed; they are covered briefly in Future Work (Section 4)." ></td>
	<td class="line x" title="27:170	We confine ourselves in other sections to describing the core Mutaphrase algorithm as currently implemented." ></td>
	<td class="line x" title="28:170	2 FrameNet The primary resource used in Mutaphrase is FrameNet (Fontenelle, 2003; FrameNet, 2007b), a lexico-semantic database that describes concepts and their interrelations, wordform and wordsequence information, syntactic categories, and mappings between conceptual and lexical/syntactic information." ></td>
	<td class="line x" title="29:170	All of these are grounded in handannotated examples of real-world sentences." ></td>
	<td class="line x" title="30:170	At a slightly more abstract level, FrameNet can be described as providing a two-way mapping between meaning (semantics) and form (syntax, wordforms, sequences)." ></td>
	<td class="line x" title="31:170	2.1 Semantics The conceptual information is represented using frames, where a frame is a type of schema or scenario (e.g. Motion, Commercial transaction), and frame elements (FEs), which are the participants and parameters of the frames (e.g. Motion.Path, Commercial transaction.Buyer)." ></td>
	<td class="line x" title="32:170	Frames and their frame elements are related and mapped with a limited type of conceptual ontology involving Inheritance (i.e. subtype), Subframe (i.e. temporal subpart), Using (i.e. presupposition) and a few other relation types." ></td>
	<td class="line x" title="33:170	2.2 Syntax On the form side, the representation is more minimal." ></td>
	<td class="line x" title="34:170	Wordforms and word-sequences are represented so that words with multiple wordforms (e.g. take/took) and word sequences with wordforms (e.g. take/took off ) can be referred to as unitary objects." ></td>
	<td class="line x" title="35:170	We have a category Support (and the more specific label ?Copula??" ></td>
	<td class="line x" title="36:170	for pieces of multi-word expressions that are optional for expressing the semantics of the whole (e.g. take in take a bath)." ></td>
	<td class="line x" title="37:170	FrameNet also represents a small but sufficiently rich set of syntactic categories of English (i.e. phrase types or PTs, such as ?Sfin??" ></td>
	<td class="line x" title="38:170	i.e. finite sentence) and syntactic relations (i.e. grammatical functions or GFs, e.g. ?Object??." ></td>
	<td class="line x" title="39:170	2.3 Syntax-Semantics Bindings The most vital part of the FrameNet data for our Mutaphrase algorithm is the mappings between semantics and syntax." ></td>
	<td class="line x" title="40:170	There are several categories pertaining to this in the data." ></td>
	<td class="line x" title="41:170	Lexical units (LUs) are a pairing of words/word sequences with the frame each evokes." ></td>
	<td class="line x" title="42:170	The valences for each LU are sequences in which semantic and form information pertinent to phrases are paired." ></td>
	<td class="line x" title="43:170	They are not stored in the database, so we have created a process that produces them entirely automatically (see 3.2)." ></td>
	<td class="line x" title="44:170	For example, for the LU hand in the Giving frame and possible in the Likelihood frame, we have the following annotated sentences: 1." ></td>
	<td class="line x" title="45:170	[She]Donor/NP/Ext [handed]Target [a bag]Theme/NP/Obj [to Nob]Recipient/PP(to)/Dep 144 2." ></td>
	<td class="line x" title="46:170	[It]Null [was]Copula [possible]Target [that he had been hoping to frighten Steve]Hypothetical event/Sfin(that)/Dep Example 1 above shows a typical valence, in which most of the positions are semantically labeled with a frame element which is paired with syntactic GF and PT information." ></td>
	<td class="line x" title="47:170	The second annotation (2) is more complex, exemplifying each of the major categories that make up the positions of a valence." ></td>
	<td class="line x" title="48:170	The categories are: 1." ></td>
	<td class="line x" title="49:170	a Null element, with syntax but no semantics (usually there or it) 2." ></td>
	<td class="line x" title="50:170	a Support or Copula with its wordforms 3." ></td>
	<td class="line x" title="51:170	a Target (i.e. an LU or word that is part of an LU) with its wordforms, conceptually representing a frame 4." ></td>
	<td class="line x" title="52:170	a frame-element/phrase-type/grammaticalfunction phrase description, which puts together semantic (FE) information with syntax (GF and PT); the PT also indicates fixed words (e.g. the word that in the example above) We can abstract away from the individual sentences, preserving only the sequences of positions with their features, as in the following representation of sentence 2 above: Null(it), Copula, Target(possible), Hypothetical event/Dep/Sfin(that) These abstract valences are the basis for the algorithm we present here." ></td>
	<td class="line x" title="53:170	There are typically between two and ten basic patterns associated with each annotated lexical unit, encompassing alternations in the realization of FEs such as Active/Passive (I recommended her vs. She was recommended by me), the Dative Alternation (He handed the paper to Stephen vs. He handed Stephen the paper), optional elements (I ate dinner vs. I ate) and many more." ></td>
	<td class="line x" title="54:170	Basing our algorithm on rearranging the fillers of these FEs allows us to abstract away from syntax, since the FEs of a frame express the same relations regardless of the LU or syntax they occur with." ></td>
	<td class="line x" title="55:170	Some meaning differences between LUs within the same frame (e.g. drink vs. eat) are not overtly modeled in FrameNet." ></td>
	<td class="line x" title="56:170	Other resources, such as WordNet, could provide added information in cases requiring finer granularity (see Section 4)." ></td>
	<td class="line x" title="57:170	3 Mutaphrase Algorithm At a very high level, the paraphrase algorithm that we use is as follows: we begin with a sentence with frame-semantic annotation, replace each lexical unit and its associated frame Elements with an alternative valence, then filter the output for its syntactic and semantic fit with the original sentence." ></td>
	<td class="line x" title="58:170	The valences may be drawn from either the same LU, an LU of the same frame, or an LU of a related frame." ></td>
	<td class="line x" title="59:170	Frame: Desiring Frame: Opinion NP/Ext Event 'is desired' Target Poss/Gen 'Your' Cognizer 'opinion' Target + = NP/Ext 'I' 'want' Frame: Opinion NP/Obj Poss/Gen 'your' Cognizer 'opinion' Target Frame: Desiring Experiencer Event Target NP/Ext 'is desired' Frame: Desiring Event Target B: Attested ValenceA: Input Tree C: Output Tree Figure 2: Algorithm Sketch: A syntactic/semantic tree of the original sentence (A) is rearranged to match a different valence (B), producing a new tree (C); thus I want your opinion yields the paraphrase Your opinion is desired." ></td>
	<td class="line x" title="60:170	Figure 2 shows an example of one step of the algorithm." ></td>
	<td class="line x" title="61:170	An input tree for the sentence I want your opinion is shown in Figure 2A." ></td>
	<td class="line x" title="62:170	The particular valence for the Desiring frame in Figure 2B describes the relations between the word desire and its dependents in sentences like A meeting was desired." ></td>
	<td class="line x" title="63:170	Because the phrase types and grammatical functions of the FEs between the input and the attested valence are compatible, it is possible to replace the input 145 frame with the new valence." ></td>
	<td class="line x" title="64:170	The output is shown in Figure 2C." ></td>
	<td class="line x" title="65:170	The remainder of this section describes in more detail how this algorithm is implemented." ></td>
	<td class="line x" title="66:170	3.1 Building a Syntax/Semantics Tree from FrameNet Data Because the FEs of the original sentence are often filled by phrases with their own annotation, the initial syntactic/semantic annotation is (conceptually, at least) in the form of a graph." ></td>
	<td class="line x" title="67:170	Typically, the graph is nearly a tree, with few or no non-tree edges1." ></td>
	<td class="line x" title="68:170	Hereafter, we will use the term ?tree??even for the cases where there are non-tree edges." ></td>
	<td class="line x" title="69:170	Since the data are not organized in this format in the FrameNet output, we have implemented a routine which can turn FrameNet data into a syntacticosemantic tree; tree examples can be seen in Figure 2A and Figure 2C." ></td>
	<td class="line x" title="70:170	3.2 Building Ordered Valences from FrameNet Data As mentioned in Section 2.3, we have constructed a routine to parse FrameNet data to produce the valences for each LU of a frame." ></td>
	<td class="line x" title="71:170	The basic output is an ordered list of syntactico-semantic elements, optional apositional features (e.g. passive +/-), and the frequency of the pattern.2 One innovation of our algorithm is its ability to handle multiword LUs." ></td>
	<td class="line x" title="72:170	It simply identifies each word of the LU as a separate element in the list, marking each with the label ?Target??" ></td>
	<td class="line x" title="73:170	Thus the ordered valences of take off.v in the Undressing frame include, among others: ??Wearer/NP/Ext, take/Target, off/Target, Clothing/NP/Obj; Frequency: 57/68 (e.g. I TOOK OFF my watch) ??Wearer/NP/Ext, take/Target, Clothing/NP/Obj, 1These non-tree edges are introduced when a phrase is an FE of more than one frame." ></td>
	<td class="line x" title="74:170	In keeping with normal syntactic analysis, we treat the node as non-local to all but one parent." ></td>
	<td class="line x" title="75:170	2Although frequency of a particular pattern in the FrameNet data is not strictly representative of the frequency of that pattern in the corpus, a close examination reveals that the rank order of patterns is largely identical, i.e. the most common pattern in FrameNet represents the most common pattern in the corpus." ></td>
	<td class="line x" title="76:170	How useful this inexact statistical data will be is the subject of future research." ></td>
	<td class="line x" title="77:170	off/Target; Frequency: 7/68 (e.g. You TAKE your shoes OFF) One way of thinking about the valence set is that it represents possible orderings of subparts of a phrase that is semantically a frame instance and syntactically a phrase headed by the Target (see, for example, Figure 2B)." ></td>
	<td class="line x" title="78:170	This semantic/syntactic information is detailed enough to build the syntax of a phrase, given FrameNet-style semantics." ></td>
	<td class="line x" title="79:170	3.3 Core algorithm Once the input has been turned into a tree and there is a set of alternative ways of expressing each frame that is in the input, the algorithm then recurses downward and then, as it returns up, replaces each phrase/frame node with a set of alternative phrases." ></td>
	<td class="line x" title="80:170	In the simplest case, these phrases are built from all the valences that are attested for the frame that the original phrase expressed 3." ></td>
	<td class="line x" title="81:170	In other words, our algorithm is a recursive tree-rewrite in which the current valence of the current LU is replaced by many alternate valences of many different LUs." ></td>
	<td class="line x" title="82:170	In the recursion, word and phrase nodes not headed by an LU are kept the same (except for pronouns, which are expanded to all their wordforms, e.g. me to I/me/my/mine)." ></td>
	<td class="line x" title="83:170	The child phrases of such an unparaphrased node, if they are headed by an LU or pronoun, can be paraphrased as long as the paraphrases match the phrase type and grammatical function of the original child phrase." ></td>
	<td class="line x" title="84:170	In Figure 2, the original sentence (represented in Figure 2A) has the phrase representing the Desiring frame replaced with an alternative phrase evoking the same frame (Figure 2B) to produce a new, roughly semantically equivalent sentence (Figure 2C) by expressing the same set of frames in the same FE relations to each other." ></td>
	<td class="line x" title="85:170	In practice, we have to throw away at the outset many of the valences because they include FEs that are not in the input sentence4 or because they have syntactic requirements of their child phrases which 3Our algorithm will work just as well with related frames as long as the relevant FEs are mapped in the FrameNet data." ></td>
	<td class="line x" title="86:170	Controlling the distance, direction, and relation-types of related frames that are included for paraphrase (if any) is one way to control the degree of semantic diversity of the paraphrase output." ></td>
	<td class="line x" title="87:170	See further Section 3.4." ></td>
	<td class="line x" title="88:170	4Thus attempting to use the valence Experiencer/NP/Ext, Degree/AVP/Dep, want/Target, Event/NP/Obj (e.g. I really 146 cannot be filled by a paraphrase of the child phrases." ></td>
	<td class="line x" title="89:170	For example, for the input sentence I gave presents to friends, the code can output 560 (unfiltered) paraphrases." ></td>
	<td class="line x" title="90:170	A random selection from the output includes Presents bequeathed to friends, I handed in presents, and Presents donated by I. Of these, the first and last are filtered out as not filling the original sentential context and the last, in addition, is filtered out because of the mismatch between the pronoun wordform I and the non-subject grammatical function." ></td>
	<td class="line x" title="91:170	To further refine the paraphrases, we must eliminate examples that are not compatible with the input sentence." ></td>
	<td class="line x" title="92:170	In our current implementation, our algorithm filters out incorrect syntax during the recursion over the tree." ></td>
	<td class="line x" title="93:170	Ultimately, we will also filter out malformed semantics." ></td>
	<td class="line x" title="94:170	The rest of this section is devoted to an explication of the details of this filtering." ></td>
	<td class="line x" title="95:170	3.4 Syntactic/Semantic Compatibility For both syntax and semantics, the degree of viability of a paraphrase can be divided up into two components: well-formedness and similarity." ></td>
	<td class="line x" title="96:170	Syntactic and semantic well-formedness is always desirable and the algorithm seeks to maximize it in ways that are outlined below." ></td>
	<td class="line x" title="97:170	Similarity between the original sentence and its paraphrases (or among the paraphrases), however, may be more or less desirable depending on the task." ></td>
	<td class="line x" title="98:170	Figure 1 shows an example of the various degrees of syntactic and semantic similarity of the paraphrase output." ></td>
	<td class="line x" title="99:170	To maintain flexibility, we will need several control parameters to allow us to filter our output for syntactic/semantic similarity." ></td>
	<td class="line x" title="100:170	3.4.1 Syntactic Compatibility Syntactic incompatibilities most commonly result from gross mismatches between the Phrase Type called for in a new valence and the Phrase Type possibilities available for the child phrase." ></td>
	<td class="line x" title="101:170	For example, if the initial sentence for paraphrase is I want your opinion as in 1 below (repeated from Figure 2), Valence 2 below represents a PT mismatch, since I, an NP filler of the Experiencer role want another chance) when paraphrasing the initial sentence in Figure 2 will not work, since there is nothing in the original to fill the Degree FE mentioned here." ></td>
	<td class="line x" title="102:170	in the original sentence, is not modifiable into an adjective phrase (AJP)." ></td>
	<td class="line x" title="103:170	1." ></td>
	<td class="line x" title="104:170	Experiencer/NP/Ext, want/Target, Event/NP/Obj 2." ></td>
	<td class="line x" title="105:170	There/Null, be/Copula, Experiencer/AJP/Dep, desire/Target, Event/PP(for)/Dep (e.g. There is a public desire for transparency) 3." ></td>
	<td class="line x" title="106:170	There/Null, be/Copula, desire/Target, Experiencer/PP(in)/Dep, Event/PP(for)/Dep (e.g. There was a desire in America for home rule) This filtering is vital, as otherwise valence 2 would yield the awful There is me desire for your opinion." ></td>
	<td class="line x" title="107:170	However, phrase types that are not exact matches may nevertheless be compatible with each other." ></td>
	<td class="line x" title="108:170	Valence 3, for example, is compatible with the original valence, since the original Experiencer and Event FEs were filled by NPs, to which prepositions can be added to match the PP realizations required by Valence 3." ></td>
	<td class="line x" title="109:170	This yields another paraphrase of the sentence in Figure 2: There is a desire in me for your opinion." ></td>
	<td class="line x" title="110:170	Similarly, full sentential clauses can be modified to match VPs by truncation of the External (subject) argument, etc. A phrase from the original sentence may also be omitted to match an empty phrase in the paraphrase, as seen in the omission of the Experiencer in the paraphrase in Figure 2." ></td>
	<td class="line x" title="111:170	These alternations provide more variety in the potential phrase types of the paraphrases." ></td>
	<td class="line x" title="112:170	Which syntactic modifications are allowed should be an externally controllable parameter, but this has not yet been implemented." ></td>
	<td class="line x" title="113:170	In general, allowing fewer types of modification should move the average output leftward in the syntax/semantic similarity graph in Figure 1 (toward more syntactic similarity)." ></td>
	<td class="line x" title="114:170	Although every annotated valence represents a grammatical structure, some of these structures will more likely be judged as well-formed than others; in particular, infrequent patterns are more likely illformed than frequent ones." ></td>
	<td class="line x" title="115:170	An additional controllable parameter, allowing a trade-off between recall and precision, is a frequency cut-off for accepting a valence pattern based on the number of times 147 the pattern is found in the FrameNet data." ></td>
	<td class="line x" title="116:170	Our algorithm currently produces a ranked list of paraphrases based on exactly this frequency parameter, and downstream processing can choose a cut-off frequency or n-best to reduce the total output." ></td>
	<td class="line x" title="117:170	3.4.2 Semantic Filtering Lexical units of the same frame are not necessarily synonyms; they may be antonyms or coordinate terms (i.e. co-hyponyms)." ></td>
	<td class="line x" title="118:170	For example, cheese and juice are both in the Food frame, but I like eating cheese and I like eating juice are certainly not a semantic match!" ></td>
	<td class="line x" title="119:170	In fact, the second is a semantically ill-formed modification of the first." ></td>
	<td class="line x" title="120:170	Similarly, like and hate are both in the Experiencer subject frame." ></td>
	<td class="line x" title="121:170	While I hate eating cheese is similar to I like eating cheese in describing an attitude toward eating cheese, they are not an exact semantic match either; in this case, however, the lack of semantic similarity does not lead to semantic ill-formedness." ></td>
	<td class="line x" title="122:170	For some tasks such as expanding a language model, exact semantic match is not necessary, but for tasks that require strict semantic match, there are several simple ways to increase robustness." ></td>
	<td class="line x" title="123:170	Tighter filtering, of whatever kind, will move the average output of the algorithm downward in the syntax/semantic similarity graph in Figure 1 (toward more semantic similarity)." ></td>
	<td class="line x" title="124:170	3.5 Preliminary Results We have implemented the above algorithm to the point that it is capable of producing paraphrases of arbitrary input sentences that have received proper FrameNet annotation." ></td>
	<td class="line x" title="125:170	A large number of paraphrases with a variety of phrase types are produced, but the lack of semantic filtering occasionally leads to semantically ill-formed results." ></td>
	<td class="line x" title="126:170	The output is ranked purely according to the frequency in the FrameNet data of the valences used to build the paraphrase." ></td>
	<td class="line x" title="127:170	For the sentence I like eating cheese, the paraphraser produced 8403 paraphrases, of which the following was top-ranked: I resented drinking cheese, which suffers from the semantic mismatch problems discussed in Section 3.4.2." ></td>
	<td class="line x" title="128:170	Some other output at random: ??I am interested in cheese devouring." ></td>
	<td class="line x" title="129:170	??I was nervous that cheese?s ingested." ></td>
	<td class="line x" title="130:170	??I?m worried about gobbling down cheese." ></td>
	<td class="line x" title="131:170	??My regrets were that cheese was eaten by me. Since most of the annotation in the Ingestion frame (the frame for eat, etc)." ></td>
	<td class="line x" title="132:170	concerns eating rather than drinking, the majority of the output is semantically well-formed." ></td>
	<td class="line x" title="133:170	The paraphrases generated from the Experiencer subject frame (the frame for like, interested, regret, etc)." ></td>
	<td class="line x" title="134:170	are more uniformly felicitous, even if semantically quite divergent from the meaning of the original." ></td>
	<td class="line x" title="135:170	Both the infelicity of drinking cheese and the semantic divergence appear to be addressable by refining semantic tightness using WordNet." ></td>
	<td class="line x" title="136:170	Averaging over senses, words like gobble and ingest have lower WordNet-based semantic distance from eat than drink." ></td>
	<td class="line x" title="137:170	For the sentence Nausea seems a commonplace symptom, the paraphraser outputs 502 paraphrases, of which the following was top-ranked: It seems a commonplace sign." ></td>
	<td class="line x" title="138:170	Other output at random: ??Tiredness looks indicative." ></td>
	<td class="line x" title="139:170	??Queasiness smelt of a commonplace sign." ></td>
	<td class="line x" title="140:170	??Sleepiness appears a commonplace sign." ></td>
	<td class="line x" title="141:170	??Queasiness smelt indicative queasiness." ></td>
	<td class="line x" title="142:170	??Somnolence appears to be indicative." ></td>
	<td class="line x" title="143:170	Longer sentences (e.g. Locally elected school boards, especially in our larger cities, become the prey of ambitious, generally corrupt, and invariably demagogic local politicians or would-be politicians) currently take excessive amounts of time and memory to run, but typically produce 10,000+ paraphrases." ></td>
	<td class="line x" title="144:170	Pruning earlier during paraphrase generation should help address this issue." ></td>
	<td class="line x" title="145:170	4 Future Work Currently, Mutaphrase requires the input sentences to have been marked with FrameNet annotations prior to processing." ></td>
	<td class="line x" title="146:170	Although automatic semantic parsing is a large and growing field (Moldovan et al. , 2004; Litkowski, 2004; Baldewein et al. , 2004), two problems present themselves." ></td>
	<td class="line x" title="147:170	First, output from 148 an automated parser is not typically compatible with FrameNet markup." ></td>
	<td class="line x" title="148:170	Although this is mostly ?a simple matter of programming??" ></td>
	<td class="line x" title="149:170	some linguistic tools must be developed to convert between formats (e.g. to infer FrameNet phrase types from part-of-speech tags).5 Second, it is not yet clear how the inevitable errors introduced by the parser will affect the Mutaphrase algorithm6." ></td>
	<td class="line x" title="150:170	We plan to use applicationdependent measures to judge the effects of parsing errors." ></td>
	<td class="line x" title="151:170	Certain types of semantic ill-formedness cannot be detected by the current version of Mutaphrase." ></td>
	<td class="line x" title="152:170	A typical example is I like sipping beef as a paraphrase of I like eating cheese." ></td>
	<td class="line x" title="153:170	We can guarantee semantic well-formedness by limiting paraphrases to morphologically related words (e.g. consume, consumption) and/or by choosing only the FrameNet LUs which are in the same WordNet (Fellbaum, 1998; WordNet, 2006) synset or higher in the WN hierarchy than the original LU (e.g. eat to consume)." ></td>
	<td class="line x" title="154:170	Clearly this will exclude many well-formed paraphrases, so for tasks in which breadth is more important than accuracy of paraphrase, we anticipate experimenting with WordNet hierarchy distances between the original and paraphrase LUs as a quantitative measure of semantic similarity as a proxy for semantic well-formedness." ></td>
	<td class="line x" title="155:170	Currently, paraphrase scores are computed simply from the frequency of a particular valence in FrameNet data." ></td>
	<td class="line x" title="156:170	We plan to significantly extend scoring to simultaneously rate each paraphrase on its WordNet similarity, syntactic edit distance7, and language model scores." ></td>
	<td class="line x" title="157:170	We also plan to measure the correlation between these estimated scores and both human-judged paraphrase accuracy and application dependent metrics, e.g. extension of in-domain language models by paraphrase." ></td>
	<td class="line x" title="158:170	WordNet can also be used to provide additional paraphrases beyond the particular valences attested in FrameNet." ></td>
	<td class="line x" title="159:170	For example, we plan to use WordNet 5It is worth noting that the current SemEval competition (FrameNet, 2007a) should lead to more complete automatic FrameNet-style annotation." ></td>
	<td class="line x" title="160:170	6An anecdotal example from a semantic parse of I was prepared for a hound, but not for such a creature as this." ></td>
	<td class="line x" title="161:170	(Doyle, 1902) assigns prepared to the Cooking creation frame, leading to the interesting paraphrase I was tenderized for a hound 7We plan to base the syntactic distance on the edit distance between the original and paraphrase syntactic valences." ></td>
	<td class="line x" title="162:170	to generate synonyms of target words so that, for example, adore could be used anywhere like is used even if adore never appears in the FrameNet data." ></td>
	<td class="line x" title="163:170	Finally, the structure of the Mutaphrase algorithm makes multi-lingual paraphrase possible." ></td>
	<td class="line x" title="164:170	This requires FrameNet-like data in other languages, and several projects are underway to provide just such a resource (FrameNet, 2007d; FrameNet, 2007c; SALSA, 2007)." ></td>
	<td class="line x" title="165:170	We plan to exploit these as they become available." ></td>
	<td class="line x" title="166:170	5 Conclusions We have presented the Mutaphrase algorithm, a system for generating a large set of paraphrases of semantically marked input sentences using FrameNet." ></td>
	<td class="line x" title="167:170	The generated sentences range widely in their similarity to the input sentence both in terms of syntax and semantics." ></td>
	<td class="line x" title="168:170	Various methods of filtering the output for well-formedness and semantic and syntactic similarity were presented." ></td>
	<td class="line x" title="169:170	Although the current implementation suffers from a number of limitations, we believe these can be addressed, eventually providing a fully automated paraphrase system suitable for use in a variety of statistical natural language processing systems." ></td>
	<td class="line x" title="170:170	Acknowledgments This work was partly supported by the European Union 6th FWP IST Integrated Project AMI (Augmented Multi-party Interaction, FP6-506811), and by the Swiss National Science Foundation through NCCR?s IM2 project." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W07-1425
A Compositional Approach toward Dynamic Phrasal Thesaurus
Fujita, Atsushi;Kato, Shuhei;Kato, Naoki;Sato, Satoshi;"></td>
	<td class="line x" title="1:188	Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 151158, Prague, June 2007." ></td>
	<td class="line x" title="2:188	c2007 Association for Computational Linguistics A Compositional Approach toward Dynamic Phrasal Thesaurus Atsushi Fujita Shuhei Kato Naoki Kato Satoshi Sato Graduate School of Engineering, Nagoya University {fujita,ssato}@nuee.nagoya-u.ac.jp {shuhei,naoki}@sslab.nuee.nagoya-u.ac.jp Abstract To enhance the technology for computing semantic equivalence, we introduce the notion of phrasal thesaurus which is a natural extension of conventional word-based thesaurus." ></td>
	<td class="line x" title="3:188	Among a variety of phrases that conveys the same meaning, i.e., paraphrases, we focus on syntactic variants that are compositionally explainable using a small number of atomic knowledge, and develop a system which dynamically generates such variants." ></td>
	<td class="line x" title="4:188	This paper describes the proposed system and three sorts of knowledge developed for dynamic phrasal thesaurus in Japanese: (i) transformation pattern, (ii) generation function, and (iii) lexical function." ></td>
	<td class="line x" title="5:188	1 Introduction Linguistic expressions that convey the same meaning are called paraphrases." ></td>
	<td class="line x" title="6:188	Handling paraphrases is one of the key issues in a broad range of natural language processing tasks, including machine translation, information retrieval, information extraction, question answering, summarization, text mining, and natural language generation." ></td>
	<td class="line x" title="7:188	Conventional approaches to computing semantic equivalence between two expressions are five-fold." ></td>
	<td class="line x" title="8:188	The first approximates it based on the similarities between their constituent words." ></td>
	<td class="line x" title="9:188	If two words belong to closer nodes in a thesaurus or semantic network, they are considered more likely to be similar." ></td>
	<td class="line x" title="10:188	The second uses the family of tree kernels (Collins and Duffy, 2001; Takahashi, 2005)." ></td>
	<td class="line x" title="11:188	The degree of equivalence of two trees (sentences) is defined as the number of common subtrees included in both trees." ></td>
	<td class="line oc" title="12:188	The third estimates the equivalence based on word alignment composed using templates or translation probabilities derived from a set of parallel text (Barzilay and Lee, 2003; Brockett and Dolan, 2005)." ></td>
	<td class="line x" title="13:188	The fourth espouses the distributional hypothesis (Harris, 1968): given two words are likely to be equivalent if distributions of their surrounding words are similar (Lin and Pantel, 2001; Weeds et al. , 2005)." ></td>
	<td class="line x" title="14:188	The final regards two expressions equivalent ifthey can be associated by using a set of lexicosyntactic paraphrase patterns (Melcuk, 1996; Dras, 1999; Yoshikane et al. , 1999; Takahashi, 2005)." ></td>
	<td class="line n" title="15:188	Despite the results previous work has achieved, no system that robustly recognizes and generates paraphrases is established." ></td>
	<td class="line n" title="16:188	We are not convinced of a hypothesis underlying the word-based approaches because the structure of words also conveys some meaning." ></td>
	<td class="line x" title="17:188	Even tree kernels, which take structures into account, do not have a mechanism for identifying typical equivalents: e.g., dative alternation and passivization, and abilities to generate paraphrases." ></td>
	<td class="line x" title="18:188	Contrary to the theoretical basis, the two lines of corpus-based approaches have problems in practice, i.e., data sparseness and computation cost." ></td>
	<td class="line x" title="19:188	The pattern-based approaches seem steadiest." ></td>
	<td class="line x" title="20:188	Yet no complete resource or methodology for handling a wide variety of paraphrases has been developed." ></td>
	<td class="line x" title="21:188	On the basis of this recognition, we introduce the notion of phrasal thesaurus to directly compute semantic equivalence of phrases such as follows." ></td>
	<td class="line x" title="22:188	(1) a. be in our favor / be favorable for us b. its reproducibility / if it is reproducible c. decrease sharply / show a sharp decrease d. investigate the cause of a fire / investigate why there was a fire / investigate what started a fire / make an investigation into the cause of a fire 151 Phrasal thesaurus is anatural extension ofconventional word-based thesaurus." ></td>
	<td class="line x" title="23:188	It is thus promised that it will bring us the following benefits: Enhancement of NLP applications: As conventional thesauri, phrasal thesaurus must be useful to handle paraphrases having different structures in a wide range of NLP applications." ></td>
	<td class="line x" title="24:188	Reading and writing aids: Showing more appropriate alternative phrases must be a powerful aid at certain situations such as writing text." ></td>
	<td class="line x" title="25:188	Controlling readability of text by altering phrases must also be beneficial to readers." ></td>
	<td class="line x" title="26:188	Our aim is to develop resources and mechanisms for computing semantic equivalence on the working hypothesis that phrase is the appropriate unit for that purpose." ></td>
	<td class="line x" title="27:188	This paper describes the first version of our paraphrase generation system and reports on our ongoing work on constructing resources for realizing phrasal thesaurus." ></td>
	<td class="line x" title="28:188	The following sections describe the range of phenomena we treat (Section 2), the overall architecture of our paraphrase generation system which functions as phrasal thesaurus (Section 3), the implementation of knowledge bases (Section 4) followed by discussion (Section 5), and conclusion (Section 6)." ></td>
	<td class="line x" title="29:188	2 Dynamic phrasal thesaurus 2.1 Issue Toward realizing phrasal thesaurus, the following two issues should be discussed." ></td>
	<td class="line x" title="30:188	 What sorts of phrases should be treated  How to cope with a variety of expressions Although technologies of shallow parsing have been dramatically improved in the last decade, it is still difficult to represent arbitrary expression in logical form." ></td>
	<td class="line x" title="31:188	We therefore think it is reasonable to define the range relying on lexico-syntactic structure instead of using particular semantic representation." ></td>
	<td class="line x" title="32:188	According to the work of (Chklovski and Pantel, 2004; Torisawa, 2006), predicate phrase (simple sentence) is a reasonable unit because it approximately corresponds to the meaning of single event." ></td>
	<td class="line x" title="33:188	Combination of words and a variety of construction coerce us into handling an enormous number of expressions than word-based approaches." ></td>
	<td class="line x" title="34:188	One may think taking phrase is like treading a thorny path because one of the arguments in Section 1 is about coverage." ></td>
	<td class="line x" title="35:188	On this issue, we speculate that one of the feasible approach to realize a robust system is to divide phenomena into compositional and non-compositional (idiosyncratic) ones 1, and separately develop resources to handle them as described in (Fujita and Inui, 2005)." ></td>
	<td class="line x" title="36:188	Tocompute semantic equivalence of idiosyncratic paraphrases, pairs or groups of paraphrases have to be statically compiled into a dictionary as wordbased thesaurus." ></td>
	<td class="line x" title="37:188	Thecorpus-based approach isvaluable for that purpose, although they are not guaranteed to collect all idiosyncratic paraphrases." ></td>
	<td class="line x" title="38:188	On the other hand, compositional paraphrases can be captured by a relatively small number of rules." ></td>
	<td class="line x" title="39:188	Thus it seems tolerable approach to generate them dynamically by applying such rules." ></td>
	<td class="line x" title="40:188	Our work is targeted at compositional paraphrases and the system can be called dynamic phrasal thesaurus." ></td>
	<td class="line x" title="41:188	Hereafter, we refer to paraphrases that are likely to be explained compositionally as syntactic variants." ></td>
	<td class="line x" title="42:188	2.2 Target language: Japanese While the discussion above does not depend on particular language, our implementation of dynamic phrasal thesaurus is targeted at Japanese." ></td>
	<td class="line x" title="43:188	Several methods for paraphrasing Japanese predicate phrases have been proposed (Kondo et al. , 1999; Kondo et al. , 2001; Kaji et al. , 2002; Fujita et al. , 2005)." ></td>
	<td class="line x" title="44:188	The range they treat is, however, relatively narrow because they tend tofocus onparticular paraphrase phenomena or to rely on existing resources." ></td>
	<td class="line x" title="45:188	On the other hand, we define the range of phenomena from a top-down viewpoint." ></td>
	<td class="line x" title="46:188	As a concrete definition of predicate phrase in Japanese, noun phrase + case marker + predicate is employed which is hereafter referred to phrase. Noun phrase and predicate in Japanese themselves subcategorize various syntactic variants as shown in Figure 1 and paraphrase phenomena for above phrase also involve those focused on their interaction." ></td>
	<td class="line x" title="47:188	Thus the range of phenomena is not so narrow, and intriguing ones, such as shown in examples 2 (2) and (3), are included." ></td>
	<td class="line x" title="48:188	1 We regard lexical paraphrases (e.g. , scope  range) and idiomatic paraphrases (e.g. , get the sackbe dismissed from employment) as idiosyncratic." ></td>
	<td class="line x" title="49:188	2 In each example, s and t denote an original sentence and its paraphrase, respectively." ></td>
	<td class="line x" title="50:188	SMALLCAPS strings indicate the syntactic role of their corresponding Japanese expressions." ></td>
	<td class="line x" title="51:188	[N] indicates a nominalizer." ></td>
	<td class="line x" title="52:188	152 (2) Head switching s. kakunin-o isogu." ></td>
	<td class="line x" title="53:188	checking-ACC to hurry-PRES We hurry checking it." ></td>
	<td class="line x" title="54:188	t. isoide kakunin-suru." ></td>
	<td class="line x" title="55:188	in a hurry to check-PRES We check it in a hurry." ></td>
	<td class="line x" title="56:188	(3) Noun phrase  sub-clause s. kekka-no saigensei-o kenshou-suru." ></td>
	<td class="line x" title="57:188	result-GEN reproducibility-ACC to validate-PRES We validate its reproducibility." ></td>
	<td class="line x" title="58:188	t. [ kekka-o saigen-dekiru ] result-ACC to reproduce-to be able ka-douka-o kenshou-suru." ></td>
	<td class="line x" title="59:188	[N]-whether-ACC to validate-PRES We validate whether it is reproducible." ></td>
	<td class="line x" title="60:188	We focus on syntactic variants at least one side of which is subcategorized into the definition of phrase above." ></td>
	<td class="line x" title="61:188	For the sake of simplicity, we hereafter represent those expressions using part-of-speech (POS) patterns." ></td>
	<td class="line x" title="62:188	For instance, (2s) is called N : C : V type, and (3s) is N 1 : no : N 2 : C : V type." ></td>
	<td class="line x" title="63:188	3 Paraphrase generation system Given a phrase, the proposed system generates its syntactic variants in the following four steps: 1." ></td>
	<td class="line x" title="64:188	Morphological analysis 2." ></td>
	<td class="line x" title="65:188	Syntactic transformation 3." ></td>
	<td class="line x" title="66:188	Surface generation with lexical choice 4." ></td>
	<td class="line x" title="67:188	SLM-based filtering where no particular domain, occasion, and media is assumed 3." ></td>
	<td class="line x" title="68:188	Candidates of syntactic variants are first over-generated in step 2 and then anomalies among themarefiltered out insteps 3and4using rule-based lexical choice and statistical language model." ></td>
	<td class="line x" title="69:188	The rest of this section elaborates on each component in turn." ></td>
	<td class="line x" title="70:188	3.1 Morphological analysis Technologies of morphological analysis in Japanese have matured by introducing machine learning techniques and large-scale annotated corpus, and there are freely available tools." ></td>
	<td class="line x" title="71:188	Sincethe structure ofinput phrase is assumed to be quite simple, employment of dependency analyzer was put off." ></td>
	<td class="line x" title="72:188	We simply use a morphological analyzer MeCab 4 . 3 This corresponds to the linguistic transformation layer of KURA (Takahashi et al. , 2001)." ></td>
	<td class="line x" title="73:188	4 http://mecab.sourceforge.net/ noun phrase 8 > > > > > > > < > > > > > > > : formal noun 8 < : koto mono no content 8 > > > > < > > > > : single word compound j N 1 N 2 N +suffixes modified 8 > < > : N 1 +no+N 2 Adj+N Adjectival verb+N clause+N predicate 8 > > > > > > > > > > < > > > > > > > > > > : verb phrase 8 > > > > > < > > > > > : single word 8 > > < > > : original verb Sino-Japanese verb lexical compound light verb Adv+suru compound 8 > < > : original+original Sino+original Sino+Sino N +Sino Adj j single word compound Adjectival verb+da Adv+da Copula Figure 1: Classification of syntactic variants of noun phrase and predicate in Japanese." ></td>
	<td class="line x" title="74:188	Our system has a post-analysis processing." ></td>
	<td class="line x" title="75:188	If either of Sino-Japanese verbal nouns (e.g. , kenshou (validation) and kandou (impression)) or transliteration of verbs in foreign language (e.g. , doraibu (to drive) and shifuto (to shift)) is immediately followed by suru (to do) or dekiru (to be able), these adjacent two morphemes are joined into a single morpheme to avoid incorrect transformation." ></td>
	<td class="line x" title="76:188	3.2 Syntactic transformation The second step over-generates syntactic variants using the following three sorts of knowledge: (i) Transformation pattern: It gives skeletons of syntactic variants." ></td>
	<td class="line x" title="77:188	Each variant is represented by POS symbols designating the input constituents and triggers of the generation function and lexical function below." ></td>
	<td class="line x" title="78:188	(ii) Generation function: It enumerates different expressions that are constituted with the same set of words and subcategorized into the required syntactic category." ></td>
	<td class="line x" title="79:188	Some of generation functions handle base phrases, while the rest generates functional words." ></td>
	<td class="line x" title="80:188	Base phrases the former generates are smaller than that transformation patterns treat." ></td>
	<td class="line x" title="81:188	Since some functional words are disjunctive, the latter generates all candidates with a separator / and leaves the selection to the following step." ></td>
	<td class="line x" title="82:188	153 Table 1: Grammar in Backus-Naur form, example, and instantiation for each knowledge." ></td>
	<td class="line x" title="83:188	Knowledge type Grammar / Example / Instantiation (i) Transformation <transformation pattern> ::= <left pattern>  <right pattern> pattern <left pattern> ::= (<POS symbol>|<word form>)+ <POS symbol> ::= (N|C|V|Adj|Adv) <word form> ::= (<hiragana>|<katakana>|<kanji>)+ <right pattern> ::= (<POS symbol>|<word form>|<function definition>|<lexical function>)+ (a) N : C : V  adv(V ):vp(N) (b) N 1 : no : N 2 : C : V N 1 : genCase() : vp(N 2 ):ka-douka : C : V (a) kakunin : o : isogu  adv(isogu) : vp(kakunin) checking ACC to hurry adv(to hurry) vp(checking) (b) kekka : no : saigensei : o : kenshou-suru result GEN reproducibility ACC to validate-PRES  kekka : genCase() : vp(saigensei) : ka-douka : o : kenshou-suru result case marker vp(reproducibility) [N]-whether ACC to validate-PRES (ii) Generation <generation function> ::= <function definition>  {<right pattern>+} function <function definition> ::= <syntactic category>(<POS symbol> * ) <syntactic category> ::= (np | vp | lvc) (a) vp(N) {v(N):genVoice() : genTense()} (b) np(N 1,N 2 ) {N 1,N 2,N 1 : N 2,N 1 : no : N 2,vp(N 1 ):N 2,wh(N 2 ):vp(N 1 ):ka,} (a) vp(kakunin) {v(kakunin) : genVoice() : genTense() } vp(verification) v(verification) verbal suffix for voice verbal suffix for tense (b) np(shukka,gen-in) np(starting fire,reason) {shukka, gen-in, shukka : gen-in, shukka : no : gen-in, starting fire reason starting fire reason starting fire GEN reason vp(shukka) :gen-in,wh(gen-in) : vp(shukka) :ka, } vp(starting fire) reason wh(reason) vp(starting fire) [N] (iii) Lexical <lexical function> ::= <relation>(<POS symbol>) function <relation> ::= (n | v | adj | adjv | adv | wh) (a) adv(V ) (b) wh(N) (a) adv(isogu) adv(to hurry)   isoide in a hurry (given by a verbadverb dictionary)  (b) wh(gen-in) wh(reason)  {naze, doushite } why why (given by a nouninterrogative dictionary)  (iii) Lexical function: It generates different lexical items in certain semantic relations, such as derivative form, from a given lexical item." ></td>
	<td class="line x" title="84:188	The back-end of this knowledge is a set of pre-compiled dictionaries as described in Section 4.2." ></td>
	<td class="line x" title="85:188	Table 1 gives a summary of grammar in BackusNaur form, examples, and instantiations of each knowledge." ></td>
	<td class="line x" title="86:188	Figure 2 illustrates an example of knowledge application flow for transforming (4s) into (4t), where : denotes delimiter of constituents." ></td>
	<td class="line x" title="87:188	(4) s. kakunin:o:isogu t. isoide:{kakunin-suru: {, reru/rareru, seru/saseru}:{, ta/da}} First, transformation patterns that match to the given input are applied." ></td>
	<td class="line x" title="88:188	Then, the skeletons of syntactic variants given by the pattern are lexicalized by consecutively invoking generation functions and lexical functions." ></td>
	<td class="line x" title="89:188	Plural number of expressions that generation function and lexical function generate are enumerated within curly brackets." ></td>
	<td class="line x" title="90:188	Transformation is ended when the skeletons are fully lexicalized." ></td>
	<td class="line x" title="91:188	In fact, knowledge design for realizing the transformation is not really new, because we have been inspired by the previous pattern-based approaches." ></td>
	<td class="line x" title="92:188	Transformation pattern is thus alike that in the Meaning-Text Theory (MTT)(Melcuk, 1996), Synchronous Tree Adjoining Grammar (STAG) (Dras, 1999), meta-rule for Fastr (Yoshikane et al. , 1999), 154 {v(kakunin):genVoice() : genTense()} okakunin N : C : isogu V Trans." ></td>
	<td class="line x" title="93:188	Pat." ></td>
	<td class="line x" title="94:188	N:C:Vg15970adv(V):vp(N) adv(isogu): vp(kakunin) Gen. Func." ></td>
	<td class="line x" title="95:188	vp(N) kakunin-suru Lex." ></td>
	<td class="line x" title="96:188	Func." ></td>
	<td class="line x" title="97:188	v(N) Gen. Func." ></td>
	<td class="line x" title="98:188	genVoice() Gen. Func." ></td>
	<td class="line x" title="99:188	genTense() isoide Lex." ></td>
	<td class="line x" title="100:188	Func." ></td>
	<td class="line x" title="101:188	adv(V) {g15458, reru/rareru, seru/saseru} {g15458, ta/da} isoide : {kakunin-suru : {g15458, reru/rareru, seru/saseru} : {g15458, ta/da}} Figure 2: Syntactic transformation (for (2))." ></td>
	<td class="line x" title="102:188	and transfer pattern for KURA (Takahashi et al. , 2001)." ></td>
	<td class="line x" title="103:188	Lexical function is also alike that in MTT." ></td>
	<td class="line x" title="104:188	However, our aim in this research is beyond the design." ></td>
	<td class="line x" title="105:188	In other words, as described in Section 1, we are aiming at the following two: to develop resources for handling syntactic variants in Japanese, and to confirm if phrasal thesaurus really contribute to computing semantic equivalence." ></td>
	<td class="line x" title="106:188	3.3 Surface generation with lexical choice Theinput ofthe third component isabunch ofcandidate phrases such as shown in (4t)." ></td>
	<td class="line x" title="107:188	This component does the following three processes in turn: Step 1." ></td>
	<td class="line x" title="108:188	Unfolding: All word sequences are generated by removing curly brackets one by one." ></td>
	<td class="line x" title="109:188	Step 2." ></td>
	<td class="line x" title="110:188	Lexical choice: Disjunctive words are concatenated with / (e.g. , reru/rareruin(4t))." ></td>
	<td class="line x" title="111:188	One of them is selected based on POS and conjugation types of the preceding word." ></td>
	<td class="line x" title="112:188	Step 3." ></td>
	<td class="line x" title="113:188	Conjugation: In the transformation step, conjugative words are moved to different positions and some of them are newly generated." ></td>
	<td class="line x" title="114:188	Inappropriate conjugation forms are corrected." ></td>
	<td class="line x" title="115:188	3.4 SLM-based filtering In the final step, we assess the correctness of each candidate of syntactic variants using a statistical language model." ></td>
	<td class="line x" title="116:188	Our model simply rejects candidate phrases that never appear in a large size of raw text corpus consisting of 15 years of newspaper articles (Mainichi 19912005, approximately 1.8GB)." ></td>
	<td class="line x" title="117:188	Although it is said that Japanese language has a degree N:C:V N1:N2:C:V +N N:C:V1:V2 +V N:C:Adv:V +Adv Adj:N:C:V +Adj N:C:Adj switch V with Adj Figure 3: Derivations of phrase types." ></td>
	<td class="line x" title="118:188	of freedom in word ordering, current implementation does not yet employ structured language models because phrases we handle are simple." ></td>
	<td class="line x" title="119:188	4 Knowledge implementation 4.1 Transformation patterns and generation functions An issue of developing resources is how to ensure their coverage." ></td>
	<td class="line x" title="120:188	Our approach to this issue is to describe transformation patterns byextending those for simpler phrases." ></td>
	<td class="line x" title="121:188	We first described following three patterns for N : C : V type phrases which we consider the simplest according to Figure 1." ></td>
	<td class="line x" title="122:188	(5) a. N : C : V  vp(N) b. N : C : V  N : genCase() : lvc(V ) c. N : C : V  adv(V ):vp(N) While the pattern (5c) is induced from example (2), the patterns (5a-b) are derived from examples (6) and (7), respectively." ></td>
	<td class="line x" title="123:188	(6) s. shigeki-o ukeru inspiration-ACC to receive to receive an inspiration t. shigeki-sareru to inspire-PASS to be inspired (7) s. hada-o shigeki-suru skin-ACC to stimulate to stimulate skin t. hada-ni shigeki-o ataeru skin-DAT stimulus-ACC to give to give skin a stimulus Regarding the patterns in (8) as the entire set of compositional paraphrases for N : C : V type phrases, we then extended them to a bit more complex phrases as in Figure 3." ></td>
	<td class="line x" title="124:188	For instance, 10 patterns 155 Table 2: Transformation patterns." ></td>
	<td class="line x" title="125:188	Target phrase # of patterns N : C : V 3 N 1 : N 2 : C : V 10 N : C : V 1 : V 2 10 N : C : Adv : V 7 Adj : N : C : V 4 N : C : Adj 3 Total 37 Table 3: Generation functions." ></td>
	<td class="line x" title="126:188	Definition Syntactic category # of returned value np(N 1,N 2 ) noun phrase 9 vp(N) verb phrase 1 vp(N 1,N 2 ) verb phrase 2 vp(V 1,V 2 ) verb phrase 3 lvc(V ) light verb construction 1 genCase() case marker 4 genVoice() verbal suffixforvoice 3 genTense() verbal suffix for tense 2 genAspect() verbal suffix for aspect 2 for N 1 : N 2 : C : V type phrases shown in (8) have been described based on patterns in (5), mainly focusing on interactions between newly introduced N 1 and other constituents." ></td>
	<td class="line x" title="127:188	(8) a. N 1 : N 2 : C : V  vp(N 1,N 2 ) (5a) b. N 1 : N 2 : C : V  N 1 : genCase() : vp(N 2 ) (5a) c. N 1 : N 2 : C : V  N 2 : genCase() : vp(N 1 ) (5a) d. N 1 : N 2 : C : V  np(N 1,N 2 ):genCase() : lvc(V ) (5b) e. N 1 : N 2 : C : V  N 1 : genCase() : N 2 : genCase() : lvc(V ) (5b) f. N 1 : N 2 : C : V  N 2 : genCase() : N 1 : genCase() : lvc(V ) (5b) g. N 1 : N 2 : C : V  adv(V ):vp(N 1,N 2 ) (5c) h. N 1 : N 2 : C : V  adv(V ):N 1 : genCase() : vp(N 2 ) (5c) i. N 1 : N 2 : C : V  adv(V ):N 2 : genCase() : vp(N 1 ) (5c) j. N 1 : N 2 : C : V  np(N 1,N 2 ):C : V (new) The number of transformation patterns we have so far developed is shown in Table 2." ></td>
	<td class="line x" title="128:188	Generation functions shown in Table 3 are developed along with creating transformation patterns." ></td>
	<td class="line x" title="129:188	Although this is the heart of the proposed model, two problems are remained: (i) the granularity of each generation function is determined according to Table 4: Dictionaries for lexical functions." ></td>
	<td class="line x" title="130:188	ID POS-pair |D||C||D C||J| (a) nounverb 3,431 3,431 3,431 (b) nounadjective 308 667 906 475  (c) nounadjectival verb 1,579 1,579 1,579 (d) nounadverb 271 271 271 (e) verbadjective 252 252 192  (f) verbadjectival verb 74 74 68  (g) verbadverb 74 74 64  (h) adjectiveadjectival verb 66 95 159 146  (i) adjectiveadverb 33 33 26  (j) adjectival verbadverb 70 70 70 Total 6,158 762 6,849 6,322 our linguistic intuition, and (ii) they do not ensure of generating all possible phrases." ></td>
	<td class="line x" title="131:188	Therefore, we have to establish the methodology to create this knowledge more precisely." ></td>
	<td class="line x" title="132:188	4.2 Lexical functions Except wh(N), which generates interrogatives as shown in the bottom line of Table 1, the relations we have so far implemented are lexical derivations." ></td>
	<td class="line x" title="133:188	These roughly correspond to S, V, A,andAdv in MTT." ></td>
	<td class="line x" title="134:188	The back-end of these lexical functions is a set of dictionaries built by the following two steps: Step 1." ></td>
	<td class="line x" title="135:188	Automatic candidate collection: Most derivatives in Japanese share the beginning of words and are characterized by the correspondences of their suffixes." ></td>
	<td class="line x" title="136:188	For example, amai (be sweet) and amami (sweetness) has a typical suffix correspondence -i:-mi of adjectivenoun derivation." ></td>
	<td class="line x" title="137:188	Using this clue, candidates are collected by two methods." ></td>
	<td class="line x" title="138:188	 From dictionary: Retrieve all word pairs from the given set of words those satisfying the following four conditions: (i) beginning with kanji character, (ii) having different POSs, (iii) sharing at least the first character and the first sound, and (iv) having a suffix pattern which corresponds to at least two pairs." ></td>
	<td class="line x" title="139:188	 Using dictionary and corpus: Generate candidates from a set of words by applying a set of typical suffix patterns, and then check if each candidate is an actual word using corpus." ></td>
	<td class="line x" title="140:188	This is based on (Langkilde and Knight, 1998)." ></td>
	<td class="line x" title="141:188	Step 2." ></td>
	<td class="line x" title="142:188	Manual selection: The set of word pairs collected in the previous step includes those do not have particular semantic relationship." ></td>
	<td class="line x" title="143:188	This step involves human to discard noises." ></td>
	<td class="line x" title="144:188	156 Table 4 shows the size of 10 dictionaries, where each column denotes the number of word pairs retrieved from IPADIC 5 (|D|), those using IPADIC, seven patterns and the same corpus as in Section 3.4 (|C|), their union (|D  C|), and those manually judged correct (|J|), respectively." ></td>
	<td class="line x" title="145:188	The sets of word pairs J are used as bi-directional lexical functions, although manual screening for four dictionaries without dagger () are still in process." ></td>
	<td class="line x" title="146:188	5 Discussion 5.1 Unit of processing The working hypothesis underlying our work is that phrase is the appropriate unit for computing semantic equivalence." ></td>
	<td class="line x" title="147:188	In addition to the arguments in Section 1, the hypothesis is supported by what is done in practice." ></td>
	<td class="line x" title="148:188	Let us see two related fields." ></td>
	<td class="line x" title="149:188	The first is the task of word sense disambiguation (WSD)." ></td>
	<td class="line x" title="150:188	State-of-the-art WSD techniques refer to context as a clue." ></td>
	<td class="line x" title="151:188	However, the range of context is usually not so wide: words and their POSs within small window centered the target word and content words within the same sentence of the target word." ></td>
	<td class="line x" title="152:188	The task therefore can be viewed as determining the meaning of phrase based on its constituent words and surrounding content words." ></td>
	<td class="line x" title="153:188	Statistical language model (SLM) is another field." ></td>
	<td class="line x" title="154:188	SLMs usually deal with various things within word sequence (or structure) at the same time." ></td>
	<td class="line x" title="155:188	However, relations within a phrase should be differentiated from that between phrases, because checking the former is for grammaticality, while the latter for cohesion." ></td>
	<td class="line x" title="156:188	We think SLMs should take the phrase to determine boundaries for assessing the correctness of generated expressions more accurately." ></td>
	<td class="line x" title="157:188	5.2 Compositionality We examined how large part of manually created paraphrases could be generated in our compositional approach." ></td>
	<td class="line x" title="158:188	First, a set of paraphrase examples were created in the following procedure: Step 1." ></td>
	<td class="line x" title="159:188	Most frequent 400 phrases typed N 1 : N 2 : C : V were sampled from one year of newspaper articles (Mainichi 1991)." ></td>
	<td class="line x" title="160:188	Step 2." ></td>
	<td class="line x" title="161:188	An annotator produced paraphrases for each phrase." ></td>
	<td class="line x" title="162:188	We allowed to record more than one 5 http://mecab.sourceforge.jp/ paraphrase for a given phrase and to give up producing paraphrases." ></td>
	<td class="line x" title="163:188	As a result, we obtained 211 paraphrases for 170 input phrases." ></td>
	<td class="line x" title="164:188	Manual classification revealed that 42% (88/211) of paraphrases could be compositionally explainable, and the (theoretical) coverage increases to 86% (182/211) if we have a synonym dictionary." ></td>
	<td class="line x" title="165:188	This ratio is enough high to give these phenomena preference as the research target, although we cannot reject a possibility that data has been biased." ></td>
	<td class="line x" title="166:188	5.3 Sufficient condition of equivalence In our system, transformation patterns and generation functions offer necessary conditions for generating syntactic variants for given input." ></td>
	<td class="line x" title="167:188	However, we have no sufficient condition to control the application of such a knowledge." ></td>
	<td class="line x" title="168:188	It has not been thoroughly clarified what clue can be sufficient condition to ensure semantic equivalence, even in a number of previous work." ></td>
	<td class="line x" title="169:188	Though, at least, roles of participants in the event have to be preserved by some means, such as the way presented in (Pantel et al. , 2007)." ></td>
	<td class="line x" title="170:188	Kaji et al.(2002) introduced amethod ofcase frame alignment in paraphrase generation." ></td>
	<td class="line x" title="172:188	In the model, arguments of main verb in the source are taken over by that of the target according to the similarities between arguments of the source and target." ></td>
	<td class="line x" title="173:188	Fujita et al.(2005) employed a semantic representation of verb to realize the alignment of the role of participants governed by the source and target verbs." ></td>
	<td class="line x" title="175:188	According to an empirical experiment in (Fujita et al. , 2005), statistical language models do not contribute to calculating semantic equivalence, but to filtering out anomalies." ></td>
	<td class="line x" title="176:188	We therefore plan to incorporate above alignment-based models into our system, for example, within or after the syntactic transformation step (Figure 2)." ></td>
	<td class="line x" title="177:188	5.4 Ideas for improvement The knowledge and system presented in Section 3 are quite simple." ></td>
	<td class="line x" title="178:188	Thus the following features should be incorporated to improve the system in addition to the one described in Section 5.3." ></td>
	<td class="line x" title="179:188	 Dependency structure: To enable flexible matching, such as Adv : N : C : V type input and transformation pattern for N : C : Adv : V type phrases." ></td>
	<td class="line x" title="180:188	 Sophisticated SLM: The generation phase should also take the structure into account to 157 evaluate generated expressions flexibly." ></td>
	<td class="line x" title="181:188	 Knowledge development: Although we have not done intrinsic evaluation of knowledge, we are aware of its incompleteness." ></td>
	<td class="line x" title="182:188	We are continuing manual screening for the dictionaries and planning to enhance the methodology of knowledge development." ></td>
	<td class="line x" title="183:188	6Conclusion To enhance the technology for computing semantic equivalence, we have introduced the notion of phrasal thesaurus, which is a natural extension of conventional word-based thesaurus." ></td>
	<td class="line x" title="184:188	Plausibility of taking phrase as the unit of processing has been discussed from several viewpoints." ></td>
	<td class="line x" title="185:188	On the basis of that, we have been developing a system to dynamically generate syntactic variants in Japanese predicate phrases which utilizes three sorts of knowledge that are inspired by MTT, STAG, Fastr, and KURA." ></td>
	<td class="line x" title="186:188	Future work includes implementing more precise features and larger resources to compute semantic equivalence." ></td>
	<td class="line x" title="187:188	We also plan to conduct an empirical evaluation of the resources and the overall system." ></td>
	<td class="line x" title="188:188	Acknowledgments This work was supported in part by MEXT Grantsin-Aid for Young Scientists (B) 18700143, and for Scientific Research (A) 16200009, Japan." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W07-1429
Biology Based Alignments of Paraphrases for Sentence Compression
Cordeiro, Joao;Dias, Gael;Cleuziou, Guillaume;"></td>
	<td class="line x" title="1:169	Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 177184, Prague, June 2007." ></td>
	<td class="line x" title="2:169	c2007 Association for Computational Linguistics Biology Based Alignments of Paraphrases for Sentence Compression Joao Cordeiro CLT and Bioinformatics University of Beira Interior Covilha, Portugal jpaulo@di.ubi.pt Gael Dias CLT and Bioinformatics University of Beira Interior Covilha, Portugal ddg@di.ubi.pt Guillaume Cleuziou LIFO University of Orleans Orleans, France guillaume.cleuziou@ univ-orleans.fr Abstract 1 In this paper, we present a study for extracting and aligning paraphrases in the context of Sentence Compression." ></td>
	<td class="line x" title="3:169	First, we justify the application of a new measure for the automatic extraction of paraphrase corpora." ></td>
	<td class="line oc" title="4:169	Second, we discuss the work done by (Barzilay & Lee, 2003) who use clustering of paraphrases to induce rewriting rules." ></td>
	<td class="line n" title="5:169	We will see, through classical visualization methodologies (Kruskal & Wish, 1977) and exhaustive experiments, that clustering may not be the best approach for automatic pattern identification." ></td>
	<td class="line x" title="6:169	Finally, we will provide some results of different biology based methodologies for pairwise paraphrase alignment." ></td>
	<td class="line x" title="7:169	1 Introduction Sentence Compression can be seen as the removal of redundant words or phrases from an input sentence by creating a new sentence in which the gist of the original meaning of the sentence remains unchanged." ></td>
	<td class="line oc" title="8:169	Sentence Compression takes an important place for Natural Language Processing (NLP) tasks where specific constraints must be satisfied, such as length in summarization (Barzilay & Lee, 2002; Knight & Marcu, 2002; Shinyama et al. , 2002; Barzilay & Lee, 2003; Le Nguyen & Ho, 2004; Unno et al. , 2006), style in text simplification (Marsi & Krahmer, 2005) or sentence simplification for subtitling (Daelemans et al. , 2004)." ></td>
	<td class="line x" title="9:169	1Project partially funded by Portuguese FCT (Reference: POSC/PLP/57438/2004) Generally, Sentence Compression involves performing the following three steps: (1) Extraction of paraphrases from comparable corpora, (2) Alignment of paraphrases and (3) Induction of rewriting rules." ></td>
	<td class="line x" title="10:169	Obviously, each of these steps can be performed in many different ways going from totally unsupervised to totally supervised." ></td>
	<td class="line x" title="11:169	In this paper, we will focus on the first two steps." ></td>
	<td class="line x" title="12:169	In particular, we will first justify the application of a new measure for the automatic extraction of paraphrase corpora." ></td>
	<td class="line oc" title="13:169	Second, we will discuss the work done by (Barzilay & Lee, 2003) who use clustering of paraphrases to induce rewriting rules." ></td>
	<td class="line x" title="14:169	We will see, through classical visualization methodologies (Kruskal & Wish, 1977) and exhaustive experiments, that clustering may not be the best approach for automatic pattern identification." ></td>
	<td class="line x" title="15:169	Finally, we will provide some results of different biology based methodologies for pairwise paraphrase alignment." ></td>
	<td class="line oc" title="16:169	2 Related Work Two different approaches have been proposed for Sentence Compression: purely statistical methodologies (Barzilay & Lee, 2003; Le Nguyen & Ho, 2004) and hybrid linguistic/statistic methodologies (Knight & Marcu, 2002; Shinyama et al. , 2002; Daelemans et al. , 2004; Marsi & Krahmer, 2005; Unno et al. , 2006)." ></td>
	<td class="line oc" title="17:169	As our work is based on the first paradigm, we will focus on the works proposed by (Barzilay & Lee, 2003) and (Le Nguyen & Ho, 2004)." ></td>
	<td class="line oc" title="18:169	(Barzilay & Lee, 2003) present a knowledge-lean algorithm that uses multiple-sequence alignment to 177 learn generate sentence-level paraphrases essentially from unannotated corpus data alone." ></td>
	<td class="line o" title="19:169	In contrast to (Barzilay & Lee, 2002), they need neither parallel data nor explicit information about sentence semantics." ></td>
	<td class="line o" title="20:169	Rather, they use two comparable corpora." ></td>
	<td class="line o" title="21:169	Their approach has three main steps." ></td>
	<td class="line o" title="22:169	First, working on each of the comparable corpora separately, they compute lattices compact graph-based representations to find commonalities within groups of structurally similar sentences." ></td>
	<td class="line o" title="23:169	Next, they identify pairs of lattices from the two different corpora that are paraphrases of each other." ></td>
	<td class="line o" title="24:169	Finally, given an input sentence to be paraphrased, they match it to a lattice and use a paraphrase from the matched lattices mate to generate an output sentence." ></td>
	<td class="line x" title="25:169	(Le Nguyen & Ho, 2004) propose a new sentencereduction algorithm that do not use syntactic parsing for the input sentence." ></td>
	<td class="line x" title="26:169	The algorithm is an extension of the template-translation algorithm (one of example-based machine-translation methods) via innovative employment of the Hidden Markov model, which uses the set of template rules learned from examples." ></td>
	<td class="line x" title="27:169	In particular, (Le Nguyen & Ho, 2004) do not propose any methodology to automatically extract paraphrases." ></td>
	<td class="line x" title="28:169	Instead, they collect a corpus by performing the decomposition program using news and their summaries." ></td>
	<td class="line x" title="29:169	After correcting them manually, they obtain more than 1,500 pairs of long and reduced sentences." ></td>
	<td class="line oc" title="30:169	Comparatively, (Barzilay & Lee, 2003) propose to use the N-gram Overlap metric to capture similarities between sentences and automatically create paraphrase corpora." ></td>
	<td class="line n" title="31:169	However, this choice is arbitrary and mainly leads to the extraction of quasi-exact or exact matching pairs." ></td>
	<td class="line x" title="32:169	For that purpose, we introduce a new metric, the Sumo-Metric." ></td>
	<td class="line pc" title="33:169	Unlike (Le Nguyen & Ho, 2004), one interesting idea proposed by (Barzilay & Lee, 2003) is to cluster similar pairs of paraphrases to apply multiplesequence alignment." ></td>
	<td class="line n" title="34:169	However, once again, this choice is not justified and we will see by classical visualization methodologies (Kruskal & Wish, 1977) and exhaustive experiments by applying different clustering algorithms, that clustering may not be the best approach for automatic pattern identification." ></td>
	<td class="line x" title="35:169	As a consequence, we will study global and local biology based sequence alignments compared to multi-sequence alignment that may lead to better results for the induction of rewriting rules." ></td>
	<td class="line x" title="36:169	3 Paraphrase Corpus Construction Paraphrase corpora are golden resources for learning monolingual text-to-text rewritten patterns." ></td>
	<td class="line x" title="37:169	However, such corpora are expensive to construct manually and will always be an imperfect and biased representation of the language paraphrase phenomena." ></td>
	<td class="line x" title="38:169	Therefore, reliable automatic methodologies able to extract paraphrases from text and subsequently corpus construction are crucial, enabling better pattern identification." ></td>
	<td class="line x" title="39:169	In fact, text-to-text generation is a particularly promising research direction given that there are naturally occurring examples of comparable texts that convey the same information but are written in different styles." ></td>
	<td class="line x" title="40:169	Web news stories are an obvious example." ></td>
	<td class="line x" title="41:169	Thus, presented with such texts, one can pair sentences that convey the same information, thereby building a training set of rewriting examples i.e. a paraphrase corpus." ></td>
	<td class="line oc" title="42:169	3.1 Paraphrase Identification A few unsupervised metrics have been applied to automatic paraphrase identification and extraction (Barzilay & Lee, 2003; Dolan & Brockett, 2004)." ></td>
	<td class="line nc" title="43:169	However, these unsupervised methodologies show a major drawback by extracting quasi-exact2 or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of (Dolan & Brockett, 2004) and word N-gram overlap for (Barzilay & Lee, 2003)." ></td>
	<td class="line n" title="44:169	Such pairs are clearly useless." ></td>
	<td class="line x" title="45:169	More recently, (Anonymous, 2007) proposed a new metric, the Sumo-Metric specially designed for asymmetrical entailed pairs identification, and proved better performance over previous established metrics, even in the specific case when tested with the Microsoft Paraphrase Research Corpus (Dolan & Brockett, 2004)." ></td>
	<td class="line x" title="46:169	For a given sentence pair, having each sentence x and y words, and with  exclusive links between the sentences, the Sumo-Metric is defined in Equation 1 and 2." ></td>
	<td class="line x" title="47:169	2Almost equal strings, for example: Bush said America is addicted to oil." ></td>
	<td class="line x" title="48:169	and Mr. Bush said America is addicted to oil." ></td>
	<td class="line x" title="49:169	178 S(Sa,Sb) = 8 >> < >> : S(x,y,) if S(x,y,) < 1.0 0 if  = 0 ekS(x,y,) otherwise (1) where S(x,y,) = log2(x)+log2(y) (2) with ,  [0,1] and + = 1." ></td>
	<td class="line x" title="50:169	(Anonymous, 2007) show that the Sumo-Metric outperforms all state-of-the-art metrics over all tested corpora." ></td>
	<td class="line oc" title="51:169	In particular, it shows systematically better F-Measure and Accuracy measures over all other metrics showing an improvement of (1) at least 2.86% in terms of F-Measure and 3.96% in terms of Accuracy and (2) at most 6.61% in terms of FMeasure and 6.74% in terms of Accuracy compared to the second best metric which is also systematically the word N-gram overlap similarity measure used by (Barzilay & Lee, 2003)." ></td>
	<td class="line x" title="52:169	3.2 Clustering Literature shows that there are two main reasons to apply clustering for paraphrase extraction." ></td>
	<td class="line oc" title="53:169	On one hand, as (Barzilay & Lee, 2003) evidence, clusters of paraphrases can lead to better learning of text-totext rewriting rules compared to just pairs of paraphrases." ></td>
	<td class="line x" title="54:169	On the other hand, clustering algorithms may lead to better performance than stand-alone similarity measures as they may take advantage of the different structures of sentences in the cluster to detect a new similar sentence." ></td>
	<td class="line nc" title="55:169	However, as (Barzilay & Lee, 2003) do not propose any evaluation of which clustering algorithm should be used, we experiment a set of clustering algorithms and present the comparative results." ></td>
	<td class="line x" title="56:169	Contrarily to what expected, we will see that clustering is not a worthy effort." ></td>
	<td class="line x" title="57:169	Instead of extracting only sentence pairs from corpora3, one may consider the extraction of paraphrase sentence clusters." ></td>
	<td class="line x" title="58:169	There are many well-known clustering algorithms, which may be applied to a corpus sentence set S = {s1,,sn}." ></td>
	<td class="line x" title="59:169	Clustering implies the definition of a similarity or (distance) matrix Ann, where each each element aij is the similarity (distance) between sentences si and sj." ></td>
	<td class="line x" title="60:169	3A pair may be seen as a cluster with only two elements." ></td>
	<td class="line x" title="61:169	3.2.1 Experimental Results We experimented four clustering algorithms on a corpus of web news stories and then three human judges manually cross-classified a random sample of the generated clusters." ></td>
	<td class="line x" title="62:169	They were asked to classify a cluster as a wrong cluster if it contained at least two sentences without any entailment relation between them." ></td>
	<td class="line x" title="63:169	Results are shown in the next table 1." ></td>
	<td class="line x" title="64:169	Table 1: Precision of clustering algorithms BASE S-HAC C-HAC QT EM 0.618 0.577 0.569 0.640 0.489 The BASE column is the baseline, where the Sumo-Metric was applied rather than clustering." ></td>
	<td class="line x" title="65:169	Columns S-HAC and C-HAC express the results for Single-link and Complete-link Hierarchical Agglomerative Clustering (Jain et al. , 1999)." ></td>
	<td class="line x" title="66:169	The QT column shows the Quality Threshold algorithm (Heyer et al. , 1999) and the last column EM is the Expectation Maximization clustering algorithm (Hogg et al. , 2005)." ></td>
	<td class="line x" title="67:169	One main conclusion, from table 1 is that clustering tends to achieve worst results than simple paraphrase pair extraction." ></td>
	<td class="line x" title="68:169	Only the QT achieves better results, but if we take the average of the four clustering algorithms it is equal to 0.568, smaller than the 0.618 baseline." ></td>
	<td class="line x" title="69:169	Moreover, these results with the QT algorithm were applied with a very restrictive value for cluster attribution as it is shown in table 2 with an average of almost two sentences per cluster." ></td>
	<td class="line nc" title="70:169	Table 2: Figures about clustering algorithms Algorithm # Sentences/# Clusters S-HAC 6,23 C-HAC 2,17 QT 2,32 EM 4,16 In fact, table 2 shows that most of the clusters have less than 6 sentences which leads to question the results presented by (Barzilay & Lee, 2003) who only keep the clusters that contain more than 10 sentences." ></td>
	<td class="line x" title="71:169	In fact, the first conclusion is that the number of experimented clusters is very low, and more important, all clusters with more than 10 sentences showed to be of very bad quality." ></td>
	<td class="line x" title="72:169	The next subsection will reinforce the sight that 179 clustering is a worthless effort for automatic paraphrase corpora construction." ></td>
	<td class="line x" title="73:169	3.2.2 Visualization In this subsection, we propose a visual analysis of the different similarity measures tested previously: the Edit Distance (Levenshtein, 1966), the BLEU metric (Papineni et al. , 2001), the word Ngram overlap and the Sumo-Metric." ></td>
	<td class="line x" title="74:169	The goal of this study is mainly to give the reader a visual interpretation about the organization each measure induces on the data." ></td>
	<td class="line x" title="75:169	To perform this study, we use a Multidimensional Scaling (MDS) process which is a traditional data analysis technique." ></td>
	<td class="line x" title="76:169	MDS (Kruskal & Wish, 1977) allows to display the structure of distance-like data into an Euclidean space." ></td>
	<td class="line x" title="77:169	Since the only available information is a similarity in our case, we transform similarity values into distance values as in Equation 3." ></td>
	<td class="line x" title="78:169	dij = (sii 2sij +sjj)1/2 (3) This transformation enables to obtain a (pseudo) distance measure satisfying properties like minimality, identity and symmetry." ></td>
	<td class="line x" title="79:169	On a theoretical point of view, the measure we obtain is a pseudo-distance only, since triangular inequality is not necessary satisfied." ></td>
	<td class="line x" title="80:169	In practice, the projection space we build with the MDS from such a pseudo-distance is sufficient to have an idea about whether data are organized into classes." ></td>
	<td class="line x" title="81:169	We perform the MDS process on 500 sentences4 randomly selected from the Microsoft Research Paraphrase Corpus." ></td>
	<td class="line x" title="82:169	In particular, the projection over the three first eigenvectors (or proper vectors) provides the best visualization where data are clearly organized into several classes (at least two classes)." ></td>
	<td class="line x" title="83:169	The obtained visualizations (Figure 1) show distinctly that no particular data organization can be drawn from the used similarity measures." ></td>
	<td class="line x" title="84:169	Indeed, we observe only one central class with some satellite data randomly placed around the class." ></td>
	<td class="line x" title="85:169	The last observation allows us to anticipate on the results we could obtain with a clustering step." ></td>
	<td class="line x" title="86:169	First, clustering seems not to be a natural way to manage 4The limitation to 500 data is due to computation costs since MDS requires the diagonalization of the square similarity or distance matrix." ></td>
	<td class="line x" title="87:169	such data." ></td>
	<td class="line x" title="88:169	Then, according to the clustering method used, several types of clusters can be expected: very small clusters which contain satellite data (pretty relevant) or large clusters with part of the main central class (pretty irrelevant)." ></td>
	<td class="line nc" title="89:169	These results confirm the observed figures in the previous subsection and reinforce the sight that clustering is a worthless effort for automatic paraphrase corpora construction, contrarily to what (Barzilay & Lee, 2003) suggest." ></td>
	<td class="line x" title="90:169	4 Biology Based Alignments Sequence alignments have been extensively explored in bioinformatics since the beginning of the Human Genome Project." ></td>
	<td class="line x" title="91:169	In general, one wants to align two sequences of symbols (genes in Biology) to find structural similarities, differences or transformations between them." ></td>
	<td class="line x" title="92:169	In NLP, alignment is relevant in sub-domains like Text Generation (Barzilay & Lee, 2002)." ></td>
	<td class="line x" title="93:169	In our work, we employ alignment methods for aligning words between two sentences, which are paraphrases." ></td>
	<td class="line x" title="94:169	The words are the base blocks of our sequences (sentences)." ></td>
	<td class="line x" title="95:169	There are two main classes of pairwise alignments: the global and local classes." ></td>
	<td class="line x" title="96:169	In the first one, the algorithms try to fully align both sequences, admitting gap insertions at a certain cost, while in the local methods the goal is to find pairwise subalignments." ></td>
	<td class="line x" title="97:169	How suitable each algorithm may be applied to a certain problem is discussed in the next two subsections." ></td>
	<td class="line x" title="98:169	4.1 Global Alignment The well established and widely used NeedlemanWunsch algorithm for pairwise global sequence alignment, uses dynamic programming to find the best possible alignment between two sequences." ></td>
	<td class="line x" title="99:169	It is an optimal algorithm." ></td>
	<td class="line x" title="100:169	However, it reveals space and time inefficiency as sequence length increases, since an mn matrix must be maintained and processed during computations." ></td>
	<td class="line x" title="101:169	This is the case with DNA sequence alignments, composed by many thousands of nucleotides." ></td>
	<td class="line x" title="102:169	Therefore, a huge optimization effort were engaged and new algorithms appeared like ktuple, not guaranteeing to find optimal alignments but able to tackle the complexity problem." ></td>
	<td class="line x" title="103:169	In our alignment tasks, we do not have these com180 plexity obstacles, because in our corpora the mean length of a sentence is equal to 20.9 words, which is considerably smaller than in a DNA sequence." ></td>
	<td class="line x" title="104:169	Therefore an implementation of the NeedlemanWunsch algorithm has been used to generate optimal global alignments." ></td>
	<td class="line x" title="105:169	The figure 2 exemplifies a global word alignment on a paraphrase pair." ></td>
	<td class="line x" title="106:169	4.2 Local Alignment The Smith-Waterman (SW) algorithm is similar to the Needleman Wunsch (NW) one, since dynamic programming is also followed hence denoting the similar complexity issues, to which our alignment task is immune." ></td>
	<td class="line x" title="107:169	The main difference is that SW seeks optimal sub-alignments instead of a global alignment and, as described in the literature, it is well tailored for pairs with considerable differences5, in length and type." ></td>
	<td class="line x" title="108:169	In table 3 we exemplify this by showing two character sequences6 where one may clearly see that SW is preferable: N Char." ></td>
	<td class="line x" title="109:169	Sequences Alignments 1 ABBAXYTRVRVTTRVTR XYTRVFWHWWHGWGFXYTVWGF XYT-V 2 ABCDXYDRQR AB-CDDQZZSTABZCD ABZCD Table 3: Preferable local alignment cases." ></td>
	<td class="line x" title="110:169	Remark that in the second pair, only the maximal local sub-alignment is shown." ></td>
	<td class="line x" title="111:169	However, there exists another sub-alignment: (DRQ, D-Q)." ></td>
	<td class="line x" title="112:169	This means that local alignment may be tuned to generate not only the maximum sub-alignment but a set of subalignments that satisfy some criterium, like having alignment value greater than some minimum threshold." ></td>
	<td class="line x" title="113:169	In fact, this is useful in our word alignment problem and were experimented by adapting the Smith Waterman algorithm." ></td>
	<td class="line x" title="114:169	4.3 Dynamic Alignment According to the previous two subsections, where two alignment strategies were presented, a natural question rises: which alignment algorithm to use for our problem of inter-sentence word alignment?" ></td>
	<td class="line x" title="115:169	Initially, we thought to use only the global 5With sufficient similar sequences there is no difference between NW and SW." ></td>
	<td class="line x" title="116:169	6As in DNA subsequences and is same for word sequences." ></td>
	<td class="line x" title="117:169	alignment Needleman Wunsch algorithm, since a complete inter-sentence word alignment is obtained." ></td>
	<td class="line x" title="118:169	However, we noticed that this strategy is unappropriate for certain pairs, specially when there are syntactical alternations, like in the next example: During his magnificent speech, a58a58a58the a58a58a58a58a58a58a58a58president a58a58a58a58a58a58a58a58a58remarkablya58a58a58a58a58a58praiseda58a58a58a58IBMa58a58a58a58a58a58a58a58research." ></td>
	<td class="line x" title="119:169	a58a58a58Thea58a58a58a58a58a58a58a58presidenta58a58a58a58a58a58a58praiseda58a58a58a58IBMa58a58a58a58a58a58a58a58research, during hisspeech." ></td>
	<td class="line x" title="120:169	If a global alignment is applied for such a pair, then weird alignments will be generated, like the one that is shown in the next representation (we use character sequences for space convenience and try to preserve the word first letter, from the previous example): D H M S T P R Q I S _ _ _ _ _ _ _ T P _ Q I S D H S Here it would be more adequate to apply local alignment and extract all relevant sub-alignments." ></td>
	<td class="line x" title="121:169	In this case, two sub-alignments would be generated: |D H M S| |T P R P I R| |D H _ S| |T P _ P I R| Therefore, for inter-paraphrase word alignments, we propose a dynamic algorithm which chooses the best alignment to perform: global or local." ></td>
	<td class="line x" title="122:169	To compute this pre-scan, we regard the notion of linkcrossing between sequences as illustrated in the figure 3, where the 4 crossings are signalized with the small squares." ></td>
	<td class="line x" title="123:169	It is easily verifiable that the maximum number of crossings, among two sequences with n exclusive links in between is equal to  = 12  n  (n  1)." ></td>
	<td class="line x" title="124:169	We suggest that if a fraction of these crossings holds, for example 0.4 or 0.5, then a local alignment should be used." ></td>
	<td class="line x" title="125:169	Remark that the more this fraction tends to 1.0 the more unlikely it is to use global alignment." ></td>
	<td class="line x" title="126:169	Crossings may be calculated by taking index pairs xi,yi to represent links between sequences, where xi and yi are respectively the first and second sequence indexes, for instance in figure 3 the U link has pair 5,1." ></td>
	<td class="line x" title="127:169	It is easily verifiable that two links xi,yi and xj,yj have a crossing point if: (xi xj)(yi yj) < 0." ></td>
	<td class="line x" title="128:169	4.4 Alignment with Similarity Matrix In bioinformatics, DNA sequence alignment algorithms are usually guided by a scoring function, related to the field of expertise, that defines what is 181 the mutation probability between nucleotides." ></td>
	<td class="line x" title="129:169	These scoring functions are defined by PAM7 or BLOSUM8 matrices and encode evolutionary approximations regarding the rates and probabilities of amino acid mutations." ></td>
	<td class="line x" title="130:169	Different matrices might produce different alignments." ></td>
	<td class="line x" title="131:169	Subsequently, this motivated the idea of modeling word mutation." ></td>
	<td class="line x" title="132:169	It seems intuitive to allow such a word mutation, considering the possible relationships that exit between words: lexical, syntactical or semantic." ></td>
	<td class="line x" title="133:169	For example, it seems evident that between spirit and spiritual there exists a stronger relation (higher mutation probability) than between spiritual and hamburger." ></td>
	<td class="line x" title="134:169	A natural possibility to choose a word mutation representation function is the Edit-distance (Levenshtein, 1966) (edist(." ></td>
	<td class="line x" title="135:169	as a negative reward for word alignment." ></td>
	<td class="line x" title="136:169	For a given word pair wi,wj, the greater the Edit-distance value, the more unlikely the word wi will be aligned with word wj." ></td>
	<td class="line x" title="137:169	However, after some early experiments with this function, it revealed to lead to some problems by enabling alignments between very different words, like total,israel, fire,made or troops,members, despite many good alignments also achieved." ></td>
	<td class="line x" title="138:169	This happens because the Editdistance returns relatively small values, unable to sufficiently penalize different words, like the ones listed before, to inhibit the alignment." ></td>
	<td class="line x" title="139:169	In bioinformatics language, it means that even for such pairs the mutation probability is still high." ></td>
	<td class="line x" title="140:169	Another problem of the Edit-distance is that it does not distinguish between long and small words, for instance the pairs in,by and governor,governed have both the Edit-distance equals to 2." ></td>
	<td class="line x" title="141:169	As a consequence, we propose a new function (Equation 4) for word mutation penalization, able to give better answers for the mentioned problems." ></td>
	<td class="line x" title="142:169	The idea is to divide the Editdistance value by the length of the normalized9 maximum common subsequence maxseq(." ></td>
	<td class="line x" title="143:169	between both words." ></td>
	<td class="line x" title="144:169	For example, the longest common subsequence for the pair w1,w2 = reinterpretation,interpreted is interpret, 7Point Access Mutation." ></td>
	<td class="line x" title="145:169	8Blocks Substitution Matrices." ></td>
	<td class="line x" title="146:169	9The length of the longest common subsequence divided by the word with maximum length value." ></td>
	<td class="line x" title="147:169	with length equal to 9 and maxseq(w1,w2) = 9 max16,11} = 0.5625 costAlign(wi,wj) =  edist(wi,wj)+maxseq(w i,wj) (4) where  is a small value10 that acts like a safety hook against divisions by zero, when maxseq(wi,wj) = 0." ></td>
	<td class="line x" title="148:169	word 1 word 2 -edist costAlign rule ruler -1 -1.235 governor governed -2 -2.632 pay paying -3 -5.882 reinterpretation interpreted -7 -12.227 hamburger spiritual -9 -74.312 in by -2 -200.000 Table 4: Word mutation functions comparision." ></td>
	<td class="line x" title="149:169	Remark that with the costAlign(." ></td>
	<td class="line x" title="150:169	scoring function the problems with pairs likein,by simply vanish." ></td>
	<td class="line x" title="151:169	The smaller the words, the more constrained the mutation will be." ></td>
	<td class="line x" title="152:169	5 Experiments and Results 5.1 Corpus of Paraphrases To test our alignment method, we used two types of corpora." ></td>
	<td class="line x" title="153:169	The first is the DUC 2002 corpus (DUC2002) and the second is automatically extracted from related web news stories (WNS) automatically extracted." ></td>
	<td class="line x" title="154:169	For both original corpora, paraphrase extraction has been performed by using the Sumo-Metric and two corpora of paraphrases were obtained." ></td>
	<td class="line x" title="155:169	Afterwards the alignment algorithm was applied over both corpora." ></td>
	<td class="line x" title="156:169	5.2 Quality of Dynamic Alignment We tested the proposed alignment methods by giving a sample of 201 aligned paraphrase sentence pairs to a human judge and ask to classify each pair as correct, acorrect11, error 12, and merror13." ></td>
	<td class="line x" title="157:169	We also asked to classify the local alignment choice14 as adequate or inadequate." ></td>
	<td class="line x" title="158:169	The results are shown in the next table: 10We take  = 0.01." ></td>
	<td class="line x" title="159:169	11Almost correct minor errors exist 12With some errors." ></td>
	<td class="line x" title="160:169	13With many errors 14Global or local alignment." ></td>
	<td class="line x" title="161:169	182 Global Local not para correct acorrect error merror adequate 31 108 28 12 8 12/14 15.5% 63.5% 16.5% 7.1% 4.7% 85.7% Table 5: Precision of alignments." ></td>
	<td class="line x" title="162:169	For global alignments15 we have 11.8% pairs with relevant errors and 85.7% (12 from 14) of all local alignment decisions were classified as adequate." ></td>
	<td class="line x" title="163:169	The not para column shows the number of false paraphrases identified, revealing a precision value of 84.5% for the Sumo-Metric." ></td>
	<td class="line x" title="164:169	6 Conclusion and Future Work A set of important steps toward automatic construction of aligned paraphrase corpora are presented and inherent relevant issues discussed, like clustering and alignment." ></td>
	<td class="line nc" title="165:169	Experiments, by using 4 algorithms and through visualization techniques, revealed that clustering is a worthless effort for paraphrase corpora construction, contrary to the literature claims (Barzilay & Lee, 2003)." ></td>
	<td class="line x" title="166:169	Therefore simple paraphrase pair extraction is suggested and by using a recent and more reliable metric (Sumo-Metric) (Anonymous, 2007) designed for asymmetrical entailed pairs." ></td>
	<td class="line x" title="167:169	We also propose a dynamic choosing of the alignment algorithm and a word scoring function for the alignment algorithms." ></td>
	<td class="line x" title="168:169	In the future we intend to clean the automatic constructed corpus by introducing syntactical constraints to filter the wrong alignments." ></td>
	<td class="line x" title="169:169	Our next step will be to employ Machine Learning techniques for rewriting rule induction, by using this automatically constructed aligned paraphrase corpus." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1029
A Probabilistic Model for Measuring Grammaticality and Similarity of Automatically Generated Paraphrases of Predicate Phrases
Fujita, Atsushi;Sato, Satoshi;"></td>
	<td class="line x" title="1:200	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 225232 Manchester, August 2008 A Probabilistic Model for Measuring Grammaticality and Similarity of Automatically Generated Paraphrases of Predicate Phrases Atsushi Fujita Satoshi Sato Graduate School of Engineering, Nagoya University {fujita,ssato}@nuee.nagoya-u.ac.jp Abstract The most critical issue in generating and recognizing paraphrases is development of wide-coverage paraphrase knowledge." ></td>
	<td class="line x" title="2:200	Previous work on paraphrase acquisition has collected lexicalized pairs of expressions; however, the results do not ensure full coverage of the various paraphrase phenomena." ></td>
	<td class="line x" title="3:200	This paper focuses on productive paraphrases realized by general transformation patterns, and addresses the issues in generating instances of phrasal paraphrases with those patterns." ></td>
	<td class="line x" title="4:200	Our probabilistic model computes how two phrases are likely to be correct paraphrases." ></td>
	<td class="line x" title="5:200	The model consists of two components: (i) a structured N-gram language model that ensures grammaticality and (ii) a distributional similarity measure for estimating semantic equivalence and substitutability." ></td>
	<td class="line x" title="6:200	1 Introduction In many languages, a concept can be expressed with several different linguistic expressions." ></td>
	<td class="line x" title="7:200	Handling such synonymous expressions in a given language, i.e., paraphrases, is one of the key issues in a broad range of natural language processing tasks." ></td>
	<td class="line x" title="8:200	For example, the technology for identifying paraphrases would play an important role in aggregating the wealth of uninhibited opinions about products and services that are available on the Web, from both the consumers and producers viewpoint." ></td>
	<td class="line x" title="9:200	On the other hand, whenever we draw up a document, we always seek the most appropriate expression for conveying our ideas." ></td>
	<td class="line x" title="10:200	In such a situation, a system that generates and proposes alternative expressions would be extremely beneficial." ></td>
	<td class="line x" title="11:200	c Atsushi Fujita and Satoshi Sato, 2008." ></td>
	<td class="line x" title="12:200	Licensed under the Creative Commons Attribution-NoncommercialShare Alike 3.0 Unported license." ></td>
	<td class="line x" title="13:200	Some rights reserved." ></td>
	<td class="line x" title="14:200	http://creativecommons.org/licenses/by-nc-sa/3.0/ Most of previous work on generating and recognizing paraphrases has been dedicated to developing context-free paraphrase knowledge." ></td>
	<td class="line x" title="15:200	It is typically represented with pairs of fragmentary expressions that satisfy the following conditions: Condition 1." ></td>
	<td class="line x" title="16:200	Semantically equivalent Condition 2." ></td>
	<td class="line x" title="17:200	Substitutable in some context The most critical issue in developing such knowledge is ensuring the coverage of the paraphrase phenomena." ></td>
	<td class="line x" title="18:200	To attain this coverage, we have proposed a strategy for dividing paraphrase phenomena into the following two classes (Fujita et al., 2007): (1) Non-productive (idiosyncratic) paraphrases a. burst into tears  cried b. comfort  console (Barzilay and McKeown, 2001) (2) Productive paraphrases a. be in our favor  be favorable to us b. show a sharp decrease decrease sharply (Fujita et al., 2007) Typical examples ofnon-productiveparaphrases are lexical paraphrases such as those shown in (1) and idiomatic paraphrases of literal phrases (e.g., kick the bucket  die)." ></td>
	<td class="line x" title="19:200	Knowledge of this class of paraphrases should be stored statically, because they cannot be represented with abstract patterns." ></td>
	<td class="line x" title="20:200	On the other hand, a productive paraphrase is one having a degree of regularity, as exhibited by the examples in (2)." ></td>
	<td class="line x" title="21:200	It is therefore reasonable to represent them with a set of general patterns such as those shown in (3)." ></td>
	<td class="line x" title="22:200	This attains a higher coverage, while keeping the knowledge manageable." ></td>
	<td class="line x" title="23:200	(3) a. N 1 VN 2  N 1 s V -ing of N 2 b. N 1 VN 2  N 2 be V -en by N 1 (Harris, 1957) Various methods have been proposed to acquire paraphrase knowledge (these are reviewed in Section 2.1) where pairs of existing expres225 sions are collected from the given corpus, taking the above two conditions into account." ></td>
	<td class="line x" title="24:200	On the other hand, another issue arises when paraphrase knowledge is generated from the patterns for productive paraphrases such as shown in (3) by instantiating variables with specific words, namely, Condition 3." ></td>
	<td class="line x" title="25:200	Both expressions are grammatical This paper proposes a probabilistic model for computing how likely a given pair of expressions satisfy the aforementioned three conditions." ></td>
	<td class="line x" title="26:200	In particular, we focus on the post-generation assessment of automatically generated productive paraphrases of predicate phrases in Japanese." ></td>
	<td class="line x" title="27:200	In the next section, we review previous approaches and models." ></td>
	<td class="line x" title="28:200	The proposed probabilistic model is then presented in Section 3, where the grammaticality factor and similarity factor are derived from a conditional probability." ></td>
	<td class="line x" title="29:200	In Section 4, the settings for and results of an empirical experiment are detailed." ></td>
	<td class="line x" title="30:200	Finally, Section 5 summarizes this paper." ></td>
	<td class="line x" title="31:200	2 Previous work 2.1 Acquiring paraphrase knowledge The task of automatically acquiring paraphrase knowledge is drawing the attention of an increasing number of researchers." ></td>
	<td class="line x" title="32:200	They are tackling the problem of how precisely paraphrase knowledge can be acquired, although they have tended to notice that it is hard to acquire paraphrase knowledge that ensures full coverage of the various paraphrase phenomena from existing text corpora alone." ></td>
	<td class="line x" title="33:200	To date, two streams of research have evolved: one acquires paraphrase knowledge from parallel/comparable corpora, while the other uses the regular corpus." ></td>
	<td class="line x" title="34:200	Several alignment techniques have been proposed to acquire paraphrase knowledge from parallel/comparable corpora, imitating the techniques devised for machine translation." ></td>
	<td class="line oc" title="35:200	Multiple translations of the same text (Barzilay and McKeown, 2001), corresponding articles from multiple news sources (Barzilay and Lee, 2003; Quirk et al., 2004; Dolan et al., 2004), and bilingual corpus (Bannard and Callison-Burch, 2005) have been utilized." ></td>
	<td class="line n" title="36:200	Unfortunately, this approach produces only a low coverage because the size of the parallel/comparable corpora is limited." ></td>
	<td class="line x" title="37:200	Inthe second stream, i.e.,paraphrase acquisition fromtheregular corpus, the distributional hypothesis (Harris, 1968) has been adopted." ></td>
	<td class="line x" title="38:200	The similarity of two expressions, computed from this hypothesis, is called distributional similarity." ></td>
	<td class="line x" title="39:200	The essence of this measure is summarized as follows: Feature representation: to compute the similarity, given expressions are first mapped to certain feature representations." ></td>
	<td class="line x" title="40:200	Expressions that co-occur with the given expression, such as adjacent words (Barzilay and McKeown, 2001; Lin and Pantel, 2001), and modifiers/modifiees (Yamamoto, 2002; Weeds et al., 2005), have so far been examined." ></td>
	<td class="line x" title="41:200	Feature weighting: to precisely compute the similarity, the weight for each feature is adjusted." ></td>
	<td class="line x" title="42:200	Point-wise mutual information (Lin, 1998) and Relative Feature Focus (Geffet and Dagan, 2004) are well-known examples." ></td>
	<td class="line x" title="43:200	Feature comparison measures: to convert two feature sets into a scalar value, several measures have been proposed, such as cosine, Lins measure (Lin, 1998), Kullback-Leibler (KL) divergence and its variants." ></td>
	<td class="line x" title="44:200	While most researchers extract fully-lexicalized pairs of words or word sequences only, two algorithms collect template-like knowledge using dependency parsers." ></td>
	<td class="line x" title="45:200	DIRT (Lin and Pantel, 2001) collects pairs of paths in dependency parses that connect two nominal entities." ></td>
	<td class="line x" title="46:200	TEASE(Szpektor et al., 2004) discovers dependency sub-parses from the Web, based on sets of representative entities for a given lexical item." ></td>
	<td class="line x" title="47:200	The output of these systems contains the variable slots as shown in (4)." ></td>
	<td class="line x" title="48:200	(4) a. X wrote Y  X is the author of Y b. X solves Y  X deals with Y (Lin and Pantel, 2001) The knowledge in (4) falls between that in (1), which is fully lexicalized, and that in (3), which is almost fully abstracted." ></td>
	<td class="line x" title="49:200	As a way of enriching such a template-like knowledge, Pantel et al.(2007) proposed the notion of inferential selectional preference and collected expressions that would fill those slots." ></td>
	<td class="line x" title="51:200	As mentioned in Section 1, the aim of the studies reviewed here is to collect paraphrase knowledge." ></td>
	<td class="line x" title="52:200	Thus, they need not to take the grammaticality of expressions into account." ></td>
	<td class="line x" title="53:200	2.2 Generating paraphrase instances Representing productive paraphrases with a set of general patterns makes them maintainable and attains a higher coverage of the paraphrase phenomena." ></td>
	<td class="line x" title="54:200	From the transformation grammar (Har226 ris, 1957), this approach has been adopted by many researchers (Melcuk and Polgu`ere, 1987; Jacquemin, 1999; Fujita et al., 2007)." ></td>
	<td class="line x" title="55:200	An important issue arises when such a pattern is used to generate instances of paraphrases by replacing its variables with specific words." ></td>
	<td class="line x" title="56:200	This involves assessing the grammaticality of two expressions in addition to their semantic equivalence and substitutability." ></td>
	<td class="line x" title="57:200	As a post-generation assessment of automatically generated productive paraphrases, we have applied distributional similarity measures (Fujita and Sato, 2008)." ></td>
	<td class="line x" title="58:200	Our findings from a series of empirical experiments are summarized as follows:  Search engines are useful for retrieving the contextual features of predicate phrases despite some limitations (Kilgarriff, 2007)." ></td>
	<td class="line x" title="59:200	 Distributional similarity measures produce a tolerable level of performance." ></td>
	<td class="line x" title="60:200	Thegrammaticality of aphrase, however, ismerely assessed by issuing the phrase as a query to a commercial search engine." ></td>
	<td class="line x" title="61:200	Although a more frequent expression is more grammatical, the length bias should also be considered in the assessment." ></td>
	<td class="line x" title="62:200	Quirk et al.(2004) built a paraphrase generation model from a monolingual comparable corpus based on a statistical machine translation framework, where the language model assesses the grammaticality of the translations, i.e., generated expressions." ></td>
	<td class="line x" title="64:200	The translation model, however, is not suitable for generating productive paraphrases, because it learns word alignments at the surface level." ></td>
	<td class="line x" title="65:200	To cover all of the productive paraphrases, we require an non-real comparable corpus in which all instances of productive paraphrases have a chance of being aligned." ></td>
	<td class="line x" title="66:200	Furthermore, as the translation model optimizes the word alignment at the sentence level, the substitutability of the aligned word sequences cannot be explicitly guaranteed." ></td>
	<td class="line x" title="67:200	2.3 Existing measures for paraphrases To date, no model has been established that takes into account all of the three aforementioned conditions." ></td>
	<td class="line x" title="68:200	With the ultimate aim of building an ideal model, this section overviews the characteristics and drawbacks of the four existing measures." ></td>
	<td class="line x" title="69:200	Lins measure Lin (1998) proposed a symmetrical measure: Par Lin (s  t)= summationtext fF s F t (w(s,f)+w(t,f)) summationtext fF s w(s,f)+ summationtext fF t w(t,f) , where F s and F t denote sets of features with positive weights for words s and t, respectively." ></td>
	<td class="line x" title="70:200	Although this measure has been widely cited and has so far exhibited good performance, its symmetry seems unnatural." ></td>
	<td class="line x" title="71:200	Moreover, it may not work well for dealing with general predicate phrases because it is hard to enumerate all phrases to determine the weights of features w(,f).We thus simply adopted the co-occurrence frequency of the phrase and the feature as in (Fujita and Sato, 2008)." ></td>
	<td class="line x" title="72:200	Skew divergence The skew divergence, a variant of KL divergence, was proposed in (Lee, 1999) based on an insight: the substitutability of one word for another need not be symmetrical." ></td>
	<td class="line x" title="73:200	The divergence is given by the following formula: d skew (t,s)=D (P s bardblP t +(1 )P s ), where P s and P t are the probability distributions of features for the given original and substituted words s and t, respectively." ></td>
	<td class="line x" title="74:200	0    1 is a parameter for approximating KL divergence D.The score can be recast into a similarity score via, for example, the following function (Fujita and Sato, 2008): Par skew (st)=exp(d skew (t,s))." ></td>
	<td class="line x" title="75:200	This measure offers an advantage: the weight for each feature is determined theoretically." ></td>
	<td class="line x" title="76:200	However, the optimization of  is difficult because it varies according to the task and even the data size (confidence of probability distributions)." ></td>
	<td class="line x" title="77:200	Translation-based conditional probability Bannard and Callison-Burch (2005) proposed a probabilistic model for acquiring phrasal paraphrases 1 . The likelihood of t as a paraphrase of the given phrase s is defined as follows: P(t|s)= summationdisplay ftr(s)tr(t) P(t|f)P(f|s), where tr(e) stands for a set of foreign language phrases that are aligned with e in the given parallel corpus." ></td>
	<td class="line x" title="78:200	Parameters P(t|f) and P(f|s) are also estimated using the given parallel corpus." ></td>
	<td class="line x" title="79:200	A largescale parallel corpus may enable us to precisely acquire a large amount of paraphrase knowledge." ></td>
	<td class="line x" title="80:200	It 1 In their definition, the term phrase is a sequence of words, while in this paper it designates the subtrees governed by predicates (Fujita et al., 2007)." ></td>
	<td class="line x" title="81:200	227 is not feasible, however, to build (or obtain) a parallel corpus inwhich all the instances of productive paraphrases are translated to the same expression in the other side of language." ></td>
	<td class="line x" title="82:200	3 Proposed probabilistic model 3.1 Formulation with conditional probability Recall that our aim is to establish a measure that computes the likelihood of a given pair of automatically generated predicate phrases satisfying the following three conditions: Condition 1." ></td>
	<td class="line x" title="83:200	Semantically equivalent Condition 2." ></td>
	<td class="line x" title="84:200	Substitutable in some context Condition 3." ></td>
	<td class="line x" title="85:200	Both expressions are grammatical Based on the characteristics of the existing measures reviewed in Section 2.3, we propose a probabilistic model." ></td>
	<td class="line x" title="86:200	Let s and t be the source and target predicate phrase, respectively." ></td>
	<td class="line x" title="87:200	Assuming that s is grammatical, the degree to which the above conditions are satisfied is formalized as a conditional probability P(t|s), as in (Bannard and CallisonBurch, 2005)." ></td>
	<td class="line x" title="88:200	Then, assuming that s and t are paradigmatic (i.e., paraphrases) and thus donot cooccur, the proposed model is derived as follows: P(t|s)= summationdisplay fF P(t|f)P(f|s) = summationdisplay fF P(f|t)P(t) P(f) P(f|s) = P(t) summationdisplay fF P(f|t)P(f|s) P(f) , where F denotes a set of features." ></td>
	<td class="line x" title="89:200	The first factor P(t) is called the grammaticality factor because it quantifies the degree to which condition 3 is satisfied, except that we assume that the given s is grammatical." ></td>
	<td class="line x" title="90:200	The second factor summationtext fF P(f|t)P(f|s) P(f) (Sim(s,t), hereafter), on the other hand, is called the similarity factor because it approximates the degree to which conditions 1 and 2 are satisfied by summing up the overlap of the features of two expressions s and t. The characteristics and advantages of the proposed model are summarized as follows: 1) Asymmetric." ></td>
	<td class="line x" title="91:200	2) Grammaticality is assessed by P(t)." ></td>
	<td class="line x" title="92:200	3) No heuristic is introduced." ></td>
	<td class="line x" title="93:200	As the skew divergence, the weight of the features can be simply estimated as conditional probabilities P(f|t) and P(f|s) and marginal probability P(f)." ></td>
	<td class="line x" title="94:200	4) There is no need to enumerate all the phrases." ></td>
	<td class="line x" title="95:200	s and t are merely the given conditions." ></td>
	<td class="line x" title="96:200	The following subsections describe each factor." ></td>
	<td class="line x" title="97:200	3.2 Grammaticality factor The factor P(t) quantifies how the phrase t is grammatical using statistical language model." ></td>
	<td class="line x" title="98:200	Unlike English, in Japanese, predicates such as verbs and adjectives do not necessarily determine the order of their arguments, although they have some preference." ></td>
	<td class="line x" title="99:200	For example, both of the two sentences in (5) are grammatical." ></td>
	<td class="line x" title="100:200	(5) a. kare-wa pasuta-o hashi-de taberu." ></td>
	<td class="line x" title="101:200	he-TOP pasta-ACC chopsticks-IMP to eat He eats pasta with chopsticks." ></td>
	<td class="line x" title="102:200	b. kare-wa hashi-de pasuta-o taberu." ></td>
	<td class="line x" title="103:200	he-TOP chopsticks-IMP pasta-ACC to eat He eats pasta with chopsticks." ></td>
	<td class="line x" title="104:200	This motivates us to use structured N-gram language models (Habash, 2004)." ></td>
	<td class="line x" title="105:200	Given a phrase t, its grammaticality P(t) is formulated as follows, assuming a (N 1)-th order Markov process for generating its dependency structure T(t): P(t)= bracketleftBigg productdisplay i=1|T(t)| P d parenleftbig c i |d 1 i ,d 2 i ,,d N1 i parenrightbig bracketrightBigg 1/|T(t)| , where |T(t)| stands for the number of nodes in T(t)." ></td>
	<td class="line x" title="106:200	Toignore the length bias of the target phrase, a normalization factor 1/|T(t)| is introduced." ></td>
	<td class="line x" title="107:200	d j i denotes the direct ancestor node of the i-th node c i ,wherej is the distance from c i ; for example, d 1 i and d 2 i are the parent and grandparent nodes of c i , respectively." ></td>
	<td class="line x" title="108:200	Then, a concrete definition of the nodes in the dependency structure is given." ></td>
	<td class="line x" title="109:200	Widely-used Japanese dependency parsers such as CaboCha 2 and KNP 3 consider a sequence of words as a node called a bunsetsu that consists of at least one content word followed by a sequence of function words if any." ></td>
	<td class="line x" title="110:200	The hyphenated word sequences in (6) exemplify those nodes." ></td>
	<td class="line x" title="111:200	(6) kitto kare-ha kyou-no surely he-TOP today-GEN kaigi-ni-ha ko-nai-daro-u." ></td>
	<td class="line x" title="112:200	meeting-DAT-TOP to come-NEG-must He will surely not come to todays meeting." ></td>
	<td class="line x" title="113:200	As bunsetsu can be quite long, involving more than ten words, regarding it as a node makes the model complex." ></td>
	<td class="line x" title="114:200	Therefore, we compare the 2 http://chasen.org/taku/software/cabocha/ 3 http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.html 228 <EOS> . = punc." ></td>
	<td class="line x" title="115:200	= u = aux da = aux= aux nai = auxnai N: noun V: verb Adv: adverb AdvN: adverbial noun Pro: pronoun cp: case particle tp: topic-marking particle ap: adnominal particle aux: auxiliary verb punc: punctuation kuru =Vkuru wa =tp ni =cp kaigi =N kaigi no =ap kyou =AdvN kyou kitto =Adv kare =Pro Japanese base-chunk (bunsetsu) wa =tp Figure 1: MDS of sentence (6)." ></td>
	<td class="line x" title="116:200	following two versions of dependency structures whose nodes are smaller than bunsetsu." ></td>
	<td class="line x" title="117:200	MDS: Morpheme-based dependency structure (Takahashi et al., 2001) regards a morpheme as a node." ></td>
	<td class="line x" title="118:200	MDS of sentence (6) is shown in Figure 1." ></td>
	<td class="line x" title="119:200	CFDS: The node of a content-function-based dependency structure is either a sequence of content words or of function words." ></td>
	<td class="line x" title="120:200	CFDS of sentence (6) is shown Figure 2." ></td>
	<td class="line x" title="121:200	Structured N-gram language models were created from 15 years of Mainichi newspaper articles 4 using a dependency parser Cabocha, with N being varied from 1 to 3." ></td>
	<td class="line x" title="122:200	Then, the 3-gram conditional probability P d (c i |d 1 i ,d 2 i ) is given by the linear interpolation of those three models as follows: P d (c i |d 1 i ,d 2 i )= 3 P ML (c i |d 1 i ,d 2 i ) + 2 P ML (c i |d 1 i ) + 1 P ML (c i ), s.t. summationdisplay j  j =1, where mixture weights  j are selected via an EM algorithm using development data 5 that has not been used for estimating P ML . 3.3 Similarity factor The similarity factor Sim(s,t) quantifies how two phrases s and t are similar by comparing two sets of contextual features f  F for s and t. 4 Mainichi 1991-2005 (1.5GB, 21M sentences)." ></td>
	<td class="line x" title="123:200	5 Yomiuri 2005 (350MB, 4.7M sentences) and Asahi 2005 (180MB, 2.7M sentences)." ></td>
	<td class="line x" title="124:200	<EOS> nai-daro-u-." ></td>
	<td class="line x" title="125:200	= Fnai-daro-u-." ></td>
	<td class="line x" title="126:200	C: Content part F: Function part kuru =C wa =F ni-wa =F kaigi =Ckaigi no =F kyou =C kitto =Ckitto kare =Ckare Japanese base-chunk (bunsetsu) Figure 2: CFDS of sentence (6)." ></td>
	<td class="line x" title="127:200	We employ the following two types of feature sets, which we have examined in our previous work (Fujita and Sato, 2008), where a feature f consists of an expression e and a relation r: BOW: A pair of phrases is likely to be semantically similar, if the distributions of the words surrounding the phrases is similar." ></td>
	<td class="line x" title="128:200	The relation set R BOW contains only cooccur in the same sentence." ></td>
	<td class="line x" title="129:200	MOD: A pair of phrases is likely to be substitutable with each other, provided they share a number of instances of modifiers and modifiees: the set of the relation R MOD consists of two relations modifier and modifiee." ></td>
	<td class="line x" title="130:200	Conditional probability distributions P(f|s) and P(f|t) are estimated using a Web search engine as in (Fujita and Sato, 2008)." ></td>
	<td class="line x" title="131:200	Given a phrase p, snippets of Web pages are firstly obtained via Yahoo API 6 by issuing p as a query." ></td>
	<td class="line x" title="132:200	The maximum number of snippets is set to 1,000." ></td>
	<td class="line x" title="133:200	Then, the features of the phrase are retrieved from those snippets using a morphological analyzer ChaSen 7 and CaboCha." ></td>
	<td class="line x" title="134:200	Finally, the conditional probability distribution P(f|p) is estimated as follows: P(f|p)=P(r, e|p) = freq sni (p,r,e) summationtext r prime R summationtext e prime freq sni (p,r prime ,e prime ) , where freq sni (p,r,e) stands for the frequency of the expression e appealing with the phrase p in relation r within the snippets for p. The weight for features P(f) is estimated using a static corpus based on the following equation: P(f)=P(r, e) = freq cp (r, e) summationtext r prime R summationtext e prime freq cp (r prime ,e prime ) , 6 http://developer.yahoo.co.jp/search/ 7 http://chasen.naist.jp/hiki/ChaSen/ 229 where freq cp (r, e) indicates the frequency of the expression e appearing with something in relation r within the given corpus." ></td>
	<td class="line x" title="135:200	Two different sorts of corpora are separately used to build two variations of P(f)." ></td>
	<td class="line x" title="136:200	The one is Mainichi, which is used for building structured N-gram language models in Section 3.2, while the other is a huge corpus consisting of 470M sentences collected from the Web (Kawahara and Kurohashi, 2006)." ></td>
	<td class="line x" title="137:200	4 Experiments 4.1 Data We conducted an empirical experiment to evaluate the proposed model using the test suite developed in (Fujita and Sato, 2008)." ></td>
	<td class="line x" title="138:200	The test suite consists of 176,541 pairs of paraphrase candidates that are automatically generated using a pattern-based paraphrase generation system (Fujita et al., 2007) for 4,002 relatively high-frequency phrases sampled from a newspaper corpus 8 . To evaluate the system from a generation viewpoint, i.e., how well a system can rank a correct candidate first, we extracted paraphrase candidates for 200 randomly sampled source phrases from the test suite." ></td>
	<td class="line x" title="139:200	Table 1 shows the statistics of the test data." ></td>
	<td class="line x" title="140:200	The All-Yield column shows that the number of candidates for a source phrase varies considerably, which implies that the data contains cases that have various difficulties." ></td>
	<td class="line x" title="141:200	While the average number of candidates for each source phrase was 48.3 (the maximum was 186), it was dramatically reduced through extracting features for each source and candidate paraphrase from Web snippets: to 5.2 with BOW and to 4.8 with MOD." ></td>
	<td class="line x" title="142:200	This suggests that a large number of spurious phrases were generated but discarded by going to the Web, and the task was significantly simplified." ></td>
	<td class="line x" title="143:200	4.2 Questions Through this experiment, weevaluated several versions of the proposed model to answer the following questions: Q1." ></td>
	<td class="line x" title="144:200	Is the proposed model superior to existing measures in practice?" ></td>
	<td class="line x" title="145:200	Par Lin and Par skew are regarded as being the baseline." ></td>
	<td class="line x" title="146:200	Q2." ></td>
	<td class="line x" title="147:200	Which language model performs better at estimating P(t)?" ></td>
	<td class="line x" title="148:200	MDS and CFDS are compared." ></td>
	<td class="line x" title="149:200	Q3." ></td>
	<td class="line x" title="150:200	Which corpus performs better at estimating P(f)?" ></td>
	<td class="line x" title="151:200	The advantage of Kawaharas huge 8 The grammaticality of the source phrases are guaranteed." ></td>
	<td class="line x" title="152:200	Table 1: Statistics of test data (Ph.: # of phrases)." ></td>
	<td class="line x" title="153:200	Source All BOW MOD Phrase type Ph." ></td>
	<td class="line x" title="154:200	Ph." ></td>
	<td class="line x" title="155:200	Yield Ph." ></td>
	<td class="line x" title="156:200	Yield Ph." ></td>
	<td class="line x" title="157:200	Yield N:C:V 18 57 3.2 54 3.0 54 3.0 N 1 :N 2 :C:V 57 4,596 80.6 594 10.4 551 9.7 N:C:V 1 :V 2 54 4,767 88.3 255 4.7 232 4.3 N:C:Adv:V 16 51 3.2 39 2.4 38 2.4 Adj:N:C:V 2 84.0 52.552.5 N:C:Adj 53 173 3.3 86 1.6 83 1.6 Total 200 9,652 48.3 1,033 5.2 963 4.8 corpus (WebCP) over Mainichi is evaluated." ></td>
	<td class="line x" title="158:200	Q4." ></td>
	<td class="line x" title="159:200	Which set of features performs better?" ></td>
	<td class="line x" title="160:200	In addition to BOW and MOD,the harmonic mean of the scores derived from BOW and MOD is examined (referred to as HAR)." ></td>
	<td class="line x" title="161:200	Q5." ></td>
	<td class="line x" title="162:200	Can the quality of P(f|s) and P(f|t) be improved by using a larger number of snippets?" ></td>
	<td class="line x" title="163:200	As the maximum number of snippets (N S ), we compared 500 and 1,000." ></td>
	<td class="line x" title="164:200	4.3 Results Twoassessors were asked to judge paraphrase candidates that are ranked first by either of the above models if each candidate satisfies each of the three conditions." ></td>
	<td class="line x" title="165:200	The results for all the above options are summarized in Table 2, where the strict precision is calculated based on those cases that gain two positive judgements, while the lenient precision is for at least one positive judgement." ></td>
	<td class="line x" title="166:200	A1: Our greatest concern is the actual performance of our probabilistic model." ></td>
	<td class="line x" title="167:200	However, no variation of the proposed model could outperform the existing models (Par Lin and Par skew )that only assess similarity." ></td>
	<td class="line x" title="168:200	Furthermore, McNemers test with p<0.05 revealed that the precisions of all the models, except the combination of CFDS for P(t) and Mainichi for P(f), were significantly worse than those of the best models." ></td>
	<td class="line x" title="169:200	To clarify the cause of these disappointing results, we investigated the performance of each factor." ></td>
	<td class="line x" title="170:200	Table 3 shows how well the grammaticality factors select a grammatical phrase, while Table 4 illustrates how well the similarity factors rank a correct paraphrase first." ></td>
	<td class="line x" title="171:200	As shown in these tables, neither factor performed the task well, although combinations produced a slight improvement in performance." ></td>
	<td class="line x" title="172:200	A detailed discussion is given below in A2 for the grammaticality factors, and in A3-A5 for the similarity factors." ></td>
	<td class="line x" title="173:200	A2: Comparisons between MDS and CFDS revealed that CFDS always produced better results than MDS not only when used for measuring grammaticality (Table 3), but also when used as a 230 Table 2: Precision for 200 test cases." ></td>
	<td class="line x" title="174:200	N S =500 Strict Lenient Model BOW MOD HAR BOW MOD HAR Par Lin 78 (39%) 88 (44%) 87 (44%) 116 (58%) 128 (64%) 127 (64%) Par skew 81 (41%) 88 (44%) 88 (44%) 120 (60%) 127 (64%) 128 (64%) MDS, Mainichi 72 (36%) 73 (37%) 76 (38%) 109 (55%) 112 (56%) 114 (57%) MDS, WebCP 71 (36%) 73 (37%) 72 (36%) 108 (54%) 110 (55%) 113 (57%) CFDS, Mainichi 79 (40%) 78 (39%) 83 (42%) 120 (60%) 119 (60%) 123 (62%) CFDS, WebCP 79 (40%) 77 (39%) 80 (40%) 118 (59%) 116 (58%) 118 (59%) N S =1,000 Strict Lenient Model BOW MOD HAR BOW MOD HAR Par Lin 79 (40%) 88 (44%) 88 (44%) 116 (58%) 128 (64%) 129 (65%) Par skew 84 (42%) 89 (45%) 89 (45%) 121 (61%) 128 (64%) 128 (64%) MDS, Mainichi 72 (36%) 75 (38%) 76 (38%) 109 (55%) 114 (57%) 114 (57%) MDS, WebCP 71 (36%) 74 (37%) 72 (36%) 109 (55%) 111 (56%) 113 (57%) CFDS, Mainichi 79 (40%) 82 (41%) 83 (42%) 121 (61%) 121 (61%) 122 (61%) CFDS, WebCP 79 (40%) 78 (39%) 79 (40%) 119 (60%) 116 (58%) 119 (60%) Table 3: Precision of measuring grammaticality." ></td>
	<td class="line x" title="175:200	Model Strict Lenient MDS 104 (52%) 141 (71%) CFDS 108 (54%) 142 (71%) Table 4: Precision of similarity factors." ></td>
	<td class="line x" title="176:200	Strict Lenient N S Corpus BOW MOD HAR BOW MOD HAR 500 Mainichi 60 (30%) 68 (34%) 74 (37%) 98 (49%) 109 (55%) 114 (57%) 500 WebCP 57 (28%) 61 (31%) 74 (37%) 94 (47%) 99 (50%) 120 (60%) 1,000 Mainichi 57 (28%) 70 (35%) 74 (37%) 92 (46%) 113 (57%) 116 (58%) 1,000 WebCP 57 (28%) 60 (30%) 72 (36%) 93 (47%) 96 (48%) 116 (58%) component of the entire model (Table 2)." ></td>
	<td class="line x" title="177:200	This result is quite natural because MDScannot verify the collocation between content words in those cases where a number of function words appear between them." ></td>
	<td class="line x" title="178:200	On the other hand, CFDS with N = 3 could verify this as a result of treating the sequence of function words as a single node." ></td>
	<td class="line x" title="179:200	As mentioned in A1, however, a more sophisticated language model must enhance the proposed model." ></td>
	<td class="line x" title="180:200	One way of obtaining a suitable granularity of nodes is to introduce latent classes, such as the Semi-Markov class model (Okanohara and Tsujii, 2007)." ></td>
	<td class="line x" title="181:200	The existence of many orthographic variants of both the content and function words may prevent us from accurately estimating the grammaticality." ></td>
	<td class="line x" title="182:200	We plan to normalize these variations by using several existing resources such as the Japanese functional expression dictionary (Matsuyoshi, 2008)." ></td>
	<td class="line x" title="183:200	A3: Contrary to our expectations, the huge Web corpus did not offer any advantage over the newspaper corpus: Mainichi always produced better results than WebCP when it was combined with the grammaticality factor or when MOD was used." ></td>
	<td class="line x" title="184:200	Wecan speculate that morphological and dependency parsers produce errors when features are extracted, because they are tuned to newspaper articles." ></td>
	<td class="line x" title="185:200	Likewise, P(f|s) and P(f|t) may involve noise even though they are estimated using relatively clean parts of Web text that are retrieved by querying phrase candidates." ></td>
	<td class="line x" title="186:200	A4: For Par Lin and Par skew , different sets of features led to consistent results with our previous experiments in (Fujita and Sato, 2008), i.e., BOW < MOD similarequal HAR." ></td>
	<td class="line x" title="187:200	On the other hand, for the proposed models, MOD and HAR led to only small or sometimes negative effects." ></td>
	<td class="line x" title="188:200	When the similarity factor was used alone, however, these features beat BOW." ></td>
	<td class="line x" title="189:200	Furthermore, the impact of combining BOW and MOD into HAR was significant." ></td>
	<td class="line x" title="190:200	Given this tendency, it is expected that the grammaticality factor might be excessively emphasized." ></td>
	<td class="line x" title="191:200	Our probability model was derived straightforwardly from the conditional probability P(t|s); however, the combination of the two factors should be tuned according to their implementation." ></td>
	<td class="line x" title="192:200	A5: Finally, the influence of the number of Web snippets was analyzed; no significant difference was observed." ></td>
	<td class="line x" title="193:200	This is because we could retrieve more than 500 snippets for only 172 pairs of expressions among our test samples." ></td>
	<td class="line x" title="194:200	As it is time-consuming to obtain a large number of Web snippets, the trade-off between the number of Web snippets and the performance should be investigated further, although the quality of the Web snippets and what appears at the top of the search results will vary according to several factors other than linguistic ones." ></td>
	<td class="line x" title="195:200	231 5Conclusion A pair of expressions qualifies as paraphrases iff they are semantically equivalent, substitutable in some context, and grammatical." ></td>
	<td class="line x" title="196:200	In cases where paraphrase knowledge is represented with abstract patterns to attain a high coverage of the paraphrase phenomena, we should assess not only the first and second conditions, but also the third condition." ></td>
	<td class="line x" title="197:200	In this paper, we proposed a probabilistic model for computing how two phrases are likely to be paraphrases." ></td>
	<td class="line x" title="198:200	The proposed model consists of two components: (i) a structured N-gram language model that ensures grammaticality and (ii) a distributional similarity measure for estimating semantic equivalence and substitutability between two phrases." ></td>
	<td class="line x" title="199:200	Through an experiment, we empirically evaluated the performance of the proposed model and analyzed the characteristics." ></td>
	<td class="line x" title="200:200	Future work includes building a more sophisticated structured language model to improve the performance of the proposed model and conducting an experiment on template-like paraphrase knowledge for other than productive paraphrases." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1107
Learning Entailment Rules for Unary Templates
Szpektor, Idan;Dagan, Ido;"></td>
	<td class="line x" title="1:203	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 849856 Manchester, August 2008 Learning Entailment Rules for Unary Templates Idan Szpektor Department of Computer Science Bar-Ilan University Ramat Gan, Israel szpekti@macs.biu.ac.il Ido Dagan Department of Computer Science Bar-Ilan University Ramat Gan, Israel dagan@macs.biu.ac.il Abstract Most work on unsupervised entailment rule acquisition focused on rules between templates with two variables, ignoring unary rules entailment rules between templates with a single variable." ></td>
	<td class="line x" title="2:203	In this paper we investigate two approaches for unsupervised learning of such rules and compare the proposed methods with a binary rule learning method." ></td>
	<td class="line x" title="3:203	The results show that the learned unary rule-sets outperform the binary rule-set." ></td>
	<td class="line x" title="4:203	In addition, a novel directional similarity measure for learning entailment, termed Balanced-Inclusion, is the best performing measure." ></td>
	<td class="line x" title="5:203	1 Introduction In many NLP applications, such as Question Answering (QA) and Information Extraction (IE), it is crucial to recognize whether a specific target meaning is inferred from a text." ></td>
	<td class="line x" title="6:203	For example, a QA system has to deduce that SCO sued IBM is inferred from SCO won a lawsuit against IBM to answer Whom did SCO sue?." ></td>
	<td class="line x" title="7:203	This type of reasoning has been identified as a core semantic inference paradigm by the generic Textual Entailment framework (Giampiccolo et al., 2007)." ></td>
	<td class="line x" title="8:203	An important type of knowledge needed for such inference is entailment rules." ></td>
	<td class="line x" title="9:203	An entailment rule specifies a directional inference relation between two templates, text patterns with variables, such as X win lawsuit against Y X sue Y." ></td>
	<td class="line x" title="10:203	Applying this rule by matching X win lawsuit against Y in the above text allows a QA system to c2008." ></td>
	<td class="line x" title="11:203	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="12:203	Some rights reserved." ></td>
	<td class="line x" title="13:203	infer X sue Y and identify IBM, Ys instantiation, as the answer for the above question." ></td>
	<td class="line x" title="14:203	Entailment rules capture linguistic and world-knowledge inferences and are used as an important building block within different applications, e.g.(Romano et al., 2006)." ></td>
	<td class="line x" title="16:203	One reason for the limited performance of generic semantic inference systems is the lack of broad-scale knowledge-bases of entailment rules (in analog to lexical resources such as WordNet)." ></td>
	<td class="line x" title="17:203	Supervised learning of broad coverage rule-sets is an arduous task." ></td>
	<td class="line x" title="18:203	This sparked intensive research on unsupervised acquisition of entailment rules (and similarly paraphrases) e.g.(Lin and Pantel, 2001; Szpektor et al., 2004; Sekine, 2005)." ></td>
	<td class="line x" title="20:203	Most unsupervised entailment rule acquisition methods learn binary rules, rules between templates with two variables, ignoring unary rules, rules between unary templates (templates with only one variable)." ></td>
	<td class="line x" title="21:203	However, a predicate quite often appears in the text with just a single variable (e.g. intransitive verbs or passives), where inference requires unary rules, e.g. X take a napX sleep (further motivations in Section 3.1)." ></td>
	<td class="line x" title="22:203	In this paper we focus on unsupervised learning of unary entailment rules." ></td>
	<td class="line x" title="23:203	Two learning approaches are proposed." ></td>
	<td class="line x" title="24:203	In our main approach, rules are learned by measuring how similar the variable instantiations of two templates in a corpus are." ></td>
	<td class="line x" title="25:203	In addition to adapting state-of-the-art similarity measures for unary rule learning, we propose a new measure, termed Balanced-Inclusion, which balances the notion of directionality in entailment with the common notion of symmetric semantic similarity." ></td>
	<td class="line x" title="26:203	In a second approach, unary rules are derived from binary rules learned by state-of-theart binary rule learning methods." ></td>
	<td class="line x" title="27:203	We tested the various unsupervised unary rule 849 learning methods, as well as a binary rule learning method, on a test set derived from a standard IE benchmark." ></td>
	<td class="line x" title="28:203	This provides the first comparison between the performance of unary and binary rulesets." ></td>
	<td class="line x" title="29:203	Several results rise from our evaluation: (a) while most work on unsupervised learning ignored unary rules, all tested unary methods outperformed the binary method; (b) it is better to learn unary rules directly than to derive them from a binary rule-base; (c) our proposed Balanced-Inclusion measure outperformed all other tested methods in terms of F1 measure." ></td>
	<td class="line x" title="30:203	Moreover, only BalancedInclusion improved F1 score over a baseline inference that does not use entailment rules at all . 2 Background This section reviews relevant distributional similarity measures, both symmetric and directional, which were applied for either lexical similarity or unsupervised entailment rule learning." ></td>
	<td class="line x" title="31:203	Distributional similarity measures follow the Distributional Hypothesis, which states that words that occur in the same contexts tend to have similar meanings (Harris, 1954)." ></td>
	<td class="line x" title="32:203	Various measures were proposed in the literature for assessing such similarity between two words,uandv." ></td>
	<td class="line x" title="33:203	Given a wordq, its set of featuresFq and feature weightswq(f) for f Fq, a common symmetric similarity measure is Lin similarity (Lin, 1998a): Lin(u,v) = summationtext fFuFv[wu(f)+wv(f)]summationtext fFu wu(f)+ summationtext fFv wv(f) where the weight of each feature is the pointwise mutual information (pmi) between the word and the feature: wq(f) =log[Pr(f|q)Pr(f) ]." ></td>
	<td class="line x" title="34:203	Weeds and Weir (2003) proposed to measure the symmetric similarity between two words by averaging two directional (asymmetric) scores: the coverage of each words features by the other." ></td>
	<td class="line x" title="35:203	The coverage of u by v is measured by: Cover(u,v) = summationtext fFuFv wu(f)summationtext fFu wu(f) The average can be arithmetic or harmonic: WeedsA(u,v) = 12[Cover(u,v)+Cover(v,u)] WeedsH(u,v) = 2Cover(u,v)Cover(v,u)Cover(u,v)+Cover(v,u) Weeds et al. also used pmi for feature weights." ></td>
	<td class="line x" title="36:203	Binary rule learning algorithms adopted such lexical similarity approaches for learning rules between templates, where the features of each template are its variable instantiations in a corpus, such as {X=SCO, Y=IBM} for the example in Section 1." ></td>
	<td class="line oc" title="37:203	Some works focused on learning rules from comparable corpora, containing comparable documents such as different news articles from the same date on the same topic (Barzilay and Lee, 2003; Ibrahim et al., 2003)." ></td>
	<td class="line p" title="38:203	Such corpora are highly informative for identifying variations of the same meaning, since, typically, when variable instantiations are shared across comparable documents the same predicates are described." ></td>
	<td class="line n" title="39:203	However, it is hard to collect broad-scale comparable corpora, as the majority of texts are non-comparable." ></td>
	<td class="line x" title="40:203	A complementary approach is learning from the abundant regular, non-comparable, corpora." ></td>
	<td class="line x" title="41:203	Yet, in such corpora it is harder to recognize variations of the same predicate." ></td>
	<td class="line x" title="42:203	The DIRT algorithm (Lin and Pantel, 2001) learns non-directional binary rules for templates that are paths in a dependency parse-tree between two noun variables X andY." ></td>
	<td class="line x" title="43:203	The similarity between two templatestand tprime is the geometric average: DIRT(t,tprime) = radicalBig Linx(t,tprime)Liny(t,tprime) where Linx is the Lin similarity between Xs instantiations of t and Xs instantiations of tprime in a corpus (equivalently for Liny)." ></td>
	<td class="line x" title="44:203	Some works take the combination of the two variable instantiations in each template occurrence as a single complex feature, e.g. {X-Y=SCO-IBM}, and compare between these complex features of t and tprime (Ravichandran and Hovy, 2002; Szpektor et al., 2004; Sekine, 2005)." ></td>
	<td class="line x" title="45:203	Directional Measures Most rule learning methods apply a symmetric similarity measure between two templates, viewing them as paraphrasing each other." ></td>
	<td class="line x" title="46:203	However, entailment is in general a directional relation." ></td>
	<td class="line x" title="47:203	For example, X acquire Y  X own Y and countersuit against X lawsuit against X." ></td>
	<td class="line x" title="48:203	(Weeds and Weir, 2003) propose a directional measure for learning hyponymy between two words, lr, by giving more weight to the coverage of the features of l by r (with > 12): WeedsD(l,r)=Cover(l,r)+(1)Cover(r,l) When =1, this measure degenerates into Cover(l,r), termed Precision(l,r)." ></td>
	<td class="line x" title="49:203	With 850 Precision(l,r) we obtain a soft version of the inclusion hypothesis presented in (Geffet and Dagan, 2005), which expects l to entail r if the important features of l appear also in r. Similarly, the LEDIR algorithm (Bhagat et al., 2007) identifies the entailment direction between two binary templates, l and r, which participate in a relation learned by (the symmetric) DIRT, by measuring the proportion of instantiations of l that are covered by the instantiations of r. As far as we know, only (Shinyama et al., 2002) and (Pekar, 2006) learn rules between unary templates." ></td>
	<td class="line x" title="50:203	However, (Shinyama et al., 2002) relies on comparable corpora for identifying paraphrases and simply takes any two templates from comparable sentences that share a named entity instantiation to be paraphrases." ></td>
	<td class="line x" title="51:203	Such approach is not feasible for non-comparable corpora where statistical measurement is required." ></td>
	<td class="line x" title="52:203	(Pekar, 2006) learns rules only between templates related by local discourse (information from different documents is ignored)." ></td>
	<td class="line x" title="53:203	In addition, their template structure is limited to only verbs and their direct syntactic arguments, which may yield incorrect rules, e.g. for light verbs (see Section 5.2)." ></td>
	<td class="line x" title="54:203	To overcome this limitation, we use a more expressive template structure." ></td>
	<td class="line x" title="55:203	3 Learning Unary Entailment Rules 3.1 Motivations Most unsupervised rule learning algorithms focused on learning binary entailment rules." ></td>
	<td class="line x" title="56:203	However, using binary rules for inference is not enough." ></td>
	<td class="line x" title="57:203	First, a predicate that can have multiple arguments may still occur with only one of its arguments." ></td>
	<td class="line x" title="58:203	For example, in The acquisition of TCA was successful, TCA is the only argument of acquisition." ></td>
	<td class="line x" title="59:203	Second, some predicate expressions are unary by nature." ></td>
	<td class="line x" title="60:203	For example, modifiers, such as the elected X, or intransitive verbs." ></td>
	<td class="line x" title="61:203	In addition, it appears more tractable to learn all variations for each argument of a predicate separately than to learn them for combinations of argument pairs." ></td>
	<td class="line x" title="62:203	For these reasons, it seems that unary rule learning should be addressed in addition to binary rule learning." ></td>
	<td class="line x" title="63:203	We are further motivated by the fact that some (mostly supervised) works in IE found learning unary templates useful for recognizing relevant named entities (Riloff, 1996; Sudo et al., 2003; Shinyama and Sekine, 2006), though they did not attempt to learn generic knowledge bases of entailment rules." ></td>
	<td class="line x" title="64:203	This paper investigates acquisition of unary entailment rules from regular non-comparable corpora." ></td>
	<td class="line x" title="65:203	We first describe the structure of unary templates and then explore two conceivable approaches for learning unary rules." ></td>
	<td class="line x" title="66:203	The first approach directly assesses the relation between two given templates based on the similarity of their instantiations in the corpus." ></td>
	<td class="line x" title="67:203	The second approach, which was also mentioned in (Iftene and BalahurDobrescu, 2007), derives unary rules from learned binary rules." ></td>
	<td class="line x" title="68:203	3.2 Unary Template Structure To learn unary rules we first need to define their structure." ></td>
	<td class="line x" title="69:203	In this paper we work at the syntactic representation level." ></td>
	<td class="line x" title="70:203	Texts are represented by dependency parse trees (using the Minipar parser (Lin, 1998b)) and templates by parse sub-trees." ></td>
	<td class="line x" title="71:203	Given a dependency parse tree, any sub-tree can be a candidate template, setting some of its nodes as variables (Sudo et al., 2003)." ></td>
	<td class="line x" title="72:203	However, the number of possible templates is exponential in the size of the sentence." ></td>
	<td class="line x" title="73:203	In the binary rule learning literature, the main solution for exhaustively learning all rules between any pair of templates in a given corpus is to restrict the structure of templates." ></td>
	<td class="line x" title="74:203	Typically, a template is restricted to be a path in a parse tree between two variable nodes (Lin and Pantel, 2001; Ibrahim et al., 2003)." ></td>
	<td class="line x" title="75:203	Following this approach, we chose the structure of unary templates to be paths as well, where one end of the path is the templates variable." ></td>
	<td class="line x" title="76:203	However, paths with one variable have more expressive power than paths between two variables, since the combination of two unary paths may generate a binary template that is not a path." ></td>
	<td class="line x" title="77:203	For example, the combination of X call indictable and call Y indictable is the template X call Y indictable, which is not a path between X and Y. For every noun node v in a parsed sentence, we generate templates with v as a variable as follows: 1." ></td>
	<td class="line x" title="78:203	Traverse the path from v towards the root of the parse tree." ></td>
	<td class="line x" title="79:203	Whenever a candidate predicate is encountered (any noun, adjective or verb) the path from that node to v is taken as a template." ></td>
	<td class="line x" title="80:203	We stop when the first verb or clause boundary (e.g. a relative clause) is encountered, which typically represent the syntactic boundary of a specific predicate." ></td>
	<td class="line x" title="81:203	851 2." ></td>
	<td class="line x" title="82:203	To enable templates with control verbs and light verbs, e.g. X help preventing, X make noise, whenever a verb is encountered we generate templates that are paths between v and the verbs modifiers, either objects, prepositional complements or infinite or gerund verb forms (paths ending at stop words, e.g. pronouns, are not generated)." ></td>
	<td class="line x" title="83:203	3." ></td>
	<td class="line x" title="84:203	To capture noun modifiers that act as predicates, e.g. the losingX, we extract template paths between v and each of its modifiers, nouns or adjectives, that are derived from a verb." ></td>
	<td class="line x" title="85:203	We use the Catvar database to identify verb derivations (Habash and Dorr, 2003)." ></td>
	<td class="line x" title="86:203	As an example for the procedure, the templates extracted from the sentence The losing party played it safe with party as the variable are: losing X, X play and X play safe." ></td>
	<td class="line x" title="87:203	3.3 Direct Learning of Unary Rules We applied the lexical similarity measures presented in Section 2 for unary rule learning." ></td>
	<td class="line x" title="88:203	Each argument instantiation of template t in the corpus is taken as a feature f, and the pmi between t and f is used for the features weight." ></td>
	<td class="line x" title="89:203	We first adapted DIRT for unary templates (unary-DIRT, applying Lin-similarity to the single feature vector), as well as its output filtering by LEDIR." ></td>
	<td class="line x" title="90:203	The various Weeds measures were also applied1: symmetric arithmetic average, symmetric harmonic average, weighted arithmetic average and Precision." ></td>
	<td class="line x" title="91:203	After initial analysis, we found that given a right hand side template r, symmetric measures such as Lin (in DIRT) generally tend to prefer (score higher) relationsl,rin which l and r are related but do not necessarily participate in an entailment or equivalence relation, e.g. the wrong rule kill X injure X." ></td>
	<td class="line x" title="92:203	On the other hand, directional measures such as Weeds Precision tend to prefer directional rules in which the entailing template is infrequent." ></td>
	<td class="line x" title="93:203	If an infrequent template has common instantiations with another template, the coverage of its features is typically high, whether or not an entailment relation exists between the two templates." ></td>
	<td class="line x" title="94:203	This behavior generates high-score incorrect rules." ></td>
	<td class="line x" title="95:203	Based on this analysis, we propose a new measure that balances the two behaviors, termed 1We applied the best performing parameter values presented in (Bhagat et al., 2007) and (Weeds and Weir, 2003)." ></td>
	<td class="line x" title="96:203	Balanced-Inclusion (BInc)." ></td>
	<td class="line x" title="97:203	BInc identifies entailing templates based on a directional measure but penalizes infrequent templates using a symmetric measure: BInc(l,r) = radicalbig Lin(l,r)Precision(l,r) 3.4 Deriving Unary Rules From Binary Rules An alternative way to learn unary rules is to first learn binary entailment rules and then derive unary rules from them." ></td>
	<td class="line x" title="98:203	We derive unary rules from a given binary rule-base in two steps." ></td>
	<td class="line x" title="99:203	First, for each binary rule, we generate all possible unary rules that are part of that rule (each unary template is extracted following the same procedure described in Section 3.2)." ></td>
	<td class="line x" title="100:203	For example, from X find solution to Y X solve Y we generate the unary rules X findX solve, X find solutionX solve, solution to Y solve Y and find solution toY solveY." ></td>
	<td class="line x" title="101:203	The score of each generated rule is set to be the score of the original binary rule." ></td>
	<td class="line x" title="102:203	The same unary rule can be derived from different binary rules." ></td>
	<td class="line x" title="103:203	For example, hire Y  employ Y is derived both from X hire Y X employ Y and hire Y for Z  employ Y for Z, having a different score from each original binary rule." ></td>
	<td class="line x" title="104:203	The second step of the algorithm aggregates the different scores yielded for each derived rule to produce the final rule score." ></td>
	<td class="line x" title="105:203	Three aggregation functions were tested: sum (Derived-Sum), average (Derived-Avg) and maximum (Derived-Max)." ></td>
	<td class="line x" title="106:203	4 Experimental Setup We want to evaluate learned unary and binary rule bases by their utility for NLP applications through assessing the validity of inferences that are performed in practice using the rule base." ></td>
	<td class="line x" title="107:203	To perform such experiments, we need a testset of seed templates, which correspond to a set of target predicates, and a corpus annotated with all argument mentions of each predicate." ></td>
	<td class="line x" title="108:203	The evaluation assesses the correctness of all argument extractions, which are obtained by matching in the corpus either the seed templates or templates that entail them according to the rule-base (the latter corresponds to rule-application)." ></td>
	<td class="line x" title="109:203	Following (Szpektor et al., 2008), we found the ACE 2005 event training set2 useful for this purpose." ></td>
	<td class="line x" title="110:203	This standard IE dataset includes 33 types of event predicates such as Injure, Sue and Divorce." ></td>
	<td class="line x" title="111:203	2http://projects.ldc.upenn.edu/ace/ 852 All event mentions are annotated in the corpus, including the instantiated arguments of the predicate." ></td>
	<td class="line x" title="112:203	ACE guidelines specify for each event its possible arguments, each associated with a semantic role." ></td>
	<td class="line x" title="113:203	For instance, some of the Injure event arguments are Agent, Victim and Time." ></td>
	<td class="line x" title="114:203	To utilize the ACE dataset for evaluating entailment rule applications, we manually represented each ACE event predicate by unary seed templates." ></td>
	<td class="line x" title="115:203	For example, the seed templates for Injure are A injure, injure V and injure in T." ></td>
	<td class="line x" title="116:203	We mapped each event role annotation to the corresponding seed template variable, e.g. Agent to A and Victim to V in the above example." ></td>
	<td class="line x" title="117:203	Templates are matched using a syntactic matcher that handles simple morpho-syntactic phenomena, as in (Szpektor and Dagan, 2007)." ></td>
	<td class="line x" title="118:203	A rule application is considered correct if the matched argument is annotated by the corresponding ACE role." ></td>
	<td class="line x" title="119:203	For testing binary rule-bases, we automatically generated binary seed templates from any two unary seeds that share the same predicate." ></td>
	<td class="line x" title="120:203	For example, for Injure the binary seeds A injure V, A injure inT and injureV inT were automatically generated from the above unary seeds." ></td>
	<td class="line x" title="121:203	We performed two adaptations to the ACE dataset to fit it better to our evaluation needs." ></td>
	<td class="line x" title="122:203	First, our evaluation aims at assessing the correctness of inferring a specific target semantic meaning, which is denoted by a specific predicate, using rules." ></td>
	<td class="line x" title="123:203	Thus, four events that correspond ambiguously to multiple distinct predicates were ignored." ></td>
	<td class="line x" title="124:203	For instance, the Transfer-Money event refers to both donating and lending money, and thus annotations of this event cannot be mapped to a specific seed template." ></td>
	<td class="line x" title="125:203	We also omitted 3 events with less than 10 mentions, and were left with 26 events (6380 argument mentions)." ></td>
	<td class="line x" title="126:203	Additionally, we regard all entailing mentions under the textual entailment definition as correct." ></td>
	<td class="line x" title="127:203	However, event mentions are annotated as correct in ACE only if they explicitly describe the target event." ></td>
	<td class="line x" title="128:203	For instance, a Divorce mention does entail a preceding marriage event but it does not explicitly describe it, and thus it is not annotated as a Marry event." ></td>
	<td class="line x" title="129:203	To better utilize the ACE dataset, we considered for a target event the annotations of other events that entail it as being correct as well." ></td>
	<td class="line x" title="130:203	We note that each argument was considered separately." ></td>
	<td class="line x" title="131:203	For example, we marked a mention of a divorced person as entailing the marriage of that person, but did not consider the place and time of the divorce act to be those of the marriage . 5 Results and Analysis We implemented the unary rule learning algorithms described in Section 3 and the binary DIRT algorithm (Lin and Pantel, 2001)." ></td>
	<td class="line x" title="132:203	We executed each method over the Reuters RCV1 corpus3, learning for each template r in the corpus the top 100 rules in which r is entailed by another templatel, lr." ></td>
	<td class="line x" title="133:203	All rules were learned in canonical form (Szpektor and Dagan, 2007)." ></td>
	<td class="line x" title="134:203	The rule-base learned by binary DIRT was taken as the input for deriving unary rules from binary rules." ></td>
	<td class="line x" title="135:203	The performance of each acquired rule-base was measured for each ACE event." ></td>
	<td class="line x" title="136:203	We measured the percentage of correct argument mentions extracted out of all correct argument mentions annotated for the event (recall) and out of all argument mentions extracted for the event (precision)." ></td>
	<td class="line x" title="137:203	We also measured F1, their harmonic average, and report macro average Recall, Precision and F1 over the 26 event types." ></td>
	<td class="line x" title="138:203	No threshold setting mechanism is suggested in the literature for the scores of the different algorithms, especially since rules for different right hand side templates have different score ranges." ></td>
	<td class="line x" title="139:203	Thus, we follow common evaluation practice (Lin and Pantel, 2001; Geffet and Dagan, 2005) and test each learned rule-set by taking the top K rules for each seed template, whereK ranges from 0 to 100." ></td>
	<td class="line x" title="140:203	WhenK=0, no rules are used and mentions are extracted only by direct matching of seed templates." ></td>
	<td class="line x" title="141:203	Our rule application setting provides a rather simplistic IE system (for example, no named entity recognition or approximate template matching)." ></td>
	<td class="line x" title="142:203	It is thus useful for comparing different rule-bases, though the absolute extraction figures do not reflect the full potential of the rules." ></td>
	<td class="line x" title="143:203	In Secion 5.2 we analyze the full-systems errors to isolate the rules contribution to overall system performance." ></td>
	<td class="line x" title="144:203	5.1 Results In this section we focus on the best performing variations of each algorithm type: binary DIRT, unary DIRT, unary Weeds Harmonic, BInc and Derived-Avg." ></td>
	<td class="line x" title="145:203	We omitted the results of methods that were clearly inferior to others: (a) WeedsA, WeedsD and Weeds-Precision did not increase 3http://about.reuters.com/researchandstandards/corpus/ 853 Recall over not using rules because rules with infrequent templates scored highest and arithmetic averaging could not balance well these high scores; (b) out of the methods for deriving unary rules from binary rule-bases, Derived-Avg performed best; (c) filtering with (the directional) LEDIR did not improve the performance of unary DIRT." ></td>
	<td class="line x" title="146:203	Figure 1 presents Recall, Precision and F1 of the methods for different cutoff points." ></td>
	<td class="line x" title="147:203	First, we observe that even when matching only the seed templates (K=0), unary seeds outperform the binary seeds in terms of both Precision and Recall." ></td>
	<td class="line x" title="148:203	This surprising behavior is consistent through all rule cutoff points: all unary learning algorithms perform better than binary DIRT in all parameters." ></td>
	<td class="line x" title="149:203	The inferior behavior of binary DIRT is analyzed in Section 5.2." ></td>
	<td class="line x" title="150:203	The graphs show that symmetric unary approaches substantially increase recall, but dramatically decrease precision already at the top 10 rules." ></td>
	<td class="line x" title="151:203	As a result, F1 only decreases for these methods." ></td>
	<td class="line x" title="152:203	Lin similarity (DIRT) and Weeds-Harmonic show similar behaviors." ></td>
	<td class="line x" title="153:203	They consistently outperform Derived-Avg." ></td>
	<td class="line x" title="154:203	One reason for this is that incorrect unary rules may be derived even from correct binary rules." ></td>
	<td class="line x" title="155:203	For example, from X gain seat on Y  elect X to Y the incorrect unary rule X gainelectX is also generated." ></td>
	<td class="line x" title="156:203	This problem is less frequent when unary rules are directly scored based on their corpus statistics." ></td>
	<td class="line x" title="157:203	The directional measure of BInc yields a more accurate rule-base, as can be seen by the much slower precision reduction rate compared to the other algorithms." ></td>
	<td class="line x" title="158:203	As a result, it is the only algorithm that improves over the F1 baseline of K=0, with the best cutoff point at K=20." ></td>
	<td class="line x" title="159:203	BIncs recall increases moderately compared to other unary learning approaches, but it is still substantially better than not using rules (a relative recall increase of 50% already at K=10)." ></td>
	<td class="line x" title="160:203	We found that many of the correct mentions missed by BInc but identified by other methods are due to occasional extractions of incorrect frequent rules, such as partial templates (see Section 5.2)." ></td>
	<td class="line x" title="161:203	This is reflected in the very low precision of the other methods." ></td>
	<td class="line x" title="162:203	On the other hand, some correct rules were only learned by BInc, e.g. countersuit againstXX sue and X take wife X marry." ></td>
	<td class="line x" title="163:203	When only one argument is annotated for a specific event mention (28% of ACE predicate mentions, which account for 15% of all annotated arFigure 1: Average Precision, Recall and F1 at different top K rule cutoff points." ></td>
	<td class="line x" title="164:203	guments), binary rules either miss that mention, or extract both the correct argument and another incorrect one." ></td>
	<td class="line x" title="165:203	To neutralize this bias, we also tested the various methods only on event mentions annotated with two or more arguments and obtained similar results to those presented for all mentions." ></td>
	<td class="line x" title="166:203	This further emphasizes the general advantage of using unary rules over binary rules." ></td>
	<td class="line x" title="167:203	854 5.2 Analysis Binary-DIRT We analyzed incorrect rules both for binary-DIRT and BInc by randomly sampling, for each algorithm, 200 rules that extracted incorrect mentions." ></td>
	<td class="line x" title="168:203	We manually classified each rule l r as either: (a) Correct the rule is valid in some contexts of the event but extracted some incorrect mentions; (b) Partial Template l is only a part of a correct template that entails r. For example, learning X decideX meet instead of X decide to meet X meet; (e) Incorrect other incorrect rules, e.g. charge Xconvict X." ></td>
	<td class="line x" title="169:203	Table 1 summarizes the analysis and demonstrates two problems of binary-DIRT." ></td>
	<td class="line x" title="170:203	First, relative to BInc, it tends to learn incorrect rules for high frequency templates, and therefore extracted many more incorrect mentions for the same number of incorrect rules." ></td>
	<td class="line x" title="171:203	Second, a large percentage of incorrect mentions extracted are due to partial templates at the rule left-hand-side." ></td>
	<td class="line x" title="172:203	Such rules are leaned because many binary templates have a more complex structure than paths between arguments." ></td>
	<td class="line x" title="173:203	As explained in Section 3.2 the unary template structure we use is more expressive, enabling to learn the correct rules." ></td>
	<td class="line x" title="174:203	For example, BInc learned take Y into custody  arrest Y while binaryDIRT learned X take Y X arrest Y." ></td>
	<td class="line x" title="175:203	System Level Analysis We manually analyzed the reasons for false positives (incorrect extractions) and false negatives (missed extractions) of BInc, at its best performing cutoff point (K=20), by sampling 200 extractions of each type." ></td>
	<td class="line x" title="176:203	From the false positives analysis (Table 2) we see that 39% of the errors are due to incorrect rules." ></td>
	<td class="line x" title="177:203	The main reasons for learning such rules are those discussed in Section 3.3: (a) related templates that are not entailing; (b) infrequent templates." ></td>
	<td class="line x" title="178:203	All learning methods suffer from these issues." ></td>
	<td class="line x" title="179:203	As was shown by our results, BInc provides a first step towards reducing these problems." ></td>
	<td class="line x" title="180:203	Yet, these issues require further research." ></td>
	<td class="line x" title="181:203	Apart from incorrectly learned rules, incorrect template matching (e.g. due to parse errors) and context mismatch contribute together 46% of the errors." ></td>
	<td class="line x" title="182:203	Context mismatches occur when the entailing template is matched in inappropriate contexts." ></td>
	<td class="line x" title="183:203	For example, slam Xattack X should not be applied when X is a ball, only when it is a person." ></td>
	<td class="line x" title="184:203	The rule-set net effect on system precision is better estimated by removing these errors and fixing the annotation errors, which yields 72% precision." ></td>
	<td class="line x" title="185:203	Binary DIRT Balanced Inclusion Correct 16 (70) 38 (91) Partial Template 27 (2665) 6 (81) Incorrect 157 (2584) 156 (787) Total 200 (5319) 200 (959) Table 1: Rule type distribution of a sample of 200 rules that extracted incorrect mentions." ></td>
	<td class="line x" title="186:203	The corresponding numbers of incorrect mentions extracted by the sampled rules is shown in parentheses." ></td>
	<td class="line x" title="187:203	Reason % mentions Incorrect Rule learned 39.0 Context mismatch 27.0 Match error 19.0 Annotation problem 15.0 Table 2: Distribution of reasons for false positives (incorrect argument extractions) by BInc at K=20." ></td>
	<td class="line x" title="188:203	Reason % mentions Rule not learned 61.5 Match error 25.0 Discourse analysis needed 12.0 Argument is predicative 1.5 Table 3: Distribution of reasons for false negatives (missed argument mentions) by BInc at K=20." ></td>
	<td class="line x" title="189:203	Table 3 presents the analysis of false negatives." ></td>
	<td class="line x" title="190:203	First, we note that 12% of the arguments cannot be extracted by rules alone, due to necessary discourse analysis." ></td>
	<td class="line x" title="191:203	Thus, a recall upper bound for entailment rules is 88%." ></td>
	<td class="line x" title="192:203	Many missed extractions are due to rules that were not learned (61.5%)." ></td>
	<td class="line x" title="193:203	However, 25% of the mentions were missed because of incorrect syntactic matching of correctly learned rules." ></td>
	<td class="line x" title="194:203	By assuming correct matches in these cases we isolate the recall of the rule-set (along with the seeds), which yields 39% recall." ></td>
	<td class="line x" title="195:203	6 Conclusions We presented two approaches for unsupervised acquisition of unary entailment rules from regular (non-comparable) corpora." ></td>
	<td class="line x" title="196:203	In the first approach, rules are directly learned based on distributional similarity measures." ></td>
	<td class="line x" title="197:203	The second approach derives unary rules from a given rule-base of binary rules." ></td>
	<td class="line x" title="198:203	Under the first approach we proposed a novel directional measure for scoring entailment rules, termed Balanced-Inclusion." ></td>
	<td class="line x" title="199:203	We tested the different approaches utilizing a standard IE test-set and compared them to binary rule learning." ></td>
	<td class="line x" title="200:203	Our results suggest the advantage of learning unary rules: (a) unary rule-bases perform 855 better than binary rules; (b) it is better to directly learn unary rules than to derive them from binary rule-bases." ></td>
	<td class="line x" title="201:203	In addition, the Balanced-Inclusion measure outperformed all other tested methods." ></td>
	<td class="line x" title="202:203	In future work, we plan to explore additional unary template structures and similarity scores, and to improve rule application utilizing context matching methods such as (Szpektor et al., 2008)." ></td>
	<td class="line x" title="203:203	Acknowledgements This work was partially supported by ISF grant 1095/05, the IST Programme of the European Community under the PASCAL Network of Excellence IST-2002-506778 and the NEGEV project (www.negev-initiative.org)." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1110
A Framework for Identifying Textual Redundancy
Thadani, Kapil;McKeown, Kathleen R.;"></td>
	<td class="line x" title="1:196	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 873880 Manchester, August 2008 A Framework for Identifying Textual Redundancy Kapil Thadani and Kathleen McKeown Department of Computer Science, Columbia University, New York, NY USA {kapil,kathy}@cs.columbia.edu Abstract The task of identifying redundant information in documents that are generated from multiple sources provides a significant challenge for summarization and QA systems." ></td>
	<td class="line x" title="2:196	Traditional clustering techniques detect redundancy at the sentential level and do not guarantee the preservation of all information within the document." ></td>
	<td class="line x" title="3:196	We discuss an algorithm that generates a novel graph-based representation for a document and then utilizes a set cover approximation algorithm to remove redundant text from it." ></td>
	<td class="line x" title="4:196	Our experiments show that this approach offers a significant performance advantage over clustering when evaluated over an annotated dataset." ></td>
	<td class="line x" title="5:196	1 Introduction This paper approaches the problem of identifying and reducing redundant information in documents that are generated from multiple sources." ></td>
	<td class="line x" title="6:196	This task is closely related to many well-studied problems in the field of natural language processing such as summarization and paraphrase recognition." ></td>
	<td class="line x" title="7:196	Systems that utilize data from multiple sources, such as question-answering and extractive summarization systems that operate on news data, usually include a component to remove redundant information from appearing in their generated output." ></td>
	<td class="line x" title="8:196	However, practical attempts at reducing redundancy in the output of these types of systems usually involve clustering the sentences of the generated output, picking a representative sentence from each cluster and discarding the rest." ></td>
	<td class="line x" title="9:196	Although this strategy would remove some redundant information, clustering approaches tuned for coarse c2008." ></td>
	<td class="line x" title="10:196	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="11:196	Some rights reserved." ></td>
	<td class="line x" title="12:196	matches could also remove non-redundant information whereas clustering approaches tuned for near-exact matches could end up removing very little repeated information." ></td>
	<td class="line x" title="13:196	This is simply a consequence of the fact that information can, and usually does, exist at the sub-sentential level and that clusters of sentences dont necessarily correspond to clusters of information." ></td>
	<td class="line x" title="14:196	In this paper, we discuss a framework for building a novel graph-based representation to detect redundancy within documents." ></td>
	<td class="line x" title="15:196	We identify redundancy at the sub-sentential level through pairwise alignment between the sentences of a document and use this to build a bipartite graph which enables us to keep track of redundant information across all sentences." ></td>
	<td class="line x" title="16:196	Common information between pairs of sentences, detected with the alignment algorithm, can be extrapolated to documentwide units of information using the graph structure." ></td>
	<td class="line x" title="17:196	Individual sentences that are encompassed by the information in the rest of the document can then be identified and removed efficiently by using a well-known greedy algorithm adapted for this representation." ></td>
	<td class="line x" title="18:196	2 Related Work The challenge of minimizing redundant information is commonly faced by IR engines and extractive summarization systems when generating their responses." ></td>
	<td class="line x" title="19:196	A well-known diversity-based reranking technique for these types of systems is MMR (Carbonell and Goldstein, 1998), which attempts to reduce redundancy by preferring sentences that differ from the sentences already selected for the summary." ></td>
	<td class="line x" title="20:196	However, this approach does not attempt to identify sub-sentential redundancy." ></td>
	<td class="line x" title="21:196	Alternative approaches to identifying redundancy use clustering at the sentence level (Lin and Hovy, 2001) to remove sentences that are largely repetitive; however, as noted earlier, this is not well-suited to the redundancy task." ></td>
	<td class="line x" title="22:196	The use of sen873 tence simplification in conjunction with clustering (Siddharthan et al., 2004) could help alleviate this problem by effectively clustering smaller units, but this issue cannot be avoided unless sentences are simplified to atomic elements of information." ></td>
	<td class="line x" title="23:196	Other research has introduced the notion of identifying concepts in the input text (Filatova and Hatzivassiloglou, 2004), using a set cover algorithm to attempt to include as many concepts as possible." ></td>
	<td class="line x" title="24:196	However, this approach uses tf-idf to approximate concepts and thus doesnt explicitly identify redundant text." ></td>
	<td class="line x" title="25:196	Our work draws on this approach but extends it to identify all detectable redundancies within a document set." ></td>
	<td class="line x" title="26:196	Another approach does identify small subsentential units of information within text called Basic Elements and uses these for evaluating summarizations (Hovy et al., 2006)." ></td>
	<td class="line x" title="27:196	Our approach, in contrast, does not make assumptions about the size or structure of redundant information since this is uncovered through alignments." ></td>
	<td class="line x" title="28:196	We thus require the use of an alignment algorithm to extract the common information between two pieces of text." ></td>
	<td class="line oc" title="29:196	This is related to the wellstudied problem of identifying paraphrases (Barzilay and Lee, 2003; Pang et al., 2003) and the more general variant of recognizing textual entailment, which explores whether information expressed in a hypothesis can be inferred from a given premise." ></td>
	<td class="line x" title="30:196	Entailment problems have also been approached with a wide variety of techniques, one of which is dependency tree alignment (Marsi et al., 2006), which we utilize as well to align segments of text while respecting syntax." ></td>
	<td class="line x" title="31:196	However, our definition of redundancy does not extend to include unidirectional entailment, and the alignment process is simply required to identify equivalent information." ></td>
	<td class="line x" title="32:196	3 Levels of Information In describing the redundancy task, we deal with multiple levels of semantic abstraction from the basic lexical form." ></td>
	<td class="line x" title="33:196	This section describes the terminology used in this paper and the graph-based representation that is central to our approach." ></td>
	<td class="line x" title="34:196	3.1 Terminology The following terms are used throughout this paper to refer to different aspects of a document." ></td>
	<td class="line x" title="35:196	Snippet: This is any span of text in the document and is a lexical realization of information." ></td>
	<td class="line x" title="36:196	While a snippet generally refers to a single sentence within a document, it can apply to multiple sentences or phrases within sentences." ></td>
	<td class="line x" title="37:196	Since redundancy will be reduced by removing whole snippets, a snippet can be defined as the smallest unit of text that can be dropped from a document for the purpose of reducing redundancy." ></td>
	<td class="line x" title="38:196	To illustrate the levels of information that we consider, consider the following set of short sentences as snippets." ></td>
	<td class="line x" title="39:196	Although this is a synthesized example to simplify presentation, sentences with this type of overlapping information occur frequently in the question-answering scenario over news in which our approach has been used." ></td>
	<td class="line x" title="40:196	x1: Whittington is an attorney." ></td>
	<td class="line x" title="41:196	x2: Cheney shot Whittington, a lawyer." ></td>
	<td class="line x" title="42:196	x3: Whittington, an attorney, was shot in Texas." ></td>
	<td class="line x" title="43:196	x4: Whittington was shot by Cheney while hunting quail." ></td>
	<td class="line x" title="44:196	x5: This happened during a quail hunt in Texas." ></td>
	<td class="line x" title="45:196	We can see that all the information in x1 is contained in both x2 and x3." ></td>
	<td class="line x" title="46:196	While no other snippet is completely subsumed by any single snippet, they can be made redundant given combinations of other snippets; for example, x4 is redundant given x2, x3 and x5." ></td>
	<td class="line x" title="47:196	In order to identify these combinations, we need to identify the elements of information within each snippet." ></td>
	<td class="line x" title="48:196	Concept: This refers to a basic unit of information within a document." ></td>
	<td class="line x" title="49:196	Concepts may be facts, opinions or details." ></td>
	<td class="line x" title="50:196	These are not necessarily sememes, which are atomic units of meaning, but simply units of information that are seen as atomic within the document." ></td>
	<td class="line x" title="51:196	We further restrict the definition of a concept to a unit of information seen in more than one snippet, since we are only interested in concepts which help in identifying redundancy." ></td>
	<td class="line x" title="52:196	Formally, a document can be defined as a set of S snippets X = {x1,,xS}, which is a literal representation of the document." ></td>
	<td class="line x" title="53:196	However, it can also be defined in terms of its information content." ></td>
	<td class="line x" title="54:196	We use Z ={z1,,zC}to represent the set of C concepts that cover all information appearing more than once in the document." ></td>
	<td class="line x" title="55:196	In the example above, we can identify five non-overlapping concepts: zA: Whittington was shot zB: Whittington is an attorney zC: The shooting occurred in Texas zD: It happened during a hunt for quail zE: Cheney was the shooter We use subscripts for snippet indices and superscripts for concept indices throughout this paper." ></td>
	<td class="line x" title="56:196	874 Nugget: This is a textual representation of a concept in a snippet and therefore expresses some information which is also expressed elsewhere in the document." ></td>
	<td class="line x" title="57:196	Different nuggets for a given concept may have unique lexico-syntactic realizations, as long as they all embody the same semantics." ></td>
	<td class="line x" title="58:196	With regard to the notation used above, nuggets can be represented by an SC matrix Y where each ycs denotes the fragment of text (if any) from the snippet xs that represents concept zc." ></td>
	<td class="line x" title="59:196	Since a concept itself has no unique textual realization, it can be simply represented by the combination of all its nuggets." ></td>
	<td class="line x" title="60:196	For instance, in the example shown above, concept zD is seen in both x4 and x5 in the form of two nuggets yD4 ( while hunting quail) and yD5 ( during a quail hunt), which are paraphrases." ></td>
	<td class="line x" title="61:196	The degree to which we can consider this and other types of lexical or syntactic differences between nuggets that have the same semantic identity depends on the alignment algorithm used." ></td>
	<td class="line x" title="62:196	Intersection: This is the common information between two snippets that can be obtained through their alignment." ></td>
	<td class="line x" title="63:196	For example, the intersection from the alignment between x2 and x4 consists of two fragments of text that express that Cheney shot Whittington (an active-voiced fragment from x2 and a passive-voiced fragment from x4)." ></td>
	<td class="line x" title="64:196	In general, aligning xi and xj produces an intersection vi,j which is simply a pair of aligned text fragments covering the set of concepts that xi and xj have in common." ></td>
	<td class="line x" title="65:196	However, these undivided segments of text may actually contain multiple nuggets from a document-wide perspective." ></td>
	<td class="line x" title="66:196	We assume that intersections can be decomposed into smaller intersections through further alignments with snippets or other intersections; this process is explained in Subsection 4.3." ></td>
	<td class="line x" title="67:196	3.2 Concept graph representation Figure 1 illustrates the example introduced in Subsection 3.1 as a network with intersections represented as edges between snippets." ></td>
	<td class="line x" title="68:196	This is the type of graph that would be built using pairwise alignments between all snippets." ></td>
	<td class="line x" title="69:196	Note that although some intersections such as v1,2 (between x1 and x2) and v3,5 express concepts directly, other intersections such as v2,3 and v2,4 are undivided combinations of concepts." ></td>
	<td class="line x" title="70:196	Since we cannot directly identify concepts and their nuggets, this graph is not immediately useful for reducing redundancy." ></td>
	<td class="line x" title="71:196	x1 B x2 ABE x3 ABC x4 ADE x5 CD B B AB AE A C D Figure 1: Graph representing pairwise alignments between the example snippets from Section 3." ></td>
	<td class="line x" title="72:196	For clarity, alphabetic labels like A represent concepts zA." ></td>
	<td class="line x" title="73:196	Node labels show concepts within snippets and edge labels indicate concepts seen in intersections." ></td>
	<td class="line x" title="74:196	x1 B x2 ABE x3 ABC x4 ADE x5 CD zAzB zC zD zE yB1 yA2 yB2 yE2 yA3 yB3 yC3 yA4 yD4 yE4 yC5 yD5 Figure 2: Structure of the equivalent concept graph for the example document illustrated in Figure 1." ></td>
	<td class="line x" title="75:196	Circular nodes xs represent snippets, large squares zc represent concepts and small squares ycs depict nuggets for each concept within a snippet." ></td>
	<td class="line x" title="76:196	Now, since the matrix Y describes the interaction of concepts with snippets, it can be viewed as an incidence matrix that defines a bipartite graph between snippets and concepts with nuggets representing the edges." ></td>
	<td class="line x" title="77:196	In this concept graph representation, each snippet can connect to any number of other snippets via a shared concept." ></td>
	<td class="line x" title="78:196	Since concepts serve to connect multiple snippets together, the concept graph can also be seen as a hypergraph, which is a generalization of a graph in which each edge may connect together multiple vertices." ></td>
	<td class="line x" title="79:196	875 Figure 2 illustrates the structure of the equivalent concept graph for the previous example." ></td>
	<td class="line x" title="80:196	This is simply the bipartite graph with the two types of nodes, namely snippets and concepts, represented using different symbols." ></td>
	<td class="line x" title="81:196	For clarity, nuggets are also depicted as nodes in the graph, thereby reducing edges to simple links indicating membership." ></td>
	<td class="line x" title="82:196	This representation identifies the redundancy between snippets in terms of non-overlapping concepts and is therefore more useful than the graph from Figure 1 for reducing redundancy." ></td>
	<td class="line x" title="83:196	4 Constructing the Concept Graph We now describe how a concept graph can be constructed from a document by using dependency tree alignment and leveraging the existing structure of the graph during construction." ></td>
	<td class="line x" title="84:196	4.1 Alignment of snippets In order to obtain the concept graph representation, the common information between each pair of snippets in the document must first be discovered by aligning all pairs of snippets with each other." ></td>
	<td class="line x" title="85:196	We make use of dependency parsing and alignment of dependency parse trees to obtain intersections between each pair of snippets, where each intersection may be a discontiguous span of text corresponding to an aligned subtree within each snippet." ></td>
	<td class="line x" title="86:196	In our experiments, dependency parsing is accomplished with Minipar (Lin, 1998) and alignment is done using a bottom-up tree alignment algorithm (Barzilay and McKeown, 2005) modified to account for the shallow semantic role labels produced by the parser." ></td>
	<td class="line x" title="87:196	The alignment implementation is not the focus of this work, however, and the framework described here could by applied using any alignment technique between segments of text in potentially any language." ></td>
	<td class="line x" title="88:196	As seen in Figure 1, the intersections that can be extracted solely by pairwise comparisons are not unique and may contain multiple concepts." ></td>
	<td class="line x" title="89:196	A truly information-preserving approach requires the explicit identification of concepts as in the concept graph from Figure 2, but efficiently converting the former into the latter poses a non-trivial challenge." ></td>
	<td class="line x" title="90:196	4.2 Extraction of irreducible concepts Our approach attempts to obtain a set of irreducible concepts such that each concept in this set cannot wholly or partially contain any other concept in the set (thereby conforming to the definition of a concept in Subsection 3.1)." ></td>
	<td class="line x" title="91:196	We attempt to build the concept graph and maintain irreducible concepts alongside each of the S(S1)/2 pairwise alignment steps." ></td>
	<td class="line x" title="92:196	Every intersection found by aligning a pair of snippets is assumed to represent some concept that these snippets share; it is then compared with existing concepts and is decomposed into smaller intersections if it overlaps partially with any one of them." ></td>
	<td class="line x" title="93:196	This implies a worst-case of C comparisons at each pairwise alignment step (2C if both fragments of an intersection are compared separately)." ></td>
	<td class="line x" title="94:196	However, this can be made more efficient by exploiting the structure of the graph." ></td>
	<td class="line x" title="95:196	A new intersection only has to be compared with concepts which might be affected by it and only affects the other snippets containing these concepts." ></td>
	<td class="line x" title="96:196	We can show that this leads to an algorithm that requires fewer than C comparisons, and additionally, that these comparisons can be performed efficiently." ></td>
	<td class="line x" title="97:196	Consider the definition of alignment along the lines of a mathematical relation." ></td>
	<td class="line x" title="98:196	We require snippet alignment to be an equivalence relation and it therefore must have the following properties." ></td>
	<td class="line x" title="99:196	Symmetry: If an intersection vi,j contains a concept zprime, then vj,i will also contain zprime." ></td>
	<td class="line x" title="100:196	This property allows only S(S 1)/2 alignments to suffice instead of the full S(S 1)." ></td>
	<td class="line x" title="101:196	Therefore, without loss of generality, we can specify that all alignments between xi and xj should have i < j. Transitivity: If intersections vi,j and vj,k both contain some concept zprime, then vi,k will also contain zprime." ></td>
	<td class="line x" title="102:196	This property leads to an interesting consequence." ></td>
	<td class="line x" title="103:196	Assuming we perform alignments in order (initially aligning x1 and x2 and iterating for j within each i), we observe that xi has been aligned with snippets{x1,,xj1}and, for any i > 1, snippets{x1,,xi1}were aligned with all snippets {x1,,xS}." ></td>
	<td class="line x" title="104:196	Since i < j, this implies that xi was directly aligned with snippets {x1,,xi1} which in turn were each aligned with all S snippets." ></td>
	<td class="line x" title="105:196	Therefore, due to the property of transitivity, all concepts contained in a new intersection vi,j that also exist in the partlyconstructed graph would already be directly associated with xi." ></td>
	<td class="line x" title="106:196	Note that this does not hold for xj as well, since xj has not been aligned with {xi+1,,xj1}; therefore, it may not have encountered all relevant concepts." ></td>
	<td class="line x" title="107:196	This implies that for any i and j, all concepts that might be affected by a new intersection vi,j 876 have already been uncovered in xi and thus vi,j only needs to be compared to these concepts." ></td>
	<td class="line x" title="108:196	4.3 Comparisons after alignment For every new intersection vi,j produced by an alignment between xi and xj, the algorithm compares it (specifically, the fragment from xi) with each existing nugget yki for each concept zk already seen in xi." ></td>
	<td class="line x" title="109:196	Checking for the following cases ensures that the graph structure contains only irreducible concepts for all the alignments seen: 1." ></td>
	<td class="line x" title="110:196	If vi,j doesnt overlap with any current nugget from xi, it becomes a new concept that links to xi and xj." ></td>
	<td class="line x" title="111:196	In our example, the first intersection v1,2 contains Whittington  an attorney from x1 and  Whittington, a lawyer from x2; this becomes a new concept zB since x1 has no other nuggets." ></td>
	<td class="line x" title="112:196	2." ></td>
	<td class="line x" title="113:196	If vi,j overlaps completely with a nugget yki , then xj must also be linked to concept zk." ></td>
	<td class="line x" title="114:196	For example, x1s fragment in the second intersection v1,3 is also Whittington  an attorney, so x3 must also link to zB." ></td>
	<td class="line x" title="115:196	3." ></td>
	<td class="line x" title="116:196	If vi,j subsumes yki , it is split up and the nonoverlapping portion is rechecked against existing nuggets recursively." ></td>
	<td class="line x" title="117:196	For example, x2s fragment in the intersection v2,3 is  shot Whittington, a lawyer, part of which overlaps with yB2 , so this intersection is divided up and the part representing  shot Whittington  becomes a new concept zA." ></td>
	<td class="line x" title="118:196	4." ></td>
	<td class="line x" title="119:196	If, on the other hand, yki subsumes vi,j, the concept zk is itself split up along with all nuggets that it links to, utilizing the present structure of the graph." ></td>
	<td class="line x" title="120:196	When comparing intersections, we can restrict the decomposition of nuggets to prevent the creation of overly-granular concepts." ></td>
	<td class="line x" title="121:196	For instance, we can filter out intersections containing only isolated named-entities or syntactic artifacts like determiners since they contain no information by themselves." ></td>
	<td class="line x" title="122:196	We can also prevent verbs and their arguments from being split apart using information from a snippets dependency parse, if available." ></td>
	<td class="line x" title="123:196	4.4 Efficiency of the algorithm Instead of C additional comparisons in the worst case after each pairwise snippet alignment, we need no more comparisons in the worst case than the maximum number of concepts that can exist in a single snippet." ></td>
	<td class="line x" title="124:196	Since this value grows no faster than C as S increases, this is a significant improvement." ></td>
	<td class="line x" title="125:196	Other factors, such as the overhead required to split up concepts, remain unchanged." ></td>
	<td class="line x" title="126:196	Furthermore, since all the additional comparisons are carried out between nuggets of the same snippet, we dont need to perform any further alignment among nuggets or concepts." ></td>
	<td class="line x" title="127:196	Alignments are expensive; each is O(n1n2) where n1 and n2 are the number of words in the two segments of text being aligned (if dependency tree alignment is used) along with an overhead for checking word similarity." ></td>
	<td class="line x" title="128:196	However, since we now only need to compare text from the same snippet, the comparison can be performed in linear time by simply comparing spans of word indices, thereby also eliminating the overhead for comparing words." ></td>
	<td class="line x" title="129:196	5 Decreasing redundancy The concept graph can now be applied to the task of reducing redundancy in the document by dropping snippets which contain no information that is not already present in the rest of the document." ></td>
	<td class="line x" title="130:196	5.1 Reduction to set cover Every snippet xs in a document can be represented as a set of concepts{zc : ycsY}." ></td>
	<td class="line x" title="131:196	Since concepts are defined as information that is seen in more than one snippet as per the definition in Subsection 3.1, representing snippets as sets of concepts will overlook any unique information present in a snippet." ></td>
	<td class="line x" title="132:196	Without loss of generality, we can add any such unique information in the form of an artificial concept for each snippet to Z so that snippets can be completely represented as sets of concepts from Z. Note that the union of snippets uniontextSs=1 xs equals Z. Reducing redundancy in the document while preserving all information requires us to identify the most snippets whose entire informational content is covered by the rest of the snippets in the document, thereby targeting them for removal." ></td>
	<td class="line x" title="133:196	Since we express informational content in concepts, this problem reduces to the task of finding the smallest group of snippets that together cover all the concepts in the document, i.e. we need to find the smallest subset Xprime  X such that, if Xprime contains R snippets xprimer, the union of these snippetsuniontext R r=1 x primer also equals Z. Therefore, every concept in a snippet from XXprime also exists in at least one snippet from Xprime and no concept from Z is lost." ></td>
	<td class="line x" title="134:196	This formulation of the problem is the classic 877 set cover problem, which seeks to find the smallest possible group of subsets of a universe that covers all the other subsets." ></td>
	<td class="line x" title="135:196	A more general variant of this problem is weighted set cover in which the subsets have weights to be maximized or costs to be minimized." ></td>
	<td class="line x" title="136:196	While this problem is known to be NP-hard, there exists a straightforward local maximization approach (Hochbaum, 1997) which runs in polynomial time and is proven to give solutions within a known bound of the optimal solution." ></td>
	<td class="line x" title="137:196	This greedy approximation algorithm can be adapted to our representation." ></td>
	<td class="line x" title="138:196	5.2 Selecting non-redundant snippets The algorithm selects a snippet xr to the subset Xprime such that information content of Xxr is maximized." ></td>
	<td class="line x" title="139:196	In general, this implies that the snippet with the highest degree over uncovered concepts must be selected at each iteration." ></td>
	<td class="line x" title="140:196	Other measures such as snippet length, fluency, or rank in an ordered list can be included in a weight measure in order to break ties and introduce a preference for shorter, more fluent, or higher-ranked snippets." ></td>
	<td class="line x" title="141:196	Consider the example from Section 3." ></td>
	<td class="line x" title="142:196	The candidates for selection are x2, x3 and x4 since they contain the most uncovered concepts." ></td>
	<td class="line x" title="143:196	If x2 is selected, its concepts zA, zB and zE are covered." ></td>
	<td class="line x" title="144:196	At this stage, x5 contains two uncovered concepts while x3 and x4 contain just one each." ></td>
	<td class="line x" title="145:196	Thus, x5 is selected next and its concepts zC and zD are covered." ></td>
	<td class="line x" title="146:196	Since no uncovered concepts remain, all snippets which havent been selected are redundant." ></td>
	<td class="line x" title="147:196	This solution, which is shown in Figure 3, selects the following text to cover all the snippets: x2: Cheney shot Whittington, a lawyer." ></td>
	<td class="line x" title="148:196	x5: This happened during a quail hunt in Texas." ></td>
	<td class="line x" title="149:196	Other solutions are also possible depending on the factors involved in choosing the snippet to be selected at each iteration." ></td>
	<td class="line x" title="150:196	For example, the algorithm might choose to select x3 first instead of x2, thereby yielding the following solution: x3: Whittington, an attorney, was shot in Texas." ></td>
	<td class="line x" title="151:196	x4: Whittington was shot by Cheney while hunting quail." ></td>
	<td class="line x" title="152:196	6 Experiments To evaluate the effectiveness of this framework empirically, we ran experiments over documents containing annotations corresponding to concepts within the document." ></td>
	<td class="line x" title="153:196	We also defined a metric x1 B x2 ABE x3 ABC x4 ADE x5 CD zAzB zC zD zE yB1 yA2 yB2 yE2 yA3 yB3 yC3 yA4 yD4 yE4 yC5 yD5 Figure 3: Pruned version of the concept graph example shown in Figure 2, illustrating the outcome of removing redundant snippets." ></td>
	<td class="line x" title="154:196	for comparing any concept graph over a document to a gold-standard concept graph." ></td>
	<td class="line x" title="155:196	This was used to compare the concept graphs created by our approach to perturbed versions of the gold-standard graphs and graphs created by clustering." ></td>
	<td class="line x" title="156:196	6.1 Dataset Due to the scarcity of available annotated datasets suitable for evaluating redundancy, we utilized the pyramid dataset from DUC 2005 (Nenkova et al., 2007) which was created from 20 articles for the purpose of summarization evaluation." ></td>
	<td class="line x" title="157:196	Each pyramid document is a hierarchical representation of 7 summaries of the orginal news article." ></td>
	<td class="line x" title="158:196	These summaries have been annotated to identify the individual semantic content units or SCUs where each SCU represents a certain fact, observation or piece of information in the summary." ></td>
	<td class="line x" title="159:196	A sentence fragment representing an occurrence of an SCU in a summary is a contributor to the SCU." ></td>
	<td class="line x" title="160:196	The pyramid construction for a group of summaries of the same article mirrors the concept graph representation described in Subsection 3.2." ></td>
	<td class="line x" title="161:196	SCUs with more than two contributors are similar in definition to concepts while their contributors fill the role of nuggets." ></td>
	<td class="line x" title="162:196	Using this analogy, each dataset consists of a combination of the seven summaries in a single pyramid document; the 20 pyramid documents therefore yield 20 datasets." ></td>
	<td class="line x" title="163:196	6.2 Evaluation metrics The evaluation task requires us to compare the concept graph generated by our algorithm to the ideal 878 x1 x2 x3 x4 x1 x2 x3 x4 Concepts SCUs (merge) (split) Lalg Lpyr Figure 4: The bipartite graph on the left shows snippets xs linked to concepts produced automatically; the one on the right shows the same snippets linked to SCUs from annotated data." ></td>
	<td class="line x" title="164:196	Dashed lines indicate mappings between concepts and SCUs." ></td>
	<td class="line x" title="165:196	concept graph extracted from the pyramid document annotations." ></td>
	<td class="line x" title="166:196	Standard metrics do not apply easily to the problem of comparing bipartite graphs, so we define a novel metric modeled on the well-known IR measures of precision, recall and F-measure." ></td>
	<td class="line x" title="167:196	Figure 4 illustrates the elements involved in the evaluation task." ></td>
	<td class="line x" title="168:196	We define the metrics of precision, recall and Fmeasure over the links between snippets and concepts." ></td>
	<td class="line x" title="169:196	Assuming we have a mapping between generated concepts and gold-standard SCUs, we can judge whether each link is correct." ></td>
	<td class="line x" title="170:196	Let each single link between a snippet and a concept have an associated weight of 1 by default and let L indicate a set of such links." ></td>
	<td class="line x" title="171:196	We use Lalg and Lpyr to distinguish between the sets of links generated by the algorithm and retrieved from the annotations respectively." ></td>
	<td class="line x" title="172:196	Precision and recall are defined as follows while F-measure retains its traditional definition as their harmonic mean." ></td>
	<td class="line x" title="173:196	Precision = Sum of weights in LalgLpyrSum of weights in L alg Recall = Sum of weights in LalgLpyrSum of weights in L pyr To determine a mapping between concepts and SCUs, we identify every concept and SCU pair, say zc and zs, which has one or more snippets in common and, for each snippet xi that they have in common, we find the longest common subsequence between their nuggets yci and ysi to obtain the following score which ranges from 0 to 1." ></td>
	<td class="line x" title="174:196	LCS score = length(LCS)min(length(yc i),length(ysi)) Measure Random Clustering Concepts Precision 0.0510 0.2961 0.4496 Recall 0.0515 0.1162 0.3266 F1 score 0.0512 0.1669 0.3783 Table 1: Summary of the evaluation metrics averaged over all 20 pyramid documents when m=0.5 This score is compared with a user-defined mapping threshold m to determine if the concept and SCU are sufficiently similar." ></td>
	<td class="line x" title="175:196	In order to avoid biasing the metric by permitting multiple mappings per concept, we adjust for merges or 1 : N mappings by cloning the concept and creating N 1:1 mappings in its place." ></td>
	<td class="line x" title="176:196	We then adjust for splits or N :1 mappings by dividing the weight of each of the links connected to a participating concept by N. Due to this normalization, the metrics are observed to be stable over variations in m. 6.3 Baselines We compare the performance of the algorithm against two baselines." ></td>
	<td class="line x" title="177:196	The first approach involves a random concept assignment scheme to build artificial concept graphs using the distributional properties of the gold-standard concept graphs." ></td>
	<td class="line x" title="178:196	The number of concepts C and the number of snippets that each concept links to is determined by sampling from distributions over these properties derived from the statistics of the actual SCU graph for that document." ></td>
	<td class="line x" title="179:196	For evaluation, these artificial concepts are randomly mapped to SCUs using m to control the likelihood of mapping." ></td>
	<td class="line x" title="180:196	The best scores from 100 evaluation runs were considered." ></td>
	<td class="line x" title="181:196	The second baseline used for comparison is a clustering algorithm, since clustering is the most common approach to dealing with redundancy." ></td>
	<td class="line x" title="182:196	For this purpose, we use a recursive spectral partitioning algorithm, a variant of spectral clustering (Shi and Malik, 2000) which obtains an average Vmeasure (Rosenberg and Hirschberg, 2007) of 0.93 when clustering just pyramid contributors labeled by their SCUs." ></td>
	<td class="line x" title="183:196	The algorithm requires a parameter that controls the homogeneity of each cluster; we run it over the entire range of settings of this parameter." ></td>
	<td class="line x" title="184:196	We consider the clustering that maximizes F-measure in order to avoid any uncertainty regarding optimal parameter selection and to implicitly compare our algorithm against an entire hierarchy of possible clusterings." ></td>
	<td class="line x" title="185:196	879 6.4 Results Table 1 shows the F1 scores over evaluation runs using the random concept assignment, clustering and concept graph techniques." ></td>
	<td class="line x" title="186:196	These results are obtained at a mapping threshold of m = 0.5, which implies that we consider a mapping between a concept and an SCU if their nuggets over common sentences share more than 50% of their words on average." ></td>
	<td class="line x" title="187:196	The results do not vary significantly at different settings of m. We observe that the concepts extracted by our graph-based approach perform significantly better than the best-performing clustering configuration." ></td>
	<td class="line x" title="188:196	Despite a fairly limited alignment approach that doesnt use synonyms or semantic analysis, the concept graph outperforms the baselines by nearly an order of magnitude on each document." ></td>
	<td class="line x" title="189:196	This validates our initial hypothesis that clustering approaches are not suitable for tackling the redundancy problem at the sub-sentential level." ></td>
	<td class="line x" title="190:196	7 Conclusions and Future Work We have described a graph-based algorithm for identifying redundancy at the sub-snippet level and shown that it outperforms clustering methods that are traditionally applied to the redundancy task." ></td>
	<td class="line x" title="191:196	Though the algorithm identifies redundancy at the sub-snippet level, redundancy can be decreased by dropping only entirely redundant snippets." ></td>
	<td class="line x" title="192:196	We hope to be able to overcome this limitation by extending this information-preserving approach to the synthesis of new non-redundant snippets which minimize redundant content in the document." ></td>
	<td class="line x" title="193:196	In addition, this work currently assumes that redundancy is bidirectional; however, we intend to also address the case of unidirectional redundancy by considering entailment recognition approaches." ></td>
	<td class="line x" title="194:196	Acknowledgements We are grateful to Andrew Rosenberg, David Elson, Mayank Lahiri and the anonymous reviewers for their useful feedback." ></td>
	<td class="line x" title="195:196	This material is based upon work supported by the Defense Advanced Research Projects Agency under Contract No." ></td>
	<td class="line x" title="196:196	HR0011-06-C-0023." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I08-1070
Computing Paraphrasability of Syntactic Variants Using Web Snippets
Fujita, Atsushi;Sato, Satoshi;"></td>
	<td class="line x" title="1:198	Computing Paraphrasability of Syntactic Variants Using Web Snippets Atsushi Fujita Satoshi Sato Graduate School of Engineering, Nagoya University {fujita,ssato}@nuee.nagoya-u.ac.jp Abstract In a broad range of natural language processing tasks, large-scale knowledge-base of paraphrases is anticipated to improve their performance." ></td>
	<td class="line x" title="2:198	The key issue in creating such a resource is to establish a practical method of computing semantic equivalence and syntactic substitutability, i.e., paraphrasability, between given pair of expressions." ></td>
	<td class="line x" title="3:198	This paper addresses the issues of computing paraphrasability, focusing on syntactic variants of predicate phrases." ></td>
	<td class="line x" title="4:198	Our model estimates paraphrasability based on traditional distributional similarity measures, where the Web snippets are used to overcome the data sparseness problem in handling predicate phrases." ></td>
	<td class="line x" title="5:198	Several feature sets are evaluated through empirical experiments." ></td>
	<td class="line x" title="6:198	1 Introduction One of the common characteristics of human languages is that the same concept can be expressed by various linguistic expressions." ></td>
	<td class="line x" title="7:198	Such linguistic variations are called paraphrases." ></td>
	<td class="line x" title="8:198	Handling paraphrases is one of the key issues in a broad range of natural language processing (NLP) tasks." ></td>
	<td class="line x" title="9:198	In information retrieval, information extraction, and question answering, technology of recognizing if or not the given pair of expressions are paraphrases is desired to gain a higher coverage." ></td>
	<td class="line x" title="10:198	On the other hand, a system which generates paraphrases for given expressions is useful for text-transcoding tasks, such as machine translation and summarization, as well as beneficial to human, for instance, in text-to-speech, text simplification, and writing assistance." ></td>
	<td class="line x" title="11:198	Paraphrase phenomena can roughly be divided into two groups according to their compositionality." ></td>
	<td class="line x" title="12:198	Examples in (1) exhibit a degree of compositionality, while each example in (2) is composed of totally different lexical items." ></td>
	<td class="line x" title="13:198	(1) a. be in our favor  be favorable for us b. show a sharp decrease  decrease sharply (Fujita et al., 2007) (2) a. burst into tears  cried b. comfort  console (Barzilay and McKeown, 2001) A number of studies have been carried out on both compositional (morpho-syntactic) and noncompositional (lexical and idiomatic) paraphrases (see Section 2)." ></td>
	<td class="line x" title="14:198	In most research, paraphrases have been represented with the similar templates, such as shownin(3)and(4)." ></td>
	<td class="line x" title="15:198	(3) a. N 1 VN 2  N 1 s V -ing of N 2 b. N 1 VN 2  N 2 be V -en by N 1 (Harris, 1957) (4) a. X wrote Y  X is the author of Y b. X solves Y  X deals with Y (Lin and Pantel, 2001) The weakness of these templates is that they should be applied only in some contexts." ></td>
	<td class="line x" title="16:198	In other words, the lack of applicability conditions for slot fillers may lead incorrect paraphrases." ></td>
	<td class="line x" title="17:198	One way to specify the applicability condition is to enumerate correct slot fillers." ></td>
	<td class="line x" title="18:198	For example, Pantel et al.(2007) have harvested instances for the given paraphrase templates based on the co-occurrence statistics of slot fillers and lexicalized part of templates (e.g. deal with in (4b))." ></td>
	<td class="line x" title="20:198	Yet, there is no method which assesses semantic equivalence and syntactic substitutability of resultant pairs of expressions." ></td>
	<td class="line x" title="21:198	537 In this paper, we propose a method of directly computing semantic equivalence and syntactic substitutability, i.e., paraphrasability, particularly focusing on automatically generated compositional paraphrases (henceforth, syntactic variants) of predicate phrases." ></td>
	<td class="line x" title="22:198	While previous studies have mainly targeted at words or canned phrases, we treat predicate phrases having a bit more complex structures." ></td>
	<td class="line x" title="23:198	This paper addresses two issues in handling phrases." ></td>
	<td class="line x" title="24:198	The first is feature engineering." ></td>
	<td class="line x" title="25:198	Generally speaking, phrases appear less frequently than single words." ></td>
	<td class="line x" title="26:198	This implies that we can obtain only a small amount of information about phrases." ></td>
	<td class="line x" title="27:198	Toovercome the data sparseness problem, we investigate if the Web snippet can be used as a dense corpus for given phrases." ></td>
	<td class="line x" title="28:198	The second is the measurement of paraphrasability." ></td>
	<td class="line x" title="29:198	We assess how well the traditional distributional similarity measures approximate the paraphrasability of predicate phrases." ></td>
	<td class="line x" title="30:198	2 Related work 2.1 Representation of paraphrases Several types of compositional paraphrases, such as passivization and nominalization, have been represented with some grammar formalisms, such as transformational generative grammar (Harris, 1957) and synchronous tree adjoining grammar (Dras, 1999)." ></td>
	<td class="line x" title="31:198	These grammars, however, lack the information of applicability conditions." ></td>
	<td class="line x" title="32:198	Word association within phrases has been an attractive topic." ></td>
	<td class="line x" title="33:198	Meaning-Text Theory (MTT) is a framework which takes into account several types of lexical dependencies in handling paraphrases (Melcuk and Polgu`ere, 1987)." ></td>
	<td class="line x" title="34:198	A bottleneck of MTT is that a huge amount of lexical knowledge is required to represent various relationships between lexical items." ></td>
	<td class="line x" title="35:198	Jacquemin (1999) has represented the syntagmatic and paradigmatic correspondences between paraphrases with context-free transformation rules and morphological and/or semantic relations between lexical items, targeting at syntactic variants of technical terms that are typically noun phrases consisting of more than one word." ></td>
	<td class="line x" title="36:198	We have proposed a framework of generating syntactic variants of predicate phrases (Fujita et al., 2007)." ></td>
	<td class="line x" title="37:198	Following the previous work, we have been developing three sorts of resources for Japanese." ></td>
	<td class="line x" title="38:198	2.2 Acquiring paraphrase rules Since the late 1990s, the task of automatic acquisition of paraphrase rules has drawn the attention of an increasing number of researchers." ></td>
	<td class="line x" title="39:198	Although most of the proposed methods do not explicitly eliminate compositional paraphrases, their output tends to be non-compositional paraphrase." ></td>
	<td class="line x" title="40:198	Previous approaches tothis task are two-fold." ></td>
	<td class="line x" title="41:198	The first group espouses the distributional hypothesis (Harris, 1968)." ></td>
	<td class="line x" title="42:198	Among a number of models based on this hypothesis, two algorithms are referred to as the state-of-the-art." ></td>
	<td class="line x" title="43:198	DIRT (Lin and Pantel, 2001) collects paraphrase rules consisting of a pair of paths between two nominal slots based on point-wise mutual information." ></td>
	<td class="line x" title="44:198	TEASE(Szpektor et al., 2004) discovers binary relation templates from the Web based on sets of representative entities for given binary relation templates." ></td>
	<td class="line x" title="45:198	These systems often output directional rules such as exemplified in (5)." ></td>
	<td class="line x" title="46:198	(5) a. X is charged by Y  Y announced the arrest of X b. X prevent Y  X lower the risk of Y They are actually called inference/entailment rules, and paraphrase is defined as bidirectional inference/entailment relation 1 . While the similarity score in DIRT is symmetric for given pair of paths, the algorithm of TEASE considers the direction." ></td>
	<td class="line oc" title="47:198	The other utilizes a sort of parallel texts, such as multiple translation of the same text (Barzilay and McKeown, 2001; Pang et al., 2003), corresponding articles from multiple news sources (Barzilay and Lee, 2003; Dolan et al., 2004), and bilingual corpus (Wu and Zhou, 2003; Bannard and Callison-Burch, 2005)." ></td>
	<td class="line n" title="48:198	This approach is, however, limited by the difficulty of obtaining parallel/comparable corpora." ></td>
	<td class="line x" title="49:198	2.3 Acquiring paraphrase instances As reviewed in Section 1, paraphrase rules generate incorrect paraphrases, because their applicability conditions are not specified." ></td>
	<td class="line x" title="50:198	To avoid the drawback, several linguistic clues, such as fine-grained classification of named entities and coordinated sentences, have been utilized (Sekine, 2005; Torisawa, 2006)." ></td>
	<td class="line x" title="51:198	Although these clues restrict phenomena to those appearing in particular domain or those describing coordinated events, they have enabled us to collect 1 See http://nlp.cs.nyu.edu/WTEP/ 538 paraphrases accurately." ></td>
	<td class="line x" title="52:198	The notion of Inferential Selectional Preference (ISP) has been introduced by Pantel et al.(2007)." ></td>
	<td class="line x" title="54:198	ISP can capture more general phenomena than above two; however, it lacks abilities to distinguish antonym relations." ></td>
	<td class="line x" title="55:198	2.4 Computing semantic equivalence Semantic equivalence between given pair of expressions has so far been estimated under the distributional hypothesis (Harris, 1968)." ></td>
	<td class="line x" title="56:198	Geffet and Dagan (2005) have extended it to the distributional inclusion hypothesis for recognizing the direction of lexical entailment." ></td>
	<td class="line x" title="57:198	Weeds et al.(2005), on the other hand, have pointed out the limitations of lexical similarity and syntactic transformation, and have proposed to directly compute the distributional similarity of pair of sub-parses based on the distributions of their modifiers and parents." ></td>
	<td class="line x" title="59:198	We think it is worth examining if the Web can be used as the source for extracting features of phrases." ></td>
	<td class="line x" title="60:198	3 Computing paraphrasability between predicate phrases using Web snippets We define the concept ofparaphrasability asfollows: A grammatical phrase s is paraphrasable withanother phrase t,ifft satisfies the following three:  t is grammatical  t holds if s holds  t is substitutable for s in some context Most previous studies on acquiring paraphrase rules have evaluated resultant pairs from only the second viewpoint, i.e., semantic equivalence." ></td>
	<td class="line x" title="61:198	Additionally, we assume that one of a pair (t) of syntactic variants is automatically generated from the other (s)." ></td>
	<td class="line x" title="62:198	Thus, grammaticality of t should also be assessed." ></td>
	<td class="line x" title="63:198	We also take into account the syntactic substitutability, because head-words of syntactic variants sometimes have different syntactic categories." ></td>
	<td class="line x" title="64:198	Given a pair of predicate phrases, we compute their paraphrasability in the following procedure: Step 1." ></td>
	<td class="line x" title="65:198	Retrieve Web snippets for each phrase." ></td>
	<td class="line x" title="66:198	Step 2." ></td>
	<td class="line x" title="67:198	Extract features for each phrase." ></td>
	<td class="line x" title="68:198	Step 3." ></td>
	<td class="line x" title="69:198	Compute their paraphrasability as distributional similarity between their features." ></td>
	<td class="line x" title="70:198	The rest of this section elaborates on each step in turn, taking Japanese as the target language." ></td>
	<td class="line x" title="71:198	3.1 Retrieving Web snippets In general, phrases appear less frequently than single words." ></td>
	<td class="line x" title="72:198	This raises a crucial problem in computing paraphrasability of phrases, i.e., the sparseness of features for given phrases." ></td>
	<td class="line x" title="73:198	One possible way to overcome the problem is to take back-off statistics assuming the independence between constituent words (Torisawa, 2006; Pantel et al., 2007)." ></td>
	<td class="line x" title="74:198	This approach, however, has a risk of involving noises due to ambiguity of words." ></td>
	<td class="line x" title="75:198	We take another approach, which utilizes the Web as a source of examples instead of a limited size of corpus." ></td>
	<td class="line x" title="76:198	Foreachof the source andtarget phrases, we retrieve snippets via the Yahoo API 2 . The number of snippets is set to 500." ></td>
	<td class="line x" title="77:198	3.2 Extracting features The second step extracts the features for each phrase from Web snippets." ></td>
	<td class="line x" title="78:198	We have some options for feature set, feature weighting, and snippet collection." ></td>
	<td class="line x" title="79:198	Feature sets To assess a given pair of phrases against the definition of paraphrasability, the following three sets of features are examined." ></td>
	<td class="line x" title="80:198	HITS: A phrase must appear in the Web if it is grammatical." ></td>
	<td class="line x" title="81:198	The more frequently a phrase appears, the more likely it is grammatical." ></td>
	<td class="line x" title="82:198	BOW: A pair of phrases are likely to be semantically similar, if the distributions of words surrounding the phrases are similar." ></td>
	<td class="line x" title="83:198	MOD: A pair of phrases are likely to be substitutable with each other, if they share a number of instances of modifiers and modifiees." ></td>
	<td class="line x" title="84:198	To extract BOW features from sentences including the given phrase within Web snippets, a morphological analyzer MeCab 3 was firstly used; however, it resulted wrong POS tags for unknown words, and hurt statistics." ></td>
	<td class="line x" title="85:198	Thus, finally ChaSen 4 is used." ></td>
	<td class="line x" title="86:198	To collect MOD features, a dependency parser CaboCha 5 is used." ></td>
	<td class="line x" title="87:198	Figure 1 depicts an example of extracting MOD features from a sentence within Web snippet." ></td>
	<td class="line x" title="88:198	A feature is generated from a bunsetsu, the Japanese base-chunk, which is either mod2 http://developer.yahoo.co.jp/search/ 3 http://mecab.sourceforge.net/ 4 http://chasen.naist.jp/hiki/ChaSen/ 5 http://chasen.org/taku/software/cabocha/ 539 kuwashikushiku jikken-kekka-nojikken-kekka-no saigen-sei-oaigen-sei-o kenshou-suruhou-suru yotei-dateikare-nokare-no Features Sentence within snippet (dependency tree) Modifiee/D: yoteiModifiee/D: t i Modifier/D: kuwashiiModifier/D: shii Modifier/D: kare_noModifier/ : kare_no (plan) (in detail) (his) Given phrase (I am) planning to verify the reproducibility of his experimental result in detail." ></td>
	<td class="line x" title="89:198	Figure 1: An example of MOD feature extraction." ></td>
	<td class="line x" title="90:198	An oval in the dependency tree denotes a bunsetsu." ></td>
	<td class="line x" title="91:198	ifier or modifiee of the given phrase." ></td>
	<td class="line x" title="92:198	Each feature is composed of three or more elements: (i) modifier or modifiee, (ii) dependency relation types (direct dependency, appositive, or parallel, c.f., RASP and MINIPAR), (iii) base form of the head-word, and (iv) case marker following noun, auxiliary verb and verbal suffixes if they appear." ></td>
	<td class="line x" title="93:198	The last feature is employed to distinguish the subtle difference of meaning of predicate phrases, such as voice, tense, aspect, and modality." ></td>
	<td class="line x" title="94:198	While Lin and Pantel (2001) have calculated similarities of paths based on slot fillers of subject and object slots, MOD targets at sub-trees and utilizes any modifiers and modifiees." ></td>
	<td class="line x" title="95:198	Feature weighting Geffet and Dagan (2004) have reported on that the better quality of feature vector (weighting function) leads better results." ></td>
	<td class="line x" title="96:198	So far, several weighting functions have been proposed, such as point-wise mutual information (Lin and Pantel, 2001) and Relative Feature Focus (Geffet and Dagan, 2004)." ></td>
	<td class="line x" title="97:198	While these functions compute weights using a small corpus for merely re-ranking samples, we are developing a measure that assesses the paraphrasability of arbitrary pair of phrases, where a more robust weighting function is necessary." ></td>
	<td class="line x" title="98:198	Therefore we directly use frequencies of features within Web snippets as weight." ></td>
	<td class="line x" title="99:198	Normalization will be done when the paraphrasability is computed (Section 3.3)." ></td>
	<td class="line x" title="100:198	Source-focused feature extraction Independent collection of Web snippets for each phrase of a given pair might yield no intersection of feature sets even if they have the same meaning." ></td>
	<td class="line x" title="101:198	To obtain more reliable feature sets, we retrieve Web snippets by querying the phrase AND the anchor of the source phrase." ></td>
	<td class="line x" title="102:198	The anchored version of Web snippets is retrieved in the following steps: Step 2-1." ></td>
	<td class="line x" title="103:198	Determine the anchor using Web snippets for the given source phrase." ></td>
	<td class="line x" title="104:198	We regarded a noun which most frequently modifies the source phrase asits anchor." ></td>
	<td class="line x" title="105:198	Examples of source phrases and their anchors are shown in (6)." ></td>
	<td class="line x" title="106:198	Step 2-2." ></td>
	<td class="line x" title="107:198	Retrieve Web snippets by querying the anchor for the source phrase AND each of source and target phrases, respectively." ></td>
	<td class="line x" title="108:198	Step 2-3." ></td>
	<td class="line x" title="109:198	Extract features for HITS, BOW, MOD." ></td>
	<td class="line x" title="110:198	Those sets are referred to as Anc., while the normal versions are referred to as Nor.." ></td>
	<td class="line x" title="111:198	(6) a. emi:o:ukaberu  manmen (be smiling  from ear to ear) b. doriburu:de:kake:agaru  saido (overlap by dribbling  side) c. yoi:sutaato:o:kiru  saisaki (make a good start  good sign) 3.3 Computing paraphrasability Paraphrasability is finally computed by two conventional distributional similarity measures." ></td>
	<td class="line x" title="112:198	The first is the measure proposed in (Lin and Pantel, 2001): Par Lin (st)= summationtext fF s F t (w(s,f)+w(t,f)) summationtext fF s w(s,f)+ summationtext fF t w(t,f) , where F s and F t denote feature sets for s and t,respectively." ></td>
	<td class="line x" title="113:198	w(x,f) stands for the weight (frequency in our experiment) of f in F x . While Par Lin is symmetric, it has been argued that itisimportant todetermine thedirection ofparaphrase." ></td>
	<td class="line x" title="114:198	As an asymmetric measure, we examine skew divergence defined by the following equation (Lee, 1999): d skew (t,s)=D (P s bardblP t +(1 )P s ), where P x denotes a probability distribution estimated 6 from a feature set F x .HowwellP t approximates P s is calculated based on the KL divergence, D. The parameter  is set to 0.99, following tradition, because the optimization of  is difficult." ></td>
	<td class="line x" title="115:198	To take consistent measurements, we define the paraphrasability score Par skew as follows: Par skew (st)=exp(d skew (t,s))." ></td>
	<td class="line x" title="116:198	6 We estimate them simply using maximum likelihood estimation, i.e., P x (f)=w(x,f)/ P f prime F x w(x,f prime )." ></td>
	<td class="line x" title="117:198	540 Table 1: # of sampled source phrases and automatically generated syntactic variants." ></td>
	<td class="line x" title="118:198	Phrase type # of tokens # of types th types Cov.(%) Output Ave. N : C : V 20,200,041 4,323,756 1,000 1,014 10.7 1,536 (489) 3.1 N 1 : N 2 : C : V 3,796,351 2,013,682 107 1,005 6.3 88,040 (966) 91.1 N : C : V 1 : V 2 325,964 213,923 15 1,022 12.9 75,344 (982) 76.7 N : C : Adv : V 1,209,265 923,475 21 1,097 3.9 8,281 (523) 15.7 Adj : N : C : V 378,617 233,952 20 1,049 14.1 128 (50) 2.6 N : C : Adj 788,038 203,845 86 1,003 31.4 3,212 (992) 3.2 Total 26,698,276 7,912,633 6,190 176,541 (4,002) 44.1 Table 2: # of syntactic variants whose paraphrasability scores are computed." ></td>
	<td class="line x" title="119:198	Nor.HITS  Nor.BOW.Nor.MOD.." ></td>
	<td class="line x" title="120:198	Anc.HITS  Anc.BOW.Anc.MOD.." ></td>
	<td class="line x" title="121:198	Nor.HITS  Anc.HITS." ></td>
	<td class="line x" title="122:198	Nor.BOW.Anc.BOW.." ></td>
	<td class="line x" title="123:198	Nor.MOD.Anc.MOD.." ></td>
	<td class="line x" title="124:198	X denotes the set of syntactic variants whose scores are computed based on X. Nor.HITS Nor.BOW. Nor.MOD. Anc.HITS Anc.BOW. Anc.MOD. Mainichi Phrase type Output Ave. Output Ave. Output Ave. Output Ave. Output Ave. Output Ave. Output Ave. N : C : V 1,405 (489) 2.9 1,402 (488) 2.9 1,396 (488) 2.9 1,368 (488) 2.8 1,366 (487) 2.8 1,360 (487) 2.8 1,103 (457) 2.4 N 1 : N 2 : C : V 9,544 (964) 9.9 9,249 (922)10.0 8,652 (921) 9.4 7,437 (897) 8.3 7,424 (894) 8.3 6,795 (891) 7.6 3,041 (948) 3.2 N : C : V 1 : V 2 3,769 (876) 4.3 3,406 (774) 4.4 3,109 (762) 4.1 2,517 (697) 3.6 2,497 (690) 3.6 2,258 (679) 3.3 1,156 (548) 2.1 N : C : Adv : V 690 (359) 1.9 506 (247) 2.0 475 (233) 2.0 342 (174) 2.0 339 (173) 2.0 322 (168) 1.9 215 (167) 1.3 Adj : N : C : V 45 (20) 2.3 45 (20) 2.3 42 (17) 2.5 41 (18) 2.3 41 (18) 2.3 39 (16) 2.4 14 (7) 2.0 N : C : Adj 1,459 (885) 1.6 1,459 (885) 1.6 1,399 (864) 1.6 1,235 (809) 1.5 1,235 (809) 1.5 1,161 (779) 1.5 559 (459) 1.2 Total 16,912 (3,593) 4.7 16,067 (3,336) 4.8 15,073 (3,285) 4.6 12,940 (3,083) 4.2 12,902 (3,071) 4.2 11,935 (3,020) 4.0 6,088 (2,586) 2.4 Now Par x falls within [0,1], and a larger Par x indicates a more paraphrasable pair of phrases." ></td>
	<td class="line x" title="125:198	4 Experimental setting We conduct empirical experiments to evaluate the proposed methods." ></td>
	<td class="line x" title="126:198	Settings are described below." ></td>
	<td class="line x" title="127:198	4.1 Test collection First, source phrases were sampled from a 15 years of newspaper articles (Mainichi 1991-2005, approximately 1.5GB)." ></td>
	<td class="line x" title="128:198	Referring to the dependency structure given by CaboCha, we extracted most frequent 1,000+ phrases for each of 6 phrase types." ></td>
	<td class="line x" title="129:198	These phrases were then fed to a system proposed in (Fujita et al., 2007) to generate syntactic variants." ></td>
	<td class="line x" title="130:198	The numbers of the source phrases and their syntactic variants are summarized in Table 1, where the numbers in the parentheses indicate that of source phrases paraphrased." ></td>
	<td class="line x" title="131:198	At least one candidate was generated for 4,002 (64.7%) phrases." ></td>
	<td class="line x" title="132:198	Although the system generates numerous syntactic variants from a given phrase, most of them are erroneous." ></td>
	<td class="line x" title="133:198	For example, among 159 syntactic variants that are automatically generated for the phrase songai:baishou:o:motomeru (demand compensation for damages), only 8 phrases are grammatical, and only 5 out of 8 are correct paraphrases." ></td>
	<td class="line x" title="134:198	Paraphrasability of each pair of source phrase and candidate is then computed by the methods proposed in Section 3." ></td>
	<td class="line x" title="135:198	Table 2 summarizes the numbers of pairs whose features can be extracted from the Web snippets." ></td>
	<td class="line x" title="136:198	While more than 90% of candidates were discarded due to No hits in the Web, at least one candidate survived for 3,020 (48.8%) phrases." ></td>
	<td class="line x" title="137:198	Mainichi is a baseline which counts HITS in the corpus used for sampling source phrases." ></td>
	<td class="line x" title="138:198	4.2 Samples for evaluation We sampled three sets of pairs for evaluation, where Mainichi, .HITS, .BOW, .MOD, the harmonic meanof the scores derived from.BOWand.MOD (referred to as .HAR), and two distributional similarity measures for .BOW, .MOD, and .HAR, in total 15 models, are compared." ></td>
	<td class="line x" title="139:198	Ev.Gen: This investigates how well a correct candidate is ranked first among candidates for a given phrase using the top-ranked pairs for randomly sampled 200 source phrases for each of 15 models." ></td>
	<td class="line x" title="140:198	Ev.Rec: This assesses how well a method gives higher scores to correct candidates using the 200-best pairs for each of 15 models." ></td>
	<td class="line x" title="141:198	Ev.Ling: This compares paraphrasability of each phrase type using the 20-best pairs for each of 6 phrase type and 14 Web-based models." ></td>
	<td class="line x" title="142:198	4.3 Criteria of paraphrasability To assess by human the paraphrasability discussed in Section 3, we designed the following four questions based on (Szpektor et al., 2007): Q sc : Is s a correct phrase in Japanese?" ></td>
	<td class="line x" title="143:198	Q tc : Is t a correct phrase in Japanese?" ></td>
	<td class="line x" title="144:198	Q s2t : Does t hold if s holds and can t substituted for s in some context?" ></td>
	<td class="line x" title="145:198	Q t2s : Does s hold if t holds and can s substituted for t in some context?" ></td>
	<td class="line x" title="146:198	541 5 Experimental results 5.1 Agreement of human judge Two human assessors separately judged all of the 1,152syntactic variant pairs (for962source phrases) within the union of the three sample sets." ></td>
	<td class="line x" title="147:198	They agreed on all four questions for 795 (68.4%) pairs." ></td>
	<td class="line x" title="148:198	For the 963 (83.6%) pairs that passed Q sc and Q tc in both two judges, we obtained reasonable agreement ratios 86.9% and 85.0% and substantial Kappa values 0.697 and 0.655 for assessing Q s2t and Q t2s . 5.2 Ev.Gen Table 3 shows the results for Ev.Gen, where the strict precision is calculated based on the number of two positive judges for Q s2t , while the lenient precision is for at least one positive judge for the same question." ></td>
	<td class="line x" title="149:198	.MOD and .HAR outperformed the other models, although there was no statistically significant difference 7 . Significant differences between Mainichi and the other models in lenient precisions indicate that the Web enables us to compute paraphrasability more accurately than a limited size of corpus." ></td>
	<td class="line x" title="150:198	From a closer look at the distributions of paraphrasability scores of .BOW and .MOD shown in Table 4, we find that if a top-ranked candidate for a given phrase is assigned enough high score, it is very likely to be correct." ></td>
	<td class="line x" title="151:198	The scores of Anc. are distributed in a wider range than those of Nor.,preserving precision." ></td>
	<td class="line x" title="152:198	This allows us to easily skim the most reliable portion by setting a threshold." ></td>
	<td class="line x" title="153:198	5.3 Ev.Rec The results for Ev.Rec, as summarized in Table 5, show the significant differences of performances between Mainichi or .HITS and the other models." ></td>
	<td class="line x" title="154:198	The results of .HITS supported the importance of comparing features of phrases." ></td>
	<td class="line x" title="155:198	On the other hand, .BOW performed as well as .MOD and .HAR." ></td>
	<td class="line x" title="156:198	This sounds nice because BOW features can be extracted extremely quickly and accurately." ></td>
	<td class="line x" title="157:198	Unfortunately, Anc. led only a small impact on strict precisions." ></td>
	<td class="line x" title="158:198	We speculate that the selection of the anchor is inadequate." ></td>
	<td class="line x" title="159:198	Another possible interpretation is that source phrases are rarely ambiguous, because they contain at least two content words." ></td>
	<td class="line x" title="160:198	In 7 p<0.05 in 2-sample test for equality of proportions." ></td>
	<td class="line x" title="161:198	Table 3: Precision for 200 candidates (Ev.Gen)." ></td>
	<td class="line x" title="162:198	Strict Lenient Model Nor. Anc. Nor. Anc. Mainichi 77 (39%) --101 (51%) -HITS 84 (42%) 83 (42%) 120 (60%) 119 (60%) BOW.Lin 82 (41%) 85 (43%) 123 (62%) 124 (62%) BOW.skew 86 (43%) 87 (44%) 125 (63%) 124 (62%) MOD.Lin 91 (46%) 91 (46%) 130 (65%) 131 (66%) MOD.skew 92 (46%) 90 (45%) 132 (66%) 130 (65%) HAR.Lin 90 (45%) 90 (45%) 129 (65%) 130 (65%) HAR.skew 93 (47%) 90 (45%) 134 (67%) 131 (66%) Table 4: Distribution of paraphrasability scores and lenient precision (Ev.Gen)." ></td>
	<td class="line x" title="163:198	Nor.BOW Anc.BOW Par(st) Lin skew Lin skew 0.9-1.0 11/ 12 (92%) 0/ 0 17/ 18 (94%) 2/ 2 (100%) 0.8-1.0 45/ 49 (92%) 1/ 1 (100%) 45/ 50 (90%) 6/ 6 (100%) 0.7-1.0 72/ 88 (82%) 7/ 7 (100%) 73/ 92 (79%) 10/ 11 (91%) 0.6-1.0 94/127 (74%) 11/ 11 (100%) 83/113 (74%) 12/ 13 (92%) 0.5-1.0 102/145 (70%) 13/ 13 (100%) 96/128 (75%) 14/ 15 (93%) 0.4-1.0 107/158 (68%) 13/ 14 (93%) 103/145 (71%) 21/ 22 (96%) 0.3-1.0 113/173 (65%) 25/ 26 (96%) 114/166 (69%) 31/ 32 (97%) 0.2-1.0 119/184 (65%) 40/ 41 (98%) 121/186 (65%) 49/ 50 (98%) 0.1-1.0 123/198 (62%) 74/ 86 (86%) 124/200 (62%) 82/ 99 (83%) 0.0-1.0 123/200 (62%) 125/200 (63%) 124/200 (62%) 124/200 (62%) Variance 0.052 0.031 0.061 0.044 Nor.MOD Anc.MOD Par(st) Lin skew Lin skew 0.9-1.0 2/ 2 (100%) 0/ 0 7/ 7 (100%) 1/ 1 (100%) 0.8-1.0 10/ 10 (100%) 0/ 0 12/ 13 (92%) 2/ 2 (100%) 0.7-1.0 13/ 14 (93%) 0/ 0 17/ 18 (94%) 6/ 6 (100%) 0.6-1.0 20/ 21 (95%) 1/ 1 (100%) 27/ 28 (96%) 9/ 9 (100%) 0.5-1.0 31/ 32 (97%) 6/ 6 (100%) 36/ 37 (97%) 10/ 10 (100%) 0.4-1.0 42/ 44 (96%) 11/ 11 (100%) 51/ 53 (96%) 12/ 12 (100%) 0.3-1.0 61/ 68 (90%) 12/ 12 (100%) 61/ 68 (90%) 13/ 14 (93%) 0.2-1.0 81/ 92 (88%) 13/ 13 (100%) 82/ 94 (87%) 18/ 19 (95%) 0.1-1.0 105/133 (79%) 17/ 18 (94%) 104/126 (83%) 24/ 25 (96%) 0.0-1.0 130/200 (65%) 132/200 (66%) 131/200 (66%) 130/200 (65%) Variance 0.057 0.014 0.072 0.030 paraphrase generation, capturing the correct boundary of phrases is rather vital, because the source phrase is usually assumed to be grammatical." ></td>
	<td class="line x" title="164:198	Q sc for 55syntactic variants (for 44source phrases) were actually judged incorrect." ></td>
	<td class="line x" title="165:198	The lenient precisions, which were reaching a ceiling, implied the limitation of the proposed methods." ></td>
	<td class="line x" title="166:198	Most common errors among the proposed methods were generated by a transformation pattern N 1 : N 2 : C : V  N 2 : C : V . Typically, dropping anominal element N 1 of thegivennominal compound N 1 : N 2 generalizes the meaning that the compound conveys, and thus results correct paraphrases." ></td>
	<td class="line x" title="167:198	However, it caused errors in some cases; for example, since N 1 was the semantic head in (7), dropping it was incorrect." ></td>
	<td class="line x" title="168:198	(7) s.shukketsu:taryou:de:shibou-suru (die due to heavy blood loss) t.  taryou:de:shibou-suru (die due to plenty) 542 Table 5: Precision for 200 candidates (Ev.Rec)." ></td>
	<td class="line x" title="169:198	Strict Lenient Model Nor. Anc. Nor. Anc. Mainichi 78 (39%) --111 (56%) -HITS 71 (36%) 93 (47%) 113 (57%) 128 (64%) BOW.Lin 159 (80%) 162 (81%) 193 (97%) 191 (96%) BOW.skew 154 (77%) 158 (79%) 192 (96%) 191 (96%) MOD.Lin 158 (79%) 164 (82%) 192 (96%) 193 (97%) MOD.skew 156 (78%) 161 (81%) 191 (96%) 191 (96%) HAR.Lin 157 (79%) 164 (82%) 192 (96%) 194 (97%) HAR.skew 155 (78%) 160 (80%) 191 (96%) 191 (96%) 5.4 Ev.Ling Finally the results for Ev.Ling is shown in Table 6." ></td>
	<td class="line x" title="170:198	Paraphrasability of syntactic variants for phrases containing an adjective was poorly computed." ></td>
	<td class="line x" title="171:198	The primal source of errors for Adj : N : C : V type phrases was the subtle change of nuance by switching syntactic heads as illustrated in (8), where underlines indicate heads." ></td>
	<td class="line x" title="172:198	(8) s.yoi:shigoto:o:suru(doa good job) t 1 . negationslash= yoku:shigoto-suru wrkhard) t 2 . negationslash= shigoto:o:yoku:suru (improve the work) Most errors in paraphrasing N : C : Adj type phrases, on the other hand, were caused due to the difference of aspectual property and agentivity between adjectives and verbs." ></td>
	<td class="line x" title="173:198	For example, (9s) can describe not only things those qualities have been improved as inferred by (9t), but also those originally having a high quality." ></td>
	<td class="line x" title="174:198	Q s2t for (9) was thus judged incorrect." ></td>
	<td class="line x" title="175:198	(9) s.shitsu:ga:takai (having high quality) t. negationslash= shitsu:ga:takamaru (quality rises) Precisions of syntactic variants for the other types of phrases were higher, but they tended to include trivial paraphrases such as shown in (10) and (11)." ></td>
	<td class="line x" title="176:198	Yet, collecting paraphrase instances statically will contribute to paraphrase recognition tasks." ></td>
	<td class="line x" title="177:198	(10) s.shounin:o:eru (clear) t.shounin-sa-re-ru (be approved) (11) s.eiga:o:mi:owaru(finish seeing the movie) t.eiga:ga:owaru (the movie ends) 6 Discussion As described in the previous sections, our quite naive methods have shown fairly good performances in this first trial." ></td>
	<td class="line x" title="178:198	This section describes some remaining issues to be discussed further." ></td>
	<td class="line x" title="179:198	The aim of this study is to create a thesaurus of phrases to recognize and generate phrases that Table 6: Precision for each phrase type (Ev.Ling)." ></td>
	<td class="line x" title="180:198	Phrase type Strict Lenient N : C : V 52/ 98 (53%) 69/ 98 (70%) N 1 : N 2 : C : V 51/ 72 (71%) 64/ 72 (89%) N : C : V 1 : V 2 42/ 86 (49%) 60/ 86 (70%) N : C : Adv : V 33/ 61 (54%) 44/ 61 (72%) Adj : N : C : V 0/ 25 (0%) 4/ 25 (16%) N : C : Adj 18/ 73 (25%) 38/ 73 (52%) Total 196/415 (47%) 279/415 (67%) Table 7: # of features." ></td>
	<td class="line x" title="181:198	Nor.BOW Nor.MOD Anc.BOW Anc.MOD # of features (type) 73,848 471,720 72,109 409,379 average features (type) 1,322 211 1,277 202 average features (token) 4,883 391 4,728 383 are semantically equivalent and syntactically substitutable, following the spirit described in (Fujita et al., 2007)." ></td>
	<td class="line x" title="182:198	Through the comparisons of Nor. and Anc., we have shown a little evidence that the ambiguity of phrases was not problematic at least for handling syntactic variants, arguing the necessity of detecting the appropriate phrase boundaries." ></td>
	<td class="line x" title="183:198	To overcome the data sparseness problem, Web snippets are harnessed." ></td>
	<td class="line x" title="184:198	Features extracted from the snippets outperformed newspaper corpus; however, the small numbers of features for phrases shown in Table 7andthe lackofsophisticated weighting function suggest that the problem might persist." ></td>
	<td class="line x" title="185:198	To examine the proposed features and measures further, we plan to use TSUBAKI 8 , an indexed Web corpus developed for NLP research, because it allow us to obtain snippets as much as it archives." ></td>
	<td class="line x" title="186:198	The use of larger number of snippets increases the computation time for assessing paraphrasability." ></td>
	<td class="line x" title="187:198	For reducing it as well as gaining a higher coverage, the enhancement of the paraphrase generation system is necessary." ></td>
	<td class="line x" title="188:198	A look at the syntactic variants automatically generated by a system, which we proposed, showed that the system could generate syntactic variants for only a half portion of the input, producing many erroneous ones (Section 4.1)." ></td>
	<td class="line x" title="189:198	To prune a multitude of incorrect candidates, statistical language models such as proposed in (Habash, 2004) will be incorporated." ></td>
	<td class="line x" title="190:198	In parallel, we plan to develop a paraphrase generation system which lets ustoquit fromthelabor ofmaintaining patterns such as shown in (4)." ></td>
	<td class="line x" title="191:198	We think a more unrestricted generation algorithm will gain a higher coverage, preserving the meaning as far as handling syntactic variants of predicate phrases." ></td>
	<td class="line x" title="192:198	8 http://tsubaki.ixnlp.nii.ac.jp/se/index.cgi 543 7Conclusion In this paper, we proposed a method of assessing paraphrasability between automatically generated syntactic variants of predicate phrases." ></td>
	<td class="line x" title="193:198	Web snippets were utilized to overcome the data sparseness problem, and the conventional distributional similarity measures were employed to quantify the similarity of feature sets for the given pair of phrases." ></td>
	<td class="line x" title="194:198	Empirical experiments revealed that features extracted from the Web snippets contribute to the task, showingpromising results, while nosignificant difference was observed between two measures." ></td>
	<td class="line x" title="195:198	Infuture, weplan toaddress several issues such as those described in Section 6." ></td>
	<td class="line x" title="196:198	Particularly, at present, the coverage and portability are of our interests." ></td>
	<td class="line x" title="197:198	Acknowledgments We are deeply grateful to all anonymous reviewers for their valuable comments." ></td>
	<td class="line x" title="198:198	This work was supported in part by MEXT Grant-in-Aid for Young Scientists (B) 18700143, and for Scientific Research (A) 16200009, Japan." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I08-2110
SYNGRAPH: A Flexible Matching Method based on Synonymous Expression Extraction from an Ordinary Dictionary and a Web Corpus
Shibata, Tomohide;Odani, Michitaka;Harashima, Jun;Oonishi, Takashi;Kurohashi, Sadao;"></td>
	<td class="line x" title="1:139	SYNGRAPH: A Flexible Matching Method based on Synonymous Expression Extraction from an Ordinary Dictionary and a Web Corpus Tomohide Shibatay, Michitaka Odaniy, Jun Harashimay, Takashi Oonishiyy, and Sadao Kurohashiy yKyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto, 606-8501, Japan yyNEC Corporation, 1753, Shimonumabe, Nakahara-Ku, Kawasaki, Kanagawa 211-8666, Japan fshibata,odani,harashima,kurog@nlp.kuee.kyoto-u.ac.jp t-onishi@bq.jp.nec.com Abstract This paper proposes a  exible matching method that can assimilate the expressive divergence." ></td>
	<td class="line x" title="2:139	First, broad-coverage synonymous expressions are automatically extracted from an ordinary dictionary, and among them, those whose distributional similarity in a Web corpus is high are used forthe exiblematching." ></td>
	<td class="line x" title="3:139	Then, toovercome the combinatorial explosion problem in the combination of expressive divergence, an ID is assigned to each synonymous group, and SYNGRAPH data structure is introduced to pack the expressive divergence." ></td>
	<td class="line x" title="4:139	We con rmed the effectiveness of our method on experiments of machine translation and information retrieval." ></td>
	<td class="line x" title="5:139	1 Introduction In natural language, many expressions have almost the same meaning, which brings great dif culty to many NLP tasks, such as machine translation (MT), information retrieval (IR), and question answering (QA)." ></td>
	<td class="line x" title="6:139	For example, suppose an input sentence (1) is given to a Japanese-English example-based machine translation system." ></td>
	<td class="line x" title="7:139	(1) hotel ni hotel ichiban best chikai near eki wa station doko-desuka where is Even if a very similar translation example (TE)  (2-a) $ (2-b) exists in the TEs, a simple exact matching method cannot utilize this example for the translation." ></td>
	<td class="line x" title="8:139	(2) a. ryokan no Japanese hotel moyori no nearest eki wa station doko-desuka where is b. Wheres the nearest station to the hotel?" ></td>
	<td class="line x" title="9:139	How to handle these synonymous expressions has become one of the important research topics in NLP." ></td>
	<td class="line x" title="10:139	This paper presents a  exible matching method, which can assimilate the expressive divergence, to solve this problem." ></td>
	<td class="line x" title="11:139	This method has the following two features: 1." ></td>
	<td class="line x" title="12:139	Synonymy relations and hypernym-hyponym relations are automatically extracted from an ordinary dictionary and a Web corpus." ></td>
	<td class="line x" title="13:139	2." ></td>
	<td class="line x" title="14:139	Extracted synonymous expressions are effectively handled by SYNGRAPH data structure, which can pack the expressive divergence." ></td>
	<td class="line x" title="15:139	An ordinary dictionary is a knowledge source to provide synonym and hypernym-hyponym relations(NakamuraandNagao, 1988; Tsurumaruetal., 1986)." ></td>
	<td class="line x" title="16:139	A problem in using synonymous expressions extracted from a dictionary is that some of them are notappropriatesincetheyarerarelyused." ></td>
	<td class="line x" title="17:139	Forexample, a synonym pair  suidou 1 =  kaikyou(strait) is extracted." ></td>
	<td class="line oc" title="18:139	Recently, some work has been done on corpusbased paraphrase extraction (Lin and Pantel, 2001; Barzilay and Lee, 2003)." ></td>
	<td class="line o" title="19:139	The basic idea of their methods is that two words with similar meanings are used in similar contexts." ></td>
	<td class="line n" title="20:139	Although their methods can obtain broad-coverage paraphrases, the obtained paraphrases are not accurate enough to be utilized 1This word usually means  water supply . 787 for achieving precise matching since they contain synonyms, near-synonyms, coordinate terms, hypernyms, and inappropriate synonymous expressions." ></td>
	<td class="line x" title="21:139	Our approach makes the best use of an ordinary dictionary and a Web corpus to extract broadcoverage and precise synonym and hypernymhyponym expressions." ></td>
	<td class="line x" title="22:139	First, synonymous expressions are extracted from a dictionary." ></td>
	<td class="line x" title="23:139	Then, the distributional similarity of a pair of them is calculated using a Web corpus." ></td>
	<td class="line x" title="24:139	Among extracted synonymous expressions, those whose similarity is high are used for the  exible matching." ></td>
	<td class="line x" title="25:139	By utilizing only synonymousexpressionsextractedfromadictionary whose distributional similarity is high, we can exclude synonymous expressions extracted from a dictionary that are rarely used, and the pair of words whose distributional similarity is high that is not actually a synonymous expression (is not listed in a dictionary)." ></td>
	<td class="line x" title="26:139	Another point of our method is to introduce SYNGRAPH data structure." ></td>
	<td class="line x" title="27:139	So far, the effectiveness of handling expressive divergence has been shown for IR using a thesaurus-based query expansion (Voorhees, 1994; Jacquemin et al., 1997)." ></td>
	<td class="line x" title="28:139	However, their methods are based on a bag-of-words approach and thus does not pay attention to sentence-level synonymy with syntactic structure." ></td>
	<td class="line x" title="29:139	MT requires such precise handling of synonymy, and advanced IR and QA also need it." ></td>
	<td class="line x" title="30:139	To handle sentence-level synonymy precisely, we have to consider the combination of expressive divergence, which may cause combinatorial explosion." ></td>
	<td class="line x" title="31:139	To overcome this problem, an ID is assigned to each synonymous group, and then SYNGRAPH data structure is introduced to pack expressive divergence." ></td>
	<td class="line x" title="32:139	2 Synonymy Database This section describes a method for constructing a synonymy database." ></td>
	<td class="line x" title="33:139	First, synonym/hypernym relations are automatically extracted from an ordinary dictionary, and the distributional similarity of a pair of synonymous expressions is calculated using a Web corpus." ></td>
	<td class="line x" title="34:139	Then, the extracted synonymous expressions whose similarity is high are used for the  exible matching." ></td>
	<td class="line x" title="35:139	2.1 Synonym/hypernym Extraction from an Ordinary Dictionary Although there were some attempts to extract synonymous expressions from a dictionary (Nakamura and Nagao, 1988; Tsurumaru et al., 1986), they extracted only hypernym-hyponym relations from the limited entries." ></td>
	<td class="line x" title="36:139	In contrast, our method extracts not only hypernym-hyponym relations, but also basic synonym relations, predicate synonyms, adverbial synonyms and synonym relations between a word and a phrase." ></td>
	<td class="line x" title="37:139	The last word of the  rst de nition sentence is usually the hypernym of an entry word." ></td>
	<td class="line x" title="38:139	Some de nition sentences in a Japanese dictionary are shown below(theleftwordof : isanentryword, theright sentence is a de nition, and words in bold font is the extracted words): yushoku (dinner) : yugata (evening) no (of) shokuji (meal)." ></td>
	<td class="line x" title="39:139	jushin (barycenter) : omosa (weight) ga (is) tsuriatte (balance) tyushin (center) tonaru (become) ten (spot)." ></td>
	<td class="line x" title="40:139	For example, the last word shokuji (meal) can be extracted as the hypernym of yushoku (dinner)." ></td>
	<td class="line x" title="41:139	In somecases, however,awordotherthanthelastword can be a hypernym or synonym." ></td>
	<td class="line x" title="42:139	These cases can be detected by sentencenal patterns as follows (the underlined expressions represent the patterns): Hypernyms dosei (Saturn) : wakusei (planet) no (of) hitotsu (one)." ></td>
	<td class="line x" title="43:139	tobi (kite) : taka (hawk) no (of) issyu (kind)." ></td>
	<td class="line x" title="44:139	Synonyms / Synonymous Phrases ice : ice cream no (of) ryaku (abbreviation)." ></td>
	<td class="line x" title="45:139	mottomo (most) : ichiban (best)." ></td>
	<td class="line x" title="46:139	( one word de nition) moyori (nearest) : ichiban (best) chikai (near) tokoro (place)2." ></td>
	<td class="line x" title="47:139	( less than three phrases) 2.2 Calculating the Distributional Similarity using a Web Corpus The similarity between a pair of synonymous expressions is calculated based on distributional similarity (J.R.Firth, 1957; Harris, 1968) using the Web corpus collected by (Kawahara and Kurohashi, 2006)." ></td>
	<td class="line x" title="48:139	The similarity between two predicates is de ned to be one between the patterns of case examples of each predicate (Kawahara and Kurohashi, 2001)." ></td>
	<td class="line x" title="49:139	Thesimilaritybetweentwonounsarede ned 2If the last word of a sentence is a highly general term such as koto (thing) and tokoro (place), it is removed from the synonymous expression." ></td>
	<td class="line x" title="50:139	788                                            Figure 1: An example of synonymy database." ></td>
	<td class="line x" title="51:139	as the ratio of the overlapped co-occurrence words using the Simpson coef cient." ></td>
	<td class="line x" title="52:139	The Simpson coef cient is computed as jT(w1)^T(w2)jmin(jT(w1)j;jT(w2)j), where T(w) is the set of co-occurrence words of word w. 2.3 Integrating the Distributional Similarity into the Synonymous Expressions Synonymous expressions can be extracted from a dictionary as described in Section 2.1." ></td>
	<td class="line x" title="53:139	However, some extracted synonyms/hypernyms are not appropriate since they are rarely used." ></td>
	<td class="line x" title="54:139	Especially, in the case of that a word has multiple senses, the synonym/hypernym extracted from the second or later de nition might cause the inappropriate matching." ></td>
	<td class="line x" title="55:139	For example, since  suidou has two senses, the two synonym pairs,  suidou =  jyosuidou(water supply) and  suidou =  kaikyou(strait) , are extracted." ></td>
	<td class="line x" title="56:139	The second sense is rarely used, and thus if the synonymy pair extracted from the second de nition is used as a synonym relation, an inappropriatematchingthroughthissynonymmightbecaused." ></td>
	<td class="line x" title="57:139	Therefore, only the pairs of synonyms/hypernyms whose distributional similarity calculated in Section 2.2 is high are utilized for the  exible matching." ></td>
	<td class="line x" title="58:139	Thesimilaritythresholdis setto0.4for synonyms and to 0.3 for hypernyms." ></td>
	<td class="line x" title="59:139	For example, since the similarity between  suidou and  kaikyou is 0.298, this synonym is not utilized." ></td>
	<td class="line x" title="60:139	2.4 Synonymy Database Construction With the extracted binomial relations, a synonymy database can be constructed." ></td>
	<td class="line x" title="61:139	Here, polysemic words should be treated carefully3." ></td>
	<td class="line x" title="62:139	When the relations A=B and B=C are extracted, and B is not polysemic, 3If a word has two or more de nition items in the dictionary, the word can be regarded as polysemic." ></td>
	<td class="line x" title="63:139	they can be merged into A=B=C. However, if B is polysemic, the synonym relations are not merged through a polysemic word." ></td>
	<td class="line x" title="64:139	In the same way, as for hypernym-hyponym relations, A ! B and B ! C, and A ! B and C ! B are not merged if B is polysemic." ></td>
	<td class="line x" title="65:139	By merging binomial synonym relations with the exception of polysemic words, synonymous groups are constructed  rst." ></td>
	<td class="line x" title="66:139	They are given IDs, hereafter called SYNID4." ></td>
	<td class="line x" title="67:139	Then, hypernymhyponym relations are established between synonymous groups." ></td>
	<td class="line x" title="68:139	We call this resulting data as synonymy database." ></td>
	<td class="line x" title="69:139	Figure 1 shows examples of synonymous groups in the synonymy database." ></td>
	<td class="line x" title="70:139	In this paper, SYNID is denoted by using English gloss word, surrounded by  h i  . 3 SYNGRAPH 3.1 SYNGRAPH Data Structure SYNGRAPH data structure is an acyclic directed graph, and the basis of SYNGRAPH is the dependencystructureofanoriginalsentence(inthispaper, a robust parser (Kurohashi and Nagao, 1994) is always employed)." ></td>
	<td class="line x" title="71:139	In the dependency structure, each node consists of one content word and zero or more function words, which is called a basic node hereafter." ></td>
	<td class="line x" title="72:139	If the content word of a basic node belongs to a synonymous group, a new node with the SYNID is attached to it, and it is called a SYN node hereafter." ></td>
	<td class="line x" title="73:139	For example, in Figure 2, the shaded nodes are basic nodes and the other nodes are SYN nodes5." ></td>
	<td class="line x" title="74:139	Then, if the expression conjoining two or more 4Spelling variations such as use of Hiragana, Katakana or Kanji are handled by the morphological analyzer JUMAN (Kurohashi et al., 1994)." ></td>
	<td class="line x" title="75:139	5The reason why we distinguish basic nodes from SYN nodes is to give priority to exact matching over synonymous matching." ></td>
	<td class="line x" title="76:139	789                              Figure 2: SYNGRAPH matching." ></td>
	<td class="line x" title="77:139	nodes corresponds to one synonymous group, a SYN node is added there." ></td>
	<td class="line x" title="78:139	In Figure 2, hnearesti is such a SYN node." ></td>
	<td class="line x" title="79:139	Furthermore, if one SYN node has a hyper synonymous group in the synonymy database, the SYN node with the hyper SYNID is also added." ></td>
	<td class="line x" title="80:139	In this SYNGRAPH data structure, each node has a score, NS (Node Score), which re ects how much the expression of the node is shifted from the original expression." ></td>
	<td class="line x" title="81:139	We explain how to calculate NSs later." ></td>
	<td class="line x" title="82:139	3.2 SYNGRAPH Matching Two SYNGRAPHs match if and only if  all the nodes in one SYNGRAPH can be matched to the nodes in the other one,  the matched nodes in two SYNGRAPHs have the same dependency structure, and  the nodes can cover the original sentences." ></td>
	<td class="line x" title="83:139	An example of SYNGRAPH matching is illustrated in Figure 2." ></td>
	<td class="line x" title="84:139	When two SYNGRAPHs match each other, their matching score is calculated as follows." ></td>
	<td class="line x" title="85:139	First, the matching score of the matching two nodes, NMS (Node Match Score) is calculated with their node scores, NS1 and NS2, NMS = NS1  NS2  FI Penalty; where we de ne FI Penalty (Function word Inconsistency Penalty) is 0.9 when their function words are not the same, and 1.0 otherwise." ></td>
	<td class="line x" title="86:139	Then, the matching score of two SYNGRAPHs, SMS (SYNGRAPH Match Score) is de ned as the average of NMSs weighted by the number of basic nodes, SMS = P(# of basic nodes  NMS) P# of basic nodes : In an example shown in Figure 2, the NMS of the left-hand side hotel node and the right-hand side hotel node is 0.9 (= 1:0  1:0  0:9)." ></td>
	<td class="line x" title="87:139	The NMS of the left-hand side hnearesti node and the right-hand side hnearesti node is 0.98 (= 0:99  0:99  1:0)." ></td>
	<td class="line x" title="88:139	Then, the SMS becomes 0:9 2+0:98 3+1:0 22+3+2 = 0:96." ></td>
	<td class="line x" title="89:139	3.3 SYNGRAPH Transformation of Synonymy Database The synonymy database is transformed into SYNGRAPHs, where SYNGRAPH matching is iteratively applied to interpret the mutual relationships in the synonymy database, as follows: Step 1: Each expression in each synonymous group is parsed and transformed into a fundamental SYNGRAPH." ></td>
	<td class="line x" title="90:139	Step 2: SYNGRAPH matching is applied to check whetherasub-treeofoneexpressionismatchedwith any other whole expressions." ></td>
	<td class="line x" title="91:139	If there is a match, a new node with the SYNID of the whole matched expression is assigned to the partially matched nodes group." ></td>
	<td class="line x" title="92:139	Furthermore, if the SYNID has a hyper synonymous group, another new node with the hypernym SYNID is also assigned." ></td>
	<td class="line x" title="93:139	This checking process starts from small parts to larger parts." ></td>
	<td class="line x" title="94:139	We de ne the NS of the newly assigned SYN node as the SMS multiplied by a relation penalty." ></td>
	<td class="line x" title="95:139	Here, we de ne the synonymy relation penalty as 0.99 and the hypernym relation penalty as 0.7." ></td>
	<td class="line x" title="96:139	For instance, the NS of hunderwateri node is 0.99 and that of hinsidei node is 0.7." ></td>
	<td class="line x" title="97:139	Step 3: Repeat Step 2, until no more new SYN node can be assigned to any expressions." ></td>
	<td class="line x" title="98:139	In the case of Figure 3 example, the new SYN node, hdivingi is given to  suityu (underwater) ni (to) moguru (dive) of hdiving(sport)i at the second iteration." ></td>
	<td class="line x" title="99:139	4 Flexible Matching using SYNGRAPH We use example-based machine translation (EBMT) as an example to explain how our  exible matching method works (Figure 4)." ></td>
	<td class="line x" title="100:139	EBMT generates a translation by combining partially matching TEs with an input6." ></td>
	<td class="line x" title="101:139	We use  exible matching to fully exploit the TEs." ></td>
	<td class="line x" title="102:139	6How to select the best TEs and combine the selected TEs for generating a translation is omitted in this paper." ></td>
	<td class="line x" title="103:139	790 ni ni ni ni sport ni ni moguru(dive) ni <underwater> <inside> <diving> 0.99 0.7 0.99 1.0 1.0 diving1.0 <diving(sport)> mizu(water) suityu(underwater) naka(inside) 1.0 1.0 1.0 <underwater> <inside> <inside>0.99 naka(inside) <inside> moguru(dive) 0.99 1.0 1.0 <inside>0.7 mizu(water) 1.0 sensui(diving) 1.0 <diving>Synonymy databaseTranslation example naka(inside) suityu(underwater) no no 1.0 1.0 suru sport suru <diving> <diving(sport)> a0 a0 sensui(diving) 0.99 1.0 0.93 1.0 <underwater>0.99 Figure 3: SYNGRAPH transformation of synonymy database." ></td>
	<td class="line x" title="104:139	input sentence translation examplestransform into a SYNGRAPH Japanese English Figure 4: Flexible matching using SYNGRAPH in EBMT." ></td>
	<td class="line x" title="105:139	First, TEs are transformed into SYNGRAPHs by SYNGRAPH matching with SYNGRAPHs of the synonymy database." ></td>
	<td class="line x" title="106:139	Since the synonymy database has been transformed into SYNGRAPHs, we do not need to care the combinations of synonymous expressions any more." ></td>
	<td class="line x" title="107:139	In the example shown in Figure 3,  sensui (diving) suru (do) sport in the TE is given hdiving(sport)i node just by looking at SYNGRAPHs in hdiving(sport)i synonymous group." ></td>
	<td class="line x" title="108:139	Then, an input sentence is transformed into a SYNGRAPH by SYNGRAPH matching, and then the SYNGRAPH matching is applied between all the sub trees of the input SYNGRAPH and SYNGRAPHs of TEs to retrieve the partially matching TEs." ></td>
	<td class="line x" title="109:139	5 Experiments and Discussion 5.1 Evaluation on Machine Translation Task To see the effectiveness of the our proposed method, we conducted our evaluations on a MT task using Japanese-English translation training corpus (20,000 sentence pairs) and 506 test sentences of IWSLT057." ></td>
	<td class="line x" title="110:139	As an evaluation measure, NIST and BLEU were used based on 16 reference English sentences for each test sentence." ></td>
	<td class="line x" title="111:139	7http://www.is.cs.cmu.edu/iwslt2005/." ></td>
	<td class="line x" title="112:139	Table 1: Size of synonymy database." ></td>
	<td class="line x" title="113:139	# of synonymous group 5,046 # of hypernym-hyponym relation 18,590 The synonymy database used in the experiments was automatically extracted from the REIKAISHOGAKU dictionary (a dictionary for children), which consists of about 30,000 entries." ></td>
	<td class="line x" title="114:139	Table 1 shows the size of the constructed synonymy database." ></td>
	<td class="line x" title="115:139	As a base translation system, we used an EBMT system developed by (Kurohashi et al., 2005)." ></td>
	<td class="line x" title="116:139	Table 2 shows the experimental results." ></td>
	<td class="line x" title="117:139	None means the baseline system without using the synonymy database." ></td>
	<td class="line x" title="118:139	Synonym is the system using only synonymous relations, and it performed best and achieved 1.2% improvement for NIST and 0.8% improvement for BLEU over the baseline." ></td>
	<td class="line x" title="119:139	These differences are statistically signi cant (p < 0:05)." ></td>
	<td class="line x" title="120:139	Some TEs that can be retrieved by our  exible matching are shown below:  input: fujin (lady) you (for) toile (toilet) $ TE: josei (woman) you (for) toile (toilet)  input: kantan-ni ieba(inshort)$TE:tsumari (in other words) On the other hand, if the system also uses hypernym-hyponym relation ( Synonym Hypernym ), the score goes down." ></td>
	<td class="line x" title="121:139	It proves that hypernym examples are not necessarily good for translation." ></td>
	<td class="line x" title="122:139	For example, for a translation of depato (department store), its hypernym  mise(store) was used, and it lowered the score." ></td>
	<td class="line x" title="123:139	Major errors are caused by the de ciency of word sense disambiguation." ></td>
	<td class="line x" title="124:139	When a polysemic word occurs in a sentence, multiple SYNIDs are attached to the word, and thus, the incorrect matching might be occurred." ></td>
	<td class="line x" title="125:139	Incorporation of unsupervised word791 Table 2: Evaluation results on MT task." ></td>
	<td class="line x" title="126:139	Synonymy DB NIST BLEU None 8.023 0.375 Synonym 8.121 0.378 Synonym Hypernym 8.010 0.374 Table 3: Evaluation results on IR task." ></td>
	<td class="line x" title="127:139	Method Synonymy DB R-prec Best IREX system  0.493 BM25  0.474 None 0.492 Our method Synonym 0.509 Synonym Hypernym 0.514 sense-disambiguation of words in dictionary de nitions and matching sentences is one of our future research targets." ></td>
	<td class="line x" title="128:139	5.2 Evaluation on Information Retrieval Task To demonstrate the effectiveness of our method in other NLP tasks, we also evaluated it in IR." ></td>
	<td class="line x" title="129:139	More concretely, we extended word-based importance weighting of Okapi BM25 (Robertson et al., 1994) to SYN node-based weighting." ></td>
	<td class="line x" title="130:139	We used the data set of IR evaluation workshop IREX, which contains 30 queries and their corresponding relevant documents in 2-year volume of newspaper articles8." ></td>
	<td class="line x" title="131:139	Table 3 shows the experimental results, which are evaluated with R-precision." ></td>
	<td class="line x" title="132:139	The baseline system is our implementation of OKAPI BM25." ></td>
	<td class="line x" title="133:139	Differently from the MT task, the system using both synonym and hypernym-hyponym relations performed best, and its improvement over the baseline was 7.8% relative." ></td>
	<td class="line x" title="134:139	This difference is statistically signi cant (p < 0:05)." ></td>
	<td class="line x" title="135:139	This result shows the wide applicability of our  exible matching method for NLP tasks." ></td>
	<td class="line x" title="136:139	Some examples that can be retrieved by our  exible matching are shown below:  query: gakkou-ni (school) computer-wo (computer) dounyuu (introduce) $ document: shou-gakkou-ni (elementary school) pasokon-wo (personal computer) dounyuu (introduce) 6 Conclusion This paper proposed a  exible matching method by extracting synonymous expressions from an ordinary dictionary and a Web corpus, and introducing SYNGRAPH data structure." ></td>
	<td class="line x" title="137:139	We con rmed the effectiveness of our method on experiments of machine translation and information retrieval." ></td>
	<td class="line x" title="138:139	8http://nlp.cs.nyu.edu/irex/." ></td>
	<td class="line x" title="139:139	Our future research targets are to incorporate word sense disambiguation to our framework, and to extend SYNGRAPH matching to more structural paraphrases." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P08-1077
Large Scale Acquisition of Paraphrases for Learning Surface Patterns
Bhagat, Rahul;Ravichandran, Deepak;"></td>
	<td class="line x" title="1:235	Proceedings of ACL-08: HLT, pages 674682, Columbus, Ohio, USA, June 2008." ></td>
	<td class="line x" title="2:235	c2008 Association for Computational Linguistics Large Scale Acquisition of Paraphrases for Learning Surface Patterns Rahul Bhagat  Information Sciences Institute University of Southern California Marina del Rey, CA rahul@isi.edu Deepak Ravichandran Google Inc. 1600 Amphitheatre Parkway Mountain View, CA deepakr@google.com Abstract Paraphrases have proved to be useful in many applications, including Machine Translation, Question Answering, Summarization, and Information Retrieval." ></td>
	<td class="line x" title="3:235	Paraphrase acquisition methods that use a single monolingual corpus often produce only syntactic paraphrases." ></td>
	<td class="line x" title="4:235	We present a method for obtaining surface paraphrases, using a 150GB (25 billion words) monolingual corpus." ></td>
	<td class="line x" title="5:235	Our method achieves an accuracyof around70% on the paraphraseacquisition task." ></td>
	<td class="line x" title="6:235	We further show that we can use these paraphrases to generate surface patterns for relation extraction." ></td>
	<td class="line x" title="7:235	Our patterns are much more precise than those obtained by using a state of the art baseline and can extract relations with more than 80% precision for each of the test relations." ></td>
	<td class="line x" title="8:235	1 Introduction Paraphrases are textual expressions that convey the same meaning using different surface words." ></td>
	<td class="line x" title="9:235	Forexample consider the following sentences: Google acquired YouTube." ></td>
	<td class="line x" title="10:235	(1) Google completed the acquisition of YouTube." ></td>
	<td class="line x" title="11:235	(2) Since they convey the same meaning, sentences (1) and (2) are sentence level paraphrases, and the phrases acquired and completed the acquisition of in (1) and (2) respectively are phrasal paraphrases." ></td>
	<td class="line x" title="12:235	Paraphrases provide a way to capture the variability of language and hence play an important  Work done during an internship at Google Inc. role in many natural language processing (NLP) applications." ></td>
	<td class="line x" title="13:235	For example, in question answering, paraphrases have been used to find multiple patterns that pinpoint the same answer (Ravichandran and Hovy, 2002); in statistical machine translation, they have been used to find translations for unseen source language phrases (Callison-Burch et al., 2006); in multi-document summarization, they have been used to identify phrases from different sentences that express the same information (Barzilay et al., 1999); in information retrieval they have been used for query expansion (Anick and Tipirneni, 1999)." ></td>
	<td class="line x" title="14:235	Learning paraphrases requires one to ensure identity of meaning." ></td>
	<td class="line x" title="15:235	Since there are no adequate semantic interpretation systems available today, paraphrase acquisition techniques use some other mechanism as a kind of pivot to (help) ensure semantic identity." ></td>
	<td class="line x" title="16:235	Each pivot mechanism selects phrases with similar meaning in a different characteristic way." ></td>
	<td class="line x" title="17:235	A popular method, the so-called distributional similarity, is based on the dictum of Zelig Harris you shall know the words by the company they keep: given highly discriminating left and right contexts, only words with very similar meaning will be found to fit in between them." ></td>
	<td class="line x" title="18:235	For paraphrasing, this has been often used to find syntactic transformations in parse trees that preserve (semantic) meaning." ></td>
	<td class="line x" title="19:235	Another method isto use abilingual dictionary or translation table as pivot mechanism: all source language words or phrases that translate to a given foreign word/phrase are deemed to be paraphrases of one another." ></td>
	<td class="line x" title="20:235	In this paper we call the paraphrases that contain only words as surface paraphrases and those 674 that contain paths in a syntax tree as syntactic paraphrases." ></td>
	<td class="line x" title="21:235	We here, present a method to acquire surface paraphrases from a single monolingual corpus." ></td>
	<td class="line x" title="22:235	We use a large corpus (about 150GB) to overcome the data sparseness problem." ></td>
	<td class="line x" title="23:235	To overcome the scalability problem, we pre-process the text with a simple parts-of-speech (POS)tagger and then apply locality sensitive hashing (LSH) (Charikar, 2002; Ravichandran et al., 2005) to speed up the remaining computation for paraphrase acquisition." ></td>
	<td class="line x" title="24:235	Our experiments show results to verify the following main claim: Claim 1: Highly precise surface paraphrases can be obtained from a very large monolingual corpus." ></td>
	<td class="line x" title="25:235	With this result, we further show that these paraphrases can be used to obtain high precision surface patterns that enable the discovery of relations in a minimally supervised way." ></td>
	<td class="line x" title="26:235	Surface patterns are templates for extracting information from text." ></td>
	<td class="line x" title="27:235	For example, if one wanted to extract a list of company acquisitions, ACQUIRERacquired ACQUIREE would be one surface pattern with ACQUIRER and ACQUIREE as the slots to be extracted." ></td>
	<td class="line x" title="28:235	Thus we can claim: Claim 2: These paraphrases can then be used for generating high precision surface patterns for relation extraction." ></td>
	<td class="line x" title="29:235	2 Related Work Most recent work in paraphrase acquisition is based on automatic acquisition." ></td>
	<td class="line x" title="30:235	Barzilay and McKeown (2001) used a monolingual parallel corpus to obtain paraphrases." ></td>
	<td class="line x" title="31:235	Bannard and Callison-Burch (2005) and Zhou et al.(2006) both employed a bilingual parallel corpus in which each foreign language word or phrase was apivot to obtain source language paraphrases." ></td>
	<td class="line oc" title="33:235	Dolan et al.(2004) and Barzilay and Lee (2003) used comparable news articles to obtain sentence level paraphrases." ></td>
	<td class="line n" title="35:235	All these approaches rely on the presence of parallel or comparable corpora and are thus limited by their availability and size." ></td>
	<td class="line x" title="36:235	Lin and Pantel (2001) and Szpektor et al.(2004) proposed methods to obtain entailment templates by using asingle monolingual resource." ></td>
	<td class="line x" title="38:235	While both differ in their approaches, they both end upfinding syntactic paraphrases." ></td>
	<td class="line x" title="39:235	Their methods cannot be used if we cannot parse the data (either because of scale or data quality)." ></td>
	<td class="line x" title="40:235	Our approach on the other hand, finds surface paraphrases; it is more scalable and robust due to the use of simple POS tagging." ></td>
	<td class="line x" title="41:235	Also, our use of locality sensitive hashing makes finding similar phrases in a large corpus feasible." ></td>
	<td class="line x" title="42:235	Another task related toour work isrelation extraction." ></td>
	<td class="line x" title="43:235	Its aim is to extract instances of a given relation." ></td>
	<td class="line x" title="44:235	Hearst (1992) the pioneering paper in the field used a small number of hand selected patterns to extract instances of hyponymy relation." ></td>
	<td class="line x" title="45:235	Berland and Charniak (1999) used a similar method for extracting instances of meronymy relation." ></td>
	<td class="line x" title="46:235	Ravichandran and Hovy (2002) used seed instances of a relation to automatically obtain surface patterns by querying the web." ></td>
	<td class="line x" title="47:235	But their method often finds patterns that are too general (e.g., X and Y), resulting in low precision extractions." ></td>
	<td class="line x" title="48:235	Rosenfeld and Feldman (2006) present a somewhat similar web based method that uses a combination of seed instances and seed patterns to learn good quality surface patterns." ></td>
	<td class="line x" title="49:235	Both these methods differ from ours in that they learn relation patterns on the fly (from the web)." ></td>
	<td class="line x" title="50:235	Our method however, pre-computes paraphrases for a large set of surface patterns using distributional similarity over a large corpus and then obtains patterns for a relation by simply finding paraphrases (offline) for a few seed patterns." ></td>
	<td class="line x" title="51:235	Using distributional similarity avoids the problem of obtaining overly general patterns and the pre-computation of paraphrases means that we can obtain the set of patterns for any relation instantaneously." ></td>
	<td class="line x" title="52:235	Romano et al.(2006) and Sekine (2006) used syntactic paraphrases to obtain patterns for extracting relations." ></td>
	<td class="line x" title="54:235	While procedurally different, both methods depend heavily on the performance of the syntax parser and require complex syntax tree matching to extract the relation instances." ></td>
	<td class="line x" title="55:235	Our method on the other hand acquires surface patterns and thus avoids the dependence on a parser and syntactic matching." ></td>
	<td class="line x" title="56:235	This also makes the extraction process scalable." ></td>
	<td class="line x" title="57:235	3 Acquiring Paraphrases This section describes our model for acquiring paraphrases from text." ></td>
	<td class="line x" title="58:235	675 3.1 Distributional Similarity Harriss distributional hypothesis (Harris, 1954) has played an important role in lexical semantics." ></td>
	<td class="line x" title="59:235	It states that words that appear in similar contexts tend to have similar meanings." ></td>
	<td class="line x" title="60:235	In this paper, we apply the distributional hypothesis to phrases i.e. word ngrams." ></td>
	<td class="line x" title="61:235	For example, consider the phrase acquired of the form X acquired Y ." ></td>
	<td class="line x" title="62:235	Considering the context of this phrase, we might find {Google, eBay, Yahoo,} in position X and {YouTube, Skype, Overture,} in position Y . Now consider another phrase completed the acquisition of, again of the form X completed the acquisition of Y ." ></td>
	<td class="line x" title="63:235	For this phrase, we might find {Google, eBay, Hilton Hotel corp.,} in position X and {YouTube, Skype, Bally Entertainment Corp.,} in position Y . Since the contexts of the two phrases are similar, our extension of the distributional hypothesis would assume that acquired and completed the acquisition of have similar meanings." ></td>
	<td class="line x" title="64:235	3.2 Paraphrase Learning Model Let p be a phrase (n-gram) of the form X p Y , where X and Y are the placeholders for words occurring on either side of p. Our first task is to find the set of phrases that are similar in meaning to p. Let P = {p 1 ,p 2 ,p 3 ,,p l } be the set of all phrases of the form Xp i Y where p i  P. Let S i,X be the set of words that occur in position X of p i and S i,Y be the set of words that occur in position Y of p i . Let V i be the vector representing p i such that V i = S i,X  S i,Y . Each word f  V i has an associated score that measures the strength of the association of the word f with phrase p i ; as do many others, we employ pointwise mutual information (Cover and Thomas, 1991) to measure this strength of association." ></td>
	<td class="line x" title="65:235	pmi(p i ;f) = log P(p i ,f) P(p i )P(f) (1) The probabilities in equation (1) are calculated by using the maximum likelihood estimate over our corpus." ></td>
	<td class="line x" title="66:235	Once we have the vectors for each phrase p i  P, we can find the paraphrases for each p i by finding its nearest neighbors." ></td>
	<td class="line x" title="67:235	We use cosine similarity, which is a commonly used measure for finding similarity between two vectors." ></td>
	<td class="line x" title="68:235	If we have two phrases p i  P and p j  P with the corresponding vectors V i and V j constructed as described above, the similarity between the two phrases is calculated as: sim(p i ;p j )= V i squaresmallsolidV j |V i ||V j | (2) Each word in V i (and V j ) has with it an associated flag which indicates weather the word came from S i,X or S i,Y . Hence for each phrase p i of the form Xp i Y , we have a corresponding phrase p i that has the form Yp i X. This is important to find certain kinds of paraphrases." ></td>
	<td class="line x" title="69:235	The following example will illustrate." ></td>
	<td class="line x" title="70:235	Consider the sentences: Google acquired YouTube." ></td>
	<td class="line x" title="71:235	(3) YouTube was bought by Google." ></td>
	<td class="line x" title="72:235	(4) From sentence (3), we obtain two phrases: 1." ></td>
	<td class="line x" title="73:235	p i = acquired which has the form X acquired Y  where X = Google and Y = YouTube 2." ></td>
	<td class="line x" title="74:235	p i = acquired which has the form Y acquired X where X = YouTube and Y = Google Similarly, from sentence (4) we obtain two phrases: 1." ></td>
	<td class="line x" title="75:235	p j = was bought by which has the form X was bought by Y  where X = YouTube and Y = Google 2." ></td>
	<td class="line x" title="76:235	p j = was bought by which has the form Y was bought by X where X = Google and Y = YouTube The switching of X and Y positions in (3) and (4) ensures that acquired and was bought by are found to be paraphrases by the algorithm." ></td>
	<td class="line x" title="77:235	3.3 Locality Sensitive Hashing As described in Section 3.2, we find paraphrases of a phrase p i by finding its nearest neighbors based on cosine similarity between the feature vector of p i and other phrases." ></td>
	<td class="line x" title="78:235	To do this for all the phrases in the corpus, well have to compute the similarity between all vector pairs." ></td>
	<td class="line x" title="79:235	If n is the number of vectors and d is the dimensionality of the vector space, finding cosine similarity between each pair of vectors has time complexity O(n 2 d)." ></td>
	<td class="line x" title="80:235	This computation is infeasible for our corpus, since both n and d are large." ></td>
	<td class="line x" title="81:235	676 To solve this problem, we make use of Locality Sensitive Hashing (LSH)." ></td>
	<td class="line x" title="82:235	The basic idea behind LSH is that a LSH function creates a fingerprint for each vector such that if two vectors are similar, they are likely to have similar fingerprints." ></td>
	<td class="line x" title="83:235	The LSHfunction we use here was proposed by Charikar (2002)." ></td>
	<td class="line x" title="84:235	It represents a d dimensional vector by a stream of b bits (b lessmuch d) and has the property of preserving the cosine similarity between vectors, which is exactly what we want." ></td>
	<td class="line x" title="85:235	Ravichandran et al.(2005) have shown that by using the LSH nearest neighbors calculation can be done in O(nd) time." ></td>
	<td class="line x" title="87:235	1 . 4 Learning Surface Patterns Let r be a target relation." ></td>
	<td class="line x" title="88:235	Our task is to find a set of surface patterns S = {s 1 ,s 2 ,,s n } that express the target relation." ></td>
	<td class="line x" title="89:235	For example, consider the relation r =acquisition." ></td>
	<td class="line x" title="90:235	We want to find the set of patterns S that express this relation: S = {ACQUIRER acquired ACQUIREE, ACQUIRER bought ACQUIREE, ACQUIREE was bought by ACQUIRER,}." ></td>
	<td class="line x" title="91:235	The remainder of the section describes our model for learning surface patterns for target relations." ></td>
	<td class="line x" title="92:235	4.1 Model Assumption Paraphrases express the same meaning using different surface forms." ></td>
	<td class="line x" title="93:235	So if one knew a pattern that expresses a target relation, one could build more patterns for that relation by finding paraphrases for the surface phrase(s) in that pattern." ></td>
	<td class="line x" title="94:235	This is the basic assumption of our model." ></td>
	<td class="line x" title="95:235	For example, consider the seed pattern ACQUIRER acquired ACQUIREE for the target relation acquisition." ></td>
	<td class="line x" title="96:235	The surface phrase in the seed pattern is acquired." ></td>
	<td class="line x" title="97:235	Our model then assumes that we can obtain more surface patterns for acquisition by replacing acquired in the seed pattern with its paraphrases i.e. {bought, was bought by 2 ,}." ></td>
	<td class="line x" title="98:235	The resulting surface patterns are: 1 The details of the algorithm are omitted, but interested readers are encouraged to read Charikar (2002) and Ravichandran et al.(2005) 2 The  in was bought by indicates that the ACQUIRER and ACQUIREE arguments of the input phrase acquired need to be switched for the phrase was bought by." ></td>
	<td class="line x" title="100:235	{ACQUIRER bought ACQUIREE, ACQUIREE was bought by ACQUIRER,} 4.2 Surface Pattern Model Let r be a target relation." ></td>
	<td class="line x" title="101:235	Let SEED = {seed 1 , seed 2 ,, seed n } be the set of seed patterns that express the target relation." ></td>
	<td class="line x" title="102:235	For each seed i  SEED, we obtain the corresponding set of new patterns PAT i in two steps: 1." ></td>
	<td class="line x" title="103:235	We find the surface phrase, p i , using a seed and find the corresponding set of paraphrases, P i = {p i,1 ,p i,2 ,,p i,m }." ></td>
	<td class="line x" title="104:235	Each paraphrase, p i,j  P i , has with it an associated score which is similarity between p i and p i,j . 2." ></td>
	<td class="line x" title="105:235	In seed pattern, seed i , we replace the surface phrase, p i , with its paraphrases and obtain the set of new patterns PAT i = {pat i,1 ,pat i,2 ,,pat i,m }." ></td>
	<td class="line x" title="106:235	Each pattern has with it an associated score, which is the same as the score of the paraphrase from which it was obtained 3 . The patterns are ranked in the decreasing order of their scores." ></td>
	<td class="line x" title="107:235	After we obtain PAT i for each seed i  SEED, we obtain the complete set of patterns, PAT, for the target relation r as the union of all the individual pattern sets, i.e., PAT = PAT 1  PAT 2    PAT n . 5 Experimental Methodology In this section, we describe experiments to validate the main claims of the paper." ></td>
	<td class="line x" title="108:235	We first describe paraphrase acquisition, we then summarize our method for learning surface patterns, and finally describe the use of patterns for extracting relation instances." ></td>
	<td class="line x" title="109:235	5.1 Paraphrases Finding surface variations in text requires a large corpus." ></td>
	<td class="line x" title="110:235	The corpus needs to be orders of magnitude larger than that required for learning syntactic variations, since surface phrases are sparser than syntactic phrases." ></td>
	<td class="line x" title="111:235	For our experiments, we used a corpus of about 150GB (25 billion words) obtained from Google News 4 . It consists of few years worth of news data." ></td>
	<td class="line x" title="112:235	3 Ifapatternisgenerated from morethanone seed, weassign it its average score." ></td>
	<td class="line x" title="113:235	4 The corpus was cleaned to remove duplicate articles." ></td>
	<td class="line x" title="114:235	677 We POS tagged the corpus using Tnt tagger (Brants, 2000) and collected all phrases (n-grams) in the corpus that contained at least one verb, and had a noun or a noun-noun compound on either side." ></td>
	<td class="line x" title="115:235	We restricted the phrase length to at most five words." ></td>
	<td class="line x" title="116:235	We build a vector for each phrase as described in Section 3." ></td>
	<td class="line x" title="117:235	Tomitigate the problem of sparseness and co-reference to a certain extent, whenever we have a noun-noun compound in the X or Y positions, we treat it as bag of words." ></td>
	<td class="line x" title="118:235	For example, in the sentence Google Inc. acquired YouTube, Google and Inc. will be treated as separate features in the vector 5 . Once we have constructed all the vectors, we find the paraphrases for every phrase by finding its nearest neighbors as described in Section 3." ></td>
	<td class="line x" title="119:235	For our experiments, we set the number of random bits in the LSH function to 3000, and the similarity cut-off between vectors to 0.15." ></td>
	<td class="line x" title="120:235	We eventually end up with a resource containing over 2.5 million phrases such that each phrase is connected to its paraphrases." ></td>
	<td class="line x" title="121:235	5.2 Surface Patterns One claim of this paper is that we can find good surface patterns for a target relation by starting with a seed pattern." ></td>
	<td class="line x" title="122:235	To verify this, we study two target relations 6 : 1." ></td>
	<td class="line x" title="123:235	Acquisition: We define this as the relation between two companies such that one company acquired the other." ></td>
	<td class="line x" title="124:235	2." ></td>
	<td class="line x" title="125:235	Birthplace: We define this as the relation between a person and his/her birthplace." ></td>
	<td class="line x" title="126:235	For acquisition relation, we start with the surface patterns containing only the words buy and acquire: 1." ></td>
	<td class="line x" title="127:235	ACQUIRER bought ACQUIREE (and its variants, i.e. buy, buys and buying) 2." ></td>
	<td class="line x" title="128:235	ACQUIRER acquired ACQUIREE (and its variants, i.e. acquire, acquires and acquiring) 5 This adds some noise in the vectors, but we found that this results in better paraphrases." ></td>
	<td class="line x" title="129:235	6 Since we have to do all the annotations for evaluations on our own, we restricted our experiments to only two commonly used relations." ></td>
	<td class="line x" title="130:235	This results in a total of eight seed patterns." ></td>
	<td class="line x" title="131:235	For birthplace relation, we start with two seed patterns: 1." ></td>
	<td class="line x" title="132:235	PERSON was born in LOCATION 2." ></td>
	<td class="line x" title="133:235	PERSON was born at LOCATION." ></td>
	<td class="line x" title="134:235	We find other surface patterns for each of these relations by replacing the surface words in the seed patterns by their paraphrases, as described in Section 4." ></td>
	<td class="line x" title="135:235	5.3 Relation Extraction The purpose of learning surface patterns for a relation is to extract instances of that relation." ></td>
	<td class="line x" title="136:235	We use the surface patterns obtained for the relations acquisition and birthplace to extract instances of these relations from the LDC North American News Corpus." ></td>
	<td class="line x" title="137:235	This helps us to extrinsically evaluate the quality of the surface patterns." ></td>
	<td class="line x" title="138:235	6 Experimental Results In this section, we present the results of the experiments and analyze them." ></td>
	<td class="line x" title="139:235	6.1 Baselines It is hard to construct a baseline for comparing the quality of paraphrases, as there isnt much work in extracting surface level paraphrases using a monolingual corpus." ></td>
	<td class="line x" title="140:235	Toovercome this, we show the effect of reduction in corpus size on the quality of paraphrases, and compare the results informally to the other methods that produce syntactic paraphrases." ></td>
	<td class="line x" title="141:235	To compare the quality of the extraction patterns, and relation instances, we use the method presented by Ravichandran and Hovy (2002) as the baseline." ></td>
	<td class="line x" title="142:235	For each of the given relations, acquisition and birthplace, we use 10 seed instances, download the top 1000 results from the Google search engine for each instance, extract the sentences that contain the instances, and learn the set of baseline patterns for each relation." ></td>
	<td class="line x" title="143:235	We then apply these patterns to the test corpus and extract the corresponding baseline instances." ></td>
	<td class="line x" title="144:235	6.2 Evaluation Criteria Here we present the evaluation criteria we used to evaluate the performance on the different tasks." ></td>
	<td class="line x" title="145:235	678 Paraphrases Weestimate the quality ofparaphrases by annotating arandom sample ascorrect/incorrect and calculating the accuracy." ></td>
	<td class="line x" title="146:235	However, estimating the recall is difficult given that wedo not have a complete set of paraphrases for the input phrases." ></td>
	<td class="line x" title="147:235	Following Szpektor et al.(2004), instead of measuring recall, we calculate the average number of correct paraphrases per input phrase." ></td>
	<td class="line x" title="149:235	Surface Patterns We can calculate the precision (P) of learned patterns for each relation by annotating the extracted patterns as correct/incorrect." ></td>
	<td class="line x" title="150:235	However calculating the recall is a problem for the same reason as above." ></td>
	<td class="line x" title="151:235	But we can calculate the relative recall (RR) of the system against the baseline and vice versa." ></td>
	<td class="line x" title="152:235	The relativerecallRR S|B ofsystemS withrespect tosystem B can be calculated as: RR S|B = C S C B C B where C S is the number of correct patterns found by our system and C B is the number of correct patterns found by the baseline." ></td>
	<td class="line x" title="153:235	RR B|S can be found in asimilar way." ></td>
	<td class="line x" title="154:235	Relation Extraction We estimate the precision (P) of the extracted instances by annotating a random sample of instances as correct/incorrect." ></td>
	<td class="line x" title="155:235	While calculating the true recall here is not possible, even calculating the true relative recall of the system against the baseline is not possible as we can annotate only a small sample." ></td>
	<td class="line x" title="156:235	However, following Pantel et al.(2004), we assume that the recall of the baseline is 1 and estimate the relative recall RR S|B of the system S with respect to the baseline B using their respective precision scores P S and P B and number of instances extracted by them |S| and |B| as: RR S|B = P S |S| P B |B| 6.3 Gold Standard In this section, we describe the creation of gold standard for the different tasks." ></td>
	<td class="line x" title="158:235	Paraphrases We created the gold standard paraphrase test set by randomly selecting 50 phrases and their corresponding paraphrases from our collection of 2.5 million phrases." ></td>
	<td class="line x" title="159:235	For each test phrase, we asked two annotators to annotate its paraphrases as correct/incorrect." ></td>
	<td class="line x" title="160:235	The annotators were instructed to look for strict paraphrases i.e. equivalent phrases that can be substituted for each other." ></td>
	<td class="line x" title="161:235	To obtain the inter-annotator agreement, the two annotators annotated the test set separately." ></td>
	<td class="line x" title="162:235	The kappa statistic (Siegal and Castellan Jr., 1988) was  =0.63." ></td>
	<td class="line x" title="163:235	The interesting thing is that the annotators got this respectable kappa score without any prior training, which is hard to achieve when one annotates for a similar task like textual entailment." ></td>
	<td class="line x" title="164:235	Surface Patterns For the target relations, we asked two annotators to annotate the patterns for each relation as either precise or vague." ></td>
	<td class="line x" title="165:235	The annotators annotated the system as well as the baseline outputs." ></td>
	<td class="line x" title="166:235	We consider the precise patterns as correct and the vague as incorrect." ></td>
	<td class="line x" title="167:235	The intuition is that applying the vague patterns for extracting target relation instances might find some good instances, but will also find many bad ones." ></td>
	<td class="line x" title="168:235	For example, consider the following two patterns for the acquisition relation: ACQUIRER acquired ACQUIREE (5) ACQUIRER and ACQUIREE (6) Example (5) is a precise pattern as it clearly identifies the acquisition relation while example (6) is a vague pattern because it is too general and says nothing about the acquisition relation." ></td>
	<td class="line x" title="169:235	The kappa statistic between the two annotators for this task was  =0.72." ></td>
	<td class="line x" title="170:235	Relation Extraction We randomly sampled 50 instances of the acquisition and birthplace relations from the system and the baseline outputs." ></td>
	<td class="line x" title="171:235	We asked two annotators to annotate the instances as correct/incorrect." ></td>
	<td class="line x" title="172:235	The annotators marked an instance as correct only if both the entities and the relation between them were correct." ></td>
	<td class="line x" title="173:235	To make their task easier, the annotators were provided the context for each instance, and were free to use any resources at their disposal (including a web search engine), to verify the correctness of the instances." ></td>
	<td class="line x" title="174:235	The annotators found that the annotation for this task was much easier than the previous two; the few disagreements they had were due to ambiguity of some of the instances." ></td>
	<td class="line x" title="175:235	The kappa statistic for this task was  =0.91." ></td>
	<td class="line x" title="176:235	679 Annotator Accuracy Average # correct paraphrases Annotator 1 67.31% 4.2 Annotator 2 74.27% 4.28 Table 1: Quality of paraphrases are being distributedto approved a revision to the have been distributed to unanimously approved a new are being handed out to approved an annual were distributed to will consider adopting a are handing out approved a revised will be distributed to all approved a new Table 2: Example paraphrases 6.4 Result Summary Table 1 shows the results of annotating the paraphrases test set." ></td>
	<td class="line x" title="177:235	We do not have a baseline to compare against but we can analyze them in light of numbers reported previously for syntactic paraphrases." ></td>
	<td class="line x" title="178:235	DIRT (Lin and Pantel, 2001) and TEASE (Szpektor et al., 2004) report accuracies of 50.1% and 44.3% respectively compared to our average accuracy across two annotators of 70.79%." ></td>
	<td class="line x" title="179:235	The average number of paraphrases per phrase is however 10.1 and 5.5 for DIRT and TEASE respectively compared to our 4.2." ></td>
	<td class="line x" title="180:235	One reason why this number is lower is that our test set contains completely random phrases from our set (2.5 million phrases): some of these phrases are rare and have very few paraphrases." ></td>
	<td class="line x" title="181:235	Table 2 shows some paraphrases generated by our system for the phrases are being distributed to and approved a revision to the." ></td>
	<td class="line x" title="182:235	Table 3 shows the results on the quality of surface patterns for the two relations." ></td>
	<td class="line x" title="183:235	It can be observed that our method outperforms the baseline by a wide margin in both precision and relative recall." ></td>
	<td class="line x" title="184:235	Table 4 shows someexample patterns learned by our system." ></td>
	<td class="line x" title="185:235	Table 5 shows the results of the quality of extracted instances." ></td>
	<td class="line x" title="186:235	Our system obtains very high precision scores but suffers in relative recall given that the baseline with its very general patterns is likely to find a huge number of instances (though a very small portion of them are correct)." ></td>
	<td class="line x" title="187:235	Table 6 shows some example instances we extracted." ></td>
	<td class="line x" title="188:235	acquisition birthplace X agreed to buy Y X , who was born in Y X , which acquired Y X , was born in Y X completed its acquisition of Y X was raised in Y X has acquired Y X was born in NNNN a in Y X purchased Y X , born in Y a Each N here is a placeholder for a number from 0 to 9." ></td>
	<td class="line x" title="189:235	Table 4: Example extraction templates acquisition birthplace 1." ></td>
	<td class="line x" title="190:235	Huntington Bancshares Inc. agreed to acquire Reliance Bank 1." ></td>
	<td class="line x" title="191:235	Cyril Andrew Ponnamperuma was born in Galle 2." ></td>
	<td class="line x" title="192:235	Sony bought Columbia Pictures 2." ></td>
	<td class="line x" title="193:235	Cook was born in NNNN in Devonshire 3." ></td>
	<td class="line x" title="194:235	Hanson Industries buys Kidde Inc. 3." ></td>
	<td class="line x" title="195:235	Tansey was born in Cincinnati 4." ></td>
	<td class="line x" title="196:235	Casino America inc. agreed to buy Grand Palais 4." ></td>
	<td class="line x" title="197:235	Tsoi was born inNNNN in Uzbekistan 5." ></td>
	<td class="line x" title="198:235	Tidewater inc. acquired Hornbeck Offshore Services Inc. 5." ></td>
	<td class="line x" title="199:235	Mrs. Totenberg was born in San Francisco Table 6: Example instances 6.5 Discussion and Error Analysis We studied the effect of the decrease in size of the available raw corpus on the quality of the acquired paraphrases." ></td>
	<td class="line x" title="200:235	We used about 10% of our original corpus to learn the surface paraphrases and evaluated them." ></td>
	<td class="line x" title="201:235	The precision, and the average number of correct paraphrases are calculated on the same test set, as described in Section 6.2." ></td>
	<td class="line x" title="202:235	The performance drop on using 10% of the original corpus is significant (11.41% precision and on an average 1 correct paraphrase per phrase), which shows that we indeed need a large amount of data to learn good quality surface paraphrases." ></td>
	<td class="line x" title="203:235	One reason for this drop is also that when we use only 10% of the original data, for some of the phrases from the test set, we do not find any paraphrases (thus resulting in 0% accuracy for them)." ></td>
	<td class="line x" title="204:235	This is not unexpected, as the larger resource would have a much larger recall, which again points at the advantage of using a large data set." ></td>
	<td class="line x" title="205:235	Another reason for this performance drop could be the parameter settings: We found that the quality of learned paraphrases depended greatly on the various cut-offs used." ></td>
	<td class="line x" title="206:235	While we adjusted our model 680 Relation Method # Patterns Annotator 1 Annotator 2 P RR P RR Acquisition Baseline 160 55% 13.02% 60% 11.16% Paraphrase Method 231 83.11% 28.40% 93.07% 25% Birthplace Baseline 16 31.35% 15.38% 31.25% 15.38% Paraphrase Method 16 81.25% 40% 81.25% 40% Table 3: Quality of Extraction Patterns Relation Method # Patterns Annotator 1 Annotator 2 P RR P RR Acquisition Baseline 1,261,986 6% 100% 2% 100% Paraphrase Method 3875 88% 4.5% 82% 12.59% Birthplace Baseline 979,607 4% 100% 2% 100% Paraphrase Method 1811 98% 4.53% 98% 9.06% Table 5: Quality of instances parameters for working with smaller sized data, it is conceivable that we did not find the ideal setting for them." ></td>
	<td class="line x" title="207:235	So we consider these numbers to be a lower bound." ></td>
	<td class="line x" title="208:235	But even then, these numbers clearly indicate the advantage of using more data." ></td>
	<td class="line x" title="209:235	We also manually inspected our paraphrases." ></td>
	<td class="line x" title="210:235	We found that the problem of antonyms was somewhat less pronounced due to our use of a large corpus, but they still were the major source of error." ></td>
	<td class="line x" title="211:235	For example, our system finds the phrase sell as a paraphrase for buy." ></td>
	<td class="line x" title="212:235	We need to deal with this problem separately in the future (may be as a postprocessing step using a list of antonyms)." ></td>
	<td class="line x" title="213:235	Moving to the task of relation extraction, we see from table 5 that our system has a much lower relative recall compared to the baseline." ></td>
	<td class="line x" title="214:235	This was expected as the baseline method learns some very general patterns, which are likely to extract some good instances, even though they result in a huge hit to its precision." ></td>
	<td class="line x" title="215:235	However, our system was able to obtain this performance using very few seeds." ></td>
	<td class="line x" title="216:235	So an increase in the number of input seeds, is likely to increase the relative recall of the resource." ></td>
	<td class="line x" title="217:235	The question however remains as to what good seeds might be." ></td>
	<td class="line x" title="218:235	It is clear that it is much harder to come up with good seed patterns (that our system needs), than seed instances (that the baseline needs)." ></td>
	<td class="line x" title="219:235	But there are some obvious ways to overcome this problem." ></td>
	<td class="line x" title="220:235	One way is to bootstrap." ></td>
	<td class="line x" title="221:235	We can look at the paraphrases of the seed patterns and use them to obtain more patterns." ></td>
	<td class="line x" title="222:235	Ourinitial experiments withthis method using handpicked seeds showed good promise." ></td>
	<td class="line x" title="223:235	However, we need to investigate automating this approach." ></td>
	<td class="line x" title="224:235	Another method is to use the good patterns from the baseline system and use them as seeds for our system." ></td>
	<td class="line x" title="225:235	We plan to investigate this approach as well." ></td>
	<td class="line x" title="226:235	One reason, why we have seen good preliminary results using these approaches (for improving recall), we believe, is that the precision of the paraphrases is good." ></td>
	<td class="line x" title="227:235	So either a seed doesnt produce any new patterns or it produces good patterns, thus keeping the precision of the system high while increasing relative recall." ></td>
	<td class="line x" title="228:235	7 Conclusion Paraphrases are an important technique to handle variations in language." ></td>
	<td class="line x" title="229:235	Given their utility in many NLP tasks, it is desirable that we come up with methods that produce good quality paraphrases." ></td>
	<td class="line x" title="230:235	We believe that the paraphrase acquisition method presented here is a step towards this very goal." ></td>
	<td class="line x" title="231:235	We have shownthat high precision surface paraphrases canbe obtained by using distributional similarity on a large corpus." ></td>
	<td class="line x" title="232:235	We made use of some recent advances in theoretical computer science to make this task scalable." ></td>
	<td class="line x" title="233:235	We have also shown that these paraphrases can be used to obtain high precision extraction patterns for information extraction." ></td>
	<td class="line x" title="234:235	While we believe that more work needs to be done to improve the system recall (some of which we are investigating), this seems to be a good first step towards developing a minimally supervised, easy to implement, and scalable relation extraction system." ></td>
	<td class="line x" title="235:235	681" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P08-1089
Pivot Approach for Extracting Paraphrase Patterns from Bilingual Corpora
Zhao, Shiqi;Wang, Haifeng;Liu, Ting;Li, Sheng;"></td>
	<td class="line x" title="1:250	Proceedings of ACL-08: HLT, pages 780788, Columbus, Ohio, USA, June 2008." ></td>
	<td class="line x" title="2:250	c2008 Association for Computational Linguistics Pivot Approach for Extracting Paraphrase Patterns from Bilingual Corpora Shiqi Zhao1, Haifeng Wang2, Ting Liu1, Sheng Li1 1Harbin Institute of Technology, Harbin, China {zhaosq,tliu,lisheng}@ir.hit.edu.cn 2Toshiba (China) Research and Development Center, Beijing, China wanghaifeng@rdc.toshiba.com.cn Abstract Paraphrase patterns are useful in paraphrase recognition and generation." ></td>
	<td class="line x" title="3:250	In this paper, we present a pivot approach for extracting paraphrase patterns from bilingual parallel corpora, whereby the English paraphrase patterns are extracted using the sentences in a foreign language as pivots." ></td>
	<td class="line x" title="4:250	We propose a loglinear model to compute the paraphrase likelihood of two patterns and exploit feature functions based on maximum likelihood estimation (MLE) and lexical weighting (LW)." ></td>
	<td class="line x" title="5:250	Using the presented method, we extract over 1,000,000 pairs of paraphrase patterns from 2M bilingual sentence pairs, the precision of which exceeds 67%." ></td>
	<td class="line x" title="6:250	The evaluation results show that: (1) The pivot approach is effective in extracting paraphrase patterns, which significantly outperforms the conventional method DIRT." ></td>
	<td class="line x" title="7:250	Especially, the log-linear model with the proposed feature functions achieves high performance." ></td>
	<td class="line x" title="8:250	(2) The coverage of the extracted paraphrase patterns is high, which is above 84%." ></td>
	<td class="line x" title="9:250	(3) The extracted paraphrase patterns can be classified into 5 types, which are useful in various applications." ></td>
	<td class="line x" title="10:250	1 Introduction Paraphrases are different expressions that convey the same meaning." ></td>
	<td class="line x" title="11:250	Paraphrases are important in plenty of natural language processing (NLP) applications, such as question answering (QA) (Lin and Pantel, 2001; Ravichandran and Hovy, 2002), machine translation (MT) (Kauchak and Barzilay, 2006; Callison-Burch et al., 2006), multi-document summarization (McKeown et al., 2002), and natural language generation (Iordanskaja et al., 1991)." ></td>
	<td class="line x" title="12:250	Paraphrase patterns are sets of semantically equivalent patterns, in which a pattern generally contains two parts, i.e., the pattern words and slots." ></td>
	<td class="line x" title="13:250	For example, in the pattern X solves Y, solves is the pattern word, while X and Y are slots." ></td>
	<td class="line x" title="14:250	One can generate a text unit (phrase or sentence) by filling the pattern slots with specific words." ></td>
	<td class="line x" title="15:250	Paraphrase patterns are useful in both paraphrase recognition and generation." ></td>
	<td class="line x" title="16:250	In paraphrase recognition, if two text units match a pair of paraphrase patterns and the corresponding slot-fillers are identical, they can be identified as paraphrases." ></td>
	<td class="line oc" title="17:250	In paraphrase generation, a text unit that matches a pattern P can be rewritten using the paraphrase patterns of P. Avarietyofmethodshavebeenproposedonparaphrase patterns extraction (Lin and Pantel, 2001; Ravichandran and Hovy, 2002; Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003; Pang et al., 2003; Szpektor et al., 2004)." ></td>
	<td class="line n" title="18:250	However, these methods have some shortcomings." ></td>
	<td class="line n" title="19:250	Especially, the precisions of the paraphrase patterns extracted with these methods are relatively low." ></td>
	<td class="line x" title="20:250	In this paper, we extract paraphrase patterns from bilingual parallel corpora based on a pivot approach." ></td>
	<td class="line x" title="21:250	We assume that if two English patterns are aligned with the same pattern in another language, they are likely to be paraphrase patterns." ></td>
	<td class="line x" title="22:250	This assumption is an extension of the one presented in (Bannard and Callison-Burch, 2005), which was used for deriving phrasal paraphrases from bilingual corpora." ></td>
	<td class="line x" title="23:250	Our method involves three steps: (1) corpus preprocessing, including English monolingual dependency 780 parsing and English-foreign language word alignment,(2)alignedpatternsinduction,whichproduces English patterns along with the aligned pivot patterns in the foreign language, (3) paraphrase patternsextraction, inwhichparaphrasepatternsareextracted based on a log-linear model." ></td>
	<td class="line x" title="24:250	Our contributions are as follows." ></td>
	<td class="line x" title="25:250	Firstly, we are the first to use a pivot approach to extract paraphrase patterns from bilingual corpora, though similar methods have been used for learning phrasal paraphrases." ></td>
	<td class="line x" title="26:250	Our experiments show that the pivot approachsignificantlyoutperformsconventionalmethods." ></td>
	<td class="line x" title="27:250	Secondly, we propose a log-linear model for computing the paraphrase likelihood." ></td>
	<td class="line x" title="28:250	Besides, we use feature functions based on maximum likelihood estimation (MLE) and lexical weighting (LW), whichareeffectiveinextractingparaphrasepatterns." ></td>
	<td class="line x" title="29:250	Using the proposed approach, we extract over 1,000,000 pairs of paraphrase patterns from 2M bilingual sentence pairs, the precision of which is above67%." ></td>
	<td class="line x" title="30:250	Experimentalresultsshowthatthepivot approachevidentlyoutperformsDIRT,awellknown methodthatextractsparaphrasepatternsfrommonolingual corpora (Lin and Pantel, 2001)." ></td>
	<td class="line x" title="31:250	Besides, the log-linear model is more effective than the conventional model presented in (Bannard and CallisonBurch, 2005)." ></td>
	<td class="line x" title="32:250	In addition, the coverage of the extracted paraphrase patterns is high, which is above 84%." ></td>
	<td class="line x" title="33:250	Further analysis shows that 5 types of paraphrase patterns can be extracted with our method, which can by used in multiple NLP applications." ></td>
	<td class="line x" title="34:250	The rest of this paper is structured as follows." ></td>
	<td class="line x" title="35:250	Section 2 reviews related work on paraphrase patterns extraction." ></td>
	<td class="line x" title="36:250	Section 3 presents our method in detail." ></td>
	<td class="line x" title="37:250	We evaluate the proposed method in Section 4, and finally conclude this paper in Section 5." ></td>
	<td class="line x" title="38:250	2 Related Work Paraphrase patterns have been learned and used in information extraction (IE) and answer extraction of QA." ></td>
	<td class="line x" title="39:250	For example, Lin and Pantel (2001) proposed a method (DIRT), in which they obtained paraphrase patterns from a parsed monolingual corpus based on an extended distributional hypothesis, where if two paths in dependency trees tend to occur in similar contexts it is hypothesized that the meanings of the paths are similar." ></td>
	<td class="line x" title="40:250	The examples of obtained para(1) X solves Y Y is solved by X X finds a solution to Y  (2) born in <ANSWER> , <NAME> <NAME> was born on <ANSWER> , <NAME> ( <ANSWER>  (3) ORGANIZATION decides  ORGANIZATION confirms   Table 1: Examples of paraphrase patterns extracted with the methods of Lin and Pantel (2001), Ravichandran and Hovy (2002), and Shinyama et al.(2002)." ></td>
	<td class="line x" title="42:250	phrase patterns are shown in Table 1 (1)." ></td>
	<td class="line x" title="43:250	Based on the same hypothesis as above, some methodsextractedparaphrasepatternsfromtheweb." ></td>
	<td class="line x" title="44:250	For instance, Ravichandran and Hovy (2002) defined a question taxonomy for their QA system." ></td>
	<td class="line x" title="45:250	They then used hand-crafted examples of each question type as queries to retrieve paraphrase patterns from the web." ></td>
	<td class="line x" title="46:250	For instance, for the question type BIRTHDAY, The paraphrase patterns produced by their method can be seen in Table 1 (2)." ></td>
	<td class="line x" title="47:250	Similar methods have also been used by Ibrahim et al.(2003) and Szpektor et al.(2004)." ></td>
	<td class="line x" title="50:250	The main disadvantage of the above methods is that the precisions of the learned paraphrase patterns are relatively low." ></td>
	<td class="line x" title="51:250	For instance, the precisions of the paraphrase patterns reported in (Lin and Pantel, 2001), (Ibrahim et al., 2003), and (Szpektor et al., 2004) are lower than 50%." ></td>
	<td class="line x" title="52:250	Ravichandran and Hovy (2002) did not directly evaluate the precision of the paraphrase patterns extracted using their method." ></td>
	<td class="line x" title="53:250	However, the performance of their method is dependent on the hand-crafted queries for web mining." ></td>
	<td class="line x" title="54:250	Shinyama et al.(2002) presented a method that extracted paraphrase patterns from multiple news articles about the same event." ></td>
	<td class="line x" title="56:250	Their method was based on the assumption that NEs are preserved across paraphrases." ></td>
	<td class="line x" title="57:250	Thus the method acquired paraphrase patterns from sentence pairs that share comparable NEs." ></td>
	<td class="line x" title="58:250	Some examples can be seen in Table 1 (3)." ></td>
	<td class="line x" title="59:250	The disadvantage of this method is that it greatly relies on the number of NEs in sentences." ></td>
	<td class="line oc" title="60:250	The preci781 start Palestinian suicide bomberblew himself up in SLOT1 on SLOT2 killing SLOT3 other people and injuring wounding SLOT4 end detroit the *e* a s *e* building buildingin detroit flattened ground levelled to blasted leveled *e* was reduced razed leveled to down rubble into ashes *e* to *e* (1) (2) Figure 1: Examples of paraphrase patterns extracted by Barzilay and Lee (2003) and Pang et al.(2003)." ></td>
	<td class="line x" title="62:250	sion of the extracted patterns may sharply decrease if the sentences do not contain enough NEs." ></td>
	<td class="line oc" title="63:250	Barzilay and Lee (2003) applied multi-sequence alignment (MSA) to parallel news sentences and induced paraphrase patterns for generating new sentences (Figure 1 (1))." ></td>
	<td class="line x" title="64:250	Pang et al.(2003) built finite state automata (FSA) from semantically equivalent translation sets based on syntactic alignment." ></td>
	<td class="line x" title="66:250	The learned FSAs could be used in paraphrase representation and generation (Figure 1 (2))." ></td>
	<td class="line x" title="67:250	Obviously, it is difficult for a sentence to match such complicated patterns, especially if the sentence is not from the same domain in which the patterns are extracted." ></td>
	<td class="line x" title="68:250	Bannard and Callison-Burch (2005) first exploited bilingual corpora for phrasal paraphrase extraction." ></td>
	<td class="line x" title="69:250	They assumed that if two English phrases e1 and e2 are aligned with the same phrase c in another language, these two phrases may be paraphrases." ></td>
	<td class="line x" title="70:250	Specifically, they computed the paraphrase probability in terms of the translation probabilities: p(e2|e1) = summationdisplay c pMLE(c|e1)pMLE(e2|c) (1) In Equation (1), pMLE(c|e1) and pMLE(e2|c) are the probabilities of translating e1 to c and c to e2, which are computed based on MLE: pMLE(c|e1) = count(c,e1)summationtext cprime count(cprime,e1) (2) where count(c,e1) is the frequency count that phrases c and e1 are aligned in the corpus." ></td>
	<td class="line x" title="71:250	pMLE(e2|c) is computed in the same way." ></td>
	<td class="line x" title="72:250	This method proved effective in extracting high quality phrasal paraphrases." ></td>
	<td class="line x" title="73:250	As a result, we extend it to paraphrase pattern extraction in this paper." ></td>
	<td class="line x" title="74:250	ST E (take) should We take market into consideration take market into consideration take into consideration PST E (take) first T E demand demand Figure 2: Examples of a subtree and a partial subtree." ></td>
	<td class="line x" title="75:250	3 Proposed Method 3.1 Corpus Preprocessing In this paper, we use English paraphrase patterns extraction as a case study." ></td>
	<td class="line x" title="76:250	An English-Chinese (EC) bilingual parallel corpus is employed for training." ></td>
	<td class="line x" title="77:250	The Chinese part of the corpus is used as pivots to extract English paraphrase patterns." ></td>
	<td class="line x" title="78:250	We conduct wordalignmentwithGiza++(OchandNey,2000)in both directions and then apply the grow-diag heuristic (Koehn et al., 2005) for symmetrization." ></td>
	<td class="line x" title="79:250	Since the paraphrase patterns are extracted from dependency trees, we parse the English sentences in the corpus with MaltParser (Nivre et al., 2007)." ></td>
	<td class="line x" title="80:250	Let SE be an English sentence, TE the parse tree of SE, e a word of SE, we define the subtree and partial subtree following the definitions in (Ouangraoua et al., 2007)." ></td>
	<td class="line x" title="81:250	In detail, a subtree STE(e) is a particular connected subgraph of the tree TE, which is rooted at e and includes all the descendants of e. A partial subtree PSTE(e) is a connected subgraphofthesubtreeSTE(e), whichisrootedatebut does not necessarily include all the descendants of e. For instance, for the sentence We should first take market demand into consideration, STE(take) and PSTE(take) are shown in Figure 21." ></td>
	<td class="line x" title="82:250	3.2 Aligned Patterns Induction To induce the aligned patterns, we first induce the English patterns using the subtrees and partial subtrees." ></td>
	<td class="line x" title="83:250	Then, we extract the pivot Chinese patterns aligning to the English patterns." ></td>
	<td class="line x" title="84:250	1Note that, a subtree may contain several partial subtrees." ></td>
	<td class="line x" title="85:250	In this paper, all the possible partial subtrees are considered when extracting paraphrase patterns." ></td>
	<td class="line x" title="86:250	782 Algorithm 1: Inducing an English pattern 1: Input: words in STE(e) : wiwi+1wj 2: Input: PE(e) =  3: For each wk (i  k  j) 4: If wk is in PSTE(e) 5: Append wk to the end of PE(e) 6: Else 7: Append POS(wk) to the end of PE(e) 8: End For Algorithm 2: Inducing an aligned pivot pattern 1: Input: SC = t1t2tn 2: Input: PC =  3: For each tl (1  l  n) 4: If tl is aligned with wk in SE 5: If wk is a word in PE(e) 6: Append tl to the end of PC 7: If POS(wk) is a slot in PE(e) 8: Append POS(wk) to the end of PC 9: End For Step-1InducingEnglishpatterns." ></td>
	<td class="line x" title="87:250	In this paper, an English pattern PE(e) is a string comprising words and part-of-speech (POS) tags." ></td>
	<td class="line x" title="88:250	Our intuition for inducing an English pattern is that a partial subtree PSTE(e) can be viewed as a unit that conveys a definite meaning, though the words in PSTE(e) may not be continuous." ></td>
	<td class="line x" title="89:250	For example, PSTE(take) in Figure 2 contains words take  into consideration." ></td>
	<td class="line x" title="90:250	Therefore, we may extract take X into consideration as a pattern." ></td>
	<td class="line x" title="91:250	In addition, the words that are in STE(e) but not in PSTE(e) (denoted as STE(e)/PSTE(e)) are also useful for inducing patterns, since they can constrain the pattern slots." ></td>
	<td class="line x" title="92:250	In the example in Figure 2, the word demand indicates that a noun can be filled in the slot X and the pattern may have the form take NN into consideration." ></td>
	<td class="line x" title="93:250	Based on this intuition, we induce an English pattern PE(e) as in Algorithm 12." ></td>
	<td class="line x" title="94:250	For the example in Figure 2, the generated pattern PE(take) is take NN NN into consideration." ></td>
	<td class="line x" title="95:250	Note that the patterns induced in this way are quite specific, since the POS of each word in STE(e)/PSTE(e) forms a slot." ></td>
	<td class="line x" title="96:250	Such patterns are difficult to be matched in applications." ></td>
	<td class="line x" title="97:250	We there2POS(wk) in Algorithm 1 denotes the POS tag of wk." ></td>
	<td class="line x" title="98:250	NN_1NN_2 NN_1NN_2 NN_1NN_2 considered byis NN_1 consider NN_2 Figure 3: Aligned patterns with numbered slots." ></td>
	<td class="line x" title="99:250	fore take an additional step to simplify the patterns." ></td>
	<td class="line x" title="100:250	Let ei and ej be two words in STE(e)/PSTE(e), whose POS posi and posj are slots in PE(e)." ></td>
	<td class="line x" title="101:250	If ei is a descendant of ej in the parse tree, we remove posi from PE(e)." ></td>
	<td class="line x" title="102:250	For the example above, the POS of market is removed, since it is the descendant of demand, whose POS also forms a slot." ></td>
	<td class="line x" title="103:250	The simplified pattern is take NN into consideration." ></td>
	<td class="line x" title="104:250	Step-2 Extracting pivot patterns." ></td>
	<td class="line x" title="105:250	For each English pattern PE(e), we extract an aligned Chinese pivot pattern PC." ></td>
	<td class="line x" title="106:250	Let a Chinese sentence SC be the translation of the English sentence SE, PE(e) a pattern induced from SE, we extract the pivot pattern PC aligning to PE(e) as in Algorithm 2." ></td>
	<td class="line x" title="107:250	Note that the Chinese patterns are not extracted from parse trees." ></td>
	<td class="line x" title="108:250	They are only sequences of Chinese words and POSes that are aligned with English patterns." ></td>
	<td class="line x" title="109:250	A pattern may contain two or more slots sharing the same POS." ></td>
	<td class="line x" title="110:250	To distinguish them, we assign a number to each slot in the aligned E-C patterns." ></td>
	<td class="line x" title="111:250	In detail, the slots having identical POS inPC are numbered incrementally (i.e., 1,2,3), while each slot in PE(e) is assigned the same number as its aligned slot in PC." ></td>
	<td class="line x" title="112:250	The examples of the aligned patterns with numbered slots are illustrated in Figure 3." ></td>
	<td class="line x" title="113:250	3.3 Paraphrase Patterns Extraction As mentioned above, if patterns e1 and e2 are aligned with the same pivot pattern c, e1 and e2 may be paraphrase patterns." ></td>
	<td class="line x" title="114:250	The paraphrase likelihood can be computed using Equation (1)." ></td>
	<td class="line x" title="115:250	However, we find that using only the MLE based probabilities can suffer from data sparseness." ></td>
	<td class="line x" title="116:250	In order to exploit more and richer information to estimate the paraphrase likelihood, we propose a log-linear model: score(e2|e1) = summationdisplay c exp[ Nsummationdisplay i=1 ihi(e1,e2,c)] (3) where hi(e1,e2,c) is a feature function and i is the 783 weight." ></td>
	<td class="line x" title="117:250	In this paper, 4 feature functions are used in our log-linear model, which include: h1(e1,e2,c) = scoreMLE(c|e1) h2(e1,e2,c) = scoreMLE(e2|c) h3(e1,e2,c) = scoreLW(c|e1) h4(e1,e2,c) = scoreLW(e2|c) Feature functions h1(e1,e2,c) and h2(e1,e2,c) are based on MLE." ></td>
	<td class="line x" title="118:250	scoreMLE(c|e) is computed as: scoreMLE(c|e) = logpMLE(c|e) (4) scoreMLE(e|c) is computed in the same way." ></td>
	<td class="line x" title="119:250	h3(e1,e2,c) and h4(e1,e2,c) are based on LW." ></td>
	<td class="line x" title="120:250	LW was originally used to validate the quality of a phrase translation pair in MT (Koehn et al., 2003)." ></td>
	<td class="line x" title="121:250	It checks how well the words of the phrases translate to each other." ></td>
	<td class="line x" title="122:250	This paper uses LW to measure the quality of aligned patterns." ></td>
	<td class="line x" title="123:250	We define scoreLW(c|e) as the logarithm of the lexical weight3: scoreLW(c|e) = 1 n nsummationdisplay i=1 log( 1|{j|(i,j)  a}| summationdisplay (i,j)a w(ci|ej)) (5) where a denotes the word alignment between c and e. n is the number of words in c. ci and ej are words of c and e. w(ci|ej) is computed as follows: w(ci|ej) = count(ci,ej)summationtext cprimei count(cprimei,ej) (6) where count(ci,ej) is the frequency count of the aligned word pair (ci,ej) in the corpus." ></td>
	<td class="line x" title="124:250	scoreLW(e|c) is computed in the same manner." ></td>
	<td class="line x" title="125:250	In our experiments, we set a threshold T. If the score between e1 and e2 based on Equation (3) exceeds T, e2 is extracted as the paraphrase of e1." ></td>
	<td class="line x" title="126:250	3.4 Parameter Estimation Five parameters need to be estimated, i.e., 1, 2, 3, 4 in Equation (3), and the threshold T. To estimate the parameters, we first construct a development set." ></td>
	<td class="line x" title="127:250	In detail, we randomly sample 7,086 3The logarithm of the lexical weight is divided by n so as not to penalize long patterns." ></td>
	<td class="line x" title="128:250	groups of aligned E-C patterns that are obtained as described in Section 3.2." ></td>
	<td class="line x" title="129:250	The English patterns in each group are all aligned with the same Chinese pivot pattern." ></td>
	<td class="line x" title="130:250	We then extract paraphrase patterns fromthealignedpatternsasdescribedinSection3.3." ></td>
	<td class="line x" title="131:250	In this process, we set i = 1 (i = 1,,4) and assign T a minimum value, so as to obtain all possible paraphrase patterns." ></td>
	<td class="line x" title="132:250	A total of 4,162 pairs of paraphrase patterns have been extracted and manually labeled as 1 (correct paraphrase patterns) or 0 (incorrect)." ></td>
	<td class="line x" title="133:250	Here, two patterns are regarded as paraphrase patterns if they can generate paraphrase fragments by filling the corresponding slots with identical words." ></td>
	<td class="line x" title="134:250	We use gradient descent algorithm (Press et al., 1992) to estimate the parameters." ></td>
	<td class="line x" title="135:250	For each set of parameters, we compute the precision P, recall R, and f-measure F as: P = |set1set2||set1| , R = |set1set2||set2| , F = 2PRP+R, whereset1denotesthesetofparaphrasepatternsextracted under the current parameters." ></td>
	<td class="line x" title="136:250	set2 denotes the set of manually labeled correct paraphrase patterns." ></td>
	<td class="line x" title="137:250	We select the parameters that can maximize the F-measure on the development set4." ></td>
	<td class="line x" title="138:250	4 Experiments The E-Cparallel corpus inour experiments wasconstructedusingseveralLDCbilingualcorpora5." ></td>
	<td class="line x" title="139:250	After filtering sentences that are too long (> 40 words) or too short (< 5 words), 2,048,009 pairs of parallel sentences were retained." ></td>
	<td class="line x" title="140:250	We used two constraints in the experiments to improve the efficiency of computation." ></td>
	<td class="line x" title="141:250	First, only subtrees containing no more than 10 words were used to induce English patterns." ></td>
	<td class="line x" title="142:250	Second, although any POS tag can form a slot in the induced patterns, we only focused on three kinds of POSes in the experiments, i.e., nouns (tags include NN, NNS, NNP, NNPS), verbs (VB, VBD, VBG, VBN, VBP, VBZ), and adjectives (JJ, JJS, JJR)." ></td>
	<td class="line x" title="143:250	In addition, we constrained that a pattern must contain at least one content word 4The parameters are: 1 = 0.0594137, 2 = 0.995936, 3 = 0.0048954, 4 = 1.47816, T = 10.002." ></td>
	<td class="line x" title="144:250	5The corpora include LDC2000T46, LDC2000T47, LDC2002E18, LDC2002T01, LDC2003E07, LDC2003E14, LDC2003T17, LDC2004E12, LDC2004T07, LDC2004T08, LDC2005E83, LDC2005T06, LDC2005T10, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006T04, LDC2007T02, LDC2007T09." ></td>
	<td class="line x" title="145:250	784 Method #PP (pairs) Precision LL-Model 1,058,624 67.03% MLE-Model 1,015,533 60.60% DIRT top-1 1,179 19.67% DIRT top-5 5,528 18.73% Table 2: Comparison of paraphrasing methods." ></td>
	<td class="line x" title="146:250	so as to filter patterns like the [NN 1]." ></td>
	<td class="line x" title="147:250	4.1 Evaluation of the Log-linear Model As previously mentioned, in the log-linear model of this paper, we use both MLE based and LW based feature functions." ></td>
	<td class="line x" title="148:250	In this section, we evaluate the log-linear model (LL-Model) and compare it with the MLE based model (MLE-Model) presented by Bannard and Callison-Burch (2005)6." ></td>
	<td class="line x" title="149:250	We extracted paraphrase patterns using two models, respectively." ></td>
	<td class="line x" title="150:250	From the results of each model, we randomly picked 3,000 pairs of paraphrase patterns to evaluate the precision." ></td>
	<td class="line x" title="151:250	The 6,000 pairs of paraphrase patterns were mixed and presented to the human judges, so that the judges cannot know by which model each pair was produced." ></td>
	<td class="line x" title="152:250	The sampled patterns were then manually labeled and the precision was computed as described in Section 3.4." ></td>
	<td class="line x" title="153:250	The number of the extracted paraphrase patterns (#PP) and the precision are depicted in the first two lines of Table 2." ></td>
	<td class="line x" title="154:250	We can see that the numbers of paraphrase patterns extracted using the two models are comparable." ></td>
	<td class="line x" title="155:250	However, the precision of LLModel is significantly higher than MLE-Model." ></td>
	<td class="line x" title="156:250	Actually, MLE-Model is a special case of LLModel and the enhancement of the precision is mainly due to the use of LW based features." ></td>
	<td class="line x" title="157:250	It is not surprising, since Bannard and CallisonBurch (2005) have pointed out that word alignment error is the major factor that influences the performance of the methods learning paraphrases from bilingual corpora." ></td>
	<td class="line x" title="158:250	The LW based features validate the quality of word alignment and assign low scores to those aligned E-C pattern pairs with incorrect alignment." ></td>
	<td class="line x" title="159:250	Hence the precision can be enhanced." ></td>
	<td class="line x" title="160:250	6In this experiment, we also estimated a threshold Tprime for MLE-Model using the development set (Tprime = 5.1)." ></td>
	<td class="line x" title="161:250	The pattern pairs whose score based on Equation (1) exceed Tprime were extracted as paraphrase patterns." ></td>
	<td class="line x" title="162:250	4.2 Comparison with DIRT It is necessary to compare our method with another paraphrase patterns extraction method." ></td>
	<td class="line n" title="163:250	However, it is difficult to find methods that are suitable for comparison." ></td>
	<td class="line nc" title="164:250	Some methods only extract paraphrase patternsusingnewsarticlesoncertaintopics(Shinyama et al., 2002; Barzilay and Lee, 2003), while some others need seeds as initial input (Ravichandran and Hovy, 2002)." ></td>
	<td class="line x" title="165:250	In this paper, we compare our method with DIRT (Lin and Pantel, 2001), which does not need to specify topics or input seeds." ></td>
	<td class="line x" title="166:250	As mentioned in Section 2, DIRT learns paraphrase patterns from a parsed monolingual corpus based on an extended distributional hypothesis." ></td>
	<td class="line x" title="167:250	In our experiment, we implemented DIRT and extracted paraphrase patterns from the English part of our bilingual parallel corpus." ></td>
	<td class="line x" title="168:250	Our corpus is smaller than that reported in (Lin and Pantel, 2001)." ></td>
	<td class="line x" title="169:250	To alleviate the data sparseness problem, we only kept patterns appearing more than 10 times in the corpus for extracting paraphrase patterns." ></td>
	<td class="line x" title="170:250	Different from our method, no threshold was set in DIRT." ></td>
	<td class="line x" title="171:250	Instead, the extracted paraphrase patterns were ranked according to their scores." ></td>
	<td class="line x" title="172:250	In our experiment, we kept top-5 paraphrase patterns for each target pattern." ></td>
	<td class="line x" title="173:250	From the extracted paraphrase patterns, we sampled 600 groups for evaluation." ></td>
	<td class="line x" title="174:250	Each group comprises a target pattern and its top-5 paraphrase patterns." ></td>
	<td class="line x" title="175:250	The sampled data were manually labeled and the top-n precision was calculated as PN i=1 niNn , where N is the number of groups and ni is the number of correct paraphrase patterns in the top-n paraphrase patterns of the i-th group." ></td>
	<td class="line x" title="176:250	The top-1 and top-5 results are shown in the last two lines of Table 2." ></td>
	<td class="line x" title="177:250	Although there are more correct patterns in the top-5 results, the precision drops sequentially from top-1 to top-5 since the denominator of top-5 is 4 times larger than that of top-1." ></td>
	<td class="line x" title="178:250	Obviously, the number of the extracted paraphrase patterns is much smaller than that extracted using our method." ></td>
	<td class="line x" title="179:250	Besides, the precision is also much lower." ></td>
	<td class="line x" title="180:250	We believe that there are two reasons." ></td>
	<td class="line x" title="181:250	First, the extended distributional hypothesis is not strict enough." ></td>
	<td class="line x" title="182:250	Patterns sharing similar slot-fillers do not necessarily have the same meaning." ></td>
	<td class="line x" title="183:250	They may even have the opposite meanings." ></td>
	<td class="line x" title="184:250	For example, X worsens Y and X solves Y were extracted as para785 Type Count Example trivial change 79 (e1) all the members of [NNPS 1] (e2) all members of [NNPS 1] phrase replacement 267 (e1) [JJ 1] economic losses (e2) [JJ 1] financial losses phrase reordering 56 (e1) [NN 1] definition (e2) the definition of [NN 1] structural paraphrase 71 (e1) the admission of [NNP 1] to the wto (e2) the [NNP 1] s wto accession information + or 27 (e1) [NNS 1] are in fact women (e2) [NNS 1] are women Table 3: The statistics and examples of each type of paraphrase patterns." ></td>
	<td class="line x" title="185:250	phrase patterns by DIRT." ></td>
	<td class="line x" title="186:250	The other reason is that DIRT can only be effective for patterns appearing plenty of times in the corpus." ></td>
	<td class="line x" title="187:250	In other words, it seriously suffers from data sparseness." ></td>
	<td class="line x" title="188:250	We believe that DIRT can perform better on a larger corpus." ></td>
	<td class="line x" title="189:250	4.3 Pivot Pattern Constraints As described in Section 3.2, we constrain that the pattern words of an English pattern e must be extracted from a partial subtree." ></td>
	<td class="line x" title="190:250	However, we do not have such constraint on the Chinese pivot patterns." ></td>
	<td class="line x" title="191:250	Hence, it is interesting to investigate whether the performance can be improved if we constrain that the pattern words of a pivot pattern c must also be extracted from a partial subtree." ></td>
	<td class="line x" title="192:250	To conduct the evaluation, we parsed the Chinese sentences of the corpus with a Chinese dependency parser (Liu et al., 2006)." ></td>
	<td class="line x" title="193:250	We then induced English patterns and extracted aligned pivot patterns." ></td>
	<td class="line x" title="194:250	For the aligned patterns (e,c), if cs pattern words were not extractedfromapartialsubtree, thepairwasfiltered." ></td>
	<td class="line x" title="195:250	After that, we extracted paraphrase patterns, from which we sampled 3,000 pairs for evaluation." ></td>
	<td class="line x" title="196:250	The results show that 736,161 pairs of paraphrase patterns were extracted and the precision is 65.77%." ></td>
	<td class="line x" title="197:250	Compared with Table 2, the number of the extracted paraphrase patterns gets smaller and the precision also gets lower." ></td>
	<td class="line x" title="198:250	The results suggest that the performance of the method cannot be improved by constraining the extraction of pivot patterns." ></td>
	<td class="line x" title="199:250	4.4 Analysis of the Paraphrase Patterns We sampled 500 pairs of correct paraphrase patterns extracted using our method and analyzed the types." ></td>
	<td class="line x" title="200:250	We found that there are 5 types of paraphrase patterns, which include: (1) trivial change, such as changes of prepositions and articles, etc; (2) phrase replacement; (3) phrase reordering; (4) structural paraphrase, which contain both phrase replacements and phrase reordering; (5) adding or reducing informationthatdoesnotchangethemeaning." ></td>
	<td class="line x" title="201:250	Some statistics and examples are shown in Table 3." ></td>
	<td class="line x" title="202:250	The paraphrase patterns are useful in NLP applications." ></td>
	<td class="line x" title="203:250	Firstly, over 50% of the paraphrase patterns are in the type of phrase replacement, which can be used in IE pattern reformulation and sentencelevel paraphrase generation." ></td>
	<td class="line x" title="204:250	Compared with phrasal paraphrases, the phrase replacements in patterns are more accurate due to the constraints of the slots." ></td>
	<td class="line x" title="205:250	The paraphrase patterns in the type of phrase reordering can also be used in IE pattern reformulation and sentence paraphrase generation." ></td>
	<td class="line x" title="206:250	Especially, in sentence paraphrase generation, this type of paraphrasepatternscanreorderthephrasesinasentence, which can hardly be achieved by the conventional MT-based generation method (Quirk et al., 2004)." ></td>
	<td class="line x" title="207:250	Thestructuralparaphrasepatternshavetheadvantagesofbothphrasereplacementandphrasereordering." ></td>
	<td class="line x" title="208:250	More paraphrase sentences can be generated using these patterns." ></td>
	<td class="line x" title="209:250	The paraphrase patterns in the type of information + and - are useful in sentence compression and expansion." ></td>
	<td class="line x" title="210:250	A sentence matching a long pattern can be compressed by paraphrasing it using shorter patterns." ></td>
	<td class="line x" title="211:250	Similarly, a short sentence can be expanded by paraphrasing it using longer patterns." ></td>
	<td class="line x" title="212:250	For the 3,000 pairs of test paraphrase patterns, we also investigate the number and type of the pattern slots." ></td>
	<td class="line x" title="213:250	The results are summarized in Table 4 and 5." ></td>
	<td class="line x" title="214:250	From Table 4, we can see that more than 92% of the paraphrase patterns contain only one slot, just like the examples shown in Table 3." ></td>
	<td class="line x" title="215:250	In addition, about 7% of the paraphrase patterns contain two slots, such as give [NN 1] [NN 2] vs. give [NN 2] to [NN 1]." ></td>
	<td class="line x" title="216:250	This result suggests that our method tends to extract short paraphrase patterns, 786 Slot No." ></td>
	<td class="line x" title="217:250	#PP Percentage Precision 1-slot 2,780 92.67% 66.51% 2-slots 218 7.27% 73.85% 3-slots 2 <1% 50.00% Table 4: The statistics of the numbers of pattern slots." ></td>
	<td class="line x" title="218:250	Slot Type #PP Percentage Precision N-slots 2,376 79.20% 66.71% V-slots 273 9.10% 70.33% J-slots 438 14.60% 70.32% Table 5: The statistics of the type of pattern slots." ></td>
	<td class="line x" title="219:250	which is mainly because the data sparseness problem is more serious when extracting long patterns." ></td>
	<td class="line x" title="220:250	From Table 5, we can find that near 80% of the paraphrase patterns contain noun slots, while about 9% and 15% contain verb slots and adjective slots7." ></td>
	<td class="line x" title="221:250	This result implies that nouns are the most typical variables in paraphrase patterns." ></td>
	<td class="line x" title="222:250	4.5 Evaluation within Context Sentences In Section 4.1, we have evaluated the precision of the paraphrase patterns without considering context information." ></td>
	<td class="line x" title="223:250	In this section, we evaluate the paraphrase patterns within specific context sentences." ></td>
	<td class="line x" title="224:250	The open test set includes 119 English sentences." ></td>
	<td class="line x" title="225:250	We parsed the sentences with MaltParser and induced patterns as described in Section 3.2." ></td>
	<td class="line x" title="226:250	For each patternein sentenceSE, we searchedes paraphrase patterns from the database of the extracted paraphrase patterns." ></td>
	<td class="line x" title="227:250	The result shows that 101 of the 119 sentences contain at least one pattern that can be paraphrased using the extracted paraphrase patterns, the coverage of which is 84.87%." ></td>
	<td class="line x" title="228:250	Furthermore, since a pattern may have several paraphrase patterns, we exploited a method to automatically select the best one in the given context sentence." ></td>
	<td class="line x" title="229:250	In detail, a paraphrase pattern eprime of e was reranked based on a language model (LM): score(eprime|e,SE) = scoreLL(eprime|e) + (1 )scoreLM(eprime|SE) (7) 7Notice that, a pattern may contain more than one type of slots, thus the sum of the percentages is larger than 1." ></td>
	<td class="line x" title="230:250	Here, scoreLL(eprime|e) denotes the score based on Equation (3)." ></td>
	<td class="line x" title="231:250	scoreLM(eprime|SE) is the LM based score: scoreLM(eprime|SE) = 1nlogPLM(SprimeE), where SprimeE is the sentence generated by replacing e in SE with eprime." ></td>
	<td class="line x" title="232:250	The language model in the experiment was a tri-gram model trained using the English sentences in the bilingual corpus." ></td>
	<td class="line x" title="233:250	We empirically set  = 0.7." ></td>
	<td class="line x" title="234:250	The selected best paraphrase patterns in context sentences were manually labeled." ></td>
	<td class="line x" title="235:250	The context information was also considered by our judges." ></td>
	<td class="line x" title="236:250	The result shows that the precision of the best paraphrase patterns is 59.39%." ></td>
	<td class="line x" title="237:250	To investigate the contribution of the LM based score, we ran the experiment again with = 1 (ignoring the LMbased score) and found that the precision is 57.09%." ></td>
	<td class="line x" title="238:250	It indicates that the LM based reranking can improve the precision." ></td>
	<td class="line x" title="239:250	However, the improvement is small." ></td>
	<td class="line x" title="240:250	Further analysis shows that about 70% of the correct paraphrase substitutes are in the type of phrase replacement." ></td>
	<td class="line x" title="241:250	5 Conclusion This paper proposes a pivot approach for extracting paraphrase patterns from bilingual corpora." ></td>
	<td class="line x" title="242:250	We use a log-linear model to compute the paraphrase likelihood and exploit feature functions based on MLE andLW.Experimentalresultsshowthatthepivotapproach is effective, which extracts over 1,000,000 pairs of paraphrase patterns from 2M bilingual sentence pairs." ></td>
	<td class="line x" title="243:250	The precision and coverage of the extracted paraphrase patterns exceed 67% and 84%, respectively." ></td>
	<td class="line x" title="244:250	In addition, the log-linear model with the proposed feature functions significantly outperforms the conventional models." ></td>
	<td class="line x" title="245:250	Analysis shows that 5 types of paraphrase patterns are extracted with our method, which are useful in various applications." ></td>
	<td class="line x" title="246:250	Inthefuturewewishtoexploitmorefeaturefunctions in the log-linear model." ></td>
	<td class="line x" title="247:250	In addition, we will try to make better use of the context information when replacing paraphrase patterns in context sentences." ></td>
	<td class="line x" title="248:250	Acknowledgments This research was supported by National Natural Science Foundation of China (60503072, 60575042)." ></td>
	<td class="line x" title="249:250	We thank Lin Zhao, Xiaohang Qu, and Zhenghua Li for their help in the experiments." ></td>
	<td class="line x" title="250:250	787" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P08-1116
Combining Multiple Resources to Improve SMT-based Paraphrasing Model
Zhao, Shiqi;Niu, Cheng;Zhou, Ming;Liu, Ting;Li, Sheng;"></td>
	<td class="line x" title="1:268	Proceedings of ACL-08: HLT, pages 10211029, Columbus, Ohio, USA, June 2008." ></td>
	<td class="line x" title="2:268	c2008 Association for Computational Linguistics Combining Multiple Resources to Improve SMT-based Paraphrasing Model Shiqi Zhao1, Cheng Niu2, Ming Zhou2, Ting Liu1, Sheng Li1 1Harbin Institute of Technology, Harbin, China {zhaosq,tliu,lisheng}@ir.hit.edu.cn 2Microsoft Research Asia, Beijing, China {chengniu,mingzhou}@microsoft.com Abstract This paper proposes a novel method that exploits multiple resources to improve statistical machine translation (SMT) based paraphrasing." ></td>
	<td class="line x" title="3:268	In detail, a phrasal paraphrase table and a feature function are derived from each resource, which are then combined in a log-linear SMT model for sentence-level paraphrase generation." ></td>
	<td class="line x" title="4:268	Experimental results show that the SMT-based paraphrasing model can be enhanced using multiple resources." ></td>
	<td class="line x" title="5:268	The phrase-level and sentence-level precision of the generated paraphrases are above 60% and 55%, respectively." ></td>
	<td class="line x" title="6:268	In addition, the contribution of each resource is evaluated, which indicates that all the exploited resources are useful for generating paraphrases of high quality." ></td>
	<td class="line x" title="7:268	1 Introduction Paraphrases are alternative ways of conveying the same meaning." ></td>
	<td class="line x" title="8:268	Paraphrases are important in many natural language processing (NLP) applications, such as machine translation (MT), question answering (QA), information extraction (IE), multidocument summarization (MDS), and natural language generation (NLG)." ></td>
	<td class="line x" title="9:268	This paper addresses the problem of sentencelevel paraphrase generation, which aims at generating paraphrases for input sentences." ></td>
	<td class="line x" title="10:268	An example of sentence-level paraphrases can be seen below: S1: The table was set up in the carriage shed." ></td>
	<td class="line x" title="11:268	S2: The table was laid under the cart-shed." ></td>
	<td class="line x" title="12:268	This research was finished while the first author worked as an intern in Microsoft Research Asia." ></td>
	<td class="line x" title="13:268	Paraphrase generation can be viewed as monolingual machine translation (Quirk et al., 2004), which typically includes a translation model and a language model." ></td>
	<td class="line x" title="14:268	The translation model can be trained using monolingual parallel corpora." ></td>
	<td class="line x" title="15:268	However, acquiring such corpora is not easy." ></td>
	<td class="line x" title="16:268	Hence, data sparseness is a key problem for the SMT-based paraphrasing." ></td>
	<td class="line x" title="17:268	On the other hand, various methods have been presented to extract phrasal paraphrases from different resources, which include thesauri, monolingual corpora, bilingual corpora, and the web." ></td>
	<td class="line x" title="18:268	However, little work has been focused on using the extracted phrasal paraphrases in sentence-level paraphrase generation." ></td>
	<td class="line x" title="19:268	In this paper, we exploit multiple resources to improve the SMT-based paraphrase generation." ></td>
	<td class="line x" title="20:268	In detail, six kinds of resources are utilized, including: (1) an automatically constructed thesaurus, (2) a monolingual parallel corpus from novels, (3) a monolingual comparable corpus from news articles, (4) a bilingual phrase table, (5) word definitions from Encarta dictionary, and (6) a corpus of similar user queries." ></td>
	<td class="line x" title="21:268	Among the resources, (1), (2), (3), and (4) have been investigated by other researchers, while (5) and (6) are first used in this paper." ></td>
	<td class="line x" title="22:268	From thoseresources, sixphrasalparaphrasetablesareextracted, which are then used in a log-linear SMTbased paraphrasing model." ></td>
	<td class="line x" title="23:268	Both phrase-level and sentence-level evaluations were carried out in the experiments." ></td>
	<td class="line x" title="24:268	In the former one, phrase substitutes occurring in the paraphrase sentences were evaluated." ></td>
	<td class="line x" title="25:268	While in the latter one, the acceptability of the paraphrase sentences was evaluated." ></td>
	<td class="line x" title="26:268	Experimental results show that: (1) The 1021 SMT-based paraphrasing is enhanced using multiple resources." ></td>
	<td class="line x" title="27:268	The phrase-level and sentence-level precision of the generated paraphrases exceed 60% and 55%, respectively." ></td>
	<td class="line x" title="28:268	(2) Although the contributions of the resources differ a lot, all the resources are useful." ></td>
	<td class="line x" title="29:268	(3) The performance of the method varies greatly on different test sets and it performs best on the test set of news sentences, which are from the same source as most of the training data." ></td>
	<td class="line x" title="30:268	The rest of the paper is organized as follows: Section 2 reviews related work." ></td>
	<td class="line x" title="31:268	Section 3 introduces the log-linear model for paraphrase generation." ></td>
	<td class="line x" title="32:268	Section 4 describes the phrasal paraphrase extraction from different resources." ></td>
	<td class="line x" title="33:268	Section 5 presents the parameter estimationmethod." ></td>
	<td class="line x" title="34:268	Section6showstheexperiments and results." ></td>
	<td class="line x" title="35:268	Section 7 draws the conclusion." ></td>
	<td class="line x" title="36:268	2 Related Work Paraphrases have been used in many NLP applications." ></td>
	<td class="line x" title="37:268	In MT, Callison-Burch et al.(2006) utilized paraphrases of unseen source phrases to alleviate data sparseness." ></td>
	<td class="line x" title="39:268	Kauchak and Barzilay (2006) used paraphrases of the reference translations to improve automatic MT evaluation." ></td>
	<td class="line x" title="40:268	In QA, Lin and Pantel (2001) and Ravichandran and Hovy (2002) paraphrased the answer patterns to enhance the recall of answer extraction." ></td>
	<td class="line x" title="41:268	In IE, Shinyama et al.(2002) automatically learned paraphrases of IE patterns to reduce the cost of creating IE patterns by hand." ></td>
	<td class="line x" title="43:268	In MDS, McKeown et al.(2002) identified paraphrase sentences across documents before generating summarizations." ></td>
	<td class="line x" title="45:268	In NLG, Iordanskaja et al.(1991) used paraphrases to generate more varied and fluent texts." ></td>
	<td class="line x" title="47:268	Previousworkhasexaminedvariousresourcesfor acquiring paraphrases, including thesauri, monolingual corpora, bilingual corpora, and the web." ></td>
	<td class="line x" title="48:268	Thesauri, such as WordNet, have been widely used for extracting paraphrases." ></td>
	<td class="line x" title="49:268	Some researchers extract synonyms as paraphrases (Kauchak and Barzilay, 2006), while some others use looser definitions, such as hypernyms and holonyms (Barzilay and Elhadad, 1997)." ></td>
	<td class="line x" title="50:268	Besides, the automatically constructed thesauri can also be used." ></td>
	<td class="line x" title="51:268	Lin (1998) constructed a thesaurus by automatically clustering words based on context similarity." ></td>
	<td class="line x" title="52:268	BarzilayandMcKeown (2001)usedmonolingual parallel corpora for identifying paraphrases." ></td>
	<td class="line x" title="53:268	They exploited a corpus of multiple English translations ofthesamesourcetextwritteninaforeignlanguage, from which phrases in aligned sentences that appear in similar contexts were extracted as paraphrases." ></td>
	<td class="line x" title="54:268	In addition, Finch et al.(2005) applied MT evaluationmethods(BLEU,NIST,WERandPER)tobuild classifiers for paraphrase identification." ></td>
	<td class="line x" title="56:268	Monolingual parallel corpora are difficult to find, especially in non-literature domains." ></td>
	<td class="line x" title="57:268	Alternatively, some researchers utilized monolingual comparable corpora for paraphrase extraction." ></td>
	<td class="line oc" title="58:268	Different news articles reporting on the same event are commonly used as monolingual comparable corpora, from which both paraphrase patterns and phrasal paraphrases can be derived (Shinyama et al., 2002; Barzilay and Lee, 2003; Quirk et al., 2004)." ></td>
	<td class="line x" title="59:268	Lin and Pantel (2001) learned paraphrases from a parsed monolingual corpus based on an extended distributional hypothesis, where if two paths in dependency trees tend to occur in similar contexts it is hypothesizedthatthemeaningsofthepathsaresimilar." ></td>
	<td class="line x" title="60:268	Themonolingualcorpususedintheirworkisnot necessarily parallel or comparable." ></td>
	<td class="line x" title="61:268	Thus it is easy to obtain." ></td>
	<td class="line x" title="62:268	However, since this resource is used to extract paraphrase patterns other than phrasal paraphrases, we do not use it in this paper." ></td>
	<td class="line x" title="63:268	Bannard and Callison-Burch (2005) learned phrasal paraphrases using bilingual parallel corpora." ></td>
	<td class="line x" title="64:268	The basic idea is that if two phrases are alignedtothesametranslationinaforeignlanguage, they may be paraphrases." ></td>
	<td class="line x" title="65:268	This method has been demonstrated effective in extracting large volume of phrasal paraphrases." ></td>
	<td class="line x" title="66:268	Besides, Wu and Zhou (2003) exploited bilingual corpora and translation information in learning synonymous collocations." ></td>
	<td class="line x" title="67:268	In addition, some researchers extracted paraphrases from the web." ></td>
	<td class="line x" title="68:268	For example, Ravichandran and Hovy (2002) retrieved paraphrase patterns from the web using hand-crafted queries." ></td>
	<td class="line x" title="69:268	Pasca and Dienes (2005) extracted sentence fragments occurring in identical contexts as paraphrases from one billion web documents." ></td>
	<td class="line x" title="70:268	Since web mining is rather time consuming, we do not exploit the web to extract paraphrases in this paper." ></td>
	<td class="line x" title="71:268	So far, two kinds of methods have been proposed for sentence-level paraphrase generation, i.e., the pattern-based and SMT-based methods." ></td>
	<td class="line x" title="72:268	Automatically learned patterns have been used in para1022 phrase generation." ></td>
	<td class="line oc" title="73:268	For example, Barzilay and Lee (2003) applied multiple-sequence alignment (MSA) to parallel news sentences and induced paraphrasing patterns for generating new sentences." ></td>
	<td class="line x" title="74:268	Pang et al.(2003) built finite state automata (FSA) from semantically equivalent translation sets based on syntactic alignment and used the FSAs in paraphrase generation." ></td>
	<td class="line o" title="76:268	The pattern-based methods can generate complex paraphrases that usually involve syntactic variation." ></td>
	<td class="line n" title="77:268	However, the methods were demonstrated to be of limited generality (Quirk et al., 2004)." ></td>
	<td class="line x" title="78:268	Quirk et al.(2004) first recast paraphrase generation as monolingual SMT." ></td>
	<td class="line x" title="80:268	They generated paraphrases using a SMT system trained on parallel sentences extracted from clustered news articles." ></td>
	<td class="line x" title="81:268	In addition, Madnani et al.(2007) also generated sentence-level paraphrases based on a SMT model." ></td>
	<td class="line x" title="83:268	The advantage of the SMT-based method is that it achieves better coverage than the pattern-based method." ></td>
	<td class="line x" title="84:268	The main difference between their methods and ours is that they only used bilingual parallel corpora as paraphrase resource, while we exploit and combine multiple resources." ></td>
	<td class="line x" title="85:268	3 SMT-based Paraphrasing Model The SMT-based paraphrasing model used by Quirk et al.(2004) was the noisy channel model of Brown etal.(1993),whichidentifiedtheoptimalparaphrase T of a sentence S by finding: T = argmax T {P(T|S)} = argmax T {P(S|T)P(T)} (1) In contrast, we adopt a log-linear model (Och and Ney, 2002) in this work, since multiple paraphrase tables can be easily combined in the loglinear model." ></td>
	<td class="line x" title="87:268	Specifically, feature functions are derived from each paraphrase resource and then combined with the language model feature1: T = argmax T { Nsummationdisplay i=1 TM ihTM i(T,S)+ LMhLM(T,S)} (2) where N is the number of paraphrase tables." ></td>
	<td class="line x" title="88:268	hTM i(T,S) is the feature function based on the ith paraphrase table PTi." ></td>
	<td class="line x" title="89:268	hLM(T,S) is the language 1The reordering model is not considered in our model." ></td>
	<td class="line x" title="90:268	model feature." ></td>
	<td class="line x" title="91:268	TM i and LM are the weights of the feature functions." ></td>
	<td class="line x" title="92:268	hTM i(T,S) is defined as: hTM i(T,S) = log Kiproductdisplay k=1 Scorei(Tk,Sk) (3) where Ki is the number of phrase substitutes from S to T based on PTi." ></td>
	<td class="line x" title="93:268	Tk in T and Sk in S are phrasal paraphrases in PTi." ></td>
	<td class="line x" title="94:268	Scorei(Tk,Sk) is the paraphrase likelihood according to PTi2." ></td>
	<td class="line x" title="95:268	A 5-gram language model is used, therefore: hLM(T,S) = log Jproductdisplay j=1 p(tj|tj4,,tj1) (4) where J is the length of T, tj is the j-th word of T. 4 Exploiting Multiple Resources This section describes the extraction of phrasal paraphrases using various resources." ></td>
	<td class="line x" title="96:268	Similar to Pharaoh (Koehn, 2004), our decoder3 uses top 20 paraphrase options for each input phrase in the default setting." ></td>
	<td class="line x" title="97:268	Therefore, we keep at most 20 paraphrases for a phrase when extracting phrasal paraphrases using each resource." ></td>
	<td class="line x" title="98:268	1 Thesaurus: The thesaurus4 used in this work was automatically constructed by Lin (1998)." ></td>
	<td class="line x" title="99:268	The similarity of two words e1 and e2 was calculated through the surrounding context words that have dependency relations with the investigated words: Sim(e1,e2) = P (r,e)Tr(e1)Tr(e2)(I(e1,r,e)+I(e2,r,e))P (r,e)Tr(e1) I(e1,r,e)+ P (r,e)Tr(e2) I(e2,r,e) (5) where Tr(ei) denotes the set of words that have dependency relation r with word ei." ></td>
	<td class="line x" title="100:268	I(ei,r,e) is the mutual information between ei, r and e. For each word, we keep 20 most similar words as paraphrases." ></td>
	<td class="line x" title="101:268	In this way, we extract 502,305 pairs of paraphrases." ></td>
	<td class="line x" title="102:268	The paraphrasing scoreScore1(p1,p2) used in Equation (3) is defined as the similarity based on Equation (5)." ></td>
	<td class="line x" title="103:268	2If none of the phrase substitutes from S to T is from PTi (i.e., Ki = 0), we cannot compute hTM i(T,S) as in Equation (3)." ></td>
	<td class="line x" title="104:268	In this case, we assign hTM i(T,S) a minimum value." ></td>
	<td class="line x" title="105:268	3The decoder used here is a re-implementation of Pharaoh." ></td>
	<td class="line x" title="106:268	4http://www.cs.ualberta.ca/ lindek/downloads.htm." ></td>
	<td class="line x" title="107:268	1023 2 Monolingual parallel corpus: Following Barzilay and McKeown (2001), we exploit a corpus of multiple English translations of foreign novels, which contains 25,804 parallel sentence pairs." ></td>
	<td class="line x" title="108:268	We find that most paraphrases extracted using the method of Barzilay and McKeown (2001) are quite short." ></td>
	<td class="line x" title="109:268	Thus we employ a new approach for paraphrase extraction." ></td>
	<td class="line x" title="110:268	Specifically, we parse the sentences with CollinsParser5 and extract the chunks from the parsing results." ></td>
	<td class="line x" title="111:268	Let S1 and S2 be a pair of parallel sentences, p1 and p2 two chunks from S1 and S2, we compute the similarity of p1 and p2 as: Sim(p1,p2) = Simcontent(p1,p2)+ (1  )Simcontext(p1,p2) (6) where, Simcontent(p1,p2) is the content similarity, which is the word overlapping rate of p1 and p2." ></td>
	<td class="line x" title="112:268	Simcontext(p1,p2)is the context similarity, which is the word overlapping rate of the contexts of p1 and p26." ></td>
	<td class="line x" title="113:268	If the similarity of p1 and p2 exceeds a threshold Th1, they are identified as paraphrases." ></td>
	<td class="line x" title="114:268	We extract 18,698 pairs of phrasal paraphrases from this resource." ></td>
	<td class="line x" title="115:268	The paraphrasing score Score2(p1,p2) is defined as the similarity in Equation (6)." ></td>
	<td class="line x" title="116:268	For the paraphrases occurring more than once, we use their maximum similarity as the paraphrasing score." ></td>
	<td class="line oc" title="117:268	3 Monolingual comparable corpus: Similar to the methods in (Shinyama et al., 2002; Barzilay and Lee, 2003), we construct a corpus of comparable documents from a large corpus D of news articles." ></td>
	<td class="line x" title="118:268	The corpusD contains 612,549 news articles." ></td>
	<td class="line x" title="119:268	Given articles d1 and d2 from D, if their publication date interval is less than 2 days and their similarity7 exceeds a threshold Th2, they are recognized as comparable documents." ></td>
	<td class="line x" title="120:268	In this way, a corpus containing 5,672,864 pairs of comparable documents is constructed." ></td>
	<td class="line x" title="121:268	From the comparable corpus, parallel sentences are extracted." ></td>
	<td class="line x" title="122:268	Let s1 and s2 be two sentences from comparable documents d1 and d2, if their similarity based on word overlapping rate is above a threshold Th3, s1 and s2 are identified as parallel sentences." ></td>
	<td class="line x" title="123:268	In this way, 872,330 parallel sentence pairs are extracted." ></td>
	<td class="line x" title="124:268	5http://people.csail.mit.edu/mcollins/code.html 6The context of a chunk is made up of 6 words around the chunk, 3 to the left and 3 to the right." ></td>
	<td class="line x" title="125:268	7Thesimilarityoftwodocumentsiscomputedusingthevector space model and the word weights are based on tfidf." ></td>
	<td class="line x" title="126:268	We run Giza++ (Och and Ney, 2000) on the parallel sentences and then extract aligned phrases as described in (Koehn, 2004)." ></td>
	<td class="line x" title="127:268	The generated paraphrase table ispruned by keepingthe top 20paraphrases for each phrase." ></td>
	<td class="line x" title="128:268	After pruning, 100,621 pairs of paraphrases are extracted." ></td>
	<td class="line x" title="129:268	Given phrase p1 and its paraphrase p2, we compute Score3(p1,p2) by relative frequency (Koehn et al., 2003): Score3(p1,p2) = p(p2|p1) = count(p2,p1)P pprime count(pprime,p1) (7) People may wonder why we do not use the same method on the monolingual parallel and comparable corpora." ></td>
	<td class="line x" title="130:268	This is mainly because the volumes of the two corpora differ a lot." ></td>
	<td class="line x" title="131:268	In detail, the monolingual parallel corpus is fairly small, thus automatical word alignment tool like Giza++ may not work well on it." ></td>
	<td class="line x" title="132:268	In contrast, the monolingual comparable corpus is quite large, hence we cannot conduct the timeconsuming syntactic parsing on it as we do on the monolingual parallel corpus." ></td>
	<td class="line x" title="133:268	4 Bilingual phrase table: We first construct a bilingual phrase table that contains 15,352,469 phrase pairs from an English-Chinese parallel corpus." ></td>
	<td class="line x" title="134:268	We extract paraphrases from the bilingual phrase table and compute the paraphrasing score of phrases p1 and p2 as in (Bannard and CallisonBurch, 2005): Score4(p1,p2) = summationdisplay f p(f|p1)p(p2|f) (8) wheref denotesaChinesetranslationofbothp1 and p2." ></td>
	<td class="line x" title="135:268	p(f|p1) and p(p2|f) are the translation probabilities provided by the bilingual phrase table." ></td>
	<td class="line x" title="136:268	For each phrase, the top 20 paraphrases are kept according to the score in Equation (8)." ></td>
	<td class="line x" title="137:268	As a result, 3,177,600 pairs of phrasal paraphrases are extracted." ></td>
	<td class="line x" title="138:268	5-Encartadictionarydefinitions: Wordsandtheir definitions can be regarded as paraphrases." ></td>
	<td class="line x" title="139:268	Here are some examples from Encarta dictionary: hurricane: severe storm, clever: intelligent, travel: go on journey." ></td>
	<td class="line x" title="140:268	In this work, we extract words definitions from Encarta dictionary web pages8." ></td>
	<td class="line x" title="141:268	If a word has more than one definition, all of them are extracted." ></td>
	<td class="line x" title="142:268	Note that the words and definitions in the 8http://encarta.msn.com/encnet/features/dictionary/dictionaryhome.aspx 1024 dictionary are lemmatized, but words in sentences are usually inflected." ></td>
	<td class="line x" title="143:268	Hence, we expand the word definition pairs by providing the inflected forms." ></td>
	<td class="line x" title="144:268	Here we use an inflection list and some rules for inflection." ></td>
	<td class="line x" title="145:268	After expanding, 159,456 pairs of phrasal paraphrases are extracted." ></td>
	<td class="line x" title="146:268	Let < p1,p2 > be a word definition pair, the paraphrasing score is defined according to the rank of p2 in all of p1s definitions: Score5(p1,p2) = i1 (9) where  is a constant (we empirically set  = 0.9) and i is the rank of p2 in p1s definitions." ></td>
	<td class="line x" title="147:268	6 Similar user queries: Clusters of similar user queries have been used for query expansion and suggestion (Gao et al., 2007)." ></td>
	<td class="line x" title="148:268	Since most queries are at the phrase level, we exploit similar user queries as phrasal paraphrases." ></td>
	<td class="line x" title="149:268	In our experiment, we use the corpusof clusteredsimilarMSN queriesconstructed by Gao et al.(2007)." ></td>
	<td class="line x" title="151:268	The similarity of two queries p1 and p2 is computed as: Sim(p1,p2) = Simcontent(p1,p2)+ (1  )Simclickthrough(p1,p2) (10) where Simcontent(p1,p2) is the content similarity, which is computed as the word overlapping rate of p1 and p2." ></td>
	<td class="line x" title="152:268	Simclickthrough(p1,p2) is the click through similarity, which is the overlapping rate of the user clicked documents for p1 and p2." ></td>
	<td class="line x" title="153:268	For each query q, we keep the top 20 similar queries, whose similarity with q exceeds a threshold Th4." ></td>
	<td class="line x" title="154:268	As a result, 395,284 pairs of paraphrases are extracted." ></td>
	<td class="line x" title="155:268	The score Score6(p1,p2) is defined as the similarity in Equation (10)." ></td>
	<td class="line x" title="156:268	7-Self-paraphrase: In addition to the six resources introduced above, a special paraphrase table is used, which is made up of pairs of identical words." ></td>
	<td class="line x" title="157:268	The reason why this paraphrase table is necessary is that awordshouldbeallowedtokeepunchangedinparaphrasing." ></td>
	<td class="line x" title="158:268	This is a difference between paraphrasing and MT, since all words should be translated in MT. In our experiments, all the words that occur in the six paraphrase table extracted above are gathered to form the self-paraphrase table, which contains 110,403 word pairs." ></td>
	<td class="line x" title="159:268	The score Score7(p1,p2) is set 1 for each identical word pair." ></td>
	<td class="line x" title="160:268	5 Parameter Estimation The weights of the feature functions, namely TM i (i = 1,2,,7) and LM, need estimation9." ></td>
	<td class="line x" title="161:268	In MT, the max-BLEU algorithm is widely used to estimate parameters." ></td>
	<td class="line x" title="162:268	However, it may not work in our case, since it is more difficult to create a reference set of paraphrases." ></td>
	<td class="line x" title="163:268	We propose a new technique to estimate parameters in paraphrasing." ></td>
	<td class="line x" title="164:268	The assumption is that, since a SMT-based paraphrase is generated through phrase substitution, we can measure the quality of a generated paraphrase by measuring its phrase substitutes." ></td>
	<td class="line x" title="165:268	Generally, the paraphrases containing more correct phrasesubstitutesarejudgedasbetterparaphrases10." ></td>
	<td class="line x" title="166:268	We therefore present the phrase substitution error rate (PSER) to score a generated paraphrase T: PSER(T) = bardblPS0(T)bardbl/bardblPS(T)bardbl (11) where PS(T) is the set of phrase substitutes in T and PS0(T) is the set of incorrect substitutes." ></td>
	<td class="line x" title="167:268	In practice, we keep top n paraphrases for each sentence S. Thus we calculate the PSER for each source sentence S as: PSER(S) = bardbl n[ i=1 PS0(Ti)bardbl/bardbl n[ i=1 PS(Ti)bardbl (12) where Ti is the i-th generated paraphrase of S. Suppose there are N sentences in the development set, the overall PSER is computed as: PSER = NX j=1 PSER(Sj) (13) where Sj is the j-th sentence in the development set." ></td>
	<td class="line x" title="168:268	Our development set contains 75 sentences (described in detail in Section 6)." ></td>
	<td class="line x" title="169:268	For each sentence, all possible phrase substitutes are extracted from the six paraphrase tables above." ></td>
	<td class="line x" title="170:268	The extracted phrase substitutes are then manually labeled as correct or incorrect." ></td>
	<td class="line x" title="171:268	Aphrasesubstituteisconsideredascorrect only if the two phrases have the same meaning in the given sentence and the sentence generated by 9Note that, we also use some other parameters when extracting phrasal paraphrases from different resources, such as the thresholds Th1, Th2, Th3, Th4, as well as  and  in Equation (6) and (10)." ></td>
	<td class="line x" title="172:268	These parameters are estimated using different development sets from the investigated resources." ></td>
	<td class="line x" title="173:268	We do not describe the estimation of them due to space limitation." ></td>
	<td class="line x" title="174:268	10Paraphrasing a word to itself (based on the 7-th paraphrase table above) is not regarded as a substitute." ></td>
	<td class="line x" title="175:268	1025 substituting the source phrase with the target phrase remains grammatical." ></td>
	<td class="line x" title="176:268	In decoding, the phrase substitutes are printed out and then the PSER is computed based on the labeled data." ></td>
	<td class="line x" title="177:268	Using each set of parameters, we generate paraphrases for the sentences in the development set based on Equation (2)." ></td>
	<td class="line x" title="178:268	PSER is then computed as in Equation (13)." ></td>
	<td class="line x" title="179:268	We use the gradient descent algorithm (Press et al., 1992) to minimize PSER on the development set and get the optimal parameters." ></td>
	<td class="line x" title="180:268	6 Experiments To evaluate the performance of the method on different types of test data, we used three kinds of sentences for testing, which were randomly extracted from Google news, free online novels, and forums, respectively." ></td>
	<td class="line x" title="181:268	For each type, 50 sentences were extracted as test data and another 25 were extracted as development data." ></td>
	<td class="line x" title="182:268	For each test sentence, top 10 of the generated paraphrases were kept for evaluation." ></td>
	<td class="line x" title="183:268	6.1 Phrase-level Evaluation The phrase-level evaluation was carried out to investigate the contributions of the paraphrase tables." ></td>
	<td class="line x" title="184:268	Foreachtestsentence, allpossiblephrasesubstitutes were first extracted from the paraphrase tables and manually labeled as correct or incorrect." ></td>
	<td class="line x" title="185:268	Here, the criterion for identifying paraphrases is the same as that described in Section 5." ></td>
	<td class="line x" title="186:268	Then, in the stage of decoding, the phrase substitutes were printed out and evaluated using the labeled data." ></td>
	<td class="line x" title="187:268	Two metrics were used here." ></td>
	<td class="line x" title="188:268	The first is the number of distinct correct substitutes (#DCS)." ></td>
	<td class="line x" title="189:268	Obviously, the more distinct correct phrase substitutes a paraphrase table can provide, the more valuable it is. The second is the accuracy of the phrase substitutes, which is computed as: Accuracy = #correct phrase substitutes#all phrase substitutes (14) To evaluate the PTs learned from different resources, we first used each PT (from 1 to 6) along with PT-7 in decoding." ></td>
	<td class="line x" title="190:268	The results are shown in Table 1." ></td>
	<td class="line x" title="191:268	It can be seen that PT-4 is the most useful, as it provides the most correct substitutes and the accuracy is the highest." ></td>
	<td class="line x" title="192:268	We believe that it is because PT-4 is much larger than the other PTs." ></td>
	<td class="line x" title="193:268	Compared with PT-4, the accuracies of the other PTs are fairly PT combination #DCS Accuracy 1+7 178 14.61% 2+7 94 25.06% 3+7 202 18.35% 4+7 553 56.93% 5+7 231 20.48% 6+7 21 14.42% Table 1: Contributions of the paraphrase tables." ></td>
	<td class="line x" title="194:268	PT-1: from the thesaurus; PT-2: from the monolingual parallel corpus; PT-3: from the monolingual comparable corpus; PT-4: from the bilingual parallel corpus; PT-5: from the Encarta dictionary definitions; PT-6: from the similar MSN user queries; PT-7: self-paraphrases." ></td>
	<td class="line x" title="195:268	low." ></td>
	<td class="line x" title="196:268	This is because those PTs are smaller, thus they can provide fewer correct phrase substitutes." ></td>
	<td class="line x" title="197:268	As a result, plenty of incorrect substitutes were included in the top 10 generated paraphrases." ></td>
	<td class="line x" title="198:268	PT-6 provides the least correct phrase substitutes and the accuracy is the lowest." ></td>
	<td class="line x" title="199:268	There are several reasons." ></td>
	<td class="line x" title="200:268	First, many phrases in PT-6 are not real phrases but only sets of keywords (e.g., lottery results ny), which may not appear in sentences." ></td>
	<td class="line x" title="201:268	Second, many words in this table have spelling mistakes (e.g., widows vista)." ></td>
	<td class="line x" title="202:268	Third, some phrase pairs in PT-6 are not paraphrases but only related queries (e.g., back tattoo vs. butterfly tattoo)." ></td>
	<td class="line x" title="203:268	Fourth, many phrases of PT-6 contain proper names or out-of-vocabulary words, which are difficult to be matched." ></td>
	<td class="line x" title="204:268	The accuracy based on PT-1 is also quite low." ></td>
	<td class="line x" title="205:268	We found that it is mainly because the phrase pairs in PT-1 are automatically clustered, many of which are merely similar words rather than synonyms (e.g., borrow vs. buy)." ></td>
	<td class="line x" title="206:268	Next, we try to find out whether it is necessary to combine all PTs." ></td>
	<td class="line x" title="207:268	Thus we conducted several runs, each of which added the most useful PT from the left ones." ></td>
	<td class="line x" title="208:268	The results are shown in Table 2." ></td>
	<td class="line x" title="209:268	We can see that all the PTs are useful, as each PT provides some new correct phrase substitutes and the accuracy increases when adding each PT except PT-1." ></td>
	<td class="line x" title="210:268	Since the PTs are extracted from different resources, they have different contributions." ></td>
	<td class="line x" title="211:268	Here we only discuss the contributions of PT-5 and PT-6, which are first used in paraphrasing in this paper." ></td>
	<td class="line x" title="212:268	PT-5 is useful for paraphrasing uncommon concepts sinceitcanexplainconceptswiththeirdefinitions." ></td>
	<td class="line x" title="213:268	1026 PT combination #DCS Accuracy 4+7 553 56.93% 4+5+7 581 58.97% 4+5+3+7 638 59.42% 4+5+3+2+7 649 60.15% 4+5+3+2+1+7 699 60.14% 4+5+3+2+1+6+7 711 60.16% Table 2: Performances of different combinations of paraphrase tables." ></td>
	<td class="line x" title="214:268	For instance, in the following test sentence S1, the word amnesia is a relatively uncommon word, especially for the people using English as the second language." ></td>
	<td class="line x" title="215:268	Based on PT-5, S1 can be paraphrased into T1, which is much easier to understand." ></td>
	<td class="line x" title="216:268	S1: I was suffering from amnesia." ></td>
	<td class="line x" title="217:268	T1: I was suffering from memory loss." ></td>
	<td class="line x" title="218:268	The disadvantage of PT-5 is that substituting words with the definitions sometimes leads to grammatical errors." ></td>
	<td class="line x" title="219:268	For instance, substituting heat shield in the sentence S2 with protective barrier against heat keeps the meaning unchanged." ></td>
	<td class="line x" title="220:268	However, the paraphrased sentence T2 is ungrammatical." ></td>
	<td class="line x" title="221:268	S2: The U.S. space agency has been cautious about heat shield damage." ></td>
	<td class="line x" title="222:268	T2: The U.S. space administration has been cautious about protective barrier against heat damage." ></td>
	<td class="line x" title="223:268	As previously mentioned, PT-6 is less effective compared with the other PTs." ></td>
	<td class="line x" title="224:268	However, it is useful for paraphrasing some special phrases, such as digital products, computer software, etc, since these phrases often appear in user queries." ></td>
	<td class="line x" title="225:268	For example, S3 below can be paraphrased into T3 using PT-6." ></td>
	<td class="line x" title="226:268	S3: I have a canon powershot S230 that uses CF memory cards." ></td>
	<td class="line x" title="227:268	T3: I have a canon digital camera S230 that uses CF memory cards." ></td>
	<td class="line x" title="228:268	The phrase canon powershot can hardly be paraphrased using the other PTs." ></td>
	<td class="line x" title="229:268	It suggests that PT6 is useful for paraphrasing new emerging concepts and expressions." ></td>
	<td class="line x" title="230:268	Test sentences Top-1 Top-5 Top-10 All 150 55.33% 45.20% 39.28% 50 from news 70.00% 62.00% 57.03% 50 from novel 56.00% 46.00% 37.42% 50 from forum 40.00% 27.60% 23.34% Table 3: Top-n accuracy on different test sentences." ></td>
	<td class="line x" title="231:268	6.2 Sentence-level Evaluation In this section, we evaluated the sentence-level quality of the generated paraphrases11." ></td>
	<td class="line x" title="232:268	In detail, each generated paraphrase was manually labeled as acceptable or unacceptable." ></td>
	<td class="line x" title="233:268	Here, the criterion for counting a sentence T as an acceptable paraphrase of sentence S is that T is understandable and its meaning is not evidently changed compared with S. For example, for the sentence S4, T4 is an acceptable paraphrase generated using our method." ></td>
	<td class="line x" title="234:268	S4: The strain on US forces of fighting in Iraq and Afghanistan was exposed yesterday when the Pentagon published a report showing that the number of suicides among US troops is at its highest level since the 1991 Gulf war." ></td>
	<td class="line x" title="235:268	T4: The pressure on US troops of fighting in Iraq and Afghanistan was revealed yesterday when the Pentagon released a report showing that the amount of suicides among US forces is at its top since the 1991 Gulf conflict." ></td>
	<td class="line x" title="236:268	We carried out sentence-level evaluation using the top-1, top-5, andtop-10resultsofeachtestsentence." ></td>
	<td class="line x" title="237:268	The accuracy of the top-n results was computed as: Accuracytopn = summationtextN i=1 ni N  n (15) where N is the number of test sentences." ></td>
	<td class="line x" title="238:268	ni is the number of acceptable paraphrases in the top-n paraphrases of the i-th test sentence." ></td>
	<td class="line x" title="239:268	We computed the accuracy on the whole test set (150 sentences) as well as on the three subsets, i.e., the 50 news sentences, 50 novel sentences, and 50 forum sentences." ></td>
	<td class="line x" title="240:268	The results are shown in table 3." ></td>
	<td class="line x" title="241:268	It can be seen that the accuracy varies greatly on different test sets." ></td>
	<td class="line x" title="242:268	The accuracy on the news sentences is the highest, while that on the forum sentences is the lowest." ></td>
	<td class="line x" title="243:268	There are several reasons." ></td>
	<td class="line x" title="244:268	First, 11The evaluation was based on the paraphrasing results using the combination of all seven PTs." ></td>
	<td class="line x" title="245:268	1027 the largest PT used in the experiments is extracted using the bilingual parallel data, which are mostly from news documents." ></td>
	<td class="line x" title="246:268	Thus, the test set of news sentences is more similar to the training data." ></td>
	<td class="line x" title="247:268	Second, the news sentences are formal while the novel and forum sentences are less formal." ></td>
	<td class="line x" title="248:268	Especially, some of the forum sentences contain spelling mistakes and grammar mistakes." ></td>
	<td class="line x" title="249:268	Third, we find in the results that, most phrases paraphrased in the novel and forum sentences are commonly used phrases or words, such as food, good, find, etc. These phrases are more difficult to paraphrase than the less common phrases, since they usually have much more paraphrases in the PTs." ></td>
	<td class="line x" title="250:268	Therefore, it is more difficult to choose the right paraphrase from all the candidates when conducting sentence-level paraphrase generation." ></td>
	<td class="line x" title="251:268	Fourth, the forum sentences contain plenty of words such as board (means computer board), site (means web site), mouse (means computer mouse), etc. These words are polysemous and have particular meanings in the domains of computer science and internet." ></td>
	<td class="line x" title="252:268	Our method performs poor when paraphrasing these words since the domain of a context sentence is hard to identify." ></td>
	<td class="line x" title="253:268	After observing the results, we find that there are three types of errors: (1) syntactic errors: the generatedsentencesareungrammatical." ></td>
	<td class="line x" title="254:268	About32%ofthe unacceptable results are due to syntactic errors." ></td>
	<td class="line x" title="255:268	(2) semantic errors: the generated sentences are incomprehensible." ></td>
	<td class="line x" title="256:268	Nearly 60% of the unacceptable paraphrases have semantic errors." ></td>
	<td class="line x" title="257:268	(3) non-paraphrase: the generated sentences are well formed and comprehensible but are not paraphrases of the input sentences." ></td>
	<td class="line x" title="258:268	8% of the unacceptable results are of this type." ></td>
	<td class="line x" title="259:268	We believe that many of the errors above can be avoided by applying syntactic constraints and by making better use of context information in decoding, which is left as our future work." ></td>
	<td class="line x" title="260:268	7 Conclusion This paper proposes a method that improves the SMT-based sentence-level paraphrase generation using phrasal paraphrases automatically extracted from different resources." ></td>
	<td class="line x" title="261:268	Our contribution is that we combine multiple resources in the framework of SMT for paraphrase generation, in which the dictionary definitions and similar user queries are first used as phrasal paraphrases." ></td>
	<td class="line x" title="262:268	In addition, we analyze andcomparethecontributionsofdifferentresources." ></td>
	<td class="line x" title="263:268	Experimental results indicate that although the contributions of the exploited resources differ a lot, they are all useful to sentence-level paraphrase generation." ></td>
	<td class="line x" title="264:268	Especially, the dictionary definitions and similar user queries are effective for paraphrasing some certain types of phrases." ></td>
	<td class="line x" title="265:268	In the future work, we will try to use syntactic and context constraints in paraphrase generation to enhance the acceptability of the paraphrases." ></td>
	<td class="line x" title="266:268	In addition, we will extract paraphrase patterns that contain more structural variation and try to combine the SMT-based and pattern-based systems for sentencelevel paraphrase generation." ></td>
	<td class="line x" title="267:268	Acknowledgments We would like to thank Mu Li for providing us with the SMT decoder." ></td>
	<td class="line x" title="268:268	We are also grateful to Dongdong Zhang for his help in the experiments." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W08-0906
Answering Learnersâ€™ Questions by Retrieving Question Paraphrases from Social Q&A Sites
Bernhard, Delphine;Gurevych, Iryna;"></td>
	<td class="line x" title="1:177	Proceedings of the Third ACL Workshop on Innovative Use of NLP for Building Educational Applications, pages 4452, Columbus, Ohio, USA, June 2008." ></td>
	<td class="line x" title="2:177	c2008 Association for Computational Linguistics AnsweringLearnersQuestionsby RetrievingQuestionParaphrases fromSocialQ&ASites DelphineBernhard and IrynaGurevych UbiquitousKnowledgeProcessingLab ComputerScienceDepartment TechnischeUniversitat Darmstadt,Hochschulstrae10 D-64289Darmstadt,Germany {delphine|gurevych}@tk.informatik.tu-darmstadt.de Abstract Information overload is a well-known problem which can be particularly detrimental to learners." ></td>
	<td class="line x" title="3:177	In this paper, we propose a method to support learners in the information seeking process which consists in answering their questions by retrieving question paraphrases and their corresponding answers from social Q&A sites." ></td>
	<td class="line x" title="4:177	Given the novelty of this kind of data, it is crucial to get a better understanding of how questions in social Q&A sites can be automatically analysed and retrieved." ></td>
	<td class="line x" title="5:177	We discuss and evaluate several pre-processing strategies and question similarity metrics, using a new question paraphrase corpus collected from the WikiAnswersQ&A site." ></td>
	<td class="line x" title="6:177	The results show that viable performancelevels of more than 80% accuracy can be obtained for the task of questionparaphraseretrieval." ></td>
	<td class="line x" title="7:177	1 Introduction Question asking is an important component of efficient learning." ></td>
	<td class="line x" title="8:177	However, instructors are often overwhelmedwith studentsquestions and are therefore unabletoprovidetimelyanswers(Fengetal.,2006)." ></td>
	<td class="line x" title="9:177	Informationseekingis also rendereddifficult by the sheer amount of learning material available, especially online." ></td>
	<td class="line x" title="10:177	The use of advanced information retrieval and natural language processing techniques to answer learners questions and reduce the difficulty of information seeking is henceforth particularly promising." ></td>
	<td class="line x" title="11:177	QuestionAnswering(QA) systems seem well suited for this task since they aim at generating precise answers to natural language questions instead of merely returning documents containing answers." ></td>
	<td class="line x" title="12:177	However, QA systems have to be adapted to meet learners needs." ></td>
	<td class="line x" title="13:177	Indeed, learners do not merely ask concreteor factoid questions, but rather open-ended, explanatory or methodological questionswhichcannotbeansweredbyasinglesentence (Baram-Tsabari et al., 2006)." ></td>
	<td class="line x" title="14:177	Despitea recent trendtorenderthetasksmorecomplex atlargescale QA evaluation campaigns such as TREC or CLEF, current QA systems are still ill-suited to meet these requirements." ></td>
	<td class="line x" title="15:177	A first alternative to full-fledged QA consists in makinguseofalreadyavailablequestionandanswer pairs extracted from archived discussions." ></td>
	<td class="line x" title="16:177	For instance,Fenget al.(2006)describean intelligentdiscussion bot for answering student questions in forums which relies on answers retrieved from an annotated corpus of discussions." ></td>
	<td class="line x" title="18:177	This renders the task of QA easiersince answersdo not have to be generated from heterogeneousdocuments by the system." ></td>
	<td class="line x" title="19:177	Thescopeofsucha discussionbotishoweverinherently limited since it relies on manually annotated data, taken from forumswithina specificdomain." ></td>
	<td class="line x" title="20:177	We proposea different solutionwhich consistsin tapping into the wisdom of crowds to answer learners questions." ></td>
	<td class="line x" title="21:177	This approach provides the compelling advantage that it utilises the wealth of already answered questions available in online social Q&A sites." ></td>
	<td class="line x" title="22:177	The task of Question Answering can then be boileddown to the problemof findingquestion paraphrases in a database of answered questions." ></td>
	<td class="line x" title="23:177	Question paraphrases are questions which haveidenticalmeaningsandexpectthesameanswer while presenting alternate wordings." ></td>
	<td class="line x" title="24:177	Several methods have alreadybeen proposedto identifyquestion 44 paraphrases mostly in FAQs (Tomuro and Lytinen, 2004)or searchenginelogs (Zhaoet al., 2007)." ></td>
	<td class="line x" title="25:177	Inthispaper, wefocusontheproblemofquestion paraphraseidentificationin socialQ&Asites within arealisticinformationseekingscenario: givenauser question,wewanttoretrievethebestmatchingquestion paraphrase from a database of previously answeredquestionsin orderto displaythecorresponding answer." ></td>
	<td class="line x" title="26:177	The use of social Q&A sites for educational applications brings about new challenges linkedtothevariablequalityofsocialmediacontent." ></td>
	<td class="line x" title="27:177	As opposed to questionsin FAQs, whichare subject to editorial control, questions in social Q&A sites are often ill-formed or contain spelling errors." ></td>
	<td class="line x" title="28:177	It is thereforecrucialtogetabetterunderstandingofhow they can be automaticallyanalysedand retrieved." ></td>
	<td class="line x" title="29:177	In thiswork,wefocusonseveralpre-processingstrategies and questionsimilaritymeasuresappliedto the task of identifying question paraphrases in a social Q&A site." ></td>
	<td class="line x" title="30:177	We chose WikiAnswerswhich has been ranked by comScoreas the first fastest growing domain of the top 1,500in the U.S. in 2007." ></td>
	<td class="line x" title="31:177	The remainder of the paper is organised as follows." ></td>
	<td class="line x" title="32:177	Section 2 first discusses related work on paraphraseidentificationandquestionparaphrasing." ></td>
	<td class="line x" title="33:177	Section 3 then presents question and answer repositories with special emphasis on social Q&A sites." ></td>
	<td class="line x" title="34:177	Ourmethodstoidentifyquestionparaphrasesaredetailed in section 4." ></td>
	<td class="line x" title="35:177	Finally, we present and analyse the experimental results obtained in section 5 and concludein section6." ></td>
	<td class="line x" title="36:177	2 RelatedWork The identification of question paraphrases in question and answer repositories is related to research focusingon sentenceparaphraseidentification(section 2.1) and query paraphrasing(section 2.2)." ></td>
	<td class="line x" title="37:177	The specific features of question paraphrasinghave also alreadybeen investigated (section2.3)." ></td>
	<td class="line x" title="38:177	2.1 SentenceParaphraseIdentification Paraphrasesare alternative ways to convey the same information (Barzilay and McKeown, 2001)." ></td>
	<td class="line x" title="39:177	Paraphrases can be found at different levels of linguistic structure: words, phrases and whole sentences." ></td>
	<td class="line nc" title="40:177	While word and phrasal paraphrases can be assimilated to the well-studied notion of synonymy, sentencelevel paraphrasingis moredifficult to grasp and cannot be equated with word-for-word or phrase-by-phrase substitution since it might entail changes in the structure of the sentence (Barzilay and Lee, 2003)." ></td>
	<td class="line x" title="41:177	In practice, sentence paraphrases are identified using various string and semantic similarity measures which aim at capturing the semanticequivalence of the sentencesbeing compared." ></td>
	<td class="line x" title="42:177	String similarity metrics, when applied to sentences, consist in comparing the words contained in the sentences." ></td>
	<td class="line oc" title="43:177	There exist many different string similarity measures: word overlap (Tomuro and Lytinen, 2004), longest common subsequence (Islamand Inkpen,2007), Levenshteinedit distance (Dolan et al., 2004), word n-gramoverlap (Barzilay and Lee, 2003) etc. Semantic similarity measures are obtained by first computing the semantic similarity of the words containedin the sentencesbeing compared." ></td>
	<td class="line x" title="44:177	Mihalcea et al.(2006) use both corpusbasedand knowledge-basedmeasuresof the semantic similarity between words." ></td>
	<td class="line x" title="46:177	Both string similarity and semantic similarity might be combined: for instance, Islam and Inkpen (2007) combine semantic similarity with longest common subsequencestring similarity, whileLi et al.(2006)make additionaluse of word ordersimilarity." ></td>
	<td class="line x" title="47:177	2.2 QueryParaphrasing In Information Retrieval, research on paraphrasing is dedicatedto queryparaphrasingwhichconsistsin identifying semantically similar queries." ></td>
	<td class="line x" title="48:177	The overall objective is to discover frequently asked questions and popular topics (Wen et al., 2002) or suggest related queries to users (Sahami and Heilman, 2006)." ></td>
	<td class="line x" title="49:177	Traditionalstring similaritymetrics are usually deemed inefficient for such short text snippetsandalternative similaritymetricshave therefore been proposed." ></td>
	<td class="line x" title="50:177	For instance, Wen et al.(2002) rely onuserclicklogs,basedontheideathatqueriesand questions which result in identical document clicks are boundto be similar." ></td>
	<td class="line x" title="52:177	2.3 QuestionParaphrasing Following previous research in this domain, we define question paraphrases as questions which have all the following properties: (a) they have identical meanings, (b) they have the same answers, and (c) they present alternate wordings." ></td>
	<td class="line x" title="53:177	Question para45 phrases differ from sentence paraphrasesby the additional condition (b)." ></td>
	<td class="line x" title="54:177	This definition encompasses the following questions, taken from the WikiAnswers web site: How many ounces are there in a pound?, Whats the number of ounces per pound?, How many oz." ></td>
	<td class="line x" title="55:177	in a lb.?" ></td>
	<td class="line x" title="56:177	Question paraphrasesshare some properties both with declarative sentence paraphrases and query paraphrases." ></td>
	<td class="line x" title="57:177	On the one hand, questions are complete sentences which differ from declarative sentences by their specific word order and the presence ofquestionwordsandaquestionfocus." ></td>
	<td class="line x" title="58:177	Ontheother hand,questionsareusuallyassociatedwithanswers, whichmakesthemsimilartoqueriesassociatedwith documents." ></td>
	<td class="line x" title="59:177	Accordingly, research on the identification of question paraphrasesin Q&A repositories builds upon both sentenceand queryparaphrasing." ></td>
	<td class="line x" title="60:177	Zhao et al.(2007) propose to utilise user click logs from the Encarta web site to identify question paraphrases." ></td>
	<td class="line x" title="62:177	Jeon et al.(2005) employ a related method, in that they identify similar answers in the Naver Questionand Answerdatabaseto retrieve semantically similar questions, while Jijkoun and de Rijke (2005)includethe answerin the retrieval process to return a ranked list of QA pairs in response to a users question." ></td>
	<td class="line x" title="64:177	Lytinen and Tomuro (2002) suggestyetanotherfeaturetoidentifyquestionparaphrases,namelyquestiontypesimilarity, whichconsistsin determininga questions categoryin orderto matchquestionsonly if they belongto the samecategory." ></td>
	<td class="line x" title="65:177	Ourfocusis on questionparaphraseidentification in social Q&A sites." ></td>
	<td class="line x" title="66:177	Previous research was mostly basedon questionparaphraseidentificationin FAQs (Lytinen and Tomuro, 2002; Tomuro and Lytinen, 2004; Jijkoun and de Rijke, 2005)." ></td>
	<td class="line x" title="67:177	In FAQs, questions and answers are edited by expert information suppliers, which guaranteesstricter conformanceto conventional writing rules." ></td>
	<td class="line x" title="68:177	In social Q&A sites, questionsand answersare writtenby users and may hence be error-prone." ></td>
	<td class="line x" title="69:177	Question paraphrase identification in social Q&A sites has been little investigated." ></td>
	<td class="line x" title="70:177	To our knowledge, only Jeon et al.(2005) have useddatafroma Q&Asite,namelythe Korean Naver portal, to find semanticallysimilar questions." ></td>
	<td class="line x" title="72:177	Our work is related to the latter since it employs a similar dataset, yet in English and from a different socialQ&Asite." ></td>
	<td class="line x" title="73:177	3 QuestionandAnswerRepositories 3.1 Propertiesof Q&ARepositories Questionand answer repositorieshave existed for a long time on the Internet." ></td>
	<td class="line x" title="74:177	Their form has evolved from Frequently Asked Questions (FAQs) to Askan-expert services(Baram-Tsabariet al., 2006)and, even more recently, social Q&A sites." ></td>
	<td class="line x" title="75:177	The latest, which include web sites such as Yahoo!" ></td>
	<td class="line x" title="76:177	Answers and AnswerBag, provide portals where users can ask their own questions as well as answer questions from other users." ></td>
	<td class="line x" title="77:177	Social Q&A sites are increasinglypopular." ></td>
	<td class="line x" title="78:177	For instance,in December2006 Yahoo!" ></td>
	<td class="line x" title="79:177	Answers was the second-most visited education/referencesite on the Internet after Wikipedia accordingto the Hitwise company (Prescott, 2006)." ></td>
	<td class="line x" title="80:177	Even more strikingly, the Q&A portal Naver is the leaderof Internetsearchin SouthKorea, well ahead of Google(Sang-Hun,2007)." ></td>
	<td class="line x" title="81:177	Severalfactorsmightexplainthesuccessofsocial Q&Asites:  they provide answers to questions which are difficulttoanswerwithatraditionalWebsearch or using static reference sites like Wikipedia, for instanceopinionsor adviceabouta specific familysituationor a relationshipproblem;  questionscan be asked anonymously;  usersdo not have to browsea list of documents but ratherobtaina completeanswer;  the answers are almost instantaneous and numerous,due to the large numberof users." ></td>
	<td class="line x" title="82:177	Social Q&A sites record the questions and their answers online, and thus constitute a formidable repository of collective intelligence, including answers to complex questions." ></td>
	<td class="line x" title="83:177	Moreover, they make it possible for learners to reach other people worldwide." ></td>
	<td class="line x" title="84:177	TherelevanceofsocialQ&Asitesforlearning has beenlittleinvestigated." ></td>
	<td class="line x" title="85:177	To our knowledge,there has been only one study which has shown that Korean users of the Naver Question and Answer platform consider that social Q&A sites can satisfactorily and reliablysupportlearning(Lee,2006)." ></td>
	<td class="line x" title="86:177	3.2 WikiAnswers For our experimentswe collecteda dataset of questions and their paraphrases from the WikiAnswers 46 website." ></td>
	<td class="line x" title="87:177	WikiAnswers1 isasocialQ&Asitesimilar to Yahoo!" ></td>
	<td class="line x" title="88:177	Answers and AnswerBag." ></td>
	<td class="line x" title="89:177	As of February2008,it contained1,807,600questions,sortedin 2,404categories(AnswersCorporation,2008)." ></td>
	<td class="line x" title="90:177	Compared with its competitors, the main originality of WikiAnswers is that it relies on the wiki technologyusedin Wikipedia,whichmeansthatanswers can be edited and improved over time by all contributors." ></td>
	<td class="line x" title="91:177	Moreover, the Answers Corporation, which owns the WikiAnswers site, explicitly targets educationaluses and even providesan educator toolkit.2 Another interesting property of WikiAnswers is that users might manually tag question reformulations in order to prevent the duplication of questions asking the same thing in a different way." ></td>
	<td class="line x" title="92:177	When a user enters a question which is not already part of the question repository, the web site displays a list of questions already existing on the site and similar to the one just asked by the user." ></td>
	<td class="line x" title="93:177	The user may then freelyselectthe questionwhichparaphrasesher question,if available, or choose to view one of the proposedalternatives without labelling it as a paraphrase." ></td>
	<td class="line x" title="94:177	The user-labelled question reformulations are stored in order to retrieve the same answerwhenthequestionrephrasingis asked again." ></td>
	<td class="line x" title="95:177	The wiki principle holds for the stored reformulations too, since they can subsequently be edited by other users if they consider that they correspond to another existing questionor actually ask an entirely new question." ></td>
	<td class="line x" title="96:177	It should be noted that contributors get not reward in terms of trust points for providing or editingalternatewordingsfor questions." ></td>
	<td class="line x" title="97:177	We use the wealth of question paraphrasesavailable on the WikiAnswers website as the so called user generated gold standard in our question paraphrasing experiments." ></td>
	<td class="line x" title="98:177	User generated gold standards have been increasingly used in recent years for research evaluation purposes, since they can be easily created from user annotated content." ></td>
	<td class="line x" title="99:177	For instance, Mihalcea and Csomai (2007) use manually annotated keywords (links to other articles) in Wikipedia articles to evaluate their automatic keyword extraction and word sense disambiguationalgorithms." ></td>
	<td class="line x" title="100:177	Similarly, quality assessments provided by users in social media have been used as gold 1http://wiki.answers.com/ 2http://educator.answers.com/ standardsfor the automaticassessmentof postquality in forum discussions (Weimer et al., 2007)." ></td>
	<td class="line x" title="101:177	It should however be kept in mind that user generated gold standardsare not perfect,as alreadynoticedby (Mihalceaand Csomai, 2007), and thus constitutea trade-off solution." ></td>
	<td class="line x" title="102:177	For the experiments described hereafter, we randomly extracted a collection of 1,000 questions along with their paraphrases (totalling 7,434 question paraphrases)from 100 randomly selected FAQ files in the Education category of the WikiAnswers web site." ></td>
	<td class="line x" title="103:177	In what follows, the corpusof 1,000questions is called the target questions collection, while the 7,434 question paraphrases constitute the input questions collection." ></td>
	<td class="line x" title="104:177	The objective of the task is to retrieve the corresponding target question for each input question." ></td>
	<td class="line x" title="105:177	The target question selected is the one which maximises the question similarity value (see section4.2)." ></td>
	<td class="line x" title="106:177	4 Method In order to rate the similarity of input and target questions, we have first pre-processed both the input andtarget questionsandthenexperimentedwith several questionsimilaritymeasures." ></td>
	<td class="line x" title="107:177	4.1 Pre-processing We employthefollowingstepsinpre-processingthe questions: Stop words elimination however, we keep question words such as how, why, what, etc. since these make it possible to implicitly identify the question type (Lytinenand Tomuro,2002;Jijkoun and de Rijke, 2005) Stemming usingthe PorterStemmer3 Lemmatisation usingthe TreeTagger4 Spelling correction using a statistical system basedon languagemodelling(Norvig,2007).5 3http://snowball.tartarus.org/ 4http://www.ims.uni-stuttgart.de/ projekte/corplex/TreeTagger/ 5We used a Java implementation of the system, jSpellCorrect available at http://developer.gauner.org/ jspellcorrect/, trained with the default English training data, to whichwe appendedthe myspellEnglishdictionaries." ></td>
	<td class="line x" title="108:177	47 Stop words were eliminated in all the experimental settings, while stemming and lemmatisation were optionally performed to evaluate the effects of these pre-processing steps on the identification of question paraphrases." ></td>
	<td class="line x" title="109:177	We added spelling correction to the conventional pre-processingsteps, since we target paraphrasing of questions which often contain spelling errors, such as When was indoor pluming invented?" ></td>
	<td class="line x" title="110:177	or What is the largest countery in the western Hemipher?" ></td>
	<td class="line x" title="111:177	Other related endeavours at retrieving question paraphrases have identified spelling mistakes in questions as a significant sourceof errorsin theretrieval process,but have not attemptedto solve this problem (Jijkoun and de Rijke, 2005;Zhao et al., 2007)." ></td>
	<td class="line x" title="112:177	4.2 QuestionSimilarityMeasures We have experimented with several kinds of question similarity measures, belongingto two different familiesof measures: stringsimilaritymeasuresand vector spacemeasures." ></td>
	<td class="line x" title="113:177	4.3 StringSimilarityMeasures Basic string similaritymeasurescomparethe words contained in the questions without taking word frequency into account." ></td>
	<td class="line x" title="114:177	Matchingcoefficient The matchingcoefficient of two questions q1 and q2 represented by the set of distinct words Q1 and Q2 they contain is computed as follows (Manningand Schutze, 1999): matchingcoefficient =| Q1  Q2 | Overlap coefficient The overlap coefficient is computedaccordingto thefollowingformula(Manning and Schutze, 1999): overlapcoefficient = | Q1  Q2 |min(| Q 1 |,| Q2 |) Normalised Edit Distance The edit distance of two questionsisthenumberofwordsthatneedtobe substituted,inserted,or deleted,to transformq1 into q2." ></td>
	<td class="line oc" title="115:177	In order to be able to compare the edit distance with the other metrics, we have used the following formula(Wen et al., 2002)whichnormalisesthe minimum edit distance by the length of the longest questionand transformsit into a similaritymetric: normalisededitdistance = 1 edit dist(q1,q2)max(| q 1 |,| q2 |) Word Ngram Overlap This metric compares the word n-gramsin both questions: ngramoverlap = 1N Nsummationdisplay n=1 | Gn(q1)  Gn(q2) | min(| Gn(q1) |,| Gn(q2) |) where Gn(q) is the set of n-grams of length n in question q and N usually equals 4 (Barzilay and Lee, 2003;Cordeiroet al., 2007)." ></td>
	<td class="line x" title="116:177	4.4 VectorSpaceBasedMeasures Vector space measures represent questions as realvalued vectors by taking word frequency into account." ></td>
	<td class="line x" title="117:177	Term Vector Similarity Questions are represented as term vectors V1 and V2." ></td>
	<td class="line x" title="118:177	The feature values of the vectors are the tf.idf scores of the correspondingterms: tf.idf = (1 + log(tf))  log N + 1df where tf is equal to the frequency of the term in the question, N is the number of target questions and df is the number of target questions in which the term occurs, computed by considering the inputquestionaspartofthetargetquestionscollection (Lytinenand Tomuro,2002)." ></td>
	<td class="line x" title="119:177	The similarity of an input question vector and a target question vector is determined by the cosine coefficient: cosinecoefficient = V1  V2| V 1 |  | V2 | Lucenes Extended Boolean Model The problem of question paraphrase identification can be cast as an Information Retrieval problem, since in real-world applications the user posts a question and the system returns the best matching questions from its database." ></td>
	<td class="line x" title="120:177	We have therefore tested the results obtained using an Information Retrieval system, namely Lucene6, which combines the Vector Space Model and the Boolean model." ></td>
	<td class="line x" title="121:177	Lucene has alreadybeensuccessfullyusedbyJijkounanddeRijke (2005) to retrieve answersfrom FAQ web pages by combining several fields: question text, answer text and the whole FAQ page." ></td>
	<td class="line x" title="122:177	The target questions are indexed as documents and retrieved by transformingthe input questionsinto queries." ></td>
	<td class="line x" title="123:177	6http://lucene.apache.org/java/docs/ 48 T -SW T -SW +SC S -SW S -SW +SC L -SW L -SW Preprocessing 50 60 70 80 90 100 Accuracy T -SW T -SW +SC S -SW S -SW +SC L -SW L -SW Preprocessing 0.5 0.6 0.7 0.8 0.9 1.0 MRR Matching coefficient Overlap coefficient Normalised edit distance Ngram Overlap Term vector similarity Lucene Figure 1: Accuracy (%) and Mean Reciprocal Rank obtained for different question similarity measures and preprocessing strategies: tokens (T), stemming (S), lemmatisation (L), stop words removal (-SW), spelling correction (+SC)." ></td>
	<td class="line x" title="124:177	5 EvaluationandExperimentalResults 5.1 EvaluationMeasures We usethefollowingevaluationmeasuresforevaluating the results: MeanReciprocalRank For a question,the reciprocal rank RR is 1r wherer is the rank of the correct targetquestion,or zeroif thetargetquestionwas not found." ></td>
	<td class="line x" title="125:177	The Mean Reciprocal Rank (MRR) is the meanof the reciprocalranksover all the inputquestions." ></td>
	<td class="line x" title="126:177	Accuracy We define accuracy as Success@1, whichis thepercentageof inputquestionsforwhich the correcttarget questionhas beenretrieved at rank 1." ></td>
	<td class="line x" title="127:177	5.2 ExperimentalResults Figure 1 displays the accuracy and the mean reciprocalranksobtainedwiththedifferentquestionsimilarity measures and pre-processing strategies." ></td>
	<td class="line x" title="128:177	As could be expected, vector space based similarity measures are consistently more accurate than simple string similarity measures." ></td>
	<td class="line x" title="129:177	Moreover, both the accuracy and the MRR are rather high for vector space metrics (accuracy around 80-85% and MRR around0.85-0.9),whichshows that goodresults can be obtainedwith these retrieval mechanisms." ></td>
	<td class="line x" title="130:177	Additional pre-processing, i.e. stemming, lemmatisation and spelling correction, does not ameliorate the tokens minusstop words (T -SW)baseline." ></td>
	<td class="line x" title="131:177	5.3 DetailedError Analysis Stemming and lemmatisation Morphological pre-processing brings about mitigated improvements over the tokens-only baseline." ></td>
	<td class="line x" title="132:177	On the one hand, it improves paraphrase retrieval for questions containingmorphologicalvariantsof the same wordssuchasWhatareanalogiesformitochondria?" ></td>
	<td class="line x" title="133:177	and What is an analogy for mitochondrion?" ></td>
	<td class="line x" title="134:177	On the other hand, it also leads to false positives, such has How was calculus started?, stemmed as How was calculus start?" ></td>
	<td class="line x" title="135:177	and lemmatisedas How be calculus start?, which is mapped by Lucene to the question How could you start your MA English studies?" ></td>
	<td class="line x" title="136:177	instead of Who developed calculus?." ></td>
	<td class="line x" title="137:177	The negative effect of stemming has already been identified by (Jijkoun and de Rijke, 2005) and our results are consistentwith this previousfinding." ></td>
	<td class="line x" title="138:177	Spelling correction We expected that spelling correction would have a positive impact on the results." ></td>
	<td class="line x" title="139:177	There are indeed cases when spelling correction helps." ></td>
	<td class="line x" title="140:177	For instance,given the questionHow do you become an anestesiologist?, it is impossible to retrieve the target questionHowmanyyears of medical school do you need to be an anesthesiolgist?" ></td>
	<td class="line x" title="141:177	withoutspellingcorrectionsince anesthesiologist is ill-spelledbothintheparaphraseandthetargetquestion." ></td>
	<td class="line x" title="142:177	49 Lemma + Stop words + Spelling correction Lemma + Stop words Stem + Stop words + Spelling correction Stem + Stop words Token + Stop words + Spelling correction Token + Stop words (a) Lucene Term Vector similarity Word Ngram overlap Overlap coefficient Matching coefficient Edit distance (b) Figure 2: Comparisonof the different pre-processingstrategies 2(a) and methods2(b) for 50 input questions." ></td>
	<td class="line x" title="143:177	For the pre-processingcomparison,the Luceneretrieval methodhas been used,whilethe methodshave been comparedusing baselinepre-processing(tokensminusstopwords)." ></td>
	<td class="line x" title="144:177	A filledsquareindicatesthatthetargetquestionhasbeenretrieved at rank 1, whilea blanksquareindicatesthat the target questionhas not been retrieved at rank 1." ></td>
	<td class="line x" title="145:177	Therearehowever caseswhenspellingcorrection inducesworseresults,sinceit is accuratein onlyapproximately 70% of the cases (Norvig, 2007)." ></td>
	<td class="line x" title="146:177	A majorsourceof errorslies in namedentitiesand abbreviations, which are recognised as spelling errors when they are not part of the training lexicon." ></td>
	<td class="line x" title="147:177	For instance, the question What are the GRE score required to get into top100 US universities?" ></td>
	<td class="line x" title="148:177	(where GRE stands for Graduate Record Examination) is badly corrected as What are the are score required to get into top100US universities?." ></td>
	<td class="line x" title="149:177	Spelling correction also induces an unexpected side effect, when the spelling error does not affect the questions focus." ></td>
	<td class="line x" title="150:177	For instance, consider the following question, with a spelling error: What events occured in 1919?, which gets correctly mapped to the target questionWhat importantevents happened in 1919?" ></td>
	<td class="line x" title="151:177	by Lucene;however, after spellingcorrection (What events occurred in 1919?), it has a biggeroverlapwithanentirelydifferentquestion: What events occurred in colonial South Carolina 16741775?." ></td>
	<td class="line x" title="152:177	The latter example also points at another limitation of the evaluatedmethods,whichdo not identify semantically similar words, such as occurred and happened." ></td>
	<td class="line x" title="153:177	Errors in the gold standard Some errors can actuallybetracedbacktoinaccuraciesinthegoldstandard: some question pairs which have been flagged as paraphrasesby the WikiAnswerscontributors are actuallydistantlyrelated." ></td>
	<td class="line x" title="154:177	Forinstance,thequestions When was the first painting made?" ></td>
	<td class="line x" title="155:177	and Where did leanardo da vinci live?" ></td>
	<td class="line x" title="156:177	are marked as reformulations of the question What is the secret about mona lisa?" ></td>
	<td class="line x" title="157:177	Though these questions all share a common broad topic, they cannot be considered as relevant paraphrases." ></td>
	<td class="line x" title="158:177	We can deduce several possible improvements from what precedes." ></td>
	<td class="line x" title="159:177	First, named entities and abbreviations play an important role in questions and shouldthereforebe identifiedand treateddifferently from other kinds of tokens." ></td>
	<td class="line x" title="160:177	This could be achieved by using a named entity recognition component during pre-processing and then assigning a higher weight to named entities in the retrieval process." ></td>
	<td class="line x" title="161:177	This shouldalso improve the resultsof spellingcorrectionsincenamedentitiesandabbreviationscould be excluded from the correction." ></td>
	<td class="line x" title="162:177	Second, semantic errors could be dealt with by using a semantic similaritymetricsimilarto those used in declarative sentence paraphrase identification (Li et al., 2006; Mihalceaet al., 2006;Islamand Inkpen,2007)." ></td>
	<td class="line x" title="163:177	5.4 ComparisonandCombinationof the Methods In a second part of the experiment, we investigated whether the evaluated methods display independent 50 error patterns, as suggested by our detailed results analysis." ></td>
	<td class="line x" title="164:177	Figure 2 confirms that the pre-processing techniques as well as the methods employed result in dissimilarerror patterns." ></td>
	<td class="line x" title="165:177	We therefore combined several methods and pre-processing techniques in orderto verify if we couldimprove accuracy." ></td>
	<td class="line x" title="166:177	We obtainedthe best results by performinga majority vote combination of the following methods and pre-processingstrategies: Lucene, Term Vector Similarity with stemming and Ngram Overlap with spellingcorrection." ></td>
	<td class="line x" title="167:177	The combinationyieldedan accuracy of 88.3%, that is 0.9% over the best Lucene resultswith an accuracy of 87.4%." ></td>
	<td class="line x" title="168:177	6 ConclusionandOutlook In thispaper, we have shown thatit is feasibleto answerlearnersquestionsbyretrievingquestionparaphrases from social Q&A sites." ></td>
	<td class="line x" title="169:177	As a first step towards this objective, we investigated several questionsimilaritymetricsandpre-processingstrategies, usingWikiAnswersas inputdataandusergenerated gold standard." ></td>
	<td class="line x" title="170:177	The approachis however not limited to this dataset and can be easily applied to retrieve questionparaphrasesfrom other socialQ&Asites." ></td>
	<td class="line x" title="171:177	We also performed an extended failure analysis whichprovidedusefulinsightson how resultscould be further improved by performing named entity analysisand usingsemanticsimilaritymetrics." ></td>
	<td class="line x" title="172:177	AnotherimportantchallengeinusingsocialQ&A sites for educational purposes lies in the quality of the answers retrieved from such sites." ></td>
	<td class="line x" title="173:177	Previous researchontheidentificationofhighqualitycontentin socialQ&Asiteshasdefinedanswerqualityinterms of correctness, well-formedness,readability, objectivity, relevance, utility and interestingness(Jeon et al., 2006; Agichtein et al., 2008)." ></td>
	<td class="line x" title="174:177	It is obvious that all these elements play an important role in the acceptance of the answers by learners." ></td>
	<td class="line x" title="175:177	We therefore plan to integrate quality measures in the retrieval process and to perform evaluations in a real educationalsetting." ></td>
	<td class="line x" title="176:177	Acknowledgments ThisworkwassupportedbytheEmmyNoetherProgrammeof theGermanResearchFoundation(DFG) undergrant No." ></td>
	<td class="line x" title="177:177	GU 798/3-1." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="Data not found"></td>
	<td class="line x" title="1:160	Coling 2008: Proceedings of the workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), pages 7785 Manchester, August 2008 Looking up phrase rephrasings via a pivot language Aurelien Max LIMSI-CNRS & Universite Paris-Sud 11 Orsay, France aurelien.max@limsi.fr Michael Zock LIF-CNRS Marseilles, France michael.zock@lif.univ-mrs.fr Abstract Rephrasing text spans is a common task when revising a text." ></td>
	<td class="line x" title="2:160	However, traditional dictionaries often cannot provide direct assistance to writers in performing this task." ></td>
	<td class="line x" title="3:160	In this article, we describe an approach to obtain a monolingual phrase lexicon using techniques used in Statistical Machine Translation." ></td>
	<td class="line x" title="4:160	A part to be rephrased is first translated into a pivot language, and then translated back into the original language." ></td>
	<td class="line x" title="5:160	Models for assessing fluency, meaning preservation and lexical divergence are used to rank possible rephrasings, and their relative weight can be tuned by the user so as to better address her needs." ></td>
	<td class="line x" title="6:160	An evaluation shows that these models can be used successfully to select rephrasings that are likely to be useful to a writer." ></td>
	<td class="line x" title="7:160	1 Introduction Once an initial draft of a text is ready, writers face the difficult phase of text revision." ></td>
	<td class="line x" title="8:160	Changes may be made for various reasons: correcting spelling or grammatical errors, making the text locally more fluent (for example, in case it contains wordings that are literal translations from another language), avoiding close repetitions or enforcing terminological consistency, or better conveying the writers ideas." ></td>
	<td class="line x" title="9:160	All these changes can affect text spans of various sizes, and can globally be seen as cases of rephrasing." ></td>
	<td class="line x" title="10:160	Paraphrasing involves rephrasings c2008." ></td>
	<td class="line x" title="11:160	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="12:160	Some rights reserved." ></td>
	<td class="line x" title="13:160	that are semantically equivalent, but targets terminology and style that are more suited to the context of use of a text." ></td>
	<td class="line x" title="14:160	In a broad sense, rephrasing may involve wordings that convey different meanings in an attempt to correct or make the writers thoughts more precise." ></td>
	<td class="line x" title="15:160	Research concerned with the study of changes between writers drafts (textual genetic criticism) can help in understanding writers rewriting processes, and can be supported by automatic tools (e.g.(Bourdaillet et al., 2007))." ></td>
	<td class="line x" title="17:160	In this work, we address the issue of how writers can be assisted in finding wordings that correspond to multi-word phrases of any nature." ></td>
	<td class="line x" title="18:160	Given an original text span, the writer is presented with a list of rephrasings that are organized by taking into account the context of the rephrasing and userspecified preferences." ></td>
	<td class="line x" title="19:160	Our proposal can therefore be used as a lexicon operating at the phrasal level, which can be used either when writers are faced with a tip-of-the-tongue lexical access problem, or when they are not completely satisfied with some initial wording." ></td>
	<td class="line x" title="20:160	In the former case, they may be able to come up with some words or phrases that would be different in meaning from what they are looking for, and in the latter they may be looking for a near-synonymous wording that is more appropriate to a given context, for example to avoid close repetitions." ></td>
	<td class="line x" title="21:160	To define such a phrase lexicon and its possible mode of use, the following questions should be considered: (a) how the lexicon entries are obtained, (b) what can be the entry points and how can one navigate in the results, and (c) how the results are displayed." ></td>
	<td class="line x" title="22:160	Rephrasing can be more or less complex and problematic depending on the consequences at the various levels:  In the simplest case, replacing one element 77 by another does not have any consequences overall." ></td>
	<td class="line x" title="23:160	This is often the case when a word is replaced by its synonym or a similar word." ></td>
	<td class="line x" title="24:160	 An entire expression or sentence is replaced by its equivalent." ></td>
	<td class="line x" title="25:160	In this case the problem is generally to obtain a good fit with regard to the surrounding text, the replacing unit being well-formed by definition." ></td>
	<td class="line x" title="26:160	 The replacing element may require syntactic changes of the matrix, i.e. the text in which it is embedded." ></td>
	<td class="line x" title="27:160	This occurs if the source word and the target word have different syntactic requirements, and this can be seen as a good reason to replace entire sentences, or at least sentence fragments." ></td>
	<td class="line x" title="28:160	This assumes a pattern dictionary, where patterns achieving the same conceptual goal are grouped together." ></td>
	<td class="line x" title="29:160	In the next section, we discuss limitations of traditional dictionaries with respect to the targeted task, and describe an approach to obtain phrase rephrasings through a pivot translation into another language." ></td>
	<td class="line x" title="30:160	In section 3, we discuss the issue of the organization of the results along various axis: fluency of rephrasings, preservation of meaning, and lexical divergence between original text spans and rephrasings." ></td>
	<td class="line x" title="31:160	We then present an initial evaluation of our approach on French rephrasing in section 4." ></td>
	<td class="line x" title="32:160	Related work is presented in section 5, and we finally discuss our approach and our future work in section 6." ></td>
	<td class="line x" title="33:160	2 Lexicon of phrase rephrasings Dictionaries and semantic resources such as thesauri can be used to find words by following links of different kinds from a given entry point." ></td>
	<td class="line x" title="34:160	WordNet (Fellbaum, 1998) is one such resource." ></td>
	<td class="line x" title="35:160	For a proposal of other kinds of links and navigational aids see also (Zock and Bilac, 2004; Zock, 2006; Zock, 2007)." ></td>
	<td class="line x" title="36:160	Words are the traditional units that people expect to find in dictionaries." ></td>
	<td class="line x" title="37:160	Whereas some types of dictionaries can contain multiword expressions, such as compound nouns and terms, those correspond to linguistically-motivated units." ></td>
	<td class="line x" title="38:160	In order to rephrase phrases of any type with a dictionary, a writer may have to look up several words, combine various information and validate the result using her experience of the language or throught the use of a concordancer." ></td>
	<td class="line x" title="39:160	Moreover, dictionary lookups are in most cases insensitive to the actual context of words in an existing text." ></td>
	<td class="line x" title="40:160	It is therefore the responsibility of its users to ensure that a choice is appropriate for a given context, which can be quite difficult, for example when writing in a second language." ></td>
	<td class="line x" title="41:160	One way of obtaining phrase rephrasings is by looking at phrases that occur in similar contexts in a monolingual corpus (e.g.(Munteanu and Marcu, 2006))." ></td>
	<td class="line x" title="43:160	In order to extract a comprehensive phrase lexicon, a very large number of sentences should be compared to extract potential rephrasings, which furthermore may often correspond to phrases that are too remotely connected." ></td>
	<td class="line x" title="44:160	Parallel corpora provide the interesting advantage that it is reasonable to assume that elements from one side of the corpus should be aligned to elements on the other side, and that associations of elements can be reinforced by the number of times they occur in the corpus." ></td>
	<td class="line x" title="45:160	Various approaches for word alignment from parallel corpora have been proposed (see e.g.(Och and Ney, 2003)), and the phrase-based approach to Statistical Machine Translation (Koehn et al., 2003) has led to the development of heuristics for obtaining alignments between phrases of any number of words." ></td>
	<td class="line x" title="47:160	Unfortunately, monolingual parallel corpora aligned at the sentence level, such as various translations of a novel in a foreign language, are resources that are extremely scarce." ></td>
	<td class="line x" title="48:160	Using bilingual parallel corpora, a much more common resource, one can obtain various possible phrase translations for a given source phrase, as well as some estimate of the distribution of probabilities for the various translations of that phrase." ></td>
	<td class="line x" title="49:160	Such N  M alignements can capture lexical translations (e.g. exigeons  ask for, call for, demand, expect, request, etc.) and phrasal literal or idiomatic translations (e.g. un bon debut  a good approach, a good first move, a good starting point, a positive initiative, an encouraging start, the right road, etc.), but can also capture noise depending on the alignment heuristics used (e.g. les etats candidats (candidate countries)  Member States, the candidate countries were to, the accession countries have called for, candidate, the, etc.) Different target phrases associated with a given source phrase can either represent paraphrases or phrases with different meanings." ></td>
	<td class="line x" title="50:160	Among the limitations of this type of phrasal alignments are their inability to model non-consecutive words and to generalize the con78 tents of phrases, and the fact that their translations are not conditioned on their context." ></td>
	<td class="line x" title="51:160	If phrase extraction is performed in two opposite directions, then it is possible to find the possible translations of a given phrase (and their conditional probabilities), and then to translate back those phrases into the original language." ></td>
	<td class="line x" title="52:160	In this approach proposed by (Bannard and Callison-Burch, 2005), the second language acts as a pivot, as illustrated on figure 1." ></td>
	<td class="line x" title="53:160	Because of the nature of the possible alignments, this pivot can represent various senses, which in context can be equivalent or comparable to that of the original phrase." ></td>
	<td class="line x" title="54:160	In turn, the same phenomena can take place when translating back from the pivot phrases to the original language, and the resulting rephrasings can be equivalent or comparable in meaning to that of the original phrase in some context, may also be incomplete and/or require other changes in the rephrased sentence." ></td>
	<td class="line x" title="55:160	Bannard and Callison-Burch have defined a paraphrase probability between two phrases p1 and p2 (with p1 negationslash= p2) that uses conditional probabilities between phrases and sums over all possible pivot phrases: P(p2|p1) = argmax p2negationslash=p1 summationdisplay pivot P(pivot|p1)P(p2|pivot) (1) (Callison-Burch, 2007) measured the importance of various factors impacting the quality of the paraphrases obtained." ></td>
	<td class="line x" title="56:160	Using manually built alignments yields a significant improvement in paraphrase quality, showing that if better alignments are available the proposed approach can produce better paraphrases." ></td>
	<td class="line x" title="57:160	Alignments between several languages can be used for finding pivot phrases, and using several simulateously tend to improve alignment quality and therefore paraphrases themselves." ></td>
	<td class="line x" title="58:160	Using a language model to find paraphrases that maximize its score in the original sentencial context leads to improved fluency, but has a negative impact on meaning preservation." ></td>
	<td class="line x" title="59:160	Lastly, restricting pivot phrases to those actually aligned in a test aligned bilingual corpus improves paraphrase quality, which illustrates the importance of disambiguating source phrases relatively to the pivot language." ></td>
	<td class="line x" title="60:160	The rephrasings obtained can be classified into several categories when used in context:  A rephrasing can be a paraphrase that is valid in all contexts (e.g. je vous donne raison  je suis daccord avec vous), in specific grammatical contexts (e.g. pouvoir accueillir dans de bonnes conditions les pays  comme il se doit) and/or pragmatic contexts (e.g. cest un bon debut  nous partons du bon pied)." ></td>
	<td class="line x" title="61:160	 A rephrasing can contain shifts in meaning with the original phrase which might be acceptable or not (e.g. nous voulons apporter notre contribution `a ce debat  donner de la valeur)." ></td>
	<td class="line x" title="62:160	Some such rephrasings reveal a natural bias towards the bilingual corpus used (e.g. le prochain elargissement constitue la principale tache  l objectif principal)." ></td>
	<td class="line x" title="63:160	 A rephrasing can be ill-formed but still contain elements of interest to a writer (e.g. ceux qui disent que  se trompent  devrions `a nouveau reflechir; here a rephrasing such as devraient `a nouveau reflechir could be deemed acceptable in some contexts)." ></td>
	<td class="line x" title="64:160	 A rephrasing may introduce a contradiction in a specific context (e.g. ce nest pas le moment de se montrer hesitant  il est trop tot pour)  A rephrasing may be inexploitable because it is syntactically ill-formed in context and does not contain any element of interest, or is too close to the original phrase." ></td>
	<td class="line x" title="65:160	The most natural entry point to such a resource is by entering a phrase or selecting it in a text under revision." ></td>
	<td class="line x" title="66:160	Approximate search can also be of use, as done in some concordancer software, for example by allowing the user to enter word-based regular expressions mixing literal words, word lemmas, word part-of-speech or even word classes (e.g. types of named entities)." ></td>
	<td class="line x" title="67:160	Boolean queries on indexes of word lemmas can also be used to offer yet more flexibility to search the lexicon, but at the cost of more candidate results." ></td>
	<td class="line x" title="68:160	Once results are returned, they can recursively be reused as source phrases, so as to offer a means to navigate by iterative refining." ></td>
	<td class="line x" title="69:160	3 Evaluation of rephrasings in context for ranking results Each candidate phrase rephrasing for a given phrase must be evaluated in order to define a ranking order for presentation to the user, and possibly 79 Figure 1: Example of rephrasing for the French phrase ce nest pas le moment de using English as pivot." ></td>
	<td class="line x" title="70:160	to discard some of them." ></td>
	<td class="line x" title="71:160	The proposed ranking should reflect as best as possible the preferences of the user for the task at hand in order to minimize reading time and maintain the users interest in using the phrase lexicon." ></td>
	<td class="line x" title="72:160	It is essential to give the user some control over how the results are returned depending on what is more important to her." ></td>
	<td class="line x" title="73:160	For example, (Ferret and Zock, 2006) have proposed to present results from a dictionary enriched with topical associations in chunks to allow for categorial search." ></td>
	<td class="line x" title="74:160	There will be cases where the user may find acceptable only grammatical results, while in other cases the user might accept agrammatical results provided they contain interesting suggestions." ></td>
	<td class="line x" title="75:160	Moreover, it seems extremely important that result ranking can take into account the phrase substitution into the original context." ></td>
	<td class="line x" title="76:160	Considering how the proposed phrase lexicon is built, the pivot paraphrasing probability of equation 1 (PIV) can be used as a baseline ordering." ></td>
	<td class="line x" title="77:160	Such a model reflects some strength of association between a rephrased phrase and the original phrase using the extracted phrases and conditional probabilities derived from a bilingual training corpus." ></td>
	<td class="line x" title="78:160	It is therefore expected that results will be biased towards that corpus if the latter belongs to a particular genre or theme." ></td>
	<td class="line x" title="79:160	Nonetheless, one can expect that some associations will be general enough to be of general interest." ></td>
	<td class="line x" title="80:160	In addition, several models that users can interpret as ranking criterion can be used simulateneously using the log-linear framework traditionally used in SMT systems." ></td>
	<td class="line x" title="81:160	However, contrary to what is done in SMT, the weight of the models cannot be automatically optimized if we do not use an automatic evaluation of rephrasing quality, the definition of which depending heavily on the subjective appreciation of a user." ></td>
	<td class="line x" title="82:160	Equation 2 shows how the score of a rephrasing p2 of p1 can be computed, where M is the set of models used, hm is the logarithm of the normalized score of a model and m its weight (withsummationtextmM m = 1), and C is the original sentence and the placeholder for the rephrased phrase." ></td>
	<td class="line x" title="83:160	s(p2,p1,C) = summationdisplay mM mhm(p1,p2,C) (2) 3.1 Control over fluency As noted by (Mutton et al., 2007), the notion of sentence-level fluency is not uniformely agreed upon, and its evaluation by human judges is sometimes found subjective, but in practice judges can obtain high levels of agreement about what can be considered fluent or not." ></td>
	<td class="line x" title="84:160	Like (Callison-Burch, 2007), we can use a language model (LM) to assess the local fluency of a sentence after a phrase has been substituted with a rephrasing." ></td>
	<td class="line x" title="85:160	A degradation in score (with a fluent original sentence) can indicate that the rephrasing segment should be adapted to the sentence, and/or that the sentence itself should be modified in order to integrate the new phrase as is. Syntax parsers can produce various information that can be relevant for assessing the fluency of sentences, which can be used as features from different parsers for classification that can correlate well with human judgment (Mutton et al., 2007)." ></td>
	<td class="line x" title="86:160	When substituting a part of a sentence with another phrase and if this substitution does not require other changes in the sentence, then at least the dependency relationships between words outside that phrase should be preserved." ></td>
	<td class="line x" title="87:160	This seems coherent with our objective of focussing on the task of phrase rephrasing when it is possible to modify only a given phrase and obtain an acceptable result." ></td>
	<td class="line x" title="88:160	80 3.2 Control over meaning preservation The preservation of dependency relationships outside of the rephrased phrase can also play a role in terms of meaning preservation." ></td>
	<td class="line x" title="89:160	Dependency relationships connecting words in the phrase and words outside the phrase (i.e., whose governor is outside the phrase and dependant inside it, or the opposite) should still exist after such a substitution, but possibly with a modified dependency target in the phrase." ></td>
	<td class="line x" title="90:160	Indeed, those relationships denote the grammatical role of the words of the phrase relative to their context, and if those are preserved then it is more likely that meaning is preserved." ></td>
	<td class="line x" title="91:160	We use a model based on dependency preservation (DEP) which involves relationships outside the rephrased phrase and relationships crossing a boundary of that phrase." ></td>
	<td class="line x" title="92:160	The score is based on some proportion of the number of such dependencies found after substitution over the number of original dependencies (see (Max, 2008) for details)." ></td>
	<td class="line x" title="93:160	Another way of controlling for meaning preservation is to ensure that only the pivot phrases with the same meaning as the original phrase are kept (and then their back translations)." ></td>
	<td class="line x" title="94:160	(Callison-Burch, 2007) has shown the positive impact on paraphrase quality of using a controlled pivot present in an aligned sentence in a test bilingual corpora." ></td>
	<td class="line x" title="95:160	Phrase disambiguation techniques have been proposed for SMT and could be applied to the problem at hand (e.g.(Stroppa et al., 2007))." ></td>
	<td class="line x" title="97:160	In an interactive context, it makes sense to let the user the opportunity to control for phrase sense by rejecting bad pivot phrases if she wants to, which is then similar to Callison-Burchs experiment settings." ></td>
	<td class="line x" title="98:160	This manual selection must of course be optional, but can be used when a user prefers a stricter control on meaning." ></td>
	<td class="line x" title="99:160	Another possibly interesting use is to disambiguate in a pivot language corresponding to ones native language when writing in a foreign language." ></td>
	<td class="line x" title="100:160	3.3 Control over lexical divergence There will be cases when possible rephrasings will be very close to their original phrase, differing for example by only punctuation marks or verbal forms1." ></td>
	<td class="line x" title="101:160	Writers may sometimes prefer rephrasings that differ by just one word, or on the contrary rephrasings that use a set of completely different words." ></td>
	<td class="line x" title="102:160	To account for differents words be1This is particularly the case when aligning between low and highly inflected languages." ></td>
	<td class="line x" title="103:160	Figure 2: Bilingual phrase lexicon statistics tween an original phrase and its rephrasing, we use a model (LEM) that returns a proportion of lemmas for full words that only belong to a rephrasing over all such lemmas for an initial phrase and its rephrasing (see (Max, 2008))." ></td>
	<td class="line x" title="104:160	4 Experiments and evaluation We carried out an evaluation on the local rephrasing of French sentences, using English as the pivot language.2 We extracted phrase alignments of up to 7 word forms using the Giza++ alignment tool (Och and Ney, 2003) and the grow-diag-final-and heuristics described in (Koehn et al., 2003) on 948,507 sentences of the French-English part of the Europarl corpus (Koehn, 2005) and obtained some 42 million phrase pairs for which probabilities were estimated using maximum likelihood estimation." ></td>
	<td class="line x" title="105:160	Statistics for the extracted lexicons are reported on figure 2." ></td>
	<td class="line x" title="106:160	Entries of the monolingual phrase lexicon are built dynamically from the entries of the monolingual lexicons." ></td>
	<td class="line x" title="107:160	For the LM model, we used a 5-gram language model trained on the French part of the corpus using Kneser-Ney smoothing." ></td>
	<td class="line x" title="108:160	The robust parser for French SYNTEX (Bourigault et al., 2005) was used to obtain lemmas for word and labeled dependency relationships between words, used respectively for the LEM and DEP models." ></td>
	<td class="line x" title="109:160	Robust parsers provide the advantage that they can provide partial analysis for correct chunks in agrammatical sentences, but they can also recover information from agrammatical chunks which can be undesirable in this case.3 A test corpus of 82 sentences that were not used for extracting phrase alignments and learning the 2The main motivation for this choice was that we could easily have access to French native speakers for manual evaluation." ></td>
	<td class="line x" title="110:160	We plan however to start new experiments using English, as well as experiments using another highly inflected language as pivot such as Spanish." ></td>
	<td class="line x" title="111:160	3We intend to use several parsers for English implementing different approaches as in (Mutton et al., 2007), but we had access to only one parser for French." ></td>
	<td class="line x" title="112:160	81 language model was built." ></td>
	<td class="line x" title="113:160	A human judge selected one phrase of length 3 words or more per sentence that would be a good candidate for rephrasing, and which was accepted if it belonged to the French-English lexicon4." ></td>
	<td class="line x" title="114:160	We kept at most the 20 first rephrasings obtained using the baseline PIV model, and asked two French native speakers to evaluate on a 5-level scale each the 1648 reformulated sentences obtained on fluency, meaning preservation, and authoring value, where the latter was described in the following way: (5) the rephrasing can be directly reused for revising a text, (4) the rephrasing can be used with a minor change, (3) the rephrasing contains elements that could be used for a good rephrasing, (2) the rephrasing contains elements that could suggest a rephrasing, and (1) the rephrasing is useless." ></td>
	<td class="line x" title="115:160	After the judges had completed manual annotation, smoothing of the scores was done by keeping mean scores for each sentence." ></td>
	<td class="line x" title="116:160	We measured a value of 0.59 standard deviation for score differences between judges for grammaticality, 0.7 for meaning preservation and 0.8 for authoring value." ></td>
	<td class="line x" title="117:160	Those values can indicate a growing difficulty in judging those characteristics, and in particular that judging authoring value on the proposed scale is more dependant on personal judgment." ></td>
	<td class="line x" title="118:160	Results of mean scores for the first rank solutions with various model combinations with uniform weights are reported on figure 3, and results for mean authoring value scores depending on the number of top results presented to the user are reported on figure 4." ></td>
	<td class="line x" title="119:160	Authoring value scores are lower, which can be explained by the fact that rephrasings with bad fluency and/or meaning preservation scores will penalize authoring value scores according to our scale." ></td>
	<td class="line x" title="120:160	The best results are obtained when combining all models, which remains true when considering mean results up to at least 8 rephrasings." ></td>
	<td class="line x" title="121:160	The baseline PIV model seems to have the most impact, but all other models also contribute in different ways." ></td>
	<td class="line x" title="122:160	This suggests that which model should be used (or its weight in our framework) could be chosen by a user." ></td>
	<td class="line x" title="123:160	In the following example, the LEM model helped select a rephrasing which obtained good scores: Original sentence: ce que je vous propose donc, 4This is a limitation of our evaluation, as our annotator was not strictly speaking revising a text that she wrote." ></td>
	<td class="line x" title="124:160	We hope to be able to conduct task-based experiments in the future." ></td>
	<td class="line x" title="125:160	fluency meaning authoring PIV (baseline) 4.46 4.18 3.62 LM 4.28 3.62 3.45 DEP 4.35 3.68 3.43 LEM 4.05 3.21 3.28 PIV+LM 4.65 4.06 3.82 PIV+DEP 4.58 4.27 3.66 PIV+LEM 4.37 4.00 3.76 LM+DEP 4.49 3.81 3.68 LM+LEM 4.28 3.59 3.56 PIV+LM+DEP 4.65 4.05 3.92 PIV+LM+LEM 4.61 4.02 3.97 PIV+DEP+LEM 4.57 4.17 4.02 LM+DEP+LEM 4.37 3.69 3.64 PIV+LM+DEP+LEM 4.68 4.09 4.05 Figure 3: Mean results at first rank for various model combinations (uniform weighting) Figure 4: Mean authoring value scores depending on the number of results presented to the user cest de travailler dans cette direction  (what I therefore propose is to work towards this ) Rephrased sentence: ce que je vous propose donc, cest de cooperer dans ce sens  (work towards this goal ) Figures 5 and 6 show two examples of rephrasings in French, whereby for each rephrasing the ranks given by PIV, LM and the combination of all mentioned models are shown." ></td>
	<td class="line x" title="126:160	5 Related work While the traditional view of lexicons is wordbased, we may as well consider larger units, including sentences." ></td>
	<td class="line x" title="127:160	Corpus Pattern Analysis (CPA) (Hanks and Pustejovsky, 2005) is concerned with the prototypical syntagmatic patterns with which words in use are associated." ></td>
	<td class="line x" title="128:160	For example, the meaning of take place is different from the mean82 Rephrasings Ranks given by model(s) PIV LM PIV+LM+DEP+LEM quelques points essentiels 1 3 1 les points essentiels 19 1 2 plusieurs questions importantes 17 4 3 des points essentiels 8 6 4 deux ou trois questions importantes 5 9 5 plusieurs points importants 11 2 5 un certain nombre de questions importantes 17 7 7 certains points importants 2 5 8 un certain nombre de points importants 3 8 9 certains elements tr`es importants 13 11 10 une serie de points importants 4 12 11 quelques accents importants 5 15 11 des choses extremement importantes 13 14 11 quelques remarques importantes , 8 16 14 des points importants 12 10 15 quelques choses tr`es importantes 13 17 16 certains points importants , 8 13 17 quelques points essentiels sur 20 18 17 de certains elements tr`es importants 13 19 19 placer quelques accents importants 5 20 20 Figure 5: Examples of rephrasings for the phrase quelques points importants in je voudrais mentionner quelques points importants de la directive Rephrasings Ranks given by model(s) PIV LM PIV+LM+DEP+LEM vous avez raison 1 1 1 je suis d accord avec vous 2 2 2 je suis d accord 3 6 3 je conviens avec vous 6 5 4 je partage votre avis 7 4 5 vous avez raison de dire 10 3 5 je pense comme vous 7 8 7 je suis parfaitement d accord avec vous 12 7 8 je partage votre point de vue 12 9 9 je vous rejoins 7 10 10 , je vous donne raison 3 12 11 l`a , je vous donne raison 3 13 12 tu as raison 16 11 12 vous avez raison de 10 14 14 je partage votre point 12 15 15 je partage votre point de 12 16 16 Figure 6: Examples of rephrasings for the phrase je vous donne raison in `a cet egard bien precis , je vous donne raison , monsieur le commissaire 83 ing of take his place, due to the possessive determiner." ></td>
	<td class="line x" title="129:160	The actual meaning of words depends on the context in which they are used." ></td>
	<td class="line x" title="130:160	The work done by the team of Gross on lexicon-grammar (e.g.(Gross, 1984)) showed that a relatively small set of clause patterns and syntactic constraints suffices to cover most of common French." ></td>
	<td class="line x" title="132:160	Comparable monolingual corpora have been used for automatic paraphrasing." ></td>
	<td class="line oc" title="133:160	Barzilay and Lee (Barzilay and Lee, 2003) learned paraphrasing patterns as pairs of word lattices, which are then used to produce sentence level paraphrases." ></td>
	<td class="line o" title="134:160	Their corpus contained news agency articles on the same events, which allows precise sentence paraphrasing, but on a small sets of phenomena and for a limited domain." ></td>
	<td class="line x" title="135:160	As sentential paraphrasing is more likely to alter meaning, Quirk et al.(Quirk et al., 2004) approached paraphrasing as a monotonous decoding by a phrase-based SMT system." ></td>
	<td class="line x" title="137:160	Their corpus consisted of monolingual sentences extracted from a comparable corpus that were automatically aligned so as to allow aligned phrase extraction." ></td>
	<td class="line x" title="138:160	Pang et al.(Pang et al., 2003) used parallel monolingual corpora built from news stories that had been independantly translated several times to learn lattices from a syntax-based alignment process." ></td>
	<td class="line x" title="140:160	Bannard and Callison-Burch (Bannard and Callison-Burch, 2005) proposed to use pivot translation for paraphrasing phrases." ></td>
	<td class="line x" title="141:160	Fujita (Fujita, 2005) proposed a transfer-and-revision framework using linguistic knowledge for generating paraphrases in Japanese and a model for error detection." ></td>
	<td class="line x" title="142:160	At the lexical level, a recent evaluation on English lexical substitution was held (McCarthy and Navigli, 2007) in which systems had to find lexical synonyms and disambiguate the context." ></td>
	<td class="line x" title="143:160	6 Discussion and future work In this article, we have presented an approach for obtaining rephrasings for short text spans from parallel bilingual corpora." ></td>
	<td class="line x" title="144:160	These rephrasings can be ranked according to user-defined preferences, and the weights of the models used can be dynamically adjusted by a user depending on what features are more important to her, for instance after an initial list of candidates has been proposed by the system." ></td>
	<td class="line x" title="145:160	Indeed, good candidates include paraphrases, but also more generally phrases that could help a writer revise a text with some shifts in meaning, even if at the cost of some corrections to make the resulting text grammatical." ></td>
	<td class="line x" title="146:160	Furthermore, search for rephrasings can be iteratively performed using candidate rephrasings as source phrases, and the user can have some fine-grained control if selecting or rejecting possible pivot phrases manually." ></td>
	<td class="line x" title="147:160	Possible user interfaces to this proposed bilingual phrase lexicon could include rephrasing memory features to learn from interaction with the user, and concordancing features to display the context of use in the bilingual corpus of the segments used to build the relevant lexicon entries." ></td>
	<td class="line x" title="148:160	In the latter case, the similarity used to select examples could take the context of the phrases into account in terms of dependency relationships." ></td>
	<td class="line x" title="149:160	There are several open issues to the presented work." ></td>
	<td class="line x" title="150:160	Important issues are where the phrases can come from and the bias introduced by the resource used." ></td>
	<td class="line x" title="151:160	Using a bilingual corpora such as the Europarl corpus with this pivot approach yields both generic and domain/genre-specific rephrasings, and it is important to be able to determine their appropriate context of use." ></td>
	<td class="line x" title="152:160	It would also be interesting to investigate enriching this framework with phrases learnt from monolingual corpora from a given domain or genre, and to use features from the current text under revision." ></td>
	<td class="line x" title="153:160	More generally, we would need to get some idea of the degree of possible reuse of a given rephrasing." ></td>
	<td class="line x" title="154:160	Another important group of issues concerns limitations due to the nature of phrases for the task at hand." ></td>
	<td class="line x" title="155:160	As we have said, phrases as units of rephrasing are limited because they cannot model non-consecutive words and because of the rigidity of their content." ></td>
	<td class="line x" title="156:160	Various types of entry points to the rephrasing lexicon such as using word-based regular expressions can in some way alleviate this problem, but work could be done on the lexicon itself." ></td>
	<td class="line x" title="157:160	As shown by Callison-Burch (CallisonBurch, 2007), much can be gained by using better alignments." ></td>
	<td class="line x" title="158:160	Alignments techniques using syntactic information could eliminate weak rephrasing candidates (i.e. increase in overall precision), but interesting phrasal alignments could be lost as well (decrease in overall recall)." ></td>
	<td class="line x" title="159:160	Furthermore, information from the context of alignments could also be used to disambiguate the source phrase and get only pivot phrases that are compatible with the context of a given rephrasing, in similar ways as recently done for SMT (Stroppa et al., 2007)." ></td>
	<td class="line x" title="160:160	84" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="D09-1122
Large-Scale Verb Entailment Acquisition from the Web
Hashimoto, Chikara;Torisawa, Kentaro;Kuroda, Kow;De Saeger, Stijn;Murata, Masaki;Kazama, Jun'ichi;"></td>
	<td class="line x" title="1:204	Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 11721181, Singapore, 6-7 August 2009." ></td>
	<td class="line x" title="2:204	c 2009 ACL and AFNLP Large-Scale Verb Entailment Acquisition from the Web Chikara Hashimoto  Kentaro Torisawa  Kow Kuroda  Stijn De Saeger  Masaki Murata  Junichi Kazama bardbl National Institute of Information and Communications Technology Sorakugun, Kyoto, 619-0289, JAPAN {  ch,  torisawa,  kuroda,  stijn,  murata, bardbl kazama}@nict.go.jp Abstract Textual entailment recognition plays a fundamental role in tasks that require indepth natural language understanding." ></td>
	<td class="line x" title="3:204	In order to use entailment recognition technologies for real-world applications, a large-scale entailment knowledge base is indispensable." ></td>
	<td class="line x" title="4:204	This paper proposes a conditional probability based directional similarity measure to acquire verb entailment pairs on a large scale." ></td>
	<td class="line x" title="5:204	We targeted 52,562 verb types that were derived from 10 8 Japanese Web documents, without regard for whether they were used in daily life or only in specific fields." ></td>
	<td class="line x" title="6:204	In an evaluation of the top 20,000 verb entailment pairs acquired by previous methods and ours, we found that our similarity measure outperformed the previous ones." ></td>
	<td class="line x" title="7:204	Our method also worked well for the top 100,000 results." ></td>
	<td class="line x" title="8:204	1 Introduction We all know that if you snored, you must have been sleeping, that if you are divorced, you must have been married, and that if you won a lawsuit, you must have sued somebody." ></td>
	<td class="line x" title="9:204	These relationships between events where one is the logical consequence of the other are called entailment." ></td>
	<td class="line x" title="10:204	Such knowledge plays a fundamental role in tasks that require in-depth natural language understanding, e.g., answering questions and using natural language interfaces." ></td>
	<td class="line x" title="11:204	This paper proposes a novel method for verb entailment acquisition." ></td>
	<td class="line x" title="12:204	Using a Japanese Web corpus (Kawahara and Kurohashi, 2006a) derived from 10 8 Japanese Web documents, we automatically acquired such verb pairs as snore  sleep and divorce  marry, where entailment holds between the verbs in the pair." ></td>
	<td class="line x" title="13:204	1 Our definition of entailment is the same as that in WordNet3.0; v 1 entails v 2 if v 1 cannot be done unless v 2 is, or has been, done." ></td>
	<td class="line x" title="14:204	2 Our method follows the distributional similarity hypothesis, i.e., words that occur in the same context tend to have similar meanings." ></td>
	<td class="line x" title="15:204	Just as in the methods of Lin and Pantel (2001) and Szpektor and Dagan (2008), we regard the arguments of verbs as the context in the hypothesis." ></td>
	<td class="line x" title="16:204	However, unlike the previous methods, ours is based on conditional probability and is augmented with a simple trick that improves the accuracy of verb entailment acquisition." ></td>
	<td class="line x" title="17:204	In an evaluation of the top 20,000 verb entailment pairs acquired by the previous methods and ours, we found that our similarity measure outperformed the previous ones." ></td>
	<td class="line x" title="18:204	Our method also worked well for the top 100,000 results, Since the scope of Natural Language Processing (NLP) has advanced from a formal writing style to a colloquial style and from restricted to open domains, it is necessary for the language resources for NLP, including verb entailment knowledge bases, to cover a broad range of expressions, regardless of whether they are used in daily life or only in specific fields that are highly technical. As we will discuss later, our method can acquire, with reasonable accuracy, verb entailment pairs that deal not only with common and familiar verbs but also with technical and unfamiliar ones like podcast  download and jibe  sail." ></td>
	<td class="line oc" title="19:204	Note that previous researches on entailment acquisition focused on templates with variables or word-lattices (Lin and Pantel, 2001; Szpektor and Dagan, 2008; Barzilay and Lee, 2003; Shinyama 1 Verb entailment pairs are described as v 1  v 2 (v 1 is the entailing verb and v 2 is the entailed one) henceforth." ></td>
	<td class="line x" title="20:204	2 WordNet3.0 provides entailment relationships between synsets like divorce, split upmarry, get married, wed, conjoin, hook up with, get hitched with, espouse." ></td>
	<td class="line x" title="21:204	1172 et al., 2002)." ></td>
	<td class="line x" title="22:204	Certainly these templates or word lattices are more useful in such NLP applications as Q&A than simple entailment relations between verbs." ></td>
	<td class="line x" title="23:204	However, our contention is that entailment certainly holds for some verb pairs (like snore  sleep) by themselves, and that such pairs constitute the core of a future entailment rule database." ></td>
	<td class="line x" title="24:204	Although we focused on verb entailment, our method can also acquire template-level entailment pairs with a reasonable accuracy." ></td>
	<td class="line x" title="25:204	The rest of this paper is organized as follows." ></td>
	<td class="line x" title="26:204	In 2, related works are described." ></td>
	<td class="line x" title="27:204	3 presents our proposed method." ></td>
	<td class="line x" title="28:204	After this, an evaluation of our method and the existing methods is presented in Section 4." ></td>
	<td class="line x" title="29:204	Finally, we conclude the paper in 5." ></td>
	<td class="line oc" title="30:204	2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008)." ></td>
	<td class="line x" title="31:204	Shinyama et al.(2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition." ></td>
	<td class="line x" title="33:204	They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases." ></td>
	<td class="line oc" title="34:204	Barzilay and Lee (2003) also used newspaper articles on the same event as comparable corpora to acquire paraphrases." ></td>
	<td class="line o" title="35:204	They induced paraphrasing patterns by sentence clustering." ></td>
	<td class="line x" title="36:204	Ibrahim et al.(2003) relied on multiple English translations of foreign novels and sentence alignment to acquire paraphrases." ></td>
	<td class="line x" title="38:204	We decided not to take this approach since using comparable corpora limits the scale of the acquired paraphrases or entailment knowledge bases." ></td>
	<td class="line x" title="39:204	Although obtaining comparable corpora has been simplified by the recent explosion of the Web, the availability of plain texts is incomparably better." ></td>
	<td class="line x" title="40:204	Entailment acquisition methods that do not require comparable corpora are mostly based on the distributional similarity hypothesis and use plain texts with a syntactic parser." ></td>
	<td class="line x" title="41:204	Basically, they parse texts to obtain pairs of predicate phrases and their arguments, which are regarded as features of the predicates with appropriately assigned weights." ></td>
	<td class="line x" title="42:204	Lin and Pantel (2001) proposed a paraphrase acquisition method (non-directional similarity measure) called DIRT which acquires pairs of binarytemplates (predicate phrases with two argument slots) that are paraphrases of each other." ></td>
	<td class="line x" title="43:204	DIRT employs the following similarity measure proposed by Lin (1998): Lin(l,r)= summationtext fF l F r [w l (f)+w r (f)] summationtext fF l w l (f)+ summationtext fF r w r (f) where l and r are the corresponding slots of two binary templates, F s is ss feature vector (argument nouns), and w s (f) is the weight of f  F s (PMI between s and f)." ></td>
	<td class="line x" title="44:204	The intuition behind this is that the more nouns two templates share, the more semantically similar they are." ></td>
	<td class="line x" title="45:204	Since we acquire verb entailment pairs based on unary templates (Szpektor and Dagan, 2008) we used the Lin formula to acquire unary templates directly rather than using the DIRT formula, which is the arithmetic-geometric mean of Lins similarities for two slots in a binary template." ></td>
	<td class="line x" title="46:204	Bhagat et al.(2007) developed an algorithm called LEDIR for learning the directionality of non-directional inference rules like those produced by DIRT." ></td>
	<td class="line x" title="48:204	LEDIR implements a Directionality Hypothesis: when two binary semantic relations tend to occur in similar contexts and the first one occurs in significantly more contexts than the second, then the second most likely implies the first and not vice versa." ></td>
	<td class="line x" title="49:204	Weeds and Weir (2003) proposed a general framework for distributional similarity that mainly consists of the notions of what they call Precision (defined below) and Recall: Precision(l,r)= summationtext fF l F r w l (f) summationtext fF l w l (f) where l and r are the targets of a similarity measurement, F s is ss feature vector, and w s (f) is the weight of f  F s . The best performing weight is PMI." ></td>
	<td class="line x" title="50:204	Precision is a directional similarity measure that examines the coverage of ls features by those of rs, with more coverage indicating more similarity." ></td>
	<td class="line x" title="51:204	Szpektor and Dagan (2008) proposed a directional similarity measure called BInc (BalancedInclusion) that consists of Lin and Precision, as BInc(l,r)= radicalBig Lin(l,r)  Precision(l,r) 1173 where l and r are the target templates." ></td>
	<td class="line x" title="52:204	For weighting features, they used PMI." ></td>
	<td class="line x" title="53:204	Szpektor and Dagan (2008) also proposed a unary template, which is defined as a template consisting of one argument slot and one predicate phrase." ></td>
	<td class="line x" title="54:204	For example, X take a nap  X sleep is an entailment pair consisting of two unary templates." ></td>
	<td class="line x" title="55:204	Note that the slot X must be shared between templates." ></td>
	<td class="line x" title="56:204	Though most of the previous entailment acquisition studies focused on binary templates, unary templates have an obvious advantage over binary ones; they can handle intransitive predicate phrases and those that have omitted arguments." ></td>
	<td class="line x" title="57:204	The Japanese language, which we deal with here, often omits arguments, and thus the advantage of unary templates is obvious." ></td>
	<td class="line x" title="58:204	As shown in 4, our method outperforms Lin, Precision, and BInc in accuracy." ></td>
	<td class="line x" title="59:204	Szpector et al.(2004) addressed broad coverage entailment acquisition." ></td>
	<td class="line x" title="61:204	But their method requires an existing lexicon to start, while ours does not." ></td>
	<td class="line x" title="62:204	Apart from the dichotomy of the comparable corpora and the distributional similarity approaches, Torisawa (2006) exploited the structure of Japanese coordinated sentences to acquire verb entailment pairs." ></td>
	<td class="line x" title="63:204	Pekar (2006) used the local structure of coherent text by identifying related clauses within a local discourse." ></td>
	<td class="line x" title="64:204	Zanzotto et al.(2006) exploited agentive nouns." ></td>
	<td class="line x" title="66:204	For example, they acquired win  play from the player wins. Geffet and Dagan (2005) proposed the Distributional Inclusion Hypotheses, which claimed that if a word v entails another word w, then all the characteristic features of v are expected to appear with w, and vice versa." ></td>
	<td class="line x" title="67:204	They applied this to noun entailment pair acquisition, rather than verb pairs." ></td>
	<td class="line x" title="68:204	3 Proposed Method This section presents our method of verb entailment acquisition." ></td>
	<td class="line x" title="69:204	First, the basics of Japanese are described." ></td>
	<td class="line x" title="70:204	Then, we present the directional similarity measure that we developed in 3.2." ></td>
	<td class="line x" title="71:204	3.3 describes the structure and acquisition of the webbased data from which entailment pairs are derived." ></td>
	<td class="line x" title="72:204	Finally, we show how we acquire verb entailment pairs using our proposed similarity measure and the web-based data in 3.4." ></td>
	<td class="line x" title="73:204	3.1 Basics of Japanese Japanese explicitly marks arguments including the subject and object by postpositions, and is a headfinal language." ></td>
	<td class="line x" title="74:204	Thus, a verb phrase consisting of an object hon (book) and a verb yomu (read), for example, is expressed as hon-wo yomu (book-ACC read) read a book with the accusative postposition wo marking the object." ></td>
	<td class="line x" title="75:204	3 Accordingly, we refer to a unary template as p,v hereafter, with p and v referring to the postposition and a verb." ></td>
	<td class="line x" title="76:204	Also, we abbreviate a template-level entailment p l ,v l p r ,v r  as l  r for simplicity." ></td>
	<td class="line x" title="77:204	We define a unary template as a template consisting of one argument slot and one predicate, following Szpektor and Dagan (2008)." ></td>
	<td class="line x" title="78:204	3.2 Directional Similarity Measure based on Conditional Probability The directional similarity measure that we developed and called Score is defined as follows: Score(l,r)=Score base (l,r) Score trick (l,r) where l and r are unary templates, and Score indicates the probability of l  r. Score base , which is the base of Score, is defined as follows: Score base (l,r)= summationdisplay fF l F r P(r|f)P(f|l) where F s is ss feature vector (nouns including compounds)." ></td>
	<td class="line x" title="79:204	The intention behind the definition of Score base is to emulate the conditional probability P(v r |v l ) 4 in a distributional similarity style function." ></td>
	<td class="line x" title="80:204	Note that P(v r |v l ) should be 1 when entailment v l  v r holds (i.e., v r is observed whenever v l is observed) and we have reliable probability values." ></td>
	<td class="line x" title="81:204	Then, if we can directly estimate P(v r |v l ), it is reasonable to assume v l  v r if P(v r |v l ) is large enough." ></td>
	<td class="line x" title="82:204	However, we cannot estimate P(v r |v l ) directly since it is unlikely that we will observe the verbs v r and v l at the same time." ></td>
	<td class="line x" title="83:204	(People do not usually repeat v r and v l in the same document to avoid redundancy.)" ></td>
	<td class="line x" title="84:204	Thus, instead of a direct estimation, we substitute Score base (l,r) as defined above." ></td>
	<td class="line x" title="85:204	In other words, we assume P(v r |v l )  P(r|l)   fF l F r P(f|l)P(r|f)." ></td>
	<td class="line x" title="86:204	Actually, Score base originally had another motivation, inspired by Torisawa (2005), for which no postposition but the instrumental postposition de was relevant." ></td>
	<td class="line x" title="87:204	In this discussion, all of the nouns (fs) that are marked by the instrumental postposition are seen as tools, and P(f|l) is interpreted 3 ACC represents an accusative postposition in Japanese." ></td>
	<td class="line x" title="88:204	Likewise, NOM, DAT, INS, and TOP are the symbols for the nominative, dative, instrumental, and topic postpositions." ></td>
	<td class="line x" title="89:204	4 Remember that v l and v r are the verbs of unary templates l and r. 1174 as a measure of how typically the tool f is used to perform the action denoted by (the v l of) l;if P(f|l) is large enough, f is a typical tool used in l. On the other hand, P(r|f) indicates the probability of (the v r of) r being the purpose for using the tool f. See (1) for an example." ></td>
	<td class="line x" title="90:204	(1) konro-de chouri-suru cooking.stove-INS cook cook (something) using a cooking stove. The purpose of using a cooking stove is to cook." ></td>
	<td class="line x" title="91:204	Torisawa (2005) has pointed out that when r expresses the purpose of using a tool f, P(r|f) tends to be large." ></td>
	<td class="line x" title="92:204	This predicts that P(r|cooking stove) is large, where r is de,cook." ></td>
	<td class="line x" title="93:204	According to this observation, if f is a single purpose tool and P(f|l), the probability of f being the tool by which l is performed, and P(r|f), the probability of r being the purpose of using the tool f, are large enough, then the typical performance of the action v l should contain some actions that can be described by v r , i.e., the purpose of using f. Moreover, if all the typical tools (fs) used in v l are also used for v r , most performances of the action v l should contain a part described by the action v r . In summary, this means that when  fF l F r P(r|f)P(f|l), Score base , has a large value, we can expect v l  v r . For example, let v l be deep-fry and v r be cook." ></td>
	<td class="line x" title="94:204	Note that v l  v r holds for this example." ></td>
	<td class="line x" title="95:204	There are many tools that are used for deep-frying, such as cooking stove, pot,orpan." ></td>
	<td class="line x" title="96:204	This means that P(cooking stove|l), P(pot|l),orP(pan|l) are large." ></td>
	<td class="line x" title="97:204	On the other hand, the purpose of using all of these tools is cooking, based on common sense." ></td>
	<td class="line x" title="98:204	Thus, probabilities such as P(r|cooking stove) and P(r|pan) should have large values." ></td>
	<td class="line x" title="99:204	Accordingly,  fF l F r P(f|l)P(r|f), Score base , should be relatively large for deep-fry  cook, Actually, we defined Score base based on the above assumption However, through a series of preliminary experiments, we found that the same score could be applied without losing the precision to the other postpositions." ></td>
	<td class="line x" title="100:204	Thus, we generalized the framework so that it could deal with most postpositions, namely ga (NOM), wo (ACC), ni (DAT), de (INS), and wa (TOP)." ></td>
	<td class="line x" title="101:204	Note that this is a variation of the distributional inclusion hypothesis (Geffet and Dagan, 2005), but that we do not use mutual information as in previous works, based on the hypothesis discussed above." ></td>
	<td class="line x" title="102:204	Actually, as shown in 4, our conditional probability based method outperformed the mutual information based metrics in our experiments." ></td>
	<td class="line x" title="103:204	On the other hand, Score trick implements another assumption that if only one feature contributes to Score base and the contribution of the other nouns is negligible, if any, the similarity is unreliable." ></td>
	<td class="line x" title="104:204	Accordingly, for Score trick , we uniformly ignore the contribution of the most dominant feature from the similarity measurement." ></td>
	<td class="line x" title="105:204	Score trick (l,r) = Score base (l,r)  max fF l F r P(r|f)P(f|l) As shown in 4, this trick actually improved the entailment acquisition accuracy." ></td>
	<td class="line x" title="106:204	We used maximum likelihood estimation to obtain P(r|f) and P(f|l) in the above discussion." ></td>
	<td class="line x" title="107:204	Bannard and Callison-Burch (2005) and Fujita and Sato (2008) also proposed directional similarity measures based on conditional probability, which are very similar to Score base , although either their methods prerequisites or the targets of the similarity measurements were different from ours." ></td>
	<td class="line x" title="108:204	The method of Bannard and Callison-Burch (2005) requires bilingual parallel corpora, and uses the translations of expressions as its feature." ></td>
	<td class="line x" title="109:204	Fujita and Sato (2008) dealt with productive predicate phrases, while our target is non-productive lexical units, i.e., verbs." ></td>
	<td class="line x" title="110:204	Thus, this is the first attempt to apply a conditional probability based similarity measure to verb entailment acquisition." ></td>
	<td class="line x" title="111:204	In addition, the trick implemented in Score trick is novel." ></td>
	<td class="line x" title="112:204	3.3 Preparing Template-Feature Tuples Our method starts from a dataset called templatefeature tuples, which was derived from the Web in the following way: 1) Parse the Japanese Web corpus (Kawahara and Kurohashi, 2006a) derived from 10 8 Japanese Web documents with Japanese dependency parser KNP (Kawahara and Kurohashi, 2006b)." ></td>
	<td class="line x" title="113:204	2) Extract triples n,p,v consisting of nouns (n), postpositions (p), and verbs (v), where an n marked by a p depends on a v from the parsed Web text." ></td>
	<td class="line x" title="114:204	3) From the triple database, construct template-feature tuples n,p,v by regarding p,v as a unary template and n as one of its features." ></td>
	<td class="line x" title="115:204	4) Convert the verbs into their canonical forms as defined by KNP." ></td>
	<td class="line x" title="116:204	5) Filter out tuples that fall into one of the following categories: 51) Freq(p,v) < 20." ></td>
	<td class="line x" title="117:204	5-2) Its verb is passivized, 1175 causativized, or negated." ></td>
	<td class="line x" title="118:204	5-3) Its verb is semantically vague like be, do,orbecome." ></td>
	<td class="line x" title="119:204	5-4) Its postposition is something other than ga (NOM), wo (ACC), ni (DAT), de (INS), or wa (TOP)." ></td>
	<td class="line x" title="120:204	The resulting unary template-feature tuples included 127,808 kinds of templates that consisted of 52,562 verb types and five kinds of postpositions." ></td>
	<td class="line x" title="121:204	The verbs included compound words like bosi-kansen-suru (mother.to.child-infectiondo) infect from mothers to infants. 3.4 Acquiring Entailment Pairs We acquired verb entailment pairs using the following procedure: i) From the template-feature tuples mentioned in 3.3, acquire unary template pairs that exhibit an entailment relation between them using the directional similarity measure in 3.2." ></td>
	<td class="line x" title="122:204	ii) Convert the acquired unary templates p,v into naked verbs v by stripping the postpositions p. iii) Remove the duplicated verb pairs resulting from stripping ps." ></td>
	<td class="line x" title="123:204	To be precise, when we removed the duplicated pairs, we left the highest ranked one." ></td>
	<td class="line x" title="124:204	iv) Retrieve N-best verb pairs as the final output from the result of iii)." ></td>
	<td class="line x" title="125:204	That is, we first acquired unary template pairs and then transformed them into verb pairs." ></td>
	<td class="line x" title="126:204	Although this paper focuses on verb entailment acquisition, we also evaluated the accuracy of template-level entailment acquisition, in order to show that our similarity measure works well, not only for verb entailment acquisition, but also for template entailment acquisition (See 4.4)." ></td>
	<td class="line x" title="127:204	we created two kinds of unary templates: the Scoring Slots template and the Nom(inative) Slots template." ></td>
	<td class="line x" title="128:204	The first is simply the result of the procedure i); all of the templates have slots that are used for similarity scoring." ></td>
	<td class="line x" title="129:204	The second one was obtained in the following way: 1) Only templates whose p is not a nominative are sampled from the result of the procedure i)." ></td>
	<td class="line x" title="130:204	2) Their ps are all changed to a nominative." ></td>
	<td class="line x" title="131:204	Templates of the second kind are used to show that the corresponding slots between templates (nominative, in this case) that are not used for similarity scoring can be incorporated to resulting template-level entailment pairs if the scoring function really captures the semantic similarity between templates." ></td>
	<td class="line x" title="132:204	Note that, for unary template entailment pairs like (2) to be well-formed, the two unary slots (Xwo) between templates must share the same noun as the index i indicates." ></td>
	<td class="line x" title="133:204	This is relevant in 4.4." ></td>
	<td class="line x" title="134:204	(2) X i -wo musaborikuu  X i -wo taberu X i -ACC gobble X i -ACC eat 4 Evaluation We compare the accuracy of our method with that of the alternative methods in 4.1." ></td>
	<td class="line x" title="135:204	4.2 shows the effectiveness of the trick." ></td>
	<td class="line x" title="136:204	We examine the entailment acquisition accuracy for frequent verbs in 4.3, and evaluate the performance of our method when applied to template-level entailment acquisition in 4.4." ></td>
	<td class="line x" title="137:204	Finally, by showing the accuracy for verb pairs obtained from the top 100,000 results, we claim that our method provides a good starting point from which a large-scale verb entailment resource can be constructed in 4.5." ></td>
	<td class="line x" title="138:204	For the evaluation, three human annotators (not the authors) checked whether each acquired entailment pair was correct." ></td>
	<td class="line x" title="139:204	The average of the three Kappa values for each annotator pair was 0.579 for verb entailment pairs and 0.568 for template entailment pairs, both of which indicate the middling stability of this evaluation annotation." ></td>
	<td class="line x" title="140:204	4.1 Experiment 1: Verb Pairs We applied Score, BInc, Lin, and Precision to the template-feature tuples (3.3), obtained template entailment pairs, and finally obtained verb entailment pairs by removing the postpositions from the templates as described in 3." ></td>
	<td class="line x" title="141:204	As a baseline, we created pairs from randomly chosen verbs." ></td>
	<td class="line x" title="142:204	Since we targeted all of the verbs that appeared on the Web (under the condition of Freq(p,v)  20), the annotators were confronted with technical terms and slang that they did not know." ></td>
	<td class="line x" title="143:204	In such cases, they consulted dictionaries (either printed or machine readable ones) and the Web." ></td>
	<td class="line x" title="144:204	If they still could not find the meaning of a verb, they labeled the pair containing the unknown verb as incorrect." ></td>
	<td class="line x" title="145:204	We used the accuracy = # of correct pairs # of acquired pairs as an evaluation measure." ></td>
	<td class="line x" title="146:204	We regarded a pair as correct if it was judged correct by one (Accuracy-1), two (Accuracy-2), or three (Accuracy-3) annotators." ></td>
	<td class="line x" title="147:204	We evaluated 200 entailment pairs sampled from the top 20,000 for each method (# of acquired pairs = 200)." ></td>
	<td class="line x" title="148:204	For fairness, the evaluation samples for each method were shuffled and placed in one file from which the annotators worked." ></td>
	<td class="line x" title="149:204	In this way, they were unable to know which entailment pair came from which method." ></td>
	<td class="line x" title="150:204	1176 Note that the verb entailment pairs produced by Lin do not provide the directionality of entailment." ></td>
	<td class="line x" title="151:204	Thus, the annotators decided the directionality of these entailment pairs as follows: i) Copy 200 original samples and reverse the order of v 1 and v 2 . ii) Shuffle the 400 Lin samples (the original and reversed samples) with the other ones." ></td>
	<td class="line x" title="152:204	iii) Evaluate all of the shuffled pairs." ></td>
	<td class="line x" title="153:204	Each Lin pair was regarded as correct if either direction was judged correct." ></td>
	<td class="line x" title="154:204	In other words, we evaluated the upper bound performance of the LEDIR algorithm." ></td>
	<td class="line x" title="155:204	Table 1 shows the accuracy of the acquired verb entailment pairs for each method." ></td>
	<td class="line x" title="156:204	Figure 1 Method Acc-1 Acc-2 Acc-3 Score 0.770 0.660 0.460 BInc 0.450 0.255 0.125 Precision 0.725 0.545 0.385 Lin 0.590 0.370 0.160 Random 0.050 0.010 0.005 Table 1: Accuracy of verb entailment pairs." ></td>
	<td class="line x" title="157:204	shows the accuracy figures for the N-best entailment pairs for each method, with N being 1,000, 2,000, , or 20,000." ></td>
	<td class="line x" title="158:204	We observed the following points from the results." ></td>
	<td class="line x" title="159:204	First, Score outperformed all the other methods." ></td>
	<td class="line x" title="160:204	Second, Score and Precision, which are directional similarity measures, worked well, while Lin, which is a symmetric one, performed poorly even though the directionality of its output was determined manually." ></td>
	<td class="line x" title="161:204	Looking at the evaluated samples, Score successfully acquired pairs in which the entailed verbs generalized entailing verbs that were technical terms." ></td>
	<td class="line x" title="162:204	(3) shows examples of Scores outputs." ></td>
	<td class="line x" title="163:204	(3) a. RSS-haisin-suru  todokeru RSS-feed-do deliver feed the RSS data b. middosippu-maunto-suru  tumu midship-mounting-do mount have (engine) midship-mounted The errors made by DIRT (4) and BInc (5) included pairs consisting of technical terms." ></td>
	<td class="line x" title="164:204	(4) kurakkingu-suru software.cracking-do crack a (security) system  koutiku-hosyu-suru building-maintenance-do build and maintain a system Accuracy-1  0  0.2  0.4  0.6  0.8  1  0  5000  10000  15000  20000 Score BInc Precision Lin Accuracy-2  0  0.2  0.4  0.6  0.8  1  0  5000  10000  15000  20000 Score BInc Precision Lin Accuracy-3  0  0.2  0.4  0.6  0.8  1  0  5000  10000  15000  20000 Score BInc Precision Lin Figure 1: Accuracy of verb entailment pairs." ></td>
	<td class="line x" title="165:204	(5) suisou-siiku-suru tank-raising-do raise (fish) in a tank  siken-houryuu-suru test-discharge-do stock (with fish) experimentally These terms are related in some sense, but they are not entailment pairs." ></td>
	<td class="line x" title="166:204	4.2 Experiment 2: Effectiveness of the Trick Next, we investigated the effectiveness of the trick described in 3." ></td>
	<td class="line x" title="167:204	We evaluated Score, Score trick , and Score base . Table 2 shows the accuracy figures for each method." ></td>
	<td class="line x" title="168:204	Figure 2 shows the accuracy figures for the N-best outputs for each method." ></td>
	<td class="line x" title="169:204	The 1177 Method Acc-1 Acc-2 Acc-3 Score 0.770 0.660 0.460 Score trick 0.725 0.610 0.395 Score base 0.590 0.465 0.315 Table 2: Effectiveness of the trick." ></td>
	<td class="line x" title="170:204	results illustrate that introducing the trick significantly improved the performance of Score base , and so did multiplying Score trick and Score base , which is our proposal Score." ></td>
	<td class="line x" title="171:204	(6) shows an example of Score base s errors." ></td>
	<td class="line x" title="172:204	(6) gazou-sakusei-suru  henkou-suru image-making-do change-do make an image change This pair has only two shared nouns (f  F l F r ), and more than 99.99% of the pairs similarity reflects only one of the two." ></td>
	<td class="line x" title="173:204	Clearly, the trick would have prevented the pair from being highly ranked." ></td>
	<td class="line x" title="174:204	4.3 Experiment 3: Pairs of Frequent Verbs We found that the errors made by Lin and BInc in Experiment 1 were mostly pairs of infrequent verbs such as technical terms." ></td>
	<td class="line x" title="175:204	Thus, we conducted the acquisition of entailment pairs targeting more frequent verbs to see how their performance changed." ></td>
	<td class="line x" title="176:204	The experimental conditions were the same as in Experiment 1, except that the templates (p,v) used were all Freq(p,v)  200." ></td>
	<td class="line x" title="177:204	Table 3 shows the accuracy figures for each method with the changes in accuracy from those of the original methods in parentheses." ></td>
	<td class="line x" title="178:204	The reMethod Acc-1 Acc-2 Acc-3 Score 0.690 0.520 0.335 (0.080) (0.140) (0.125) BInc 0.455 0.295 0.160 (+0.005) (+0.040) (+0.035) Precision 0.450 0.355 0.205 (0.275) (0.190) (0.180) Lin 0.635 0.385 0.205 (+0.045) (+0.015) (+0.045) Table 3: Accuracy of frequent verb pairs." ></td>
	<td class="line x" title="179:204	sults show that the accuracies of Score and Precision (the two best methods in Experiment 1) degraded, while the other two improved a little." ></td>
	<td class="line x" title="180:204	We suspect that the performance difference between these methods would get smaller if we further restricted the target verbs to more frequent ones." ></td>
	<td class="line x" title="181:204	Accuracy-1  0  0.2  0.4  0.6  0.8  1  0  5000  10000  15000  20000 Score Score trick Score base Accuracy-2  0  0.2  0.4  0.6  0.8  1  0  5000  10000  15000  20000 Score Score trick Score base Accuracy-3  0  0.2  0.4  0.6  0.8  1  0  5000  10000  15000  20000 Score Score trick Score base Figure 2: Accuracy of verb entailment pairs acquired by Score, Score trick , and Score base . However, we believe that dealing with verbs comprehensively, including infrequent ones, is important, since, in the era of information explosion, the impact on applications is determined not only by frequent verbs but also infrequent ones that constitute the long tail of a verb-frequency graph." ></td>
	<td class="line x" title="182:204	Thus, this tendency does not matter for our purpose." ></td>
	<td class="line x" title="183:204	4.4 Experiment 4: Template Pairs This section presents the entailment acquisition accuracy for template pairs to show that our method can also perform the entailment acquisition of unary templates." ></td>
	<td class="line x" title="184:204	We presented pairs of unary templates, obtained by the procedure in 1178 3.4, to the annotators." ></td>
	<td class="line x" title="185:204	In doing so, we restricted the correct entailment pairs to those for which entailment always held regardless of what argument filled the two unary slots, and the two slots had to be filled with the same argument, as exemplified in (2)." ></td>
	<td class="line x" title="186:204	We evaluated Score and Precision." ></td>
	<td class="line x" title="187:204	Table 4 shows the accuracy of the acquired pairs of unary templates." ></td>
	<td class="line x" title="188:204	Compared to verb entailment Method Acc-1 Acc-2 Acc-3 Score 0.655 0.510 0.300 Scoring (0.115) (0.150) (0.160) Slots Precision 0.565 0.430 0.265 (0.160) (0.115) (0.120) Score 0.665 0.515 0.315 Nom (0.105) (0.145) (0.145) Slots Precision 0.490 0.325 0.215 (0.235) (0.220) (0.170) Table 4: Accuracy of entailment pairs of templates whose slots were used for scoring." ></td>
	<td class="line x" title="189:204	acquisition, the accuracy of both methods dropped by about 10%." ></td>
	<td class="line x" title="190:204	This was mainly due to the evaluation restriction exemplified in (2) which was not introduced in the previous experiments; the annotators ignored the argument correspondence between the verb pairs in Experiment 1." ></td>
	<td class="line x" title="191:204	Also note that Score outperformed Precision in this experiment, too." ></td>
	<td class="line x" title="192:204	(7) and (8) are examples of the Scoring Slots template entailment pairs and (9) is that of the Nom Slots acquired by our method." ></td>
	<td class="line x" title="193:204	(7) X-wo tatigui-suru  X-wo taberu X-ACC standing.up.eating-do X-ACC eat eat X standing up eat X (8) X-de marineedo-suru  X-wo ireru X-INS marinade-do X-ACC pour marinate with X pour X (9) X-ga NBA-iri-suru (was X-de (INS)) X-NOM NBA-entering-do X joins an NBA team  X-ga nyuudan-suru (was X-de) X-NOM enrollment-do X joins a team 4.5 Experiment 5: Verb Pairs form the Top 100,000 Finally, we examined the accuracy of the top 100,000 verb pairs acquired by Score and Precision." ></td>
	<td class="line x" title="194:204	As Table 5 shows, Score outperformed PreMethod Acc-1 Acc-2 Acc-3 Score 0.610 0.480 0.300 Precision 0.470 0.295 0.190 Table 5: Accuracy of the top 100,000 verb pairs." ></td>
	<td class="line x" title="195:204	cision." ></td>
	<td class="line x" title="196:204	Note also that Score kept a reasonable accuracy for the top 100,000 results (Acc-2: 48%)." ></td>
	<td class="line x" title="197:204	The accuracy is encouraging enough to consider human annotation for the top 100,000 results to produce a language resource for verb entailment, which we actually plan to do." ></td>
	<td class="line x" title="198:204	Below are correct verb entailment examples from the top 100,000 results of our method." ></td>
	<td class="line x" title="199:204	(10) The 121th pair kaado-kessai-suru  siharau card-payment-do pay pay by card pay (11) The 6,081th pair saitei-suru  sadameru adjudicate-do settle adjudicate settle (12) The 15,464th pair eraa-syuuryou-suru  jikkou-suru error-termination-do perform-do abend execute (13) The 30,044th pair ribuuto-suru  kidou-suru reboot-do start-do reboot boot (14) The 57,653th pair rinin-suru  syuunin-suru resignation-do accession-do resign accede (15) The 70,103th pair sijou-tounyuu-suru  happyou-suru market-input-do publication-do bring to the market publicize Below are examples of erroneous pairs from our results." ></td>
	<td class="line x" title="200:204	(16) is a causal relation but not an entailment." ></td>
	<td class="line x" title="201:204	(17) is a contradictory pair." ></td>
	<td class="line x" title="202:204	(16) The 5,475th pair juken-suru  goukaku-suru take.an.exam-do acceptance-do take an exam gain admission 1179 (17) The 40,504th pair ketujou-suru  syutujou-suru not.take.part-do take.part-do not take part take part 5 Conclusion This paper addressed verb entailment acquisition from the Web, and proposed a novel directional similarity measure Score." ></td>
	<td class="line x" title="203:204	Through a series of experiments, we showed i) that Score outperforms the previously proposed measures, Lin, Precision, and BInc in large scale verb entailment acquisition, ii) that our proposed trick implemented in Score trick significantly improves the accuracy of verb entailment acquisition despite its simplicity, iii) that Score worked better than the others even when we restricted the target verbs to more frequent ones, iv) that our method is also moderately successful at producing template-level entailment pairs, and v) that our method maintained reasonable accuracy (in terms of human annotation) for the top 100,000 results." ></td>
	<td class="line x" title="204:204	As examples of the acquired verb entailment pairs illustrated, our method can acquire from an ocean of information, namely the Web, a variety of verb entailment pairs ranging from those that are used in daily life to those that are used in very specific fields." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="E09-1082
Word Lattices for Multi-Source Translation
Schroeder, Josh;Cohn, Trevor;Koehn, Philipp;"></td>
	<td class="line x" title="1:216	Proceedings of the 12th Conference of the European Chapter of the ACL, pages 719727, Athens, Greece, 30 March  3 April 2009." ></td>
	<td class="line x" title="2:216	c2009 Association for Computational Linguistics Word Lattices for Multi-Source Translation Josh Schroeder, Trevor Cohn, and Philipp Koehn School of Informatics University of Edinburgh 10 Crichton Street, Edinburgh EH8 9AB Scotland, United Kingdom {jschroe1, tcohn, pkoehn}@inf.ed.ac.uk Abstract Multi-source statistical machine translation is the process of generating a single translation from multiple inputs." ></td>
	<td class="line x" title="3:216	Previous work has focused primarily on selecting from potential outputs of separate translation systems, and solely on multi-parallel corpora and test sets." ></td>
	<td class="line x" title="4:216	We demonstrate how multi-source translation can be adapted for multiple monolingual inputs." ></td>
	<td class="line x" title="5:216	We also examine different approaches to dealing with multiple sources, including consensus decoding, and we present a novel method of input combination to generate lattices for multi-source translation within a single translation model." ></td>
	<td class="line x" title="6:216	1 Introduction Multi-source statistical machine translation was first formally defined by Och and Ney (2001) as the process of translating multiple meaningequivalent source language texts into a single target language." ></td>
	<td class="line x" title="7:216	Multi-source translation is of particular use when translating a document that has already been translated into several languages, either by humans or machines, and needs to be further translated into other target languages." ></td>
	<td class="line x" title="8:216	This situation occurs often in large multi-lingual organisations such as the United Nations and the European Parliament, which must translate their proceedings into the languages of the member institutions." ></td>
	<td class="line x" title="9:216	It is also common in multi-national companies, which need to translate product and marketing documentation for their different markets." ></td>
	<td class="line x" title="10:216	Clearly, any existing translations for a document can help automatic translation into other languages." ></td>
	<td class="line x" title="11:216	These different versions of the input can resolve deficiencies and ambiguities (e.g., syntactic and semantic ambiguity) present in a single input, resulting in higher quality translation output." ></td>
	<td class="line x" title="12:216	In this paper, we present three models of multisource translation, with increasing degrees of sophistication, which we compare empirically on a number of different corpora." ></td>
	<td class="line x" title="13:216	We generalize the definition of multi-source translation to include any translation case with multiple inputs and a single output, allowing for, e.g., multiple paraphrased inputs in a single language." ></td>
	<td class="line x" title="14:216	Our methods include simple output selection, which treats the multisource translation task as many independent translation steps followed by selection of one of their outputs (Och and Ney, 2001), and outputcombination, which uses consensus decoding to construct a string from n-gram fragments of the translation outputs (Bangalore et al., 2001)." ></td>
	<td class="line x" title="15:216	We also present a novel method, input combination, in which we compile the input texts into a compact lattice, over which we perform a single decoding pass." ></td>
	<td class="line x" title="16:216	We show that as we add additional inputs, the simplest output selection method performs quite poorly relative to a single input translation system, while the latter two methods are able to make better use of the additional inputs." ></td>
	<td class="line x" title="17:216	The paper is structured as follows." ></td>
	<td class="line x" title="18:216	2 presents the three methods for multi-source translation in detail: output selection, output combination, and our novel lattice-based method for input combination." ></td>
	<td class="line x" title="19:216	We report experiments applying these techniques to three different corpora, with both monolingual inputs (3) and multilingual inputs (4)." ></td>
	<td class="line x" title="20:216	We finish in5 by analyzing the benefits and drawbacks of these approaches." ></td>
	<td class="line x" title="21:216	2 Approaches to Multi-Source Translation We now present three ways to combine multiple inputs into a single output translation, in the context of related work for each technique." ></td>
	<td class="line x" title="22:216	719 2.1 Output Selection The most straightforward approach to multisource translation, proposed by Och and Ney (2001), is to independently translate each of the N source languages and then select a single translation from the outputs." ></td>
	<td class="line x" title="23:216	Given N sources sN1 = s1,,sN, first translate each with a separate translation system, p1,,pN, to obtain N target translations, tN1 = t1,,tN." ></td>
	<td class="line x" title="24:216	Och and Ney present two approaches for selecting a single target from these outputs." ></td>
	<td class="line x" title="25:216	The first, PROD, finds the maximiser of the product, argmaxttN 1 p(t)producttextNn=1pn(sn|t), where p(t) is the language model probability." ></td>
	<td class="line x" title="26:216	For reasons of tractability, the maximisation is performed only over targets generated by the translation systems, tN1 , not the full space of all translations." ></td>
	<td class="line x" title="27:216	The PROD method requires each model to provide a model score for each tn generated by the other models." ></td>
	<td class="line x" title="28:216	However, this is often impossible due to the models highly divergent output spaces (Schwartz, 2008), and therefore the technique cannot be easily applied." ></td>
	<td class="line x" title="29:216	The second approach, MAX, solves argmaxttN 1 maxNn=1p(t)pn(sn|t), which is much easier to calculate." ></td>
	<td class="line x" title="30:216	As with PROD, the translation models outputs are used for the candidate translations." ></td>
	<td class="line x" title="31:216	While different models may have different score ranges, Och and Ney (2001) state that there is little benefit in weighting these scores to normalise the output range." ></td>
	<td class="line x" title="32:216	In their experiments, they show that MAX used on pairs or triples of language inputs can outperform a model with single language input, but that performance degrades as more languages are added." ></td>
	<td class="line x" title="33:216	These methods limit the explored space to a full translation output of one of the inputs, and therefore cannot make good use of the full diversity of the translations." ></td>
	<td class="line x" title="34:216	In this paper we present MAX scores as a baseline for output selection, and approximate an oracle using the BLEU metric as an upper bound for the output selection technique." ></td>
	<td class="line x" title="35:216	2.2 Output Combination Consensus decoding as a form of system combination is typically used to integrate the outputs of multiple translation systems into a single synthetic output that seeks to combine the best fragments from each component system." ></td>
	<td class="line x" title="36:216	Multi-source translation can be treated as a special case of consensus decoding." ></td>
	<td class="line x" title="37:216	Indeed, several authors have seen the epsilon1 dog barked very loudly a big dog barked epsilon1 loudly sub insert  shift delete  Table 1: Example minimum TER edit script." ></td>
	<td class="line x" title="38:216	0 1 the a 2  big 3 dog 4 barked 5 very  6 loudly Figure 1: Conversion of TER script from Table 1 to a confusion network." ></td>
	<td class="line x" title="39:216	improvements in translation quality by performing multi-source translation using generic system combination techniques (Matusov et al., 2006; Paulik et al., 2007)." ></td>
	<td class="line x" title="40:216	One class of approaches to consensus decoding focuses on construction of a confusion network or lattice1 from translation outputs, from which new sentences can be created using different reorderings or combinations of translation fragments (e.g., Bangalore et al.(2001); Rosti et al.(2007b))." ></td>
	<td class="line x" title="43:216	These methods differ in the types of lattices used, their means of creation, and scoring method used to extract the best consensus output from the lattice." ></td>
	<td class="line x" title="44:216	The system used in this paper is a variant of the one proposed in Rosti et al.(2007a), which we now describe in detail." ></td>
	<td class="line x" title="46:216	The first step in forming a lattice is to align the inputs." ></td>
	<td class="line x" title="47:216	Consensus decoding systems often use the script of edit operations that minimises the translation edit rate (TER; Snover et al.(2006))." ></td>
	<td class="line x" title="49:216	TER is a word-based measure of edit distance which also allows n-gram shifts when calculating the best match between a hypothesis and reference." ></td>
	<td class="line x" title="50:216	Because TER describes the correspondence between the hypothesis and reference as a sequence of insertions, substitutions, deletions, and shifts, the edit script it produces can be used to create a confusion network." ></td>
	<td class="line x" title="51:216	Consider a reference of The dog barked very loudly and a hypothesis A big dog loudly barked. The TER alignment is shown in Table 1, along with the edit operations." ></td>
	<td class="line x" title="52:216	Note that the matching barked tokens are labelled shift, as one needs to be shifted for this match to occur." ></td>
	<td class="line x" title="53:216	Using the shifted hypothesis, we can form a confusion 1Different authors refer to lattices, confusion networks, word sausages, etc. to describe these data structures, and specific terminology varies from author to author." ></td>
	<td class="line x" title="54:216	We define a lattice as a weighted directed acyclic graph, and a confusion network as a special case where each node n in the ordered graph has word arcs only to node n + 1." ></td>
	<td class="line x" title="55:216	720      Confusion Network 1  Confusion Network 2  Confusion Network 3  Figure 2: Structure of a lattice of confusion networks for consensus decoding." ></td>
	<td class="line x" title="56:216	network as in Figure 1." ></td>
	<td class="line x" title="57:216	Additional sentences can be added by aligning them to the reference as well." ></td>
	<td class="line x" title="58:216	Each link is weighted by the number of component sentences sharing that particular word at the given location." ></td>
	<td class="line x" title="59:216	Similar to Rosti et al.(2007a), we let each hypothesis take a turn as the reference for TER, using it as a skeleton for a confusion network." ></td>
	<td class="line x" title="61:216	We then form a lattice of confusion networks (Figure 2), assigning a prior weight to each confusion network based on the average TER of the selected skeleton with the other hypotheses." ></td>
	<td class="line x" title="62:216	This allows each system to set the word order for a component confusion network, but at the cost of a more complex lattice structure." ></td>
	<td class="line x" title="63:216	We can score pathsPthrough these lattices with the assistance of a language model." ></td>
	<td class="line x" title="64:216	Formally, the path score is given by: w(P) = logpLM(t(P)) + summationdisplay dP bracketleftBigg Nsummationdisplay n=1 n logpn(d|sn) +(d,epsilon1) +(1(d,epsilon1)) bracketrightBigg where pLM is the language model probability of the target string specified by the lattice path, t(P), pn(d|sn) is the proportion of system ns k-best outputs that use arc d in pathP, and the last two terms count the number of epsilon and non-epsilon transitions in the path." ></td>
	<td class="line x" title="65:216	The model parameters are 1,,n,,,, which are trained using Powells search to maximise the BLEU score for the highest scoring path, argmaxPw(P)." ></td>
	<td class="line x" title="66:216	2.3 Input Combination Loosely defined, input combination refers to finding a compact single representation of N translation inputs." ></td>
	<td class="line x" title="67:216	The hope is that the new input preserves as many of the salient differences between the inputs as possible, while eliminating redundant information." ></td>
	<td class="line x" title="68:216	Lattices are well suited to this task." ></td>
	<td class="line x" title="69:216	0 1  watch it 2  out 's 3  for 4 the purse pick a  5 robber thief snatcher burglar crook pocket 6 . Figure 3: A monolingual confusion network." ></td>
	<td class="line x" title="70:216	Thicker lines indicate higher probability word arcs." ></td>
	<td class="line x" title="71:216	When translating speech recognition output, previous work has shown that representing the ambiguity in the recognized text via confusion networks leads to better translations than simply translating the single best hypothesis of the speech recognition system (Bertoldi et al., 2007)." ></td>
	<td class="line x" title="72:216	The application of input lattices to other forms of input ambiguity has been limited to encoding input reorderings, word segmentation, or morphological segmentation, all showing improvements in translation quality (Costa-juss`a et al., 2007; Xu et al., 2005; Dyer et al., 2008)." ></td>
	<td class="line x" title="73:216	However, these applications encode the ambiguity arising from a single input, while in this work we combine distinct inputs into a more compact and expressive single input format." ></td>
	<td class="line x" title="74:216	When given many monolingual inputs, we can apply TER and construct a confusion network as in Section 2.2.2 In this application of confusion networks, arc weights are calculated by summing votes from each input for a given word, and normalizing all arcs leaving a node to sum to 1." ></td>
	<td class="line x" title="75:216	Figure 3 shows an example of a TER-derived input from IWSLT data." ></td>
	<td class="line x" title="76:216	Because the decoder will handle reordering, we select the input with the lowest average TER against the other inputs to serve as the skeleton system, and do not create a lattice with multiple skeletons." ></td>
	<td class="line x" title="77:216	The problem becomes more complex when we consider cases of multi-lingual multi-source translation." ></td>
	<td class="line x" title="78:216	We cannot easily apply TER across languages because there is no clear notion of an exact match between words." ></td>
	<td class="line oc" title="79:216	Matusov et al.(2006) propose using a statistical word alignment algorithm as a more robust way of aligning (monolingual) outputs into a confusion network for system com2Barzilay and Lee (2003) construct lattices over paraphrases using an iterative pairwise multiple sequence alignment (MSA) algorithm." ></td>
	<td class="line n" title="81:216	Unlike our approach, MSA does not allow reordering of inputs." ></td>
	<td class="line x" title="82:216	721 bination." ></td>
	<td class="line x" title="83:216	We take a similar approach for multilingual lattice generation." ></td>
	<td class="line x" title="84:216	Our process consists of four steps: (i) Align words for each of the N(N1) pairs of inputs; (ii) choose an input (or many inputs) to be the lattice skeleton; (iii) extract all minimal consistent alignments between the skeleton and the other inputs; and (iv) add links to the lattice for each aligned phrase pair." ></td>
	<td class="line x" title="85:216	A multi-parallel corpus such as Europarl (Koehn, 2005) is ideally suited for training this setup, as training data is available for each pair of input languages needed by the word aligner." ></td>
	<td class="line x" title="86:216	We used the GIZA++ word alignment tool (Och and Ney, 2003) for aligning inputs, trained on a portion of the Europarl training data for each pair." ></td>
	<td class="line x" title="87:216	We select a skeleton input based on which single-language translation system performs the best when translating a development set." ></td>
	<td class="line x" title="88:216	For our Europarl test condition, this was French." ></td>
	<td class="line x" title="89:216	We define a minimal consistent alignment (MCA) as a member of the set of multi-word alignment pairs that can be extracted from a manyto-many word alignment between skeleton sentence x and non-skeleton sentence y with the following restrictions: (i) no word in x or y is used more than once in the set of MCAs; (ii) words and phrases selected from y cannot be aligned to null; and (iii) no smaller MCA can be decomposed from a given pair." ></td>
	<td class="line x" title="90:216	This definition is similar to that of minimal translation units as described in Quirk and Menezes (2006), although they allow null words on either side." ></td>
	<td class="line x" title="91:216	Different word alignment approaches will result in different sets of MCAs." ></td>
	<td class="line x" title="92:216	For input lattices, we want sets of MCAs with as many aligned words as possible, while minimising the average number of words in each pair in the set." ></td>
	<td class="line x" title="93:216	Experiments with GIZA++ on the Europarl data showed that the grow-diag-final-and word alignment symmetrization heuristic had the best balance between coverage and pair length: over 85% of skeleton words were part of a non-null minimal pair, and the average length of each pair was roughly 1.5 words." ></td>
	<td class="line x" title="94:216	This indicates that our lattices will preserve most of the input space while collapsing easily alignable sub-segments." ></td>
	<td class="line x" title="95:216	Once a set of phrase alignments has been found, we construct a lattice over the skeleton sentence x. For each additional input yn we add a set of links and nodes for each word in x to any relevant  podra darnoslas cifras correspondientes a espaay grecia?" ></td>
	<td class="line x" title="96:216	pouvez-vous nous donner les chiffres pour  l' espagneet la grce?" ></td>
	<td class="line x" title="97:216	siffrorna frkan ni ge oss spanien och grekland ? Figure 4: A multi-lingual alignment between French, Spanish and Swedish, showing the minimal consistent alignments." ></td>
	<td class="line x" title="98:216	The lattice generated by this alignment is shown in Figure 5." ></td>
	<td class="line x" title="99:216	words in yn, rejoining at the last word in x that is covered by the pair." ></td>
	<td class="line x" title="100:216	Figures 4 and 5 show an example of the alignments and lattice generated by using a French skeleton with Spanish and Swedish sentences." ></td>
	<td class="line x" title="101:216	Once a lattice is created, we can submit it to a phrase-based decoder in place of text input." ></td>
	<td class="line x" title="102:216	The decoder traverses lattice nodes in a manner similar to how words are traversed in text translation." ></td>
	<td class="line x" title="103:216	Instead of one input word represented by each location in the coverage vector as in text input, with lattices there are a set of possible input word arcs, each with its own translation possibilities." ></td>
	<td class="line x" title="104:216	The concept of compatible coverage vectors for the locations of translated words becomes the notion of reachability between frontier nodes in the lattice (Dyer et al., 2008)." ></td>
	<td class="line x" title="105:216	It is possible to construct multi-skeleton lattices by connecting up a set of N lattices, each built around a different skeleton xn, in much the same manner as multiple confusion networks can be connected to form a lattice in output combination." ></td>
	<td class="line x" title="106:216	With sufficient diversity in the input ordering of each skeleton, the decoder need not perform reordering." ></td>
	<td class="line x" title="107:216	Because of the size and complexity of these multi-skeleton lattices, we attempt only monotonic decoding." ></td>
	<td class="line x" title="108:216	In this scenario, as in consensus decoding, we hope to exploit the additional word order information provided by the alternative skeletons." ></td>
	<td class="line x" title="109:216	3 Experiments: Monolingual Input We start our experimental evaluation by translating multiple monolingual inputs into a foreign language." ></td>
	<td class="line x" title="110:216	This is a best-case scenario for testing and analytic purposes because we have a single translation model from one source language to one target language." ></td>
	<td class="line x" title="111:216	While translating from multiple monolingual inputs is not a common use for machine translation, it could be useful in situations where we have a number of paraphrases of the input text, e.g., cross-language information retrieval and summarization." ></td>
	<td class="line x" title="112:216	722 0 5 pouvez-vous 1  2 kan 7 darnos 6 nouspodra 3 ni 4 ge oss 9 las les 8 siffrorna donner 11 chiffres 10 cifras 12 fr 13 l' 14 espaa spanien a pour correspondientes espagne 15 y et och 17 la 18 grecia 16 grekland grce 19 ? ?" ></td>
	<td class="line x" title="113:216	Figure 5: A multi-lingual lattice input for French, Spanish, and Swedish from Europarl dev2006." ></td>
	<td class="line x" title="114:216	Data sets for this condition are readily available in the form of test sets created for machine translation evaluation, which contains multiple target references for each source sentence." ></td>
	<td class="line x" title="115:216	By flipping these test sets around, we create multiple monolingual inputs (the original references) and a single reference output (the original source text)." ></td>
	<td class="line x" title="116:216	We examine two datasets: the BTEC Italian-English corpus (Takezawa et al., 2002), and the Multiple Translation Chinese to English (MTC) corpora,3 as used in past years NIST MT evaluations." ></td>
	<td class="line x" title="117:216	All of our translation experiments use the Moses decoder (Koehn et al., 2007), and are evaluated using BLEU-4." ></td>
	<td class="line x" title="118:216	Moses is a phrase-based decoder with features for lexicalized reordering, distance-based reordering, phrase and word translation probabilities, phrase and word counts, and an n-gram language model." ></td>
	<td class="line x" title="119:216	3.1 English to Italian We use the portion of the BTEC data made available for the Italian-English translation task at IWSLT 2007, consisting of approximately 24,000 sentences." ></td>
	<td class="line x" title="120:216	We also use the Europarl EnglishItalian parallel corpus to supplement our training data with approximately 1.2 million out-ofdomain sentences." ></td>
	<td class="line x" title="121:216	We train a 5-gram language model over both training corpora using SRILM (Stolcke, 2002) with Kneser-Ney smoothing and linear interpolation, the interpolation weight chosen to minimise perplexity on the Italian side of the development tuning set." ></td>
	<td class="line x" title="122:216	For multiple translation data, we use IWSLT test sets devset1-3 which have sixteen English translations for each Italian sentence." ></td>
	<td class="line x" title="123:216	The Italian version of the BTEC corpus was created after the original Japanese-English version, and only the first English translation was used to generate the Italian data." ></td>
	<td class="line x" title="124:216	The other fifteen versions of each English sentence were generated as paraphrases of the primary English translation." ></td>
	<td class="line x" title="125:216	We explore translation conditions using only the fifteen paraphrased inputs (Para. in Table 2), as well as using all sixteen English inputs (All)." ></td>
	<td class="line x" title="126:216	3LDC2002T01, LDC2003T17, LDC2004T07 and LDC2006T04." ></td>
	<td class="line x" title="127:216	All Para." ></td>
	<td class="line x" title="128:216	BEST 40.06 24.02 ORACLE 51.64 47.27 MAX 29.32 23.94 SYSCOMB 32.89 30.39 CN INPUT 31.86 27.62 Table 2: BLEU scores on the BTEC test set for translating English inputs into Italian." ></td>
	<td class="line x" title="129:216	We tune our translation models on devset1, system combination on devset2 and report results on devset3 for each condition." ></td>
	<td class="line x" title="130:216	When tuning the single input Para. and All baselines, we include all relevant copies of the 506 lines of devset1 English data, and repeat the Italian reference fifteen or sixteen times on the target side, resulting in a total of 7,590 and 8,096 sentence pairs respectively." ></td>
	<td class="line x" title="131:216	The results for devset3 are shown in Table 2." ></td>
	<td class="line x" title="132:216	For comparison, we show the BEST score any input produced, as well as an approximated ORACLE output selection generated by choosing the best BLEU-scoring output for each sentence using a greedy search." ></td>
	<td class="line x" title="133:216	Our output combination method, SYSCOMB, uses no system-specific weights to distinguish the inputs." ></td>
	<td class="line x" title="134:216	For SYSCOMB and MAX, we translated all versions of the English input separately, and we use the top ten distinct hypotheses from each input sentence for n-best input to SYSCOMB." ></td>
	<td class="line x" title="135:216	For input combination, CN INPUT, we used the TER-based monolingual input lattice approach described in Section 2.3, choosing as a skeleton the input with the lowest average TER score when compared with the other inputs (assessed separately for each sentence)." ></td>
	<td class="line x" title="136:216	Each input was given equal probability in the confusion network links." ></td>
	<td class="line x" title="137:216	Note that the quality of output from translating the primary English input is much higher than from translating any of the paraphrases." ></td>
	<td class="line x" title="138:216	The primary input sentence scores a BLEU of 40.06, while the highest scoring paraphrased input manages only a 24.02." ></td>
	<td class="line x" title="139:216	When we look at Para. the difference in the scores when using a single input 723 (BEST) versus all the inputs (SYSCOMB and CN INPUT) is striking  clearly there is considerable information in the other inputs which can radically improve the translation output." ></td>
	<td class="line x" title="140:216	Removing the primary input from ORACLE reinforces this observation: the score drops by only 4.37 BLEU despite the nearly 16 BLEU drop for the single best input." ></td>
	<td class="line x" title="141:216	Interestingly, the output selection technique, MAX, performs at a similar level to the combination techniques when we include the primary input, but degrades when given only the lower quality translations of paraphrased input under condition Para. In previous work on multi-lingual output selection, the MAX score degraded after two or three outputs were combined, but even without the primary reference it maintains a score near the best single paraphrased input when combining fifteen outputs." ></td>
	<td class="line x" title="142:216	One possible explanation for this is that the inputs are all being translated with the same translation model, so comparing their scores can give a more accurate ranking of their relative translation quality according to the model." ></td>
	<td class="line x" title="143:216	The input combination method, CN INPUT, performs better than MAX and only slightly worse than the output combination approach." ></td>
	<td class="line x" title="144:216	3.2 English to Chinese We can add an extra dimension to monolingual multi-source translation by considering inputs of differing quality." ></td>
	<td class="line x" title="145:216	A multi-source translation system can exploit features indicating the origin of the input to improve output quality." ></td>
	<td class="line x" title="146:216	For these experiments, we use the MTC English-Chinese corpus, parts 14." ></td>
	<td class="line x" title="147:216	This data was translated from Chinese into English by four teams of annotators, denoted E01E04." ></td>
	<td class="line x" title="148:216	This allows us to examine the results for translating the same teams work over multiple years." ></td>
	<td class="line x" title="149:216	We train on the news domain portion of the official NIST data4 (excluding the UN and Hong Kong data) for both the translation model and the 5-gram Chinese language model." ></td>
	<td class="line x" title="150:216	While we still have a single translation model, all of our inputs are now of a traceable origin and are known to have quality differences when judged by human evaluators." ></td>
	<td class="line x" title="151:216	With this information we can tune one of two ways: We can create a set of all input systems and replicate the reference as we did for English to Italian translation (All tuned), 4http://www.nist.gov/speech/tests/mt/ 2008 Team Tuning Part 3 Part 4 E01 All 16.18 15.52 E01 Self 16.02 15.63 E02 All 14.29 14.00 E02 Self 13.88 14.05 E03 All 14.99 15.06 E03 Self 15.10 14.94 E04 All 14.03 12.65 E04 Self 14.03 12.59 Table 3: BLEU scores using single inputs from each different team on the MTC." ></td>
	<td class="line x" title="152:216	Bold indicates the better score between All and Self tuning." ></td>
	<td class="line x" title="153:216	Approach Tuning Part 3 Part 4 MAX All 15.06 15.08 MAX Self 14.97 13.75 SYSCOMB All 16.82 16.24 SYSCOMB Self 16.87 16.45 Table 4: BLEU scores for multi-source translations of MTC test sets." ></td>
	<td class="line x" title="154:216	Better score for each outputbased multi-source method is shown in bold." ></td>
	<td class="line x" title="155:216	or we can tune each input using only the version of the tuning data generated by the same translation team (Self tuned).5 For example, we can tune a system with the MTC Part 2 data provided by translation team E01, and then decode E01s translations of parts 3 and 4 with the weights obtained in tuning." ></td>
	<td class="line x" title="156:216	The results for each system are shown in Table 3." ></td>
	<td class="line x" title="157:216	Despite the different tuning conditions, there is no clear advantage to tuning to all inputs versus tuning to each input separately  on average we see a 0.06 BLEU score advantage by using All weights." ></td>
	<td class="line x" title="158:216	With four different inputs to our multi-source translation system, and two ways of weighting the features for each input, how can we best utilize these systems in output selection and combination?" ></td>
	<td class="line x" title="159:216	We perform system combination and MAX selection and obtain the scores shown in Table 4." ></td>
	<td class="line x" title="160:216	The consensus decoding approach uses systemspecific features as described in Section 2.2 to distinguish between E01-E04." ></td>
	<td class="line x" title="161:216	As with English to Italian, output combination performs the best of the multi-source techniques." ></td>
	<td class="line x" title="162:216	MAX performs better with translations generated by All weights than with Self, and the con5Note that in the Self tuned setting we have only a quarter as much tuning data as for All tuned." ></td>
	<td class="line x" title="163:216	724 Input Language test2006 test2007 French (FR) 29.72 30.21 Spanish (ES) 29.55 29.62 Swedish (SV) 29.33 29.44 Portuguese (PT) 28.75 28.79 Danish (DA) 27.20 27.48 Greek (EL) 26.93 26.78 Italian (IT) 26.82 26.51 German (DE) 24.04 24.41 Dutch (NL) 23.79 24.28 Finnish (FI) 18.96 18.85 Table 5: BLEU scores for individual translation systems into English trained on Europarl, from best to worst." ></td>
	<td class="line x" title="164:216	verse is true for SYSCOMB." ></td>
	<td class="line x" title="165:216	Given the robust performance of MAX when translation scores originated from the same translation model in English to Italian, it is not surprising that it favors the case where all the outputs are scored by the same model (All tuned)." ></td>
	<td class="line x" title="166:216	On the other hand, diversity amongst the system outputs has been shown to be important to the performance of system combination techniques (Macherey and Och, 2007)." ></td>
	<td class="line x" title="167:216	This may give an indication as to why the Self tuned data produced higher scores in consensus decoding  the outputs will be more highly divergent due to their different tuning conditions." ></td>
	<td class="line x" title="168:216	4 Experiments: Multilingual Input Multilingual cases are the traditional realm of multi-source translation." ></td>
	<td class="line x" title="169:216	We no longer have directly comparable translation models; instead each input language has a separate set of rules for translating to the output language." ></td>
	<td class="line x" title="170:216	However, the availability of (and demand for) multi-parallel corpora makes this form of multi-source translation of great practical use." ></td>
	<td class="line x" title="171:216	4.1 Lattice Inputs As described in Section 2.3, lattices can be used to provide a compact format for translating multilingual inputs to a multi-source translation system." ></td>
	<td class="line x" title="172:216	We trim all non-skeleton node paths to a maximum length of four to reduce complexity when decoding." ></td>
	<td class="line x" title="173:216	Such long paths are mostly a result of errors in the original word alignments, and therefore pruning these links is largely innocuous." ></td>
	<td class="line x" title="174:216	We train on the Europarl corpus and use the FR SV ES DAPT IT EL NL DE FI BLEU 0.15 0.20 0.25 0.30 0.35 0.40 0.45 Oracle MAX Solo Figure 6: Performance for multilingual multisource translation (test2005) as each language input is added, showing Oracle target selection, MAX score, or just a single language input (Solo)." ></td>
	<td class="line x" title="175:216	in-domain test sets provided for previous years Workshops on Statistical Machine Translation." ></td>
	<td class="line x" title="176:216	Because of the computational complexity of dealing with so many models, we train on only the first 100,000 sentences of each parallel corpus." ></td>
	<td class="line x" title="177:216	Single system baseline scores for each language are shown in Table 5." ></td>
	<td class="line x" title="178:216	Besides comparing the different multi-source translation methods discussed above, in this task we also want to examine what happens when we use different numbers of input languages." ></td>
	<td class="line x" title="179:216	To determine the best order to add languages, we performed a greedy search over oracle BLEU scores for test set test2005." ></td>
	<td class="line x" title="180:216	We started with the best scoring single system, French to English, and in each iteration picked one additional system that would maximise BLEU if we always selected the translation system output closest to the reference." ></td>
	<td class="line x" title="181:216	The results are shown in Figure 6." ></td>
	<td class="line x" title="182:216	The oracle selection order differs from the order of the best performing systems, which could be due to the high scoring systems having very similar output while lower scoring systems exhibit greater diversity." ></td>
	<td class="line x" title="183:216	Interestingly, the order of the languages chosen iterates between the Roman and Germanic language families and includes Greek early on." ></td>
	<td class="line x" title="184:216	This supports our claim that diversity is important." ></td>
	<td class="line x" title="185:216	Note though that Finnish, which is also in a separate language family, is selected last, most likely due to difficulties in word alignment and translation stemming from its morphological complexity (Birch et al., 2008)." ></td>
	<td class="line x" title="186:216	This finding might also carry over to phrase-table triangulation (Cohn and Lapata, 2007), where multi-parallel data is used in training to augment a standard translation 725 Approach test2006 test2007 French Only 29.72 30.21 French + Swedish MAX 29.86 30.13 LATTICE 29.33 29.97 MULTILATTICE 29.55 29.88 SYSCOMB 31.32 31.77 French + Swedish + Spanish MAX 30.18 30.33 LATTICE 29.98 30.45 MULTILATTICE 30.50 30.50 SYSCOMB 33.77 33.87 6 Languages MAX 28.37 28.33 LATTICE 30.22 30.91 MULTILATTICE 30.59 30.59 SYSCOMB 35.47 36.03 Table 6: BLEU scores for multi-source translation systems into English trained on Europarl." ></td>
	<td class="line x" title="187:216	Single source French decoding is shown as a baseline." ></td>
	<td class="line x" title="188:216	system." ></td>
	<td class="line x" title="189:216	We choose to evaluate translation performance at three combination levels: two languages (French and Swedish), three languages (+Spanish), and six languages (+Danish, Portuguese, Italian)." ></td>
	<td class="line x" title="190:216	For each combination we apply MAX, SYSCOMB, French skeleton lattice input translation LATTICE, and monotone decoding over multiple skeleton lattices, MULTILATTICE." ></td>
	<td class="line x" title="191:216	Results are shown in Table 6." ></td>
	<td class="line x" title="192:216	To enable the decoder used in LATTICE and MULTILATTICE to learn weights for different sources, we add a feature to the phrase table for each of the languages being translated." ></td>
	<td class="line x" title="193:216	This feature takes as its value the number of words on the source side of the phrase." ></td>
	<td class="line x" title="194:216	By weighting this feature up or down for each language, the decoder can prefer word links from specific languages." ></td>
	<td class="line x" title="195:216	As seen in previous work in multi-source translation, MAX output selection performs well with two or three languages but degrades as more languages are added to the input." ></td>
	<td class="line x" title="196:216	Conversely, our lattice input method shows upward trends: LATTICE is comparable with MAX on three inputs and scores increase in the six language case." ></td>
	<td class="line x" title="197:216	Given the higher scores for output combination over input combination, what differences can we observe between the systems?" ></td>
	<td class="line x" title="198:216	Both systems have features that indicate the contributions of each input language to the final output." ></td>
	<td class="line x" title="199:216	With input combination, we are forced by the decoder to take the maximum scoring path through the lattice, but in output combination we have the aggregate vote of word confidences generated by each system." ></td>
	<td class="line x" title="200:216	If we could combine word arc scores across inputs, as in output combination, we might get a more robust solution for taking advantage of the available similarities on the target side of the translation." ></td>
	<td class="line x" title="201:216	This points to a direction for future research." ></td>
	<td class="line x" title="202:216	Other differences between the systems may explain the score gap between our input and output combination approaches." ></td>
	<td class="line x" title="203:216	Consensus decoding allows you to mix and match fragments that arent necessarily stored as fragments in the phrase table." ></td>
	<td class="line x" title="204:216	Another difference is the richer space of reorderings in TER-based lattices, due to the ability of the metric to handle long-distance alignments." ></td>
	<td class="line x" title="205:216	5 Conclusion We analyzed three approaches for dealing with multi-source translation." ></td>
	<td class="line x" title="206:216	While MAX is mostly a poor performer, the upper bound of output selection is stunning." ></td>
	<td class="line x" title="207:216	The very positive results for output system combination across all data conditions are quite promising." ></td>
	<td class="line x" title="208:216	Output combination achieves these results while the using the limited expressive power of n-best inputs." ></td>
	<td class="line x" title="209:216	The potential of using a more expressive format  such as lattices that represent the joint search space of multiple models  is high." ></td>
	<td class="line x" title="210:216	Our first attempts at adapting lattices to multi-source translation input show promise for future development." ></td>
	<td class="line x" title="211:216	We have only scratched the surface of methods for constructing input lattices, and plan to actively continue research into improving these methods." ></td>
	<td class="line x" title="212:216	Acknowledgments Thanks to Chris Callison-Burch for many insightful discussions, and to Chris Dyer for his implementation of lattice decoding in Moses." ></td>
	<td class="line x" title="213:216	This work was supported by the EuroMatrix project funded by the European Commission (6th Framework Programme), and has made use of the resources provided by the Edinburgh Compute and Data Facility (http://www.ecdf." ></td>
	<td class="line x" title="214:216	ed.ac.uk/), which is partially supported by the eDIKT initiative (http://www.edikt.org)." ></td>
	<td class="line x" title="215:216	We also acknowledge the support of the EPSRC (grant GR/T04557/01)." ></td>
	<td class="line x" title="216:216	726" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N09-3008
Multiple Word Alignment with Profile Hidden Markov Models
Bhargava, Aditya;Kondrak, Grzegorz;"></td>
	<td class="line x" title="1:144	Proceedings of the NAACL HLT Student Research Workshop and Doctoral Consortium, pages 4348, Boulder, Colorado, June 2009." ></td>
	<td class="line x" title="2:144	c 2009 Association for Computational Linguistics Multiple Word Alignment with Profile Hidden Markov Models Aditya Bhargava and Grzegorz Kondrak Department of Computing Science University of Alberta Edmonton, Alberta, Canada, T6G 2E8 {abhargava,kondrak}@cs.ualberta.ca Abstract Profile hidden Markov models (Profile HMMs) are specific types of hidden Markov models used in biological sequence analysis." ></td>
	<td class="line x" title="3:144	We propose the use of Profile HMMs for word-related tasks." ></td>
	<td class="line x" title="4:144	We test their applicability to the tasks of multiple cognate alignment and cognate set matching, and find that they work well in general for both tasks." ></td>
	<td class="line x" title="5:144	On the latter task, the Profile HMM method outperforms average and minimum edit distance." ></td>
	<td class="line x" title="6:144	Given the success for these two tasks, we further discuss the potential applications of Profile HMMs to any task where consideration of a set of words is necessary." ></td>
	<td class="line x" title="7:144	1 Introduction In linguistics, it is often necessary to align words or phonetic sequences." ></td>
	<td class="line x" title="8:144	Covington (1996) uses alignments of cognate pairs for the historical linguistics task of comparative reconstruction and Nerbonne and Heeringa (1997) use alignments to compute relative distances between words from various Dutch dialects." ></td>
	<td class="line x" title="9:144	Algorithms for aligning pairs of words have been proposed by Covington (1996) and Kondrak (2000)." ></td>
	<td class="line x" title="10:144	However, it is often necessary to align multiple words." ></td>
	<td class="line x" title="11:144	Covington (1998) proposed a method to align multiple words based on a handcrafted scale of similarity between various classes of phonemes, again for the purpose of comparative reconstruction of languages." ></td>
	<td class="line x" title="12:144	Profile hidden Markov models (Profile HMMs) are specific types of hidden Markov models used in biological sequence analysis, where they have yielded success for the matching of given sequences to sequence families as well as to multiple sequence alignment (Durbin et al., 1998)." ></td>
	<td class="line x" title="13:144	In this paper, we show that Profile HMMs can be adapted to the task of aligning multiple words." ></td>
	<td class="line x" title="14:144	We apply them to sets of multilingual cognates and show that they produce good alignments." ></td>
	<td class="line x" title="15:144	We also use them for the related task of matching words to established cognate sets, useful for a situation where it is not immediately obvious to which cognate set a word should be matched." ></td>
	<td class="line x" title="16:144	The accuracy on the latter task exceeds the accuracy of a method based on edit distance." ></td>
	<td class="line x" title="17:144	Profile HMMs could also potentially be used for the computation of word similarity when a word must be compared not to another word but to another set of words, taking into account properties of all constituent words." ></td>
	<td class="line oc" title="18:144	The use of Profile HMMs for multiple sequence alignment also presents applications to the acquisition of mapping dictionaries (Barzilay and Lee, 2002) and sentence-level paraphrasing (Barzilay and Lee, 2003)." ></td>
	<td class="line x" title="19:144	This paper is organized as follows: we first describe the uses of Profile HMMs in computational biology, their structure, and then discuss their applications to word-related tasks." ></td>
	<td class="line x" title="20:144	We then discuss our data set and describe the tasks that we test and their experimental setups and results." ></td>
	<td class="line x" title="21:144	We conclude with a summary of the results and a brief discussion of potential future work." ></td>
	<td class="line x" title="22:144	2 Profile hidden Markov models In computational biology, it is often necessary to deal with multiple sequences, including DNA and protein sequences." ></td>
	<td class="line x" title="23:144	For such biological sequence analysis, Profile HMMs are applied to the common tasks of simultaneously aligning multiple related sequences to each other, aligning a new sequence to 43 Begin End DL IL MLM1 I1 D1 I0 Figure 1: A prototypical Profile HMM of length L. Mi is the ith match state, Ii is the ith insert state, and Di is the ith delete state." ></td>
	<td class="line x" title="24:144	Delete states are silent and are used to indicate gaps in a sequence." ></td>
	<td class="line x" title="25:144	an already-aligned family of sequences, and evaluating a new sequence for membership in a family of sequences." ></td>
	<td class="line x" title="26:144	Profile HMMs consist of several types of states: match states, insert states, delete states, as well as a begin and end state." ></td>
	<td class="line x" title="27:144	For each position in a Profile HMM, there is one match state, one insert state, and one delete state." ></td>
	<td class="line x" title="28:144	A Profile HMM can thus be visualized as a series of columns, where each column represents a position in the sequence (see Figure 1)." ></td>
	<td class="line x" title="29:144	Any arbitrary sequence can then be represented as a traversal of states from column to column." ></td>
	<td class="line x" title="30:144	Match states form the core of the model; each match state is represented by a set of emission probabilities for each symbol in the output alphabet." ></td>
	<td class="line x" title="31:144	These probabilities indicate the distribution of values for a given position in a sequence." ></td>
	<td class="line x" title="32:144	Each match state can probabilistically transition to the next (i.e. next-column) match and delete states as well as the current (i.e. current-column) insert state." ></td>
	<td class="line x" title="33:144	Insert states represent possible values that can be inserted at a given position in a sequence (before a match emission or deletion)." ></td>
	<td class="line x" title="34:144	They are represented in the same manner as match states, with each output symbol having an associated probability." ></td>
	<td class="line x" title="35:144	Insert states are used to account for symbols that have been inserted to a given position that might not otherwise have occurred naturally via a match state." ></td>
	<td class="line x" title="36:144	Insert states can probabilistically transition to the next match and delete states as well as the current insert state (i.e. itself)." ></td>
	<td class="line x" title="37:144	Allowing insert states to transition to themselves enables the consideration of multiplesymbol inserts." ></td>
	<td class="line x" title="38:144	MMIIIM AGC A-AG.C AG.AA--AAAC AGC Figure 2: A small DNA multiple alignment from (Durbin et al., 1998, p. 123)." ></td>
	<td class="line x" title="39:144	Similarly, delete states represent symbols that have been removed from a given position." ></td>
	<td class="line x" title="40:144	For a sequence to use a delete state for a given position indicates that a given character position in the model has no corresponding characters in the given sequence." ></td>
	<td class="line x" title="41:144	Hence, delete states are by nature silent and thus have no emission probabilities for the output symbols." ></td>
	<td class="line x" title="42:144	This is an important distinction from match states and insert states." ></td>
	<td class="line x" title="43:144	Each delete state can probabilistically transition to the next match and delete states as well as the current insert state." ></td>
	<td class="line x" title="44:144	Figure 2 shows a small example of a set of DNA sequences." ></td>
	<td class="line x" title="45:144	The match columns and insert columns are marked with the letters M and I respectively in the first line." ></td>
	<td class="line x" title="46:144	Where a word has a character in a match column, it is a match state emission; when there is instead a gap, it is a delete state occurrence." ></td>
	<td class="line x" title="47:144	Any characters in insert columns are insert state emissions, and gaps in insert columns represent simply that the particular insert state was not used for the sequence in question." ></td>
	<td class="line x" title="48:144	Durbin et al.(1998) describe the uses of Profile HMMs for tasks in biological sequence analysis." ></td>
	<td class="line x" title="50:144	Firstly, a Profile HMM must be constructed." ></td>
	<td class="line x" title="51:144	If a Profile HMM is to be constructed from a set of aligned sequences, it is necessary to designate certain columns as match columns and others as insert column." ></td>
	<td class="line x" title="52:144	The simple heuristic that we adopt is to label those columns match states for which half or more of the sequences have a symbol present (rather than a gap)." ></td>
	<td class="line x" title="53:144	Other columns are labelled insert states." ></td>
	<td class="line x" title="54:144	Then the probability akl of state k transitioning to state l can be estimated by counting the number of timesAkl that the transition is used in the alignment: akl = Aklsummationtext lprime Aklprime Similarly, the probability ek(a) of state k emitting symbol a is estimated by counting the number of 44 times Ek(a) that the emission is used in the alignment: ek(a) = Ek(a)summationtext aprime Ek(aprime) There is the danger that some probabilities may be set to zero, so it is essential to add pseudocounts." ></td>
	<td class="line x" title="55:144	The pseudocount methods that we explore are described in section 3." ></td>
	<td class="line x" title="56:144	If a Profile HMM is to be constructed from a set of unaligned sequences, an initial model is generated after which it can be trained to the sequences using the Baum-Welch algorithm." ></td>
	<td class="line x" title="57:144	The length of the model must be chosen, and is usually set to the average length of the unaligned sequences." ></td>
	<td class="line x" title="58:144	To generate the initial model, which amounts to setting the transition and emission probabilities to some initial values, the probabilities are sampled from Dirichlet distributions." ></td>
	<td class="line x" title="59:144	Once a Profile HMM has been constructed, it can be used to evaluate a given sequence for membership in the family." ></td>
	<td class="line x" title="60:144	This is done via a straightforward application of the forward algorithm (to get the full probability of the given sequence) or the Viterbi algorithm (to get the alignment of the sequence to the family)." ></td>
	<td class="line x" title="61:144	For the alignment of multiple unaligned sequences, a Profile HMM is constructed and trained as described above and then each sequence can be aligned using the Viterbi algorithm." ></td>
	<td class="line x" title="62:144	It should also be noted that Profile HMMs are generalizations of Pair HMMs, which have been used for cognate identification and word similarity (Mackay and Kondrak, 2005) between pairs of words." ></td>
	<td class="line x" title="63:144	Unlike Pair HMMs, Profile HMMs are position-specific; this is what allows their application to multiple sequences but also means that each Profile HMM must be trained to a given set of sequences, whereas Pair HMMs can be trained over a very large data set of pairs of words." ></td>
	<td class="line x" title="64:144	3 Adapting Profile HMMs to words Using Profile HMMs for biological sequences involves defining an alphabet and working with related sequences consisting of symbols from that alphabet." ></td>
	<td class="line x" title="65:144	One could perform tasks with cognates sets in a similar manner; cognates are, after all, related words, and words are nothing more than sequences of symbols from an alphabet." ></td>
	<td class="line x" title="66:144	Thus Profile HMMs present potential applications to similar tasks for cognate sets." ></td>
	<td class="line x" title="67:144	We apply Profile HMMs to the multiple alignment of cognate sets, which is done in the same manner as multiple sequence alignment for biological sequences described above." ></td>
	<td class="line x" title="68:144	We also test Profile HMMs for determining the correct cognate set to which a word belongs when given a variety of cognate sets for the same meaning; this is done in a similar manner to the sequence membership evaluation task described above." ></td>
	<td class="line x" title="69:144	Although there are a number of Profile HMM packages available (e.g. HMMER), we decided to develop an implementation from scratch in order to achieve greater control over various adjustable parameters.1 We investigated the following parameters: Favouring match states When constructing a Profile HMM from unaligned sequences, the choice of initial model probabilities can have a significant effect on results." ></td>
	<td class="line x" title="70:144	It may be sensible to favour match states compared to other states when constructing the initial model; since the transition probabilities are sampled from a Dirichlet distribution, the option of favouring match states assigns the largest returned probability to the transition to a match state." ></td>
	<td class="line x" title="71:144	Pseudocount method We implemented three pseudocount methods from (Durbin et al., 1998)." ></td>
	<td class="line x" title="72:144	In the following equations,ej(a) is the probability of state j emitting character a. cja represents the observed counts of state j emitting symbol a. A is the weight given to the pseudocounts." ></td>
	<td class="line x" title="73:144	Constant value A constant value AC is added to each count." ></td>
	<td class="line x" title="74:144	This is a generalization of Laplaces rule, where C = 1A." ></td>
	<td class="line x" title="75:144	ej(a) = cja +ACsummationtext aprime cjaprime +A Background frequency Pseudocounts are added in proportion to the background frequency qa, which is the frequency of occurrence of character a. ej(a) = cja +Aqasummationtext aprime cjaprime +A 1Our implementation is available online at http://www." ></td>
	<td class="line x" title="76:144	cs.ualberta.ca/ab31/profilehmm." ></td>
	<td class="line x" title="77:144	45 Substitution matrix (Durbin et al., 1998) Given a matrix s(a,b) that gives the logodds similarity of characters a and b, we can determine the conditional probability of a character b given character a: P(b|a) = qbes(a,b) Then we define fja to be the probability derived from the counts: fja = cjasummationtext aprime cjaprime Then the pseudocount values are set to: ja = Asummationdisplay b fjbP(a|b) Finally, the pseudocount values are added to the real counts as above: ej(a) = cja +jasummationtext aprime cjaprime +japrime Pseudocount weight The weight that the pseudocounts are given (A in the above equations)." ></td>
	<td class="line x" title="78:144	Smoothing during Baum-Welch The problem has many local optima and it is therefore easy for the Baum-Welch algorithm to get stuck around one of these." ></td>
	<td class="line x" title="79:144	In order to avoid local optima, we tested the option of adding pseudocounts during Baum-Welch (i.e. between iterations) rather than after it." ></td>
	<td class="line x" title="80:144	This serves as a form of noise injection, effectively bumping BaumWelch away from local optima." ></td>
	<td class="line x" title="81:144	4 Data for experiments Our data come from the Comparative Indoeuropean Data Corpus (Dyen et al., 1992)." ></td>
	<td class="line x" title="82:144	The data consist of words in 95 languages in the Indoeuropean family organized into word lists corresponding to one of 200 meanings." ></td>
	<td class="line x" title="83:144	Each word is represented in the English alphabet." ></td>
	<td class="line x" title="84:144	Figure 3 shows a sample from the original corpus data." ></td>
	<td class="line x" title="85:144	We manually converted the data into disjoint sets of cognate words, where each cognate set contains only one word from each language." ></td>
	<td class="line x" title="86:144	We also removed words that were not cognate with any other words." ></td>
	<td class="line x" title="87:144	On average, there were 4.37 words per cognate set." ></td>
	<td class="line x" title="88:144	The smallest cognate set had two words (since a 026 DAY  b 003 026 53 Bulgarian DEN 026 47 Czech E DENY 026 45 Czech DEN 026 43 Lusatian L ZEN 026 44 Lusatian U DZEN 026 50 Polish DZIEN 026 51 Russian DEN 026 54 Serbocroatian DAN 026 42 Slovenian DAN 026 41 Latvian DIENA 026 05 Breton List DEIZ, DE(Z) 026 04 Welsh C DYDD 026 20 Spanish DIA 026 17 Sardinian N DIE 026 11 Ladin DI 026 08 Rumanian List ZI 026 09 Vlach ZUE 026 15 French Creole C ZU 026 13 French JOUR 026 14 Walloon DJOU 026 10 Italian GIORNO  Figure 3: An excerpt from the original corpus data." ></td>
	<td class="line x" title="89:144	The first two numbers denote the meaning and the language, respectively." ></td>
	<td class="line x" title="90:144	we excluded those words that were not cognate with any other words), and the largest had 84 words." ></td>
	<td class="line x" title="91:144	There were on average 10.92 cognate sets in a meaning." ></td>
	<td class="line x" title="92:144	The lowest number of cognate sets in a meaning was 1, and the largest number was 22." ></td>
	<td class="line x" title="93:144	5 Multiple cognate alignment Similar to their use for multiple sequence alignment of sequences in a family, we test Profile HMMs for the task of aligning cognates." ></td>
	<td class="line x" title="94:144	As described above, an initial model is generated." ></td>
	<td class="line x" title="95:144	We use the aforementioned heuristic of setting the initial model length to the average length of the sequences." ></td>
	<td class="line x" title="96:144	The transition probabilities are sampled from a uniform-parameter Dirichlet distribution, with each parameter having a value of 5.0." ></td>
	<td class="line x" title="97:144	The insert-state emission probabilities are set to the background frequencies and the match-state emission probabilities are sampled from a Dirichlet distribution with parameters set in proportion to the background frequency." ></td>
	<td class="line x" title="98:144	The model is 46 MIIMIIMI MIIMIIMI D--E--ND--E--NY Z--E--NDZ-E--NDZIE--ND--A--NDI-E--NA D--E--IZ D--I--AD--Y--DD D--I--EZ-----UZ--U--EZ-----IJ--O--UR D-----IDJ-O--UG--IORNO Figure 4: The alignment generated via the Profile HMM method for some cognates." ></td>
	<td class="line x" title="99:144	These were aligned together, but we show them in two columns to preserve space." ></td>
	<td class="line x" title="100:144	trained to the cognate set via the Baum-Welch algorithm, and then each word in the set is aligned to the model using the Viterbi algorithm." ></td>
	<td class="line x" title="101:144	The words are added to the training via a summation; therefore, the order in which the words are considered has no effect, in contrast to iterative pairwise methods." ></td>
	<td class="line x" title="102:144	The setting of the parameter values is discussed in section 6." ></td>
	<td class="line x" title="103:144	5.1 Results To evaluate Profile HMMs for multiple cognate alignment, we analyzed the alignments generated for a number of cognate sets." ></td>
	<td class="line x" title="104:144	We found that increasing the pseudocount weight to 100 improved the quality of the alignments by effectively biasing the model towards similar characters according to the substitution matrix." ></td>
	<td class="line x" title="105:144	Figure 4 shows the Profile HMM alignment for a cognate set of words with the meaning day. As with Figure 2, the alignments first line is a guide label used to indicate which columns are match columns and which are insert columns; note that consecutive insert columns represent the same insert state and so are not aligned by the Profile HMM." ></td>
	<td class="line x" title="106:144	While there were some duplicate words (i.e. words that had identical English orthographic representations but came from different languages), we do not show them here for brevity." ></td>
	<td class="line x" title="107:144	In this example, we see that the Profile HMM manages to identify those columns that are more highly conserved as match states." ></td>
	<td class="line x" title="108:144	The ability to identify characters that are similar and align them correctly can be attributed to the provided substitution matrix." ></td>
	<td class="line x" title="109:144	Note that the characters in the insert columns should not be treated as aligned even though they represent emissions from the same insert state (this highlights the difference between match and insert states)." ></td>
	<td class="line x" title="110:144	For example, Y, A, Z, D, R, and O are all placed in a single insert column even though they cannot be traced to a single phoneme in a protoform of the cognate set." ></td>
	<td class="line x" title="111:144	Particularly infrequent characters are more likely to be put together than separated even if they are phonetically dissimilar." ></td>
	<td class="line x" title="112:144	There is some difficulty, also evident from other alignments we generated, in isolating phonemes represented by pairs of characters (digraphs) as singular entities." ></td>
	<td class="line x" title="113:144	In the given example, this means that the dz in dzien was modelled as a match state and then an insert state." ></td>
	<td class="line x" title="114:144	This is, however, an inherent difficulty in using data represented only with the English alphabet, which could potentially be addressed if the data were instead represented in a standard phonetic notation such as IPA." ></td>
	<td class="line x" title="115:144	6 Cognate set matching Evaluating alignments in a principled way is difficult because of the lack of a gold standard." ></td>
	<td class="line x" title="116:144	To adjust for this, we also evaluate Profile HMMs for the task of matching a word to the correct cognate set from a list of cognate sets with the same meaning as the given word, similar to the evaluation of a biological sequence for membership in a family." ></td>
	<td class="line x" title="117:144	This is realized by removing one word at a time from each word list and then using the resulting cognate sets within the meaning as possible targets." ></td>
	<td class="line x" title="118:144	A model is generated from each possible target and a log-odds score is computed for the word using the forward algorithm." ></td>
	<td class="line x" title="119:144	The scores are then sorted and the highest score is taken to be the cognate set to which the given word belongs." ></td>
	<td class="line x" title="120:144	The accuracy is then the fraction of times the correct cognate set is identified." ></td>
	<td class="line x" title="121:144	To determine the best parameter values, we used a development set of 10 meanings (roughly 5% of the data)." ></td>
	<td class="line x" title="122:144	For the substitution matrix pseudocount method, we used a log-odds similarity matrix derived from Pair HMM training (Mackay and Kondrak, 2005)." ></td>
	<td class="line x" title="123:144	The best results were achieved with favouring of match states enabled, substitutionmatrix-based pseudocount, pseudocount weight of 0.5, and pseudocounts added during Baum-Welch." ></td>
	<td class="line x" title="124:144	47 6.1 Results We employed two baselines to generate scores between a given word and cognate set." ></td>
	<td class="line x" title="125:144	The first baseline uses the average edit distance of the test word and the words in the given cognate set as the score of the word against the set." ></td>
	<td class="line x" title="126:144	The second baseline is similar but uses the minimum edit distance between the test word and any word in the given cognate set as the score of the word against the entire set." ></td>
	<td class="line x" title="127:144	For example, in the example set given in Figure 4, the average edit distance between zen and all other words in the set is 2.58 (including the hidden duplicate words) and the minimum edit distance is 1." ></td>
	<td class="line x" title="128:144	All other candidate sets are similarly scored and the one with the lowest score is considered to be the correct cluster with ties broken randomly." ></td>
	<td class="line x" title="129:144	With the parameter settings described in the previous section, the Profile HMM method correctly identifies the corresponding cognate set with an accuracy of 93.2%, a substantial improvement over the average edit distance baseline, which obtains an accuracy of 77.0%." ></td>
	<td class="line x" title="130:144	Although the minimum edit distance baseline also yields an impressive accuracy of 91.0%, its score is based on a single word in the candidate set, and so would not be appropriate for cases where consideration of the entire set is necessary." ></td>
	<td class="line x" title="131:144	Furthermore, the baseline benefits from the frequent presence of duplicate words in the cognate sets." ></td>
	<td class="line x" title="132:144	Profile HMMs are more robust, thanks to the presence of identical or similar characters in corresponding positions." ></td>
	<td class="line x" title="133:144	7 Conclusions Profile HMMs present an approach for working with sets of words." ></td>
	<td class="line x" title="134:144	We tested their use for two cognaterelated tasks." ></td>
	<td class="line x" title="135:144	The method produced good-quality multiple cognate alignments, and we believe that they could be further improved with phonetically transcribed data." ></td>
	<td class="line x" title="136:144	For the task of matching words to correct cognate sets, we achieved an improvement over the average edit distance and minimum edit distance baselines." ></td>
	<td class="line x" title="137:144	Since Profile HMM training is highly sensitive to the choice of initial model, we would like to explore more informed methods of constructing the initial model." ></td>
	<td class="line x" title="138:144	Similarly, for building models from unaligned sequences, the addition of domain knowledge would likely prove beneficial." ></td>
	<td class="line x" title="139:144	We also plan to investigate better pseudocount methods, as well as the possibility of using n-grams as output symbols." ></td>
	<td class="line x" title="140:144	By simultaneously considering an entire set of related words, Profile HMMs provide a distinct advantage over iterative pairwise methods." ></td>
	<td class="line x" title="141:144	The success on our tasks of multiple alignment and cognate set matching suggests applicability to similar tasks involving words, such as named entity recognition across potentially multi-lingual corpora." ></td>
	<td class="line x" title="142:144	Acknowledgements We thank Qing Dou for organizing the cognate sets from the original data." ></td>
	<td class="line x" title="143:144	We are also grateful to the anonymous reviewers for their valuable comments." ></td>
	<td class="line x" title="144:144	This research was funded in part by the Natural Sciences and Engineering Research Council of Canada." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-1053
Paraphrase Identification as Probabilistic Quasi-Synchronous Recognition
Das, Dipanjan;Smith, Noah A.;"></td>
	<td class="line x" title="1:248	Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 468476, Suntec, Singapore, 2-7 August 2009." ></td>
	<td class="line x" title="2:248	c2009 ACL and AFNLP Paraphrase Identification as Probabilistic Quasi-Synchronous Recognition Dipanjan Das and Noah A. Smith Language Technologies Institute Carnegie Mellon University Pittsburgh, PA 15213, USA {dipanjan,nasmith}@cs.cmu.edu Abstract We present a novel approach to deciding whether two sentences hold a paraphrase relationship." ></td>
	<td class="line x" title="3:248	We employ a generative model that generates a paraphrase of a given sentence, and we use probabilistic inference to reason about whether two sentences share the paraphrase relationship." ></td>
	<td class="line x" title="4:248	The model cleanly incorporates both syntax and lexical semantics using quasi-synchronous dependency grammars (Smith and Eisner, 2006)." ></td>
	<td class="line x" title="5:248	Furthermore, using a product of experts (Hinton, 2002), we combine the model with a complementary logistic regression model based on state-of-the-art lexical overlap features." ></td>
	<td class="line x" title="6:248	We evaluate our models on the task of distinguishing true paraphrase pairs from false ones on a standard corpus, giving competitive state-of-the-art performance." ></td>
	<td class="line x" title="7:248	1 Introduction The problem of modeling paraphrase relationships between natural language utterances (McKeown, 1979) has recently attracted interest." ></td>
	<td class="line x" title="8:248	For computational linguists, solving this problem may shed light on how best to model the semantics of sentences." ></td>
	<td class="line oc" title="9:248	For natural language engineers, the problem bears on information management systems like abstractive summarizers that must measure semantic overlap between sentences (Barzilay and Lee, 2003), question answering modules (Marsi and Krahmer, 2005) and machine translation (Callison-Burch et al., 2006)." ></td>
	<td class="line x" title="10:248	The paraphrase identification problem asks whether two sentences have essentially the same meaning." ></td>
	<td class="line x" title="11:248	Although paraphrase identification is defined in semantic terms, it is usually solved using statistical classifiers based on shallow lexical, n-gram, and syntactic overlap features." ></td>
	<td class="line x" title="12:248	Such overlap features give the best-published classification accuracy for the paraphrase identification task (Zhang and Patrick, 2005; Finch et al., 2005; Wan et al., 2006; Corley and Mihalcea, 2005, inter alia), but do not explicitly model correspondence structure (or alignment) between the parts of two sentences." ></td>
	<td class="line x" title="13:248	In this paper, we adopt a model that posits correspondence between the words in the two sentences, defining it in loose syntactic terms: if two sentences are paraphrases, we expect their dependency trees to align closely, though some divergences are also expected, with some more likely than others." ></td>
	<td class="line x" title="14:248	Following Smith and Eisner (2006), we adopt the view that the syntactic structure of sentences paraphrasing some sentence s should be inspired by the structure of s. Because dependency syntax is still only a crude approximation to semantic structure, we augment the model with a lexical semantics component, based on WordNet (Miller, 1995), that models how words are probabilistically altered in generating a paraphrase." ></td>
	<td class="line x" title="15:248	This combination of loose syntax and lexical semantics is similar to the Jeopardy model of Wang et al.(2007)." ></td>
	<td class="line x" title="17:248	This syntactic framework represents a major departure from useful and popular surface similarity features, and the latter are difficult to incorporate into our probabilistic model." ></td>
	<td class="line x" title="18:248	We use a product of experts (Hinton, 2002) to bring together a logistic regression classifier built from n-gram overlap features and our syntactic model." ></td>
	<td class="line x" title="19:248	This combined model leverages complementary strengths of the two approaches, outperforming a strong state-ofthe-art baseline (Wan et al., 2006)." ></td>
	<td class="line x" title="20:248	This paper is organized as follows." ></td>
	<td class="line x" title="21:248	We introduce our probabilistic model in 2." ></td>
	<td class="line x" title="22:248	The model makes use of three quasi-synchronous grammar models (Smith and Eisner, 2006, QG, hereafter) as components (one modeling paraphrase, one modeling not-paraphrase, and one a base grammar); these are detailed, along with latent-variable inference and discriminative training algorithms, in 3." ></td>
	<td class="line x" title="23:248	We discuss the Microsoft Research Paraphrase Corpus, upon which we conduct experiments, in 4." ></td>
	<td class="line x" title="24:248	In 5, we present experiments on paraphrase 468 identification with our model and make comparisons with the existing state-of-the-art." ></td>
	<td class="line x" title="25:248	We describe the product of experts and our lexical overlap model, and discuss the results achieved in6." ></td>
	<td class="line x" title="26:248	We relate our approach to prior work (7) and conclude (8)." ></td>
	<td class="line x" title="27:248	2 Probabilistic Model Since our task is a classification problem, we require our model to provide an estimate of the posterior probability of the relationship (i.e., paraphrase, denoted p, or not paraphrase, denoted n), given the pair of sentences.1 Here, pQ denotes model probabilities, c is a relationship class (p or n), and s1 and s2 are the two sentences." ></td>
	<td class="line x" title="28:248	We choose the class according to: c = argmax c{p,n} pQ(c|s1,s2) = argmax c{p,n} pQ(c)pQ(s1,s2 |c) (1) We define the class-conditional probabilities of the two sentences using the following generative story." ></td>
	<td class="line x" title="29:248	First, grammar G0 generates a sentence s. Then a class c is chosen, corresponding to a classspecific probabilistic quasi-synchronous grammar Gc." ></td>
	<td class="line x" title="30:248	(We will discuss QG in detail in3." ></td>
	<td class="line x" title="31:248	For the present, consider it a specially-defined probabilistic model that generates sentences with a specific property, like paraphrases s, whenc = p.)" ></td>
	<td class="line x" title="32:248	Given s, Gc generates the other sentence in the pair, sprime." ></td>
	<td class="line x" title="33:248	When we observe a pair of sentences s1 and s2 we do not presume to know which came first (i.e., which was s and which was sprime)." ></td>
	<td class="line x" title="34:248	Both orderings are assumed to be equally probable." ></td>
	<td class="line x" title="35:248	For class c, pQ(s1,s2 |c) = 0.5pQ(s1 |G0)pQ(s2 |Gc(s1)) + 0.5pQ(s2 |G0)pQ(s1 |Gc(s2))(2) where c can be p or n; Gp(s) is the QG that generates paraphrases for sentence s, while Gn(s) is the QG that generates sentences that are not paraphrases of sentence s. This latter model may seem counter-intuitive: since the vast majority of possible sentences are not paraphrases of s, why is a special grammar required?" ></td>
	<td class="line x" title="36:248	Our use of a Gn follows from the properties of the corpus currently used for learning, in which the negative examples 1Although we do not explore the idea here, the model could be adapted for other sentence-pair relationships like entailment or contradiction." ></td>
	<td class="line x" title="37:248	were selected to have high lexical overlap." ></td>
	<td class="line x" title="38:248	We return to this point in4." ></td>
	<td class="line x" title="39:248	3 QG for Paraphrase Modeling Here, we turn to the models Gp and Gn in detail." ></td>
	<td class="line x" title="40:248	3.1 Background Smith and Eisner (2006) introduced the quasisynchronous grammar formalism." ></td>
	<td class="line x" title="41:248	Here, we describe some of its salient aspects." ></td>
	<td class="line x" title="42:248	The model arose out of the empirical observation that translated sentences have some isomorphic syntactic structure, but divergences are possible." ></td>
	<td class="line x" title="43:248	Therefore, rather than an isomorphic structure over a pair of source and target sentences, the syntactic tree over a target sentence is modeled by a source sentencespecific grammar inspired by the source sentences tree." ></td>
	<td class="line x" title="44:248	This is implemented by associating with each node in the target tree a subset of the nodes in the source tree." ></td>
	<td class="line x" title="45:248	Since it loosely links the two sentences syntactic structures, QG is well suited for problems like word alignment for MT (Smith and Eisner, 2006) and question answering (Wang et al., 2007)." ></td>
	<td class="line x" title="46:248	Consider a very simple quasi-synchronous context-free dependency grammar that generates one dependent per production rule.2 Let s = s1,,smbe the source sentence." ></td>
	<td class="line x" title="47:248	The grammar rules will take one of the two forms: t,lt,ltprime,kort,ltprime,kt,l where t and tprime range over the vocabulary of the target language, and l and k {0,,m} are indices in the source sentence, with 0 denoting null.3 Hard or soft constraints can be applied between l and k in a rule." ></td>
	<td class="line x" title="48:248	These constraints imply permissible configurations. For example, requiringlnegationslash= 0 and, if knegationslash= 0 then sk must be a child of sl in the source tree, we can implement a synchronous dependency grammar similar to (Melamed, 2004)." ></td>
	<td class="line x" title="49:248	Smith and Eisner (2006) used a quasisynchronous grammar to discover the correspondence between words implied by the correspondence between the trees." ></td>
	<td class="line x" title="50:248	We follow Wang et al.(2007) in treating the correspondences as latent variables, and in using a WordNet-based lexical semantics model to generate the target words." ></td>
	<td class="line x" title="52:248	2Our actual model is more complicated; see 3.2." ></td>
	<td class="line x" title="53:248	3A more general QG could allow one-to-many alignments, replacing l and k with sets of indices." ></td>
	<td class="line x" title="54:248	469 3.2 Detailed Model We describe how we model pQ(t | Gp(s)) and pQ(t | Gn(s)) for source and target sentences s and t (appearing in Eq." ></td>
	<td class="line x" title="55:248	2 alternately as s1 and s2)." ></td>
	<td class="line x" title="56:248	A dependency tree on a sequence w = w1,,wk is a mapping of indices of words to indices of syntactic parents, p : {1,,k}  {0,,k}, and a mapping of indices of words to dependency relation types inL, lscript : {1,,k} L. The set of indices children of wi to its left, {j : w(j) = i,j < i}, is denoted w(i), and w(i) is used for right children." ></td>
	<td class="line x" title="57:248	wi has a single parent, denoted by wp(i)." ></td>
	<td class="line x" title="58:248	Cycles are not allowed, and w0 is taken to be the dummy wall symbol, $, whose only child is the root word of the sentence (normally the main verb)." ></td>
	<td class="line x" title="59:248	The label for wi is denoted by lscript(i)." ></td>
	<td class="line x" title="60:248	We denote the whole tree of a sentence w by w, the subtree rooted at the ith word by w,i. Consider two sentences: let the source sentence s contain m words and the target sentence t contain n words." ></td>
	<td class="line x" title="61:248	Let the correspondence x : {1,,n}  {0,,m} be a mapping from indices of words in t to indices of words in s." ></td>
	<td class="line x" title="62:248	(We require each target word to map to at most one source word, though multiple target words can map to the same source word, i.e., x(i) = x(j) while inegationslash= j.)" ></td>
	<td class="line x" title="63:248	When x(i) = 0, the ith target word maps to the wall symbol, equivalently a null word." ></td>
	<td class="line x" title="64:248	Each of our QGs Gp and Gn generates the alignments x, the target tree t, and the sentence t. Both Gp and Gn are structured in the same way, differing only in their parameters; henceforth we discuss Gp; Gn is similar." ></td>
	<td class="line x" title="65:248	We assume that the parse trees of s and t are known.4 Therefore our model defines: pQ(t|Gp(s)) = p(t|Gp(s)) = summationtextxp(t,x|Gp(s)) (3) Because the QG is essentially a context-free dependency grammar, we can factor it into recursive steps as follows (let i be an arbitrary index in{1,,n}): P(t,i|ti,x(i),s) = pval(|t(i)|,|t(i)||ti) 4In our experiments, we use the parser described by McDonald et al.(2005), trained on sections 221 of the WSJ Penn Treebank, transformed to dependency trees following Yamada and Matsumoto (2003)." ></td>
	<td class="line x" title="67:248	(The same treebank data were also to estimate many of the parameters of our model, as discussed in the text.)" ></td>
	<td class="line x" title="68:248	Though it leads to a partial pipeline approximation of the posterior probability p(c| s,t), we believe that the relatively high quality of English dependency parsing makes this approximation reasonable." ></td>
	<td class="line x" title="69:248	 productdisplay jt(i)t(i) msummationdisplay x(j)=0 P(t,j|tj,x(j),s) pkid(tj,tlscript(j),x(j)|ti,x(i),s) (4) where pval and pkid are valence and childproduction probabilities parameterized as discussed in3.4." ></td>
	<td class="line x" title="70:248	Note the recursion in the secondto-last line." ></td>
	<td class="line x" title="71:248	We next describe a dynamic programming solution for calculating p(t |Gp(s))." ></td>
	<td class="line x" title="72:248	In3.4 we discuss the parameterization of the model." ></td>
	<td class="line x" title="73:248	3.3 Dynamic Programming Let C(i,l) refer to the probability of t,i, assuming that the parent of ti, ttp(i), is aligned to sl." ></td>
	<td class="line x" title="74:248	For leaves of t, the base case is: C(i,l) = pval(0,0|ti) (5)summationtext m k=0pkid(ti,tlscript(i),k|ttp(i),l,s) where k ranges over possible values of x(i), the source-tree node to which ti is aligned." ></td>
	<td class="line x" title="75:248	The recursive case is: C(i,l) = pval(|t(i)|,|t(i)||ti) (6) summationtextmk=0pkid(ti,tlscript(i),k|ttp(i),l,s) producttextjt(i)t(i)C(j,k) We assume that the wall symbols t0 and s0 are aligned, so p(t |Gp(s)) = C(r,0), where r is the index of the root word of the target tree t. It is straightforward to show that this algorithm requires O(m2n) runtime and O(mn) space." ></td>
	<td class="line x" title="76:248	3.4 Parameterization The valency distribution pval in Eq." ></td>
	<td class="line x" title="77:248	4 is estimated in our model using the transformed treebank (see footnote 4)." ></td>
	<td class="line x" title="78:248	For unobserved cases, the conditional probability is estimated by backing off to the parent POS tag and child direction." ></td>
	<td class="line x" title="79:248	We discuss next how to parameterize the probability pkid that appears in Equations 4, 5, and 6." ></td>
	<td class="line x" title="80:248	This conditional distribution forms the core of our QGs, and we deviate from earlier research using QGs in defining pkid in a fully generative way." ></td>
	<td class="line x" title="81:248	In addition to assuming that dependency parse trees for s and t are observable, we also assume each word wi comes with POS and named entity tags." ></td>
	<td class="line x" title="82:248	In our experiments these were obtained automatically using MXPOST (Ratnaparkhi, 1996) and BBNs Identifinder (Bikel et al., 1999)." ></td>
	<td class="line x" title="83:248	470 For clarity, let j = tp(i) and let l = x(j)." ></td>
	<td class="line x" title="84:248	pkid(ti,tlscript(i),x(i)|tj,l,s) = pconfig(config(ti,tj,sx(i),sl)|tj,l,s) (7) punif (x(i)|config(ti,tj,sx(i),sl)) (8) plab(tlscript(i)|config(ti,tj,sx(i),sl)) (9) ppos(pos(ti)|pos(sx(i))) (10) pne(ne(ti)|ne(sx(i))) (11) plsrel(lsrel(ti)|sx(i)) (12) pword(ti|lsrel(ti),sx(i)) (13) We consider each of the factors above in turn." ></td>
	<td class="line x" title="85:248	Configuration In QG, configurations refer to the tree relationship among source-tree nodes (above, sl and sx(i)) aligned to a pair of parentchild target-tree nodes (above, tj and ti)." ></td>
	<td class="line x" title="86:248	In deriving t,j, the model first chooses the configuration that will hold among ti, tj, sx(i) (which has yet to be chosen), and sl (line 7)." ></td>
	<td class="line x" title="87:248	This is defined for configuration c log-linearly by:5 pconfig(c|tj,l,s) = csummationdisplay cprime:sk,config(ti,tj,sk,sl)=cprime cprime (14) Permissible configurations in our model are shown in Table 1." ></td>
	<td class="line x" title="88:248	These are identical to prior work (Smith and Eisner, 2006; Wang et al., 2007), except that we add a root configuration that aligns the target parent-child pair to null and the head word of the source sentence, respectively." ></td>
	<td class="line x" title="89:248	Using many permissible configurations helps remove negative effects from noisy parses, which our learner treats as evidence." ></td>
	<td class="line x" title="90:248	Fig." ></td>
	<td class="line x" title="91:248	1 shows some examples of major configurations that Gp discovers in the data." ></td>
	<td class="line x" title="92:248	Source tree alignment After choosing the configuration, the specific node in s that ti will align to, sx(i) is drawn uniformly (line 8) from among those in the configuration selected." ></td>
	<td class="line x" title="93:248	Dependency label, POS, and named entity class The newly generated target words dependency label, POS, and named entity class drawn from multinomial distributions plab, ppos, and pne that condition, respectively, on the configuration and the POS and named entity class of the aligned source-tree word sx(i) (lines 911)." ></td>
	<td class="line x" title="94:248	5We use log-linear models three times: for the configuration, the lexical semantics class, and the word." ></td>
	<td class="line x" title="95:248	Each time, we are essentially assigning one weight per outcome and renormalizing among the subset of outcomes that are possible given what has been derived so far." ></td>
	<td class="line x" title="96:248	Configuration Description parent-child sp(x(i)) = x(j), appended with slscript(x(i)) child-parent x(i) = sp(x(j)), appended withslscript(x(j)) grandparentgrandchild sp(sp(x(i))) = x(j), appended with slscript(x(i)) siblings sp(x(i)) = sp(x(j)),x(i) negationslash= x(j) same-node x(i) = x(j) c-command the parent of one source-side word is an ancestor of the other source-side word root x(j) = 0,x(i) is the root of s child-null x(i) = 0 parent-null x(j) = 0, x(i) is something other than root of s other catch-all for all other types of configurations, which are permitted Table 1: Permissible configurations." ></td>
	<td class="line x" title="97:248	i is an index in t whose configuration is to be chosen; j = tp(i) is is parent." ></td>
	<td class="line x" title="98:248	WordNet relation(s) The model next chooses a lexical semantics relation between sx(i) and the yet-to-be-chosen word ti (line 12)." ></td>
	<td class="line x" title="99:248	Following Wang et al.(2007),6 we employ a 14-feature loglinear model over all logically possible combinations of the 14 WordNet relations (Miller, 1995).7 Similarly to Eq." ></td>
	<td class="line x" title="101:248	14, we normalize this log-linear model based on the set of relations that are nonempty in WordNet for the word sx(i)." ></td>
	<td class="line x" title="102:248	Word Finally, the target word is randomly chosen from among the set of words that bear the lexical semantic relationship just chosen (line 13)." ></td>
	<td class="line x" title="103:248	This distribution is, again, defined log-linearly: pword(ti|lsrel(ti) = R,sx(i)) = tisummationtext wprime:sx(i)Rwprime wprime (15) Here w is the Good-Turing unigram probability estimate of a word w from the Gigaword corpus (Graff, 2003)." ></td>
	<td class="line x" title="104:248	3.5 Base Grammar G0 In addition to the QG that generates a second sentence bearing the desired relationship (paraphrase or not) to the first sentence s, our model in2 also requires a base grammar G0 over s. We view this grammar as a trivial special case of the same QG model already described." ></td>
	<td class="line x" title="105:248	G0 assumes the empty source sentence consists only of 6Note that Wang et al.(2007) designed pkid as an interpolation between a log-linear lexical semantics model and a word model." ></td>
	<td class="line x" title="107:248	Our approach is more fully generative." ></td>
	<td class="line x" title="108:248	7These are: identical-word, synonym, antonym (including extended and indirect antonym), hypernym, hyponym, derived form, morphological variation (e.g., plural form), verb group, entailment, entailed-by, see-also, causal relation, whether the two words are same and is a number, and no relation." ></td>
	<td class="line x" title="109:248	471 (a) parent-child fill questionnaire complete questionnaire dozens wounded injured dozens (b) child-parent (c) grandparent-grandchild will chief will Secretary Liscouski quarter first first-quarter (e) same-node U.S refunding massive (f) siblings U.S treasury treasury (g) root null fell null dropped (d) c-command signatures necessary signatures needed 897,158 the twice approaching collected Figure 1: Some example configurations from Table 1 that Gp discovers in the dev." ></td>
	<td class="line x" title="110:248	data." ></td>
	<td class="line x" title="111:248	Directed arrows show head-modifier relationships, while dotted arrows show alignments." ></td>
	<td class="line x" title="112:248	a single wall node." ></td>
	<td class="line x" title="113:248	Thus every word generated under G0 aligns to null, and we can simplify the dynamic programming algorithm that scores a tree s under G0: Cprime(i) = pval(|t(i)|,|t(i)||si) plab(tlscript(i))ppos(pos(ti))pne(ne(ti)) pword(ti)producttextj:t(j)=iCprime(j) (16) where the final product is 1 when ti has no children." ></td>
	<td class="line x" title="114:248	It should be clear that p(s|G0) = Cprime(0)." ></td>
	<td class="line x" title="115:248	We estimate the distributions over dependency labels, POS tags, and named entity classes using the transformed treebank (footnote 4)." ></td>
	<td class="line x" title="116:248	The distribution over words is taken from the Gigaword corpus (as in3.4)." ></td>
	<td class="line x" title="117:248	It is important to note thatG0 is designed to give a smoothed estimate of the probability of a particular parsed, named entity-tagged sentence." ></td>
	<td class="line x" title="118:248	It is never used for parsing or for generation; it is only used as a component in the generative probability model presented in2 (Eq." ></td>
	<td class="line x" title="119:248	2)." ></td>
	<td class="line x" title="120:248	3.6 Discriminative Training Given training data angbracketleftBig s(i)1 ,s(i)2 ,c(i) angbracketrightBigN i=1, we trainthe model discriminatively by maximizing regularized conditional likelihood: max Nsummationdisplay i=1 log pQ(c(i) |s(i)1 ,s(i)2 ,)bracehtipupleft bracehtipdownrightbracehtipdownleft bracehtipupright Eq." ></td>
	<td class="line x" title="121:248	2 relates this to G{0,p,n} Cbardblbardbl22 (17) The parameters  to be learned include the class priors, the conditional distributions of the dependency labels given the various configurations, the POS tags given POS tags, the NE tags given NE tags appearing in expressions 911, the configuration weights appearing in Eq." ></td>
	<td class="line x" title="122:248	14, and the weights of the various features in the log-linear model for the lexical-semantics model." ></td>
	<td class="line x" title="123:248	As noted, the distributions pval , the word unigram weights in Eq." ></td>
	<td class="line x" title="124:248	15, and the parameters of the base grammar are fixed using the treebank (see footnote 4) and the Gigaword corpus." ></td>
	<td class="line x" title="125:248	Since there is a hidden variable (x), the objective function is non-convex." ></td>
	<td class="line x" title="126:248	We locally optimize using the L-BFGS quasi-Newton method (Liu and Nocedal, 1989)." ></td>
	<td class="line x" title="127:248	Because many of our parameters are multinomial probabilities that are constrained to sum to one and L-BFGS is not designed to handle constraints, we treat these parameters as unnormalized weights that get renormalized (using a softmax function) before calculating the objective." ></td>
	<td class="line x" title="128:248	4 Data and Task In all our experiments, we have used the Microsoft Research Paraphrase Corpus (Dolan et al., 2004; Quirk et al., 2004)." ></td>
	<td class="line x" title="129:248	The corpus contains 5,801 pairs of sentences that have been marked as equivalent or not equivalent. It was constructed from thousands of news sources on the web." ></td>
	<td class="line x" title="130:248	Dolan and Brockett (2005) remark that this corpus was created semi-automatically by first training an SVM classifier on a disjoint annotated 10,000 sentence pair dataset and then applying the SVM on an unseen 49,375 sentence pair corpus, with its output probabilities skewed towards over-identification, i.e., towards generating some false paraphrases." ></td>
	<td class="line x" title="131:248	5,801 out of these 49,375 pairs were randomly selected and presented to human judges for refinement into true and false paraphrases." ></td>
	<td class="line x" title="132:248	3,900 of the pairs were marked as having 472 About 120 potential jurors were being asked to complete a lengthy questionnaire . The jurors were taken into the courtroom in groups of 40 and asked to fill out a questionnaire . Figure 2: Discovered alignment of Ex." ></td>
	<td class="line x" title="133:248	19 produced by Gp." ></td>
	<td class="line x" title="134:248	Observe that the model aligns identical words and also complete and fill in this specific case." ></td>
	<td class="line x" title="135:248	This kind of alignment provides an edge over a simple lexical overlap model." ></td>
	<td class="line x" title="136:248	mostly bidirectional entailment, a standard definition of the paraphrase relation." ></td>
	<td class="line x" title="137:248	Each sentence was labeled first by two judges, who averaged 83% agreement, and a third judge resolved conflicts." ></td>
	<td class="line x" title="138:248	We use the standard data split into 4,076 (2,753 paraphrase, 1,323 not) training and 1,725 (1147 paraphrase, 578 not) test pairs." ></td>
	<td class="line x" title="139:248	We reserved a randomly selected 1,075 training pairs for tuning.We cite some examples from the training set here: (18) Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier." ></td>
	<td class="line x" title="140:248	With the scandal hanging over Stewarts company, revenue in the first quarter of the year dropped 15 percent from the same period a year earlier." ></td>
	<td class="line x" title="141:248	(19) About 120 potential jurors were being asked to complete a lengthy questionnaire." ></td>
	<td class="line x" title="142:248	The jurors were taken into the courtroom in groups of 40 and asked to fill out a questionnaire." ></td>
	<td class="line x" title="143:248	Ex." ></td>
	<td class="line x" title="144:248	18 is a true paraphrase pair." ></td>
	<td class="line x" title="145:248	Notice the high lexical overlap between the two sentences (unigram overlap of 100% in one direction and 72% in the other)." ></td>
	<td class="line x" title="146:248	Ex." ></td>
	<td class="line x" title="147:248	19 is another true paraphrase pair with much lower lexical overlap (unigram overlap of 50% in one direction and 30% in the other)." ></td>
	<td class="line x" title="148:248	Notice the use of similar-meaning phrases and irrelevant modifiers that retain the same meaning in both sentences, which a lexical overlap model cannot capture easily, but a model like a QG might." ></td>
	<td class="line x" title="149:248	Also, in both pairs, the relationship cannot be called total bidirectional equivalence because there is some extra information in one sentence which cannot be inferred from the other." ></td>
	<td class="line x" title="150:248	Ex." ></td>
	<td class="line x" title="151:248	20 was labeled not paraphrase: (20) There were a number of bureaucratic and administrative missed signals theres not one person whos responsible here, Gehman said." ></td>
	<td class="line x" title="152:248	In turning down the NIMA offer, Gehman said, there were a number of bureaucratic and administrative missed signals here." ></td>
	<td class="line x" title="153:248	There is significant content overlap, making a decision difficult for a nave lexical overlap classifier." ></td>
	<td class="line x" title="154:248	(In fact, pQ labels this example n while the lexical overlap models label it p.)" ></td>
	<td class="line x" title="155:248	The fact that negative examples in this corpus were selected because of their high lexical overlap is important." ></td>
	<td class="line x" title="156:248	It means that any discriminative model is expected to learn to distinguish mere overlap from paraphrase." ></td>
	<td class="line x" title="157:248	This seems appropriate, but it does mean that the not paraphrase relation ought to be denoted not paraphrase but deceptively similar on the surface. It is for this reason that we use a special QG for the n relation." ></td>
	<td class="line x" title="158:248	5 Experimental Evaluation Here we present our experimental evaluation using pQ." ></td>
	<td class="line x" title="159:248	We trained on the training set (3,001 pairs) and tuned model metaparameters (C in Eq." ></td>
	<td class="line x" title="160:248	17) and the effect of different feature sets on the development set (1,075 pairs)." ></td>
	<td class="line x" title="161:248	We report accuracy on the official MSRPC test dataset." ></td>
	<td class="line x" title="162:248	If the posterior probability pQ(p | s1,s2) is greater than 0.5, the pair is labeled paraphrase (as in Eq." ></td>
	<td class="line x" title="163:248	1)." ></td>
	<td class="line x" title="164:248	5.1 Baseline We replicated a state-of-the-art baseline model for comparison." ></td>
	<td class="line x" title="165:248	Wan et al.(2006) report the best published accuracy, to our knowledge, on this task, using a support vector machine." ></td>
	<td class="line x" title="167:248	Our baseline is a reimplementation of Wan et al.(2006), using features calculated directly from s1 and s2 without recourse to any hidden structure: proportion of word unigram matches, proportion of lemmatized unigram matches, BLEU score (Papineni et al., 2001), BLEU score on lemmatized tokens, F measure (Turian et al., 2003), difference of sentence length, and proportion of dependency relation overlap." ></td>
	<td class="line x" title="169:248	The SVM was trained to classify positive and negative examples of paraphrase using SVMlight (Joachims, 1999).8 Metaparameters, tuned on the development data, were the regularization constant and the degree of the polynomial kernel (chosen in [105, 102] and 15 respectively.).9 It is unsurprising that the SVM performs very well on the MSRPC because of the corpus creation process (see Sec." ></td>
	<td class="line x" title="170:248	4) where an SVM was applied as well, with very similar features and a skewed decision process (Dolan and Brockett, 2005)." ></td>
	<td class="line x" title="171:248	8http://svmlight.joachims.org 9Our replication of the Wan et al. model is approximate, because we used different preprocessing tools: MXPOST for POS tagging (Ratnaparkhi, 1996), MSTParser for parsing (McDonald et al., 2005), and Dan Bikels interface (http://www.cis.upenn.edu/dbikel/ software.html#wn) to WordNet (Miller, 1995) for lemmatization information." ></td>
	<td class="line x" title="172:248	Tuning led to C = 17 and polynomial degree 4." ></td>
	<td class="line x" title="173:248	473 Model Accuracy Precision Recall baselines all p 66.49 66.49 100.00 Wan et al. SVM (reported) 75.63 77.00 90.00 Wan et al. SVM (replication) 75.42 76.88 90.14 pQ lexical semantics features removed 68.64 68.84 96.51 all features 73.33 74.48 91.10 c-command disallowed (best; see text) 73.86 74.89 91.28 6 pL 75.36 78.12 87.44product of experts 76.06 79.57 86.05 oracles Wan et al. SVM and pL 80.17 100.00 92.07 Wan et al. SVM and pQ 83.42 100.00 96.60 pQ and pL 83.19 100.00 95.29 Table 2: Accuracy, p-class precision, and p-class recall on the test set (N = 1,725)." ></td>
	<td class="line x" title="174:248	See text for differences in implementation between Wan et al. and our replication; their reported score does not include the full test set." ></td>
	<td class="line x" title="175:248	5.2 Results Tab." ></td>
	<td class="line x" title="176:248	2 shows performance achieved by the baseline SVM and variations on pQ on the test set." ></td>
	<td class="line x" title="177:248	We performed a few feature ablation studies, evaluating on the development data." ></td>
	<td class="line x" title="178:248	We removed the lexical semantics component of the QG,10 and disallowed the syntactic configurations one by one, to investigate which components ofpQ contributes to system performance." ></td>
	<td class="line x" title="179:248	The lexical semantics component is critical, as seen by the drop in accuracy from the table (without this component, pQ behaves almost like the all p baseline)." ></td>
	<td class="line x" title="180:248	We found that the most important configurations are parent-child, and child-parent while damage from ablating other configurations is relatively small." ></td>
	<td class="line x" title="181:248	Most interestingly, disallowing the ccommand configuration resulted in the best absolute accuracy, giving us the best version of pQ." ></td>
	<td class="line x" title="182:248	The c-command configuration allows more distant nodes in a source sentence to align to parent-child pairs in a target (see Fig." ></td>
	<td class="line x" title="183:248	1d)." ></td>
	<td class="line x" title="184:248	Allowing this configuration guides the model in the wrong direction, thus reducing test accuracy." ></td>
	<td class="line x" title="185:248	We tried disallowing more than one configuration at a time, without getting improvements on development data." ></td>
	<td class="line x" title="186:248	We also tried ablating the WordNet relations, and observed that the identical-word feature hurt the model the most." ></td>
	<td class="line x" title="187:248	Ablating the rest of the features did not produce considerable changes in accuracy." ></td>
	<td class="line x" title="188:248	The development data-selected pQ achieves higher recall by 1 point than Wan et al.s SVM, but has precision 2 points worse." ></td>
	<td class="line x" title="189:248	5.3 Discussion It is quite promising that a linguistically-motivated probabilistic model comes so close to a stringsimilarity baseline, without incorporating stringlocal phrases." ></td>
	<td class="line x" title="190:248	We see several reasons to prefer 10This is accomplished by eliminating lines 12 and 13 from the definition of pkid and redefining pword to be the unigram word distribution estimated from the Gigaword corpus, as in G0, without the help of WordNet." ></td>
	<td class="line x" title="191:248	the more intricate QG to the straightforward SVM." ></td>
	<td class="line x" title="192:248	First, the QG discovers hidden alignments between words." ></td>
	<td class="line x" title="193:248	Alignments have been leveraged in related tasks such as textual entailment (Giampiccolo et al., 2007); they make the model more interpretable in analyzing system output (e.g., Fig." ></td>
	<td class="line x" title="194:248	2)." ></td>
	<td class="line x" title="195:248	Second, the paraphrases of a sentence can be considered to be monolingual translations." ></td>
	<td class="line x" title="196:248	We model the paraphrase problem using a direct machine translation model, thus providing a translation interpretation of the problem." ></td>
	<td class="line x" title="197:248	This framework could be extended to permit paraphrase generation, or to exploit other linguistic annotations, such as representations of semantics (see, e.g., Qiu et al., 2006)." ></td>
	<td class="line x" title="198:248	Nonetheless, the usefulness of surface overlap features is difficult to ignore." ></td>
	<td class="line x" title="199:248	We next provide an efficient way to combine a surface model with pQ." ></td>
	<td class="line x" title="200:248	6 Product of Experts Incorporating structural alignment and surface overlap features inside a single model can make exact inference infeasible." ></td>
	<td class="line x" title="201:248	As an example, consider features liken-gram overlap percentages that provide cues of content overlap between two sentences." ></td>
	<td class="line x" title="202:248	One intuitive way of including these features in a QG could be including these only at the root of the target tree, i.e. while calculating C(r,0)." ></td>
	<td class="line x" title="203:248	These features have to be included in estimating pkid, which has log-linear component models (Eq." ></td>
	<td class="line x" title="204:248	713)." ></td>
	<td class="line x" title="205:248	For these bigram or trigram overlap features, a similar log-linear model has to be normalized with a partition function, which considers the (unnormalized) scores of all possible target sentences, given the source sentence." ></td>
	<td class="line x" title="206:248	We therefore combine pQ with a lexical overlap model that gives another posterior probability estimate pL(c|s1,s2) through a product of experts (PoE; Hinton, 2002), pJ(c|s1,s2) = pQ(c|s1,s2)pL(c|s1,s2)summationdisplay cprime{p,n} pQ(cprime|s1,s2)pL(cprime|s1,s2) (21) 474 Eq." ></td>
	<td class="line x" title="207:248	21 takes the product of the two models posterior probabilities, then normalizes it to sum to one." ></td>
	<td class="line x" title="208:248	PoE models are used to efficiently combine several expert models that individually constrain different dimensions in high-dimensional data, the product therefore constraining all of the dimensions." ></td>
	<td class="line x" title="209:248	Combining models in this way grants to each expert component model the ability to veto a class by giving it low probability; the most probable class is the one that is least objectionable to all experts." ></td>
	<td class="line x" title="210:248	Probabilistic Lexical Overlap Model We devised a logistic regression (LR) model incorporating 18 simple features, computed directly from s1 and s2, without modeling any hidden correspondence." ></td>
	<td class="line x" title="211:248	LR (like the QG) provides a probability distribution, but uses surface features (like the SVM)." ></td>
	<td class="line x" title="212:248	The features are of the form precisionn (number of n-gram matches divided by the number of n-grams in s1), recalln (number of n-gram matches divided by the number of n-grams in s2) and Fn (harmonic mean of the previous two features), where 1  n  3." ></td>
	<td class="line x" title="213:248	We also used lemmatized versions of these features." ></td>
	<td class="line x" title="214:248	This model gives the posterior probability pL(c | s1,s2), where c {p,n}." ></td>
	<td class="line x" title="215:248	We estimated the model parameters analogously to Eq." ></td>
	<td class="line x" title="216:248	17." ></td>
	<td class="line x" title="217:248	Performance is reported in Tab." ></td>
	<td class="line x" title="218:248	2; this model is on par with the SVM, though trading recall in favor of precision." ></td>
	<td class="line x" title="219:248	We view it as a probabilistic simulation of the SVM more suitable for combination with the QG." ></td>
	<td class="line x" title="220:248	Training the PoE Various ways of training a PoE exist." ></td>
	<td class="line x" title="221:248	We first trained pQ and pL separately as described, then initialized the PoE with those parameters." ></td>
	<td class="line x" title="222:248	We then continued training, maximizing (unregularized) conditional likelihood." ></td>
	<td class="line x" title="223:248	Experiment We used pQ with the c-command configuration excluded, and the LR model in the product of experts." ></td>
	<td class="line x" title="224:248	Tab." ></td>
	<td class="line x" title="225:248	2 includes the final results achieved by the PoE." ></td>
	<td class="line x" title="226:248	The PoE model outperforms all the other models, achieving an accuracy of 76.06%.11 The PoE is conservative, labeling a pair as p only if the LR and the QG give it strong p probabilities." ></td>
	<td class="line x" title="227:248	This leads to high precision, at the expense of recall." ></td>
	<td class="line x" title="228:248	Oracle Ensembles Tab." ></td>
	<td class="line x" title="229:248	2 shows the results of three different oracle ensemble systems that correctly classify a pair if either of the two individual systems in the combination is correct." ></td>
	<td class="line x" title="230:248	Note that the combinations involving pQ achieve 83%, the 11This accuracy is significant over pQ under a paired t-test (p< 0.04), but is not significant over the SVM." ></td>
	<td class="line x" title="231:248	human agreement level for the MSRPC." ></td>
	<td class="line x" title="232:248	The LR and SVM are highly similar, and their oracle combination does not perform as well." ></td>
	<td class="line x" title="233:248	7 Related Work There is a growing body of research that uses the MSRPC (Dolan et al., 2004; Quirk et al., 2004) to build models of paraphrase." ></td>
	<td class="line x" title="234:248	As noted, the most successful work has used edit distance (Zhang and Patrick, 2005) or bag-of-words features to measure sentence similarity, along with shallow syntactic features (Finch et al., 2005; Wan et al., 2006; Corley and Mihalcea, 2005)." ></td>
	<td class="line x" title="235:248	Qiu et al.(2006) used predicate-argument annotations." ></td>
	<td class="line x" title="237:248	Most related to our approach, Wu (2005) used inversion transduction grammarsa synchronous context-free formalism (Wu, 1997)for this task." ></td>
	<td class="line x" title="238:248	Wu reported only positive-class (p) precision (not accuracy) on the test set." ></td>
	<td class="line x" title="239:248	He obtained 76.1%, while our PoE model achieves 79.6% on that measure." ></td>
	<td class="line x" title="240:248	Wus model can be understood as a strict hierarchical maximum-alignment method." ></td>
	<td class="line x" title="241:248	In contrast, our alignments are soft (we sum over them), and we do not require strictly isomorphic syntactic structures." ></td>
	<td class="line x" title="242:248	Most importantly, our approach is founded on a stochastic generating process and estimated discriminatively for this task, while Wu did not estimate any parameters from data at all." ></td>
	<td class="line x" title="243:248	8 Conclusion In this paper, we have presented a probabilistic model of paraphrase incorporating syntax, lexical semantics, and hidden loose alignments between two sentences trees." ></td>
	<td class="line x" title="244:248	Though it fully defines a generative process for both sentences and their relationship, the model is discriminatively trained to maximize conditional likelihood." ></td>
	<td class="line x" title="245:248	We have shown that this model is competitive for determining whether there exists a semantic relationship between them, and can be improved by principled combination with more standard lexical overlap approaches." ></td>
	<td class="line x" title="246:248	Acknowledgments The authors thank the three anonymous reviewers for helpful comments and Alan Black, Frederick Crabbe, Jason Eisner, Kevin Gimpel, Rebecca Hwa, David Smith, and Mengqiu Wang for helpful discussions." ></td>
	<td class="line x" title="247:248	This work was supported by DARPA grant NBCH-1080004." ></td>
	<td class="line x" title="248:248	475" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-1094
Application-driven Statistical Paraphrase Generation
Zhao, Shiqi;Lan, Xiang;Liu, Ting;Li, Sheng;"></td>
	<td class="line x" title="1:246	Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834842, Suntec, Singapore, 2-7 August 2009." ></td>
	<td class="line x" title="2:246	c2009 ACL and AFNLP Application-driven Statistical Paraphrase Generation Shiqi Zhao, Xiang Lan, Ting Liu, Sheng Li Information Retrieval Lab, Harbin Institute of Technology 6F Aoxiao Building, No.27 Jiaohua Street, Nangang District Harbin, 150001, China {zhaosq,xlan,tliu,lisheng}@ir.hit.edu.cn Abstract Paraphrase generation (PG) is important in plenty of NLP applications." ></td>
	<td class="line x" title="3:246	However, the research of PG is far from enough." ></td>
	<td class="line x" title="4:246	In this paper, we propose a novel method for statistical paraphrase generation (SPG), which can (1) achieve various applications based on a uniform statistical model, and (2) naturally combine multiple resources to enhance the PG performance." ></td>
	<td class="line x" title="5:246	In our experiments, we use the proposed method to generate paraphrases for three different applications." ></td>
	<td class="line x" title="6:246	The results show that the method can be easily transformed from one application to another and generate valuable and interesting paraphrases." ></td>
	<td class="line x" title="7:246	1 Introduction Paraphrases are alternative ways that convey the same meaning." ></td>
	<td class="line x" title="8:246	There are two main threads in the research of paraphrasing, i.e., paraphrase recognition and paraphrase generation (PG)." ></td>
	<td class="line x" title="9:246	Paraphrase generation aims to generate a paraphrase for a source sentence in a certain application." ></td>
	<td class="line x" title="10:246	PG shows its importance in many areas, such as question expansion in question answering (QA) (Duboue and Chu-Carroll, 2006), text polishing in natural language generation (NLG) (Iordanskaja et al., 1991), text simplification in computer-aided reading (Carroll et al., 1999), and sentence similarity computation in the automatic evaluation of machine translation (MT) (Kauchak and Barzilay, 2006) and summarization (Zhou et al., 2006)." ></td>
	<td class="line x" title="11:246	This paper presents a method for statistical paraphrase generation (SPG)." ></td>
	<td class="line x" title="12:246	As far as we know, this is the first statistical model specially designed for paraphrase generation." ></td>
	<td class="line x" title="13:246	Its distinguishing feature is that it achieves various applications with a uniform model." ></td>
	<td class="line x" title="14:246	In addition, it exploits multiple resources, including paraphrase phrases, patterns, and collocations, to resolve the data shortage problem and generate more varied paraphrases." ></td>
	<td class="line x" title="15:246	We consider three paraphrase applications in our experiments, including sentence compression, sentence simplification, and sentence similarity computation." ></td>
	<td class="line x" title="16:246	The proposed method generates paraphrases for the input sentences in each application." ></td>
	<td class="line x" title="17:246	The generated paraphrases are then manually scored based on adequacy, fluency, and usability." ></td>
	<td class="line x" title="18:246	The results show that the proposed method is promising, which generates useful paraphrases for the given applications." ></td>
	<td class="line x" title="19:246	In addition, comparison experiments show that our method outperforms a conventional SMT-based PG method." ></td>
	<td class="line x" title="20:246	2 Related Work Conventional methods for paraphrase generation can be classified as follows: Rule-based methods: Rule-based PG methods build on a set of paraphrase rules or patterns, which are either hand crafted or automatically collected." ></td>
	<td class="line x" title="21:246	In the early rule-based PG research, the paraphrase rules are generally manually written (McKeown, 1979; Zong et al., 2001), which is expensive and arduous." ></td>
	<td class="line oc" title="22:246	Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods." ></td>
	<td class="line n" title="23:246	However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004)." ></td>
	<td class="line x" title="24:246	Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 2004; 834 Kauchak and Barzilay, 2006)." ></td>
	<td class="line x" title="25:246	This kind of method usually involves two phases, i.e., candidate extraction and paraphrase validation." ></td>
	<td class="line x" title="26:246	In the first phase, it extracts all synonyms from a thesaurus, such as WordNet, for the words to be substituted." ></td>
	<td class="line x" title="27:246	In the second phase, it selects an optimal substitute for each given word from the synonyms according to the context in s. This kind of method is simple, since the thesaurus synonyms are easy to access." ></td>
	<td class="line x" title="28:246	However, it cannot generate other types of paraphrases but only synonym substitution." ></td>
	<td class="line x" title="29:246	NLG-based methods: NLG-based methods (Kozlowski et al., 2003; Power and Scott, 2005) generally involve two stages." ></td>
	<td class="line x" title="30:246	In the first one, the source sentence s is transformed into its semantic representation r by undertaking a series of NLP processing, including morphology analyzing, syntactic parsing, semantic role labeling, etc. In the second stage, a NLG system is employed to generate a sentence t from r. s and t are paraphrases as they are both derived from r. The NLG-based methods simulate human paraphrasing behavior, i.e., understanding a sentence and presenting the meaning in another way." ></td>
	<td class="line x" title="31:246	However, deep analysis of sentences is a big challenge." ></td>
	<td class="line x" title="32:246	Moreover, developing a NLG system is also not trivial." ></td>
	<td class="line x" title="33:246	SMT-based methods: SMT-based methods viewed PG as monolingual MT, i.e., translating s into t that are in the same language." ></td>
	<td class="line x" title="34:246	Researchers employ the existing SMT models for PG (Quirk et al., 2004)." ></td>
	<td class="line x" title="35:246	Similar to typical SMT, a large parallel corpus is needed as training data in the SMT-based PG." ></td>
	<td class="line x" title="36:246	However, such data are difficult to acquire compared with the SMT data." ></td>
	<td class="line x" title="37:246	Therefore, data shortage becomes the major limitation of the method." ></td>
	<td class="line x" title="38:246	To address this problem, we have tried combining multiple resources to improve the SMT-based PG model (Zhao et al., 2008a)." ></td>
	<td class="line x" title="39:246	There have been researchers trying to propose uniform PG methods for multiple applications." ></td>
	<td class="line x" title="40:246	But they are either rule-based (Murata and Isahara, 2001; Takahashi et al., 2001) or thesaurusbased (Bolshakov and Gelbukh, 2004), thus they have some limitations as stated above." ></td>
	<td class="line x" title="41:246	Furthermore, few of them conducted formal experiments to evaluate the proposed methods." ></td>
	<td class="line x" title="42:246	3 Statistical Paraphrase Generation 3.1 Differences between SPG and SMT Despite the similarity between PG and MT, the statistical model used in SMT cannot be directly applied in SPG, since there are some clear differences between them: 1." ></td>
	<td class="line x" title="43:246	SMT has a unique purpose, i.e., producing high-quality translations for the inputs." ></td>
	<td class="line x" title="44:246	On the contrary, SPG has distinct purposes in different applications, such as sentence compression, sentence simplification, etc. The usability of the paraphrases have to be assessed in each application." ></td>
	<td class="line x" title="45:246	2." ></td>
	<td class="line x" title="46:246	In SMT, words of an input sentence should be totally translated, whereas in SPG, not all words of an input sentence need to be paraphrased." ></td>
	<td class="line x" title="47:246	Therefore, a SPG model should be able to decide which part of a sentence needs to be paraphrased." ></td>
	<td class="line x" title="48:246	3." ></td>
	<td class="line x" title="49:246	The bilingual parallel data for SMT are easy to collect." ></td>
	<td class="line x" title="50:246	In contrast, the monolingual parallel data for SPG are not so common (Quirk et al., 2004)." ></td>
	<td class="line x" title="51:246	Thus the SPG model should be able to easily combine different resources and thereby solve the data shortage problem (Zhao et al., 2008a)." ></td>
	<td class="line x" title="52:246	4." ></td>
	<td class="line x" title="53:246	Methods have been proposed for automatic evaluation in MT (e.g., BLEU (Papineni et al., 2002))." ></td>
	<td class="line x" title="54:246	The basic idea is that a translation should be scored based on their similarity to the human references." ></td>
	<td class="line x" title="55:246	However, they cannot be adopted in SPG." ></td>
	<td class="line x" title="56:246	The main reason is that it is more difficult to provide human references in SPG." ></td>
	<td class="line x" title="57:246	Lin and Pantel (2001) have demonstrated that the overlapping between the automatically acquired paraphrases and handcrafted ones is very small." ></td>
	<td class="line x" title="58:246	Thus the human references cannot properly assess the quality of the generated paraphrases." ></td>
	<td class="line x" title="59:246	3.2 Method Overview The SPG method proposed in this work contains three components, i.e., sentence preprocessing, paraphrase planning, and paraphrase generation (Figure 1)." ></td>
	<td class="line x" title="60:246	Sentence preprocessing mainly includes POS tagging and dependency parsing for the input sentences, as POS tags and dependency information are necessary for matching the paraphrase pattern and collocation resources in the following stages." ></td>
	<td class="line x" title="61:246	Paraphrase planning (Section 3.3) aims to select the units to be paraphrased (called source units henceforth) in an input sentence and the candidate paraphrases for the source 835 Multiple Paraphrase Tables PT1 Paraphrase Planning Paraphrase Generation t Sentence Preprocessings A PT2 PTn Figure 1: Overview of the proposed SPG method." ></td>
	<td class="line x" title="62:246	units (called target units) from multiple resources according to the given application A. Paraphrase generation (Section 3.4) is designed to generate paraphrases for the input sentences by selecting the optimal target units with a statistical model." ></td>
	<td class="line x" title="63:246	3.3 Paraphrase Planning In this work, the multiple paraphrase resources are stored in paraphrase tables (PTs)." ></td>
	<td class="line x" title="64:246	A paraphrase table is similar to a phrase table in SMT, which contains fine-grained paraphrases, such as paraphrase phrases, patterns, or collocations." ></td>
	<td class="line x" title="65:246	The PTs used in this work are constructed using different corpora and different score functions (Section 3.5)." ></td>
	<td class="line x" title="66:246	If the applications are not considered, all units of an input sentence that can be paraphrased using the PTs will be extracted as source units." ></td>
	<td class="line x" title="67:246	Accordingly, all paraphrases for the source units will be extracted as target units." ></td>
	<td class="line x" title="68:246	However, when a certain application is given, only the source and target units that can achieve the application will be kept." ></td>
	<td class="line x" title="69:246	We call this process paraphrase planning, which is formally defined as in Figure 2." ></td>
	<td class="line x" title="70:246	An example is depicted in Figure 3." ></td>
	<td class="line x" title="71:246	The application in this example is sentence compression." ></td>
	<td class="line x" title="72:246	All source and target units are listed below the input sentence, in which the first two source units are phrases, while the third and fourth are a pattern and a collocation, respectively." ></td>
	<td class="line x" title="73:246	As can be seen, the first and fourth source units are filtered in paraphrase planning, since none of their paraphrases achieve the application (i.e., shorter in bytes than the source)." ></td>
	<td class="line x" title="74:246	The second and third source units are kept, but some of their paraphrases are filtered." ></td>
	<td class="line x" title="75:246	3.4 Paraphrase Generation Our SPG model contains three sub-models: a paraphrase model, a language model, and a usability model, which control the adequacy, fluency, Input: source sentence s Input: paraphrase application A Input: paraphrase tables PTs Output: set of source units SU Output: set of target units TU Extract source units of s from PTs: SU={su1, , sun} For each source unit sui Extract its target units TUi={tui1, ,tuim} For each target unit tuij If tuij cannot achieve the application A Delete tuij from TUi End If End For If TUi is empty Delete sui from SU End If End for Figure 2: The paraphrase planning algorithm." ></td>
	<td class="line x" title="76:246	and usability of the paraphrases, respectively1." ></td>
	<td class="line x" title="77:246	Paraphrase Model: Paraphrase generation is a decoding process." ></td>
	<td class="line x" title="78:246	The input sentence s is first segmented into a sequence of I units sI1, which are then paraphrased to a sequence of units tI1." ></td>
	<td class="line x" title="79:246	Let (si,ti) be a pair of paraphrase units, their paraphrase likelihood is computed using a score function pm(si,ti)." ></td>
	<td class="line x" title="80:246	Thus the paraphrase score ppm(sI1,tI1) between s and t is decomposed into: ppm(sI1,tI1) = Iproductdisplay i=1 pm(si,ti)pm (1) where pm is the weight of the paraphrase model." ></td>
	<td class="line x" title="81:246	Actually, it is defined similarly to the translation model in SMT (Koehn et al., 2003)." ></td>
	<td class="line x" title="82:246	In practice, the units of a sentence may be paraphrased using different PTs." ></td>
	<td class="line x" title="83:246	Suppose we have K PTs, (ski,tki) is a pair of paraphrase units from the k-th PT with the score function k(ski,tki), then Equation (1) can be rewritten as: ppm(sI1,tI1) = Kproductdisplay k=1 ( productdisplay ki k(ski,tki)k) (2) where k is the weight for k(ski,tki)." ></td>
	<td class="line x" title="84:246	Equation (2) assumes that a pair of paraphrase units is from only one paraphrase table." ></td>
	<td class="line x" title="85:246	However, 1The SPG model applies monotone decoding, which does not contain a reordering sub-model that is often used in SMT." ></td>
	<td class="line x" title="86:246	Instead, we use the paraphrase patterns to achieve word reordering in paraphrase generation." ></td>
	<td class="line x" title="87:246	836 The US government should take the overall situation into consideration and actively promote bilateral high-tech trades." ></td>
	<td class="line x" title="88:246	The US government The US administration The US government on overall situation overall interest overall picture overview situation as a whole whole situation take [NN_1] into consideration consider [NN_1] take into account [NN_1] take account of [NN_1] take [NN_1] into account take into consideration [NN_1] <promote, OBJ, trades> <sanction, OBJ, trades> <stimulate, OBJ, trades> <strengthen, OBJ, trades> <support, OBJ, trades> <sustain, OBJ, trades> Paraphrase application: sentence compression Figure 3: An example of paraphrase planning." ></td>
	<td class="line x" title="89:246	we find that about 2% of the paraphrase units appear in two or more PTs." ></td>
	<td class="line x" title="90:246	In this case, we only count the PT that provides the largest paraphrase score, i.e., k = argmaxk{k(si,ti)k}." ></td>
	<td class="line x" title="91:246	In addition, note that there may be some units that cannot be paraphrased or prefer to keep unchanged during paraphrasing." ></td>
	<td class="line x" title="92:246	Therefore, we have a self-paraphrase table in the K PTs, which paraphrases any separate word w into itself with a constant score c: self(w,w) = c (we set c = e1)." ></td>
	<td class="line x" title="93:246	Language Model: We use a tri-gram language model in this work." ></td>
	<td class="line x" title="94:246	The language model based score for the paraphrase t is computed as: plm(t) = Jproductdisplay j=1 p(tj|tj2tj1)lm (3) where J is the length of t, tj is the j-th word of t, and lm is the weight for the language model." ></td>
	<td class="line x" title="95:246	Usability Model: The usability model prefers paraphrase units that can better achieve the application." ></td>
	<td class="line x" title="96:246	The usability of t depends on paraphrase units it contains." ></td>
	<td class="line x" title="97:246	Hence the usability model pum(sI1,tI1) is decomposed into: pum(sI1,tI1) = Iproductdisplay i=1 pum(si,ti)um (4) where um is the weight for the usability model and pum(si,ti) is defined as follows: pum(si,ti) = e(si,ti) (5) We consider three applications, including sentence compression, simplification, and similarity computation." ></td>
	<td class="line x" title="98:246	(si,ti) is defined separately for each:  Sentence compression: Sentence compression2 is important for summarization, subtitle generation, and displaying texts in small screens such as cell phones." ></td>
	<td class="line x" title="99:246	In this application, only the target units shorter than the sources are kept in paraphrase planning." ></td>
	<td class="line x" title="100:246	We define (si,ti) = len(si)  len(ti), where len() denotes the length of a unit in bytes." ></td>
	<td class="line x" title="101:246	 Sentence simplification: Sentence simplification requires using common expressions in sentences so that readers can easily understand the meaning." ></td>
	<td class="line x" title="102:246	Therefore, only the target units more frequent than the sources are kept in paraphrase planning." ></td>
	<td class="line x" title="103:246	Here, the frequency of a unit is measured using the language model mentioned above3." ></td>
	<td class="line x" title="104:246	Specifically, the langauge model assigns a score scorelm() for each unit and the unit with larger score is viewed as more frequent." ></td>
	<td class="line x" title="105:246	We define (si,ti) = 1 iff scorelm(ti) > scorelm(si)." ></td>
	<td class="line x" title="106:246	 Sentence similarity computation: Given a reference sentence sprime, this application aims to paraphrase s into t, so that t is more similar (closer in wording) with sprime than s. This application is important for the automatic evaluation of machine translation and summarization, since we can paraphrase the human translations/summaries to make them more similar to the system outputs, which can refine the accuracy of the evaluation (Kauchak and Barzilay, 2006)." ></td>
	<td class="line x" title="107:246	For this application, 2This work defines compression as the shortening of sentence length in bytes rather than in words." ></td>
	<td class="line x" title="108:246	3To compute the language model based score, the matched patterns are instantiated and the matched collocations are connected with words between them." ></td>
	<td class="line x" title="109:246	837 only the target units that can enhance the similarity to the reference sentence are kept in planning." ></td>
	<td class="line x" title="110:246	We define (si,ti) = sim(ti,sprime) sim(si,sprime), where sim(,) is simply computed as the count of overlapping words." ></td>
	<td class="line x" title="111:246	We combine the three sub-models based on a log-linear framework and get the SPG model: p(t|s) = Ksummationdisplay k=1 (k summationdisplay ki logk(ski,tki)) +lm Jsummationdisplay j=1 logp(tj|tj2tj1) +um Isummationdisplay i=1 (si,ti) (6) 3.5 Paraphrase Resources We use five PTs in this work (except the selfparaphrase table), in which each pair of paraphrase units has a score assigned by the score function of the corresponding method." ></td>
	<td class="line x" title="112:246	Paraphrase phrases (PT-1 to PT-3): Paraphrase phrases are extracted from three corpora: (1) Corp-1: bilingual parallel corpus, (2) Corp2: monolingual comparable corpus (comparable news articles reporting on the same event), and (3) Corp-3: monolingual parallel corpus (parallel translations of the same foreign novel)." ></td>
	<td class="line x" title="113:246	The details of the corpora, methods, and score functions are presented in (Zhao et al., 2008a)." ></td>
	<td class="line x" title="114:246	In our experiments, PT-1 is the largest, which contains 3,041,822 pairs of paraphrase phrases." ></td>
	<td class="line x" title="115:246	PT-2 and PT-3 contain 92,358, and 17,668 pairs of paraphrase phrases, respectively." ></td>
	<td class="line x" title="116:246	Paraphrase patterns (PT-4): Paraphrase patterns are also extracted from Corp-1." ></td>
	<td class="line x" title="117:246	We applied the approach proposed in (Zhao et al., 2008b)." ></td>
	<td class="line x" title="118:246	Its basic assumption is that if two English patterns e1 and e2 are aligned with the same foreign pattern f, then e1 and e2 are possible paraphrases." ></td>
	<td class="line x" title="119:246	One can refer to (Zhao et al., 2008b) for the details." ></td>
	<td class="line x" title="120:246	PT-4 contains 1,018,371 pairs of paraphrase patterns." ></td>
	<td class="line x" title="121:246	Paraphrase collocations (PT-5): Collocations4 can cover long distance dependencies in sentences." ></td>
	<td class="line x" title="122:246	Thus paraphrase collocations are useful for SPG." ></td>
	<td class="line x" title="123:246	We extract collocations from a monolingual 4A collocation is a lexically restricted word pair with a certain syntactic relation." ></td>
	<td class="line x" title="124:246	This work only considers verbobject collocations, e.g., <promote, OBJ, trades>." ></td>
	<td class="line x" title="125:246	corpus and use a binary classifier to recognize if any two collocations are paraphrases." ></td>
	<td class="line x" title="126:246	Due to the space limit, we cannot introduce the detail of the approach." ></td>
	<td class="line x" title="127:246	We assign the score 1 for any pair of paraphrase collocations." ></td>
	<td class="line x" title="128:246	PT-5 contains 238,882 pairs of paraphrase collocations." ></td>
	<td class="line x" title="129:246	3.6 Parameter Estimation To estimate parameters k(1  k  K), lm, and um, we adopt the approach of minimum error rate training (MERT) that is popular in SMT (Och, 2003)." ></td>
	<td class="line x" title="130:246	In SMT, however, the optimization objective function in MERT is the MT evaluation criteria, such as BLEU." ></td>
	<td class="line x" title="131:246	As we analyzed above, the BLEU-style criteria cannot be adapted in SPG." ></td>
	<td class="line x" title="132:246	We therefore introduce a new optimization objective function in this paper." ></td>
	<td class="line x" title="133:246	The basic assumption is that a paraphrase should contain as many correct unit replacements as possible." ></td>
	<td class="line x" title="134:246	Accordingly, we design the following criteria: Replacement precision (rp): rp assesses the precision of the unit replacements, which is defined as rp = cdev(+r)/cdev(r), where cdev(r) is the total number of unit replacements in the generated paraphrases on the development set." ></td>
	<td class="line x" title="135:246	cdev(+r) is the number of the correct replacements." ></td>
	<td class="line x" title="136:246	Replacement rate (rr): rr measures the paraphrase degree on the development set, i.e., the percentage of words that are paraphrased." ></td>
	<td class="line x" title="137:246	We define rr as: rr = wdev(r)/wdev(s), where wdev(r) is the total number of words in the replaced units on the development set, and wdev(s) is the number of words of all sentences on the development set." ></td>
	<td class="line x" title="138:246	Replacement f-measure (rf): We use rf as the optimization objective function in MERT, which is similar to the conventional f-measure and leverages rp and rr: rf = (2rprr)/(rp+rr)." ></td>
	<td class="line x" title="139:246	We estimate parameters for each paraphrase application separately." ></td>
	<td class="line x" title="140:246	For each application, we first ask two raters to manually label all possible unit replacements on the development set as correct or incorrect, so that rp, rr, and rf can be automatically computed under each set of parameters." ></td>
	<td class="line x" title="141:246	The parameters that result in the highest rf on the development set are finally selected." ></td>
	<td class="line x" title="142:246	4 Experimental Setup Our SPG decoder is developed by remodeling Moses that is widely used in SMT (Hoang and Koehn, 2008)." ></td>
	<td class="line x" title="143:246	The POS tagger and dependency parser for sentence preprocessing are SVM838 Tool (Gimenez and Marquez, 2004) and MSTParser (McDonald et al., 2006)." ></td>
	<td class="line x" title="144:246	The language model is trained using a 9 GB English corpus." ></td>
	<td class="line x" title="145:246	4.1 Experimental Data Our method is not restricted in domain or sentence style." ></td>
	<td class="line x" title="146:246	Thus any sentence can be used in development and test." ></td>
	<td class="line x" title="147:246	However, for the sentence similarity computation purpose in our experiments, we want to evaluate if the method can enhance the stringlevel similarity between two paraphrase sentences." ></td>
	<td class="line x" title="148:246	Therefore, for each input sentence s, we need a reference sentence sprime for similarity computation." ></td>
	<td class="line x" title="149:246	Based on the above consideration, we acquire experiment data from the human references of the MT evaluation, which provide several human translations for each foreign sentence." ></td>
	<td class="line x" title="150:246	In detail, we use the first translation of a foreign sentence as the source s and the second translation as the reference sprime for similarity computation." ></td>
	<td class="line x" title="151:246	In our experiments, the development set contains 200 sentences and the test set contains 500 sentences, both of which are randomly selected from the human translations of 2008 NIST Open Machine Translation Evaluation: Chinese to English Task." ></td>
	<td class="line x" title="152:246	4.2 Evaluation Metrics The evaluation metrics for SPG are similar to the human evaluation for MT (Callison-Burch et al., 2007)." ></td>
	<td class="line x" title="153:246	The generated paraphrases are manually evaluated based on three criteria, i.e., adequacy, fluency, and usability, each of which has three scales from 1 to 3." ></td>
	<td class="line x" title="154:246	Here is a brief description of the different scales for the criteria: Adequacy 1: The meaning is evidently changed." ></td>
	<td class="line x" title="155:246	2: The meaning is generally preserved." ></td>
	<td class="line x" title="156:246	3: The meaning is completely preserved." ></td>
	<td class="line x" title="157:246	Fluency 1: The paraphrase t is incomprehensible." ></td>
	<td class="line x" title="158:246	2: t is comprehensible." ></td>
	<td class="line x" title="159:246	3: t is a flawless sentence." ></td>
	<td class="line x" title="160:246	Usability 1: t is opposite to the application purpose." ></td>
	<td class="line x" title="161:246	2: t does not achieve the application." ></td>
	<td class="line x" title="162:246	3: t achieves the application." ></td>
	<td class="line x" title="163:246	5 Results and Analysis We use our method to generate paraphrases for the three applications." ></td>
	<td class="line x" title="164:246	Results show that the percentages of test sentences that can be paraphrased are 97.2%, 95.4%, and 56.8% for the applications of sentence compression, simplification, and similarity computation, respectively." ></td>
	<td class="line x" title="165:246	The reason why the last percentage is much lower than the first two is that, for sentence similarity computation, many sentences cannot find unit replacements from the PTs that improve the similarity to the reference sentences." ></td>
	<td class="line x" title="166:246	For the other applications, only some very short sentences cannot be paraphrased." ></td>
	<td class="line x" title="167:246	Further results show that the average number of unit replacements in each sentence is 5.36, 4.47, and 1.87 for sentence compression, simplification, and similarity computation." ></td>
	<td class="line x" title="168:246	It also indicates that sentence similarity computation is more difficult than the other two applications." ></td>
	<td class="line x" title="169:246	5.1 Evaluation of the Proposed Method We ask two raters to label the paraphrases based on the criteria defined in Section 4.2." ></td>
	<td class="line x" title="170:246	The labeling results are shown in the upper part of Table 1." ></td>
	<td class="line x" title="171:246	We can see that for adequacy and fluency, the paraphrases in sentence similarity computation get the highest scores." ></td>
	<td class="line x" title="172:246	About 70% of the paraphrases are labeled 3." ></td>
	<td class="line x" title="173:246	This is because in sentence similarity computation, only the target units appearing in the reference sentences are kept in paraphrase planning." ></td>
	<td class="line x" title="174:246	This constraint filters most of the noise." ></td>
	<td class="line x" title="175:246	The adequacy and fluency scores of the other two applications are not high." ></td>
	<td class="line x" title="176:246	The percentages of label 3 are around 30%." ></td>
	<td class="line x" title="177:246	The main reason is that the average numbers of unit replacements for these two applications are much larger than sentence similarity computation." ></td>
	<td class="line x" title="178:246	It is thus more likely to bring in incorrect unit replacements, which influence the quality of the generated paraphrases." ></td>
	<td class="line x" title="179:246	The usability is needed to be manually labeled only for sentence simplification, since it can be automatically labeled in the other two applications." ></td>
	<td class="line x" title="180:246	As shown in Table 1, for sentence simplification, most paraphrases are labeled 2 in usability, while merely less than 20% are labeled 3." ></td>
	<td class="line x" title="181:246	We conjecture that it is because the raters are not sensitive to the slight change of the simplification degree." ></td>
	<td class="line x" title="182:246	Thus they labeled 2 in most cases." ></td>
	<td class="line x" title="183:246	We compute the kappa statistic between the raters." ></td>
	<td class="line x" title="184:246	Kappa is defined as K = P(A)P(E)1P(E) (Carletta, 1996), where P(A) is the proportion of times that the labels agree, and P(E) is the proportion of times that they may agree by chance." ></td>
	<td class="line x" title="185:246	We define P(E) = 13 , as the labeling is based on three point scales." ></td>
	<td class="line x" title="186:246	The results show that the kappa statistics for adequacy and fluency are 0.6560 and 0.6500, which indicates a substantial agreement (K: 0.610.8) according to (Landis and Koch, 1977)." ></td>
	<td class="line x" title="187:246	The 839 Adequacy (%) Fluency (%) Usability (%) 1 2 3 1 2 3 1 2 3 Sentence rater1 32.92 44.44 22.63 21.60 47.53 30.86 0 0 100 compression rater2 40.54 34.98 24.49 25.51 43.83 30.66 0 0 100 Sentence rater1 29.77 44.03 26.21 22.01 42.77 35.22 25.37 61.84 12.79 simplification rater2 33.33 35.43 31.24 24.32 39.83 35.85 30.19 51.99 17.82 Sentence rater1 7.75 24.30 67.96 7.75 22.54 69.72 0 0 100 similarity rater2 7.75 19.01 73.24 6.69 21.48 71.83 0 0 100 Baseline-1 rater1 47.31 30.75 21.94 43.01 33.12 23.87 rater2 47.10 30.11 22.80 34.41 41.51 24.09 Baseline-2 rater1 29.45 52.76 17.79 25.15 52.76 22.09 rater2 33.95 46.01 20.04 27.61 48.06 24.34 Table 1: The evaluation results of the proposed method and two baseline methods." ></td>
	<td class="line x" title="188:246	kappa statistic for usability is 0.5849, which is only moderate (K: 0.41-0.6)." ></td>
	<td class="line x" title="189:246	Table 2 shows an example of the generated paraphrases." ></td>
	<td class="line x" title="190:246	A source sentence s is paraphrased in each application and we can see that: (1) for sentence compression, the paraphrase t is 8 bytes shorter than s; (2) for sentence simplification, the words wealth and part in t are easier than their sources asset and proportion, especially for the non-native speakers; (3) for sentence similarity computation, the reference sentence sprime is listed below t, in which the words appearing in t but not in s are highlighted in blue." ></td>
	<td class="line x" title="191:246	5.2 Comparison with Baseline Methods In our experiments, we implement two baseline methods for comparison: Baseline-1: Baseline-1 follows the method proposed in (Quirk et al., 2004), which generates paraphrases using typical SMT tools." ></td>
	<td class="line x" title="192:246	Similar to Quirk et al.s method, we extract a paraphrase table for the SMT model from a monolingual comparable corpus (PT-2 described above)." ></td>
	<td class="line x" title="193:246	The SMT decoder used in Baseline-1 is Moses." ></td>
	<td class="line x" title="194:246	Baseline-2: Baseline-2 extends Baseline-1 by combining multiple resources." ></td>
	<td class="line x" title="195:246	It exploits all PTs introduced above in the same way as our proposed method." ></td>
	<td class="line x" title="196:246	The difference from our method is that Baseline-2 does not take different applications into consideration." ></td>
	<td class="line x" title="197:246	Thus it contains no paraphrase planning stage or the usability sub-model." ></td>
	<td class="line x" title="198:246	We tune the parameters for the two baselines using the development data as described in Section 3.6 and evaluate them with the test data." ></td>
	<td class="line x" title="199:246	Since paraphrase applications are not considered by the baselines, each baseline method outputs a single best paraphrase for each test sentence." ></td>
	<td class="line x" title="200:246	The generation results show that 93% and 97.8% of the test sentences can be paraphrased by Baseline-1 and Baseline-2." ></td>
	<td class="line x" title="201:246	The average number of unit replacements per sentence is 4.23 and 5.95, respectively." ></td>
	<td class="line x" title="202:246	This result suggests that Baseline-1 is less capable than Baseline-2, which is mainly because its paraphrase resource is limited." ></td>
	<td class="line x" title="203:246	The generated paraphrases are also labeled by our two raters and the labeling results can be found in the lower part of Table 1." ></td>
	<td class="line x" title="204:246	As can be seen, Baseline-1 performs poorly compared with our method and Baseline-2, as the percentage of label 1 is the highest for both adequacy and fluency." ></td>
	<td class="line x" title="205:246	This result demonstrates that it is necessary to combine multiple paraphrase resources to improve the paraphrase generation performance." ></td>
	<td class="line x" title="206:246	Table 1 also shows that Baseline-2 performs comparably with our method except that it does not consider paraphrase applications." ></td>
	<td class="line x" title="207:246	However, we are interested how many paraphrases generated by Baseline-2 can achieve the given applications by chance." ></td>
	<td class="line x" title="208:246	After analyzing the results, we find that 24.95%, 8.79%, and 7.16% of the paraphrases achieve sentence compression, simplification, and similarity computation, respectively, which are much lower than our method." ></td>
	<td class="line x" title="209:246	5.3 Informal Comparison with Application Specific Methods Previous research regarded sentence compression, simplification, and similarity computation as totally different problems and proposed distinct method for each one." ></td>
	<td class="line x" title="210:246	Therefore, it is interesting to compare our method to the application-specific methods." ></td>
	<td class="line x" title="211:246	However, it is really difficult for us to 840 Source sentence Liu Lefei says that in the long term, in terms of asset allocation, overseas investment should occupy a certain proportion of an insurance companys overall allocation." ></td>
	<td class="line x" title="212:246	Sentence compression Liu Lefei says that in [the long run]phr, [in area of [asset allocation][NN 1]]pat, overseas investment should occupy [a [certain][JJ 1] part of [an insurance companys overall allocation][NN 1]]pat." ></td>
	<td class="line x" title="213:246	Sentence simplification Liu Lefei says that in [the long run]phr, in terms of [wealth]phr [distribution]phr, overseas investment should occupy [a [certain][JJ 1] part of [an insurance companys overall allocation][NN 1]]pat." ></td>
	<td class="line x" title="214:246	Sentence similarity Liu Lefei says that in [the long run]phr, in terms [of capital]phr allocation, overseas investment should occupy [the [certain][JJ 1] ratio of [an insurance companys overall allocation][NN 1]]pat." ></td>
	<td class="line x" title="215:246	(reference sentence: Liu Lefei said that in terms of capital allocation, outbound investment should make up a certain ratio of overall allocations for insurance companies in the long run .) Table 2: The generated paraphrases of a source sentence for different applications." ></td>
	<td class="line x" title="216:246	The target units after replacement are shown in blue and the pattern slot fillers are in cyan." ></td>
	<td class="line x" title="217:246	[]phr denotes that the unit is a phrase, while []pat denotes that the unit is a pattern." ></td>
	<td class="line x" title="218:246	There is no collocation replacement in this example." ></td>
	<td class="line x" title="219:246	reimplement the methods purposely designed for these applications." ></td>
	<td class="line x" title="220:246	Thus here we just conduct an informal comparison with these methods." ></td>
	<td class="line x" title="221:246	Sentence compression: Sentence compression is widely studied, which is mostly reviewed as a word deletion task." ></td>
	<td class="line x" title="222:246	Different from prior research, Cohn and Lapata (2008) achieved sentence compression using a combination of several operations including word deletion, substitution, insertion, and reordering based on a statistical model, which is similar to our paraphrase generation process." ></td>
	<td class="line x" title="223:246	Besides, they also used paraphrase patterns extracted from bilingual parallel corpora (like our PT-4) as a kind of rewriting resource." ></td>
	<td class="line x" title="224:246	However, as most other sentence compression methods, their method allows information loss after compression, which means that the generated sentences are not necessarily paraphrases of the source sentences." ></td>
	<td class="line x" title="225:246	Sentence Simplification: Carroll et al.(1999) has proposed an automatic text simplification method for language-impaired readers." ></td>
	<td class="line x" title="227:246	Their method contains two main parts, namely the lexical simplifier and syntactic simplifier." ></td>
	<td class="line x" title="228:246	The former one focuses on replacing words with simpler synonyms, while the latter is designed to transfer complex syntactic structures into easy ones (e.g., replacing passive sentences with active forms)." ></td>
	<td class="line x" title="229:246	Our method is, to some extent, simpler than Carroll et al.s, since our method does not contain syntactic simplification strategies." ></td>
	<td class="line x" title="230:246	We will try to address sentence restructuring in our future work." ></td>
	<td class="line x" title="231:246	Sentence Similarity computation: Kauchak and Barzilay (2006) have tried paraphrasing-based sentence similarity computation." ></td>
	<td class="line x" title="232:246	They paraphrase a sentence s by replacing its words with WordNet synonyms, so that s can be more similar in wording to another sentence sprime." ></td>
	<td class="line x" title="233:246	A similar method has also been proposed in (Zhou et al., 2006), which uses paraphrase phrases like our PT-1 instead of WordNet synonyms." ></td>
	<td class="line x" title="234:246	These methods can be roughly viewed as special cases of ours, which only focus on the sentence similarity computation application and only use one kind of paraphrase resource." ></td>
	<td class="line x" title="235:246	6 Conclusions and Future Work This paper proposes a method for statistical paraphrase generation." ></td>
	<td class="line x" title="236:246	The contributions are as follows." ></td>
	<td class="line x" title="237:246	(1) It is the first statistical model specially designed for paraphrase generation, which is based on the analysis of the differences between paraphrase generation and other researches, especially machine translation." ></td>
	<td class="line x" title="238:246	(2) It generates paraphrases for different applications with a uniform model, rather than presenting distinct methods for each application." ></td>
	<td class="line x" title="239:246	(3) It uses multiple resources, including paraphrase phrases, patterns, and collocations, to relieve data shortage and generate more varied and interesting paraphrases." ></td>
	<td class="line x" title="240:246	Our future work will be carried out along two directions." ></td>
	<td class="line x" title="241:246	First, we will improve the components of the method, especially the paraphrase planning algorithm." ></td>
	<td class="line x" title="242:246	The algorithm currently used is simple but greedy, which may miss some useful paraphrase units." ></td>
	<td class="line x" title="243:246	Second, we will extend the method to other applications, We hope it can serve as a universal framework for most if not all applications." ></td>
	<td class="line x" title="244:246	Acknowledgements The research was supported by NSFC (60803093, 60675034) and 863 Program (2008AA01Z144)." ></td>
	<td class="line x" title="245:246	Special thanks to Wanxiang Che, Ruifang He, Yanyan Zhao, Yuhang Guo and the anonymous reviewers for insightful comments and suggestions." ></td>
	<td class="line x" title="246:246	841" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-2063
Introduction of a new paraphrase generation tool based on Monte-Carlo sampling
Chevelu, Jonathan;Lavergne, Thomas;Lepage, Yves;Moudenc, Thierry;"></td>
	<td class="line x" title="1:121	Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 249252, Suntec, Singapore, 4 August 2009." ></td>
	<td class="line x" title="2:121	c 2009 ACL and AFNLP Introduction of a new paraphrase generation tool based on Monte-Carlo sampling Jonathan Chevelu1,2 Thomas Lavergne Yves Lepage1 Thierry Moudenc2 (1) GREYC, universit de Caen Basse-Normandie (2) Orange Labs; 2, avenue Pierre Marzin, 22307 Lannion {jonathan.chevelu,thierry.moudenc}@orange-ftgroup.com, thomas.lavergne@reveurs.org, yves.lepage@info.unicaen.fr Abstract We propose a new specifically designed method for paraphrase generation based on Monte-Carlo sampling and show how this algorithm is suitable for its task." ></td>
	<td class="line x" title="3:121	Moreover, the basic algorithm presented here leaves a lot of opportunities for future improvement." ></td>
	<td class="line x" title="4:121	In particular, our algorithm does not constraint the scoring function in opposite to Viterbi based decoders." ></td>
	<td class="line x" title="5:121	It is now possible to use some global features in paraphrase scoring functions." ></td>
	<td class="line x" title="6:121	This algorithm opens new outlooks for paraphrase generation and other natural language processing applications like statistical machine translation." ></td>
	<td class="line x" title="7:121	1 Introduction A paraphrase generation system is a program which, given a source sentence, produces a different sentence with almost the same meaning." ></td>
	<td class="line x" title="8:121	Paraphrase generation is useful in applications to choose between different forms to keep the most appropriate one." ></td>
	<td class="line oc" title="9:121	For instance, automatic summary can be seen as a particular paraphrasing task (Barzilay and Lee, 2003) with the aim of selecting the shortest paraphrase." ></td>
	<td class="line x" title="10:121	Paraphrases can also be used to improve natural language processing (NLP) systems." ></td>
	<td class="line x" title="11:121	(CallisonBurch et al., 2006) improved machine translations by augmenting the coverage of patterns that can be translated." ></td>
	<td class="line x" title="12:121	Similarly, (Sekine, 2005) improved information retrieval based on pattern recognition by introducing paraphrase generation." ></td>
	<td class="line x" title="13:121	In order to produce paraphrases, a promising approach is to see the paraphrase generation problem as a translation problem, where the target language is the same as the source language (Quirk et al., 2004; Bannard and Callison-Burch, 2005)." ></td>
	<td class="line x" title="14:121	A problem that has drawn less attention is the generation step which corresponds to the decoding step in SMT." ></td>
	<td class="line x" title="15:121	Most paraphrase generation tools use some standard SMT decoding algorithms (Quirk et al., 2004) or some off-the-shelf decoding tools like MOSES (Koehn et al., 2007)." ></td>
	<td class="line x" title="16:121	The goal of a decoder is to find the best path in the lattice produced from a paraphrase table." ></td>
	<td class="line x" title="17:121	This is basically achieved by using dynamic programming and especially the Viterbi algorithm associated with beam searching." ></td>
	<td class="line x" title="18:121	However decoding algorithms were designed for translation, not for paraphrase generation." ></td>
	<td class="line x" title="19:121	Although left-to-right decoding is justified for translation, it may not be necessary for paraphrase generation." ></td>
	<td class="line x" title="20:121	A paraphrase generation tool usually starts with a sentence which may be very similar to some potential solution." ></td>
	<td class="line x" title="21:121	In other words, there is no need to 'translate' all of the sentences." ></td>
	<td class="line x" title="22:121	Moreover, decoding may not be suitable for non-contiguous transformation rules." ></td>
	<td class="line x" title="23:121	In addition, dynamic programming imposes an incremental scoring function to evaluate the quality of each hypothesis." ></td>
	<td class="line x" title="24:121	For instance, it cannot capture some scattered syntactical dependencies." ></td>
	<td class="line x" title="25:121	Improving on this major issue is a key point to improve paraphrase generation systems." ></td>
	<td class="line x" title="26:121	This paper first presents an alternative to decoding that is based on transformation rule application in section 2." ></td>
	<td class="line x" title="27:121	In section 3 we propose a paraphrase generation method for this paradigm based on an algorithm used in two-player games." ></td>
	<td class="line x" title="28:121	Section 4 briefly explain experimental context and its associated protocol for evaluation of the proposed system." ></td>
	<td class="line x" title="29:121	We compare the proposed algorithm with a baseline system in section 5." ></td>
	<td class="line x" title="30:121	Finally, in section 6, we point to future research tracks to improve paraphrase generation tools." ></td>
	<td class="line x" title="31:121	2 Statistical paraphrase generation using transformation rules The paraphrase generation problem can be seen as an exploration problem." ></td>
	<td class="line x" title="32:121	We seek the best paraphrase according to a scoring function in a space 249 to search by applying successive transformations." ></td>
	<td class="line x" title="33:121	This space is composed of states connected by actions." ></td>
	<td class="line x" title="34:121	An action is a transformation rule with a place where it applies in the sentence." ></td>
	<td class="line x" title="35:121	States are a sentence with a set of possible actions." ></td>
	<td class="line x" title="36:121	Applying an action in a given state consists in transforming the sentence of the state and removing all rules that are no more applicable." ></td>
	<td class="line x" title="37:121	In our framework, each state, except the root, can be a final state." ></td>
	<td class="line x" title="38:121	This is modelised by adding a stop rule as a particular action." ></td>
	<td class="line x" title="39:121	We impose the constraint that any transformed part of the source sentence cannot be transformed anymore." ></td>
	<td class="line x" title="40:121	This paradigm is more approriate for paraphrase generation than the standard SMT approach in respect to several points: there is no need for leftto-right decoding because a transformation can be applied anywhere without order; there is no need to transform the whole of a sentence because each state is a final state; there is no need to keep the identity transformation for each phrase in the paraphrase table; the only domain knowledge needed is a generative model and a scoring function for final states; it is possible to mix different generative models because a statistical paraphrase table, an analogical solver and a paraphrase memory for instance; there is no constraint on the scoring function because it only scores final states." ></td>
	<td class="line x" title="41:121	Note that the branching factor with a paraphrase table can be around thousand actions per states which makes the generation problem a difficult computational problem." ></td>
	<td class="line x" title="42:121	Hence we need an efficient generation algorithm." ></td>
	<td class="line x" title="43:121	3 Monte-Carlo based Paraphrase Generation UCT (Kocsis and Szepesvri, 2006) (Upper Confidence bound applied to Tree) is a Monte-Carlo planning algorithm that have some interesting properties: it grows the search tree non-uniformly and favours the most promising sequences, without pruning branch; it can deal with high branching factor; it is an any-time algorithm and returns best solution found so far when interrupted; it does not require expert domain knowledge to evaluate states." ></td>
	<td class="line x" title="44:121	These properties make it ideally suited for games with high branching factor and for which there is no strong evaluation function." ></td>
	<td class="line x" title="45:121	For the same reasons, this algorithm sounds interesting for paraphrase generation." ></td>
	<td class="line x" title="46:121	In particular, it does not put constraint on the scoring function." ></td>
	<td class="line x" title="47:121	We propose a variation of the UCT algorithm for paraphrase generation named MCPG for MonteCarlo based Paraphrase Generation." ></td>
	<td class="line x" title="48:121	The main part of the algorithm is the sampling step." ></td>
	<td class="line x" title="49:121	An episode of this step is a sequence of states and actions, s1,a1,s2,a2,,sT, from the root state to a final state." ></td>
	<td class="line x" title="50:121	During an episode construction, there are two ways to select the action ai to perfom from a state si." ></td>
	<td class="line x" title="51:121	If the current state was already explored in a previous episode, the action is selected according to a compromise between exploration and exploitation." ></td>
	<td class="line x" title="52:121	This compromise is computed using the UCB-Tunned formula (Auer et al., 2001) associated with the RAVE heuristic (Gelly and Silver, 2007)." ></td>
	<td class="line x" title="53:121	If the current state is explored for the first time, its score is estimated using MonteCarlo sampling." ></td>
	<td class="line x" title="54:121	In other word, to complete the episode, the actions ai,ai+1,,aT1,aT are selected randomly until a stop rule is drawn." ></td>
	<td class="line x" title="55:121	At the end of each episode, a reward is computed for the final state sT using a scoring function and the value of each (state, action) pair of the episode is updated." ></td>
	<td class="line x" title="56:121	Then, the algorithm computes an other episode with the new values." ></td>
	<td class="line x" title="57:121	Periodically, the sampling step is stopped and the best action at the root state is selected." ></td>
	<td class="line x" title="58:121	This action is then definitely applied and a sampling is restarted from the new root state." ></td>
	<td class="line x" title="59:121	The action sequence is built incrementally and selected after being enough sampled." ></td>
	<td class="line x" title="60:121	For our experiments, we have chosen to stop sampling regularly after a fixed amount  of episodes." ></td>
	<td class="line x" title="61:121	Our main adaptation of the original algorithm is in the (state, action) value updating procedure." ></td>
	<td class="line x" title="62:121	Since the goal of the algorithm is to maximise a scoring function, we use the maximum reachable score from a state as value instead of the score expectation." ></td>
	<td class="line x" title="63:121	This algorithm suits the paradigm proposed for paraphrase generation." ></td>
	<td class="line x" title="64:121	4 Experimental context This section describes the experimental context and the methodology followed to evaluate our statistical paraphrase generation tool." ></td>
	<td class="line x" title="65:121	4.1 Data For the experiment reported in section 5, we use one of the largest, multi-lingual, freely available aligned corpus, Europarl (Koehn, 2005)." ></td>
	<td class="line x" title="66:121	It consists of European parliament debates." ></td>
	<td class="line x" title="67:121	We choose 250 French as the language for paraphrases and English as the pivot language." ></td>
	<td class="line x" title="68:121	For this pair of languages, the corpus consists of 1,487,459 French sentences aligned with 1,461,429 English sentences." ></td>
	<td class="line x" title="69:121	Note that the sentences in this corpus are long, with an average length of 30 words per French sentence and 27.1 for English." ></td>
	<td class="line x" title="70:121	We randomly extracted 100 French sentences as a test corpus." ></td>
	<td class="line x" title="71:121	4.2 Language model and paraphrase table Paraphrase generation tools based on SMT methods need a language model and a paraphrase table." ></td>
	<td class="line x" title="72:121	Both are computed on a training corpus." ></td>
	<td class="line x" title="73:121	The language models we use are n-gram language models with back-off." ></td>
	<td class="line x" title="74:121	We use SRILM (Stolcke, 2002) with its default parameters for this purpose." ></td>
	<td class="line x" title="75:121	The length of the n-grams is five." ></td>
	<td class="line x" title="76:121	To build a paraphrase table, we use the construction method via a pivot language proposed in (Bannard and Callison-Burch, 2005)." ></td>
	<td class="line x" title="77:121	Three heuristics are used to prune the paraphrase table." ></td>
	<td class="line x" title="78:121	The first heuristic prunes any entry in the paraphrase table composed of tokens with a probability lower than a threshold epsilon1." ></td>
	<td class="line x" title="79:121	The second, called pruning pivot heuristic, consists in deleting all pivot clusters larger than a threshold ." ></td>
	<td class="line x" title="80:121	The last heuristic keeps only the  most probable paraphrases for each source phrase in the final paraphrase table." ></td>
	<td class="line x" title="81:121	For this study, we empirically fix epsilon1 = 105,  = 200 and  = 10." ></td>
	<td class="line x" title="82:121	4.3 Evaluation Protocol We developed a dedicated website to allow the human judges with some flexibility in workplaces and evaluation periods." ></td>
	<td class="line x" title="83:121	We retain the principle of the two-step evaluation, common in the machine translation domain and already used for paraphrase evaluation (Bannard and Callison-Burch, 2005)." ></td>
	<td class="line x" title="84:121	The question asked to the human evaluator for the syntactic task is: Is the following sentence in good French?" ></td>
	<td class="line x" title="85:121	The question asked to the human evaluator for the semantic task is: Do the following two sentences express the same thing?" ></td>
	<td class="line x" title="86:121	In our experiments, each paraphrase was evaluated by two native French evaluators." ></td>
	<td class="line x" title="87:121	5 Comparison with a SMT decoder In order to validate our algorithm for paraphrase generation, we compare it with an off-the-shelf SMT decoder." ></td>
	<td class="line x" title="88:121	We use the MOSES decoder (Koehn et al., 2007) as a baseline." ></td>
	<td class="line x" title="89:121	The MOSES scoring function is set by four weighting factors ,LM,D,W. Conventionally, these four weights are adjusted during a tuning step on a training corpus." ></td>
	<td class="line x" title="90:121	The tuning step is inappropriate for paraphrase because there is no such tuning corpus available." ></td>
	<td class="line x" title="91:121	We empirically set  = 1, LM = 1, D = 10 and W = 0." ></td>
	<td class="line x" title="92:121	Hence, the scoring function (or reward function for MCPG) is equivalent to: R(fprime|f,I) = p(fprime)(f|fprime,I) where f and fprime are the source and target sentences, I a segmentation in phrases of f, p(fprime) the language model score and (f|fprime,I) =producttext iI p(f i|fprimei) the paraphrase table score." ></td>
	<td class="line x" title="93:121	The MCPG algorithm needs two parameters." ></td>
	<td class="line x" title="94:121	One is the number of episodes  done before selecting the best action at root state." ></td>
	<td class="line x" title="95:121	The other is k, an equivalence parameter which balances the exploration/exploitation compromise (Auer et al., 2001)." ></td>
	<td class="line x" title="96:121	We empirically set  = 1,000,000 and k = 1,000." ></td>
	<td class="line x" title="97:121	For our algorithm, note that identity paraphrase probabilities are biased: for each phrase it is equal to the probability of the most probable paraphrase." ></td>
	<td class="line x" title="98:121	Moreover, as the source sentence is the best meaning preserved 'paraphrase', a sentence cannot have a better score." ></td>
	<td class="line x" title="99:121	Hence, we use a slightly different scoring function: R(fprime|f,I) = min    p(fprime) p(f) productdisplay iI finegationslash=fprimei p(fi|fprimei) p(fi|fi),1    Note that for this model, there is no need to know the identity transformations probability for unchanged part of the sentence." ></td>
	<td class="line x" title="100:121	Results are presented in Table 1." ></td>
	<td class="line x" title="101:121	The Kappa statistics associated with the results are 0.84, 0.64 and 0.59 which are usually considered as a 'perfect', 'substantial' and 'moderate' agreement." ></td>
	<td class="line x" title="102:121	Results are close to evaluations from the baseline system." ></td>
	<td class="line x" title="103:121	The main differences are from Kappa statistics which are lower for the MOSES system evaluation." ></td>
	<td class="line x" title="104:121	Judges changed between the two experiments." ></td>
	<td class="line x" title="105:121	We may wonder whether an evaluation with only two judges is reliable." ></td>
	<td class="line x" title="106:121	This points to the ambiguity of any paraphrase definition." ></td>
	<td class="line x" title="107:121	251 System MOSES MCPG Well formed (Kappa) 64%(0.57) 63%(0.84) Meaning preserved (Kappa) 58%(0.48) 55%(0.64) Well formed and meaning preserved (Kappa) 50%(0.54) 49%(0.59) Table 1: Results of paraphrases evaluation for 100 sentences in French using English as the pivot language." ></td>
	<td class="line x" title="108:121	Comparison between the baseline system MOSES and our algorithm MCPG." ></td>
	<td class="line x" title="109:121	By doing this experiment, we have shown that our algorithm with a biased paraphrase table is state-of-the-art to generate paraphrases." ></td>
	<td class="line x" title="110:121	6 Conclusions and further research In this paper, we have proposed a different paradigm and a new algorithm in NLP field adapted for statistical paraphrases generation." ></td>
	<td class="line x" title="111:121	This method, based on large graph exploration by Monte-Carlo sampling, produces results comparable with state-of-the-art paraphrase generation tools based on SMT decoders." ></td>
	<td class="line x" title="112:121	The algorithm structure is flexible and generic enough to easily work with discontinous patterns." ></td>
	<td class="line x" title="113:121	It is also possible to mix various transformation methods to increase paraphrase variability." ></td>
	<td class="line x" title="114:121	The rate of ill-formed paraphrase is high at 37%." ></td>
	<td class="line x" title="115:121	The result analysis suggests an involvement of the non-preservation of the original meaning when a paraphrase is evaluated ill-formed." ></td>
	<td class="line x" title="116:121	Although the mesure is not statistically significant because the test corpus is too small, the same trend is also observed in other experiments." ></td>
	<td class="line x" title="117:121	Improving on the language model issue is a key point to improve paraphrase generation systems." ></td>
	<td class="line x" title="118:121	Our algorithm can work with unconstraint scoring functions, in particular, there is no need for the scoring function to be incremental as for Viterbi based decoders." ></td>
	<td class="line x" title="119:121	We are working to add, in the scoring function, a linguistic knowledge based analyzer to solve this problem." ></td>
	<td class="line x" title="120:121	Because MCPG is based on a different paradigm, its output scores cannot be directly compared to MOSES scores." ></td>
	<td class="line x" title="121:121	In order to prove the optimisation qualities of MCPG versus state-of-the-art decoders, we are transforming our paraphrase generation tool into a translation tool." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-3004
Paraphrase Recognition Using Machine Learning to Combine Similarity Measures
Malakasiotis, Prodromos;"></td>
	<td class="line x" title="1:164	Proceedings of the ACL-IJCNLP 2009 Student Research Workshop, pages 2735, Suntec, Singapore, 4 August 2009." ></td>
	<td class="line x" title="2:164	c 2009 ACL and AFNLP Paraphrase Recognition Using Machine Learning to Combine Similarity Measures Prodromos Malakasiotis Department of Informatics Athens University of Economics and Business Patission 76, GR-104 34 Athens, Greece Abstract This paper presents three methods that can be used to recognize paraphrases." ></td>
	<td class="line x" title="3:164	They all employ string similarity measures applied to shallow abstractions of the input sentences, and a Maximum Entropy classifier to learn how to combine the resulting features." ></td>
	<td class="line x" title="4:164	Two of the methods also exploit WordNet to detect synonyms and one of them also exploits a dependency parser." ></td>
	<td class="line x" title="5:164	We experiment on two datasets, the MSR paraphrasing corpus and a dataset that we automatically created from the MTC corpus." ></td>
	<td class="line x" title="6:164	Our system achieves state of the art or better results." ></td>
	<td class="line x" title="7:164	1 Introduction Recognizing or generating semantically equivalent phrases is of significant importance in many natural language applications." ></td>
	<td class="line x" title="8:164	In question answering, for example, a question may be phrased differently than in a document collection (e.g., Who is the author of War and Peace? vs. Leo Tolstoy is the writer of War and Peace.), and taking such variations into account can improve system performance significantly (Harabagiu et al., 2003; Harabagiu and Hickl, 2006)." ></td>
	<td class="line x" title="9:164	A paraphrase generator, meaning a module that produces new phrases or patterns that are semantically equivalent (or almost equivalant) to a given input phrase or pattern (e.g., X is the writer of Y X wrote Y  Y was written by XX is the author of Y , or X produces Y   X manufactures Y   X is the manufacturer of Y ) can be used to produce alternative phrasings of the question, before matching it against a document collection." ></td>
	<td class="line x" title="10:164	Unlike paraphrase generators, paraphrase recognizers decide whether or not two given phrases (or patterns) are paraphrases, possibly by generalizing over many different training pairs of phrases." ></td>
	<td class="line x" title="11:164	Paraphrase recognizers can be embedded in paraphrase generators to filter out erroneous generated paraphrases; but they are also useful on their own." ></td>
	<td class="line x" title="12:164	In question answering, for example, they can be used to check if a pattern extracted from the question (possibly by replacing named entities by their semantic categories and turning the question into a statement) matches any patterns extracted from candidate answers." ></td>
	<td class="line x" title="13:164	As a further example, in text summarization, especially multi-document summarization, a paraphrase recognizer can be used to check if a sentence is a paraphrase of any other sentence already present in a partially constructed summary." ></td>
	<td class="line x" title="14:164	Note that, although paraphrasing and textual entailment are sometimes used as synonyms, we use the former to refer to methods that generate or recognize semantically equivalent (or almost equivalent) phrases or patterns, whereas in textual entailment (Dagan et al., 2006; Bar-Haim et al., 2006; Giampiccolo et al., 2007) the expressions or patterns are not necessarily semantically equivalent; it suffices if one entails the other, even if the reverse direction does not hold." ></td>
	<td class="line x" title="15:164	For example, Y was written by X textually entails Y is the work of X, but the reverse direction does not necessarily hold (e.g., if Y is a statue); hence, the two sentences are not paraphrases." ></td>
	<td class="line x" title="16:164	In this paper, we focus on paraphrase recognition." ></td>
	<td class="line x" title="17:164	We propose three methods that employ string similarity measures, which are applied to several abstractions of a pair of input phrases (e.g., the phrases themselves, their stems, POS tags)." ></td>
	<td class="line x" title="18:164	The scores returned by the similarity measures are used as features in a Maximum Entropy (ME) classifier (Jaynes, 1957; Good, 1963), which learns to separate true paraphrase pairs from false ones." ></td>
	<td class="line x" title="19:164	Two of our methods also exploit WordNet to detect synonyms, and one of them uses additional features to measure similarities of grammatical relations 27 obtained by a dependency parser.1 Our experiments were conducted on two datasets: the publicly available Microsoft Research Paraphrasing corpus (Dolan et al., 2004) and a dataset that we constructed from the MTC corpus.2 The experimental results show that our methods perform very well." ></td>
	<td class="line x" title="20:164	Even the simplest one manages to achieve state of the art results, even though it uses fewer linguistic resources than other reported systems." ></td>
	<td class="line x" title="21:164	The other two, more elaborate methods perform even better." ></td>
	<td class="line x" title="22:164	Section 2 presents the three methods, and section 3 our experiments." ></td>
	<td class="line x" title="23:164	Section 4 covers related work." ></td>
	<td class="line x" title="24:164	Section 5 concludes and proposes further work." ></td>
	<td class="line x" title="25:164	2 The three methods The main idea underlying our methods is that by capturing similarities at various shallow abstractions of the input (e.g., the original sentences, the stems of their words, their POS tags), we can recognize paraphrases and textual entailment reasonably well, provided that we learn to assign appropriate weights to the resulting features." ></td>
	<td class="line x" title="26:164	Further improvements are possible by recognizing synonyms and by employing similarity measures that operate on the output of dependency grammar parsers." ></td>
	<td class="line x" title="27:164	2.1 Method 1 (INIT) During training, the first method, called INIT, is given a set{S1,1,S1,2,y1,,Sn,1,Sn,2,yn}, where Si,1 and Si,2 are sentences (more generally, phrases), yi = 1 (positive class) if the two sentences are paraphrases, and yi = 1 (negative class) otherwise." ></td>
	<td class="line x" title="28:164	Each pair of sentences Si,1,Si,2 is converted to a feature vector vectorvi, whose values are scores returned by similarity measures that indicate how similar Si,1 and Si,2 are at various levels of abstraction." ></td>
	<td class="line x" title="29:164	The vectors and the corresponding categories {vectorv1,yi,,vectorvn,yn} are given as input to the ME classifier, which learns how to classify new vectors vectorv, corresponding to unseen pairs of sentencesS1,S2." ></td>
	<td class="line x" title="30:164	We use nine string similarity measures: Levenshtein distance (edit distance), Jaro-Winkler distance, Manhattan distance, Euclidean distance, co1We use Stanford Universitys ME classifier and parser; see http://nlp.stanford.edu/." ></td>
	<td class="line x" title="31:164	2The corpus is available by the LDC, Catalogue Number LDC2002T01, ISBN 1-58563-217-1." ></td>
	<td class="line x" title="32:164	sine similarity, n-gram distance (with n = 3), matching coefficient, Dice coefficient, and Jaccard coefficient." ></td>
	<td class="line x" title="33:164	To save space, we do not repeat the definitions of the similarity measures here, since they are readily available in the literature and they are also summarized in our previous work (Malakasiotis and Androutsopoulos, 2007)." ></td>
	<td class="line x" title="34:164	For each pair of input stringsS1,S2, we form ten new pairs of strings angbracketleftbigs11,s12angbracketrightbig,,angbracketleftbigs101 ,s102 angbracketrightbig corresponding to ten different levels of abstraction of S1 and S2, and we apply the nine similarity measures to the ten new pairs, resulting in a total of 90 measurements." ></td>
	<td class="line x" title="35:164	These measurements are then included as features in the vector vectorv that corresponds toS1,S2." ></td>
	<td class="line x" title="36:164	The angbracketleftbigsi1,si2angbracketrightbig pairs are: angbracketleftbigs1 1,s 1 2 angbracketrightbig: two strings consisting of the original tokens of S 1 and S2, respectively, with the original order of the tokens maintained;3 angbracketleftbigs2 1,s 2 2 angbracketrightbig: as in the previous case, but now the tokens are replaced by their stems; angbracketleftbigs3 1,s 3 2 angbracketrightbig: as in the previous case, but now the tokens are replaced by their part-of-speech (POS) tags; angbracketleftbigs4 1,s 4 2 angbracketrightbig: as in the previous case, but now the tokens are replaced by their soundex codes;4 angbracketleftbigs5 1,s 5 2 angbracketrightbig: two strings consisting of only the nouns of S 1 and S2, as identified by a POS-tagger, with the original order of the nouns maintained; angbracketleftbigs6 1,s 6 2 angbracketrightbig: as in the previous case, but now with nouns replaced by their stems; angbracketleftbigs7 1,s 7 2 angbracketrightbig: as in the previous case, but now with nouns replaced by their soundex codes; angbracketleftbigs8 1,s 8 2 angbracketrightbig: two strings consisting of only the verbs of S 1 and S2, as identified by a POS-tagger, with the original order of the verbs maintained; angbracketleftbigs9 1,s 9 2 angbracketrightbig: as in the previous case, but now with verbs replaced by their stems; angbracketleftbigs10 1 ,s 10 2 angbracketrightbig: as in the previous case, but now with verbs replaced by their soundex codes." ></td>
	<td class="line x" title="37:164	Note that the similarities are measured in terms of tokens, not characters." ></td>
	<td class="line x" title="38:164	For instance, the edit distance of S1 and S2 is the minimum number of operations needed to transform S1 to S2, where an operation is an insertion, deletion or substitution of a single token." ></td>
	<td class="line x" title="39:164	Moreover, we use high-level 3We use Stanford Universitys tokenizer and POS-tagger, and Porters stemmer." ></td>
	<td class="line x" title="40:164	4Soundex is an algorithm intended to map English names to alphanumeric codes, so that names with the same pronunciations receive the same codes, despite spelling differences; see http://en.wikipedia.org/wiki/Soundex." ></td>
	<td class="line x" title="41:164	28 POS tags only, i.e., we do not consider the number of nouns, the voice of verbs etc.; this increases the similarity of positive angbracketleftbigs31,s32angbracketrightbig pairs." ></td>
	<td class="line x" title="42:164	A common problem is that the string similarity measures may be misled by differences in the lengths of S1 and S2." ></td>
	<td class="line x" title="43:164	This is illustrated in the following examples, where the underlined part of S1 is much more similar to S2 than the entire S1." ></td>
	<td class="line x" title="44:164	S1: While Bolton apparently fell and was immobilized, Selenski used the mattress to scale a 10-foot, razor-wire fence, Fischi said." ></td>
	<td class="line x" title="45:164	S2: After the other inmate fell, Selenski used the mattress to scale a 10-foot, razor-wire fence, Fischi said." ></td>
	<td class="line x" title="46:164	To address this problem, when we consider a pair of stringss1,s2, if s1 is longer than s2, we obtain all of the substrings sprime1 of s1 that have the same length as s2." ></td>
	<td class="line x" title="47:164	Then, for each sprime1, we compute the nine values fj(sprime1,s2), where fj (1  j  9) are the string similarity measures." ></td>
	<td class="line x" title="48:164	Finally, we locate the sprime1 with the best average similarity (over all similarity measures) to s2, namely sprime1 : sprime1 = argmax sprime1 10summationdisplay j=1 fj(sprime1,s2) and we keep the nine fj(sprime1 ,s2) values and their average as ten additional measurements." ></td>
	<td class="line x" title="49:164	Similarly, if s2 is longer than s1, we keep the nine fj(s1,sprime2 ) values and their average." ></td>
	<td class="line x" title="50:164	This process is applied to pairs angbracketleftbigs11,s12angbracketrightbig, . . ., angbracketleftbigs41,s42angbracketrightbig, where large length differences are more likely to appear, adding 40 more measurements (features) to the vector vectorv of eachS1,S2pair of input strings." ></td>
	<td class="line x" title="52:164	The measurements discussed above provide 130 numeric features.5 To those, we add two Boolean features indicating the existence or absence of negation in S1 or S2, respectively; negation is detected by looking for words like not, wont etc. Finally, we add a length ratio feature, defined as min(LS1,LS2)max(LS 1,LS2) , where LS1 and LS2 are the lengths, in tokens, of S1 and S2." ></td>
	<td class="line x" title="53:164	Hence, there is a total of 133 available features in INIT." ></td>
	<td class="line x" title="54:164	2.2 Method 2 (INIT+WN) Paraphrasing may involve using synonyms which cannot be detected by the features we have considered so far." ></td>
	<td class="line x" title="55:164	In the following pair of sentences, for example, dispatched is used as a synonym 5All feature values are normalized in [1,1]." ></td>
	<td class="line x" title="56:164	We use our own implementation of the string similarity measures." ></td>
	<td class="line x" title="57:164	of sent; treating the two verbs as the same token during the calculation of the string similarity measures would yield a higher similarity." ></td>
	<td class="line x" title="58:164	The second method, called INIT+WN, treats words from S1 and S2 that are synonyms as identical; otherwise the method is the same as INIT." ></td>
	<td class="line x" title="59:164	S1: Fewer than a dozen FBI agents were dispatched to secure and analyze evidence." ></td>
	<td class="line x" title="60:164	S2: Fewer than a dozen FBI agents will be sent to Iraq to secure and analyze evidence of the bombing." ></td>
	<td class="line x" title="61:164	2.3 Method 3 (INIT+WN+DEP) The features of the previous two methods operate at the lexical level." ></td>
	<td class="line x" title="62:164	The third method, called INIT+WN+DEP, adds features that operate on the grammatical relations (dependencies) a dependency grammar parser returns for S1 and S2." ></td>
	<td class="line x" title="63:164	We use three measures to calculate similarity at the level of grammatical relations, namely S1 dependency recall (R1), S2 dependency recall (R2) and their F-measure (FR1,R2), defined below: R1 = |common dependencies||S1 dependencies| R2 = |common dependencies||S2 dependencies| FR1,R2 = 2R1R2R1+R2 The following two examples illustrate the usefulness of dependency similarity measures in detecting paraphrases." ></td>
	<td class="line x" title="64:164	In the first example S1 and S2 are not paraphrases and the scores are low, while in the second example where S1 and S2 have almost identical meanings, the scores are much higher." ></td>
	<td class="line x" title="65:164	Figures 1 and 2 lists the grammatical relations (dependencies) of the two sentences with the common ones shown in bold." ></td>
	<td class="line x" title="66:164	Example 1: S1: Gyorgy Heizler, head of the local disaster unit, said the coach was carrying 38 passengers." ></td>
	<td class="line x" title="67:164	S2: The head of the local disaster unit, Gyorgy Heizler, said the coach driver had failed to heed red stop lights." ></td>
	<td class="line x" title="68:164	R1 = 0.43, R2 = 0.32, FR1,R2 = 0.36 Example 2: S1: Amrozi accused his brother, whom he called the witness, of deliberately distorting his evidence." ></td>
	<td class="line x" title="69:164	S2: Referring to him as only the witness, Amrozi accused his brother of deliberately distorting his evidence." ></td>
	<td class="line x" title="70:164	R1 = 0.69, R2 = 0.6, FR1,R2 = 0.64 29 Grammatical relations of S 1  Grammatical relations of S 2  mod(Heizler-2, Gyorgy-1) mod(head-2, The-1) arg(said-11, Heizler-2) arg(said-12, head-2) mod(head-2, of-3) mod(Heizler-2, head-4) mod(head-4, of-5) mod(unit-7, the-4) mod(unit-9, the-6) mod(unit-7, local-5) mod(unit-9, local-7) mod(unit-7, disaster-6) mod(unit-9, disaster-8) arg(of-3, unit-7) arg(of-5, unit-9) mod(Heizler-10, Gyorgy-9) mod(coach-13, the-12) mod(unit-7, Heizler-10) arg(carrying-15, coach-13) mod(driver-15, the-13) aux(carrying-15, was-14) mod(driver-15, coach-14) arg(said-11, carrying-15) arg(failed-17, driver-15) mod(passengers-17, 38-16) aux(failed-17, had-16) arg(said-12, failed-17) arg(carrying-15, passengers-17) aux(heed-19, to-18) arg(failed-17, heed-19) mod(lights-22, red-20) mod(lights-22, stop-21) arg(heed-19, lights-22)  Figure 1: Grammatical relations of example 1." ></td>
	<td class="line x" title="71:164	Grammatical relations of S 1  Grammatical relations of S 2  arg(accused-2, Amrozi-1) dep(accused-12, Referring-1) mod(brother-4, his-3) mod(Referring-1, to-2) arg(accused-2, brother-4) arg(to-2, him-3) arg(called-8, whom-6) cc(him-3, as-4) arg(called-8, he-7) dep(as-4, only-5) mod(witness-8, the-7) mod(brother-4, called-8) mod(witness-11, the-10) conj(him-3, witness-8) arg(accused-12, Amrozi-11) dep(called-8, witness-11) mod(brother-4, of-14) mod(brother-14, his-13) mod(distorting-16, deliberately-15) arg(accused-12, brother-14) arg(of-14, distorting-16) mod(brother-14, of-15) mod(evidence-18, his-17) mod(distorting-17, deliberately-16) arg(distorting-16, evidence-18) arg(of-15, distorting-17) mod(evidence-19, his-18) arg(distorting-17, evidence-19)  Figure 2: Grammatical relations of example 2." ></td>
	<td class="line x" title="72:164	30 As with POS-tags, we use only the highest level of the tags of the grammatical relations, which increases the similarity of positive pairs of S1 and S2." ></td>
	<td class="line x" title="73:164	For the same reason, we ignore the directionality of the dependency arcs which we have found to improve the results." ></td>
	<td class="line x" title="74:164	INIT+WN+DEP employs a total of 136 features." ></td>
	<td class="line x" title="75:164	2.4 Feature selection Larger feature sets do not necessarily lead to improved classification performance." ></td>
	<td class="line x" title="76:164	Despite seeming useful, some features may in fact be too noisy or irrelevant, increasing the risk of overfitting the training data." ></td>
	<td class="line x" title="77:164	Some features may also be redundant, given other features; thus, feature selection methods that consider the value of each feature on its own (e.g., information gain) may lead to suboptimal feature sets." ></td>
	<td class="line x" title="78:164	Finding the best subset of a set of available features is a search space problem for which several methods have been proposed (Guyon et al., 2006)." ></td>
	<td class="line x" title="79:164	We have experimented with a wrapper approach, whereby each feature subset is evaluated according to the predictive power of a classifier (treated as a black box) that uses the subset; in our experiments, the predictive power was measured as Fmeasure (defined below, not to be confused with FR1,R2)." ></td>
	<td class="line x" title="80:164	More precisely, during feature selection, for each feature subset we performed 10-fold cross validation on the training data to evaluate its predictive power." ></td>
	<td class="line x" title="81:164	After feature selection, the classifier was trained on all the training data, and it was evaluated on separate test data." ></td>
	<td class="line x" title="82:164	With large feature sets, an exhaustive search over all subsets is intractable." ></td>
	<td class="line x" title="83:164	Instead, we experimented with forward hill-climbing and beam search (Guyon et al., 2006)." ></td>
	<td class="line x" title="84:164	Forward hill-climbing starts with an empty feature set, to which it adds features, one at a time, by preferring to add at each step the feature that leads to the highest predictive power." ></td>
	<td class="line x" title="85:164	Forward beam search is similar, except that the search frontier contains the k best examined states (feature subsets) at each time; we used k = 10." ></td>
	<td class="line x" title="86:164	For k = 1, beam search reduces to hillclimbing." ></td>
	<td class="line x" title="87:164	3 Experiments We now present our experiments, starting from a description of the datasets used." ></td>
	<td class="line x" title="88:164	3.1 Datasets We mainly used the Microsoft Research (MSR) Paraphrasing Corpus (Dolan et al., 2004), which consists of 5,801 pairs of sentences." ></td>
	<td class="line x" title="89:164	Each pair is manually annotated by two human judges as a true or false paraphrase; a third judge resolved disagreements." ></td>
	<td class="line x" title="90:164	The data are split into 4,076 training pairs and 1,725 testing pairs." ></td>
	<td class="line x" title="91:164	We have experimented with a dataset we created from the MTC corpus." ></td>
	<td class="line x" title="92:164	MTC is a corpus containing news articles in Mandarin Chinese; for each article 11 English translations (by different translators) are also provided." ></td>
	<td class="line x" title="93:164	We considered the translations of the same Chinese sentence as paraphrases." ></td>
	<td class="line x" title="94:164	We obtained all the possible paraphrase pairs and we added an equal number of randomly selected non paraphrase pairs, which contained sentences that were not translations of the same sentence." ></td>
	<td class="line x" title="95:164	In this way, we constructed a dataset containing 82,260 pairs of sentences." ></td>
	<td class="line x" title="96:164	The dataset was then split in training (70%) and test (30%) parts, with an equal number of positive and negative pairs in each part." ></td>
	<td class="line x" title="97:164	3.2 Evaluation measures and baseline We used four evaluation measures, namely accuracy (correctly classified pairs over all pairs), precision (P, pairs correctly classified in the positive class over all pairs classified in the positive class), recall (R, pairs correctly classified in the positive class over all true positive pairs), and F-measure (with equal weight on precision and recall, defined as 2PRP+R )." ></td>
	<td class="line x" title="98:164	These measures are not to be confused with the R1, R2, and FR1,R2 of section 2.3 which are used as features." ></td>
	<td class="line x" title="99:164	A reasonable baseline method (BASE) is to use just the edit distance similarity measure and a threshold in order to decide whether two phrases are paraphrases or not." ></td>
	<td class="line x" title="100:164	The threshold is chosen using a grid search utility and 10-fold cross validation on the training data." ></td>
	<td class="line x" title="101:164	More precisely, in a first step we search the range [-1, 1] with a step of 0.1.6 In each step, we perform 10-fold cross validation and the value that achieves the best Fmeasure is our initial threshold, th, for the second step." ></td>
	<td class="line x" title="102:164	In the second step, we perform the same procedure in the range [th 0.1, th + 0.1] and with a step of 0.001." ></td>
	<td class="line x" title="103:164	6Recall that we normalize similarity in [-1, 1]." ></td>
	<td class="line x" title="104:164	31 3.3 Experimental results With both datasets, we experimented with a Maximum Entropy (ME) classifier." ></td>
	<td class="line x" title="105:164	However, preliminary results (see table 1) showed that our MTC dataset is very easy." ></td>
	<td class="line x" title="106:164	BASE achieves approximately 95% in accuracy and F-measure, and an approximate performance of 99.5% in all measures (accuracy, precision, recall, F-measure) is achieved by using ME and only some of the features of INIT (we use 36 features corresponding to pairsangbracketleftbig s11,s12angbracketrightbig, angbracketleftbigs21,s22angbracketrightbig, angbracketleftbigs31,s32angbracketrightbig, angbracketleftbigs41,s42angbracketrightbig plus the two negation features)." ></td>
	<td class="line x" title="107:164	Therefore, we did not experiment with the MTC dataset any further." ></td>
	<td class="line x" title="108:164	Table 2 (upper part) lists the results of our experiments on the MSR corpus." ></td>
	<td class="line x" title="109:164	We optionally performed feature selection with both forward hillclimbing (FHC) and forward beam search (FBS)." ></td>
	<td class="line x" title="110:164	All of our methods clearly perform better than BASE." ></td>
	<td class="line x" title="111:164	As one might expect, there is a lot of redundancy in the complete feature set." ></td>
	<td class="line x" title="112:164	Hence, the two feature selection methods (FHC and FBS) lead to competitive results with much fewer features (7 and 10, respectively, instead of 136)." ></td>
	<td class="line x" title="113:164	However, feature selection deteriorates performance, especially accuracy, i.e., the full feature set is better, despite its redundancy." ></td>
	<td class="line x" title="114:164	Table 2 also includes all other reported results for the MSR corpus that we are aware of; we are not aware of the exact number of features used by the other researchers." ></td>
	<td class="line x" title="115:164	It is noteworthy that INIT achieves state of the art performance, even though the other approaches use many more linguistic resources." ></td>
	<td class="line x" title="116:164	For example, Wan et al.s approach (Wan et al., 2006), which achieved the best previously reported results, is similar to ours, in that it also trains a classifier with similarity measures; but some of Wan et al.s measures require a dependency grammar parser, unlike INIT." ></td>
	<td class="line x" title="117:164	More precisely, for each pair of sentences, Wan et al. construct a feature vector with values that measure lexical and dependency similarities." ></td>
	<td class="line x" title="118:164	The measures are: word overlap, length difference (in words), BLEU (Papineni et al., 2002), dependency relation overlap (i.e., R1 and R2 but not FR1,R2), and dependency tree edit distance." ></td>
	<td class="line x" title="119:164	The measures are also applied on sequences containing the lemmatized words of the original sentences, similarly to one of our levels of abstraction." ></td>
	<td class="line x" title="120:164	Interestingly, INIT achieves the same (and slightly better) accuracy as Wan et al.s system, without employing any parsing." ></td>
	<td class="line x" title="121:164	Our more enhanced methods, INIT+WN and INIT+WN+DEP, achieve even better results." ></td>
	<td class="line x" title="122:164	Zhang and Patrick (2005) use a dependency grammar parser to convert passive voice phrases to active voice ones." ></td>
	<td class="line x" title="123:164	They also use a preprocessing stage to generalize the pairs of sentences." ></td>
	<td class="line x" title="124:164	The preprocessing replaces dates, times, percentages, etc. with generic tags, something that we have also done in the MSR corpus, but it also replaces words and phrases indicating future actions (e.g., plans to, be expected to) with the word will; the latter is an example of further preprocessing that could be added to our system." ></td>
	<td class="line x" title="125:164	After the preprocessing, Zhang and Patrick create for each sentence pair a feature vector whose values measure the lexical similarity between the two sentences; they appear to be using the maximum number of consecutive common words, the number of common words, edit distance (in words), and modified n-gram precision, a measure similar to BLEU." ></td>
	<td class="line x" title="126:164	The produced vectors are then used to train a decision tree classifier." ></td>
	<td class="line x" title="127:164	Hence, Zhang and Patricks approach is similar to ours, but we use more and different similarity measures and several levels of abstraction of the two sentences." ></td>
	<td class="line x" title="128:164	We also use ME, along with a wrapper approach to feature selection, rather than decision tree induction and its embedded information gain-based feature selection." ></td>
	<td class="line x" title="129:164	Furthermore, all of our methods, even INIT which employs no parsing at all, achieve better results compared to Zhang and Patricks. Qiu et al.(2006) first convert the sentences into tuples using parsing and semantic role labeling." ></td>
	<td class="line x" title="131:164	They then match similar tuples across the two sentences, and use an SVM (Vapnik, 1998) classifier to decide whether or not the tuples that have not been matched are important or not." ></td>
	<td class="line x" title="132:164	If not, the sentences are paraphrases." ></td>
	<td class="line x" title="133:164	Despite using a parser and a semantic role identifier, Qiu et al.s system performs worse than our methods." ></td>
	<td class="line x" title="134:164	Finally, Finch et al.s system (2005) achieved the second best overall results by employing POS tagging, synonymy resolution, and an SVM." ></td>
	<td class="line x" title="135:164	Interestingly, the features of the SVM correspond to machine translation evaluation metrics, rather than string similarity measures, unlike our system." ></td>
	<td class="line x" title="136:164	We plan to examine further how the features of Finch et al. and other ideas from machine translation can be embedded in our system, although INIT+WN+DEP outperforms Finch et al.s system." ></td>
	<td class="line x" title="137:164	Interestingly, even when not using more resources than Finch et al. as in methods INIT and INIT+WN 32 method features accuracy precision recall F-measure BASE  95.30 98.16 92.32 95.15 INIT 38 99.62 99.50 99.75 99.62 Table 1: Results (%) of our methods on our MTC dataset." ></td>
	<td class="line x" title="138:164	method features accuracy precision recall F-measure BASE 1 69.04 72.42 86.31 78.76 INIT 133 75.19 78.51 86.31 82.23 INIT+WN 133 75.48 78.91 86.14 82.37 INIT+WN+DEP 136 76.17 79.35 86.75 82.88 INIT+WN+DEP + FHC 7 73.86 75.14 90.67 82.18 INIT+WN+DEP + FBS 10 73.68 73.68 93.98 82.61 Finch et al.  74.96 76.58 89.80 82.66 Qiu et al.  72.00 72.50 93.40 81.60 Wan et al.  75.00 77.00 90.00 83.00 Zhang & Patrick  71.90 74.30 88.20 80.70 Table 2: Results (%) of our methods (upper part) and other methods (lower part) on the MSR corpus." ></td>
	<td class="line x" title="139:164	we achieve similar or better accuracy results." ></td>
	<td class="line x" title="140:164	4 Related work We have already made the distinction between paraphrase (and textual entailment) generators vs. recognizers, and we have pointed out that recognizers can be embedded in generators as filters." ></td>
	<td class="line xc" title="141:164	The latter is particularly useful in bootstrapping paraphrase generation approaches (Riloff and Jones, 1999; Barzilay and McKeown, 2001; Ravichandran and Hovy, 2001; Ravichandran et al., 2003; Duclaye et al., 2003; Szpektor et al., 2004), which are typically given seed pairs of named entities for which a particular relation holds; the system locates in a document collection (or the entire Web) contexts were the seeds cooccur, and uses the contexts as patterns that can express the relation; the patterns are then used to locate new named entities that satisfy the relation, and a new iteration begins." ></td>
	<td class="line x" title="142:164	A paraphrase recognizer could be used to filter out erroneous generated paraphrases between iterations." ></td>
	<td class="line x" title="143:164	Another well known paraphrase generator is Lin and Pantels (2001) DIRT, which produces slotted semantically equivalent patterns (e.g., X is the writer of Y   X wrote Y   Y was written by X  X is the author of Y ), based on the assumption that different paths of dependency trees (obtained from a corpus) that occur frequently with the same words (slot fillers) at their ends are often paraphrases." ></td>
	<td class="line x" title="144:164	An extension of DIRT, named LEDIR, has also been proposed (Bhagat et al., 2007) to recognize directional textual entailment rules (e.g., Y was written by X  Y is the work of X)." ></td>
	<td class="line x" title="145:164	Ibrahim et al.s (2003) method is similar to DIRT, but it uses only dependency grammar paths from aligned sentences (from a parallel corpus) that share compatible anchors (e.g., identical strings, or entity names of the same semantic category)." ></td>
	<td class="line x" title="146:164	Shinyama and Sekine (2003) adopt a very similar approach." ></td>
	<td class="line oc" title="147:164	In another generation approach, Barzilay and Lee (2002; 2003) look for pairs of slotted word lattices that share many common slot fillers; the lattices are generated by applying a multiplesequence alignment algorithm to a corpus of multiple news articles about the same events." ></td>
	<td class="line x" title="148:164	Finally, Pang et al.(2003) create finite state automata by merging parse trees of aligned sentences from a parallel corpus; in each automaton, different paths represent paraphrases." ></td>
	<td class="line n" title="150:164	Again, a paraphrase recognizer could be embedded in all of these methods, to filter out erroneous generated patterns." ></td>
	<td class="line x" title="151:164	5 Conclusions and further work We have presented three methods (INIT, INIT+WN, INIT+WN+DEP) that recognize paraphrases given pairs of sentences." ></td>
	<td class="line x" title="152:164	These methods employ nine string similarity measures applied to ten shallow abstractions of the input sentences." ></td>
	<td class="line x" title="153:164	Moreover, INIT+WN and INIT+WN+DEP exploit WordNet for synonymy resolution, and INIT+WN+DEP uses additional features that measure grammatical relation similarity." ></td>
	<td class="line x" title="154:164	Supervised machine learning is used to learn how to combine the resulting features." ></td>
	<td class="line x" title="155:164	We experimented with a Maximum Entropy classifier on two datasets; the publicly available MSR corpus and one that we constructed from the 33 MTC corpus." ></td>
	<td class="line x" title="156:164	However, the latter was found to be very easy, and consequently we mainly focused on the MSR corpus." ></td>
	<td class="line x" title="157:164	On the MSR corpus, all of our methods achieved similar or better performance than the sate of the art, even INIT, despite the fact that it uses fewer linguistic resources." ></td>
	<td class="line x" title="158:164	Hence, INIT may have practical advantages in less spoken languages, which have limited resources." ></td>
	<td class="line x" title="159:164	The most elaborate of our methods, INIT+WN+DEP, achieved the best results, but it requires WordNet and a reliable dependency grammar parser." ></td>
	<td class="line x" title="160:164	Feature selection experiments indicate that there is significant redundancy in our feature set, though the full feature set leads to better performance than the subsets produced by feature selection." ></td>
	<td class="line x" title="161:164	Further improvements may be possible by including in our system additional features, such as BLEU scores or features for word alignment." ></td>
	<td class="line x" title="162:164	Our long-term goal is to embed our recognizer in a bootstrapping paraphrase generator, to filter out erroneous paraphrases between bootstrapping iterations." ></td>
	<td class="line x" title="163:164	We hope that our recognizer will be adequate for this purpose, possibly in combination with a human in the loop, who will inspect paraphrases the recognizer is uncertain of." ></td>
	<td class="line x" title="164:164	Acknowledgements This work was funded by the Greek PENED 2003 programme, which is co-funded by the European Union (80%), and the Greek General Secretariat for Research and Technology (20%)." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W09-0604
Is Sentence Compression an NLG task?
Marsi, Erwin;Krahmer, Emiel;Hendrickx, Iris;Daelemans, Walter;"></td>
	<td class="line x" title="1:186	Proceedings of the 12th European Workshop on Natural Language Generation, pages 2532, Athens, Greece, 30  31 March 2009." ></td>
	<td class="line x" title="2:186	c2009 Association for Computational Linguistics Is sentence compression an NLG task?" ></td>
	<td class="line x" title="3:186	Erwin Marsi, Emiel Krahmer Tilburg University Tilburg, The Netherlands e.j.krahmer@uvt.nl e.c.marsi@uvt.nl Iris Hendrickx, Walter Daelemans Antwerp University Antwerpen, Belgium iris.hendrickx@ua.ac.be walter.daelemans@ua.ac.be Abstract Data-driven approaches to sentence compression define the task as dropping any subset of words from the input sentence while retaining important information and grammaticality." ></td>
	<td class="line x" title="4:186	We show that only 16% of the observed compressed sentences in the domain of subtitling can be accounted for in this way." ></td>
	<td class="line x" title="5:186	We argue that part of this is due to evaluation issues and estimate that a deletion model is in fact compatible with approximately 55% of the observed data." ></td>
	<td class="line x" title="6:186	We analyse the remaining problems and conclude that in those cases word order changes and paraphrasing are crucial, and argue for more elaborate sentence compression models which build on NLG work." ></td>
	<td class="line x" title="7:186	1 Introduction The task of sentence compression (or sentence reduction) can be defined as summarizing a single sentence by removing information from it (Jing and McKeown, 2000)." ></td>
	<td class="line x" title="8:186	The compressed sentence should retain the most important information and remain grammatical." ></td>
	<td class="line x" title="9:186	One of the applications is in automatic summarization in order to compress sentences extracted for the summary (Lin, 2003; Jing and McKeown, 2000)." ></td>
	<td class="line x" title="10:186	Other applications include automatic subtitling (Vandeghinste and Tsjong Kim Sang, 2004; Vandeghinste and Pan, 2004; Daelemans et al., 2004) and displaying text on devices with very small screens (CorstonOliver, 2001)." ></td>
	<td class="line x" title="11:186	A more restricted version defines sentence compression as dropping any subset of words from the input sentence while retaining important information and grammaticality (Knight and Marcu, 2002)." ></td>
	<td class="line x" title="12:186	This formulation of the task provided the basis for the noisy-channel en decisiontree based algorithms presented in (Knight and Marcu, 2002), and for virtually all follow-up work on data-driven sentence compression (Le and Horiguchi, 2003; Vandeghinste and Pan, 2004; Turner and Charniak, 2005; Clarke and Lapata, 2006; Zajic et al., 2007; Clarke and Lapata, 2008) It makes two important assumptions: (1) only word deletions are allowed  no substitutions or insertions  and therefore no paraphrases; (2) the word order is fixed." ></td>
	<td class="line x" title="13:186	In other words, the compressed sentence must be a subsequence of the source sentence." ></td>
	<td class="line x" title="14:186	We will call this the subsequence constraint, and refer to the corresponding compression models as word deletion models." ></td>
	<td class="line x" title="15:186	Another implicit assumption in most work is that the scope of sentence compression is limited to isolated sentences and that the textual context is irrelevant." ></td>
	<td class="line x" title="16:186	Under this definition, sentence compression is reduced to a word deletion task." ></td>
	<td class="line x" title="17:186	Although one may argue that even this counts as a form of text-to-text generation, and consequently an NLG task, the generation component is virtually nonexistent." ></td>
	<td class="line x" title="18:186	One can thus seriously doubt whether it really is an NLG task." ></td>
	<td class="line x" title="19:186	Things would become more interesting from an NLG perspective if we could show that sentence compression necessarily involves transformations beyond mere deletion of words, and that this requires linguistic knowledge and resources typical to NLG." ></td>
	<td class="line x" title="20:186	The aim of this paper is therefore to challenge the deletion model and the underlying subsequence constraint." ></td>
	<td class="line x" title="21:186	To use an analogy, our aim is to show that sentence compression is less like carving something out of wood where material can only be removed and more like molding something out of clay where the material can be thor25 oughly reshaped." ></td>
	<td class="line x" title="22:186	In support of this claim we provide evidence that the coverage of deletion models is in fact rather limited and that word reordering and paraphrasing play an important role." ></td>
	<td class="line x" title="23:186	The remainder of this paper is structured as follows." ></td>
	<td class="line x" title="24:186	In Section 2, we introduce our text material which comes from the domain of subtitling." ></td>
	<td class="line x" title="25:186	We explain why not all material is equally well suited for studying sentence compression and motivate why we disregard certain parts of the data." ></td>
	<td class="line x" title="26:186	We also describe the manual alignment procedure and the derivation of edit operations from it." ></td>
	<td class="line x" title="27:186	In Section 3, an analysis of the number of deletions, insertions, substitutions, and reorderings in our data is presented." ></td>
	<td class="line x" title="28:186	We determine how many of the compressed sentences actually satisfy the subsequence constraint, and how many of them could in principle be accounted for." ></td>
	<td class="line x" title="29:186	That is, we consider alternatives with the same compression ratio which do not violate the subsequence constraint." ></td>
	<td class="line x" title="30:186	Next is an analysis of the remaining problematic cases in which violation of the subsequence constraint is crucial to accomplish the observed compression ratio." ></td>
	<td class="line x" title="31:186	We single out (1) reordering after deletion and (2) paraphrasing as important factors." ></td>
	<td class="line x" title="32:186	Given the importance of paraphrases, Section 3.4 discusses the perspectives for automatic extraction of paraphrase pairs from large text corpora, and tries to estimate how much text is required to obtain a reasonable coverage." ></td>
	<td class="line x" title="33:186	We finish with a summary and discussion in Section 4." ></td>
	<td class="line x" title="34:186	2 Material We study sentence compression in the context of subtitling." ></td>
	<td class="line x" title="35:186	The basic problem of subtitling is that on average reading takes more time than listening, so subtitles can not be a verbatim transcription of the speech without increasingly lagging behind." ></td>
	<td class="line x" title="36:186	Subtitles can be presented at a rate of 690 to 780 characters per minute, while the average speech rate is considerably higher (Vandeghinste and Tsjong Kim Sang, 2004)." ></td>
	<td class="line x" title="37:186	Subtitles are therefore often a compressed representation of the original spoken text." ></td>
	<td class="line x" title="38:186	Our text material stems from the NOS Journaal, the daily news broadcast of the Dutch public television." ></td>
	<td class="line x" title="39:186	It is parallel text with on one side the autocue sentences (aut), i.e. the text the news reader is reading, and on the other side the corresponding subtitle sentences (sub)." ></td>
	<td class="line x" title="40:186	It was originally collected and processed in two earlier research projects  Atranos and Musa  on automatic subtitling (Vandeghinste and Tsjong Kim Sang, 2004; Vandeghinste and Pan, 2004; Daelemans et al., 2004)." ></td>
	<td class="line x" title="41:186	All text was automatically tokenized and aligned at the sentence level, after which alignments were manually checked." ></td>
	<td class="line x" title="42:186	The same material was further annotated in an ongoing project called DAESO1, in which the general goal is automatic detection of semantic overlap." ></td>
	<td class="line x" title="43:186	All aligned sentences were first syntactically parsed after which their parse trees were manually aligned in more detail." ></td>
	<td class="line x" title="44:186	Pairs of similar syntactic nodes  either words or phrases  were aligned and labeled according to a set of five semantic similarity relations (Marsi and Krahmer, 2007)." ></td>
	<td class="line x" title="45:186	For current purposes, only the alignment at the word level is used, ignoring phrasal alignments and relation labels." ></td>
	<td class="line x" title="46:186	Not all material in this corpus is equally well suited for studying sentence compression as defined in the introduction." ></td>
	<td class="line x" title="47:186	As we will discuss in more detail below, this prompted us to disregard certain parts of the data." ></td>
	<td class="line x" title="48:186	Sentence deletion, splitting and merging For a start, autocue and subtitle sentences are often not in a one-to-one alignment relation." ></td>
	<td class="line x" title="49:186	Table 1 specifies the alignment degree (i.e. the number of other sentences that a sentence is aligned to) for autocue and subtitle sentences." ></td>
	<td class="line x" title="50:186	The first thing to notice is that there is a large number of unaligned subtitles." ></td>
	<td class="line x" title="51:186	These correspond to non-anchor text from, e.g., interviews or reporters abroad." ></td>
	<td class="line x" title="52:186	More interesting is that about one in five autocue sentences is completely dropped." ></td>
	<td class="line x" title="53:186	A small number of about 4 to 8 percent of the sentence pairs are not oneto-one aligned." ></td>
	<td class="line x" title="54:186	A long autocue sentence may be split into several simpler subtitle sentences, each containing only a part of the semantic content of the autocue sentence." ></td>
	<td class="line x" title="55:186	Conversely, one or more usually short autocue sentences may be merged into a single subtitle sentence." ></td>
	<td class="line x" title="56:186	These decisions of sentence deletion, splitting and merging are worthy research topics in the context of automatic subtitling, but they should not be confused with sentence compression, the scope of which is by definition limited to single sentence." ></td>
	<td class="line x" title="57:186	Accordingly we disregarded all sentence pairs where autocue and subtitle are not in a oneto-one relation with each other." ></td>
	<td class="line x" title="58:186	This reduced the data set from 15289 to 11034 sentence pairs." ></td>
	<td class="line x" title="59:186	1http://daeso.uvt.nl 26 Degree: Autocue: (%) Subtitle: (%) 0 3607 (20.74) 12542 (46.75) 1 12382 (71.19) 13340 (49.72) 2 1313 (7.55) 901 (3.36) 3 83 (0.48) 41 (0.15) 4 8 (0.05) 6 (0.02) Table 1: Degree of sentence alignment Word compression A significant part of the reduction in subtitle characters is actually not obtained by deleting words but by lexical substitution of a shorter token." ></td>
	<td class="line x" title="60:186	Examples of this include substitution by digits (7 for seven), abbreviations or acronyms (US for United States), symbols (euro symbol for Euro), or reductions of compound words (elections for state-elections)." ></td>
	<td class="line x" title="61:186	We will call this word compression." ></td>
	<td class="line x" title="62:186	Although an important part of subtitling, we prefer to abstract from word compression and focus here on sentence compression proper." ></td>
	<td class="line x" title="63:186	Removing all sentence pairs containing a word compression has the disadvantage of further reducing the data set." ></td>
	<td class="line x" title="64:186	Instead we choose to measure compression ratio (CR) in terms of tokens2 rather than characters." ></td>
	<td class="line x" title="65:186	CR = #toksub#tok aut (1) This means that the majority of the word compressions do not affect the sentence CR." ></td>
	<td class="line x" title="66:186	Variability in compression ratio The CR of subtitles is not constant, but varies depending (mainly) on the amount of provided autocue material in a given time frame." ></td>
	<td class="line x" title="67:186	The histogram in Figure 1 shows the distribution of the CR (measured in words) for one-to-one aligned sentences." ></td>
	<td class="line x" title="68:186	In fact, autocue sentences are most likely not to be compressed at all (thus belonging to the largest bin, from 1.00 to 1.09 in the histogram).3 In order to obtain a proper set of compression examples, we retained only those sentence pairs where the compression ratio is less than one." ></td>
	<td class="line x" title="69:186	Parsing failures As mentioned earlier detailed alignment of autocue and subtitle sentences was carried out on their syntactic trees." ></td>
	<td class="line x" title="70:186	However, for various reasons a small number of sentences (0.2%) failed to pass the parser and received no parse tree." ></td>
	<td class="line x" title="71:186	As a consequence, their trees could not 2Throughout this study we ignore punctuation and letter case." ></td>
	<td class="line x" title="72:186	3Some instances even show a CR larger than one, because occasionally there is sufficient time/space to provide a clarification, disambiguation, update, or stylistic enhancement." ></td>
	<td class="line x" title="73:186	Figure 1: Histogram of compression ratio Min: Max: Sum: Mean: SD: aut-tokens 2 43 80651 15.41 5.48 sub-tokens 1 29 53691 10.26 3.72 CR 0.07 0.96 nan 0.69 0.17 Table 2: Properties of the final data set of 5233 pairs of autocue-subtitle sentences: minimum value, maximal value, total sum, mean and standard deviation for number of tokens per autocue/subtitle sentence and Compression Ratio be aligned and there is no alignment at the word level available either." ></td>
	<td class="line x" title="74:186	Variability in CR and parsing failures are together responsible for a further reduction down to 5233 sentence pairs, the final size of our data set, with an overall CR of 0.69." ></td>
	<td class="line x" title="75:186	Other properties of this data set are summarized in Table 2.4 Word deletions, insertions and substitutions Having a manual alignment of similar words in both sentences allows us to simply deduce word deletions, substitutions and insertions, as well as word order changes, in the following way:  if an autocue word is not aligned to a subtitle word, then it is was deleted  if a subtitle word is not aligned to an autocue word, then it was inserted  if different autocue and subtitle words are aligned, then the former was substituted by the latter  if alignments cross each other, then the word order was changed The remaining option is where the aligned words are identical (ignoring differences in case)." ></td>
	<td class="line x" title="76:186	4We use the acronym nan (not a number) for undefined/meaningless values." ></td>
	<td class="line x" title="77:186	27 Without the word alignment, we would have to resort to automatically calculating the edit distance, i.e. the sum of the minimal number of insertions, deletions and substitutions required to transform one sentence in to the other." ></td>
	<td class="line x" title="78:186	However, this would result in different and often counterintuitive sequences of edit operations." ></td>
	<td class="line x" title="79:186	Our approach clearly distinguishes word order changes from the edit operations; the conventional edit distance, by contrast, can only account for changes in word order by sequences of the edit operations." ></td>
	<td class="line x" title="80:186	Another difference is that substitution can also be accomplished as deletion followed by insertion, which means edit operations need to have an associated weight." ></td>
	<td class="line x" title="81:186	Global tuning of these weights turns out to be hard." ></td>
	<td class="line x" title="82:186	3 Analysis 3.1 Edit operations The observed deletions, insertions, substitutions, edit distances, and word order changes are shown in Table 3." ></td>
	<td class="line x" title="83:186	As expected, deletion is the most frequent operation, with on average seven deletions per sentence." ></td>
	<td class="line x" title="84:186	Insertion and substitutions are far less frequent." ></td>
	<td class="line x" title="85:186	Note also that  even though the task is compression  insertions are somewhat more frequent than substitutions." ></td>
	<td class="line x" title="86:186	Word order changes occur in 1688 cases (32.26%)." ></td>
	<td class="line x" title="87:186	Here, reordering is a binary variable  i.e. the word order is changed or not  hence Min, Max and SD are undefined." ></td>
	<td class="line x" title="88:186	Another point of view is to look at the number of sentence pairs containing a certain edit operation." ></td>
	<td class="line x" title="89:186	Here we find 5233 pairs (100.00%) with deletion, 2738 (52.32%) with substitution, 3263 (62.35%) with insertion, and 1688 (32.26%) with reordering." ></td>
	<td class="line x" title="90:186	The average CR for subsequences is 0.68 (SD = 0.20) versus 0.69 (SD = 0.17) for non-subsequences." ></td>
	<td class="line x" title="91:186	A detailed inspection of the relation between the subsequence/non  subsequence ratio and CR revealed no clear correlation, so we did not find indications that nonsubsequences occur more frequently at higher compression ratios." ></td>
	<td class="line x" title="92:186	3.2 Percentage of subsequences The subtitle is a subsequence of the autocue if there are no insertions, no substitutions, and no word order changes." ></td>
	<td class="line x" title="93:186	In contrast, if any of these do occur, the subtitle is not a subsequence." ></td>
	<td class="line x" title="94:186	It turns Min: Max: Sum: Mean: SD: del 1 34 34728 6.64 4.57 sub 0 6 4116 0.79 0.94 ins 0 17 7768 1.48 1.78 dist 1 46 46612 8.91 5.78 reorder nan nan 1688 0.32 nan Table 3: Observed word deletions, insertions, substitutions, and edit distances out that only 843 (16.11%) subtitles are a subsequence, which is rather low." ></td>
	<td class="line x" title="95:186	At first sight, this appears to be bad news for any deletion model, as it seems to imply that the model cannot account for close to 84% the observed data." ></td>
	<td class="line x" title="96:186	However, the important thing to keep in mind is that compression of a given sentence is a problem for which there are usually multiple solutions (Belz and Reiter, 2006)." ></td>
	<td class="line x" title="97:186	This is exactly what makes it so hard to perform automatic evaluation of NLG systems." ></td>
	<td class="line x" title="98:186	There may very well exist semantically equivalent alternatives with the same CR which do satisfy the subsequence constraint." ></td>
	<td class="line x" title="99:186	For this reason, a substantial part of the observed non-subsequences may have subsequence counterparts which can be accounted for by a deletion model." ></td>
	<td class="line x" title="100:186	The question is: how many?" ></td>
	<td class="line x" title="101:186	In order to address this question, we took a random sample of 200 non-subsequence sentence pairs." ></td>
	<td class="line x" title="102:186	In each case we tried to come up with an alternative subsequence subtitle with the same meaning and the same CR (or when opportune, even a lower CR)." ></td>
	<td class="line x" title="103:186	Table 4 shows the distribution of the difference in tokens between the original non-subsequence subtitle and the manuallyconstructed equivalent subsequence subtitle." ></td>
	<td class="line x" title="104:186	Apparently 95 out of 200 (47%) subsequence subtitles have the same (or even fewer) tokens, and thus the same (or an even lower) compression ratio." ></td>
	<td class="line x" title="105:186	This suggests that the subsequence constraint is not as problematic as it seemed and that the coverage of a deletion model is in fact far better than it appeared to be." ></td>
	<td class="line x" title="106:186	Recall that 16% of the original subtitles were already subsequences, so our analysis suggests that a deletion model is compatible with 55% (16% plus 47% of 84%)." ></td>
	<td class="line x" title="107:186	3.3 Problematic non-subsequences Another result of this exercise in rewriting subtitles is that it allows us to identify those cases where the attempt to create a proper subsequence fails." ></td>
	<td class="line x" title="108:186	In (1), we show one representative example of a problematic subtitle, for which 28 (1) Aut de the bron source was was een a geriatrische geriatric patient patient die who zonder without het it zelf self te to merken notice uitzonderlijk exceptionally veel many larven larvae bij with zich him bleek appeared te to dragen carry en and een a grote large verspreiding spreading veroorzaakte caused the source was a geriatric patient who unknowingly carried exceptionally many larvae and caused a wide spreading Sub een a geriatrische geriatric patient patient met with larven larvae heeft has de the verspreiding spreading veroorzaakt caused Seq de bron was een geriatrische patient die veel larven bij zich bleek te dragen en een verspreiding veroorzaakte (2) Aut in in verband relation met to de the lawineramp avalanche-disaster in in galur Galtur hebben have de the politieke political partijen parties in in tirol Tirol gezamenlijk together besloten decided de the verkiezingscampagne election-campaign voor for het the regionale regional parlement parliament op up te to schorten postpone Sub de the politieke political partijen parties in in tirol Tirol hebben have besloten decided de the verkiezingen elections op up te to schorten postpone Political parties in Tirol have decided to postpone the elections (3) Aut velen many van of hen them worden are door by de the serviers Serbs in in volgeladen crammed treinen trains gedeporteerd deported Sub vluchtelingen refugees worden are per by trein train gedeporteerd deported token-diff: count: (%:) -2 4 2.00 -1 18 9.00 0 73 36.50 1 42 21.00 2 32 16.00 3 11 5.50 4 9 4.50 5 5 2.50 7 2 1.00 8 2 1.00 9 1 0.50 11 1 0.50 Table 4: Distribution of difference in tokens between original non-subsequence subtitle and equivalent subsequence subtitle the best equivalent subsequence we could obtain still has nine more tokens than the original non-subsequence." ></td>
	<td class="line x" title="109:186	These problematic nonsubsequences reveal where insertion, substitution and/or word reordering are essential to obtain a subtitle with a sufficient CR (i.e. the CR observed in the real subtitles)." ></td>
	<td class="line x" title="110:186	At least three different types of phenomena were observed." ></td>
	<td class="line x" title="111:186	Word order In some cases deletion of a constituent necessitates a change in word order to obtain a grammatical sentence." ></td>
	<td class="line x" title="112:186	In example (2), the autocue sentence has the PP modifier in verband met de lawineramp in galur in its topic position (first sentence position)." ></td>
	<td class="line x" title="113:186	Deleting this modifier, as is done in the subtitle, results in a sentence that starts with the verb hebben, which is interpreted as a yes-no question." ></td>
	<td class="line x" title="114:186	For a declarative interpretation, we have to move the subject de politieke partijen to the first position, as in the subtitle." ></td>
	<td class="line x" title="115:186	Incidentally, this indicates that it is instructive to apply sentence compression models to multiple languages, as a word order problem like this never arises in English." ></td>
	<td class="line x" title="116:186	Similar problems arise whenever an embedded clause is promoted to a main clause, which requires a change in the position of the finite verb in Dutch." ></td>
	<td class="line x" title="117:186	In total, a word order problem occurred in 24 out 200 sentences." ></td>
	<td class="line x" title="118:186	Referring expressions Referring expressions are on many occasions replaced by a shorter one  usually a little less precise." ></td>
	<td class="line x" title="119:186	For example, de belgische overheid the Belgian authorities is replaced by belgie Belgium." ></td>
	<td class="line x" title="120:186	Extreme cases of this occur where a long NP like deze tweede impeachment-procedure in de amerikaanse geschiedenis this second impeachment-procedure in the American history is replaced by an anaphor like het it." ></td>
	<td class="line x" title="121:186	Since a referring expression or anaphor must be appropriate in the given context, substitutions like these transcend the domain of a single sentence and require taking the preceding textual context into account." ></td>
	<td class="line x" title="122:186	This is especially clear in examples like (3) in which many of them is replaced the refugees." ></td>
	<td class="line x" title="123:186	It is questionable whether these types of substitutions belong to the task of sentence compression." ></td>
	<td class="line x" title="124:186	We prefer to regard it as one of the additional tasks in automatic subtitling, apart from compression." ></td>
	<td class="line x" title="125:186	Incidentally, it is interesting that the challenge of generating referring expressions is also relevant for automatic subtitling." ></td>
	<td class="line x" title="126:186	29 Paraphrasing Apart from the reduced referring expressions, there are nominal paraphrases reducing a noun phrases like medewerkers van banken employees of banks to a compound word like bankmedewerkers bank-employees." ></td>
	<td class="line x" title="127:186	Likewise, there are adverbial paraphrases such as sinds een paar jaar since a few years to tegenwoordig nowadays, and van de afgelopen tijd of the past time to recent recent." ></td>
	<td class="line x" title="128:186	However, the majority of the paraphrasing concerns verbs as in the two examples below." ></td>
	<td class="line x" title="129:186	(4) Aut X X neemt takes het the initiatief initiative tot to oprichting raising van of Y Y Sub X X zet sets Y Y op up (5) Aut X X om for zijn his uitlevering extradition vroeg asked maar but Y Y die that weigerde refused Sub Y Y hem him niet not wilde wanted uitleveren extradite aan to X Y Y refused to extradite him to Y Even though not all paraphrases are actually shorter, it seems that at least some of them boost compression beyond what can be accomplished with only word deletion." ></td>
	<td class="line x" title="130:186	In the next Section, we look at the possibilities of automatic extraction of such paraphrases." ></td>
	<td class="line oc" title="131:186	3.4 Perspectives for automatic paraphrase extraction There is a growing amount of work on automatic extraction of paraphrases from text corpora (Lin and Pantel, 2001; Barzilay and Lee, 2003; Ibrahim et al., 2003; Dolan et al., 2004)." ></td>
	<td class="line x" title="132:186	One general prerequisite for learning a particular paraphrase pattern is that it must occur in the text corpus with a sufficiently high frequency, otherwise the chances of learning the pattern are proportionally small." ></td>
	<td class="line x" title="133:186	In this section, we investigate to what extent the paraphrases encountered in our random sample of 200 pairs can be retrieved from a reasonably large text corpus." ></td>
	<td class="line x" title="134:186	In a first step, we manually extracted 106 paraphrase patterns." ></td>
	<td class="line x" title="135:186	We filtered these patterns and excluded anaphoric expressions, general verb alternation patterns like active/passive and continuous/non-continuous, as well as verbal patterns involving more than two slots." ></td>
	<td class="line x" title="136:186	After this filtering step, 59 pairs of paraphrases remained, including the examples shown in the preceding Section." ></td>
	<td class="line x" title="137:186	The aim was to estimate how big our corpus has to be to cover the majority of these paraphrase pairs." ></td>
	<td class="line x" title="138:186	We started with counting for each of the paraphrase pairs in our sample how often they occur in a corpus of Dutch news texts, the Twente News Corpus5, which contains approximately 325M tokens and 20M sentences." ></td>
	<td class="line x" title="139:186	We employed regular expressions to count the number of paraphrase pattern matches." ></td>
	<td class="line x" title="140:186	The corpus turned out to contain 70% percent of all paraphrase pairs (i.e. both patterns in the pair occur at least once)." ></td>
	<td class="line x" title="141:186	We also counted how many pairs have a frequencies of at least 10 and 100." ></td>
	<td class="line x" title="142:186	To study the effect of corpus size on the percentage of covered paraphrases, we performed these counts on 1, 2, 5, 10, 25, 50 and 100% of the corpus." ></td>
	<td class="line x" title="143:186	Figure 2 shows the percentage of covered paraphrases dependent on the corpus size." ></td>
	<td class="line x" title="144:186	The most strict threshold that only counts pairs that occur at least 100 times in our corpus, does not retrieve any counts on 1% of the corpus (3M words)." ></td>
	<td class="line x" title="145:186	At 10% of the corpus size only 4% of the paraphases is found, and on the full data set 25% of the pairs is found." ></td>
	<td class="line x" title="146:186	For 51% percent of the patterns (with a frequency of at least 10) we find substantial evidence in our corpus of 325M tokens." ></td>
	<td class="line x" title="147:186	We fitted a curve through our data points, and found a logarithmic line fit with adjusted R2 value of .943." ></td>
	<td class="line x" title="148:186	This suggests that in order to get 75% of the patterns, we would need a corpus that is 18 times bigger than our current one, which amounts to roughly 6 billion words." ></td>
	<td class="line x" title="149:186	Although this seems like a lot of text, using the WWW as our corpus would easily give us these numbers." ></td>
	<td class="line x" title="150:186	Todays estimate of the Index Dutch World Wide Web is 688 million pages6." ></td>
	<td class="line x" title="151:186	If we assume that each page contains at least 100 tokens on average, this implies a corpus size of 68 billion tokens." ></td>
	<td class="line x" title="152:186	The patterns used here are word-based and in many cases they express a particular verb tense or verb form (e.g. 3rd person singular), and word order." ></td>
	<td class="line x" title="153:186	This implies that our estimations are the minimum number of matches one can find." ></td>
	<td class="line x" title="154:186	For more abstract matching, we would need syntactically parsed data (Lin and Pantel, 2001)." ></td>
	<td class="line x" title="155:186	We expect that this would also positively affect the coverage." ></td>
	<td class="line x" title="156:186	5http://www.vf.utwente.nl/druid/TwNC/ TwNC-main.html 6http://www.worldwidewebsize.com/ index.php?lang=NL, as measured in December 2008 30 Figure 2: Percentage of covered paraphrases as a function of the corpus size 4 Discussion We found that only 16.11% of 5233 subtitle sentences were proper subsequences of the corresponding autocue sentence, and therefore 84% can not be accounted for by a deletion model." ></td>
	<td class="line x" title="157:186	One consequence appears to be that the subsequence constraint greatly reduces the amount of available training material for any word deletion model." ></td>
	<td class="line x" title="158:186	However, an attempt to rewrite non-subsequences to semantically equivalent sequences with the same CR suggests that a deletion model could in principle be adequate for 55% of the data." ></td>
	<td class="line x" title="159:186	Moreover, in those cases where an application can tolerate a little slack in the CR, a deletion model might be sufficient." ></td>
	<td class="line x" title="160:186	For instance, if we are willing to tolerate up to two more tokens, we can account for as much as 169 (84%) of the 200 non-subsequences in our sample, which amounts to 87% (16% plus 84% of 84%) of the total data." ></td>
	<td class="line x" title="161:186	It should be noted that we have been very strict regarding what counts as a semantically equivalent subtitle: every piece of information occurring in the non-subsequence subtitle must reoccur in the sequence subtitle." ></td>
	<td class="line x" title="162:186	However, looking at our original data, it is clear that considerable liberty is taken as far as conserving semantic content is concerned: subtitles often drop substantial pieces of information." ></td>
	<td class="line x" title="163:186	If we relax the notion of semantic equivalence a little, an even larger part of the non-subsequences can be rewritten as proper sequences." ></td>
	<td class="line x" title="164:186	The remaining problematic non-subsequences are those where insertion, substitution and/or word reordering are essential to obtain a sufficient CR." ></td>
	<td class="line x" title="165:186	One of the issues we identified is that deletion of certain constituents must be accompanied by a change in word order to prevent an ungrammatical sentence." ></td>
	<td class="line x" title="166:186	Since changes in word order appear to require grammatical modeling or knowledge, this brings sentence compression closer to being an NLG task." ></td>
	<td class="line x" title="167:186	Nguyen and Horiguchi (2003) describe an extension of the decision tree-based compression model (Knight and Marcu, 2002) which allows for word order changes." ></td>
	<td class="line x" title="168:186	The key to their approach is that dropped constituents are temporarily stored on a deletion stack, from which they can later be re-inserted in the tree where required." ></td>
	<td class="line x" title="169:186	Although this provides an unlimited freedom for rearranging constituents, it also complicates the task of learning the parsing steps, which might explain why their evaluation results show marginal improvements at best." ></td>
	<td class="line x" title="170:186	In our data, most of the word order changes appear to be minor though, often only moving the verb to second position after deleting a constituent in the topic position." ></td>
	<td class="line x" title="171:186	We believe that unrestricted word order changes are perhaps not necessary and that the vast majority of the word order problems can be solved by a fairly restricted way of reordering." ></td>
	<td class="line x" title="172:186	In particular, we plan to implement a parserbased model with an additional swap operation that swaps the two topmost items on the stack." ></td>
	<td class="line x" title="173:186	We expect that this is more feasible as a learning task than a model with a deletion stack." ></td>
	<td class="line x" title="174:186	Apart from reordering, other problems for word deletion models are the insertions and substitutions as a result of paraphrasing." ></td>
	<td class="line x" title="175:186	Within a decision tree-based model, paraphrasing of words or continuous phrases may be modeled by a combination of a paraphrase lexicon and an extra operation which replaces the n topmost elements on the stack by the corresponding paraphrase." ></td>
	<td class="line x" title="176:186	However, paraphrases involving variable arguments, as typical for verbal paraphrases, cannot be accounted for in this way." ></td>
	<td class="line x" title="177:186	More powerful compression models may draw on existing NLG methods for text revision (Inui et al., 1992) to accommodate full paraphrasing." ></td>
	<td class="line x" title="178:186	We also looked at the perspectives for automatic paraphrase extraction from large text corpora." ></td>
	<td class="line x" title="179:186	About a quarter of the required paraphrase patterns was found at least a hundred times in our corpus of 325M tokens." ></td>
	<td class="line x" title="180:186	Extrapolation suggests that using the web at its current size would give us a coverage of approximately ten counts for three 31 quarters of the paraphrases." ></td>
	<td class="line x" title="181:186	Incidentally, we identified two other tasks in automatic subtitling which are closely related to NLG." ></td>
	<td class="line x" title="182:186	First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation." ></td>
	<td class="line x" title="183:186	Second, generation of a shorter referring expression or an anaphoric expression, which is currently one of the main themes in data-driven NLG." ></td>
	<td class="line x" title="184:186	In conclusion, we have presented evidence that deletion models for sentence compression are not sufficient, and that more elaborate models involving reordering and paraphrasing are required, which puts sentence compression in the field of NLG." ></td>
	<td class="line x" title="185:186	Acknowledgments We would like to thank Nienke Eckhardt, Paul van Pelt, Hanneke Schoormans and Jurry de Vos for the corpus annotation work, and Erik Tsjong Kim Sang and colleagues for the autocue-subtitle material from the ATRANOS project, and Martijn Goudbeek for help with curve fitting." ></td>
	<td class="line x" title="186:186	This work was conducted within the DAESO project funded by the Stevin program (De Nederlandse Taalunie)." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W09-2805
Unsupervised Induction of Sentence Compression Rules
Cordeiro, Joao;Dias, Gael;Brazdil, Pavel;"></td>
	<td class="line x" title="1:188	Proceedings of the 2009 Workshop on Language Generation and Summarisation, ACL-IJCNLP 2009, pages 1522, Suntec, Singapore, 6 August 2009." ></td>
	<td class="line x" title="2:188	c 2009 ACL and AFNLP Unsupervised Induction of Sentence Compression Rules Joao Cordeiro CLT and Bioinformatics University of Beira Interior Covilha, Portugal jpaulo@di.ubi.pt Gael Dias CLT and Bioinformatics University of Beira Interior Covilha, Portugal ddg@di.ubi.pt Pavel Brazdil LIAAD University of Porto Porto, Portugal pbrazdil@liaad.up.pt Abstract In this paper, we propose a new unsupervised approach to sentence compression based on shallow linguistic processing." ></td>
	<td class="line x" title="3:188	For that purpose, paraphrase extraction and alignment is performed over web news stories extracted automatically from the web on a daily basis to provide structured data examples to the learning process." ></td>
	<td class="line x" title="4:188	Compression rules are then learned through the application of Inductive Logic Programming techniques." ></td>
	<td class="line x" title="5:188	Qualitative and quantitative evaluations suggests that this is a worth following approach, which might be even improved in the future." ></td>
	<td class="line x" title="6:188	1 Introduction Sentence compression, simplification or summarization has been an active research subject during this decade." ></td>
	<td class="line x" title="7:188	A set of approaches involving machine learning algorithms and statistical models have been experimented and documented in the literature and several of these are described next." ></td>
	<td class="line x" title="8:188	1.1 Related Work In (Knight & Marcu, 2002) two methods were proposed, one is a probabilistic model the noisy channel model where the probabilities for sentence reduction (P{Scompress|S)} 1) are estimated from a training set of 1035 (Sentence,Sentencecompress) pairs, manually crafted, while considering lexical and syntactical features." ></td>
	<td class="line x" title="9:188	The other approach learns syntactic tree rewriting rules, defined through four operators: SHIFT, REDUCE DROP and ASSIGN." ></td>
	<td class="line x" title="10:188	Sequences of these operators are learned from the training set, and each sequence defines a complete 1In the original paper the P(t|s) notation is used, where t is the sentence in the target language and s the original sentence in the source language." ></td>
	<td class="line x" title="11:188	transformation from an original sentence to the compressed version." ></td>
	<td class="line x" title="12:188	In the work of (Le Nguyen & Ho, 2004) two sentence reduction algorithms were also proposed." ></td>
	<td class="line x" title="13:188	The first one is based on templatetranslation learning, a method inherited from the machine translation field, which learns lexical transformation rules2, by observing a set of 1500 (Sentence,Sentencereduced) pair, selected from a news agency and manually tuned to obtain the training data." ></td>
	<td class="line x" title="14:188	Due to complexity difficulties found for the application of this big lexical ruleset, they proposed an improvement where a stochastic Hidden Markov Model is trained to help in the decision of which sequence of possible lexical reduction rules should be applied to a specific case." ></td>
	<td class="line x" title="15:188	An unsupervised approach was included in the work of (Turner & Charniak, 2005), where training data are automatically extracted from the Penn Treebank corpus, to fit a noisy channel model, similar to the one used by (Knight & Marcu, 2002)." ></td>
	<td class="line x" title="16:188	Although it seems an interesting approach to provide new training instances, it still be dependent upon data manually labeled." ></td>
	<td class="line x" title="17:188	More recently, the work of (Clarke & Lapata, 2006) devise a different and quite curious approach, where the sentence compression task is defined as an optimization goal, from an Integer Programming problem." ></td>
	<td class="line x" title="18:188	Several constraints are defined, according to language models, linguistic, and syntactical features." ></td>
	<td class="line x" title="19:188	Although this is an unsupervised approach, without using any paralel corpus, it is completely knowledge driven, like a set of crafted rules and heuristics incorporated into a system to solve a certain problem." ></td>
	<td class="line x" title="20:188	1.2 Our Proposal In this paper, we propose a new approach to this research field, which follows an unsupervised methodology to learn sentence compression rules 2Those rules are named there as template-reduction rules." ></td>
	<td class="line x" title="21:188	15 based on shallow linguistic processing." ></td>
	<td class="line x" title="22:188	We designed a system composed of four main steps working in pipeline, where the first three are responsible for data extraction and preparation and in the last one the induction process takes place." ></td>
	<td class="line x" title="23:188	The first step gathers web news stories from related news events collected on a daily basis from which paraphrases are extracted." ></td>
	<td class="line x" title="24:188	In the second step, word alignment between two sentences of a paraphrase is processed." ></td>
	<td class="line x" title="25:188	In the third step, special regions from these aligned paraphrases, called bubbles, are extracted and conveniently preprocessed to feed the induction process." ></td>
	<td class="line x" title="26:188	The whole sequence is schematized in figure 1." ></td>
	<td class="line x" title="27:188	Figure 1: The Pipeline Architecture." ></td>
	<td class="line x" title="28:188	The induction process generates sentence reduction rules which have the following general structure: LcondXcondRcondsuppress(X)." ></td>
	<td class="line x" title="29:188	This means that the sentence segment X will be eliminated if certain conditions hold over left (L), middle (X) and right (R) segments3." ></td>
	<td class="line x" title="30:188	In Figure 2, we present seven different rules which have been automatically induced from our architecture." ></td>
	<td class="line x" title="31:188	These rules are formed by the conjunction of several literals, and they define constraints under which certain sentence subparts may be deleted, therefore compressing or simplifying the sentence." ></td>
	<td class="line x" title="32:188	The X symbol stands for the segment 3For the sake of simplicity and compact representation, we will omit the rule consequent, which is always the same (suppress(X)), whenever a rule is presented." ></td>
	<td class="line x" title="33:188	Z(X) = 1Lc = NPX1 = JJR1 = IN (1) Z(X) = 1Lc = NPX1 = RBR1 = IN (2) Z(X) = 2L1 = andX1 = theR1 = JJ (3) Z(X) = 2L1 = theX2 = ofR1 = NN (4) Z(X) = 2L1 = theXc = NPR1 = NN (5) Z(X) = 3Lc = PPX1 = theRc = NP (6) Z(X) = 3Lc = NPX1 = andR2 = VB (7) Figure 2: Learned Sentence Compression Rules." ></td>
	<td class="line x" title="34:188	to be dropped, L(star) and R(star) are conditions over the left and right contexts respectively." ></td>
	<td class="line x" title="35:188	The numeric subscripts indicate the positions4 where a segment constraint holds and thecsubscript stands for a syntactic chunk type." ></td>
	<td class="line x" title="36:188	TheZ() function computes the length of a given segment, by counting the number of words it contains." ></td>
	<td class="line x" title="37:188	For instance, the first rule means that a word5 will be eliminated if we have a NP (Noun Phrase) chunk in the left context, and a preposition or subordinating conjunction, in the right context (R1 =IN)." ></td>
	<td class="line x" title="38:188	The rule also requires that the elimination word must be an adjective, as we have X1 =JJ." ></td>
	<td class="line x" title="39:188	This rule would be applied to the following segment6 [NP mutual/jj funds/nns information/nn] [ADJP available/jj] [PP on/in] [NP reuters.com/nn] and would delete the word available giving rise to the simplified segment: [NP mutual/jj funds/nns information/nn] [PP on/in] [NP reuters.com/nn]." ></td>
	<td class="line x" title="40:188	Comparatively to all existing works, we propose in this paper a framework capable to extract compression rules in a real world environment." ></td>
	<td class="line x" title="41:188	Moreover, it is fully unsupervised as, at any step of the process, examples do not need to be labeled." ></td>
	<td class="line x" title="42:188	In the remaining of the paper, we will present the overall architecture which achieves precision 4The position starts with 1 and is counted from left to right, on the word segments, except for the left context, where it is counted reversely." ></td>
	<td class="line x" title="43:188	5As we have Z(X) = 1, the candidate segment size to eliminate is equal to one." ></td>
	<td class="line x" title="44:188	6The segment is marked with part-of-speech tags (POS) and chunked with a shallow parser." ></td>
	<td class="line x" title="45:188	Both transformations were made with the OpenNLP toolkit." ></td>
	<td class="line x" title="46:188	16 values up to 85.72%, correctness up to 4.03 in 5 and utility up to 85.72%." ></td>
	<td class="line x" title="47:188	2 Data Preparation Creating relevant training sets, with some thousands examples is a difficult task, as well as is the migration of such a system to process other languages." ></td>
	<td class="line x" title="48:188	Therefore, we propose an unsupervised methodology to automatically create a training set of aligned paraphrases, from electronically available texts on the web." ></td>
	<td class="line x" title="49:188	This step is done through step one and step two of Figure 1, and the details are described in the next two subsections." ></td>
	<td class="line x" title="50:188	2.1 Paraphrase Extraction Our system collects web news stories on a daily basis, and organized them into clusters, which are exclusively related to different and unique events, happening each day: a company acquisition, a presidential speech, a bomb attack, etc. Usually, such clusters contain near 30 small or medium news articles, collected from different media sources." ></td>
	<td class="line x" title="51:188	This environment proves to be very fruitful for paraphrase extraction, since we have many sentences conveying similar information yet written in a different form." ></td>
	<td class="line oc" title="52:188	A few unsupervised metrics have been applied to automatic paraphrase identification and extraction (Barzilay & Lee, 2003; Dolan et al., 2004)." ></td>
	<td class="line nc" title="53:188	However, these unsupervised methodologies show a major drawback by extracting quasi-exact or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of (Dolan et al., 2004) and Word N-gram Overlap for (Barzilay & Lee, 2003)." ></td>
	<td class="line n" title="54:188	Such pairs are useless for our purpose, since we aim to identify asymmetrical paraphrase pairs to be used for sentence compression rule induction, as explained in (Cordeiro et al., Oct 2007)." ></td>
	<td class="line x" title="55:188	There we proposed a new metric, the Sumo-Metric, specially designed for asymmetrical entailed pairs identification, and proved better performance over previous established metrics, even in the specific case when tested with the Microsoft Paraphrase Research Corpus (Dolan et al., 2004), which contains mainly symmetrical cases." ></td>
	<td class="line x" title="56:188	For a given sentence pair, having each sentence x and y words, and with  exclusive links between the sentences, the Sumo-Metric is defined in Equation 8 and 9." ></td>
	<td class="line x" title="57:188	S(Sa,Sb) = 8 >>< >> : S(x,y,) if S(x,y,) < 1.0 0 if  = 0 ekS(x,y,) otherwise (8) where S(x,y,) = log2(x) +log2(y) (9) with ,[0,1] and + = 1." ></td>
	<td class="line x" title="58:188	We have shown (Cordeiro et al., Oct 2007) that Sumo-Metric outperforms all state-of-the-art metrics over all tested corpora and allows to identifying similar sentences with high probability to be paraphrases." ></td>
	<td class="line x" title="59:188	In Figure 3, we provide the reader with an example of an extracted paraphrase." ></td>
	<td class="line x" title="60:188	(1) To the horror of their fans, Miss Ball and Arnaz were divorced in 1960." ></td>
	<td class="line x" title="61:188	(2) Ball and Arnaz divorced in 1960." ></td>
	<td class="line x" title="62:188	Figure 3: An Assymetrical Paraphrase 2.2 Paraphrase Alignment From a corpus of asymmetrical paraphrases, we then use biology-based gene alignment algorithms to align the words contained in each of the two sentences within each paraphrase." ></td>
	<td class="line x" title="63:188	For that purpose, we implemented two well established algorithms, one identifying local alignments (Smith & Waterman, 1981) and the other one computing global alignments (Needleman & Wunsch, 1970)." ></td>
	<td class="line x" title="64:188	We also proposed a convenient dynamic strategy (Cordeiro et al., 2007), which chooses the best alignment algorithm to be applied to a specific case at runtime." ></td>
	<td class="line x" title="65:188	The difference between local and global sequence alignments is illustrated below, where we use letters, instead of words, to better fit our paper space constraints." ></td>
	<td class="line x" title="66:188	Suppose that we have the following two sequences: [D,H,M,S,T,P,R,Q,I,S] and [T,P,Q,I,S,D,H,S] a global alignment would produce the following pair." ></td>
	<td class="line x" title="67:188	D H M S T P R Q I S _ _ _ _ _ _ _ T P _ Q I S D H S For the same two sequences, a local alignment strategy could generate two or more aligned subsequences as follows." ></td>
	<td class="line x" title="68:188	17 |D H M S| |T P R Q I S| |D H _ S| |T P _ Q I S| Hence, at this stage of the process, we end with a corpus of aligned7 asymmetrical paraphrases." ></td>
	<td class="line x" title="69:188	In Figure 4, we present the alignment of the paraphrase of Figure 3." ></td>
	<td class="line x" title="70:188	(1) To the horror of their fans , (2) __ ___ ______ __ _____ ____ _ (1) Miss Ball and Arnaz were divorced in 1960." ></td>
	<td class="line x" title="71:188	(2) ____ Ball and Arnaz ____ divorced in 1960." ></td>
	<td class="line x" title="72:188	Figure 4: An Aligned Paraphrase The next section describes how we use this structured data to extract instances which are going to feed a learning system." ></td>
	<td class="line x" title="73:188	3 Bubble Extraction In order to learn rewriting rules, we have focus our experiences on a special kind of data, selected from the corpus of aligned sentences, and we named this data as Bubbles8." ></td>
	<td class="line x" title="74:188	Given two word aligned sentences, a bubble is a non-empty segment aligned with an empty segment of the other sentence of the paraphrase, sharing a strong context." ></td>
	<td class="line x" title="75:188	In Figure 5, we show different examples of bubbles." ></td>
	<td class="line x" title="76:188	the situation here in chicago with the workers the situation ____ in chicago with the workers obama talks exclusively with tom brokaw on meet obama talks ___________ with tom brokaw on meet Ball and Arnaz were divorced in 1960 Ball and Arnaz ____ divorced in 1960 america is in the exact same seat as sweigert and america is in ___ _____ same seat as sweigert and after a while at the regents park gym, the president after a while at ___ _______ ____ gym, the president Figure 5: Examples of Bubbles To extract a bubble, left and right contexts of equally aligned words must occur, and the probability of such extraction depends on the contexts size as well as the size of the region aligned with the empty space." ></td>
	<td class="line x" title="77:188	The main idea is to eliminate cases where the bubble middle sequence is too large when compared to the size of left and right contexts." ></td>
	<td class="line x" title="78:188	More precisely, we use the condition in 7By aligned we mean, from now on, word alignment between paraphrase sentence pairs." ></td>
	<td class="line x" title="79:188	8There are other possible regions to explore, but due to the complexity of this task, we decided to initially work only with bubbles Equation 10 to decide whether a bubble should be extracted or not." ></td>
	<td class="line x" title="80:188	Z(L)Z(X) +Z(R) 0 (10) whereLandRstand for the left and right contexts, respectively, and X is the middle region." ></td>
	<td class="line x" title="81:188	The Z() function computes the length of a given segment, in terms of number of words." ></td>
	<td class="line x" title="82:188	For example, in the first and last examples of Figure 5, we have: 2 1+5 = 60 and 43+4 = 50." ></td>
	<td class="line x" title="83:188	In this case, both bubbles will be extracted." ></td>
	<td class="line x" title="84:188	This condition is defined to prevent from extracting eccentric cases, as the ones shown in the examples shown in Figure 6, where the conditions respectively fail: 08 + 3 =5<0 and 17+2 =4<0." ></td>
	<td class="line x" title="85:188	To the horror of their fans , Miss Ball and Arnaz __ ___ ______ __ _____ ____ _ ____ Ball and Arnaz will vote __ ___ _______ ____ __ _____ __ friday . ____ vote on the amended bill as early as friday . Figure 6: Examples of Rejected Bubbles Indeed, we favor examples with high common contexts and few deleted words to enhance the induction process." ></td>
	<td class="line x" title="86:188	So far, we only consider bubbles where the middle region is aligned with a void segment (X transf )." ></td>
	<td class="line x" title="87:188	However, more general transformations will be investigated in the future." ></td>
	<td class="line x" title="88:188	Indeed, any transformation X transf Y, where Y negationslash=, having Z(X) > Z(Y ), may be a relevant compression example." ></td>
	<td class="line x" title="89:188	Following this methodology, we obtain a huge set of examples, where relevant sentence transformations occur." ></td>
	<td class="line x" title="90:188	To have an idea about the amount of data we are working with, from a set of 30 days web news stories (133.5 MB of raw text), we identified and extracted 596678 aligned paraphrases, from which 143761 bubbles were obtained." ></td>
	<td class="line x" title="91:188	In the next section, we show how we explore Inductive Logic Programming (ILP) techniques to generalize regularities and find conditions to compress sentence segments." ></td>
	<td class="line x" title="92:188	4 The Induction of Compression Rules Many different algorithms exist to induce knowledge from data." ></td>
	<td class="line x" title="93:188	In this paper, we use Inductive Logic Programming (ILP) (Muggleton, 1991) and it was a choice based on a set of relevant features like: the capacity to generate symbolic and 18 relational knowledge; the possibility to securely avoid negative instances; the ability to mix different types of attribute and to have more control over the theory search process." ></td>
	<td class="line x" title="94:188	Unlike (Clarke & Lapata, 2006), we aim at inducing human understandable knowledge, also known as symbolic knowledge." ></td>
	<td class="line x" title="95:188	For that purpose, ILP satisfies perfectly this goal by producing clauses based on first order logic." ></td>
	<td class="line x" title="96:188	Moreover, most of the learning algorithms require a complete definition and characterization of the feature set, prior to the learning process, where any attribute must be specified." ></td>
	<td class="line x" title="97:188	This is a conceptual bottleneck to many learning problems such as ours, since we need to combine different types of attributes i.e. lexical, morpho-syntactic and syntactical." ></td>
	<td class="line x" title="98:188	With ILP, we only need to define a set of possible features and the induction process will search throughout this set." ></td>
	<td class="line x" title="99:188	4.1 The Aleph System The Aleph system(Srinivasan, 2000) is an empirical ILP system, initially designed to be a prototype for exploring ILP ideas." ></td>
	<td class="line x" title="100:188	It has become a quite mature ILP implementation, used in many research projects, ranging form Biology to NLP." ></td>
	<td class="line x" title="101:188	In fact, Aleph is the successor of several and more primitive ILP systems, like: Progol (Muggleton, 1999), FOIL (Quinlan, 1990), and Indlog (Camacho, 1994), among others, and may be appropriately parametrized to emulate any of those older systems." ></td>
	<td class="line x" title="102:188	One interesting advantage in Aleph is the possibility to learn exclusively from positive instances, contrarily to what is required by most learning systems." ></td>
	<td class="line x" title="103:188	Moreover, there is theoretical research work (Muggleton, 1996) demonstrating that the increase in the learning error tend to be negligible with the absence of negative examples, as the number of learning instances increases." ></td>
	<td class="line x" title="104:188	This is a relevant issue, for many learning domains, and specially ours, where negative examples are not available." ></td>
	<td class="line x" title="105:188	4.2 Learning Instances In our problem, we define predicates that characterize possible features to be considered during the induction process." ></td>
	<td class="line x" title="106:188	Regarding the structure of our learning instances (bubbles), we define predicates which restrict left and right context sequences as well as the aligned middle sequence." ></td>
	<td class="line x" title="107:188	In particular, we limit the size of our context sequences to a maximum of three words and, so far, only use bubbles in which the middle sequence has a maximum length of three9 words." ></td>
	<td class="line x" title="108:188	The notion of contexts from bubbles is clarified with the next example." ></td>
	<td class="line x" title="109:188	L2 L1 X1 X2 X3 R1 R2 R3 R4 L2 L1 __ __ __ R1 R2 R3 R4 For such a case, we consider [L1, L2] as the left context, [R1, R2, R3] as the right context, and [X1, X2, X3] as the aligned middle sequence." ></td>
	<td class="line x" title="110:188	Such an example is represented with a Prolog term with arity 5 (bub/5) in the following manner: bub(ID, t(3,0), [L1,L2], [X1,X2,X3]--->[], [R1,R2,R3])." ></td>
	<td class="line x" title="111:188	The ID is the identifier of the sequence instance, t/2 defines the transformation dimension, in this case from 3 words to 0." ></td>
	<td class="line x" title="112:188	The third and fifth arguments are lists with the left and right contexts, respectively, and the fourth argument contains the list with the elements deleted from the middle sequence." ></td>
	<td class="line x" title="113:188	It is important to point out that everyLi, Xi andRi are structures with 3 elements such as word/POS/Chunk." ></td>
	<td class="line x" title="114:188	For example, the word president would be represented by the expanded structure president/nn/np." ></td>
	<td class="line x" title="115:188	4.3 Feature Space As mentioned previously, with an ILP system, and in particular with Aleph, the set of attributes is defined through a set of conditions, expressed in the form of predicates." ></td>
	<td class="line x" title="116:188	These predicates are the building blocks that will be employed to construct rules, during the induction process." ></td>
	<td class="line x" title="117:188	Hence, our attribute search space is defined using Prolog predicates, which define the complete set of possibilities for rule body construction." ></td>
	<td class="line x" title="118:188	In our problem, we let the induction engine seek generalization conditions for the bubble main regions (left, middle, and right)." ></td>
	<td class="line x" title="119:188	Each condition may be from one of the four types: dimensional, lexical, POS, and chunk." ></td>
	<td class="line x" title="120:188	Dimensional conditions simply express the aligned sequence transformation dimensionality." ></td>
	<td class="line x" title="121:188	Lexical conditions impose a fixed position to match a given word." ></td>
	<td class="line x" title="122:188	The POS condition is similar to the lexical one, but more general, as the position must match a specific part-of-speech tag." ></td>
	<td class="line x" title="123:188	Likely, chunk conditions bind a region to be equal to a particular chunk type." ></td>
	<td class="line x" title="124:188	For example, by looking 9They represent 83.47% from the total number of extracted bubbles." ></td>
	<td class="line x" title="125:188	19 at Figure 2, the attentive reader may have noticed that these three conditions are present in rule 7." ></td>
	<td class="line x" title="126:188	In terms of Aleph declaration mode, these conditions are defined as follows." ></td>
	<td class="line x" title="127:188	:modeh(1,rule(+bub))." ></td>
	<td class="line x" title="128:188	:modeb(1,transfdim(+bub,n(#nat,#nat)))." ></td>
	<td class="line x" title="129:188	:modeb(3,chunk(+bub,#side,#chk))." ></td>
	<td class="line x" title="130:188	:modeb(*,inx(+bub,#side,#k,#tword))." ></td>
	<td class="line x" title="131:188	:determination(rule/1,transfdim/2)." ></td>
	<td class="line x" title="132:188	:determination(rule/1,chunk/3)." ></td>
	<td class="line x" title="133:188	:determination(rule/1,inx/4)." ></td>
	<td class="line x" title="134:188	The inx/4 predicate defines lexical and POS type conditions, the chunk/3 predicate defines chunking conditions and the transfdim/2 predicate defines the transformation dimensionality, which is in the form transfdim(N,0) with N>0, according to the kind of bubbles we are working with." ></td>
	<td class="line x" title="135:188	4.4 The Rule Value Function The Aleph system implements many different evaluation10 functions which guide the theory search process, allowing the basic procedure for theory construction to be altered." ></td>
	<td class="line x" title="136:188	In order to better fit to our problem, we define a new evaluation function calculated as the geometrical mean between the coverage percentage and the rule size value, as shown in Equation 11 whereRis the candidate rule and Cov(R) is the proportion of positive instances covered by R and the LV() function defines the rule value in terms of its length, returning a value in the [0,1] interval." ></td>
	<td class="line x" title="137:188	Value(R) = p Cov(R)LV(R) (11) The Value() function guides the induction process, by preferring not too general rules having maximum possible coverage value." ></td>
	<td class="line x" title="138:188	As shown in Figure 7, the Value() function gives preferences to rules with 3, 4 and 5 literals." ></td>
	<td class="line x" title="139:188	5 Results The automatic evaluation of a system is always the best way to do it, due to its objectivity and scalability." ></td>
	<td class="line x" title="140:188	However, in many cases it is unfeasible for several practical reasons, like the unavailability of data or the difficulty to prepare an appropriate 10In the Aleph terminology, this function is named as the cost function, despite the fact that it really computes the value in the sense that the grater the value, the more likely it is to be chosen." ></td>
	<td class="line x" title="141:188	0 10 20 30 40 50 60 70 80 90 100 10 25 50 90 60 40 20 1 2 3 4 5 6 7 no clauses value Figure 7: Rule length value function dataset." ></td>
	<td class="line x" title="142:188	Some supervised learning approach use manually labeled test sets to evaluated their systems." ></td>
	<td class="line x" title="143:188	However, these are small test sets, for example, (Knight & Marcu, 2002) use a set of 1035 sentences to train the system and only 32 sentences to test it, which is a quite small test set." ></td>
	<td class="line x" title="144:188	As a consequence, it is also important to propose more through evaluation." ></td>
	<td class="line x" title="145:188	In order to assess as clearly as possible the performance of our methodology on large datasets, we propose a set of qualitative and quantitative evaluations based on three different measures: Utility, Ngram simplification and Correctness." ></td>
	<td class="line x" title="146:188	5.1 Evaluation A relevant issue, not very commonly discussed, is the Utility of a learned theory." ></td>
	<td class="line x" title="147:188	In real life problems, people may be more interested in the volume of data processed than the quality of the results." ></td>
	<td class="line x" title="148:188	Maybe, between a system which is 90% precise and processes only 10% of data, and a system with 70% precision, processing 50% of data, the user would prefer the last one." ></td>
	<td class="line x" title="149:188	The Utility may be a stronger than the Recall measure, used for the evaluation of supervised learning systems, because the later measures how many instances were well identified or processed from the test set only, and the former takes into account the whole universe." ></td>
	<td class="line x" title="150:188	For example, in a sentence compression system, it is important to know how many sentences would be compressed, from the whole possible set of sentences encountered in electronic news papers, or in classical literature books, or both." ></td>
	<td class="line x" title="151:188	This is what we mean here by Utility." ></td>
	<td class="line x" title="152:188	The Ngram-Simplification methodology is an automatic extrinsic test, performed to perceive how much a given sentence reduction ruleset would simplify sentences in terms of syntactical complexity." ></td>
	<td class="line x" title="153:188	The answer is not obvious at first sight, because even smaller sentences can contain 20 more improbable syntactical subsequences than their uncompressed versions." ></td>
	<td class="line x" title="154:188	To evaluate the syntactical complexity of a sentence, we use a 4 gram model and compute a relative11 sequence probability as defined in Equation 12 where vectorW = [t1,t2,,tm] is the sequence of part-of-speech tags for a given sentence with size m. P{vectorW}= mnY k=n P{tk|tk1,,tkn}  1 m (12) The third evaluation is qualitative." ></td>
	<td class="line x" title="155:188	We measure the quality of the learned rules when applied to sentence reduction." ></td>
	<td class="line x" title="156:188	The objective is to assess how correct is the application of the reduction rules." ></td>
	<td class="line x" title="157:188	This evaluation was made through manual annotation for a statistically representative random sample of compressed sentences." ></td>
	<td class="line x" title="158:188	A human judged the adequacy and Correctness of each compression rule to a given sentence segment, in a scale from 1 to 5, where 1 means that it is absolutely incorrect and inadequate, and 5 that the compression rule fits perfectly to the situation (sentence) being analyzed." ></td>
	<td class="line x" title="159:188	To perform our evaluation, a sample of 300 sentences were randomly extracted, where at least one compression rule had been applied." ></td>
	<td class="line x" title="160:188	This evaluation set may be subdivided into three subsets, where 100 instances came from rules withZ(X) = 1 (BD1), 100 from rules with Z(X) = 2 (BD2), and the other 100 from rules with Z(X) = 3 (BD3)." ></td>
	<td class="line x" title="161:188	Another random sample, also with 100 cases has been extracted to evaluate our base-line (BL) which consists in the direct application of the bubble set to make compressions." ></td>
	<td class="line x" title="162:188	This means that no learning process is performed." ></td>
	<td class="line x" title="163:188	Instead, we store the complete bubble set as if they were rules by themselves (in the same manner as (Le Nguyen & Ho, 2004) do)." ></td>
	<td class="line x" title="164:188	Table 1 compiles the comparative results for Correctness, Precision, Utility and Ngramsimplification for all datasets." ></td>
	<td class="line x" title="165:188	In particular, Ngram-simplification in percentage is the proportion of test cases where P{reduced(vectorW)}  P{vectorW}." ></td>
	<td class="line x" title="166:188	Table 1 provides evidence of the improvement achieved with the induction rules, in comparison with the base line, on each test parameter: Correctness, Utility and Ngram-simplification." ></td>
	<td class="line x" title="167:188	Con11Because it is raised to the inverse power of m, which is the number of words in the sentence." ></td>
	<td class="line x" title="168:188	Parameter BL BD1 BD2 BD3 Correctness: 2.93 3.56 4.03 4.01 Precision: 58.60% 71.20% 80.60% 80.20% Utility: 8.65% 32.67% 85.72% 26.86% NG-Simpl: 47.39% 89.33% 90.03% 89.23% Table 1: Results with Four Evaluation Parameters." ></td>
	<td class="line x" title="169:188	sidering the three experiences, BD1, BD2, and BD3, as a unique evaluation run, we obtained a mean Correctness quality of 3.867 (i.e. 77.33% Precision), a mean Utility of 48.45%, and a mean Ngram-simplification equal to 89.53%, which are significantly better than the base line." ></td>
	<td class="line x" title="170:188	Moreover, best results overall are obtained for BD2 with 80.6% Precision, 85.72% Utility and 90.03% Ngram-simplification which means that we can expect a reduction of two words with high quality for a great number of sentences." ></td>
	<td class="line x" title="171:188	In particular, Figure 2 shows examples of learned rules." ></td>
	<td class="line x" title="172:188	5.2 Time Complexity In the earlier12 days of ILP, the computation time spent by their systems was a serious difficult obstacle, disabling its implementation for real life problems." ></td>
	<td class="line x" title="173:188	However, nowadays these time efficiency issues have been overcome, opening a wide range of application possibilities, for many problems, from Biology to Natural Language Processing." ></td>
	<td class="line x" title="174:188	The graph in figure 8, shows that even with considerable big datasets, our learning system (based on Aleph) evidences acceptable feasible computation time." ></td>
	<td class="line x" title="175:188	0 20 40 60 80 100 120 140 12 27 0 53 0 120 0 10 20 30 40 50 60 103 bubbles seconds Figure 8: Time spent during the induction process, for datasets with size expressed in thousands of bubbles." ></td>
	<td class="line x" title="176:188	To give an idea about the size of an induced rule set, and taking as an example the learned rules 12In the 1990-2000 decade." ></td>
	<td class="line x" title="177:188	21 with Z(X) = 2, these were learned from a dataset containing 37271 t(2,0) bubbles, and in the final 5806 sentence reduction rules were produced." ></td>
	<td class="line x" title="178:188	6 Conclusion and Future Directions Sentence Compression is an active research topic, where several relevant contributions have recently been proposed." ></td>
	<td class="line x" title="179:188	However, we believe that many milestones still need to be reached." ></td>
	<td class="line x" title="180:188	In this paper, we propose a new framework in the form of a pipeline, which processes huge sets of web news articles and retrieves compression rules in an unsupervised way." ></td>
	<td class="line x" title="181:188	For that purpose, we extract and align paraphrases, explore and select specific text characteristics called bubbles and finally induce a set of logical rules for sentence reduction in a realworld environment." ></td>
	<td class="line x" title="182:188	Although we have only considered bubbles having Z(X) 3, a sentence may have a compression length greater than this value, since several compression rules may be applied to a single sentence." ></td>
	<td class="line x" title="183:188	Our results evidence good practical applicability, both in terms of Utility, Precision and Ngramsimplification." ></td>
	<td class="line x" title="184:188	In particular, we assess results up to 80.6% Precision, 85.72% Utility and 90.03% Ngram-simplification for reduction rules of two word length." ></td>
	<td class="line x" title="185:188	Moreover, results were compared to a base line set of rules produced without learning and the difference reaches a maximum improvement using Inductive Logic Programming of 22%." ></td>
	<td class="line x" title="186:188	Acknowledgments This work was supported by the VIPACCESS project Ubiquitous Web Access for Visually Impaired People." ></td>
	<td class="line x" title="187:188	Funding Agency: Fundac ao para a Ciencia e a Tecnologia (Portugal)." ></td>
	<td class="line x" title="188:188	Reference: PTDC/PLP/72142/2006." ></td>
</tr></table>
</div
</body></html>
