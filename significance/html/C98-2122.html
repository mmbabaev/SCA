<html><body><head><link rel="stylesheet" type="text/css" href="style.css" /><script src="map.js"></script><script src="jquery-1.7.1.min.js"></script></head>
<div class="dstPaperData">
C98-2122 <div class="dstPaperTitle">Automatic Retrieval and Clustering of Similar Words</div><div class="dstPaperAuthors">Lin, Dekang;</div>
</div>
<table cellspacing="0" cellpadding="0"><tr>
	<td class="srcData" >Source Paper</td>
	<td class="pp legend" ><input type="checkbox" id="cbIPositive" checked="true"/><label for="cbIPositive">Informal +<label></td>
	<td class="nn legend" ><input type="checkbox" id="cbINegative" checked="true"/><label for="cbINegative">Informal -<label></td>
	<td class="oo legend" ><input type="checkbox" id="cbIObjective" checked="true"/><label for="cbIObjective">Informal Neutral<label></td>
	<td class="ppc legend" ><input type="checkbox" id="cbEPositive" checked="true"/><label for="cbEPositive">Formal +</label></td>
	<td class="nnc legend" ><input type="checkbox" id="cbENegative" checked="true"/><label for="cbENegative">Formal -</label></td>
	<td class="ooc legend" ><input type="checkbox" id="cbEObjective" checked="true"/><label for="cbEObjective">Formal Neutral</label></td>
	<td class="lb"><input type="checkbox" id="cbSentenceBoundary"/><label for="cbSentenceBoundary">Sentence Boundary</label></td>
</tr></table>
<div class="dstPaper">
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1009
Good Neighbors Make Good Senses: Exploiting Distributional Similarity for Unsupervised WSD
Brody, Samuel;Lapata, Mirella;"></td>
	<td class="line x" title="1:223	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 6572 Manchester, August 2008 Good Neighbors Make Good Senses: Exploiting Distributional Similarity for Unsupervised WSD Samuel Brody School of Informatics University of Edinburgh s.brody@sms.ed.ac.uk Mirella Lapata School of Informatics University of Edinburgh mlap@inf.ed.ac.uk Abstract We present an automatic method for senselabeling of text in an unsupervised manner." ></td>
	<td class="line x" title="2:223	The method makes use of distributionally similar words to derive an automatically labeled training set, which is then used to train a standard supervised classifier for distinguishing word senses." ></td>
	<td class="line x" title="3:223	Experimental results on the Senseval-2 and Senseval-3 datasets show that our approach yields significant improvements over state-of-the-art unsupervised methods, and is competitive with supervised ones, while eliminating the annotation cost." ></td>
	<td class="line x" title="4:223	1 Introduction Word sense disambiguation (WSD), the task of identifying the intended meaning (sense) of words in context, is a long-standing problem in Natural Language Processing." ></td>
	<td class="line x" title="5:223	Sense disambiguation is often characterized as an intermediate task, which is notanendinitself,buthasthepotentialtoimprove many applications." ></td>
	<td class="line x" title="6:223	Examples include summarization (Barzilay and Elhadad, 1997), question answering (Ramakrishnan et al., 2003) and machine translation (Chan and Ng, 2007)." ></td>
	<td class="line x" title="7:223	WSD is commonly treated as a supervised classification task." ></td>
	<td class="line x" title="8:223	Assuming we have access to data that has been hand-labeled with correct word senses, we can train a classifier to assign senses to unseen words in context." ></td>
	<td class="line x" title="9:223	While this approach often achieves high accuracy, adequately large sense labeled data sets are unfortunately difficult to obtain." ></td>
	<td class="line x" title="10:223	For many words, domains, languages, and sense inventories they are unavailable, and c2008." ></td>
	<td class="line x" title="11:223	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="12:223	Some rights reserved." ></td>
	<td class="line x" title="13:223	in most cases it is unreasonable to expect to acquire them." ></td>
	<td class="line x" title="14:223	Ng (1997) estimates that a high accuracy domain-independent system for WSD would probably need a corpus of about 3.2 million sense tagged words." ></td>
	<td class="line x" title="15:223	At a throughput of one word per minute (Edmonds, 2000), this would require about 27 person-years of human annotation effort." ></td>
	<td class="line x" title="16:223	SemCor (Fellbaum, 1998) is one of the few corpora that have been manually annotated for all words  it contains sense labels for 23,346 lemmas." ></td>
	<td class="line x" title="17:223	In spite of being widely used, SemCor contains too few tagged instances for the majority of polysemous words (typically fewer than 10 each)." ></td>
	<td class="line x" title="18:223	Supervised methods require much larger data sets than this to perform adequately." ></td>
	<td class="line x" title="19:223	The problem of obtaining sufficient labeled data, often referred to as the data acquisition bottleneck, creates a significant barrier to the use of supervised WSD methods in real world applications.Inthisworkwewishtotakeadvantageofthe highaccuracyandstrongcapabilitiesofsupervised methods,whileeliminatingtheneedforhumanannotation of training data." ></td>
	<td class="line x" title="20:223	Our approach exploits a senseinventorysuchasWordNet(Fellbaum,1998) and corpus data to automatically create a collection of sense labeled instances which can subsequentlyservetotrainanysupervisedclassifier.The key premise of our work is that a words senses can be broadly described by semantically related words." ></td>
	<td class="line x" title="21:223	So, rather than laboriously annotating all instances ofa polysemous word withits senses, we collectinstancesofitsrelatedwordsandtreatthem as sense labels for the target word." ></td>
	<td class="line x" title="22:223	The method is inexpensive, language-independent, and can be used to create large sense-labeled data without human intervention." ></td>
	<td class="line x" title="23:223	Our results demonstrate significant improvements over state-of-the-art unsupervised methods that do not make use of handlabeled annotations." ></td>
	<td class="line x" title="24:223	In the following section we provide an overview 65 of existing work on unsupervised WSD." ></td>
	<td class="line x" title="25:223	Section 3 introduces our method for automatically creating sense annotations." ></td>
	<td class="line x" title="26:223	We present our evaluation framework in Section 4 and results in Section 5." ></td>
	<td class="line x" title="27:223	2 Related Work ThedatarequirementsforsupervisedWSDandthe current paucity of suitably annotated corpora for many languages and text genres, has sparked considerable interest in unsupervised methods." ></td>
	<td class="line x" title="28:223	These typically come in two flavors: (1) developing algorithms that assign word senses without relying on a sense-labeled corpus (Lesk, 1986; Galley and McKeown, 2003) and (2) making use of pseudolabels, i.e., labelled data that has not been specifically annotated for sense disambiguation purposes but contains some form of sense distinctions (Gale et al., 1992; Leacock et al., 1998)." ></td>
	<td class="line x" title="29:223	We briefly discuss representative examples of both approaches, with a bias to those closely related to our own work." ></td>
	<td class="line x" title="30:223	Unsupervised Algorithms One of the first approaches to unsupervised WSD, and the foundation of many algorithms to come, was originally introduced by Lesk (1986)." ></td>
	<td class="line x" title="31:223	The method assigns a sensetoatargetambiguouswordbycomparingthe dictionary definitions of each of its senses with the wordsinthesurroundingcontext.Thesensewhose definition has the highest overlap (i.e., words in common) with the context is assumed to be the correct one." ></td>
	<td class="line x" title="32:223	Despite its simplicity, the algorithm provides a good baseline for comparison." ></td>
	<td class="line x" title="33:223	Coverage can be increased by augmenting the dictionary definition (gloss) of each sense with the glosses of related words and senses (Banerjee and Pedersen, 2003)." ></td>
	<td class="line x" title="34:223	Although most algorithms disambiguate word senses in context, McCarthy et al.(2004) propose a method that does not rely on contextual cues." ></td>
	<td class="line x" title="36:223	Their algorithm capitalizes on the fact that the distribution of word senses is highly skewed." ></td>
	<td class="line x" title="37:223	A large number of frequent words is often associated with one dominant sense." ></td>
	<td class="line x" title="38:223	Indeed, current supervised methods rarely outperform the simple heuristic of choosing the most common sense in the training data(henceforththefirstsenseheuristic),despite taking local context into account." ></td>
	<td class="line x" title="39:223	Rather than obtaining the first sense via annotating word senses manually, McCarthy et al. propose to acquire first sensesautomaticallyandusethemfordisambiguation." ></td>
	<td class="line x" title="40:223	Thus, by design, their algorithm assigns the same sense to all instances of a polysemous word." ></td>
	<td class="line x" title="41:223	Their approach is based on the observation that distributionally similar neighbors often provide cues about a words senses." ></td>
	<td class="line x" title="42:223	Assuming that a set of neighbors is available, the algorithm quantifies the degree of similarity between the neighbors and the sense descriptions of the polysemous word." ></td>
	<td class="line x" title="43:223	The sense with the highest overall similarity is the first sense." ></td>
	<td class="line x" title="44:223	Specifically, the approach makes use of two similarity measures which complement each other and provide a large amount of data regarding the word senses." ></td>
	<td class="line x" title="45:223	Distributional similarity indicates the similarity between words in the distributional feature space, whereas WordNet similarity in the semantic space, is used to discover which sense of the ambiguous word is used in the corpus, and causing the distributional similarity." ></td>
	<td class="line x" title="46:223	Pseudo-labels as Training Instances Gale et al.(1992) pioneered the use of parallel corpora as a source of sense-tagged data." ></td>
	<td class="line x" title="48:223	Their key insight is that different translations of an ambiguous word can serve to distinguish its senses." ></td>
	<td class="line x" title="49:223	Ng et al.(2003) extend this approach further and demonstrate that it is feasible for large scale WSD." ></td>
	<td class="line x" title="51:223	They gather examples from English-Chinese parallel corpora and use automatic word alignment as a means of obtaining a translation dictionary." ></td>
	<td class="line x" title="52:223	Translations are next assigned to senses of English ambiguous words." ></td>
	<td class="line x" title="53:223	English instances corresponding to these translations serve as training data." ></td>
	<td class="line x" title="54:223	It has become common to use related words fromadictionarytolearncontextualcuesforWSD (Mihalcea, 2002)." ></td>
	<td class="line x" title="55:223	Perhaps the first incarnation of this idea is found in Leacock et al.(1998), who describe a system for acquiring topical contexts that can be used to distinguish between senses." ></td>
	<td class="line x" title="57:223	For each sense, related monosemous words are extracted from WordNet using the various relationship connections between sense entries (e.g., hyponymy, hypernymy)." ></td>
	<td class="line x" title="58:223	Their system then queries the Web with these related words." ></td>
	<td class="line x" title="59:223	The contexts surrounding the relatives of a specific sense are presumed to be indicators of that sense, and used for disambiguation." ></td>
	<td class="line x" title="60:223	A similar idea, proposed by Yarowsky (1992), is to use a thesaurus and acquire informative contexts from words in the same category as the target." ></td>
	<td class="line x" title="61:223	Our own work uses insights gained from unsupervised methods with the aim of creating large datasetsofsense-labeledinstanceswithoutexplicit manual coding." ></td>
	<td class="line x" title="62:223	Unlike Ng et al.(2003) our algorithm works on monolingual corpora, which are 66 much more abundant than parallel ones, and is fully automatic." ></td>
	<td class="line x" title="64:223	In their approach translations and their English senses must be associated manually." ></td>
	<td class="line x" title="65:223	Similarly to McCarthy et al.(2004), we assume that words related to the target word are useful indicators of its senses." ></td>
	<td class="line x" title="67:223	Importantly, our method disambiguates words in context and is able to assign additional senses, besides the first one." ></td>
	<td class="line x" title="68:223	3 Method As discussed earlier, our aim is to alleviate the need for manual annotation by creating a large dataset labeled with word senses without human intervention." ></td>
	<td class="line x" title="69:223	This dataset can be subsequently used by any supervised machine learning algorithm." ></td>
	<td class="line x" title="70:223	We assume here that we have access to a corpus and a sense inventory." ></td>
	<td class="line x" title="71:223	We first obtain a list of words that are semantically related to our target word." ></td>
	<td class="line x" title="72:223	In the remainder of this paper we use the term neighbors to refer to these words." ></td>
	<td class="line x" title="73:223	Next, we separate the neighbors into sense-specific groups." ></td>
	<td class="line x" title="74:223	Finally, we replace the occurrences of each neighbor in our corpus with an instance of the target word, labeled with the matching sense for that neighbor." ></td>
	<td class="line x" title="75:223	The procedure has two important steps: (1) acquiring neighbors and (2) associating them with appropriate senses." ></td>
	<td class="line x" title="76:223	We describe our implementation of each stage in more detail below." ></td>
	<td class="line x" title="77:223	Neighbor Acquisition Considerable latitude is allowedinspecifyingappropriateneighborsforthe target word." ></td>
	<td class="line x" title="78:223	Broadly speaking, the neighbors can be extracted from a corpus or from a semantic resource, for example the dictionary providing the sense inventory." ></td>
	<td class="line x" title="79:223	A wealth of algorithms have been proposed in the literature for acquiring distributional neighbors from a corpus (see Weeds (2003) for an overview)." ></td>
	<td class="line x" title="80:223	They differ as to which features they consider and how they use the distributional statistics to calculate similarity." ></td>
	<td class="line pc" title="81:223	Lins (1998) information-theoretic similarity measure is commonly used in lexicon acquisition tasks and has demonstrated good performance in unsupervised WSD (McCarthy et al., 2004)." ></td>
	<td class="line o" title="82:223	It operates over dependency relations." ></td>
	<td class="line x" title="83:223	A word w is described by a set T(w) of co-occurrence triplets < w,r,wprime >, which can be viewed as a sparsely represented feature vector, where r represents the type of relation (e.g., object-of, subject-of, modified-by) between w and its dependent wprime." ></td>
	<td class="line x" title="84:223	The similarity between w1 and w2 is then defined as:  (r,w)T(w1)T(w2) I(w1,r,w)+I(w2,r,w)  (r,w)T(w1) I(w1,r,w)+  (r,w)T(w2) I(w2,r,w) where I(w,r,wprime) is the information value of w with regard to (r,wprime), defined as: I(w,r,wprime)=log count(w,r,w prime)count(r) count(,r,wprime)count(w,r,) The measure is used to estimate the pairwise similarity between the target word and all other words in the corpus (with the same part of speech); the k words most similar to the target are selected as its neighbors." ></td>
	<td class="line nc" title="85:223	A potential caveat with Lins (1998) distributional similarity measure is its reliance on syntactic information for obtaining dependency relations." ></td>
	<td class="line x" title="86:223	Parsing resources may not be available for all languages or domains." ></td>
	<td class="line x" title="87:223	An alternative is to use a measure of distributional similarity which considers word collocation statistics and therefore does not require a syntactic parser (see Weeds (2003))." ></td>
	<td class="line x" title="88:223	As mentioned earlier, it is also possible to obtain neighbors simply by consulting a semantic dictionary." ></td>
	<td class="line x" title="89:223	In WordNet, for example, we can assume that WordNet relations, (e.g., hypernymy, hyponymy, synonymy) indicate words which are semantic neighbors." ></td>
	<td class="line x" title="90:223	An advantage of using distributional neighbors is that they reflect the characteristics of the corpus we wish to disambiguate andarepotentiallybettersuitedforcapturingsense differences across genres and domains, whereas dictionary-based neighbors are corpus-invariant." ></td>
	<td class="line x" title="91:223	Associating Neighbors with Senses If the neighbors are extracted from WordNet, it is not necessary to associate them with their senses as they are already assigned a specific sense." ></td>
	<td class="line x" title="92:223	Distributional similarity methods, however, do not provide a way to distinguish which neighbors pertain to each sense of the target." ></td>
	<td class="line x" title="93:223	For that purpose, we adapt a method proposed by McCarthy et al.(2004)." ></td>
	<td class="line x" title="95:223	Specifically, for each acquired neighbor, we choose the sense of the target which gives the highest semantic similarity score to any sense of the neighbor." ></td>
	<td class="line x" title="96:223	There are a large number of semantic similarity measures to choose from (see Budanitsky and Hirst (2001) for an overview)." ></td>
	<td class="line x" title="97:223	We use Lesks measure as modified by Banerjee and Pedersen (2003) for two reasons." ></td>
	<td class="line x" title="98:223	First, it has 67 been shown to perform well in the related task of predominant sense detection (McCarthy et al., 2004)." ></td>
	<td class="line x" title="99:223	Second, it has the advantage of relying only upon the sense definitions, rather than the complex graph structure which is unique to WordNet." ></td>
	<td class="line x" title="100:223	This makes the method more suitable for use with other sense inventories." ></td>
	<td class="line x" title="101:223	Note that unlike McCarthy et al.(2004), we are associating neighbors with senses, rather than merely trying to detect the predominant sense, and therefore we require more precision in our selection." ></td>
	<td class="line x" title="103:223	When it is unclear which sense of the target word is most similar to a given neighbor (when the scores of two or more senses are close together), that neighbor is discarded." ></td>
	<td class="line x" title="104:223	As an example, consider the word sense, which has four meanings1 in WordNet: (1) a general consciousawareness(e.g., a sense of security),(2)the meaning of a word (e.g., the dictionary gave several senses for the word), (3) sound practicaljudgment (e.g., I cant see the sense in doing it now), and (4) a natural appreciation or ability (e.g., keen musical sense)." ></td>
	<td class="line oc" title="105:223	On the British National Corpus (BNC), using Lins (1998) similarity method, we retrieve the following neighbors for the first and second sense, respectively: 1." ></td>
	<td class="line x" title="106:223	awareness, feeling, instinct, enthusiasm, sensation,vision,tradition,consciousness,anger, panic, loyalty 2." ></td>
	<td class="line x" title="107:223	emotion, belief, meaning, manner, necessity, tension, motivation No neighbors are associated with the last two senses, indicating that they are not prevalent enough in the BNC to be detected by this method." ></td>
	<td class="line x" title="108:223	Once sense-specific neighbors are acquired, the next stage is to replace all instances of the neighbors in the corpus with the target ambiguous word labeled with the appropriate sense." ></td>
	<td class="line x" title="109:223	For example, when encountering the sentence  attempt to state the meaning of a word, our method would automatically transform this to  attempt to state the sense (s#2) of a word. These pseudo-labeled instances comprise the training instances we provide to our machine learning algorithms." ></td>
	<td class="line x" title="110:223	4 Experimental Setup We evaluated the performance of our approach on benchmark datasets." ></td>
	<td class="line x" title="111:223	In this section we give details 1We are using the coarse-grained representation according to Senseval 2 annotators." ></td>
	<td class="line x" title="112:223	The sense definitions are simplified for the sake of brevity." ></td>
	<td class="line x" title="113:223	regarding our training and test data, and describe the features and machine learners we employed." ></td>
	<td class="line x" title="114:223	Finally, we discuss the methods to which we compare our approach." ></td>
	<td class="line x" title="115:223	4.1 Data Our experiments use a subset of the data provided for the English lexical sample task in the Senseval 2 (Preiss and Yarowsky, 2001) and Senseval 3 (Mihalcea and Edmonds, 2004) evaluation exercises." ></td>
	<td class="line x" title="116:223	Since our method does not require hand taggedtrainingdata,wemergedtheprovidedtraining and test data into a single test set." ></td>
	<td class="line x" title="117:223	As a proof of concept we focus on the disambiguationofnouns,sincetheyconstitutethelargest portion of content words (50% in the BNC)." ></td>
	<td class="line x" title="118:223	In addition, WordNet, which is our semantic resource and point of comparison, has a wide coverage of nouns." ></td>
	<td class="line x" title="119:223	Also, for many tasks and applications (e.g., web queries) nouns are the most frequently encountered part-of-speech (Jansen et al., 2000)." ></td>
	<td class="line x" title="120:223	We made use of the coarse-grained sense groupings provided for both Senseval datasets." ></td>
	<td class="line x" title="121:223	For many applications (e.g., information retrieval) coarsely defined senses are more useful (see Snow et al.(2007) for discussion)." ></td>
	<td class="line x" title="123:223	Our training data was created from the BNC usingdifferentwaysofobtainingtheneighborsofthe target word." ></td>
	<td class="line oc" title="124:223	As described in Section 3 we retrieved neighbors using Lins (1998) similarity measure on a RASP parsed (Briscoe and Carroll, 2002) version of the BNC." ></td>
	<td class="line x" title="125:223	We used subject and object dependencies, as well as adjective and noun modifier dependencies." ></td>
	<td class="line x" title="126:223	We also created training data sets using collocational neighbors." ></td>
	<td class="line x" title="127:223	Specifically, using the InfoMap toolkit2, we constructed vector-based representationsforindividualwordsfromtheBNC using a term-document matrix and the cosine similarity measure." ></td>
	<td class="line x" title="128:223	Vectors were initially constructed with 1,000 dimensions, the most frequent content words." ></td>
	<td class="line x" title="129:223	The space was reduced to 100 dimensions with singular value decomposition." ></td>
	<td class="line x" title="130:223	Finally, we also extracted neighbors from WordNet using first-order and sibling relations (i.e., hyponyms of thesamehypernym).Aproblemoftenencountered when using dictionary-based neighbors is that they are themselves polysemous, and the related sense is often not the most prominent one in the corpus, which leads to noisy data." ></td>
	<td class="line x" title="131:223	We therefore experimented with using all neighbors for a given word 2http://infomap.stanford.edu/ 68 The philosophical explanation of authority is not an attempt to state the sense of a word. Contextual features 10 words explanation, of, authority, be,  5 words an, attempt, to, state, of, a,  Collocational features -2/+0 n-gram state the X -1/+1 n-gram the X of -0/+2 n-gram X of a -2/+0 POS n-gram Verb Det X -1/+1 POS n-gram Det X Prep -0/+2 POS n-gram X Prep Det Syntactic features Object of Verb obj of state Table 1: Example sentence and extracted features for the word sense; X denotes the target word." ></td>
	<td class="line x" title="132:223	or only those which are monosemous and hopefully less noisy." ></td>
	<td class="line x" title="133:223	In all cases we used 50 neighbors, the most similar nouns to the target." ></td>
	<td class="line x" title="134:223	4.2 Features We used a rich feature space based on lemmas, part-of-speech (POS) tags and a variety of positionalandsyntacticrelationshipsofthetargetword capturing both immediate local context and wider context.Thesefeaturetypeshavebeenwidelyused in WSD algorithms (see Lee and Ng (2002) for an evaluationoftheireffectiveness).Theiruseisillustrated on a sample English sentence for the target word sense in Table 1." ></td>
	<td class="line x" title="135:223	4.3 Supervised Classifiers One of our evaluation goals was to examine the effect of our training-data creation procedure on different types of classifiers and determine which ones are most suited for use with our method." ></td>
	<td class="line x" title="136:223	We therefore chose three supervised classifiers (support vector machines, maximum entropy, and label propagation) which are based on different learning paradigms and have shown competitive performance in WSD (Niu et al., 2005; Preiss and Yarowsky, 2001; Mihalcea and Edmonds, 2004)." ></td>
	<td class="line x" title="137:223	We summarize below their main characteristics and differences." ></td>
	<td class="line x" title="138:223	Support Vector Machines SVMs model classification as the problem of finding a separating hyperplane in a high dimensional vector space." ></td>
	<td class="line x" title="139:223	They focus on differentiating between the most problematic cases  instances which are close to each other in the high dimensional space, but have different labels." ></td>
	<td class="line x" title="140:223	They are discriminative, rather than generative, and do not explicitly model the classes." ></td>
	<td class="line x" title="141:223	SVMs have been applied successfully in many NLP tasks." ></td>
	<td class="line x" title="142:223	We used the multi-class boundconstrained support vector classification (SVC) version of SVM described in Hsu and Lin (2001) and implemented in the BSVM package3." ></td>
	<td class="line x" title="143:223	All parameters were set to their default values with the exception of the misclassification penalty, which was set to a high value (1,000) to penalize labeling all instances with the most frequent sense." ></td>
	<td class="line x" title="144:223	Maximum Entropy Model Maximum entropybased classifiers are a common alternative to other probabilistic classifiers, such as Naive Bayes, and have received much interest in various NLP tasks ranging from part-of-speech tagging to parsing andtextclassification." ></td>
	<td class="line x" title="145:223	Theyrepresentaprobabilistic, global constrained approach." ></td>
	<td class="line x" title="146:223	They assume a uniform, zero-knowledge model, under the constraints of the training dataset." ></td>
	<td class="line x" title="147:223	The classifier finds the (unique) maximal entropy model which conforms to the expected feature distribution of the trainingdata.Inourexperiments,weusedMegam4 a publicly available maximum entropy classifier (Daume III, 2004) with the default parameters." ></td>
	<td class="line x" title="148:223	Label Propagation The basic Label Propagation algorithm (Zhu and Ghahramani, 2002) represents labeled and unlabeled instances as nodes in an undirected graph with weighted edges." ></td>
	<td class="line x" title="149:223	Initially only the known data nodes are labeled." ></td>
	<td class="line x" title="150:223	The goal is to propagate labels from labeled to unlabeled points along the weighted edges." ></td>
	<td class="line x" title="151:223	The weights are based on distance in a high-dimensional space." ></td>
	<td class="line x" title="152:223	At each iteration, only the original labels are fixed, whereas the propagated labels are soft, and may change in subsequent iterations." ></td>
	<td class="line x" title="153:223	This property allows the final labeling to be affected by more distant labels, that have propagated further, and gives the algorithm a global aspect." ></td>
	<td class="line x" title="154:223	We used SemiL5, a publicly available implementation of label propagation (all parameters were set to default values)." ></td>
	<td class="line x" title="155:223	4.4 Comparison with State-of-the-art As an upper bound, we considered the accuracy of our classifiers when trained on the manuallylabeled Senseval data (using the same experimental settings and 5-fold crossvalidation)." ></td>
	<td class="line x" title="156:223	This can be used to estimate the expected decrease in accuracy caused solely by the use of our automatic sense labeling method." ></td>
	<td class="line x" title="157:223	We also compared our approach to other unsupervised ones." ></td>
	<td class="line x" title="158:223	These include McCarthy 3http://www.csie.ntu.edu.tw/cjlin/bsvm/ 4http://www.isi.edu/hdaume/megam/index.html 5http://www.engineers.auckland.ac.nz/vkec001 69 et al.s (2004) method for inferring the predominant sense and Lesks (1986) algorithm." ></td>
	<td class="line x" title="159:223	We modified the latter slightly so as to increase its coverage and used McCarthy et al.s first sense heuristic to disambiguateunknowninstanceswherenooverlap was found." ></td>
	<td class="line x" title="160:223	For McCarthy et al. we used parameters they report as optimal." ></td>
	<td class="line x" title="161:223	5 Results The evaluation of our method was motivated by three questions: (1) How do different choices in constructing the pseudo-labeled training data affect WSD performance?" ></td>
	<td class="line x" title="162:223	Here, we would like to assess whether the origin of the target word neighbors (e.g., from a corpus or dictionary) matters." ></td>
	<td class="line x" title="163:223	(2) What is the degree of noise and subsequent loss in accuracy incurred by our method?" ></td>
	<td class="line x" title="164:223	(3) How does the proposed approach compare against other unsupervised methods?" ></td>
	<td class="line x" title="165:223	In particular, we are interested to find out whether we outperform McCarthy et al.s (2004) related method for predominant sense detection." ></td>
	<td class="line x" title="166:223	5.1 The Choice of Neighbors Our results are summarized in Table 2." ></td>
	<td class="line x" title="167:223	We report accuracy (rather than F-score) since all algorithms labeled all instances." ></td>
	<td class="line x" title="168:223	The three center columns present our results with the automatically constructed training sets." ></td>
	<td class="line pc" title="169:223	The best accuracies are observed when the labelsarecreatedfromdistributionallysimilarwords using Lins (1998) dependency-based similarity measure (Depend)." ></td>
	<td class="line x" title="170:223	We observe a small decrease in performance (within the range of 2%4%) when using collocational neighbors without any syntactic information.6 Using the neighbors provided by WordNet leads to worse results than using distributional neighbors." ></td>
	<td class="line x" title="171:223	The differences in performance are significant7 (p < 0.01) on both SensevaldatasetsforallclassifiersandforbothWordNet configurations, i.e., using all neighbors (AllWN) vs. monosemous ones (MonoWN)." ></td>
	<td class="line x" title="172:223	This result may seem counterintuitive since neighbors provided by a semantic resource are based on expert knowledge and are often more accuratethanthoseobtainedautomatically.However, semantic resources like WordNet are designed to be as general as possible without a specific corpus or domain in mind." ></td>
	<td class="line x" title="173:223	They will therefore provide related words for all senses, even rare ones, 6We omit these results from the table for brevity." ></td>
	<td class="line x" title="174:223	7Throughout, we report significance using a 2 test." ></td>
	<td class="line x" title="175:223	whichmaynotappearinourchosencorpus.Distributional methods, on the other hand, are anchored in the corpus." ></td>
	<td class="line x" title="176:223	The extracted neighbors are usually relevant and representative of the corpus." ></td>
	<td class="line x" title="177:223	Another drawback of resource-based neighbors is that they often do not share local behavior, i.e., they do not appear in the same immediate local context and do not share the same syntax." ></td>
	<td class="line x" title="178:223	For this reason, the useful information that can be extracted from their contexts tends to be topical (e.g., words that are indicative of the domain), rather than local (e.g., grammatical dependencies)." ></td>
	<td class="line x" title="179:223	Topical information is mostly useful when the difference betweensensescanbeattributedtoaspecificdomain." ></td>
	<td class="line x" title="180:223	However, for many words and senses, this is not the case (Leacock et al., 1998)." ></td>
	<td class="line x" title="181:223	5.2 Comparison against Manual Labels The rightmost column of Table 2 shows the accuracy of our classifiers when these are trained on the manually annotated Senseval datasets." ></td>
	<td class="line x" title="182:223	In general, all algorithms exhibit a similar level of performance when trained on hand-coded data, with slightly lower scores for Senseval 3." ></td>
	<td class="line x" title="183:223	On Senseval 2, the SVM is significantly better than the other two classifiers (p < 0.01)." ></td>
	<td class="line x" title="184:223	On Senseval 3, label propagation is significantly worse than the others (p < 0.01)." ></td>
	<td class="line x" title="185:223	The results shown here do not represent the highest achievable performance in a supervised setting, but rather those obtained without extensive parameter tuning." ></td>
	<td class="line x" title="186:223	The best performing systems on coarse-grained nouns in Senseval 2 and 3 (Preiss and Yarowsky, 2001; Mihalcea and Edmonds, 2004) achieved approximately 76% and 80%, respectively." ></td>
	<td class="line x" title="187:223	Besides being more finely tuned, these systems employed more sophisticated learning paradigms (e.g., ensemble learning)." ></td>
	<td class="line x" title="188:223	When we compare the results from the manually labeled data to those achieved with the distributional neighbors, we can see that use of our pseudo-labels results in accuracies that are approximately 810% lower." ></td>
	<td class="line x" title="189:223	Since the results were achieved using the same feature set and classifier settings, the comparison provides an estimate of the expected decrease in accuracy due only to our unsupervised tagging method." ></td>
	<td class="line x" title="190:223	With more detailed feature engineering and more sophisticated machine learning methods, we could probably improve our classifiers performance on the automaticallylabeleddataset.Alsonotethatimprovements in supervised methods can be expected to automatically translate to improvements in unsupervised 70 Senseval 2 AllWN MonoWN Depend Manual SVM 48.12 53.29 64.38 72.52 MaxEnt 40.93 52.11 62.32 71.91 LP 42.67 49.54 63.32 69.28 McCarthy 59.98 Lesk 48.12 Senseval 3 AllWN MonoWN Depend Manual SVM 53.16 46.32 57.47 71.22 MaxEnt 49.67 44.85 57.35 71.75 LP 47.41 43.60 60.60 67.57 McCarthy 57.14 Lesk 48.66 Table 2: Accuracy (%) on Senseval 2 and 3 lexical samples." ></td>
	<td class="line x" title="191:223	Support vector machines (SVM), maximumentropy(MaxEnt)andlabelpropagation(LP) are trained on automatically and manually labeled data sets WSD using our method." ></td>
	<td class="line x" title="192:223	Interestingly, label propagation performed relatively poorly on the manually labeled data." ></td>
	<td class="line x" title="193:223	However, it ranks highly when using the automatic labels." ></td>
	<td class="line x" title="194:223	This may be due to the fact that LP is the only algorithm that does not separate the training and test set (it is principally a semi-supervised method), allowing the properties of both to influence the structure of the resulting graph." ></td>
	<td class="line x" title="195:223	Since the instances in the training data are not actual occurrences of the target word, it is important to learn which instances in the training set are closest to a given instance in the test set." ></td>
	<td class="line x" title="196:223	The two other algorithms only attempt to distinguish between classes in the training set." ></td>
	<td class="line x" title="197:223	5.3 Other Unsupervised Methods As shown in Table 2 our classifiers are significantly better than Lesk on both Senseval datasets (p < 0.01)." ></td>
	<td class="line x" title="198:223	They also significantly outperform the automatically acquired predominant sense (McCarthy) on Senseval 2 (for the Maximum Entropy classifier, the difference is significant at p < 0.05)." ></td>
	<td class="line x" title="199:223	On Senseval 3, all classifiers quantitatively outperform the first sense heuristic, but the difference is statistically significant only for label propagation (p < 0.01)." ></td>
	<td class="line x" title="200:223	The differences in performance on the two datasets can be explained by analyzing their sense distributions." ></td>
	<td class="line x" title="201:223	Senseval 3 has a higher level of ambiguity (4.35 senses per word, on average, compared to 3.28 for Senseval 2), and is therefore a more difficult dataset." ></td>
	<td class="line x" title="202:223	Although Senseval 3 has a slightly lower percentage of first sense instances, the higher ambiguity means that the skew is, in fact, much higher than in Senseval 2." ></td>
	<td class="line x" title="203:223	A high Senseval 2 Depend Manual SVM 14.3 (60.1) 16.9 (60.4) MaxEnt 6.3 (66.9) 17.1 (56.7) LP 8.9 (63.3) 14.8 (49.4) Senseval 3 Depend Manual SVM 17.6 (45.0) 23.3 (60.0) MaxEnt 8.5 (55.0) 23.7 (60.9) LP 5.6 (60.9) 17.8 (53.5) Table 3: Percentage of non-first instances in automaticallyandmanuallylabeledtrainingdata;numbers in parentheses show the classifiers accuracy on these instances." ></td>
	<td class="line x" title="204:223	skew towards the predominant sense means there are less instances from which we can learn about the rarer senses, and that we run a higher risk when labeling an instance as one of the rarer senses (instead of defaulting to the predominant one)." ></td>
	<td class="line x" title="205:223	Our method shares some of the principles of McCarthy et al.s (2004) unsupervised algorithm." ></td>
	<td class="line x" title="206:223	However, instead of focusing on detecting a single predominant sense throughout the corpus, we build a dataset that will allow us to learn about and identify all existing (prevalent) senses." ></td>
	<td class="line x" title="207:223	Despite the fact that the first-sense heuristic is a strong baseline, and fall-back option in case of limited local information, it is not a true context-specific WSD algorithm." ></td>
	<td class="line x" title="208:223	Any approach that ignores local context, and labels all instances with a single sense has limited effectiveness when WSD is needed in an application." ></td>
	<td class="line x" title="209:223	Context-indifferent methods run the risk of completely mistaking the predominant sense, thereby mis-labeling most of the instances, whereas approaches that consider local context are less prone to such large-scope errors." ></td>
	<td class="line x" title="210:223	We further analyzed the performance of our method by examining instances labeled with senses other than the most frequent one." ></td>
	<td class="line x" title="211:223	Table 3 shows the percentage of such instances depending on the machine learner and type of training data (automatic versus manual) being employed." ></td>
	<td class="line x" title="212:223	It also presents the classifiers accuracy (figures in parentheses) with regard to only the non-first senses." ></td>
	<td class="line x" title="213:223	When trained on the automatically labeled data, our classifiers tend to be more conservative in assigning non-first senses." ></td>
	<td class="line x" title="214:223	Interestingly, we obtain similar accuracies with the classifiers trained on the manually labeled data, even though the latter assign more non-first senses." ></td>
	<td class="line x" title="215:223	It is worth noting that the SVM labels two to three times as many instances with non-first-sense labels, yet achieves similar levels of overall accuracy to the other clas71 sifiers (compare Tables 2 and 3) and only slightly lower accuracy on the non-first senses." ></td>
	<td class="line x" title="216:223	This would make it a better choice when it is important to have more data on rarer senses." ></td>
	<td class="line x" title="217:223	6 Conclusions and Future Work We have presented an unsupervised approach to WSD which retains many of the advantages of supervised methods, while being free of the costly requirement for human annotation." ></td>
	<td class="line x" title="218:223	We demonstrate that classifiers trained using our method can out-perform state-of-the-art unsupervised methods, and approach the accuracy of fully-supervised methods trained on manually-labeled data." ></td>
	<td class="line x" title="219:223	In the future we plan to scale our system to the all-words task." ></td>
	<td class="line x" title="220:223	There is nothing inherent in our method that restricts us to the lexical sample, which we chose primarily to assess the feasibility of our ideas." ></td>
	<td class="line x" title="221:223	Another interesting direction concerns the use of our method in a semi-supervised setting." ></td>
	<td class="line x" title="222:223	For example, we could automatically acquire labeled instances for words whose senses are rareinamanuallytaggeddataset.Finally,wecould potentially improve accuracy, at the expense of coverage, by estimating confidence scores on the classifiers predictions, and assigning labels only to instances with high confidence." ></td>
	<td class="line x" title="223:223	Acknowledgments The authors acknowledge the support of EPSRC (grant EP/C538447/1) and would like to thank David Talbot for his insightful suggestions." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1029
A Probabilistic Model for Measuring Grammaticality and Similarity of Automatically Generated Paraphrases of Predicate Phrases
Fujita, Atsushi;Sato, Satoshi;"></td>
	<td class="line x" title="1:200	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 225232 Manchester, August 2008 A Probabilistic Model for Measuring Grammaticality and Similarity of Automatically Generated Paraphrases of Predicate Phrases Atsushi Fujita Satoshi Sato Graduate School of Engineering, Nagoya University {fujita,ssato}@nuee.nagoya-u.ac.jp Abstract The most critical issue in generating and recognizing paraphrases is development of wide-coverage paraphrase knowledge." ></td>
	<td class="line x" title="2:200	Previous work on paraphrase acquisition has collected lexicalized pairs of expressions; however, the results do not ensure full coverage of the various paraphrase phenomena." ></td>
	<td class="line x" title="3:200	This paper focuses on productive paraphrases realized by general transformation patterns, and addresses the issues in generating instances of phrasal paraphrases with those patterns." ></td>
	<td class="line x" title="4:200	Our probabilistic model computes how two phrases are likely to be correct paraphrases." ></td>
	<td class="line x" title="5:200	The model consists of two components: (i) a structured N-gram language model that ensures grammaticality and (ii) a distributional similarity measure for estimating semantic equivalence and substitutability." ></td>
	<td class="line x" title="6:200	1 Introduction In many languages, a concept can be expressed with several different linguistic expressions." ></td>
	<td class="line x" title="7:200	Handling such synonymous expressions in a given language, i.e., paraphrases, is one of the key issues in a broad range of natural language processing tasks." ></td>
	<td class="line x" title="8:200	For example, the technology for identifying paraphrases would play an important role in aggregating the wealth of uninhibited opinions about products and services that are available on the Web, from both the consumers and producers viewpoint." ></td>
	<td class="line x" title="9:200	On the other hand, whenever we draw up a document, we always seek the most appropriate expression for conveying our ideas." ></td>
	<td class="line x" title="10:200	In such a situation, a system that generates and proposes alternative expressions would be extremely beneficial." ></td>
	<td class="line x" title="11:200	c Atsushi Fujita and Satoshi Sato, 2008." ></td>
	<td class="line x" title="12:200	Licensed under the Creative Commons Attribution-NoncommercialShare Alike 3.0 Unported license." ></td>
	<td class="line x" title="13:200	Some rights reserved." ></td>
	<td class="line x" title="14:200	http://creativecommons.org/licenses/by-nc-sa/3.0/ Most of previous work on generating and recognizing paraphrases has been dedicated to developing context-free paraphrase knowledge." ></td>
	<td class="line x" title="15:200	It is typically represented with pairs of fragmentary expressions that satisfy the following conditions: Condition 1." ></td>
	<td class="line x" title="16:200	Semantically equivalent Condition 2." ></td>
	<td class="line x" title="17:200	Substitutable in some context The most critical issue in developing such knowledge is ensuring the coverage of the paraphrase phenomena." ></td>
	<td class="line x" title="18:200	To attain this coverage, we have proposed a strategy for dividing paraphrase phenomena into the following two classes (Fujita et al., 2007): (1) Non-productive (idiosyncratic) paraphrases a. burst into tears  cried b. comfort  console (Barzilay and McKeown, 2001) (2) Productive paraphrases a. be in our favor  be favorable to us b. show a sharp decrease decrease sharply (Fujita et al., 2007) Typical examples ofnon-productiveparaphrases are lexical paraphrases such as those shown in (1) and idiomatic paraphrases of literal phrases (e.g., kick the bucket  die)." ></td>
	<td class="line x" title="19:200	Knowledge of this class of paraphrases should be stored statically, because they cannot be represented with abstract patterns." ></td>
	<td class="line x" title="20:200	On the other hand, a productive paraphrase is one having a degree of regularity, as exhibited by the examples in (2)." ></td>
	<td class="line x" title="21:200	It is therefore reasonable to represent them with a set of general patterns such as those shown in (3)." ></td>
	<td class="line x" title="22:200	This attains a higher coverage, while keeping the knowledge manageable." ></td>
	<td class="line x" title="23:200	(3) a. N 1 VN 2  N 1 s V -ing of N 2 b. N 1 VN 2  N 2 be V -en by N 1 (Harris, 1957) Various methods have been proposed to acquire paraphrase knowledge (these are reviewed in Section 2.1) where pairs of existing expres225 sions are collected from the given corpus, taking the above two conditions into account." ></td>
	<td class="line x" title="24:200	On the other hand, another issue arises when paraphrase knowledge is generated from the patterns for productive paraphrases such as shown in (3) by instantiating variables with specific words, namely, Condition 3." ></td>
	<td class="line x" title="25:200	Both expressions are grammatical This paper proposes a probabilistic model for computing how likely a given pair of expressions satisfy the aforementioned three conditions." ></td>
	<td class="line x" title="26:200	In particular, we focus on the post-generation assessment of automatically generated productive paraphrases of predicate phrases in Japanese." ></td>
	<td class="line x" title="27:200	In the next section, we review previous approaches and models." ></td>
	<td class="line x" title="28:200	The proposed probabilistic model is then presented in Section 3, where the grammaticality factor and similarity factor are derived from a conditional probability." ></td>
	<td class="line x" title="29:200	In Section 4, the settings for and results of an empirical experiment are detailed." ></td>
	<td class="line x" title="30:200	Finally, Section 5 summarizes this paper." ></td>
	<td class="line x" title="31:200	2 Previous work 2.1 Acquiring paraphrase knowledge The task of automatically acquiring paraphrase knowledge is drawing the attention of an increasing number of researchers." ></td>
	<td class="line x" title="32:200	They are tackling the problem of how precisely paraphrase knowledge can be acquired, although they have tended to notice that it is hard to acquire paraphrase knowledge that ensures full coverage of the various paraphrase phenomena from existing text corpora alone." ></td>
	<td class="line x" title="33:200	To date, two streams of research have evolved: one acquires paraphrase knowledge from parallel/comparable corpora, while the other uses the regular corpus." ></td>
	<td class="line x" title="34:200	Several alignment techniques have been proposed to acquire paraphrase knowledge from parallel/comparable corpora, imitating the techniques devised for machine translation." ></td>
	<td class="line x" title="35:200	Multiple translations of the same text (Barzilay and McKeown, 2001), corresponding articles from multiple news sources (Barzilay and Lee, 2003; Quirk et al., 2004; Dolan et al., 2004), and bilingual corpus (Bannard and Callison-Burch, 2005) have been utilized." ></td>
	<td class="line x" title="36:200	Unfortunately, this approach produces only a low coverage because the size of the parallel/comparable corpora is limited." ></td>
	<td class="line x" title="37:200	Inthe second stream, i.e.,paraphrase acquisition fromtheregular corpus, the distributional hypothesis (Harris, 1968) has been adopted." ></td>
	<td class="line x" title="38:200	The similarity of two expressions, computed from this hypothesis, is called distributional similarity." ></td>
	<td class="line x" title="39:200	The essence of this measure is summarized as follows: Feature representation: to compute the similarity, given expressions are first mapped to certain feature representations." ></td>
	<td class="line x" title="40:200	Expressions that co-occur with the given expression, such as adjacent words (Barzilay and McKeown, 2001; Lin and Pantel, 2001), and modifiers/modifiees (Yamamoto, 2002; Weeds et al., 2005), have so far been examined." ></td>
	<td class="line x" title="41:200	Feature weighting: to precisely compute the similarity, the weight for each feature is adjusted." ></td>
	<td class="line oc" title="42:200	Point-wise mutual information (Lin, 1998) and Relative Feature Focus (Geffet and Dagan, 2004) are well-known examples." ></td>
	<td class="line oc" title="43:200	Feature comparison measures: to convert two feature sets into a scalar value, several measures have been proposed, such as cosine, Lins measure (Lin, 1998), Kullback-Leibler (KL) divergence and its variants." ></td>
	<td class="line x" title="44:200	While most researchers extract fully-lexicalized pairs of words or word sequences only, two algorithms collect template-like knowledge using dependency parsers." ></td>
	<td class="line x" title="45:200	DIRT (Lin and Pantel, 2001) collects pairs of paths in dependency parses that connect two nominal entities." ></td>
	<td class="line x" title="46:200	TEASE(Szpektor et al., 2004) discovers dependency sub-parses from the Web, based on sets of representative entities for a given lexical item." ></td>
	<td class="line x" title="47:200	The output of these systems contains the variable slots as shown in (4)." ></td>
	<td class="line x" title="48:200	(4) a. X wrote Y  X is the author of Y b. X solves Y  X deals with Y (Lin and Pantel, 2001) The knowledge in (4) falls between that in (1), which is fully lexicalized, and that in (3), which is almost fully abstracted." ></td>
	<td class="line x" title="49:200	As a way of enriching such a template-like knowledge, Pantel et al.(2007) proposed the notion of inferential selectional preference and collected expressions that would fill those slots." ></td>
	<td class="line x" title="51:200	As mentioned in Section 1, the aim of the studies reviewed here is to collect paraphrase knowledge." ></td>
	<td class="line x" title="52:200	Thus, they need not to take the grammaticality of expressions into account." ></td>
	<td class="line x" title="53:200	2.2 Generating paraphrase instances Representing productive paraphrases with a set of general patterns makes them maintainable and attains a higher coverage of the paraphrase phenomena." ></td>
	<td class="line x" title="54:200	From the transformation grammar (Har226 ris, 1957), this approach has been adopted by many researchers (Melcuk and Polgu`ere, 1987; Jacquemin, 1999; Fujita et al., 2007)." ></td>
	<td class="line x" title="55:200	An important issue arises when such a pattern is used to generate instances of paraphrases by replacing its variables with specific words." ></td>
	<td class="line x" title="56:200	This involves assessing the grammaticality of two expressions in addition to their semantic equivalence and substitutability." ></td>
	<td class="line x" title="57:200	As a post-generation assessment of automatically generated productive paraphrases, we have applied distributional similarity measures (Fujita and Sato, 2008)." ></td>
	<td class="line x" title="58:200	Our findings from a series of empirical experiments are summarized as follows:  Search engines are useful for retrieving the contextual features of predicate phrases despite some limitations (Kilgarriff, 2007)." ></td>
	<td class="line x" title="59:200	 Distributional similarity measures produce a tolerable level of performance." ></td>
	<td class="line x" title="60:200	Thegrammaticality of aphrase, however, ismerely assessed by issuing the phrase as a query to a commercial search engine." ></td>
	<td class="line x" title="61:200	Although a more frequent expression is more grammatical, the length bias should also be considered in the assessment." ></td>
	<td class="line x" title="62:200	Quirk et al.(2004) built a paraphrase generation model from a monolingual comparable corpus based on a statistical machine translation framework, where the language model assesses the grammaticality of the translations, i.e., generated expressions." ></td>
	<td class="line x" title="64:200	The translation model, however, is not suitable for generating productive paraphrases, because it learns word alignments at the surface level." ></td>
	<td class="line x" title="65:200	To cover all of the productive paraphrases, we require an non-real comparable corpus in which all instances of productive paraphrases have a chance of being aligned." ></td>
	<td class="line x" title="66:200	Furthermore, as the translation model optimizes the word alignment at the sentence level, the substitutability of the aligned word sequences cannot be explicitly guaranteed." ></td>
	<td class="line x" title="67:200	2.3 Existing measures for paraphrases To date, no model has been established that takes into account all of the three aforementioned conditions." ></td>
	<td class="line x" title="68:200	With the ultimate aim of building an ideal model, this section overviews the characteristics and drawbacks of the four existing measures." ></td>
	<td class="line oc" title="69:200	Lins measure Lin (1998) proposed a symmetrical measure: Par Lin (s  t)= summationtext fF s F t (w(s,f)+w(t,f)) summationtext fF s w(s,f)+ summationtext fF t w(t,f) , where F s and F t denote sets of features with positive weights for words s and t, respectively." ></td>
	<td class="line n" title="70:200	Although this measure has been widely cited and has so far exhibited good performance, its symmetry seems unnatural." ></td>
	<td class="line n" title="71:200	Moreover, it may not work well for dealing with general predicate phrases because it is hard to enumerate all phrases to determine the weights of features w(,f).We thus simply adopted the co-occurrence frequency of the phrase and the feature as in (Fujita and Sato, 2008)." ></td>
	<td class="line x" title="72:200	Skew divergence The skew divergence, a variant of KL divergence, was proposed in (Lee, 1999) based on an insight: the substitutability of one word for another need not be symmetrical." ></td>
	<td class="line x" title="73:200	The divergence is given by the following formula: d skew (t,s)=D (P s bardblP t +(1 )P s ), where P s and P t are the probability distributions of features for the given original and substituted words s and t, respectively." ></td>
	<td class="line x" title="74:200	0    1 is a parameter for approximating KL divergence D.The score can be recast into a similarity score via, for example, the following function (Fujita and Sato, 2008): Par skew (st)=exp(d skew (t,s))." ></td>
	<td class="line x" title="75:200	This measure offers an advantage: the weight for each feature is determined theoretically." ></td>
	<td class="line x" title="76:200	However, the optimization of  is difficult because it varies according to the task and even the data size (confidence of probability distributions)." ></td>
	<td class="line x" title="77:200	Translation-based conditional probability Bannard and Callison-Burch (2005) proposed a probabilistic model for acquiring phrasal paraphrases 1 . The likelihood of t as a paraphrase of the given phrase s is defined as follows: P(t|s)= summationdisplay ftr(s)tr(t) P(t|f)P(f|s), where tr(e) stands for a set of foreign language phrases that are aligned with e in the given parallel corpus." ></td>
	<td class="line x" title="78:200	Parameters P(t|f) and P(f|s) are also estimated using the given parallel corpus." ></td>
	<td class="line x" title="79:200	A largescale parallel corpus may enable us to precisely acquire a large amount of paraphrase knowledge." ></td>
	<td class="line x" title="80:200	It 1 In their definition, the term phrase is a sequence of words, while in this paper it designates the subtrees governed by predicates (Fujita et al., 2007)." ></td>
	<td class="line x" title="81:200	227 is not feasible, however, to build (or obtain) a parallel corpus inwhich all the instances of productive paraphrases are translated to the same expression in the other side of language." ></td>
	<td class="line x" title="82:200	3 Proposed probabilistic model 3.1 Formulation with conditional probability Recall that our aim is to establish a measure that computes the likelihood of a given pair of automatically generated predicate phrases satisfying the following three conditions: Condition 1." ></td>
	<td class="line x" title="83:200	Semantically equivalent Condition 2." ></td>
	<td class="line x" title="84:200	Substitutable in some context Condition 3." ></td>
	<td class="line x" title="85:200	Both expressions are grammatical Based on the characteristics of the existing measures reviewed in Section 2.3, we propose a probabilistic model." ></td>
	<td class="line x" title="86:200	Let s and t be the source and target predicate phrase, respectively." ></td>
	<td class="line x" title="87:200	Assuming that s is grammatical, the degree to which the above conditions are satisfied is formalized as a conditional probability P(t|s), as in (Bannard and CallisonBurch, 2005)." ></td>
	<td class="line x" title="88:200	Then, assuming that s and t are paradigmatic (i.e., paraphrases) and thus donot cooccur, the proposed model is derived as follows: P(t|s)= summationdisplay fF P(t|f)P(f|s) = summationdisplay fF P(f|t)P(t) P(f) P(f|s) = P(t) summationdisplay fF P(f|t)P(f|s) P(f) , where F denotes a set of features." ></td>
	<td class="line x" title="89:200	The first factor P(t) is called the grammaticality factor because it quantifies the degree to which condition 3 is satisfied, except that we assume that the given s is grammatical." ></td>
	<td class="line x" title="90:200	The second factor summationtext fF P(f|t)P(f|s) P(f) (Sim(s,t), hereafter), on the other hand, is called the similarity factor because it approximates the degree to which conditions 1 and 2 are satisfied by summing up the overlap of the features of two expressions s and t. The characteristics and advantages of the proposed model are summarized as follows: 1) Asymmetric." ></td>
	<td class="line x" title="91:200	2) Grammaticality is assessed by P(t)." ></td>
	<td class="line x" title="92:200	3) No heuristic is introduced." ></td>
	<td class="line x" title="93:200	As the skew divergence, the weight of the features can be simply estimated as conditional probabilities P(f|t) and P(f|s) and marginal probability P(f)." ></td>
	<td class="line x" title="94:200	4) There is no need to enumerate all the phrases." ></td>
	<td class="line x" title="95:200	s and t are merely the given conditions." ></td>
	<td class="line x" title="96:200	The following subsections describe each factor." ></td>
	<td class="line x" title="97:200	3.2 Grammaticality factor The factor P(t) quantifies how the phrase t is grammatical using statistical language model." ></td>
	<td class="line x" title="98:200	Unlike English, in Japanese, predicates such as verbs and adjectives do not necessarily determine the order of their arguments, although they have some preference." ></td>
	<td class="line x" title="99:200	For example, both of the two sentences in (5) are grammatical." ></td>
	<td class="line x" title="100:200	(5) a. kare-wa pasuta-o hashi-de taberu." ></td>
	<td class="line x" title="101:200	he-TOP pasta-ACC chopsticks-IMP to eat He eats pasta with chopsticks." ></td>
	<td class="line x" title="102:200	b. kare-wa hashi-de pasuta-o taberu." ></td>
	<td class="line x" title="103:200	he-TOP chopsticks-IMP pasta-ACC to eat He eats pasta with chopsticks." ></td>
	<td class="line x" title="104:200	This motivates us to use structured N-gram language models (Habash, 2004)." ></td>
	<td class="line x" title="105:200	Given a phrase t, its grammaticality P(t) is formulated as follows, assuming a (N 1)-th order Markov process for generating its dependency structure T(t): P(t)= bracketleftBigg productdisplay i=1|T(t)| P d parenleftbig c i |d 1 i ,d 2 i ,,d N1 i parenrightbig bracketrightBigg 1/|T(t)| , where |T(t)| stands for the number of nodes in T(t)." ></td>
	<td class="line x" title="106:200	Toignore the length bias of the target phrase, a normalization factor 1/|T(t)| is introduced." ></td>
	<td class="line x" title="107:200	d j i denotes the direct ancestor node of the i-th node c i ,wherej is the distance from c i ; for example, d 1 i and d 2 i are the parent and grandparent nodes of c i , respectively." ></td>
	<td class="line x" title="108:200	Then, a concrete definition of the nodes in the dependency structure is given." ></td>
	<td class="line x" title="109:200	Widely-used Japanese dependency parsers such as CaboCha 2 and KNP 3 consider a sequence of words as a node called a bunsetsu that consists of at least one content word followed by a sequence of function words if any." ></td>
	<td class="line x" title="110:200	The hyphenated word sequences in (6) exemplify those nodes." ></td>
	<td class="line x" title="111:200	(6) kitto kare-ha kyou-no surely he-TOP today-GEN kaigi-ni-ha ko-nai-daro-u." ></td>
	<td class="line x" title="112:200	meeting-DAT-TOP to come-NEG-must He will surely not come to todays meeting." ></td>
	<td class="line x" title="113:200	As bunsetsu can be quite long, involving more than ten words, regarding it as a node makes the model complex." ></td>
	<td class="line x" title="114:200	Therefore, we compare the 2 http://chasen.org/taku/software/cabocha/ 3 http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.html 228 <EOS> . = punc." ></td>
	<td class="line x" title="115:200	= u = aux da = aux= aux nai = auxnai N: noun V: verb Adv: adverb AdvN: adverbial noun Pro: pronoun cp: case particle tp: topic-marking particle ap: adnominal particle aux: auxiliary verb punc: punctuation kuru =Vkuru wa =tp ni =cp kaigi =N kaigi no =ap kyou =AdvN kyou kitto =Adv kare =Pro Japanese base-chunk (bunsetsu) wa =tp Figure 1: MDS of sentence (6)." ></td>
	<td class="line x" title="116:200	following two versions of dependency structures whose nodes are smaller than bunsetsu." ></td>
	<td class="line x" title="117:200	MDS: Morpheme-based dependency structure (Takahashi et al., 2001) regards a morpheme as a node." ></td>
	<td class="line x" title="118:200	MDS of sentence (6) is shown in Figure 1." ></td>
	<td class="line x" title="119:200	CFDS: The node of a content-function-based dependency structure is either a sequence of content words or of function words." ></td>
	<td class="line x" title="120:200	CFDS of sentence (6) is shown Figure 2." ></td>
	<td class="line x" title="121:200	Structured N-gram language models were created from 15 years of Mainichi newspaper articles 4 using a dependency parser Cabocha, with N being varied from 1 to 3." ></td>
	<td class="line x" title="122:200	Then, the 3-gram conditional probability P d (c i |d 1 i ,d 2 i ) is given by the linear interpolation of those three models as follows: P d (c i |d 1 i ,d 2 i )= 3 P ML (c i |d 1 i ,d 2 i ) + 2 P ML (c i |d 1 i ) + 1 P ML (c i ), s.t. summationdisplay j  j =1, where mixture weights  j are selected via an EM algorithm using development data 5 that has not been used for estimating P ML . 3.3 Similarity factor The similarity factor Sim(s,t) quantifies how two phrases s and t are similar by comparing two sets of contextual features f  F for s and t. 4 Mainichi 1991-2005 (1.5GB, 21M sentences)." ></td>
	<td class="line x" title="123:200	5 Yomiuri 2005 (350MB, 4.7M sentences) and Asahi 2005 (180MB, 2.7M sentences)." ></td>
	<td class="line x" title="124:200	<EOS> nai-daro-u-." ></td>
	<td class="line x" title="125:200	= Fnai-daro-u-." ></td>
	<td class="line x" title="126:200	C: Content part F: Function part kuru =C wa =F ni-wa =F kaigi =Ckaigi no =F kyou =C kitto =Ckitto kare =Ckare Japanese base-chunk (bunsetsu) Figure 2: CFDS of sentence (6)." ></td>
	<td class="line x" title="127:200	We employ the following two types of feature sets, which we have examined in our previous work (Fujita and Sato, 2008), where a feature f consists of an expression e and a relation r: BOW: A pair of phrases is likely to be semantically similar, if the distributions of the words surrounding the phrases is similar." ></td>
	<td class="line x" title="128:200	The relation set R BOW contains only cooccur in the same sentence." ></td>
	<td class="line x" title="129:200	MOD: A pair of phrases is likely to be substitutable with each other, provided they share a number of instances of modifiers and modifiees: the set of the relation R MOD consists of two relations modifier and modifiee." ></td>
	<td class="line x" title="130:200	Conditional probability distributions P(f|s) and P(f|t) are estimated using a Web search engine as in (Fujita and Sato, 2008)." ></td>
	<td class="line x" title="131:200	Given a phrase p, snippets of Web pages are firstly obtained via Yahoo API 6 by issuing p as a query." ></td>
	<td class="line x" title="132:200	The maximum number of snippets is set to 1,000." ></td>
	<td class="line x" title="133:200	Then, the features of the phrase are retrieved from those snippets using a morphological analyzer ChaSen 7 and CaboCha." ></td>
	<td class="line x" title="134:200	Finally, the conditional probability distribution P(f|p) is estimated as follows: P(f|p)=P(r, e|p) = freq sni (p,r,e) summationtext r prime R summationtext e prime freq sni (p,r prime ,e prime ) , where freq sni (p,r,e) stands for the frequency of the expression e appealing with the phrase p in relation r within the snippets for p. The weight for features P(f) is estimated using a static corpus based on the following equation: P(f)=P(r, e) = freq cp (r, e) summationtext r prime R summationtext e prime freq cp (r prime ,e prime ) , 6 http://developer.yahoo.co.jp/search/ 7 http://chasen.naist.jp/hiki/ChaSen/ 229 where freq cp (r, e) indicates the frequency of the expression e appearing with something in relation r within the given corpus." ></td>
	<td class="line x" title="135:200	Two different sorts of corpora are separately used to build two variations of P(f)." ></td>
	<td class="line x" title="136:200	The one is Mainichi, which is used for building structured N-gram language models in Section 3.2, while the other is a huge corpus consisting of 470M sentences collected from the Web (Kawahara and Kurohashi, 2006)." ></td>
	<td class="line x" title="137:200	4 Experiments 4.1 Data We conducted an empirical experiment to evaluate the proposed model using the test suite developed in (Fujita and Sato, 2008)." ></td>
	<td class="line x" title="138:200	The test suite consists of 176,541 pairs of paraphrase candidates that are automatically generated using a pattern-based paraphrase generation system (Fujita et al., 2007) for 4,002 relatively high-frequency phrases sampled from a newspaper corpus 8 . To evaluate the system from a generation viewpoint, i.e., how well a system can rank a correct candidate first, we extracted paraphrase candidates for 200 randomly sampled source phrases from the test suite." ></td>
	<td class="line x" title="139:200	Table 1 shows the statistics of the test data." ></td>
	<td class="line x" title="140:200	The All-Yield column shows that the number of candidates for a source phrase varies considerably, which implies that the data contains cases that have various difficulties." ></td>
	<td class="line x" title="141:200	While the average number of candidates for each source phrase was 48.3 (the maximum was 186), it was dramatically reduced through extracting features for each source and candidate paraphrase from Web snippets: to 5.2 with BOW and to 4.8 with MOD." ></td>
	<td class="line x" title="142:200	This suggests that a large number of spurious phrases were generated but discarded by going to the Web, and the task was significantly simplified." ></td>
	<td class="line x" title="143:200	4.2 Questions Through this experiment, weevaluated several versions of the proposed model to answer the following questions: Q1." ></td>
	<td class="line x" title="144:200	Is the proposed model superior to existing measures in practice?" ></td>
	<td class="line x" title="145:200	Par Lin and Par skew are regarded as being the baseline." ></td>
	<td class="line x" title="146:200	Q2." ></td>
	<td class="line x" title="147:200	Which language model performs better at estimating P(t)?" ></td>
	<td class="line x" title="148:200	MDS and CFDS are compared." ></td>
	<td class="line x" title="149:200	Q3." ></td>
	<td class="line x" title="150:200	Which corpus performs better at estimating P(f)?" ></td>
	<td class="line x" title="151:200	The advantage of Kawaharas huge 8 The grammaticality of the source phrases are guaranteed." ></td>
	<td class="line x" title="152:200	Table 1: Statistics of test data (Ph.: # of phrases)." ></td>
	<td class="line x" title="153:200	Source All BOW MOD Phrase type Ph." ></td>
	<td class="line x" title="154:200	Ph." ></td>
	<td class="line x" title="155:200	Yield Ph." ></td>
	<td class="line x" title="156:200	Yield Ph." ></td>
	<td class="line x" title="157:200	Yield N:C:V 18 57 3.2 54 3.0 54 3.0 N 1 :N 2 :C:V 57 4,596 80.6 594 10.4 551 9.7 N:C:V 1 :V 2 54 4,767 88.3 255 4.7 232 4.3 N:C:Adv:V 16 51 3.2 39 2.4 38 2.4 Adj:N:C:V 2 84.0 52.552.5 N:C:Adj 53 173 3.3 86 1.6 83 1.6 Total 200 9,652 48.3 1,033 5.2 963 4.8 corpus (WebCP) over Mainichi is evaluated." ></td>
	<td class="line x" title="158:200	Q4." ></td>
	<td class="line x" title="159:200	Which set of features performs better?" ></td>
	<td class="line x" title="160:200	In addition to BOW and MOD,the harmonic mean of the scores derived from BOW and MOD is examined (referred to as HAR)." ></td>
	<td class="line x" title="161:200	Q5." ></td>
	<td class="line x" title="162:200	Can the quality of P(f|s) and P(f|t) be improved by using a larger number of snippets?" ></td>
	<td class="line x" title="163:200	As the maximum number of snippets (N S ), we compared 500 and 1,000." ></td>
	<td class="line x" title="164:200	4.3 Results Twoassessors were asked to judge paraphrase candidates that are ranked first by either of the above models if each candidate satisfies each of the three conditions." ></td>
	<td class="line x" title="165:200	The results for all the above options are summarized in Table 2, where the strict precision is calculated based on those cases that gain two positive judgements, while the lenient precision is for at least one positive judgement." ></td>
	<td class="line x" title="166:200	A1: Our greatest concern is the actual performance of our probabilistic model." ></td>
	<td class="line x" title="167:200	However, no variation of the proposed model could outperform the existing models (Par Lin and Par skew )that only assess similarity." ></td>
	<td class="line x" title="168:200	Furthermore, McNemers test with p<0.05 revealed that the precisions of all the models, except the combination of CFDS for P(t) and Mainichi for P(f), were significantly worse than those of the best models." ></td>
	<td class="line x" title="169:200	To clarify the cause of these disappointing results, we investigated the performance of each factor." ></td>
	<td class="line x" title="170:200	Table 3 shows how well the grammaticality factors select a grammatical phrase, while Table 4 illustrates how well the similarity factors rank a correct paraphrase first." ></td>
	<td class="line x" title="171:200	As shown in these tables, neither factor performed the task well, although combinations produced a slight improvement in performance." ></td>
	<td class="line x" title="172:200	A detailed discussion is given below in A2 for the grammaticality factors, and in A3-A5 for the similarity factors." ></td>
	<td class="line x" title="173:200	A2: Comparisons between MDS and CFDS revealed that CFDS always produced better results than MDS not only when used for measuring grammaticality (Table 3), but also when used as a 230 Table 2: Precision for 200 test cases." ></td>
	<td class="line x" title="174:200	N S =500 Strict Lenient Model BOW MOD HAR BOW MOD HAR Par Lin 78 (39%) 88 (44%) 87 (44%) 116 (58%) 128 (64%) 127 (64%) Par skew 81 (41%) 88 (44%) 88 (44%) 120 (60%) 127 (64%) 128 (64%) MDS, Mainichi 72 (36%) 73 (37%) 76 (38%) 109 (55%) 112 (56%) 114 (57%) MDS, WebCP 71 (36%) 73 (37%) 72 (36%) 108 (54%) 110 (55%) 113 (57%) CFDS, Mainichi 79 (40%) 78 (39%) 83 (42%) 120 (60%) 119 (60%) 123 (62%) CFDS, WebCP 79 (40%) 77 (39%) 80 (40%) 118 (59%) 116 (58%) 118 (59%) N S =1,000 Strict Lenient Model BOW MOD HAR BOW MOD HAR Par Lin 79 (40%) 88 (44%) 88 (44%) 116 (58%) 128 (64%) 129 (65%) Par skew 84 (42%) 89 (45%) 89 (45%) 121 (61%) 128 (64%) 128 (64%) MDS, Mainichi 72 (36%) 75 (38%) 76 (38%) 109 (55%) 114 (57%) 114 (57%) MDS, WebCP 71 (36%) 74 (37%) 72 (36%) 109 (55%) 111 (56%) 113 (57%) CFDS, Mainichi 79 (40%) 82 (41%) 83 (42%) 121 (61%) 121 (61%) 122 (61%) CFDS, WebCP 79 (40%) 78 (39%) 79 (40%) 119 (60%) 116 (58%) 119 (60%) Table 3: Precision of measuring grammaticality." ></td>
	<td class="line x" title="175:200	Model Strict Lenient MDS 104 (52%) 141 (71%) CFDS 108 (54%) 142 (71%) Table 4: Precision of similarity factors." ></td>
	<td class="line x" title="176:200	Strict Lenient N S Corpus BOW MOD HAR BOW MOD HAR 500 Mainichi 60 (30%) 68 (34%) 74 (37%) 98 (49%) 109 (55%) 114 (57%) 500 WebCP 57 (28%) 61 (31%) 74 (37%) 94 (47%) 99 (50%) 120 (60%) 1,000 Mainichi 57 (28%) 70 (35%) 74 (37%) 92 (46%) 113 (57%) 116 (58%) 1,000 WebCP 57 (28%) 60 (30%) 72 (36%) 93 (47%) 96 (48%) 116 (58%) component of the entire model (Table 2)." ></td>
	<td class="line x" title="177:200	This result is quite natural because MDScannot verify the collocation between content words in those cases where a number of function words appear between them." ></td>
	<td class="line x" title="178:200	On the other hand, CFDS with N = 3 could verify this as a result of treating the sequence of function words as a single node." ></td>
	<td class="line x" title="179:200	As mentioned in A1, however, a more sophisticated language model must enhance the proposed model." ></td>
	<td class="line x" title="180:200	One way of obtaining a suitable granularity of nodes is to introduce latent classes, such as the Semi-Markov class model (Okanohara and Tsujii, 2007)." ></td>
	<td class="line x" title="181:200	The existence of many orthographic variants of both the content and function words may prevent us from accurately estimating the grammaticality." ></td>
	<td class="line x" title="182:200	We plan to normalize these variations by using several existing resources such as the Japanese functional expression dictionary (Matsuyoshi, 2008)." ></td>
	<td class="line x" title="183:200	A3: Contrary to our expectations, the huge Web corpus did not offer any advantage over the newspaper corpus: Mainichi always produced better results than WebCP when it was combined with the grammaticality factor or when MOD was used." ></td>
	<td class="line x" title="184:200	Wecan speculate that morphological and dependency parsers produce errors when features are extracted, because they are tuned to newspaper articles." ></td>
	<td class="line x" title="185:200	Likewise, P(f|s) and P(f|t) may involve noise even though they are estimated using relatively clean parts of Web text that are retrieved by querying phrase candidates." ></td>
	<td class="line x" title="186:200	A4: For Par Lin and Par skew , different sets of features led to consistent results with our previous experiments in (Fujita and Sato, 2008), i.e., BOW < MOD similarequal HAR." ></td>
	<td class="line x" title="187:200	On the other hand, for the proposed models, MOD and HAR led to only small or sometimes negative effects." ></td>
	<td class="line x" title="188:200	When the similarity factor was used alone, however, these features beat BOW." ></td>
	<td class="line x" title="189:200	Furthermore, the impact of combining BOW and MOD into HAR was significant." ></td>
	<td class="line x" title="190:200	Given this tendency, it is expected that the grammaticality factor might be excessively emphasized." ></td>
	<td class="line x" title="191:200	Our probability model was derived straightforwardly from the conditional probability P(t|s); however, the combination of the two factors should be tuned according to their implementation." ></td>
	<td class="line x" title="192:200	A5: Finally, the influence of the number of Web snippets was analyzed; no significant difference was observed." ></td>
	<td class="line x" title="193:200	This is because we could retrieve more than 500 snippets for only 172 pairs of expressions among our test samples." ></td>
	<td class="line x" title="194:200	As it is time-consuming to obtain a large number of Web snippets, the trade-off between the number of Web snippets and the performance should be investigated further, although the quality of the Web snippets and what appears at the top of the search results will vary according to several factors other than linguistic ones." ></td>
	<td class="line x" title="195:200	231 5Conclusion A pair of expressions qualifies as paraphrases iff they are semantically equivalent, substitutable in some context, and grammatical." ></td>
	<td class="line x" title="196:200	In cases where paraphrase knowledge is represented with abstract patterns to attain a high coverage of the paraphrase phenomena, we should assess not only the first and second conditions, but also the third condition." ></td>
	<td class="line x" title="197:200	In this paper, we proposed a probabilistic model for computing how two phrases are likely to be paraphrases." ></td>
	<td class="line x" title="198:200	The proposed model consists of two components: (i) a structured N-gram language model that ensures grammaticality and (ii) a distributional similarity measure for estimating semantic equivalence and substitutability between two phrases." ></td>
	<td class="line x" title="199:200	Through an experiment, we empirically evaluated the performance of the proposed model and analyzed the characteristics." ></td>
	<td class="line x" title="200:200	Future work includes building a more sophisticated structured language model to improve the performance of the proposed model and conducting an experiment on template-like paraphrase knowledge for other than productive paraphrases." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1051
Using Hidden Markov Random Fields to Combine Distributional and Pattern-Based Word Clustering
Kaji, Nobuhiro;Kitsuregawa, Masaru;"></td>
	<td class="line x" title="1:191	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 401408 Manchester, August 2008 Using Hidden Markov Random Fields to Combine Distributional and Pattern-based Word Clustering Nobuhiro Kaji and Masaru Kitsuregawa Institute of Industrial Science, University of Tokyo 4-6-1 Komaba, Meguro-ku, Tokyo 153-8505 Japan {kaji,kitsure}@tkl.iis.u-tokyo.ac.jp Abstract Word clustering is a conventional and important NLP task, and the literature has suggested two kinds of approaches to this problem." ></td>
	<td class="line x" title="2:191	One is based on the distributional similarity and the other relies on the co-occurrence of two words in lexicosyntactic patterns." ></td>
	<td class="line x" title="3:191	Although the two methods have been discussed separately, it is promising to combine them since they are complementary with each other." ></td>
	<td class="line x" title="4:191	This paper proposes to integrate them using hidden Markov random fields and demonstrates its effectiveness through experiments." ></td>
	<td class="line x" title="5:191	1 Introduction Word clustering is a technique of grouping similar words together, and it is important for various NLP systems." ></td>
	<td class="line oc" title="6:191	Applications of word clustering include language modeling (Brown et al., 1992), text classification (Baker and McCallum, 1998), thesaurus construction (Lin, 1998) and so on." ></td>
	<td class="line x" title="7:191	Furthermore, recent studies revealed that word clustering is useful for semi-supervised learning in NLP (Miller et al., 2004; Li and McCallum, 2005; Kazama and Torisawa, 2008; Koo et al., 2008)." ></td>
	<td class="line x" title="8:191	A well-known approach to grouping similar words is to use distribution of contexts in which target words appear." ></td>
	<td class="line x" title="9:191	It is founded on the hypothesis that similar words tend to appear in similar contexts (Harris, 1968)." ></td>
	<td class="line x" title="10:191	Based on this idea, some studies proposed probabilistic models for word clustering (Pereira et al., 1993; Li and Abe, 1998; Rooth c2008." ></td>
	<td class="line x" title="11:191	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="12:191	Some rights reserved." ></td>
	<td class="line x" title="13:191	et al., 1999; Torisawa, 2002)." ></td>
	<td class="line oc" title="14:191	Others proposed distributional similarity measures between words (Hindle, 1990; Lin, 1998; Lee, 1999; Weeds et al., 2004)." ></td>
	<td class="line x" title="15:191	Once such similarity is defined, it is trivial to perform clustering." ></td>
	<td class="line x" title="16:191	On the other hand, some researchers utilized co-occurrence for word clustering." ></td>
	<td class="line x" title="17:191	The idea behind it is that similar words tend to co-occur in certain patterns." ></td>
	<td class="line x" title="18:191	Considerable efforts have been devoted to measure word similarity based on cooccurrence frequency of two words in a window (Church and Hanks, 1989; Turney, 2001; Terra and Clarke, 2003; Matsuo et al., 2006)." ></td>
	<td class="line x" title="19:191	In addition to the classical window-based technique, some studies investigated the use of lexico-syntactic patterns (e.g., X or Y) to get more accurate co-occurrence statistics (Chilovski and Pantel, 2004; Bollegala et al., 2007)." ></td>
	<td class="line x" title="20:191	These two approaches are complementary with each other, because they are founded on different hypotheses and utilize different corpus statistics." ></td>
	<td class="line x" title="21:191	Consider to cluster a set of words based on the distributional similarity." ></td>
	<td class="line x" title="22:191	It is likely that some words are difficult to cluster due to the data sparseness or some other problems, while we can still expect that those words are correctly classified using patterns." ></td>
	<td class="line x" title="23:191	This consideration leads us to combine distributional and pattern-based word clustering." ></td>
	<td class="line x" title="24:191	In this paper we propose to combine them using mixture models based on hidden Markov random fields." ></td>
	<td class="line x" title="25:191	This model was originally proposed by (Basu et al., 2004) for semi-supervised clustering." ></td>
	<td class="line x" title="26:191	In semisupervised clustering, the system is provided with supervision in the form of pair-wise constraints specifying data points that are likely to belong to the same cluster." ></td>
	<td class="line x" title="27:191	These constraints are directly incorporated into the clustering process as a prior knowledge." ></td>
	<td class="line x" title="28:191	Our idea is to view the co-occurrence 401 of two words in lexico-syntactic patterns as constraints, and incorporate them into distributional word clustering." ></td>
	<td class="line x" title="29:191	In summary, this paper discusses the problem of integrating multiple approaches for word clustering." ></td>
	<td class="line x" title="30:191	We consider that the clustering results are improved if multiple approaches are successfully combined and if they are complementary with each other." ></td>
	<td class="line x" title="31:191	Our contribution is to provide a probabilistic framework for this problem." ></td>
	<td class="line x" title="32:191	Although our proposal aims at combining the distributional and pattern-based approaches, it is also applicable to combine other approaches like (Lin et al., 2003), as we will discuss in Section 5.4." ></td>
	<td class="line x" title="33:191	2 Distributional Clustering This and next section describe distributional and pattern-based word clustering respectively." ></td>
	<td class="line x" title="34:191	Section 4 will explain how to combine them." ></td>
	<td class="line x" title="35:191	2.1 Probabilistic model In distributional word clustering, similarity between words (= nouns) is measured by the distribution of contexts in which they appear." ></td>
	<td class="line x" title="36:191	As a context, verbs that appear in certain grammatical relations with the target nouns are typically used." ></td>
	<td class="line x" title="37:191	Using the distribution of such verbs, we can express a noun n by a feature vector (n): (n)=(f nv 1 ,f nv 2 ,f nv V ) where f nv i denotes the frequency of noun-verb pair (n,v i ), and V denotes the number of distinct verbs." ></td>
	<td class="line x" title="38:191	The basic idea of using the distribution for clustering is to group n and n prime together if (n) and (n prime ) are similar." ></td>
	<td class="line x" title="39:191	Let us consider a soft clustering model." ></td>
	<td class="line x" title="40:191	We hypothesize that (n) is a mixture of multinomial, and the probability of n is defined by 1 p(n)= Z summationdisplay z=1 p(z)p((n)|z) = Z summationdisplay z=1  z f n ! producttext v f nv ! productdisplay v  f nv vz where Z is the number of mixture components,  z is the mixing coefficient ( summationtext z  z =1), f n = summationtext v f nv is the total number of occurrence of n, and 1 We ignored p(f n ) by assuming that it is independent of hidden variables." ></td>
	<td class="line x" title="41:191	See (McCallum and Nigam, 1998) for detail discussion." ></td>
	<td class="line x" title="42:191	 vz is the parameter of the multinomial distribution ( summationtext v  vz =1)." ></td>
	<td class="line x" title="43:191	In this model the hidden variables can be interpreted as semantic class of nouns." ></td>
	<td class="line x" title="44:191	Now consider a set of nouns n = {n i } N i=1 . Let z = {z i } N i=1 be a set of hidden variables corresponding to n. Assuming that the hidden variables are independent and n i is also independent of other nouns given the hidden variables, the probability of n is defined by p(n)= summationdisplay z p(z)p(n|z) where p(z)= N productdisplay i=1 p(z i ) p(n|z)= N productdisplay i=1 p(n i |z i )." ></td>
	<td class="line x" title="45:191	Hereafter, we use p(n|z) instead of p((n)|z) to keep the notation simple." ></td>
	<td class="line x" title="46:191	p(n|z) is the conditional distribution on all nouns given all the hidden variables, and p(z) is the prior distribution on the hidden variables." ></td>
	<td class="line x" title="47:191	Computing the log-likelihood of the complete data (n,z), we found log p(n,z)= N summationdisplay i=1 log p(z i )p(n i |z i )." ></td>
	<td class="line x" title="48:191	(1) 2.2 Parameter estimation The parameters can be estimated by the EM algorithm." ></td>
	<td class="line x" title="49:191	In the E-step, p(z i |n i ) is computed based on current parameters." ></td>
	<td class="line x" title="50:191	It is computed by p(z i = k|n i )= p(z i = k)p(n i |z i = k) summationtext z p(z)p(n i |z) =  k producttext v  f n i v vk summationtext z  z producttext v  f n i v vz . In the M-step, the parameters are re-estimated by using the result of the E-step:  k =  + summationtext i f n i  p(z i = k|n i ) V + summationtext v summationtext i f n i v p(z i = k|n i )  k =  + summationtext i p(z i = k|n i ) Z + summationtext z summationtext i p(z i = z|n i ) where  is a smoothing factor." ></td>
	<td class="line x" title="51:191	2 Both steps are repeated until a convergence criteria is satisfied." ></td>
	<td class="line x" title="52:191	The important point to note is that the E-step can be computed using the above equation because the hidden variables are independent." ></td>
	<td class="line x" title="53:191	2 =1.0 in our experiment." ></td>
	<td class="line x" title="54:191	402 X ya YXmo Y mo X to Y to X, Y nado (X or Y) (X and Y) (X and Y) (X, Y etc.) Table 1: Four lexico-syntactic patterns, where X and Y are extracted as co-occurring words." ></td>
	<td class="line x" title="55:191	Note that ya, mo, and to are Japanese postpositions, and they correspond to or or and in English." ></td>
	<td class="line x" title="56:191	3 Pattern-based Clustering A graph-based algorithm was employed in order to cluster words using patterns." ></td>
	<td class="line x" title="57:191	3.1 Graph Construction We first construct the graph in which vertices and edges correspond to words and their cooccurrences in patterns respectively (Figure 1)." ></td>
	<td class="line x" title="58:191	We employed four lexico-syntactic patterns (Table 1) to extract co-occurrence of two words from corpus." ></td>
	<td class="line x" title="59:191	Note that we target Japanese in this paper although our proposal is independent of languages." ></td>
	<td class="line x" title="60:191	The edges are weighted by the strength of cooccurrence that is computed by the Point-wise Mutual Information (PMI): PMI(n i ,n j )=log f(n i ,n j )f(,) f(n i ,)f(,n j ) where f(n i ,n j ) is the co-occurrence frequency of two nouns, and  means summation over all nouns." ></td>
	<td class="line x" title="61:191	If PMI is less than zero, the edge is removed." ></td>
	<td class="line x" title="62:191	3.2 Graph Partitioning Assuming that similar words tend to co-occur in the lexico-syntactic patterns, it is reasonable to consider that a dense subgraph is a good cluster (Figure 1)." ></td>
	<td class="line x" title="63:191	Following (Matsuo et al., 2006), we exploit the Newman clustering (Newman, 2004) to partition the graph into such dense subgraphs." ></td>
	<td class="line x" title="64:191	We start by describing Newmans algorithm for unweighted graphs and we will generalize it to weighted graphs later." ></td>
	<td class="line x" title="65:191	The Newman clustering is an algorithm that divides a graph into subgraphs based on connectivity." ></td>
	<td class="line x" title="66:191	Roughly speaking, it divides a graph such that there are a lot of edges between vertices in the same cluster." ></td>
	<td class="line x" title="67:191	In the algorithm goodness of clustering is measured by score Q: Q = summationdisplay i parenleftBig e ii  a 2 i parenrightBig ramen dumpling pasta steak Japan U.S.A. Germany China France Figure 1: An example of the graph consisting of two dense subgraphs." ></td>
	<td class="line x" title="68:191	where e ij = # of edges between two vertices in cluster i and j # of all edges a i = summationdisplay k e ik . The term e ij is the fraction of edges between cluster i and j. a i is the sum of e ik over all clusters, and a 2 i represents the expected number of fraction of edges within the cluster i when edges are given at random." ></td>
	<td class="line x" title="69:191	See (Newman, 2004) for the detail." ></td>
	<td class="line x" title="70:191	The Newman clustering optimizes Q in an agglomerative fashion." ></td>
	<td class="line x" title="71:191	At the beginning of the algorithm every vertex forms a singleton cluster, and we repeatedly merge two clusters so that the join results in the largest increase in Q. The change in Q when cluster i and j are merged is given by Q = e ij + e ji  2a i a j =2(e ij  a i a j )." ></td>
	<td class="line x" title="72:191	The above procedure is repeated until Q reaches local maximum." ></td>
	<td class="line x" title="73:191	The algorithm can be easily generalized to weighted graphs by substituting sum of weights of edges for # of edges in the definition of e ij . The other part of the algorithm remains the same." ></td>
	<td class="line x" title="74:191	4 Integration based on Hidden Markov Random Fields This section represents how to integrate the distribution and pattern for word clustering." ></td>
	<td class="line x" title="75:191	4.1 Background and idea Clustering has long been discussed as an unsupervised learning problem." ></td>
	<td class="line x" title="76:191	In some applications, however, it is possible to provide some form of supervision by hand in order to improve the clustering result." ></td>
	<td class="line x" title="77:191	This motivated researchers to investigate semi-supervised clustering, which uses not only unlabeled data but supervision in the form of pair-wise constraints (Basu et al., 2004)." ></td>
	<td class="line x" title="78:191	In this 403 framework, the clustering system is provided with a set of pair-wise constraints specifying data points that are likely to belong to the same cluster." ></td>
	<td class="line x" title="79:191	These constraints are directly incorporated into the clustering process as a prior knowledge." ></td>
	<td class="line x" title="80:191	Our idea is to view the co-occurrence of two words in lexico-syntactic patterns as constraints, and incorporate them into the distributional clustering." ></td>
	<td class="line x" title="81:191	The rest of this section describes how to extend the distributional clustering so as to incorporate the constraints, and how to generate the constraints using the patterns." ></td>
	<td class="line x" title="82:191	4.2 Probabilistic model Let C be a set of pair-wise constraints, and consider to incorporate the constraints into the distributional clustering (Section 2)." ></td>
	<td class="line x" title="83:191	In what follows we assume each constraint i,jC represents that z i and z j are likely to have the same value, and it is associated with a weight w ij (> 0) corresponding to a penalty for constraint violation." ></td>
	<td class="line x" title="84:191	It is easy to extend the distributional clustering algorithm so as to incorporate the constraints." ></td>
	<td class="line x" title="85:191	This is done by just changing the prior distribution on hidden variables p(z)." ></td>
	<td class="line x" title="86:191	Following (Basu et al., 2004), we construct the Markov random field on the hidden variables so as to incorporate the constraints." ></td>
	<td class="line x" title="87:191	The new prior distribution is defined as p(z)= N productdisplay i=1 p(z i )  1 G exp{ summationdisplay i,jC (z i negationslash= z j )w ij } where () is the delta function." ></td>
	<td class="line x" title="88:191	(z i negationslash= z j ) takes one if the constraint i,j is violated and otherwise zero." ></td>
	<td class="line x" title="89:191	G is the normalization factor of the Markov random field (the second term)." ></td>
	<td class="line x" title="90:191	By examining the log-likelihood of the complete data, we can see how violation of constraints is penalized." ></td>
	<td class="line x" title="91:191	Using the new prior distribution, we get log p(n,z)= N summationdisplay i=1 log p(z i )p(n i |z i )  summationdisplay i,jC (z i negationslash= z j )w ij  log G. The first term in the right-hand side is equal to the log-likelihood of the multinomial mixture, namely equation (1)." ></td>
	<td class="line x" title="92:191	The second term can be interpreted as the penalty for constraint violation." ></td>
	<td class="line x" title="93:191	The last term is a constant." ></td>
	<td class="line x" title="94:191	It is worth pointing out that the resulting algorithm makes a soft assignment and polysemous words can belong to more than one clusters." ></td>
	<td class="line x" title="95:191	4.3 Parameter estimation The parameters are estimated by the EM algorithm." ></td>
	<td class="line x" title="96:191	The M-step is exactly the same as discussed in Section 2.2." ></td>
	<td class="line x" title="97:191	The problem is that the hidden variables are no longer independent and the E-step requires the calculation of p(z i |n)= summationdisplay z i p(z i ,z i |n)  summationdisplay z i p(z i ,z i )p(n|z i ,z i ) where z i means all hidden variables but z i . The computation of the above equation is intractable because the summation in it requires O(Z N1 ) operations." ></td>
	<td class="line x" title="98:191	Instead of exactly computing p(z i |n), we approximate it by using the mean field approximation (Lange et al., 2005)." ></td>
	<td class="line x" title="99:191	In the mean field approximation, p(z|n) is approximated by a factorized distribution q(z), in which all hidden variables are independent: q(z)= N productdisplay i=1 q i (z i )." ></td>
	<td class="line x" title="100:191	(2) Using q(z) instead of p(z|n), computation of the E-step can be written as follows: p(z i |n) similarequal summationdisplay z i q(z i ,z i )=q i (z i )." ></td>
	<td class="line x" title="101:191	(3) The parameters of q(z) are determined such that the KL divergence between q(z) and p(z|n) is minimized." ></td>
	<td class="line x" title="102:191	In other words, the approximate distribution q(z) is determined by minimizing summationdisplay z q(z)log q(z) p(z|n) (4) under the condition that summationtext k q i (z i = k)=1 for all i. This optimization problem can be resolved by introducing Lagrange multipliers." ></td>
	<td class="line x" title="103:191	Because we cannot get the solution in closed form, an iterative method is employed." ></td>
	<td class="line x" title="104:191	Taking the derivative of equation (4) with respect to a parameter q ik = q i (z i = k) and setting it to zero, we get the following updating formula: q (t+1) ik  p(n i ,k)exp{ summationdisplay jN i (1  q (t) jk )w ij } (5) 404 where N i = {j|i,jC} and q (t) ik is the value of q ik at t-th iteration." ></td>
	<td class="line x" title="105:191	The derivation of this formula is found in Appendix." ></td>
	<td class="line x" title="106:191	4.4 Generation of constraints It is often pointed out that even small amounts of misspecified constraints significantly decrease the performance of semi-supervised clustering." ></td>
	<td class="line x" title="107:191	This is because the error of misspecified constraints is propagated to the entire transitive neighborhoods of the constrained data (Nelson and Cohen, 2007)." ></td>
	<td class="line x" title="108:191	As an example, consider that we have two constraints i,j and j, k." ></td>
	<td class="line x" title="109:191	If the former is misspecified one, the error propagate to k through j. To tackle this problem, we propose a technique to put an upper bound  on the size of the transitive neighborhoods." ></td>
	<td class="line x" title="110:191	Our constraint generation process is as follows." ></td>
	<td class="line x" title="111:191	To begin with, we modified the Newman clustering so that the maximum cluster size does not exceed ." ></td>
	<td class="line x" title="112:191	This can be done by prohibiting such merge that results in larger cluster than ." ></td>
	<td class="line x" title="113:191	Given the result of the modified Newman clustering, it is straightforward to generate constraints." ></td>
	<td class="line x" title="114:191	Constraints are generated between two nouns in the same cluster if they co-occur in the lexicosyntactic patterns at least one time." ></td>
	<td class="line x" title="115:191	The penalty for constraint violation w ij was set to PMI(n i ,n j )." ></td>
	<td class="line x" title="116:191	This procedure obviously ensures that the size of the transitive neighborhoods is less than ." ></td>
	<td class="line x" title="117:191	5 Experiments 5.1 Data sets We parsed 15 years of news articles by KNP 3 so as to obtain data sets for the distributional and pattern-based word clustering (Table 2)." ></td>
	<td class="line x" title="118:191	The number of distinct nouns in total was 297,719." ></td>
	<td class="line x" title="119:191	Note that, due to the computational efficiency, we removed such nouns that appeared less than 10 times with verbs and did not appear at all in the patterns." ></td>
	<td class="line x" title="120:191	A test set was created using manually tailored Japanese thesaurus (Ikehara et al., 1997)." ></td>
	<td class="line x" title="121:191	We randomly selected 500 unambiguous nouns from 25 categories (20 words for each category)." ></td>
	<td class="line x" title="122:191	5.2 Baselines For comparison we implemented the following baseline systems." ></td>
	<td class="line x" title="123:191	 The multinomial mixture (Section 2)." ></td>
	<td class="line x" title="124:191	 The Newman clustering (Newman, 2004)." ></td>
	<td class="line x" title="125:191	3 http://nlp.kuee.kyoto-u.ac.jp/nl-resource/ nouns 208,934 verbs 64,954 noun-verb pairs 4,804,715 nouns 245,465 noun-noun pairs 633,302 Table 2: Data sets statistics." ></td>
	<td class="line x" title="126:191	The first and second row shows the number of distinct words (and word pairs) used for the distributional and pattern-based word clustering respectively." ></td>
	<td class="line oc" title="127:191	 Three K-means algorithms using different distributional similarity or dissimilarity measures: cosine, -skew divergence (Lee, 1999) 4 , and Lins similarity (Lin, 1998)." ></td>
	<td class="line x" title="128:191	 The CBC algorithm (Lin and Pantel, 2002; Pantel and Lin, 2002)." ></td>
	<td class="line x" title="129:191	5.3 Evaluation procedure All the nouns in the data set were clustered by the proposed and baseline systems." ></td>
	<td class="line x" title="130:191	5 For the mixture models and K-means, the number of clusters was set to 1,000." ></td>
	<td class="line x" title="131:191	The parameter  was set to 100." ></td>
	<td class="line x" title="132:191	The result was assessed by precision and recall using the test data." ></td>
	<td class="line x" title="133:191	The precision and recall were computed by the B-CUBED algorithm as follows (Bagga and Baldwin, 1998)." ></td>
	<td class="line x" title="134:191	For each noun n i in the test data, precision i and recall i are defined as precision i = |S i  T i | |S i | recall i = |S i  T i | | T i | where S i is the system generated cluster containing n i and T i is the goldstandard cluster containing n i . The precision and recall are defined as an average of precision i and recall i for all the nouns in the test data respectively." ></td>
	<td class="line x" title="135:191	The result of soft clustering models cannot be directly evaluated by the precision and recall." ></td>
	<td class="line x" title="136:191	In such cases, each noun is assigned to the cluster that maximizes p(z|n)." ></td>
	<td class="line x" title="137:191	5.4 The result and discussion Table 3 shows the experimental results." ></td>
	<td class="line x" title="138:191	The best results for each statistic are shown in bold." ></td>
	<td class="line x" title="139:191	For the mixture models and K-means, the precision and recall are an average of 10 trials." ></td>
	<td class="line x" title="140:191	Table 3 demonstrates the impact of combining distribution and pattern." ></td>
	<td class="line x" title="141:191	Our method outperformed 4  = 0.99 in our experiment." ></td>
	<td class="line x" title="142:191	5 Our implementation is available from http://www.tkl.iis.u-tokyo.ac.jp/kaji/clustering." ></td>
	<td class="line oc" title="143:191	405 PRF 1 proposed .383 .437 .408 multinomial mixture .360 .374 .367 Newman (2004) .318 .353 .334 cosine .603 .114 .192 -skew divergence (Lee, 1999) .730 .155 .255 Lins similarity (Lin, 1998) .691 .096 .169 CBC (Lin and Pantel, 2002) .981 .060 .114 Table 3: Precision, recall, and F-measure." ></td>
	<td class="line x" title="144:191	all the baseline systems." ></td>
	<td class="line x" title="145:191	It was statistically significantly better than the multinomial mixture (P < 0.01, Mann-Whitney U-test)." ></td>
	<td class="line x" title="146:191	Note that it is possible to improve some baseline systems, especially CBC, by tuning the parameters." ></td>
	<td class="line x" title="147:191	For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002)." ></td>
	<td class="line x" title="148:191	Compared with the multinomial mixture, one advantage of our method is that it has broad coverage." ></td>
	<td class="line x" title="149:191	Our method can successfully handle unknown words, which do not appear with verbs at all (i.e., f n =0and (n) is zero vector), if they co-occur with other words in the lexico-syntactic patterns." ></td>
	<td class="line x" title="150:191	For unknown words, the hidden variables are determined based only on p(z) because p(n|z) takes the same value for all hidden variables." ></td>
	<td class="line x" title="151:191	This means that our method clusters unknown words using pair-wise constraints." ></td>
	<td class="line x" title="152:191	On the other hand, the multinomial mixture assigns all the unknown words to the cluster that maximizes p(z)." ></td>
	<td class="line x" title="153:191	The test set included 51 unknown words." ></td>
	<td class="line x" title="154:191	6 We split the test set into two parts: f n =0and f n negationslash=0, and calculated precision and recall for each subset (Table 4)." ></td>
	<td class="line x" title="155:191	Although the improvement is especially significant for the unknown words, we can clearly confirm the improvement for both subsets." ></td>
	<td class="line x" title="156:191	For the Newman clustering we can discuss similar things (Table 5)." ></td>
	<td class="line x" title="157:191	Different from the Newman clustering, our method can handle nouns that do not co-occur with other nouns if 0 <f n . In this case the test set included 64 unknown words." ></td>
	<td class="line x" title="158:191	It is interesting to point out that our framework can further incorporate lexico-syntactic patterns for dissimilar words (Lin et al., 2003)." ></td>
	<td class="line x" title="159:191	Namely, we can use patterns so as to prevent distributionally similar but semantically different words (e.g., ally and supporter (Lin et al., 2003)) from being assigned to the same cluster." ></td>
	<td class="line x" title="160:191	This can be achieved by using cannot-link constraints, which specify data points that are likely to belong to different clus6 The baseline systems assigned the unknown words to a default cluster as the multinomial mixture does." ></td>
	<td class="line x" title="161:191	f n =0 f n negationslash=0 PRF 1 PRF 1 proposed .320 .632 .435 .412 .450 .430 multi." ></td>
	<td class="line x" title="162:191	.099 1.000 .181 .402 .394 .398 Table 4: Detail comparison with the multinomial mixture." ></td>
	<td class="line x" title="163:191	f(n i ,)=0 f(n i ,) negationslash=0 PRF 1 PRF 1 proposed .600 .456 .518 .380 .479 .424 Newman .071 1.000 .133 .354 .412 .381 Table 5: Detail comparison with the Newman clustering." ></td>
	<td class="line x" title="164:191	ters (Basu et al., 2004)." ></td>
	<td class="line x" title="165:191	The remaining problem is which patterns to use so as to extract dissimilar words." ></td>
	<td class="line x" title="166:191	Although this problem has already been discussed by (Lin et al., 2003), they mainly addressed antonyms." ></td>
	<td class="line x" title="167:191	We believe that a more exhaustive investigation is required." ></td>
	<td class="line x" title="168:191	In addition, it is still unclear whether dissimilar words are really useful to improve clustering results." ></td>
	<td class="line x" title="169:191	One problem that we did not examine is how to determine optimal number of clusters." ></td>
	<td class="line x" title="170:191	In the experiment, the number was decided with trial-anderror through our initial experiment." ></td>
	<td class="line x" title="171:191	We leave it as our future work to test methods of automatically determining the cluster number (Pedersen and Kulkarni, 2006; Blei and Jordan, 2006)." ></td>
	<td class="line x" title="172:191	6 Related work As far as we know, the distributional and patternbased word clustering have been discussed independently (e.g., (Pazienza et al., 2006))." ></td>
	<td class="line x" title="173:191	One of the most relevant work is (Bollegala et al., 2007), which proposed to integrate various patterns in order to measure semantic similarity between words." ></td>
	<td class="line x" title="174:191	Although they extensively discussed the use of patterns, they did not address the distributional approach." ></td>
	<td class="line x" title="175:191	Mirkin (2006) pointed out the importance of integrating distributional similarity and lexicosyntactic patterns, and showed how to combine the two approaches for textual entailment acquisition." ></td>
	<td class="line x" title="176:191	Although their work inspired our research, we discussed word clustering, which is related to but different from entailment acquisition." ></td>
	<td class="line x" title="177:191	Lin (2003) also proposed to use both distributional similarity and lexico-syntactic patterns for finding synonyms." ></td>
	<td class="line x" title="178:191	However, they present an opposite viewpoint from our research." ></td>
	<td class="line x" title="179:191	Their proposal is to exploit patterns in order to filter dissimilar 406 words." ></td>
	<td class="line x" title="180:191	As we have already discussed, the integration of such patterns can also be formalized using similar probabilistic model to ours." ></td>
	<td class="line x" title="181:191	A variety of studies discussed determining polarity of words." ></td>
	<td class="line x" title="182:191	Because this problem is ternary (positive, negative, and neutral) classification of words, it can be seen as one kind of word clustering." ></td>
	<td class="line x" title="183:191	The literature suggested two methods of determining polarity, and they are analogous to the distributional and co-occurrence-based approaches in word clustering (Takamura et al., 2005; Higashiyama et al., 2008)." ></td>
	<td class="line x" title="184:191	We consider it is also promising to integrate them for polarity determination." ></td>
	<td class="line x" title="185:191	7 Conclusion The distributional and pattern-based word clustering have long been discussed separately despite the potentiality for their integration." ></td>
	<td class="line x" title="186:191	In this paper, we provided a probabilistic framework for combining the two approaches, and demonstrated that the clustering result is significantly improved." ></td>
	<td class="line x" title="187:191	Our important future work is to extend current framework so as to incorporate patterns for dissimilar words using cannot-link constraints." ></td>
	<td class="line x" title="188:191	We consider such patterns further improve the clustering result." ></td>
	<td class="line x" title="189:191	Combining distribution and pattern is important for other NLP problems as well (e.g., entailment acquisition, polarity determination)." ></td>
	<td class="line x" title="190:191	Although this paper examined word clustering, we consider a part of our idea can be applied to other problems." ></td>
	<td class="line x" title="191:191	Acknowledgement This work was supported by the Comprehensive Development of e-Society Foundation Software program of the Ministry of Education, Culture, Sports, Science and Technology, Japan." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1054
Coordination Disambiguation without Any Similarities
Kawahara, Daisuke;Kurohashi, Sadao;"></td>
	<td class="line x" title="1:221	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 425432 Manchester, August 2008 Coordination Disambiguation without Any Similarities Daisuke Kawahara National Institute of Information and Communications Technology, 3-5 Hikaridai Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan dk@nict.go.jp Sadao Kurohashi Graduate School of Informatics, Kyoto University, Yoshida-Honmachi, Sakyo-ku, Kyoto, 606-8501, Japan kuro@i.kyoto-u.ac.jp Abstract The use of similarities has been one of the main approaches to resolve the ambiguities of coordinate structures." ></td>
	<td class="line x" title="2:221	In this paper, we present an alternative method for coordination disambiguation, which does not use similarities." ></td>
	<td class="line x" title="3:221	Our hypothesis is that coordinate structures are supported by surrounding dependency relations, and that such dependency relations rather yield similarity between conjuncts, which humans feel." ></td>
	<td class="line x" title="4:221	Based on this hypothesis, we built a Japanese fully-lexicalized generative parser that includes coordination disambiguation." ></td>
	<td class="line x" title="5:221	Experimental results on web sentencesindicatedtheeffectivenessofour approach, and endorsed our hypothesis." ></td>
	<td class="line x" title="6:221	1 Introduction The interpretation of coordinate structures directly affects the meaning of the text." ></td>
	<td class="line x" title="7:221	Addressing coordination ambiguities is fundamental to natural language understanding." ></td>
	<td class="line x" title="8:221	Previous studies on coordination disambiguation suggested that conjuncts in coordinate structures have syntactic or semantic similarities, and dealt with coordination ambiguities using (sub-)string matching, part-ofspeech matching, semantic similarities, and so forth(AgarwalandBoggess,1992)." ></td>
	<td class="line x" title="9:221	Semanticsimilarities are acquired from thesauri (Kurohashi and Nagao, 1994; Resnik, 1999) or distributional similarity (Chantree et al., 2005)." ></td>
	<td class="line x" title="10:221	c2008." ></td>
	<td class="line x" title="11:221	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="12:221	Some rights reserved." ></td>
	<td class="line x" title="13:221	For instance, consider the following example: (1) eat Caesar salad and Italian pasta The above methods detect the similarity between salad and pasta using a thesaurus or distributional similarity, and identify the coordinate structure that conjoins salad and pasta." ></td>
	<td class="line x" title="14:221	They do not use the information of the word eat." ></td>
	<td class="line x" title="15:221	On the other hand, this coordinate structure can be analyzed by using selectional preference of eat." ></td>
	<td class="line x" title="16:221	Sinceeat islikelytohavesalad andpastaasitsobjects, it is plausible that salad and pasta are coordinated." ></td>
	<td class="line x" title="17:221	Such selectional preferences are thought tosupporttheconstructionofcoordinatestructures and to yield similarity between conjuncts on the contrary." ></td>
	<td class="line x" title="18:221	We present a method of coordination disambiguation without using similarities." ></td>
	<td class="line x" title="19:221	Coordinate structures are supported by their surrounding dependency relations that provide selectional preferences." ></td>
	<td class="line x" title="20:221	These relations implicitly work as similarities, and thus it is not necessary to use similarities explicitly." ></td>
	<td class="line x" title="21:221	In this paper, we focus on Japanese." ></td>
	<td class="line x" title="22:221	Coordination disambiguation is integrated in a fullylexicalized generative dependency parser (Kawahara and Kurohashi, 2007)." ></td>
	<td class="line x" title="23:221	For the selectional preferences, we use lexical knowledge, such as case frames, which is extracted from a large raw corpus." ></td>
	<td class="line x" title="24:221	The remainder of this paper is organized as follows." ></td>
	<td class="line x" title="25:221	Section 2 summarizes previous work related to coordination disambiguation and its integration into parsing." ></td>
	<td class="line x" title="26:221	Section 3 briey describes the background of this study." ></td>
	<td class="line x" title="27:221	Section 4 overviews our idea, and section 5 describes our model in detail." ></td>
	<td class="line x" title="28:221	Section 6 is devoted to our experiments." ></td>
	<td class="line x" title="29:221	Finally, section 7 gives the conclusions." ></td>
	<td class="line x" title="30:221	425 2 Related Work Previous work on coordination disambiguation has focused mainly on nding the scope of coordinate structures." ></td>
	<td class="line x" title="31:221	There are several methods that use similarities between the heads of conjuncts." ></td>
	<td class="line x" title="32:221	Similarities are obtained from manually assigned semantic tags (Agarwal and Boggess, 1992), a thesaurus (Resnik, 1999) and a distributional thesaurus (Chantree et al., 2005)." ></td>
	<td class="line x" title="33:221	Other approaches used cooccurrence statistics." ></td>
	<td class="line x" title="34:221	To determine the attachments of ambiguous coordinate noun phrases, Goldberg (1999) applied a cooccurrence-based probabilistic model, and Nakov and Hearst (2005) used web-based frequencies." ></td>
	<td class="line x" title="35:221	The performance of these methods ranges from 50% to 80%." ></td>
	<td class="line x" title="36:221	Of the above approaches, Resnik (1999) and Nakov and Hearst (2005) considered the statistics of noun-noun modication." ></td>
	<td class="line x" title="37:221	For example, the coordinate structure ((mail and securities) fraud) is guidedbytheestimationthat mail fraud isasalient compound nominal phrase." ></td>
	<td class="line x" title="38:221	On the other hand, the coordinate structure (corn and (peanut butter)) is led because corn butter is not a familiar concept." ></td>
	<td class="line x" title="39:221	They did not use the selectional preferences of the predicates that the conjuncts depend on." ></td>
	<td class="line x" title="40:221	Therefore, this idea is subsumed into ours." ></td>
	<td class="line x" title="41:221	The previously described methods focused on coordination disambiguation." ></td>
	<td class="line x" title="42:221	Some research has been undertaken that integrated coordination disambiguation into parsing." ></td>
	<td class="line x" title="43:221	Several techniques have considered the characteristics of coordinate structures in a generative or reranking parser." ></td>
	<td class="line x" title="44:221	Dubey et al.(2006) proposed an unlexicalized PCFG parser that modied PCFG probabilities to condition the existence of syntactic parallelism." ></td>
	<td class="line x" title="46:221	Hogan (2007) improved a generative lexicalizedparserbyconsideringthesymmetrybetween words in each conjunct." ></td>
	<td class="line x" title="47:221	As for a reranking parser, Charniak and Johnson (2005) incorporated some features of syntactic parallelism in coordinate structures into their MaxEnt reranking parser." ></td>
	<td class="line x" title="48:221	Nilsson et al. tried to transform the tree representation of a treebank into a more suitable representation for data-driven dependency parsers (Nilsson et al., 2006; Nilsson et al., 2007)." ></td>
	<td class="line x" title="49:221	One of their targets is the representation of coordinate structures." ></td>
	<td class="line x" title="50:221	They succeeded in improving a deterministic parser, but failed for a globally optimized discriminative parser." ></td>
	<td class="line x" title="51:221	Kurohashi and Nagao proposed a Japanese parsing method that included coordinate structure detection (Kurohashi and Nagao, 1994)." ></td>
	<td class="line x" title="52:221	Their method rst detects coordinate structures in a sentence, and then determines the dependency structure of the sentence under the constraints of the detected coordinate structures." ></td>
	<td class="line x" title="53:221	Their method correctly analyzed 97 out of 150 Japanese sentences." ></td>
	<td class="line x" title="54:221	Kawahara and Kurohashi (2007) integrated this method into a generative parsing model." ></td>
	<td class="line x" title="55:221	Shimbo and Hara (2007) considered many features for coordination disambiguation and automatically optimized their weights, which were heuristically determined in Kurohashi and Nagao (1994), using a discriminative learning model." ></td>
	<td class="line x" title="56:221	A number of machine learning-based approachestoJapaneseparsinghavebeendeveloped." ></td>
	<td class="line x" title="57:221	Among them, the best parsers are the SVM-based dependency analyzers (Kudo and Matsumoto, 2002; Sassano,2004)." ></td>
	<td class="line x" title="58:221	Inparticular,Sassanoadded some features to improve his parser by enabling it to detect coordinate structures (Sassano, 2004)." ></td>
	<td class="line x" title="59:221	However, the added features did not contribute to improving the parsing accuracy." ></td>
	<td class="line x" title="60:221	Tamura et al.(2007) learned not only standard modier-head relations but also ancestor-descendant relations." ></td>
	<td class="line x" title="62:221	With this treatment, their method can indirectly improve the handling of coordinate structures in limited cases." ></td>
	<td class="line x" title="63:221	3 Background 3.1 Japanese Grammar Let us rst briey introduce Japanese grammar." ></td>
	<td class="line x" title="64:221	The structure of a Japanese sentence can be described well by the dependency relation between bunsetsus." ></td>
	<td class="line x" title="65:221	A bunsetsu is a basic unit of dependency,consistingofoneormorecontentwordsand the following zero or more function words." ></td>
	<td class="line x" title="66:221	A bunsetsu corresponds to a base phrase in English and eojeol in Korean." ></td>
	<td class="line x" title="67:221	The Japanese language is headnal, that is, a bunsetsu depends on another bunsetsu to its right (but not necessarily the adjacent bunsetsu)." ></td>
	<td class="line x" title="68:221	For example, consider the following sentence1: (2) ane-to sister-CMI gakkou-ni school-ALL itta went (went to school with (my) sister) 1In this paper, we use the following abbreviations: NOM (nominative), ACC (accusative), ABL (ablative), ALL (allative), CMI (comitative), CNJ (conjunction) and TM (topic marker)." ></td>
	<td class="line x" title="69:221	426 This sentence consists of three bunsetsus." ></td>
	<td class="line x" title="70:221	The nal bunsetsu, itta, is a predicate, and the other bunsetsus, ane-to and gakkou-ni, are its arguments." ></td>
	<td class="line x" title="71:221	Their endings, to and ni, are postpositions that function as case markers." ></td>
	<td class="line x" title="72:221	3.2 Treebank To evaluate our method, we use a web corpus that is manually annotated using the criteria of the Kyoto Text Corpus (Kurohashi and Nagao, 1998)." ></td>
	<td class="line x" title="73:221	The Kyoto Text Corpus is syntactically annotated in dependency formalism, and consists of 40K Japanese newspaper sentences." ></td>
	<td class="line x" title="74:221	The web corpus, which is used in our evaluation, consists of 759 sentences extracted from the web." ></td>
	<td class="line x" title="75:221	Under the annotation criteria of the Kyoto Text Corpus,thelastbunsetsuinapre-conjunctdepends on the last bunsetsu in a post-conjunct, as shown in the dependency trees of Figure 1." ></td>
	<td class="line x" title="76:221	4 Our Idea of Addressing Coordination Ambiguities The target of our approach is nominal coordinate structures." ></td>
	<td class="line x" title="77:221	Consider, for example, the following sentence, which contains a nominal coordinate structure." ></td>
	<td class="line x" title="78:221	(3) jinkou-no population-GEN zouka-to increase-CNJ taiki-no air-GEN osen-ga pollution-NOM sokushin-sareta stimulated (increase of population and pollution of air were stimulated) In this sentence, the postposition to is a coordinate conjunction2." ></td>
	<td class="line x" title="79:221	In Japanese, a coordinate conjunction is attached to a verb or noun, forming a bunsetsu, like case-marking postpositions." ></td>
	<td class="line x" title="80:221	We call a bunsetsuthatcontainsacoordinateconjunctioncoordination key bunsetsu." ></td>
	<td class="line x" title="81:221	The coordinate structure in example (3) has four possible scopes as depicted in Figure 1." ></td>
	<td class="line x" title="82:221	In this gure, our parser generates the constituent words according to the arrows in the reverse direction." ></td>
	<td class="line x" title="83:221	Note that the words that have 1/2 marks are generated from multiple words, because they depend 2Note that the postposition to can be used as a coordinate conjunction and also a comitative case marker as in example (2)." ></td>
	<td class="line x" title="84:221	The detection of coordinate conjunctions is a task of coordination disambiguation as well as the identication of coordination scopes." ></td>
	<td class="line x" title="85:221	Both of these tasks are simultaneously handled in our method." ></td>
	<td class="line x" title="86:221	on a coordinate structure." ></td>
	<td class="line x" title="87:221	In this case, their generative probabilities, which are described later, are averaged." ></td>
	<td class="line x" title="88:221	The scope patterns in Figure 1 can be written in English as follows: a." ></td>
	<td class="line x" title="89:221	(population increase) and (air pollution) b. population (increase and (air pollution)) c." ></td>
	<td class="line x" title="90:221	((population increase) and air) pollution d. population (increase and air) pollution In (a) and (b), two arguments, zouka (increase) and osen (pollution), are generated from the verb sokushin-sareta (stimulated), and are eligible for the ga (NOM) words of the verb sokushin-sareta (stimulated)." ></td>
	<td class="line x" title="91:221	However, (b) is not appropriate, because we cannot say the nominal compound jinkou-no osen (pollution of population)." ></td>
	<td class="line x" title="92:221	In (c) and (d), the heads of conjuncts, zouka (increase) and taiki (air), are generated from osen (pollution)." ></td>
	<td class="line x" title="93:221	These cases are also inappropriate, because we cannot say the nominal compound zouka-no osen (pollution of increase)." ></td>
	<td class="line x" title="94:221	Accordingly, in this case, the correct scope, (a), is derived based on the selectional preferences of predicates and nouns." ></td>
	<td class="line x" title="95:221	In this framework, we require selectional preferences." ></td>
	<td class="line x" title="96:221	We use case frames for predicates (Kawahara and Kurohashi, 2006) and occurrences of noun-noun modications for nouns." ></td>
	<td class="line x" title="97:221	Both of them are extracted from a large amount of raw text." ></td>
	<td class="line x" title="98:221	5 Our Model of Coordination Disambiguation This section describes an integrated model of coordination disambiguation in a generative parsing framework." ></td>
	<td class="line x" title="99:221	First, we describe resources for selectional preferences, and then illustrate our model of coordination disambiguation." ></td>
	<td class="line x" title="100:221	5.1 Resources for Selectional Preferences As the resources of selectional preferences to support coordinate structures, we use automatically constructed case frames and cooccurrences of noun-noun modications." ></td>
	<td class="line x" title="101:221	5.1.1 Automatically Constructed Case Frames We employ automatically constructed case frames (Kawahara and Kurohashi, 2006)." ></td>
	<td class="line x" title="102:221	This section outlines the method for constructing the case frames." ></td>
	<td class="line x" title="103:221	427 zouka-to increase-CNJ jinkou-no population-GEN zouka-to increase-CNJ taiki-no air-GEN osen-ga pollution-NOM sokushin-sareta stimulated C (a) jinkou-no populuation-GEN zouka-to increase-CNJ taiki-no air-GEN osen-ga pollution-NOM sokushin-sareta stimulated (b) jinkou-no population-GEN zouka-to increase-CNJ taiki-no air-GEN osen-ga pollution-NOM sokushin-sareta stimulated C (c) jinkou-no population-GEN taiki-no air-GEN osen-ga pollution-NOM sokushin-sareta stimulated C (d) C 1/2 1/2 Figure 1: Four possible coordination scopes for example (3)." ></td>
	<td class="line x" title="104:221	Rounded rectangles represent conjuncts." ></td>
	<td class="line x" title="105:221	The solid arrows represent dependency trees." ></td>
	<td class="line x" title="106:221	The dotted arrows represent the additional processes of generation for coordinate structures." ></td>
	<td class="line x" title="107:221	Note that the arrows with coordinate relation (C mark) do not participate in generation instead." ></td>
	<td class="line x" title="108:221	Table 1: Acquired case frames of yaku." ></td>
	<td class="line x" title="109:221	Example words are expressed only in English due to space limitation." ></td>
	<td class="line x" title="110:221	The number following each word denotes its frequency." ></td>
	<td class="line x" title="111:221	CS examples ga I:18, person:15, craftsman:10, yaku (1) wo bread:2484, meat:1521, cake:1283, (bake) de oven:1630, frying pan:1311,  yaku (2) ga teacher:3, government:3, person:3,  (have wo ngers:2950 difculty) ni attack:18, action:15, son:15,  ga maker:1, distributor:1yaku (3) wo data:178, le:107, copy:9, (burn) ni R:1583, CD:664, CDR:3,     A large corpus is automatically parsed, and case frames are constructed from modier-head examples in the resulting parses." ></td>
	<td class="line x" title="112:221	The problems of automatic case frame construction are syntactic and semantic ambiguities." ></td>
	<td class="line x" title="113:221	That is to say, the parsing results inevitably contain errors, and verb senses are intrinsically ambiguous." ></td>
	<td class="line x" title="114:221	To cope with these problems, case frames are gradually constructed from reliable modier-head examples." ></td>
	<td class="line x" title="115:221	First, modier-head examples that have no syntactic ambiguity are extracted, and they are disambiguated by a pair consisting of a verb and its closest case component." ></td>
	<td class="line x" title="116:221	Such pairs are explicitly expressed on the surface of text, and are thought to play an important role in sentence meanings." ></td>
	<td class="line x" title="117:221	For instance, examples are distinguished not by verbs (e.g., yaku (bake/broil/have difculty)), but by pairs (e.g., pan-wo yaku (bake bread), niku-wo yaku (broil meat), and te-wo yaku (have difculty))." ></td>
	<td class="line x" title="118:221	Modier-head examples are aggregated in this way, and yield basic case frames." ></td>
	<td class="line x" title="119:221	Thereafter, the basic case frames are clustered to merge similar case frames." ></td>
	<td class="line x" title="120:221	For example, since pan-wo yaku (bake bread) and niku-wo yaku (broil meat) are similar, they are clustered." ></td>
	<td class="line x" title="121:221	The similarity is measured using a thesaurus (The National Institute for Japanese Language, 2004)." ></td>
	<td class="line x" title="122:221	Using this gradual procedure, we constructed case frames from a web corpus (Kawahara and Kurohashi, 2006)." ></td>
	<td class="line x" title="123:221	The case frames were obtained from approximately 500M sentences extracted from the web corpus." ></td>
	<td class="line x" title="124:221	They consisted of 90,000 verbs, and the average number of case frames for a verb was 34.3." ></td>
	<td class="line x" title="125:221	In Table 1, some examples of the resulting case frames of the verb yaku are listed." ></td>
	<td class="line x" title="126:221	In this table, CS indicates a case slot." ></td>
	<td class="line x" title="127:221	428 ane-tosister-CNJ otouto-wobrother-ACC yondainvited C(b)ane-tosister-CMI otouto-wobrother-ACC yondainvited (a) to wo wo wo Figure 2: Dependency trees and generation processes for example (4)." ></td>
	<td class="line x" title="128:221	This example sentence has two possible dependency structures according to the interpretation of to: comitative in (a) and coordinate conjunction in (b)." ></td>
	<td class="line x" title="129:221	5.1.2 Cooccurrences of Noun-noun Modications Adnominal nouns have selectional preferences to nouns, and thus this characteristic is useful for coordination disambiguation (Resnik, 1999)." ></td>
	<td class="line x" title="130:221	We collect dependency relations between nouns from automatic parses of the web corpus." ></td>
	<td class="line x" title="131:221	As a result, 10.7M unique dependency relations were obtained." ></td>
	<td class="line x" title="132:221	5.2 Our Model We employ a probabilistic generative dependency parser (Kawahara and Kurohashi, 2007) as a base model." ></td>
	<td class="line x" title="133:221	This base model measures similarities between conjuncts in the same way as (Kurohashi and Nagao, 1994), and calculates probabilities of generating these similarities." ></td>
	<td class="line x" title="134:221	Our proposed model, however, does not do both of them." ></td>
	<td class="line x" title="135:221	Our model purely depends on selectional preferences provided by automatically acquired lexical knowledge." ></td>
	<td class="line x" title="136:221	Our model gives probabilities to all the possible dependency structures for an input sentence, and selects the structure that has the highest probability." ></td>
	<td class="line x" title="137:221	For example, consider the following sentence: (4) ane-to sister-CNJ otouto-wo brother-ACC yonda invited (invited (my) sister and brother) For this sentence, our model assesses the two dependency structures (a) and (b) in Figure 2." ></td>
	<td class="line x" title="138:221	In our model, both of the pre-conjunct and post-conjunct are generated from the predicate." ></td>
	<td class="line x" title="139:221	That is, in (b), both ane (sister) and otouto (brother) with wo (ACC) are generated from yonda (invited)." ></td>
	<td class="line x" title="140:221	To identify the correct structure, (b), it is essential that both ane (sister) and otouto (brother) are eligible for the accusative words of yonda (invited)." ></td>
	<td class="line x" title="141:221	Therefore, selectional preferences play an important role in coordination disambiguation." ></td>
	<td class="line x" title="142:221	On the other hand, in (a), ane (sister) with to (CMI) is generated from yonda (invited), and also otouto (brother) with wo (ACC) is generated from yonda." ></td>
	<td class="line x" title="143:221	However, yonda is not likely to have the to case slot, so the probability of (a) is lower than that of (b)." ></td>
	<td class="line x" title="144:221	Our model can nally select the correct structure, (b), which has the highest probability." ></td>
	<td class="line x" title="145:221	This kind of assessment is also performed to resolve the scope ambiguities of coordinate structures as shown in Figure 1." ></td>
	<td class="line x" title="146:221	This model gives a probability to each possible dependency structure, T, and case structure, L, of the input sentence, S, and outputs the dependency andcasestructurethathavethehighestprobability." ></td>
	<td class="line x" title="147:221	That is to say, the model selects the dependency structure, Tbest, and the case structure, Lbest, that maximize the probability, P(T,L|S): (Tbest,Lbest) = argmax (T,L)P(T,L|S) = argmax (T,L)P(T,L,S)P(S) = argmax (T,L)P(T,L,S) (1) The last equation is derived because P(S) is constant." ></td>
	<td class="line x" title="148:221	The model considers a clause as a generation unit and generates the input sentence from the end of the sentence in turn." ></td>
	<td class="line x" title="149:221	The probabilityP(T,L,S) is dened as the product of probabilities for generating clause Ci as follows: P(T,L,S) =  CiSP(Ci,relihi|Chi) (2) Chi is Cis modifying clause, and relihi is the dependency relation between Ci and Chi." ></td>
	<td class="line x" title="150:221	The main clause, Cn, at the end of a sentence does not have a modifying head, but a virtual clause Chn = EOS (End Of Sentence) is added." ></td>
	<td class="line x" title="151:221	Dependency relation relihi is classied into two types, C (coordinate) and D (normal dependency)." ></td>
	<td class="line x" title="152:221	Clause Ci is decomposed into its clause type, fi, (including the predicates inection and function words) and its remaining content part Ciprime." ></td>
	<td class="line x" title="153:221	Clause Chi is also decomposed into its content part, Chiprime, and its clause type, fhi." ></td>
	<td class="line x" title="154:221	P(Ci,relihi|Chi) = P(Ciprime,fi,relihi|Chiprime,fhi)  P(Ciprime,relihi|fi,Chiprime)P(fi|fhi)  P(Ciprime|relihi,fi,Chiprime)P(relihi|fi) P(fi|fhi) (3) 429 Equation (3) is derived using appropriate approximations described in Kawahara and Kurohashi (2007)." ></td>
	<td class="line x" title="155:221	We call P(Ciprime|relihi,fi,Chiprime) generative probability of a content part, and P(relihi|fi) generative probability of a dependency relation." ></td>
	<td class="line x" title="156:221	The following two subsections describe these probabilities." ></td>
	<td class="line x" title="157:221	5.2.1 Generative Probability of Dependency Relation The most important feature to determine whether two clauses are coordinate is a coordination key." ></td>
	<td class="line x" title="158:221	Therefore, we consider a coordination key, ki, as clause type fi." ></td>
	<td class="line x" title="159:221	The generative probability of a dependency relation, P(relihi|fi), is dened as follows: P(relihi|fi) = P(relihi|ki) (4) We classied coordination keys into 52 classes according to the classication described in (Kurohashi and Nagao, 1994)." ></td>
	<td class="line x" title="160:221	If type fi does not contain a coordination key, the relation is always D (normal dependency), that is, P(relihi|fi) = P(D|) = 1." ></td>
	<td class="line x" title="161:221	The generative probability of a dependency relation was estimated from the Kyoto Text Corpus using maximum likelihood." ></td>
	<td class="line x" title="162:221	5.2.2 Generative Probability of Content Part The generative probability of a content part changes according to the class of a content part, Ciprime." ></td>
	<td class="line x" title="163:221	We classify Ciprime into two classes: predicate clause and nominal phrase." ></td>
	<td class="line x" title="164:221	If Ciprime is a predicate clause, Ciprime represents a case structure." ></td>
	<td class="line x" title="165:221	We consider that a case structure consists of a predicate, vi, a case frame, CFl, and a case assignment, CAk." ></td>
	<td class="line x" title="166:221	Case assignment CAk represents correspondences between the input case components and the case slots shown in Figure 3." ></td>
	<td class="line x" title="167:221	Thus, the generative probability of a content part is decomposed as follows: Pv(Ciprime|relihi,fi,Chiprime) = P(vi,CFl,CAk|relihi,fi,Chiprime)  P(vi|relihi,fi,whi) P(CFl|vi) P(CAk|CFl,fi) (5) These generative probabilities are estimated from case frames themselves and parsing results of a large web corpus." ></td>
	<td class="line x" title="168:221	bentou-wa tabete(lunchbox) (eat)  lunchbox, bread, wo man, student, gataberu1 (eat) Case Frame CFl Case AssignmentCA k (no correspondence)Dependency Structure of S Figure 3: Example of case assignment." ></td>
	<td class="line x" title="169:221	If Ciprime is a nominal phrase and consists of a noun ni, we consider the following probability instead of equation (5): Pn(Ciprime|relihi,fi,Chiprime)  P(ni|relihi,fi,whi) This is because a noun does not have a case frame or any case components in the current framework." ></td>
	<td class="line x" title="170:221	Since we do not use cooccurrences of coordinate phrases as used in the base model, relihi is always D (normal dependency)." ></td>
	<td class="line x" title="171:221	This probability is estimated from the cooccurrences of noun-noun modications using maximum likelihood." ></td>
	<td class="line x" title="172:221	6 Experiments We evaluated the dependency structures that were output by our model." ></td>
	<td class="line x" title="173:221	The case frames used in this paper were automatically constructed from 500M Japanese sentences obtained from the web." ></td>
	<td class="line x" title="174:221	In this work, the parameters related to unlexical types were calculated from the Kyoto Text Corpus, which is a small tagged corpus of newspaper articles, and lexical parameters were obtained from a huge web corpus." ></td>
	<td class="line x" title="175:221	To evaluate the effectiveness of our model, our experiments were conducted using web sentences." ></td>
	<td class="line x" title="176:221	As the test corpus, we used 759 web sentences 3, which are described in section 3.2." ></td>
	<td class="line x" title="177:221	We also used the Kyoto Text Corpus as a development corpus to optimize the smoothing parameters." ></td>
	<td class="line x" title="178:221	The system input was automatically tagged using the JUMAN morphological analyzer 4." ></td>
	<td class="line x" title="179:221	We used two baseline systems for comparative purposes: a rule-based dependency parser (Kurohashi and Nagao, 1994) and the probabilistic generative model of dependency, coordinate and case structure analysis (Kawahara and Kurohashi, 2007)5." ></td>
	<td class="line x" title="180:221	6.1 Evaluation of Dependency Structures We evaluated the dependency structures that were analyzed by the proposed model." ></td>
	<td class="line x" title="181:221	Evaluating the 3The test set was not used to construct case frames or estimate probabilities." ></td>
	<td class="line x" title="182:221	4http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman-e.html 5http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp-e.html 430 Table 2: Experimental results of dependency structures." ></td>
	<td class="line x" title="183:221	all represents the accuracy of all the dependencies, and coordination key represents the accuracy of only the coordination key bunsetsus." ></td>
	<td class="line x" title="184:221	rule-coord-w/sim prob-coord-w/sim prob-coord-wo/sim all 3,821/4,389 (87.1%) 3,852/4,389 (87.8%) 3,877/4,389 (88.3%) coordination key 878/1,106 (79.4%) 881/1,106 (79.7%) 897/1,106 (81.1%) scope ambiguity of coordinate structures is subsumed within this dependency evaluation." ></td>
	<td class="line x" title="185:221	The dependency structures obtained were evaluated with regard to dependency accuracy  the proportion of correct dependencies out of all dependencies except for the last one in the sentence end 6." ></td>
	<td class="line x" title="186:221	Table 2 lists the dependency accuracy." ></td>
	<td class="line x" title="187:221	In this table, rule-coord-w/sim represents a rule-based dependency parser; prob-coord-w/sim represents the probabilistic parser of dependency, coordinate and case structure (Kawahara and Kurohashi, 2007); and prob-coord-wo/sim represents our proposed model." ></td>
	<td class="line x" title="188:221	all represents the overall accuracy, and coordination key represents the accuracy of only the coordination key bunsetsus." ></td>
	<td class="line x" title="189:221	The proposed model, prob-coord-wo/sim, signicantly outperformed both rule-coord-w/sim and prob-coordw/sim (McNemars test; p < 0.05) for all." ></td>
	<td class="line x" title="190:221	Figure 4 shows some analyses that are correctly analyzed by the proposed method." ></td>
	<td class="line x" title="191:221	For example, in sentence (1), our model can recognize the correct coordinate structure that conjoins densya-no hassyaaizu (departure signals of trains) and keitaidenwa-no tyakushinon (ring tones of cell phones)." ></td>
	<td class="line x" title="192:221	This is because the case frame of ongaku-ni naru (become music) is likely to generate hassyaaizu (departure signal) and tyakushinon (ring tone)." ></td>
	<td class="line x" title="193:221	To compare our results with a state-of-the-art discriminative dependency parser, we input the same test corpus into an SVM-based Japanese dependency parser, CaboCha7(Kudo and Matsumoto, 2002)." ></td>
	<td class="line x" title="194:221	Its dependency accuracy was 86.7% (3,807/4,389), which is close to that of rule-coord-w/sim." ></td>
	<td class="line x" title="195:221	This low accuracy is attributed to the lack of the consideration of coordinate structures." ></td>
	<td class="line x" title="196:221	Though dependency structures are closely related to coordinate structures, the CaboCha parser failed to incorporate coordination features." ></td>
	<td class="line x" title="197:221	Another cause of the low accuracy is the out-of-domain training corpus." ></td>
	<td class="line x" title="198:221	That is, the parser is trained on a newspaper corpus, whereas 6Since Japanese is head-nal, the second to last bunsetsu unambiguouslydependsonthelast bunsetsu, andthelast bunsetsu has no dependency." ></td>
	<td class="line x" title="199:221	7http://chasen.org/taku/software/cabocha/ the test corpus is obtained from the web, because of the non-availability of a tagged web corpus that is large enough to train a supervised parser." ></td>
	<td class="line x" title="200:221	6.2 Discussion We presented a method for coordination disambiguation without using similarities, and this method achieved better performance than the conventional approaches based on similarities." ></td>
	<td class="line x" title="201:221	Though we do not use similarities, we implicitly consider similarities between conjuncts." ></td>
	<td class="line x" title="202:221	This is because the heads of preand post-conjuncts share a case marker and a predicate, and thus they are essentially similar." ></td>
	<td class="line x" title="203:221	Our idea is related to the notion of distributional similarity." ></td>
	<td class="line oc" title="204:221	Chantree et al.(2005) applied the distributional similarity proposed by Lin (1998) to coordination disambiguation." ></td>
	<td class="line o" title="206:221	Lin extracted from a corpus dependency triples of two words and the grammatical relationship between them, and considered that similar words are likely to have similar dependency relations." ></td>
	<td class="line x" title="207:221	The difference between Chantree et al.(2005) and ours is that their method does not use the information of verbs in the sentence under consideration, but use only the cooccurrence information extracted from a corpus." ></td>
	<td class="line x" title="209:221	On the other hand, the disadvantage of our model is that it cannot consider the parallelism of conjuncts, which still seems to exist in especially strongcoordinatestructures." ></td>
	<td class="line x" title="210:221	Handlingofsuchparallelism is an open question of our model." ></td>
	<td class="line x" title="211:221	The generation process adopted in this work is similar to the design of dependency structure described in Hudson (1990), which lets the conjuncts have a dependency relation to the predicate." ></td>
	<td class="line x" title="212:221	Nilsson et al.(2006) mentioned this notion, but did not consider this idea in their experiments of tree transformations for data-driven dependency parsers." ></td>
	<td class="line x" title="214:221	In addition, it is not necessary for our method to transform dependency trees in preand post-processes, because we just changed the process of generation in the generative parser." ></td>
	<td class="line x" title="215:221	7 Conclusion In this paper, we rst came up with a hypothesis that coordinate structures are supported by 431 a63 a63(1) densya-no hassyaaizu-ya, keitaidenwa-no tyakushinon-madega ongaku-ni naru-hodoni,  train-GEN departure signal cell phone-GEN ring tone-also music-ACC become (departure signals of trains and ring tones of cell phones become music, ) a63 a63(2) nabe-ni dashijiru 3 kappu-to, nokori-no syouyu, mirin, sake-wo irete,  pot-DAT stock three cups-and remainder-GEN soy mirin sake-ACC pour (pour three cups of stock and remaining soy, mirin and sake to the pot, ) Figure 4: Examples of correct analyses." ></td>
	<td class="line x" title="216:221	The dotted lines represent the analysis by the baseline, probcoord-w/sim, and the solid lines represent the analysis by the proposed method, prob-coord-wo/sim." ></td>
	<td class="line x" title="217:221	surrounding dependency relations." ></td>
	<td class="line x" title="218:221	Based on this hypothesis, we built an integrated probabilistic model for coordination disambiguation and dependency/case structure analysis." ></td>
	<td class="line x" title="219:221	This model does not make use of similarities to analyze coordinate structures, but takes advantage of selectional preferences from a huge raw corpus and large-scale case frames." ></td>
	<td class="line x" title="220:221	The experimental results indicate the effectiveness of our model, and thus support our hypothesis." ></td>
	<td class="line x" title="221:221	Our future work involves incorporating ellipsis resolution to develop an integrated model for syntactic, case, and ellipsis analysis." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1058
Extending a Thesaurus with Words from Pan-Chinese Sources
Kwong, Oi Yee;Tsou, Benjamin K.;"></td>
	<td class="line x" title="1:158	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 457464 Manchester, August 2008 Extending a Thesaurus with Words from Pan-Chinese Sources Oi Yee Kwong and Benjamin K. Tsou Department of Chinese, Translation and Linguistics Language Information Sciences Research Centre City University of Hong Kong Tat Chee Avenue, Kowloon, Hong Kong {rlolivia, rlbtsou}@cityu.edu.hk  Abstract In this paper, we work on extending a Chinese thesaurus with words distinctly used in various Chinese communities." ></td>
	<td class="line x" title="2:158	The acquisition and classification of such region-specific lexical items is an important step toward the larger goal of constructing a Pan-Chinese lexical resource." ></td>
	<td class="line x" title="3:158	In particular, we extend a previous study in three respects: (1) to improve automatic classification by removing duplicated words from the thesaurus, (2) to experiment with classifying words at the subclass level and semantic head level, and (3) to further investigate the possible effects of data heterogeneity between the region-specific words and words in the thesaurus on classification performance." ></td>
	<td class="line x" title="4:158	Automatic classification was based on the similarity between a target word and individual categories of words in the thesaurus, measured by the cosine function." ></td>
	<td class="line x" title="5:158	Experiments were done on 120 target words from four regions." ></td>
	<td class="line x" title="6:158	The automatic classification results were evaluated against a gold standard obtained from human judgements." ></td>
	<td class="line x" title="7:158	In general accuracy reached 80% or more with the top 10 (out of 80+) and top 100 (out of 1,300+) candidates considered at the subclass level and semantic head level respectively, provided that the appropriate data sources were used." ></td>
	<td class="line x" title="8:158	 2008." ></td>
	<td class="line x" title="9:158	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-ncsa/3.0/)." ></td>
	<td class="line x" title="10:158	Some rights reserved." ></td>
	<td class="line x" title="11:158	1 Introduction A unique problem in Chinese language processing arises from the extensive lexical variations among major Chinese speech communities." ></td>
	<td class="line x" title="12:158	Although different communities (e.g. Beijing, Hong Kong, Taipei and Singapore) often share a large core lexicon, lexical variations could occur in at least two ways." ></td>
	<td class="line x" title="13:158	On the one hand, even the same word forms shared by various communities could be used with different meanings." ></td>
	<td class="line x" title="14:158	For instance, the word (ju1wu1)1 refers to general housing in Mainland China but specifically to housing under the Home Ownership Scheme in Hong Kong." ></td>
	<td class="line x" title="15:158	On the other hand, there are substantially different lexical items used for lexicalizing common or region-specific concepts." ></td>
	<td class="line x" title="16:158	For example, while the word  (zhu4fang2) is similarly used as  to mean general housing in Mainland China, it is rarely seen in the Hong Kong context; and  (xia4gang3) is specific, if not exclusive, to Mainland China for referring to a special concept of unemployment." ></td>
	<td class="line x" title="17:158	Existing Chinese lexical resources are often based on language use in one particular region and are therefore not comprehensive enough to capture the substantial regional variation as an important part of the lexical knowledge, which will be useful and critical for many NLP applications, including natural language understanding, information retrieval, and machine translation." ></td>
	<td class="line x" title="18:158	Tsou and Kwong (2006) proposed a comprehensive Pan-Chinese lexical resource, using a large and unique synchronous Chinese corpus as an authentic source of lexical variation among various Chinese speech communities." ></td>
	<td class="line x" title="19:158	They also studied the feasibility of taking an existing Chinese thesaurus as leverage and classifying new words from various Chinese communities with respect to the classificatory structure therein (Kwong and Tsou, 2007)." ></td>
	<td class="line x" title="20:158	They used the catego 1 The transcriptions in brackets are based on Hanyu Pinyin." ></td>
	<td class="line x" title="21:158	457 ries at the subclass level of the Tongyici Cilin ( , abbreviated as Cilin hereafter) for the task." ></td>
	<td class="line x" title="22:158	The classification was done by comparing the similarity of a target word (i.e. the word to be classified) and individual categories of words in the thesaurus based on a feature vector of cooccurring words in a corpus." ></td>
	<td class="line x" title="23:158	Since words in the thesaurus are mostly based on lexical items used in Mainland China, and the target words come from various Chinese communities, a major issue in the classification task is thus the heterogeneity of the data sources." ></td>
	<td class="line x" title="24:158	It was hypothesized that the datasets from which the features were extracted (for the target words and words in the thesaurus respectively) may affect the performance of automatic classification." ></td>
	<td class="line x" title="25:158	The experimental results supported the hypothesis in part, and the actual effect varied with datasets from individual regions." ></td>
	<td class="line x" title="26:158	Moreover, there is room to improve the overall accuracy for the method to be useful in practice, and it appears that the duplicated words in the thesaurus might have skewed the similarity measurement to a certain extent." ></td>
	<td class="line x" title="27:158	The current study thus attempts to extend this previous study in three respects: (1) to improve automatic classification by removing duplicated words from the thesaurus, (2) to experiment with classifying words at the subclass level and semantic head level (a finer level), and (3) to further investigate the possible effects of data heterogeneity between the region-specific words and words in the thesaurus on classification performance." ></td>
	<td class="line x" title="28:158	In Section 2, we will briefly review related work and the background of the current study." ></td>
	<td class="line x" title="29:158	In Sections 3 and 4, we will describe the materials used and the experimental setup respectively." ></td>
	<td class="line x" title="30:158	Results will be presented in Section 5 and discussed in Section 6, followed by a conclusion in Section 7." ></td>
	<td class="line x" title="31:158	2 Related Work To build a semantic lexicon, one has to identify the relation between words within a semantic hierarchy, and to group similar words together into a class." ></td>
	<td class="line x" title="32:158	Previous work on automatic methods for building semantic lexicons could be divided into two main groups." ></td>
	<td class="line oc" title="33:158	One is automatic thesaurus acquisition, that is, to identify synonyms or topically related words from corpora based on various measures of similarity (e.g. Riloff and Shepherd, 1997; Lin, 1998; Caraballo, 1999; Thelen and Riloff, 2002; You and Chen, 2006)." ></td>
	<td class="line x" title="34:158	Another line of research, which is more closely related to the current study, is to extend existing thesauri by classifying new words with respect to their given structures (e.g. Tokunaga et al., 1997; Pekar, 2004)." ></td>
	<td class="line x" title="35:158	An early effort along this line is Hearst (1992), who attempted to identify hyponyms from large text corpora, based on a set of lexico-syntactic patterns, to augment and critique the content of WordNet." ></td>
	<td class="line x" title="36:158	Ciaramita (2002) compared several models in classifying nouns with respect to a simplified version of WordNet and signified the gain in performance with morphological features." ></td>
	<td class="line x" title="37:158	For Chinese, Tseng (2003) proposed a method based on morphological similarity to assign a Cilin category to unknown words from the Sinica corpus which were not in the Chinese Electronic Dictionary and Cilin; but somehow the test data were taken from Cilin, and therefore could not really demonstrate the effectiveness with unknown words found in the Sinica corpus." ></td>
	<td class="line x" title="38:158	Kwong and Tsou (2007) attempted to classify words distinctly used in Beijing, Hong Kong, Singapore, and Taiwan, with respect to the Cilin classificatory structure." ></td>
	<td class="line x" title="39:158	They brought up the issue of data heterogeneity in the task." ></td>
	<td class="line x" title="40:158	In general, automatic classification of words via similarity measurement between two words, or between a word and a class of words, was often done on words from a similar data source, with the assumption that the feature vectors under comparison are directly comparable." ></td>
	<td class="line x" title="41:158	In the Pan-Chinese context, however, the words to be classified come from corpora collected from various Chinese speech communities, but the words in the thesaurus are often based on usages found in a particular community, such as Mainland China in the case of Cilin." ></td>
	<td class="line x" title="42:158	It is thus questionable whether the words in Cilin would appear in comparable contexts in texts from other places, thus affecting the similarity measurement." ></td>
	<td class="line x" title="43:158	In view of this heterogeneous nature of the data, they experimented with extracting feature vectors for the Cilin words from different datasets and found that the classification of words from Taipei was most affected in this regard." ></td>
	<td class="line x" title="44:158	In general, up to 85% accuracy was reached with the top 15 candidates for classification at the Cilin subclass level." ></td>
	<td class="line x" title="45:158	This performance, however, should be improved for the method to be useful in practice." ></td>
	<td class="line x" title="46:158	It is observed that Cilin, as most other thesauri, does not have a mutually exclusive classification." ></td>
	<td class="line x" title="47:158	Many words appear in more than one category (at various levels)." ></td>
	<td class="line x" title="48:158	Such duplication may affect the similarity comparison 458 between a target word and words in a category." ></td>
	<td class="line x" title="49:158	The current study thus attempts to avoid this confounding factor by removing duplicated words from Cilin for the comparison of similarity, and to extend the classification to a finer level." ></td>
	<td class="line x" title="50:158	3 Materials 3.1 The Tongyici Cilin The Tongyici Cilin () (Mei et al., 1984) is a Chinese synonym dictionary, or more often known as a Chinese thesaurus in the tradition of the Rogets Thesaurus for English." ></td>
	<td class="line x" title="51:158	The Rogets Thesaurus has about 1,000 numbered semantic heads, more generally grouped under higher level semantic classes and subclasses, and more specifically differentiated into paragraphs and semicolon-separated word groups." ></td>
	<td class="line x" title="52:158	Similarly, some 70,000 Chinese lexical items are organized into a hierarchy of broad conceptual categories in Cilin." ></td>
	<td class="line x" title="53:158	Its classification consists of 12 top-level semantic classes, 94 subclasses, 1,428 semantic heads and 3,925 paragraphs." ></td>
	<td class="line x" title="54:158	It was first published in the 1980s and was based on lexical usages mostly of post-1949 Mainland China." ></td>
	<td class="line x" title="55:158	In the current study, we will focus on the subclass level and semantic head level." ></td>
	<td class="line x" title="56:158	Some example subclasses and semantic heads are shown in Table 1." ></td>
	<td class="line x" title="57:158	We classify words with respect to the subclass level and semantic head level (that is, second and third levels in the Cilin organisation)." ></td>
	<td class="line x" title="58:158	Moreover, we skip class K and class L as the former contains mostly function words and the latter longer expressions." ></td>
	<td class="line x" title="59:158	We are thus considering 88 subclasses and 1,356 semantic heads in this study." ></td>
	<td class="line x" title="60:158	Within classes A to J, there are 7,517 words which were found to appear in more than one category." ></td>
	<td class="line x" title="61:158	Upon removing these entries, 44,588 words were used in the similarity comparison for the current study." ></td>
	<td class="line x" title="62:158	Class Subclasses Semantic Heads A  (Human) Aa  Ae  (Occupation)  Af (Identity)  An Aa01  Ae10     (commander, soldier)  An07 B  (Things) Ba  Bb  (Shape)  Bi  (Animal) Bm  (Material)Bq  (Clothing)  Br Ba01  Bm08   (coal, carbon)  Bn03  (room)  Br14 C  (Time and Space) Ca  (Time)  Cb  (Space) Ca01  Ca18  (year)  Cb28  (location)  Cb30 D  (Abstract entities) Da   (Condition)  Df  (Ideology)  Di   (Society) Dj  (Economics)  Dm  (Organization) Dn   (Quantity) Da01  Di10   (group, party)  Dj04     (capital, interest) Dj05   (currency, invoice)  Dm01  (government)  Dn10 E  (Characteristics) Ea  Ed  (Property) Ef Ea01  Ed03   (goodness, badness)  Ef14 F  (Action) Fa  Fd  (Body action) Fa01  Fb01   (run)  Fd09 G  (Psychological activities) Ga  Gb  (Psychological activities) Gc Ga01  Gb01     (imagine, think)  Gc04 H  (Activities) Ha  He  (Economic activities)  Hd  (Production)  Hf   (Transportation) Hg  (Scientific research) Hi  (Social contact) Hj  (Livelihood) Ha01  Hc09      (in charge, administer, lead)  He03   (buy, sell)  Hg01    (teach, demo)  Hj12     (do, cooperate, try)  Hn13 I  (Phenomenon and state) Ia  If  (Circumstance)  Ig  (Process) Ih Ia01  Ig01   (begin, end)  Ih05    (increase, decrease)  Ih13 J  (Association) Ja  (Liaison)  Jb  (Similarity and Difference) Jc  (Matching)  Je Ja01  Jc01    (adapt, match)  Je14 Table 1  Some Examples of Cilin Subclasses and Semantic Heads  3.2 The LIVAC Synchronous Corpus LIVAC (http://www.livac.org) stands for Linguistic Variation in Chinese Speech Communities." ></td>
	<td class="line x" title="63:158	It is a synchronous corpus developed and dynamically maintained by the Language Information Sciences Research Centre of the City University of Hong Kong since 1995 (Tsou and Lai, 2003)." ></td>
	<td class="line x" title="64:158	The corpus consists of newspaper articles collected regularly and synchronously from six Chinese speech communities, namely Hong Kong, Beijing, Taipei, Singapore, Shang459 hai, and Macau." ></td>
	<td class="line x" title="65:158	Texts collected cover a variety of domains, including front page news stories, local news, international news, editorials, sports news, entertainment news, and financial news." ></td>
	<td class="line x" title="66:158	Up to December 2007, the corpus has already accumulated over 250 million character tokens which, upon automatic word segmentation and manual verification, yielded about 1.2 million word types." ></td>
	<td class="line x" title="67:158	For the present study, we made use of subcorpora consisting of the financial news sections collected over the 9-year period 1995-2004 from Beijing (BJ), Hong Kong (HK), Singapore (SG), and Taipei (TW)." ></td>
	<td class="line x" title="68:158	Table 2 shows the sizes of the subcorpora." ></td>
	<td class="line x" title="69:158	Region Size of Financial Subcorpus (rounded to nearest 1K)  Word Token Word Type BJ 232K 20K HK 970K 38K SG 621K 28K TW 254K 22K Table 2  Sizes of Individual Subcorpora  3.3 Test Data Kwong and Tsou (2006) observed that among the unique lexical items found from the individual subcorpora, only about 30-40% are covered by Cilin, but not necessarily in the expected senses." ></td>
	<td class="line x" title="70:158	In other words, Cilin could in fact be enriched with over 60% of the unique items from various regions." ></td>
	<td class="line x" title="71:158	In the current study, we sampled the most frequent 30 words distinctly and predominantly used in each of the BJ, HK, SG, and TW subcorpus." ></td>
	<td class="line x" title="72:158	Classification was based on their similarity with each of the Cilin subclasses and semantic heads, compared by the cosine measure, as discussed in Section 4.2." ></td>
	<td class="line x" title="73:158	4 Experiments 4.1 Setting the Gold Standard Three linguistics undergraduate students and one research student on computational linguistics from the City University of Hong Kong were asked to assign what they would consider to be the most appropriate Cilin category (at the subclass and semantic head level) to each of the 120 target words." ></td>
	<td class="line x" title="74:158	All human judges reported difficulties in various degrees in assigning Cilin categories to the target words." ></td>
	<td class="line x" title="75:158	The major problem came from the regional specificity and thus the unfamiliarity of the judges with the respective lexical items and contexts." ></td>
	<td class="line x" title="76:158	For example, all judges reported problem with the term  (zi4cuo1), one of the target words from Singapore referring to  (zi4cuo1gu3shi4, CLOB in the Singaporean stock market), which is specific to Singapore." ></td>
	<td class="line x" title="77:158	Notwithstanding the difficulty, the interannotator agreement, as measured by Kappa, was found to be 0.6870 at the subclass level and 0.5971 at the semantic head level." ></td>
	<td class="line x" title="78:158	We took a loose approach to form the gold standard, which includes all categories (at the subclass level and semantic head level respectively) assigned by one or more judges." ></td>
	<td class="line x" title="79:158	Automatic classification will be considered correct if any of these categories is matched." ></td>
	<td class="line x" title="80:158	4.2 Automatic Classification Each target word was compared to all Cilin categories and automatically classified to the category which is most similar to it." ></td>
	<td class="line x" title="81:158	The Cilin data was first pre-processed to remove duplicated words." ></td>
	<td class="line x" title="82:158	We compute the similarity by the cosine between the two corresponding feature vectors containing all co-occurring content words in a corpus within a window of 5 words (excluding many general adjectives and adverbs, and numbers and proper names were all ignored)." ></td>
	<td class="line x" title="83:158	The feature vector of a Cilin category is based on the union of the features from all individual members in the category." ></td>
	<td class="line x" title="84:158	The cosine of two feature vectors vv and wv  is computed as  wv wvwv vv vvvv =),cos(  The feature vector of a given target word is extracted from the respective subcorpus from which the target word was found (called the target subcorpus hereafter)." ></td>
	<td class="line x" title="85:158	To study the data heterogeneity effect, we experimented with two conditions for the extraction of feature vectors for Cilin words: from the target subcorpus or from the BJ subcorpus which is assumed to be representative of usages in Mainland China." ></td>
	<td class="line x" title="86:158	All automatic classification results were evaluated against the gold standard based on hu460 Sub-tw-tw 0 10 20 30 40 50 60 70 80 90 100 0 5 10 15 Top N Candidates Ac cu rac y ( %) Baseline With Duplicates No Duplicates Sub-hk-hk 0 10 20 30 40 50 60 70 80 90 100 0 5 10 15 Top N Candidates Ac cu rac y ( %) Baseline With Duplicates No Duplicates Sub-sg-sg 0 10 20 30 40 50 60 70 80 90 100 0 5 10 15 Top N Candidates Ac cu rac y ( %) Baseline With Duplicates No Duplicates Sub-bj-bj 0 10 20 30 40 50 60 70 80 90 100 0 5 10 15 Top N Candidates Ac cu rac y ( %) Baseline With Duplicates No Duplicates Sub-bj-bj 0 10 20 30 40 50 60 70 80 90 100 0 5 10 15 Top N Candidates Ac cu rac y ( %) Baseline Sub-bj-bj Sub-tw-tw and Sub-tw-bj 0 10 20 30 40 50 60 70 80 90 100 0 5 10 15 Top N Candidates Ac cu rac y ( %) Baseline Sub-tw-tw Sub-tw-bj Sub-hk-hk and Sub-hk-bj 0 10 20 30 40 50 60 70 80 90 100 0 5 10 15 Top N Candidates Ac cu rac y ( %) Baseline Sub-hk-hk Sub-hk-bj Sub-sg-sg and Sub-sg-bj 0 10 20 30 40 50 60 70 80 90 100 0 5 10 15 Top N Candidates Ac cu rac y ( %) Baseline Sub-sg-sg Sub-sg-bj man judgements as discussed in Section 4.1." ></td>
	<td class="line x" title="87:158	Classification performance is measured based on the correctness of the top N candidates." ></td>
	<td class="line x" title="88:158	4.3 Baseline A simple baseline measure was obtained by ranking the subclasses in descending order of the number of words they cover." ></td>
	<td class="line x" title="89:158	It was assumed that the bigger the subclass size, the more likely it covers a new term." ></td>
	<td class="line x" title="90:158	The top N candidates in this ranking were checked against the gold standard as above." ></td>
	<td class="line x" title="91:158	5 Results In the following discussion, we will use labels in the form of <Cat>-<Target>-<CilinFeatSource> to refer to the various testing conditions, where Cat refers to the category type, Target to the originating source of the target words, and CilinFeatSource to the source from which the feature vectors for the Cilin words were extracted." ></td>
	<td class="line x" title="92:158	Thus the label Sub-hk-hk means classification of HK target words at the Cilin subclass level, with feature vectors for target words and Cilin words extracted from the HK subcorpus; and the label Head-tw-bj means classification of TW target words at the Cilin semantic head level, with feature vectors for the target words extracted from the TW subcorpus and those for the Cilin words extracted from the BJ subcorpus." ></td>
	<td class="line x" title="93:158	5.1 Pre-processing of Cilin Figure 1 shows the comparison of classification accuracy for words from the four regions at the subclass level before and after duplicates in Cilin were removed." ></td>
	<td class="line x" title="94:158	All feature vectors were extracted from the respective target corpora." ></td>
	<td class="line x" title="95:158	Figure 1  Effect of Pre-processing Cilin It can be seen from Figure 1 that removing duplicated words in Cilin could improve the classification of words from all regions at the subclass level." ></td>
	<td class="line x" title="96:158	5.2 Data Heterogeneity Effect As explained earlier, since the words to be classified come from various Chinese speech communities, but the words in Cilin are mostly based on usages found in Mainland China, it is uncertain whether the words in Cilin would appear in comparable contexts in texts from other places, for the similarity measurement to be effective." ></td>
	<td class="line x" title="97:158	Hence, we experimented with two conditions for extracting feature vectors for the Cilin words." ></td>
	<td class="line x" title="98:158	While the features for a target word to be classified are extracted from the respective target subcorpus, the features for the Cilin words are extracted either from the target subcorpus or from the BJ subcorpus." ></td>
	<td class="line x" title="99:158	Figure 2 shows the data heterogeneity effect on the classification of target words from various regions at the subclass level." ></td>
	<td class="line x" title="100:158	Figure 2  Data Heterogeneity Effect  The data heterogeneity effect is most noticeable for the TW words." ></td>
	<td class="line x" title="101:158	Extracting features for the Cilin words from the BJ subcorpus always gives better classification results for the TW words, than if the features were extracted from the TW subcorpus." ></td>
	<td class="line x" title="102:158	The difference between Subhk-hk and Sub-hk-bj, and that between Sub-sg-sg and Sub-sg-bj, however, is not as great." ></td>
	<td class="line x" title="103:158	This suggests that the lexical difference is particularly significant between BJ and TW." ></td>
	<td class="line x" title="104:158	5.3 Fine-grainedness of Classification The semantic head level is more fine-grained than the subclass level, and is expected to be 461 Head-bj-bj 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 110 Top N Candidates Ac cu rac y ( %) Head-bj-bj Head-tw-tw and Head-tw-bj 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 110 Top N Candidates Ac cu rac y ( %) Head-tw-tw Head-tw-bj Head-hk-hk and Head-hk-bj 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 110 Top N Candidates Ac cu rac y ( %) Head-hk-hk Head-hk-bj Head-sg-sg and Head-sg-bj 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 110 Top N Candidates Ac cu rac y ( %) Head-sg-sg Head-sg-bj more difficult for classification." ></td>
	<td class="line x" title="105:158	Figure 3 shows the results of classification at the semantic head level, with the effect of data heterogeneity." ></td>
	<td class="line x" title="106:158	Figure 3  Semantic Head Level Classification  It is observed from Figures 2 and 3 that data heterogeneity affects the classification of TW words at both the subclass and semantic head level." ></td>
	<td class="line x" title="107:158	In both cases, features for Cilin words extracted from BJ subcorpus work better than those from TW subcorpus." ></td>
	<td class="line x" title="108:158	A somewhat opposite effect was observed for SG target words, especially beyond the top 5 to 10 candidates." ></td>
	<td class="line x" title="109:158	There is not much difference for the HK target words." ></td>
	<td class="line x" title="110:158	The classification at the semantic head level is expectedly less precise than that at the subclass level." ></td>
	<td class="line x" title="111:158	At the subclass level, 80% or more accuracy could be reached with the top 10 candidates considered, whereas the top 50 candidates or more would be needed to reach a similar level of accuracy at the semantic head level." ></td>
	<td class="line x" title="112:158	This is nevertheless encouraging in view of the total number of categories at the semantic head level." ></td>
	<td class="line x" title="113:158	6 Discussions 6.1 Overall Classification Accuracy From the results reported in the last section, it can be seen that removing the duplicated words in Cilin could help improve the classification accuracy at all conditions." ></td>
	<td class="line x" title="114:158	This is because some words, which appear in more than one category at the subclass or semantic head level, might skew the similarity measured between a target word and a given category." ></td>
	<td class="line x" title="115:158	An example will be discussed in Section 6.3." ></td>
	<td class="line x" title="116:158	In general, the top 10 candidates could lead to over 80% accuracy at the subclass level (much improved from previous results before removing duplicates in Cilin, where it usually took the top 15 candidates to reach about 80% accuracy)." ></td>
	<td class="line x" title="117:158	At the semantic head level, the top 50 candidates could lead to over 70% accuracy for HK and TW words and to 80% or more for BJ and SG words." ></td>
	<td class="line x" title="118:158	The accuracy, nevertheless, is also dependent on the datasets from which features were extracted, as shown in Sections 5.2 and 5.3 above and further discussed below." ></td>
	<td class="line x" title="119:158	6.2 Regional Variation The various Chinese speech communities might differ not only in the lexical items they use, but also in the way they use the lexical items in common." ></td>
	<td class="line x" title="120:158	The demand on cross-cultural knowledge thus poses a challenge for building a PanChinese lexical resource manually." ></td>
	<td class="line x" title="121:158	Cilin, for instance, is quite biased in language use in Mainland China, and it requires experts with knowledge of a wide variety of Chinese terms to be able to manually classify lexical items specific to other Chinese speech communities." ></td>
	<td class="line x" title="122:158	It is therefore even more important to devise robust ways for automatic classification of words from various regions." ></td>
	<td class="line x" title="123:158	The data heterogeneity effect is quite different for the classification of SG words and TW words, but apparently not very significant for HK words." ></td>
	<td class="line x" title="124:158	Beyond the top 5 to 10 candidates, features extracted from the SG subcorpus for Cilin words seem to have an advantage." ></td>
	<td class="line x" title="125:158	This suggests that although the SG subcorpus shares those words in Cilin, the context in which they are used might be slightly different from their use in Mainland China." ></td>
	<td class="line x" title="126:158	Thus extracting their contextual features from the SG subcorpus might better reflect their usage and make them more comparable with the target words from SG." ></td>
	<td class="line x" title="127:158	For the TW words, on the contrary, features for Cilin words extracted from the BJ subcorpus always have an advantage over those extracted from the TW subcorpus." ></td>
	<td class="line x" title="128:158	As Kwong and Tsou (2006) observed, Beijing and Taipei data share the least number of lexical items among the four regions under investigation." ></td>
	<td class="line x" title="129:158	Words in Cilin therefore might not have the appropriate contextual feature vectors extracted from the TW subcorpus." ></td>
	<td class="line x" title="130:158	6.3 Analysis for Individual Words In order to study the actual effect of various experimental conditions on the classification of individual target words, we also worked out the change in the ranking (r) of the correct category for each target word." ></td>
	<td class="line x" title="131:158	A negative r thus corre462 sponds to an improvement in the classification as the new ranking of the correct category is smaller (earlier) than the old one." ></td>
	<td class="line x" title="132:158	Table 3 shows some examples with improvement in this regard." ></td>
	<td class="line x" title="133:158	The Rank column refers to the rank of the correct category in Sub-{bj,hk,tw,sg}-bj, r(D) is the change after duplicates were removed from Cilin, and r(H) is the change from Sub-x-x conditions." ></td>
	<td class="line x" title="134:158	No." ></td>
	<td class="line x" title="135:158	Word (Region) Rank r(D) r(H) 1  (BJ) 1 -6 2  (BJ) 3 -15 3  (BJ) 1 -1 4  (BJ) 1 -2 5  (BJ) 3 -2 6  (HK) 4 -4 -6 7  (HK) 2 -3 -6 8  (HK) 1 -6 -1 9  (HK) 1 -8 -5 10   (HK) 2 -4 -5 11  (SG) 1 -3 -4 12  (SG) 1 -12 -1 13  (SG) 1 -3 -1 14  (SG) 2 -2 -4 15  (SG) 2 -7 1 16  (TW) 3 -1 -13 17  (TW) 2 -3 -7 18  (TW) 1 0 -3 19  (TW) 6 -3 -20 20  (TW) 3 -6 -5 Table 3  Ranking Change for Individual Words2  Take the example of the BJ target word   (xin4xi1hua4, informationize)." ></td>
	<td class="line x" title="136:158	Before duplicated words were removed from Cilin, the most appropriate subclass (Ih:Change) ranked 7th in the automatic classification." ></td>
	<td class="line x" title="137:158	Upon the removal of duplicated words, subclass Ih ranked first in the results." ></td>
	<td class="line x" title="138:158	The words shared by other top ranking subclasses (e.g. Je:influence, Da:condition, etc.) such as  (jia1, increase),  (tui1, push),  (ti2gao1, raise), etc., may have skewed the similarity comparison by introducing many common co-occurring words which are not particularly characteristic of any subclass." ></td>
	<td class="line x" title="139:158	For the TW target word  (tou2xin4, investment trust), the appropriate subclass  2 English gloss: 1-informationize, 2-re-employed, 3unemployed, 4-resist drought, 5-quality check, 6-general trend of stock market, 7-buy in stocks, 8-H stock, 9-interest rate, 10-sell (stocks), 11-Singaporean dollar, 12-Malaysian stocks, 13-closing price, 14-rights issue, 15-holding space rate, 16-investment trust, 17-growth rate, 18-financial holdings, 19-over-bought, 20-bank." ></td>
	<td class="line x" title="140:158	(Dm:organization) soared from the 16th to the 3rd when features were extracted for the Cilin words from the BJ subcorpus instead of the TW subcorpus." ></td>
	<td class="line x" title="141:158	It was observed that both vectors have a large part in common, but the one extracted from TW subcorpus contained many more spurious features which might not be characteristic of the subclass, thus affecting the similarity score." ></td>
	<td class="line x" title="142:158	It is also apparent that region-specific but common concepts like  (xie3zi4lou2, office),  (zu3wu1, apartment), and  (si1zhai2, private residence), etc., are more adversely affected when features for Cilin words were extracted from the BJ subcorpus instead of the respective target subcorpora, while other more core financial concepts could often take advantage of the former." ></td>
	<td class="line x" title="143:158	Thus it appears that the domain and concept specificity could also affect the effectiveness of the method." ></td>
	<td class="line x" title="144:158	6.4 Future Directions There is room to improve the results at both the subclass and semantic head level." ></td>
	<td class="line x" title="145:158	More qualitative analysis is needed for the data heterogeneity effect." ></td>
	<td class="line x" title="146:158	The category size, and as pointed out above, the domain and concept specificity are also worth further investigation." ></td>
	<td class="line x" title="147:158	The latter will thus involve the classification of words from other special domains like sports, as well as those from the general domain." ></td>
	<td class="line x" title="148:158	One problem we need to address in the next step is the class imbalance problem as Cilin categories could differ considerably in size, which will affect the number of features and subsequent classification." ></td>
	<td class="line x" title="149:158	For this we plan to try the k nearest neighbours approach." ></td>
	<td class="line x" title="150:158	In addition, the features might need to be constrained, as simple cooccurrence might be too coarse for distinguishing the subtle characteristics among Cilin categories." ></td>
	<td class="line x" title="151:158	7 Conclusion We have worked on extending a Chinese thesaurus with words distinctly used in various Chinese communities." ></td>
	<td class="line x" title="152:158	Classification results have improved as duplicated words in Cilin were removed." ></td>
	<td class="line x" title="153:158	In view of the demand on cross-cultural knowledge for building a Pan-Chinese lexical resource manually, it is particularly important to devise robust ways for automatic acquisition of such a resource." ></td>
	<td class="line x" title="154:158	Automatic classification of words with respect to an existing classificatory structure with proper datasets for feature extraction should be a prominent direction in this re463 gard." ></td>
	<td class="line x" title="155:158	Further investigation is needed to better understand the interaction among data heterogeneity, category size, feature selection, and the domain and concept specificity of the words." ></td>
	<td class="line x" title="156:158	Acknowledgements The work described in this paper was supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No." ></td>
	<td class="line x" title="157:158	CityU 1317/03H)." ></td>
	<td class="line x" title="158:158	The authors would like to thank Jingbo Zhu for useful discussions on an earlier draft of this paper, and the anonymous reviewers for their comments on the submission." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1086
A Joint Information Model for N-Best Ranking
Pantel, Patrick;Vyas, Vishnu;"></td>
	<td class="line x" title="1:180	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 681688 Manchester, August 2008 A Joint Information Model for n-best Ranking Patrick Pantel Yahoo!" ></td>
	<td class="line x" title="2:180	Inc. Santa Clara, CA 95054 me@patrickpantel.com Vishnu Vyas USC Information Sciences Institute Marina del Rey, CA vishnu@isi.edu  Abstract In this paper, we present a method for modeling joint information when generating n-best lists." ></td>
	<td class="line x" title="3:180	We apply the method to a novel task of characterizing the similarity of a group of terms where only a small set of many possible semantic properties may be displayed to a user." ></td>
	<td class="line x" title="4:180	We demonstrate that considering the results jointly, by accounting for the information overlap between results, generates better n-best lists than considering them independently." ></td>
	<td class="line x" title="5:180	We propose an information theoretic objective function for modeling the joint information in an n-best list and show empirical evidence that humans prefer the result sets produced by our joint model." ></td>
	<td class="line x" title="6:180	Our results show with 95% confidence that the n-best lists generated by our joint ranking model are significantly different from a baseline independent model 50.0%  3.1% of the time, out of which they are preferred 76.6%  5.2% of the time." ></td>
	<td class="line x" title="7:180	1 Introduction Ranking result sets is a pervasive problem in the NLP and IR communities, exemplified by keyword search engines such as Google (Brin and Page 1998), machine translation systems (Zhang et al. 2006), and recommender systems (Shardanand and Maes 1995; Resnick and Varian 1997)." ></td>
	<td class="line x" title="8:180	Consider the lexical semantics task of explaining why a set of terms are similar: given a set of terms and a large set of possible explanations for   2008." ></td>
	<td class="line x" title="9:180	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-ncsa/3.0/)." ></td>
	<td class="line x" title="10:180	Some rights reserved." ></td>
	<td class="line x" title="11:180	their similarity, one must choose only the best n explanations to display to a user." ></td>
	<td class="line x" title="12:180	There are many ways to explain why terms are similar 2 ; one way is to list the semantic properties that are shared by the terms." ></td>
	<td class="line x" title="13:180	For example, consider the following set of terms corresponding to fruit names:  {apple, ume, pawpaw, quince} Example semantic properties that could be used to explain their similarity include: they are products, they can be eaten, they are solid (but not they are companies, for example)." ></td>
	<td class="line x" title="14:180	The list of such semantic properties can be very large and some are much more informative than others." ></td>
	<td class="line x" title="15:180	For example, the property can-be-eaten is much more informative of the similarity of {apple, ume, pawpaw, quince} than the property is-solid." ></td>
	<td class="line x" title="16:180	Using a simple measure of association between properties and queries, explained in detail later in this paper, one can rank each property and obtain the following three highest scoring properties for explaining the similarity of these terms: {they are products, they can be imported, they can be exported} Even though can be imported and can be exported are highly ranked explanations, taken jointly, once we know one the other does not offer much more information since most things that can be imported can also be exported." ></td>
	<td class="line x" title="17:180	In other words, there is a large overlap in information between the two properties." ></td>
	<td class="line x" title="18:180	A more informative set of explanations could be obtained by replacing one of these two properties with a property that scored lower but had less information overlap with the others, for example:  2  In (Vyas and Pantel 2008), we explore the task of explaining the similarity between terms in detail." ></td>
	<td class="line x" title="19:180	In this paper, we focus on the task of choosing the best set of explanations given a set of candidates." ></td>
	<td class="line x" title="20:180	681 {they are products, they can be imported, they can be eaten} Even though, taken alone, the property can be eaten may not be as informative as can be exported, it does indeed add more information to the explanation set when considered jointly with the other explanations." ></td>
	<td class="line x" title="21:180	In this paper, we propose an information theoretic objective function for modeling the joint information in an n-best list." ></td>
	<td class="line x" title="22:180	Derived using conditional self-information, we measure the amount of information that each property contributes to a query." ></td>
	<td class="line x" title="23:180	Intuitively, when adding a new property to a result set, we should prefer a property that contributes the maximum amount of information to the existing set." ></td>
	<td class="line x" title="24:180	In our experiments, we show empirical evidence that humans prefer our joint models result sets on the task of explaining why a set of terms are similar." ></td>
	<td class="line x" title="25:180	The remainder of this paper is organized as follows." ></td>
	<td class="line x" title="26:180	In the next section, we review related literature and position our contribution within that landscape." ></td>
	<td class="line x" title="27:180	Section 3 presents the task of explaining the similarity of a set of terms and describes a method for generating candidate explanations from which we will apply our ranking model." ></td>
	<td class="line x" title="28:180	In Section 4, we formally define our ranking task and present our Joint Information Ranking model." ></td>
	<td class="line x" title="29:180	Experimental results are presented in Section 5 and finally, we conclude with a discussion and future work." ></td>
	<td class="line x" title="30:180	2 Related Work There are a vast number of applications of ranking and its importance to the commercial success at companies such as Google and Yahoo have fueled a great deal of research in recent years." ></td>
	<td class="line x" title="31:180	In this paper, we investigate one particular aspect of ranking, the importance of considering the results in an n-best list jointly because of the information overlap issues described in the introduction, and one particular application, namely explaining why a set of terms are similar." ></td>
	<td class="line x" title="32:180	Considering results jointly is not a new idea and is very similar to the concept of diversitybased ranking introduced in the IR community by Carbonell and Goldstein (1998)." ></td>
	<td class="line x" title="33:180	In short, selecting an n-best list is a balancing act between maximizing the relevance of the list and the information novelty of its results." ></td>
	<td class="line x" title="34:180	One commonly used approach is to define a measure of novelty/semantic similarity between documents and to apply heuristics to reduce the relevance score of a result item (a hit) by a function of the similarity of this item to other results in the list (Carbonell and Goldstein 1998; Zhu et al. 2007)." ></td>
	<td class="line x" title="35:180	Another common approach is to cluster result documents according to their semantic similarity and present clusters to users instead of individual documents (Hearst and Pedersen 1996; Leuski 2001; Liu and Croft 2004)." ></td>
	<td class="line x" title="36:180	In this paper, we argue that the balance between relevance and novelty can be captured by a formal model that maximizes the joint information content of a result set." ></td>
	<td class="line x" title="37:180	Instead of ranking documents in an IR setting, we focus in this paper on a new task of selecting the best semantic properties that describe the similarity of a set of query terms." ></td>
	<td class="line x" title="38:180	By no means an exhaustive list, the most commonly cited ranking and scoring algorithms are HITS (Kleinberg 1998) and PageRank (Page et al. 1998), which rank hyperlinked documents using the concepts of hubs and authorities." ></td>
	<td class="line x" title="39:180	The most well-known keyword scoring methods within the IR community are the tf-idf (Salton and McGill 1983) and pointwise mutual information (Church and Hanks 1989) measures, which put more importance on matching keywords that occur frequently in a document relative to the total number of documents that contain the keyword (by normalizing term frequencies with inverse document frequencies)." ></td>
	<td class="line x" title="40:180	Various methods including tf-idf have been comparatively evaluated by Salton and Buckley (1987)." ></td>
	<td class="line x" title="41:180	Creating nbest lists using the above algorithms produce result sets where each result is considered independently." ></td>
	<td class="line x" title="42:180	In this paper, we investigate the utility of considering the result sets jointly and compare our joint method to a pointwise mutual information model." ></td>
	<td class="line xc" title="43:180	Within the NLP community, n-best list ranking has been looked at carefully in parsing, extractive summarization (Barzilay et al. 1999; Hovy and Lin 1998), and machine translation (Zhang et al. 2006), to name a few." ></td>
	<td class="line x" title="44:180	The problem of learning to rank a set of objects by combining a given collection of ranking functions using boosting techniques is investigated in (Freund et al. 2003)." ></td>
	<td class="line x" title="45:180	This rank boosting technique has been used in re-ranking parsers (Collins and Koo 2000; Charniak and Johnson 2005)." ></td>
	<td class="line x" title="46:180	Such reranking approaches usually improve the likelihood of candidate results using extraneous features and, for example in parsing, the properties of the trees." ></td>
	<td class="line x" title="47:180	In this paper, we focus on a difference task: the lexical semantics task of selecting the best semantic properties that help explain why a set of query terms are similar." ></td>
	<td class="line x" title="48:180	Unlike in parsing and machine translation, we are not ulti682 mately looking for the best single result, but instead the n-best." ></td>
	<td class="line x" title="49:180	Looking at commercial applications, there are many examples showcasing the importance of ranking, for example Internet search engines like Google and Yahoo (Brin and Page 1998)." ></td>
	<td class="line x" title="50:180	Another application is online recommendation systems where suggestions must be ranked before being presented to a user (Shardanand and Maes 1995)." ></td>
	<td class="line x" title="51:180	Also, in online social networks such as Facebook and LinkedIn, new connections or communities are suggested to users by leveraging their social connections (Spretus, et al. 2005)." ></td>
	<td class="line x" title="52:180	3 Explaining Similarity Several applications, such as IR engines, return the n-best ranked results to a query." ></td>
	<td class="line x" title="53:180	Although we expect our joint information model, presented in Section 4.2, to generalize to many ranking tasks, our focus in this paper is on the task of choosing the n-best explanations that describe the similarity of a set of terms." ></td>
	<td class="line x" title="54:180	That is, given a set of terms, one must choose the best set of characterizations of why the terms are similar, chosen from a large set of possible explanations." ></td>
	<td class="line x" title="55:180	Analyzing the different ways in which one can explain/characterize the similarity between terms is beyond the scope of this paper 3 . The types of explanations that we consider in this paper are semantic properties that are shared by the terms." ></td>
	<td class="line x" title="56:180	For example, consider the query terms {apple, ume, pawpaw, quince} presented in Section 1." ></td>
	<td class="line x" title="57:180	An example set of properties that explains the similarity of these words might include {they are products, they can be imported, they can be exported, they are tasty, they grow}." ></td>
	<td class="line x" title="58:180	The range of possible semantic properties is large." ></td>
	<td class="line x" title="59:180	For the above example, we may have offered many other properties like {they are entities, they can be eaten, they have skin, they are words, they can be roasted, they can be shipped, etc.} Choosing a high quality concise set of properties is the goal of this paper." ></td>
	<td class="line x" title="60:180	Our hypothesis is that considering items in a result set jointly for ranking produces better result sets than considering them independently." ></td>
	<td class="line x" title="61:180	An important question then is: what is a utility function for measuring a better result?" ></td>
	<td class="line x" title="62:180	We propose that a result set is considered better than another if a person could more easily reconstruct the original query from it." ></td>
	<td class="line x" title="63:180	Or, in other words, a result set is considered better than another if it  3  This topic is the focus of (Vyas and Pantel 2008)." ></td>
	<td class="line x" title="64:180	reduces more the uncertainty of what the original query was." ></td>
	<td class="line x" title="65:180	Here, reducing the uncertainty means making it easier for a human to understand the original question (i.e., a good explanation should clarify the query)." ></td>
	<td class="line x" title="66:180	Formally, we define our ranking task as: Task Definition: Given a query Q = {q 1, q 2, , q m } and a set of candidate properties R = {r 1, r 2, , r k }, where q is a term and r is a property, find the set of properties R' = {r 1, r 2, , r n } that most reduces the uncertainty of Q, where n << k. Recall from Section 1 the example Q = {apple, ume, pawpaw, quince}." ></td>
	<td class="line x" title="67:180	The set of properties: {they are products, they can be imported, they can be eaten} is preferred over the set {they are products, they can be imported, they can be exported} since it reduces more the uncertainty of what the original query is. That is, if we hid the query {apple, ume, pawpaw, quince} from a person, the first set of properties would help more that person guess the query elements than the second properties." ></td>
	<td class="line x" title="68:180	In Section 4, we describe two models for measuring this uncertainty reduction and in Section 5.1, we describe an evaluation methodology for quantifying this reduction in uncertainty using human judgments." ></td>
	<td class="line x" title="69:180	3.1 Source of Properties What is the source of the semantic properties to be used as explanations?" ></td>
	<td class="line oc" title="70:180	Following Lin (1998), we use syntactic dependencies between words to model their semantic properties." ></td>
	<td class="line x" title="71:180	The assumption here is that some grammatical relations, such as subject and object can often yield semantic properties of terms." ></td>
	<td class="line x" title="72:180	For example, given enough corpus occurrences of a phrase like students eat many apples, then we can infer the properties can-be-eaten for apples and can-eat for students." ></td>
	<td class="line x" title="73:180	Unfortunately, many grammatical relations do not specify semantic properties, such as most conjunction relations for example." ></td>
	<td class="line x" title="74:180	In this paper, we use a combination of corpus statistics and manual filters of grammatical relations (such as omitting conjunction relations) to uncover candidate semantic properties, as described in the next section." ></td>
	<td class="line x" title="75:180	With this method, we unfortunately uncover some non-semantic properties and fail to uncover some correct semantic properties." ></td>
	<td class="line x" title="76:180	683 Improving the candidate lists of semantic properties is grounds for further investigation." ></td>
	<td class="line x" title="77:180	3.2 Extracting Properties Given a set of similar terms, we look at the overlapping syntactic dependencies between the words in the set to form candidate semantic properties." ></td>
	<td class="line x" title="78:180	Example properties extracted by our system (described below) for a random sample of two instances from a cluster of food, {apple, beef}, include 4 : shredded, sliced, lean, sour, delicious, cooked, import, export, eat, cook, dice, taste, market, consume, slice,  We obtain candidate properties by parsing a large textual corpus with the Minipar parser (Lin 1993) 5 . For each word in the corpus, we extract all of its dependency links, forming a feature vector of syntactic dependencies." ></td>
	<td class="line x" title="79:180	For example, below is a sample of the feature vector for the word apple: adj-mod:gala, adj-mod:shredded, object-of:caramelize, object-of:eat, object-of:import,  Intersecting apples feature vector with beefs, we are left with the following candidate properties: adj-mod:shredded, object-of:eat, object-of:import,  In this paper, we omit the relation name of the syntactic dependencies, and instead write:  shredded, eat, import,  This list of syntactic dependencies forms the candidate properties for our ranking task defined in Section 3." ></td>
	<td class="line x" title="80:180	In Section 4, we use corpus statistics over these syntactic dependencies to find the most informative properties that explain the similarity of a set of terms." ></td>
	<td class="line x" title="81:180	Some syntactic dependencies are not reliably descriptive of the similarity of words such as conjunctions and determiners." ></td>
	<td class="line x" title="82:180	We omit these dependency links from our model." ></td>
	<td class="line x" title="83:180	4 Ranking Models In this section, we present our ranking models for choosing the n-best results to a query according to our task definition from Section 3." ></td>
	<td class="line x" title="84:180	The models  4  We omit the syntactic relations for readability." ></td>
	<td class="line x" title="85:180	5  Section 5.1 describes the specific corpus and method that was used to obtain our reported results." ></td>
	<td class="line x" title="86:180	are expected to generalize to many ranking tasks, however in this paper we focus solely on the problem of choosing the best semantic properties that describe the similarity of a set of terms." ></td>
	<td class="line x" title="87:180	In the next section, we outline our baseline independent model, which is based on a commonly used ranking metric in lexical semantics for selecting the most informative properties of a term." ></td>
	<td class="line x" title="88:180	Then in Section 4.2, we propose our new model for considering the properties jointly." ></td>
	<td class="line x" title="89:180	4.1 EIIR: Expected Independent Information Ranking Model (Baseline Model) Recall the task definition from Section 3." ></td>
	<td class="line x" title="90:180	Finding a property r that most reduces the uncertainty in a query set Q can be modeled by measuring the strength of association between r and Q. Following Pantel and Lin (2002), we use pointwise mutual information (pmi) to measure the association strength between two events q and r, where q is a term in Q and r is syntactic dependency, as follows (Church and Hanks 1989):  () () () () N fqc N rwc N rqc Ff Ww rqpmi    =   , , , log,  (4.1) where c(q,r) is the frequency of r in the feature vector of q (as defined in Section 3.2), W is the set of all words in our corpus, F is the set of all syntactic dependencies in our corpus, and N = () WwFf fwc , is the total frequency count of all features of all words." ></td>
	<td class="line x" title="91:180	We estimate the association strength between a property r and a set of terms Q by taking the expected pmi between r and each term in Q as:  ( )()()   = Qq rqpmiqPrQpmi ,,  (4.2) where P(q) is the probability of q in the corpus." ></td>
	<td class="line x" title="92:180	Finally, the EIIR model chooses an n-best list by selecting the n properties from R that have highest pmi(Q, r)." ></td>
	<td class="line x" title="93:180	4.2 JIR: Joint Information Ranking Model The hypothesis of this paper is that considering items in an n-best result set jointly for ranking produces better result sets than considering them independently, an example of which is shown in Section 1." ></td>
	<td class="line x" title="94:180	Recall our task definition from Section 3: to select an n-best list R' from R such that it most reduces the uncertainty of Q. Recall that for explaining the similarity of terms, Q is the set of 684 query words to be explained and R is the set of all properties shared by words in Q. The above task of finding R' can be captured by the following objective function:  ()RQIR RR =  minarg  (4.3) where I(Q|R') is the amount of information in Q given R': 6   () () ()   = Qq RqIqPRQI  (4.4) where P(q) is the probability of term q in our corpus (defined in the Section 4.1) and I(q|R') is the amount of information in q given R', which is defined as the conditional self-information between q and R' (Merhav and Feder 1998):  ( ) ( ) () () ()Rc Rqc rrrqP rrrqIRqI n n   = = = *, , log ,,,log ,,, 21 21  (4.5) where c(q,R') is the frequency of all properties in R' occurring with word q and * represents all possible terms in the corpus 7 . We have:  () ()   = Rr rqcRqc ,,  and () ( )    = RrQq rqcRc ,*,  where c(q,r) is defined as in Section 4.1 and Q' is the set of all words that have all the properties in R'." ></td>
	<td class="line x" title="95:180	Computing c(*,R') efficiently can be done using a reverse index from properties to terms." ></td>
	<td class="line x" title="96:180	The Joint Information Ranking model (JIR) is the objective function in Eq." ></td>
	<td class="line x" title="97:180	4.3." ></td>
	<td class="line x" title="98:180	We find a suboptimal solution to Eq." ></td>
	<td class="line x" title="99:180	4.3 using a greedy algorithm by starting with an empty set R' and iteratively adding one property r at a time into R' such that:  () ()    = Qq RRr rRqIqPr minarg  (4.6) The intuition behind this algorithm is as follows: when choosing a property r to add to a partial result set, we should choose the r that contributes the maximum amount of information to the existing set (where all properties are considered jointly)." ></td>
	<td class="line x" title="100:180	6  Note that finding the set R' that minimizes the amount of information in Q given R' equates to finding the R' that reduces most the uncertainty in Q. 7  Note that each property in R' is shared by q because of the way the candidate properties in R were constructed (see Section 3.2)." ></td>
	<td class="line x" title="101:180	A brute force optimal solution to Eq." ></td>
	<td class="line x" title="102:180	4.3 involves computing I(Q|R') for all subsets R' of size n of R. In future work, we will investigate heuristic search algorithms for finding better solutions to Eq." ></td>
	<td class="line x" title="103:180	4.3, but our experimental results discussed in Section 5 show that our greedy solution to Eq." ></td>
	<td class="line x" title="104:180	4.3 already yields significantly better n-best lists than the baseline EIIR model." ></td>
	<td class="line x" title="105:180	5 Experimental Results In this section, we show empirical evidence that considering items in an n-best result set jointly for ranking produces better result sets than considering them independently." ></td>
	<td class="line x" title="106:180	We validate this claim by testing whether or not human judges prefer the set of explanations generated by our joint model (JIR) over the independent model (EIIR)." ></td>
	<td class="line x" title="107:180	5.1 Experimental Setup We trained the probabilities described in Section 4 using corpus statistics extracted from the TREC-9 and TREC-2002 Aquaint collections consisting of approximately 600 million words." ></td>
	<td class="line x" title="108:180	We used the Minipar parser (Lin 1993) to analyze each sentence and we collected the frequency counts of the grammatical contexts output by Minipar and used them to compute the probability and pointwise mutual information values from Sections 4.1 and 4.2." ></td>
	<td class="line x" title="109:180	Given any set of words Q from the corpus, our joint and independent models generate a ranked list of n-best explanations (i.e., properties) for the similarity of the words." ></td>
	<td class="line x" title="110:180	Recall the example set Q = {apple, beef} from Section 3.2." ></td>
	<td class="line x" title="111:180	Following Section 3.2, all grammatical contexts output by Minipar that both words share form a candidate explanation set R for their similarity." ></td>
	<td class="line x" title="112:180	For {apple, beef}, our systems found 312 candidate explanations." ></td>
	<td class="line x" title="113:180	Applying the independent ranking model, EIIR, we obtain the following top-5 best explanations, R': product, import of, export, ban on, industry Using the joint model, JIR, we obtain: export, product, eat, ban on, from menu 5.2 Comparing Ranking Models In order to obtain a representative set of similar terms as queries to our systems, we randomly chose 100 concepts from the CBC collection (Pantel and Lin 2002) consisting of 1628 clusters of nouns." ></td>
	<td class="line x" title="114:180	For each of these concepts, we randomly chose a set of cluster instances (nouns), 685 where the size of each set was randomly chosen to consist of two or three noun (chosen to reduce the runtime of our algorithm)." ></td>
	<td class="line x" title="115:180	For example, three of our randomly sampled concepts were Music, Flowers, and Alcohol and below are the random instances selected from these concepts:  {concerto, quartet, Fifth Symphony}  {daffodil, lily}  {gin, alcohol, rum} Each of these three samples forms a query." ></td>
	<td class="line x" title="116:180	Applying both our EIIR and JIR models, we generated the top-5 explanations for each of the 100 samples." ></td>
	<td class="line x" title="117:180	For example, below are the explanations returned for {daffodil, lily}:  EIIR: bulb, bouquet of, yellow, pink, hybrid  JIR: flowering, bulb, bouquet of, hybrid, yellow Two judges then independently annotated 500 test cases using the following scheme." ></td>
	<td class="line x" title="118:180	For each of the 100 samples, a judge is presented with the sample along with the top-1 explanation of both systems, randomly ordered for each sample such that the judge can never know which system generated which explanation." ></td>
	<td class="line x" title="119:180	The judge then must make one of the following three choices:  Explanation 1: The judge prefers the first explanation to the second." ></td>
	<td class="line x" title="120:180	 Explanation 2: The judge prefers the second explanation to the first." ></td>
	<td class="line x" title="121:180	 Equal: The judge cannot determine that one explanation is better than the other." ></td>
	<td class="line x" title="122:180	The judge is then presented with the top-2 explanations from each system, then the top-3, top4, and finally the top-5 explanations, making the above annotation decision each time." ></td>
	<td class="line x" title="123:180	Once the judge has seen the top-5 explanations for the sample, the judge moves on to the next sample and repeats this process until all 100 samples are annotated." ></td>
	<td class="line x" title="124:180	Allowing the judges to see the top-1, top-2, up to top-5 explanations allows us to later inspect how our ranking algorithms perform on different sizes of explanation sets." ></td>
	<td class="line x" title="125:180	The above annotation task was performed independently by two judges and the resulting agreement between the judges, using the Kappa statistic (Siegel and Castellan Jr. 1988), was  = 0.60." ></td>
	<td class="line x" title="126:180	Table 1 lists the full confusion matrix on the annotation task." ></td>
	<td class="line x" title="127:180	On just the annotations of the top-5 explanations, the agreement was  = 0.73." ></td>
	<td class="line x" title="128:180	Table 2 lists the Kappas for the different sizes of explanation sets." ></td>
	<td class="line x" title="129:180	It is more difficult for judges to determine the quality of smaller explanation sets." ></td>
	<td class="line x" title="130:180	For the above top-5 explanations for the query {daffodil, lily}, both judges preferred the JIR properties since flowering was deemed more informative than pink given that we also know the property yellow." ></td>
	<td class="line x" title="131:180	5.2.1 Evaluation Results Table 3 shows sample n-best lists generated by our system and Table 4 presents the results of the experiment described in the previous section." ></td>
	<td class="line x" title="132:180	Table 4 lists the preferences of the judges for the n-best lists generated by the independent and joint models, in terms of the percentage of samples preferred by each judge on each model." ></td>
	<td class="line x" title="133:180	We report our results on both all 500 annotations and on the 100 annotations for the explanation sets of size n = 5." ></td>
	<td class="line x" title="134:180	Instead of using an adjudicator for resolving the two judges disagreements, we weighted each judges decision by 0.5." ></td>
	<td class="line x" title="135:180	We used bootstrap resampling to obtain the 95% confidence intervals." ></td>
	<td class="line x" title="136:180	The judges significantly preferred the joint model over the independent model." ></td>
	<td class="line x" title="137:180	Looking at all annotated explanation sets (varying n from 1 to 5), the n-best lists from JIR were preferred 39.7% of the time." ></td>
	<td class="line x" title="138:180	On the 50.0%  3.1% test cases where one list was preferred over another, the JIR lists were preferred overall 76.6%  5.2% of the time, with 95% confidence." ></td>
	<td class="line x" title="139:180	Caution should be taken when interpreting the results for n < 3 since the annotator agreement for these was very low." ></td>
	<td class="line x" title="140:180	However, as shown in Figure 1, human preference for the JIR model was higher at n  3." ></td>
	<td class="line x" title="141:180	Table 2." ></td>
	<td class="line x" title="142:180	Inter-annotator agreement statistics over varying explanation set sizes n. n AGREEMENT (%) KAPPA () 1 75.0 0.47 2 70.0 0.50 3 77.0 0.62 4 78.0 0.63 5 84.0 0.73  Table 1." ></td>
	<td class="line x" title="143:180	Confusion matrix between the two judges on the annotation task over all explanation set sizes (n = 1  5)." ></td>
	<td class="line x" title="144:180	JIR EIIR EQUAL JIR 153 2 48 EIIR 11 33 19 EQUAL 29 7 198  686 5.2.2 Discussion and Error Analysis Figure 1 illustrates the annotated preferences over varying sizes of explanation sets, for n  [1  5]." ></td>
	<td class="line x" title="145:180	Except in the case where only one explanation is returned, we see consistent preferences between the judges." ></td>
	<td class="line x" title="146:180	Manual inspection of the size 1 explanation sets showed that often one property is not enough to understand the similarity of the query words." ></td>
	<td class="line x" title="147:180	For example, consider the following two explanation sets: {sell} and {drink}." ></td>
	<td class="line x" title="148:180	If you did not know the original query Q, one list would not be much better than the other in determining what the query was." ></td>
	<td class="line x" title="149:180	But, by adding one more property, we get: {sell, drink} and {drink, spike with}." ></td>
	<td class="line x" title="150:180	The second explanation list reduces much more the uncertainty that the query consists of alcoholic beverages, as you probably guessed (the first list also reduces the uncertainty, but not as much as the second)." ></td>
	<td class="line x" title="151:180	The above example is taken from our random sample list for the query words {gin, alcohol, rum}  the explanation {drink, spike with} was generated using the JIR model." ></td>
	<td class="line x" title="152:180	We manually inspected some of the sample queries where both judges preferred the EIIR nbest list." ></td>
	<td class="line x" title="153:180	One such sample query was: {Jerry Falwell, Jim Bakker, Pat Robertson}." ></td>
	<td class="line x" title="154:180	The n-best lists returned by the JIR and EIIR models respectively were {televangelist, evangelist, Rev., television, founder} and {evangelist, television, Rev., founder, religious}." ></td>
	<td class="line x" title="155:180	Both judges preferred the EIIR list because of the overlap in information between televangelist and evangelist." ></td>
	<td class="line x" title="156:180	The problem here in JIR was that the word televangelist was very rare in the corpus and thus few terms had both the feature televangelist and evangelist." ></td>
	<td class="line x" title="157:180	We would expect in a larger corpus to see a larger overlap with the two features, in which case evangelist would not be chosen by the JIR model." ></td>
	<td class="line x" title="158:180	As discussed in Section 2, considering results jointly is not a new idea and is very similar to the concept of diversity-based ranking introduced in the IR community by Carbonell and Goldstein (1998)." ></td>
	<td class="line x" title="159:180	Their proposed technique, called maximal marginal relevance (MMR), forms the basis of most schemes used today and works as follows." ></td>
	<td class="line x" title="160:180	Initially, each result item is scored independently of the others." ></td>
	<td class="line x" title="161:180	Then, the n-best list is selected by iteratively choosing the highest scoring result and then discounting each remaining candidates score by some function of the similarity (or information gain) between that candidate and the currently selected members of the n-best list." ></td>
	<td class="line x" title="162:180	In practice, these heuristic-based algorithms are fast to compute and are used heavily by commercial IR engines." ></td>
	<td class="line x" title="163:180	The purpose of this paper is to investigate a principled definition of diversity using the concept of maximal joint information." ></td>
	<td class="line x" title="164:180	The objective function proposed in Eq." ></td>
	<td class="line x" title="165:180	4.3 provides a basis for understanding diversity through the lens of information theory." ></td>
	<td class="line x" title="166:180	Although this paper foTable 3." ></td>
	<td class="line x" title="167:180	Five example n-best lists, drawn from our random sample described in Section 5.1, using the joint JIR model and the independent EIIR model (for n=5)." ></td>
	<td class="line x" title="168:180	Query (Q) JIR n-best (R') EIIR n-best (R') {gin, alcohol, rum} drink, spike with, sell, use, consume sell, drink, use, consume, buy {Temple University, Michigan State} political science at, professor at, director at, student at, attend professor at, professor, director at, student at, student {concerto, quartet, Fifth Symphony} Beethoven, his, play, write, performance his, play, write, performance, perform {ranch house, loft} offer, brick, sprawling, rambling, turn-of-the-century his, live, her, buy, small {dysentery, tuberculosis} morbidity, die of, case, patient, suffer from die of, case, patient, case of, have  Table 4." ></td>
	<td class="line x" title="169:180	Percentage of test cases where the judges preferred JIR vs. EIIR vs. they had no preference, computed over all explanation set sizes (n = 1  5) vs. only the explanation sets of size n = 5." ></td>
	<td class="line x" title="170:180	SYSTEM ALL (95% CONF  ) N=5 (95% CONF  ) JIR 39.7%  3.0% 43.7%  6.9% EIIR 10.4%  1.3% 10.1%  4.2% Equal 50.0%  3.1% 45.2%  6.9%  95% confidence intervals estimated using bootstrap resampling." ></td>
	<td class="line x" title="171:180	Figure 1." ></td>
	<td class="line x" title="172:180	Percentage of human preference for each model with varying sizes of explanation sets (n)." ></td>
	<td class="line x" title="173:180	0 0.2 0.4 0.6 0.8 1 12345 P r ef e r en c e Numberofexplanations (n) ModelPreferencevs.NumberofExplanations JIRPreferred EIIRBaselinePreferred Equal(NoPreference) 687 cuses on the task of explaining the similarity of terms, we plan in future work to apply our method to an IR task in order to compare and contrast our method with MMR." ></td>
	<td class="line x" title="174:180	6 Conclusion This paper investigates the problem of n-best ranking on the lexical semantics task of explaining/characterizing the similarity of a group of terms where only a small set of many possible semantic properties may be displayed to a user." ></td>
	<td class="line x" title="175:180	We propose that considering the results jointly, by accounting for the information overlap between results, helps generate better n-best lists." ></td>
	<td class="line x" title="176:180	We presented an information theoretic objective function, called Joint Information Ranking, for modeling the joint information in an n-best list." ></td>
	<td class="line x" title="177:180	On our lexical semantics task, empirical evidence shows that humans significantly prefer JIR n-best lists over a baseline model that considers the explanations independently." ></td>
	<td class="line x" title="178:180	Our results show that the n-best lists generated by the joint model are judged to be significantly different from those generated by the independent model 50.0%  3.1% of the time, out of which they are preferred 76.6%  5.2% of the time, with 95% confidence." ></td>
	<td class="line x" title="179:180	In future work, we plan to investigate other joint models using latent semantic analysis techniques, and to investigate heuristic algorithms to both optimize search efficiency and to better approximate our JIR objective function." ></td>
	<td class="line x" title="180:180	Although applied only to the task of characterizing the similarity of terms, it is our hope that the JIR model will generalize well to many ranking tasks, from keyword search ranking, to recommendation systems, to advertisement placements." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1100
Metric Learning for Synonym Acquisition
Shimizu, Nobuyuki;Hagiwara, Masato;Ogawa, Yasuhiro;Toyama, Katsuhiko;Nakagawa, Hiroshi;"></td>
	<td class="line x" title="1:180	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 793800 Manchester, August 2008 Metric Learning for Synonym Acquisition Nobuyuki Shimizu Information Technology Center University of Tokyo shimizu@r.dl.itc.u-tokyo.ac.jp Masato Hagiwara Graduate School of Information Science Nagoya University hagiwara@kl.i.is.nagoya-u.ac.jp Yasuhiro Ogawa and Katsuhiko Toyama Graduate School of Information Science Nagoya University {yasuhiro,toyama}@kl.i.is.nagoya-u.ac.jp Hiroshi Nakagawa Information Technology Center University of Tokyo n3@dl.itc.u-tokyo.ac.jp Abstract The distance or similarity metric plays an important role in many natural language processing (NLP) tasks." ></td>
	<td class="line x" title="2:180	Previous studies have demonstrated the effectiveness of a number of metrics such as the Jaccard coefficient, especially in synonym acquisition." ></td>
	<td class="line x" title="3:180	While the existing metrics perform quite well, to further improve performance, we propose the use of a supervised machine learning algorithm that fine-tunes them." ></td>
	<td class="line x" title="4:180	Given the known instances of similar or dissimilar words, we estimated the parameters of the Mahalanobis distance." ></td>
	<td class="line x" title="5:180	We compared a number of metrics in our experiments, and the results show that the proposed metric has a higher mean average precision than other metrics." ></td>
	<td class="line x" title="6:180	1 Introduction Accurately estimating the semantic distance between words in context has applications for machine translation, information retrieval (IR), speech recognition, and text categorization (Budanitsky and Hirst, 2006), and it is becoming clear that a combination of corpus statistics can be used with a dictionary, thesaurus, or other knowledge source such as WordNet or Wikipedia, to increase the accuracy of semantic distance estimation (Mohammad and Hirst, 2006)." ></td>
	<td class="line x" title="7:180	Although compiling such resources is labor intensive and achieving wide coverage is difficult, these resources to some extent explicitly capture semantic structures c2008." ></td>
	<td class="line x" title="8:180	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="9:180	Some rights reserved." ></td>
	<td class="line x" title="10:180	of concepts and words." ></td>
	<td class="line x" title="11:180	In contrast, corpus statistics achieve wide coverage, but the semantic structure of a concept is only implicitly represented in the context." ></td>
	<td class="line x" title="12:180	Assuming that two words are semantically closer if they occur in similar contexts, statistics on the contexts of words can be gathered and compared for similarity, by using a metric such as the Jaccard coefficient." ></td>
	<td class="line x" title="13:180	Our proposal is to extend and fine-tune the latter approach with the training data obtained from the former." ></td>
	<td class="line x" title="14:180	We apply metric learning to this task." ></td>
	<td class="line x" title="15:180	Although still in their infancy, distance metric learning methods have undergone rapid development in the field of machine learning." ></td>
	<td class="line x" title="16:180	In a setting similar to semi-supervised clustering, where known instances of similar or dissimilar objects are given, a metric such as the Mahalanobis distance can be learned from a few data points and tailored to fit a particular purpose." ></td>
	<td class="line x" title="17:180	Although classification methods such as logistic regression now play important roles in natural language processing, the use of metric learning has yet to be explored." ></td>
	<td class="line x" title="18:180	Since popular current methods for synonym acquisition require no statistical learning, it seems that supervised machine learning should easily outperform them." ></td>
	<td class="line x" title="19:180	Unfortunately, there are obstacles to overcome." ></td>
	<td class="line x" title="20:180	Since metric learning algorithms usually learn the parameters of a Mahalanobis distance, the number of parameters is quadratic to the number of features." ></td>
	<td class="line x" title="21:180	They learn how two features should interact to produce the final metric." ></td>
	<td class="line x" title="22:180	While traditional metrics forgo examining of the interactions entirely, in applying metrics such as Jaccard coefficient, it is not uncommon nowadays to use more than 10,000 features, a number that a typical metric learner is incapable of processing." ></td>
	<td class="line x" title="23:180	Thus we have two options: one is to find the most important features and model the interactions between 793 them, and the other is simply to use a large number of features." ></td>
	<td class="line x" title="24:180	We experimentally examined the two options and found that metric learning is useful in synonym acquisition, despite it utilizing fewer features than traditional methods." ></td>
	<td class="line x" title="25:180	The remainder of this paper is organized as follows: in section 2, we review prior work on synonym acquisition and metric learning." ></td>
	<td class="line x" title="26:180	In section 3, we introduce the Mahalanobis distance metric and a learning algorithm based on this metric." ></td>
	<td class="line x" title="27:180	In section 4 and 5, we explain the experimental settings and propose the use of normalization to make the Mahalanobis distances work in practice, and then in section 6, we discuss issues we encountered when applying this metric to synonym acquisition." ></td>
	<td class="line x" title="28:180	We conclude in section 7." ></td>
	<td class="line x" title="29:180	2 Prior Work As this paper is based on two different lines of research, we first review the work in synonym acquisition, and then review the work in generic metric learning." ></td>
	<td class="line x" title="30:180	To the best of the authors knowledge, none of the metric learning algorithms have been applied to automatic synonym acquisition." ></td>
	<td class="line x" title="31:180	Synonym relation is important lexical knowledge for many natural language processing tasks including automatic thesaurus construction (Croach and Yang, 1992; Grefenstette, 1994) and IR (Jing and Croft, 1994)." ></td>
	<td class="line oc" title="32:180	Various methods (Hindle, 1990; Lin, 1998) of automatically acquiring synonyms have been proposed." ></td>
	<td class="line o" title="33:180	They are usually based on the distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts, and they can be roughly viewed as the combinations of two steps: context extraction and similarity calculation." ></td>
	<td class="line x" title="34:180	The former extracts useful features from the contexts of words, such as surrounding words or dependency structure." ></td>
	<td class="line x" title="35:180	The latter calculates how semantically similar two given words are based on similarity or distance metrics." ></td>
	<td class="line x" title="36:180	Many studies (Lee, 1999; Curran and Moens, 2002; Weeds et al., 2004) have investigated similarity calculation, and a variety of distance/similarity measures have already been compared and discussed." ></td>
	<td class="line x" title="37:180	Weeds et al.s work is especially useful because it investigated the characteristics of metrics based on a few criteria such as the relative frequency of acquired synonyms and clarified the correlation between word frequency, distributional generality, and semantic generality." ></td>
	<td class="line n" title="38:180	However, all of the existing research conducted only a posteriori comparison, and as Weeds et al. pointed out, there is no one best measure for all applications." ></td>
	<td class="line x" title="39:180	Therefore, the metrics must be tailored to applications, even to corpora and other settings." ></td>
	<td class="line x" title="40:180	We next review the prior work in generic metric learning." ></td>
	<td class="line x" title="41:180	Most previous metric learning methods learn the parameters of the Mahalanobis distance." ></td>
	<td class="line x" title="42:180	Although the algorithms proposed in earlier work (Xing et al., 2002; Weinberger et al., 2005; Globerson and Roweis, 2005) were shown to yield excellent classification performance, these algorithms all have worse than cubic computational complexity in the dimensionality of the data." ></td>
	<td class="line x" title="43:180	Because of the high dimensionality of our objects, we opted for information-theoretic metric learning proposed by (Davis et al., 2007)." ></td>
	<td class="line x" title="44:180	This algorithm only uses an operation quadratic in the dimensionality of the data." ></td>
	<td class="line x" title="45:180	Other work on learning Mahalanobis metrics includes online metric learning (Shalev-Shwartz et al., 2004), locally-adaptive discriminative methods (Hastie and Tibshirani, 1996), and learning from relative comparisons (Schutz and Joahims, 2003)." ></td>
	<td class="line x" title="46:180	Non-Mahalanobis-based metric learning methods have also been proposed, though they seem to suffer from suboptimal performance, non-convexity, or computational complexity." ></td>
	<td class="line x" title="47:180	Examples include neighborhood component analysis (Goldberger et al., 2004)." ></td>
	<td class="line x" title="48:180	3 Metric Learning 3.1 Problem Formulation To set the context for metric learning, we first describe the objects whose distances from one another we would like to know." ></td>
	<td class="line x" title="49:180	As noted above regarding the distributional hypothesis, our object is the context of a target word." ></td>
	<td class="line x" title="50:180	To represent the context, we use a sparse vector in Rd. Each dimension of an input vector represents a feature of the context, and its value corresponds to the strength of the association." ></td>
	<td class="line x" title="51:180	The vectors of two target words represent their contexts as points in multidimensional feature-space." ></td>
	<td class="line x" title="52:180	A suitable metric (for example, Euclidean) defines the distance between the two points, thereby estimating the semantic distance between the target words." ></td>
	<td class="line x" title="53:180	Given points xi,xj  Rd, the (squared) Mahalanobis distance between them is parameterized by a positive definite matrix A as follows dA(xi,xj) = (xi  xj)A(xi  xj)." ></td>
	<td class="line x" title="54:180	The Ma794 halanobis distance is a straightforward extension of the standard Euclidean distance." ></td>
	<td class="line x" title="55:180	If we let A be the identity matrix, the Mahalanobis distance reduces to the Euclidean distance." ></td>
	<td class="line x" title="56:180	Our objective is to obtain the positive definite matrix A that parameterizes the Mahalanobis distance, so that the distance between the vectors of two synonymous words is small, and the distance between the vectors of two dissimilar words is large." ></td>
	<td class="line x" title="57:180	Stated more formally, the Mahalanobis distance between two similar points must be smaller than a given upper bound, i.e., dA(xi,xj)  u for a relatively small value of u. Similarly, two points are dissimilar if dA(xi,xj)  l for sufficiently large l. As we discuss below, we were able to use the Euclidean distance to acquire synonyms quite well." ></td>
	<td class="line x" title="58:180	Therefore, we would like the positive definite matrix A of the Mahalanobis distance to be close to the identity matrix I. This keeps the Mahalanobis distance similar to the Euclidean distance, which would help to prevent overfitting the data." ></td>
	<td class="line x" title="59:180	To optimize the matrix, we follow the information theoretic metric learning approach described in (Davis et al., 2007)." ></td>
	<td class="line x" title="60:180	We summarize the problem formulation advocated by this approach in this section and the learning algorithm in the next section." ></td>
	<td class="line x" title="61:180	To define the closeness between A and I, we use a simple bijection (up to a scaling function) from the set of Mahalanobis distances to the set of equal mean multivariate Gaussian distributions." ></td>
	<td class="line x" title="62:180	Without loss of generalization, let the equal mean be ." ></td>
	<td class="line x" title="63:180	Then given a Mahalanobis distance parameterized by A, the corresponding Gaussian is p(x;A) = 1Z exp(12dA(x,)) where Z is the normalizing factor." ></td>
	<td class="line x" title="64:180	This enables us to measure the distance between two Mahalanobis distances with the Kullback-Leibler (KL) divergence of two Gaussians: KL(p(x;I)||p(x;A)) = integraldisplay p(x,I)log parenleftbiggp(x;I) p(x;A) parenrightbigg dx." ></td>
	<td class="line x" title="65:180	Given pairs of similar points S and pairs of dissimilar points D, the optimization problem is: minA KL(p(x;I)||p(x;A)) subject to dA(xi,xj)  u (i,j)  S dA(xi,xj)  l (i,j)  D 3.2 Learning Algorithm (Davis and Dhillon, 2006) has shown that the KL divergence between two multivariate Gaussians can be expressed as the convex combination of a Mahalanobis distance between mean vectors and the LogDet divergence between the covariance matrices." ></td>
	<td class="line x" title="66:180	The LogDet divergence equals Dld(A,A0) = tr(AA10 )logdet(AA10 )n for n by n matrices A,A0." ></td>
	<td class="line x" title="67:180	If we assume the means of the Gaussians to be the same, we have KL(p(x;A0||p(x,A)) = 12Dld(A,A0) The optimization problem can be restated as minAfollowsequal0 Dld(A,I) s.t. tr(A(xi xj)(xi xj))  u (i,j)  S tr(A(xi xj)(xi xj))  l (i,j)  D We then incorporate slack variables into the formulation to guarantee the existence of a feasible solution for A. The optimization problem becomes: minAfollowsequal0 Dld(A,I) + Dld(diag(),diag(0)) s.t. tr(A(xi xj)(xi xj))  c(i,j) (i,j)  S tr(A(xi xj)(xi xj))  c(i,j) (i,j)  D where c(i,j) is the index of the (i,j)-th constraint and  is a vector of slack variables whose components are initialized to u for similarity constraints and l for dissimilarity constraints." ></td>
	<td class="line x" title="68:180	The tradeoff between satisfying the constraints and minimizing Dld(A,I) is controlled by the parameter ." ></td>
	<td class="line x" title="69:180	To solve this optimization problem, the algorithm shown in Algorithm 3.1 repeatedly projects the current solution onto a single constraint." ></td>
	<td class="line x" title="70:180	This completes the summary of (Davis et al., 2007)." ></td>
	<td class="line x" title="71:180	4 Experimental Settings In this section, we describe the experimental settings including the preprocessing of data and features, creation of the query word sets, and settings of the cross validation." ></td>
	<td class="line oc" title="72:180	4.1 Features We used a dependency structure as the context for words because it is the most widely used and one of the best performing contextual information in the past studies (Ruge, 1997; Lin, 1998)." ></td>
	<td class="line x" title="73:180	As the extraction of an accurate and comprehensive dependency structure is in itself a complicated task, the sophisticated parser RASP Toolkit 2 (Briscoe et al., 2006) was utilized to extract this kind of word relation." ></td>
	<td class="line x" title="74:180	Let N(w,c) be the raw cooccurrence count of word w and context c, the grammatical relation 795 Algorithm 3.1: INFORMATION THEORETIC METRIC LEARNING Input : X(d by n matrix),I(identity matrix) S(set of similar pairs),D(set of dissimilar pairs) (slack parameter),c(constraint index function) u,l(distance thresholds) Output : A(Mahalanobis matrix) A := I ij := 0 c(i,j) := u for (i,j)  S; otherwise, c(i,j) := l repeat Pick a constraint (i,j)  S or (i,j)  D p := (xi xj)A(xi xj)  := 1 if (i,j)  S,1 otherwise." ></td>
	<td class="line x" title="75:180	 := min(ij, 2(1p   c(i,j) ))  := /(1c(i,j)) c(i,j) := c(i,j)/( + c(i,j)) ij := ij  A := A + A(xi xj)(xi xj)A until convergence return (A) in which w occurs." ></td>
	<td class="line x" title="76:180	These raw counts were obtained from New York Times articles (July 1994) extracted from English Gigaword 1." ></td>
	<td class="line x" title="77:180	The section consists of 7,593 documents and approx." ></td>
	<td class="line x" title="78:180	5 million words." ></td>
	<td class="line x" title="79:180	As discussed below, we limited the vocabulary to the nouns in the Longman Defining Vocabulary (LDV) 2." ></td>
	<td class="line x" title="80:180	The features were constructed by weighting them using pointwise mutual information: wgt(w,c) = PMI(w,c) = log P(w,c)P(w)P(c)." ></td>
	<td class="line x" title="81:180	Co-occurrence data constructed this way can yield more than 10,000 context types, rendering metric learning impractical." ></td>
	<td class="line x" title="82:180	As the applications of feature selection reduce the performance of the baseline metrics, we tested them in two different settings: with and without feature selection." ></td>
	<td class="line x" title="83:180	To mitigate this problem, we applied a feature selection technique to reduce the feature dimensionality." ></td>
	<td class="line x" title="84:180	We selected features using two approaches." ></td>
	<td class="line x" title="85:180	The first approach is a simple frequency cutoff, applied as a pre-processing to filter out words and contexts with low frequency and to reduce computational cost." ></td>
	<td class="line x" title="86:180	Specifically, all words w such that summationtextc N(w,c) < f and contexts c such thatsummationtext w N(w,c) < f, with f = 5, are removed from the co-occurrence data." ></td>
	<td class="line x" title="87:180	The second approach is feature selection by con1http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?" ></td>
	<td class="line x" title="88:180	catalogId=LDC2003T05 2http://www.cs.utexas.edu/users/kbarker/working notes/ ldoce-vocab.html text importance (Hagiwara et al., 2008)." ></td>
	<td class="line x" title="89:180	First, the context importance score for each context type is calculated, and then the least important context types are eliminated, until a desired numbers of them remains." ></td>
	<td class="line x" title="90:180	To measure the context importance score, we used the number of unique words the context co-occurs with: df(c) = |{w|N(w,c) > 0}|." ></td>
	<td class="line x" title="91:180	We adopted this context selection criterion on the assumption that the contexts shared by many words should be informative, and the synonym acquisition performance based on normal distributional similarity calculation retains its original level of performance until up to almost 90% of context types are eliminated (Hagiwara et al., 2008)." ></td>
	<td class="line x" title="92:180	In our experiment, we selected features rather aggressively, finally using only 10% of the original contexts." ></td>
	<td class="line x" title="93:180	These feature reduction operations reduced the dimensionality to a figure as small as 1,281, while keeping the performance loss at a minimum." ></td>
	<td class="line x" title="94:180	4.2 Similarity and Distance Functions We compared seven similarity/distance functions in our experiments: cosine similarity, Euclidean distance, Manhattan distance, Jaccard coefficient, vector-based Jaccard coefficient (Jaccardv), Jensen-Shannon Divergence (JS) and skew divergence (SD99)." ></td>
	<td class="line x" title="95:180	We first define some notations." ></td>
	<td class="line x" title="96:180	Let C(w) be the set of context types that co-occur with word w, i.e., C(w) = {c|N(w,c) > 0}, and wi be the feature vector corresponding to word w, i.e., wi = [wgt(wi,c1)  wgt(wi,cM)]." ></td>
	<td class="line x" title="97:180	The first three, the cosine, Euclidean and Manhattan distance, are vector-based metrics." ></td>
	<td class="line x" title="98:180	cosine similarity w1 w2 ||w1||||w2|| Euclidean distance radicalBigg summationdisplay cC(w1)C(w2) (wgt(w1,c)wgt(w2,c))2 Manhattan distance summationdisplay cC(w1)C(w2) |wgt(w1,c)wgt(w2,c)| Jaccard coefficient summationtext cC(w1)C(w2) min(wgt(w1,c),wgt(w2,c))summationtext cC(w1)C(w2) max(wgt(w1,c),wgt(w2,c)) , 796 vector-based Jaccard coefficient (Jaccardv) wi wj ||wi|| +||wj||wi wj . Jensen-Shannon divergence (JS) 1 2{KL(p1||m) + KL(p2||m)}, m = p1 + p2." ></td>
	<td class="line x" title="99:180	JS and SD99 are based on the KL divergence, so the vectors must be normalized to form a probability distribution." ></td>
	<td class="line x" title="100:180	For notational convenience, we let pi be the probability distribution representation of feature vector wi, i.e., pi(c) = N(wi,c)/N(wi)." ></td>
	<td class="line x" title="101:180	While the KL divergence suffers from the so-called zero-frequency problem, a symmetric version of the KL divergence called the Jensen-Shannon divergence naturally avoids it." ></td>
	<td class="line x" title="102:180	skew divergence (SD99) KL(p1||p2 + (1)p1)." ></td>
	<td class="line x" title="103:180	As proposed by (Lee, 2001), the skew divergence also avoids the zero-frequency problem by mixing the original distribution with the target distribution." ></td>
	<td class="line x" title="104:180	Parameter  is set to 0.99." ></td>
	<td class="line x" title="105:180	4.3 Query Word Set and Cross Validation To formalize the experiments, we must prepare a set of query words for which synonyms are known in advance." ></td>
	<td class="line x" title="106:180	We chose the Longman Defining Vocabulary (LDV) as the candidate set of query words." ></td>
	<td class="line x" title="107:180	For each word in the LDV, we consulted three existing thesauri: Rogets Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998)." ></td>
	<td class="line x" title="108:180	Each LDV word was looked up as a noun to obtain the union of synonyms." ></td>
	<td class="line x" title="109:180	After removing words marked idiom, informal or slang and phrases comprised of two or more words, this union was used as the reference set of query words." ></td>
	<td class="line x" title="110:180	LDV words for which no noun synonyms were found in any of the reference thesauri were omitted." ></td>
	<td class="line x" title="111:180	From the remaining 771 LDV words, there were 231 words that had five or more synonyms in the combined thesaurus." ></td>
	<td class="line x" title="112:180	We selected these 231 words to be the query words and distributed them into five partitions so as to conduct five-fold cross validation." ></td>
	<td class="line x" title="113:180	Four partitions were used in training, and the remaining partition was used in testing." ></td>
	<td class="line x" title="114:180	For each fold, we created the training set from four partitions as follows; for each query word in the partitions, we randomly selected five synonymous words and added the pairs of query words and synonymous words to S, the set of similar pairs." ></td>
	<td class="line x" title="115:180	Similarly, five pairs of query words and dissimilar words were randomly added to D, the set of dissimilar pairs." ></td>
	<td class="line x" title="116:180	The training set for each fold consisted of S and D. Since a learner trained on an imbalanced dataset may not learn to discriminate enough between classes, we sampled dissimilar pairs to create an evenly distributed training dataset." ></td>
	<td class="line x" title="117:180	To make the evaluation realistic, we used a different method to create the test set: we paired each query word with each of the 771 remaining words to form the test set." ></td>
	<td class="line x" title="118:180	Thus, in each fold, the training set had an equal number of positive and negative pairs, while in the test set, negative pairs outnumbered the positive pairs." ></td>
	<td class="line x" title="119:180	While this is not a typical setting for cross validation, it renders the evaluation more realistic since an automatic synonym acquisition system in operation must be able to pick a few synonyms from a large number of dissimilar words." ></td>
	<td class="line x" title="120:180	The meta-parameters of the metric learning model were simply set u = 1, l = 2 and  = 1." ></td>
	<td class="line x" title="121:180	Each training set consisted of 1,850 pairs, and the test set consisted of 34,684 pairs." ></td>
	<td class="line x" title="122:180	Since we conducted five-fold cross validation, the reported performance in this paper is actually a summary over different folds." ></td>
	<td class="line x" title="123:180	4.4 Evaluation Measures We used an evaluation program for KDD Cup 2004 (Caruana et al., 2004) called Perf to measure the effectiveness of the metrics in acquiring synonyms." ></td>
	<td class="line x" title="124:180	To use the program, we used the following formula to convert each distance metric to a similarity metric." ></td>
	<td class="line x" title="125:180	s(xi,xj) = 1/(1 + exp(d(xi,xj)))." ></td>
	<td class="line x" title="126:180	Below, we summarize the three measures we used: Mean Average Precision, TOP1, and Average Rank of Last Synonym." ></td>
	<td class="line x" title="127:180	Mean Average Precision (APR) Perf implements a definition of average precision sometimes called expected precision." ></td>
	<td class="line x" title="128:180	Perf calculates the precision at every recall where it is defined." ></td>
	<td class="line x" title="129:180	For each of these recall values, Perf finds the threshold that produces the maximum precision, and takes the average over all of the recall values greater than 0." ></td>
	<td class="line x" title="130:180	Average precision is measured on each query, and then the mean of each querys average precision is used as the final metric." ></td>
	<td class="line x" title="131:180	A mean average precision of 1.0 indicates perfect prediction." ></td>
	<td class="line x" title="132:180	The lowest possible mean average 797 precision is 0.0." ></td>
	<td class="line x" title="133:180	Average Rank of Last Synonym (RKL) As in other evaluation measures, synonym candidates are sorted by predicted similarity, and this metric measures how far down the sorted cases we must go to find the last true synonym." ></td>
	<td class="line x" title="134:180	A rank of 1 indicates that the last synonym is placed in the top position." ></td>
	<td class="line x" title="135:180	Given a query word, the highest obtainable rank is N if there are N synonyms in the corpus." ></td>
	<td class="line x" title="136:180	The lower this measure is the better." ></td>
	<td class="line x" title="137:180	Average ranks near 771 indicate poor performance." ></td>
	<td class="line x" title="138:180	TOP1 In each query, synonym candidates are sorted by predicted similarity." ></td>
	<td class="line x" title="139:180	If the word that ranks at the top (highest similarity to the query word) is a true synonym of the query word, Perf scores a 1 for that query, and 0 otherwise." ></td>
	<td class="line x" title="140:180	If there are ties, Perf scores 0 unless all of the tied cases are synonyms." ></td>
	<td class="line x" title="141:180	TOP1 score ranges from 1.0 to 0.0." ></td>
	<td class="line x" title="142:180	To achieve 1.0, perfect TOP1 prediction, a similarity metric must place a true synonym at the top of the sorted list in every query." ></td>
	<td class="line x" title="143:180	In the next section, we report the mean of each querys TOP1." ></td>
	<td class="line x" title="144:180	5 Results The evaluations of the metrics are listed in Table 1." ></td>
	<td class="line x" title="145:180	The figure on the left side of  represents the performance with 1,281 features, and that on the right side with 12,812 features." ></td>
	<td class="line x" title="146:180	Of all the metrics in Table 1, only the Mahalanobis L2 is trained with the previously presented metric learning algorithm." ></td>
	<td class="line x" title="147:180	Thus, the values for the Mahalanobis L2 are produced by the five-fold cross validation, while the rest are given by the straight application of the metrics discussed in Section 4.2 to the same dataset." ></td>
	<td class="line x" title="148:180	Strictly speaking, this is not a fair comparison, since we ought to compare a supervised learning with a supervised learning." ></td>
	<td class="line x" title="149:180	However, our baseline is not the simple Euclidean distance; it is the Jaccard coefficient and cosine similarity, a handcrafted, best performing metric for synonym acquisition, with 10 times as many features." ></td>
	<td class="line x" title="150:180	The computational resources required to obtain the Mahalanobis L2 results were as follows: in the training phase, each fold of cross validation took about 80 iterations (less than one week) to converge on a Xeon 5160 3.0GHz." ></td>
	<td class="line x" title="151:180	The time required to use the learned distance was a few hours at most." ></td>
	<td class="line x" title="152:180	At first, we were unable to perform competitively with the Euclidean distance." ></td>
	<td class="line x" title="153:180	As seen in Table 1, the TOP1 measure of the Euclidean distance is only 1.732%." ></td>
	<td class="line x" title="154:180	This indicates that the likelihood of finding the first item on the ranked list to be a true synonym is 1.732%." ></td>
	<td class="line x" title="155:180	The vector-based Jaccard coefficient performs much better than the Euclidean distance, placing a true synonym at the top of the list 30.736% of the time." ></td>
	<td class="line x" title="156:180	Table 2 shows the Top 10 Words for Query branch." ></td>
	<td class="line x" title="157:180	The results for the Euclidean distance rank hut and other dissimilar words highly." ></td>
	<td class="line x" title="158:180	This is because the norm of such vectors is small, and in a high dimensional space, the sparse vectors near the origin are relatively close to many other sparse vectors." ></td>
	<td class="line x" title="159:180	To overcome this problem, we normalized the input vectors by the L2 norm x = x/||x|| This normalization enables the Euclidean distance to perform very much like the cosine similarity, since the Euclidean distance between points on a sphere acts like the angle between the vectors." ></td>
	<td class="line x" title="160:180	Surprisingly, normalization by L2 did not affect other metrics all that much; while the performances of some metrics improved slightly, the L2 normalization lowered that of the Jaccardv metric." ></td>
	<td class="line x" title="161:180	Once we learned the normalization trick, the learned Mahalanobis distance consistently outperformed all other metrics, including the ones with 10 times more features, in all three evaluation measures, achieving an APR of 18.66%, RKL of 545.09 and TOP1 of 45.455%." ></td>
	<td class="line x" title="162:180	6 Discussion Examining the learned Mahalanobis matrix revealed interesting features." ></td>
	<td class="line x" title="163:180	The matrix essentially shows the covariance between features." ></td>
	<td class="line x" title="164:180	While it was not as heavily weighted as the diagonal elements, we found that its positive non-diagonal elements were quite interesting." ></td>
	<td class="line x" title="165:180	They indicate that some of the useful features for finding synonyms are correlated and somewhat interchangeable." ></td>
	<td class="line x" title="166:180	The example includes a pair of features, (dobj begin *) and (dobj end *)." ></td>
	<td class="line x" title="167:180	It was a pleasant surprise to see that one implies the other." ></td>
	<td class="line x" title="168:180	Among the diagonal elements of the matrix, one of the heaviest features was being the direct object of by." ></td>
	<td class="line x" title="169:180	This indicates that being the object of the preposition by is a good indicator that two words are similar." ></td>
	<td class="line x" title="170:180	A closer inspection of the NYT corpus showed that this preposition overwhelmingly takes a person or organization as its object, indicating that words with this feature belong to the same class of a person or organization." ></td>
	<td class="line x" title="171:180	Similarly, the class 798 Metric APR RKL TOP1 Cosine 0.1184  0.1324 580.27  579.00 0.2987  0.3160 Euclidean 0.0229  0.0173 662.74  695.71 0.0173  0.0000 Euclidean L2 0.1182  0.1324 580.30  578.99 0.2943  0.3160 Jaccard 0.1120  0.1264 580.76  579.51 0.2684  0.2943 Jaccard L2 0.1113  0.1324 580.29  570.88 0.2640  0.2987 Jaccardv 0.1189  0.1318 580.50  580.19 0.3073  0.3030 Jaccardv L2 0.1184  0.1254 580.27  570.00 0.2987  0.3160 JS 0.0199  0.0170 681.97  700.53 0.0129  0.0000 JS L2 0.0229  0.0173 679.21  699.00 0.0303  0.0086 Manhattan 0.0181  0.0168 687.73  701.47 0.0043  0.0000 Manhattan L2 0.0185  0.0170 686.56  701.11 0.0043  0.0086 SD99 0.0324  0.1039 640.71  588.16 0.0173  0.2640 SD99 L2 0.0334  0.1117 633.32  586.78 0.0216  0.2900 Mahalanobis L2 0.1866 545.09 0.4545 Table 1: Evaluation of Various Metrics, as Number of Features Increase from 1,281 to 12,812 Cosine Euclidean Euclidean L2 Jaccard Jaccardv Mahalanobis L2 1 (*) office hut (*) office (*) office (*) office (*) division 2 area wild area border area group 3 (*) division polish (*) division area (*) division (*) office 4 border thirst border plant border line 5 group hollow group (*) division group period 6 organization shout organization mouth organization organization 7 store fold store store store (*) department 8 mouth dear mouth circle mouth charge 9 plant hate plant stop plant world 10 home wake home track home body (*) = a true synonym Table 2: Top 10 Words for Query branch of words that to and within, take as an objects were clear from the corpus: to takes a person or place, within takes duration of time 3." ></td>
	<td class="line x" title="172:180	Other heavy features includes being the object of write or about." ></td>
	<td class="line x" title="173:180	While not obvious, we postulate that having these words as a part of the context indicates that a word is an event of some type." ></td>
	<td class="line x" title="174:180	7 Conclusion We applied metric learning to automatic synonym acquisition for the first time, and our experiments showed that the learned metric significantly outperforms existing similarity metrics." ></td>
	<td class="line x" title="175:180	This outcome indicates that while we must resort to feature selection to apply metric learning, the performance gain from the supervised learning is enough to offset the disadvantage and justify its usage in some applications." ></td>
	<td class="line x" title="176:180	This leads us to think that a combination of the learned metric with unsupervised metrics with even more features may produces the best results." ></td>
	<td class="line x" title="177:180	We also discussed interesting features found in the learned Mahalanobis matrix." ></td>
	<td class="line x" title="178:180	Since 3Interestingly, we note that not all prepositions were as heavy: beyond and without were relatively light among the diagonal elements." ></td>
	<td class="line x" title="179:180	In the NYT corpus, the class of words they take was not as clear as, for example, by." ></td>
	<td class="line x" title="180:180	metric learning is known to boost clustering performance in a semi-supervised clustering setting, we believe these automatically identified features would be helpful in assigning a target word to a word class." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1107
Learning Entailment Rules for Unary Templates
Szpektor, Idan;Dagan, Ido;"></td>
	<td class="line x" title="1:203	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 849856 Manchester, August 2008 Learning Entailment Rules for Unary Templates Idan Szpektor Department of Computer Science Bar-Ilan University Ramat Gan, Israel szpekti@macs.biu.ac.il Ido Dagan Department of Computer Science Bar-Ilan University Ramat Gan, Israel dagan@macs.biu.ac.il Abstract Most work on unsupervised entailment rule acquisition focused on rules between templates with two variables, ignoring unary rules entailment rules between templates with a single variable." ></td>
	<td class="line x" title="2:203	In this paper we investigate two approaches for unsupervised learning of such rules and compare the proposed methods with a binary rule learning method." ></td>
	<td class="line x" title="3:203	The results show that the learned unary rule-sets outperform the binary rule-set." ></td>
	<td class="line x" title="4:203	In addition, a novel directional similarity measure for learning entailment, termed Balanced-Inclusion, is the best performing measure." ></td>
	<td class="line x" title="5:203	1 Introduction In many NLP applications, such as Question Answering (QA) and Information Extraction (IE), it is crucial to recognize whether a specific target meaning is inferred from a text." ></td>
	<td class="line x" title="6:203	For example, a QA system has to deduce that SCO sued IBM is inferred from SCO won a lawsuit against IBM to answer Whom did SCO sue?." ></td>
	<td class="line x" title="7:203	This type of reasoning has been identified as a core semantic inference paradigm by the generic Textual Entailment framework (Giampiccolo et al., 2007)." ></td>
	<td class="line x" title="8:203	An important type of knowledge needed for such inference is entailment rules." ></td>
	<td class="line x" title="9:203	An entailment rule specifies a directional inference relation between two templates, text patterns with variables, such as X win lawsuit against Y X sue Y." ></td>
	<td class="line x" title="10:203	Applying this rule by matching X win lawsuit against Y in the above text allows a QA system to c2008." ></td>
	<td class="line x" title="11:203	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="12:203	Some rights reserved." ></td>
	<td class="line x" title="13:203	infer X sue Y and identify IBM, Ys instantiation, as the answer for the above question." ></td>
	<td class="line x" title="14:203	Entailment rules capture linguistic and world-knowledge inferences and are used as an important building block within different applications, e.g.(Romano et al., 2006)." ></td>
	<td class="line x" title="16:203	One reason for the limited performance of generic semantic inference systems is the lack of broad-scale knowledge-bases of entailment rules (in analog to lexical resources such as WordNet)." ></td>
	<td class="line x" title="17:203	Supervised learning of broad coverage rule-sets is an arduous task." ></td>
	<td class="line x" title="18:203	This sparked intensive research on unsupervised acquisition of entailment rules (and similarly paraphrases) e.g.(Lin and Pantel, 2001; Szpektor et al., 2004; Sekine, 2005)." ></td>
	<td class="line x" title="20:203	Most unsupervised entailment rule acquisition methods learn binary rules, rules between templates with two variables, ignoring unary rules, rules between unary templates (templates with only one variable)." ></td>
	<td class="line x" title="21:203	However, a predicate quite often appears in the text with just a single variable (e.g. intransitive verbs or passives), where inference requires unary rules, e.g. X take a napX sleep (further motivations in Section 3.1)." ></td>
	<td class="line x" title="22:203	In this paper we focus on unsupervised learning of unary entailment rules." ></td>
	<td class="line x" title="23:203	Two learning approaches are proposed." ></td>
	<td class="line x" title="24:203	In our main approach, rules are learned by measuring how similar the variable instantiations of two templates in a corpus are." ></td>
	<td class="line x" title="25:203	In addition to adapting state-of-the-art similarity measures for unary rule learning, we propose a new measure, termed Balanced-Inclusion, which balances the notion of directionality in entailment with the common notion of symmetric semantic similarity." ></td>
	<td class="line x" title="26:203	In a second approach, unary rules are derived from binary rules learned by state-of-theart binary rule learning methods." ></td>
	<td class="line x" title="27:203	We tested the various unsupervised unary rule 849 learning methods, as well as a binary rule learning method, on a test set derived from a standard IE benchmark." ></td>
	<td class="line x" title="28:203	This provides the first comparison between the performance of unary and binary rulesets." ></td>
	<td class="line x" title="29:203	Several results rise from our evaluation: (a) while most work on unsupervised learning ignored unary rules, all tested unary methods outperformed the binary method; (b) it is better to learn unary rules directly than to derive them from a binary rule-base; (c) our proposed Balanced-Inclusion measure outperformed all other tested methods in terms of F1 measure." ></td>
	<td class="line x" title="30:203	Moreover, only BalancedInclusion improved F1 score over a baseline inference that does not use entailment rules at all . 2 Background This section reviews relevant distributional similarity measures, both symmetric and directional, which were applied for either lexical similarity or unsupervised entailment rule learning." ></td>
	<td class="line x" title="31:203	Distributional similarity measures follow the Distributional Hypothesis, which states that words that occur in the same contexts tend to have similar meanings (Harris, 1954)." ></td>
	<td class="line x" title="32:203	Various measures were proposed in the literature for assessing such similarity between two words,uandv." ></td>
	<td class="line oc" title="33:203	Given a wordq, its set of featuresFq and feature weightswq(f) for f Fq, a common symmetric similarity measure is Lin similarity (Lin, 1998a): Lin(u,v) = summationtext fFuFv[wu(f)+wv(f)]summationtext fFu wu(f)+ summationtext fFv wv(f) where the weight of each feature is the pointwise mutual information (pmi) between the word and the feature: wq(f) =log[Pr(f|q)Pr(f) ]." ></td>
	<td class="line x" title="34:203	Weeds and Weir (2003) proposed to measure the symmetric similarity between two words by averaging two directional (asymmetric) scores: the coverage of each words features by the other." ></td>
	<td class="line x" title="35:203	The coverage of u by v is measured by: Cover(u,v) = summationtext fFuFv wu(f)summationtext fFu wu(f) The average can be arithmetic or harmonic: WeedsA(u,v) = 12[Cover(u,v)+Cover(v,u)] WeedsH(u,v) = 2Cover(u,v)Cover(v,u)Cover(u,v)+Cover(v,u) Weeds et al. also used pmi for feature weights." ></td>
	<td class="line x" title="36:203	Binary rule learning algorithms adopted such lexical similarity approaches for learning rules between templates, where the features of each template are its variable instantiations in a corpus, such as {X=SCO, Y=IBM} for the example in Section 1." ></td>
	<td class="line x" title="37:203	Some works focused on learning rules from comparable corpora, containing comparable documents such as different news articles from the same date on the same topic (Barzilay and Lee, 2003; Ibrahim et al., 2003)." ></td>
	<td class="line x" title="38:203	Such corpora are highly informative for identifying variations of the same meaning, since, typically, when variable instantiations are shared across comparable documents the same predicates are described." ></td>
	<td class="line x" title="39:203	However, it is hard to collect broad-scale comparable corpora, as the majority of texts are non-comparable." ></td>
	<td class="line x" title="40:203	A complementary approach is learning from the abundant regular, non-comparable, corpora." ></td>
	<td class="line x" title="41:203	Yet, in such corpora it is harder to recognize variations of the same predicate." ></td>
	<td class="line x" title="42:203	The DIRT algorithm (Lin and Pantel, 2001) learns non-directional binary rules for templates that are paths in a dependency parse-tree between two noun variables X andY." ></td>
	<td class="line o" title="43:203	The similarity between two templatestand tprime is the geometric average: DIRT(t,tprime) = radicalBig Linx(t,tprime)Liny(t,tprime) where Linx is the Lin similarity between Xs instantiations of t and Xs instantiations of tprime in a corpus (equivalently for Liny)." ></td>
	<td class="line x" title="44:203	Some works take the combination of the two variable instantiations in each template occurrence as a single complex feature, e.g. {X-Y=SCO-IBM}, and compare between these complex features of t and tprime (Ravichandran and Hovy, 2002; Szpektor et al., 2004; Sekine, 2005)." ></td>
	<td class="line x" title="45:203	Directional Measures Most rule learning methods apply a symmetric similarity measure between two templates, viewing them as paraphrasing each other." ></td>
	<td class="line x" title="46:203	However, entailment is in general a directional relation." ></td>
	<td class="line x" title="47:203	For example, X acquire Y  X own Y and countersuit against X lawsuit against X." ></td>
	<td class="line x" title="48:203	(Weeds and Weir, 2003) propose a directional measure for learning hyponymy between two words, lr, by giving more weight to the coverage of the features of l by r (with > 12): WeedsD(l,r)=Cover(l,r)+(1)Cover(r,l) When =1, this measure degenerates into Cover(l,r), termed Precision(l,r)." ></td>
	<td class="line x" title="49:203	With 850 Precision(l,r) we obtain a soft version of the inclusion hypothesis presented in (Geffet and Dagan, 2005), which expects l to entail r if the important features of l appear also in r. Similarly, the LEDIR algorithm (Bhagat et al., 2007) identifies the entailment direction between two binary templates, l and r, which participate in a relation learned by (the symmetric) DIRT, by measuring the proportion of instantiations of l that are covered by the instantiations of r. As far as we know, only (Shinyama et al., 2002) and (Pekar, 2006) learn rules between unary templates." ></td>
	<td class="line x" title="50:203	However, (Shinyama et al., 2002) relies on comparable corpora for identifying paraphrases and simply takes any two templates from comparable sentences that share a named entity instantiation to be paraphrases." ></td>
	<td class="line x" title="51:203	Such approach is not feasible for non-comparable corpora where statistical measurement is required." ></td>
	<td class="line x" title="52:203	(Pekar, 2006) learns rules only between templates related by local discourse (information from different documents is ignored)." ></td>
	<td class="line x" title="53:203	In addition, their template structure is limited to only verbs and their direct syntactic arguments, which may yield incorrect rules, e.g. for light verbs (see Section 5.2)." ></td>
	<td class="line x" title="54:203	To overcome this limitation, we use a more expressive template structure." ></td>
	<td class="line x" title="55:203	3 Learning Unary Entailment Rules 3.1 Motivations Most unsupervised rule learning algorithms focused on learning binary entailment rules." ></td>
	<td class="line x" title="56:203	However, using binary rules for inference is not enough." ></td>
	<td class="line x" title="57:203	First, a predicate that can have multiple arguments may still occur with only one of its arguments." ></td>
	<td class="line x" title="58:203	For example, in The acquisition of TCA was successful, TCA is the only argument of acquisition." ></td>
	<td class="line x" title="59:203	Second, some predicate expressions are unary by nature." ></td>
	<td class="line x" title="60:203	For example, modifiers, such as the elected X, or intransitive verbs." ></td>
	<td class="line x" title="61:203	In addition, it appears more tractable to learn all variations for each argument of a predicate separately than to learn them for combinations of argument pairs." ></td>
	<td class="line x" title="62:203	For these reasons, it seems that unary rule learning should be addressed in addition to binary rule learning." ></td>
	<td class="line x" title="63:203	We are further motivated by the fact that some (mostly supervised) works in IE found learning unary templates useful for recognizing relevant named entities (Riloff, 1996; Sudo et al., 2003; Shinyama and Sekine, 2006), though they did not attempt to learn generic knowledge bases of entailment rules." ></td>
	<td class="line x" title="64:203	This paper investigates acquisition of unary entailment rules from regular non-comparable corpora." ></td>
	<td class="line x" title="65:203	We first describe the structure of unary templates and then explore two conceivable approaches for learning unary rules." ></td>
	<td class="line x" title="66:203	The first approach directly assesses the relation between two given templates based on the similarity of their instantiations in the corpus." ></td>
	<td class="line x" title="67:203	The second approach, which was also mentioned in (Iftene and BalahurDobrescu, 2007), derives unary rules from learned binary rules." ></td>
	<td class="line x" title="68:203	3.2 Unary Template Structure To learn unary rules we first need to define their structure." ></td>
	<td class="line x" title="69:203	In this paper we work at the syntactic representation level." ></td>
	<td class="line oc" title="70:203	Texts are represented by dependency parse trees (using the Minipar parser (Lin, 1998b)) and templates by parse sub-trees." ></td>
	<td class="line x" title="71:203	Given a dependency parse tree, any sub-tree can be a candidate template, setting some of its nodes as variables (Sudo et al., 2003)." ></td>
	<td class="line x" title="72:203	However, the number of possible templates is exponential in the size of the sentence." ></td>
	<td class="line x" title="73:203	In the binary rule learning literature, the main solution for exhaustively learning all rules between any pair of templates in a given corpus is to restrict the structure of templates." ></td>
	<td class="line x" title="74:203	Typically, a template is restricted to be a path in a parse tree between two variable nodes (Lin and Pantel, 2001; Ibrahim et al., 2003)." ></td>
	<td class="line x" title="75:203	Following this approach, we chose the structure of unary templates to be paths as well, where one end of the path is the templates variable." ></td>
	<td class="line x" title="76:203	However, paths with one variable have more expressive power than paths between two variables, since the combination of two unary paths may generate a binary template that is not a path." ></td>
	<td class="line x" title="77:203	For example, the combination of X call indictable and call Y indictable is the template X call Y indictable, which is not a path between X and Y. For every noun node v in a parsed sentence, we generate templates with v as a variable as follows: 1." ></td>
	<td class="line x" title="78:203	Traverse the path from v towards the root of the parse tree." ></td>
	<td class="line x" title="79:203	Whenever a candidate predicate is encountered (any noun, adjective or verb) the path from that node to v is taken as a template." ></td>
	<td class="line x" title="80:203	We stop when the first verb or clause boundary (e.g. a relative clause) is encountered, which typically represent the syntactic boundary of a specific predicate." ></td>
	<td class="line x" title="81:203	851 2." ></td>
	<td class="line x" title="82:203	To enable templates with control verbs and light verbs, e.g. X help preventing, X make noise, whenever a verb is encountered we generate templates that are paths between v and the verbs modifiers, either objects, prepositional complements or infinite or gerund verb forms (paths ending at stop words, e.g. pronouns, are not generated)." ></td>
	<td class="line x" title="83:203	3." ></td>
	<td class="line x" title="84:203	To capture noun modifiers that act as predicates, e.g. the losingX, we extract template paths between v and each of its modifiers, nouns or adjectives, that are derived from a verb." ></td>
	<td class="line x" title="85:203	We use the Catvar database to identify verb derivations (Habash and Dorr, 2003)." ></td>
	<td class="line x" title="86:203	As an example for the procedure, the templates extracted from the sentence The losing party played it safe with party as the variable are: losing X, X play and X play safe." ></td>
	<td class="line x" title="87:203	3.3 Direct Learning of Unary Rules We applied the lexical similarity measures presented in Section 2 for unary rule learning." ></td>
	<td class="line x" title="88:203	Each argument instantiation of template t in the corpus is taken as a feature f, and the pmi between t and f is used for the features weight." ></td>
	<td class="line o" title="89:203	We first adapted DIRT for unary templates (unary-DIRT, applying Lin-similarity to the single feature vector), as well as its output filtering by LEDIR." ></td>
	<td class="line x" title="90:203	The various Weeds measures were also applied1: symmetric arithmetic average, symmetric harmonic average, weighted arithmetic average and Precision." ></td>
	<td class="line o" title="91:203	After initial analysis, we found that given a right hand side template r, symmetric measures such as Lin (in DIRT) generally tend to prefer (score higher) relationsl,rin which l and r are related but do not necessarily participate in an entailment or equivalence relation, e.g. the wrong rule kill X injure X." ></td>
	<td class="line x" title="92:203	On the other hand, directional measures such as Weeds Precision tend to prefer directional rules in which the entailing template is infrequent." ></td>
	<td class="line x" title="93:203	If an infrequent template has common instantiations with another template, the coverage of its features is typically high, whether or not an entailment relation exists between the two templates." ></td>
	<td class="line x" title="94:203	This behavior generates high-score incorrect rules." ></td>
	<td class="line x" title="95:203	Based on this analysis, we propose a new measure that balances the two behaviors, termed 1We applied the best performing parameter values presented in (Bhagat et al., 2007) and (Weeds and Weir, 2003)." ></td>
	<td class="line x" title="96:203	Balanced-Inclusion (BInc)." ></td>
	<td class="line x" title="97:203	BInc identifies entailing templates based on a directional measure but penalizes infrequent templates using a symmetric measure: BInc(l,r) = radicalbig Lin(l,r)Precision(l,r) 3.4 Deriving Unary Rules From Binary Rules An alternative way to learn unary rules is to first learn binary entailment rules and then derive unary rules from them." ></td>
	<td class="line x" title="98:203	We derive unary rules from a given binary rule-base in two steps." ></td>
	<td class="line x" title="99:203	First, for each binary rule, we generate all possible unary rules that are part of that rule (each unary template is extracted following the same procedure described in Section 3.2)." ></td>
	<td class="line x" title="100:203	For example, from X find solution to Y X solve Y we generate the unary rules X findX solve, X find solutionX solve, solution to Y solve Y and find solution toY solveY." ></td>
	<td class="line x" title="101:203	The score of each generated rule is set to be the score of the original binary rule." ></td>
	<td class="line x" title="102:203	The same unary rule can be derived from different binary rules." ></td>
	<td class="line x" title="103:203	For example, hire Y  employ Y is derived both from X hire Y X employ Y and hire Y for Z  employ Y for Z, having a different score from each original binary rule." ></td>
	<td class="line x" title="104:203	The second step of the algorithm aggregates the different scores yielded for each derived rule to produce the final rule score." ></td>
	<td class="line x" title="105:203	Three aggregation functions were tested: sum (Derived-Sum), average (Derived-Avg) and maximum (Derived-Max)." ></td>
	<td class="line x" title="106:203	4 Experimental Setup We want to evaluate learned unary and binary rule bases by their utility for NLP applications through assessing the validity of inferences that are performed in practice using the rule base." ></td>
	<td class="line x" title="107:203	To perform such experiments, we need a testset of seed templates, which correspond to a set of target predicates, and a corpus annotated with all argument mentions of each predicate." ></td>
	<td class="line x" title="108:203	The evaluation assesses the correctness of all argument extractions, which are obtained by matching in the corpus either the seed templates or templates that entail them according to the rule-base (the latter corresponds to rule-application)." ></td>
	<td class="line x" title="109:203	Following (Szpektor et al., 2008), we found the ACE 2005 event training set2 useful for this purpose." ></td>
	<td class="line x" title="110:203	This standard IE dataset includes 33 types of event predicates such as Injure, Sue and Divorce." ></td>
	<td class="line x" title="111:203	2http://projects.ldc.upenn.edu/ace/ 852 All event mentions are annotated in the corpus, including the instantiated arguments of the predicate." ></td>
	<td class="line x" title="112:203	ACE guidelines specify for each event its possible arguments, each associated with a semantic role." ></td>
	<td class="line x" title="113:203	For instance, some of the Injure event arguments are Agent, Victim and Time." ></td>
	<td class="line x" title="114:203	To utilize the ACE dataset for evaluating entailment rule applications, we manually represented each ACE event predicate by unary seed templates." ></td>
	<td class="line x" title="115:203	For example, the seed templates for Injure are A injure, injure V and injure in T." ></td>
	<td class="line x" title="116:203	We mapped each event role annotation to the corresponding seed template variable, e.g. Agent to A and Victim to V in the above example." ></td>
	<td class="line x" title="117:203	Templates are matched using a syntactic matcher that handles simple morpho-syntactic phenomena, as in (Szpektor and Dagan, 2007)." ></td>
	<td class="line x" title="118:203	A rule application is considered correct if the matched argument is annotated by the corresponding ACE role." ></td>
	<td class="line x" title="119:203	For testing binary rule-bases, we automatically generated binary seed templates from any two unary seeds that share the same predicate." ></td>
	<td class="line x" title="120:203	For example, for Injure the binary seeds A injure V, A injure inT and injureV inT were automatically generated from the above unary seeds." ></td>
	<td class="line x" title="121:203	We performed two adaptations to the ACE dataset to fit it better to our evaluation needs." ></td>
	<td class="line x" title="122:203	First, our evaluation aims at assessing the correctness of inferring a specific target semantic meaning, which is denoted by a specific predicate, using rules." ></td>
	<td class="line x" title="123:203	Thus, four events that correspond ambiguously to multiple distinct predicates were ignored." ></td>
	<td class="line x" title="124:203	For instance, the Transfer-Money event refers to both donating and lending money, and thus annotations of this event cannot be mapped to a specific seed template." ></td>
	<td class="line x" title="125:203	We also omitted 3 events with less than 10 mentions, and were left with 26 events (6380 argument mentions)." ></td>
	<td class="line x" title="126:203	Additionally, we regard all entailing mentions under the textual entailment definition as correct." ></td>
	<td class="line x" title="127:203	However, event mentions are annotated as correct in ACE only if they explicitly describe the target event." ></td>
	<td class="line x" title="128:203	For instance, a Divorce mention does entail a preceding marriage event but it does not explicitly describe it, and thus it is not annotated as a Marry event." ></td>
	<td class="line x" title="129:203	To better utilize the ACE dataset, we considered for a target event the annotations of other events that entail it as being correct as well." ></td>
	<td class="line x" title="130:203	We note that each argument was considered separately." ></td>
	<td class="line x" title="131:203	For example, we marked a mention of a divorced person as entailing the marriage of that person, but did not consider the place and time of the divorce act to be those of the marriage . 5 Results and Analysis We implemented the unary rule learning algorithms described in Section 3 and the binary DIRT algorithm (Lin and Pantel, 2001)." ></td>
	<td class="line x" title="132:203	We executed each method over the Reuters RCV1 corpus3, learning for each template r in the corpus the top 100 rules in which r is entailed by another templatel, lr." ></td>
	<td class="line x" title="133:203	All rules were learned in canonical form (Szpektor and Dagan, 2007)." ></td>
	<td class="line x" title="134:203	The rule-base learned by binary DIRT was taken as the input for deriving unary rules from binary rules." ></td>
	<td class="line x" title="135:203	The performance of each acquired rule-base was measured for each ACE event." ></td>
	<td class="line x" title="136:203	We measured the percentage of correct argument mentions extracted out of all correct argument mentions annotated for the event (recall) and out of all argument mentions extracted for the event (precision)." ></td>
	<td class="line x" title="137:203	We also measured F1, their harmonic average, and report macro average Recall, Precision and F1 over the 26 event types." ></td>
	<td class="line x" title="138:203	No threshold setting mechanism is suggested in the literature for the scores of the different algorithms, especially since rules for different right hand side templates have different score ranges." ></td>
	<td class="line x" title="139:203	Thus, we follow common evaluation practice (Lin and Pantel, 2001; Geffet and Dagan, 2005) and test each learned rule-set by taking the top K rules for each seed template, whereK ranges from 0 to 100." ></td>
	<td class="line x" title="140:203	WhenK=0, no rules are used and mentions are extracted only by direct matching of seed templates." ></td>
	<td class="line x" title="141:203	Our rule application setting provides a rather simplistic IE system (for example, no named entity recognition or approximate template matching)." ></td>
	<td class="line x" title="142:203	It is thus useful for comparing different rule-bases, though the absolute extraction figures do not reflect the full potential of the rules." ></td>
	<td class="line x" title="143:203	In Secion 5.2 we analyze the full-systems errors to isolate the rules contribution to overall system performance." ></td>
	<td class="line x" title="144:203	5.1 Results In this section we focus on the best performing variations of each algorithm type: binary DIRT, unary DIRT, unary Weeds Harmonic, BInc and Derived-Avg." ></td>
	<td class="line x" title="145:203	We omitted the results of methods that were clearly inferior to others: (a) WeedsA, WeedsD and Weeds-Precision did not increase 3http://about.reuters.com/researchandstandards/corpus/ 853 Recall over not using rules because rules with infrequent templates scored highest and arithmetic averaging could not balance well these high scores; (b) out of the methods for deriving unary rules from binary rule-bases, Derived-Avg performed best; (c) filtering with (the directional) LEDIR did not improve the performance of unary DIRT." ></td>
	<td class="line x" title="146:203	Figure 1 presents Recall, Precision and F1 of the methods for different cutoff points." ></td>
	<td class="line x" title="147:203	First, we observe that even when matching only the seed templates (K=0), unary seeds outperform the binary seeds in terms of both Precision and Recall." ></td>
	<td class="line x" title="148:203	This surprising behavior is consistent through all rule cutoff points: all unary learning algorithms perform better than binary DIRT in all parameters." ></td>
	<td class="line x" title="149:203	The inferior behavior of binary DIRT is analyzed in Section 5.2." ></td>
	<td class="line x" title="150:203	The graphs show that symmetric unary approaches substantially increase recall, but dramatically decrease precision already at the top 10 rules." ></td>
	<td class="line x" title="151:203	As a result, F1 only decreases for these methods." ></td>
	<td class="line x" title="152:203	Lin similarity (DIRT) and Weeds-Harmonic show similar behaviors." ></td>
	<td class="line x" title="153:203	They consistently outperform Derived-Avg." ></td>
	<td class="line x" title="154:203	One reason for this is that incorrect unary rules may be derived even from correct binary rules." ></td>
	<td class="line x" title="155:203	For example, from X gain seat on Y  elect X to Y the incorrect unary rule X gainelectX is also generated." ></td>
	<td class="line x" title="156:203	This problem is less frequent when unary rules are directly scored based on their corpus statistics." ></td>
	<td class="line x" title="157:203	The directional measure of BInc yields a more accurate rule-base, as can be seen by the much slower precision reduction rate compared to the other algorithms." ></td>
	<td class="line x" title="158:203	As a result, it is the only algorithm that improves over the F1 baseline of K=0, with the best cutoff point at K=20." ></td>
	<td class="line x" title="159:203	BIncs recall increases moderately compared to other unary learning approaches, but it is still substantially better than not using rules (a relative recall increase of 50% already at K=10)." ></td>
	<td class="line x" title="160:203	We found that many of the correct mentions missed by BInc but identified by other methods are due to occasional extractions of incorrect frequent rules, such as partial templates (see Section 5.2)." ></td>
	<td class="line x" title="161:203	This is reflected in the very low precision of the other methods." ></td>
	<td class="line x" title="162:203	On the other hand, some correct rules were only learned by BInc, e.g. countersuit againstXX sue and X take wife X marry." ></td>
	<td class="line x" title="163:203	When only one argument is annotated for a specific event mention (28% of ACE predicate mentions, which account for 15% of all annotated arFigure 1: Average Precision, Recall and F1 at different top K rule cutoff points." ></td>
	<td class="line x" title="164:203	guments), binary rules either miss that mention, or extract both the correct argument and another incorrect one." ></td>
	<td class="line x" title="165:203	To neutralize this bias, we also tested the various methods only on event mentions annotated with two or more arguments and obtained similar results to those presented for all mentions." ></td>
	<td class="line x" title="166:203	This further emphasizes the general advantage of using unary rules over binary rules." ></td>
	<td class="line x" title="167:203	854 5.2 Analysis Binary-DIRT We analyzed incorrect rules both for binary-DIRT and BInc by randomly sampling, for each algorithm, 200 rules that extracted incorrect mentions." ></td>
	<td class="line x" title="168:203	We manually classified each rule l r as either: (a) Correct the rule is valid in some contexts of the event but extracted some incorrect mentions; (b) Partial Template l is only a part of a correct template that entails r. For example, learning X decideX meet instead of X decide to meet X meet; (e) Incorrect other incorrect rules, e.g. charge Xconvict X." ></td>
	<td class="line x" title="169:203	Table 1 summarizes the analysis and demonstrates two problems of binary-DIRT." ></td>
	<td class="line x" title="170:203	First, relative to BInc, it tends to learn incorrect rules for high frequency templates, and therefore extracted many more incorrect mentions for the same number of incorrect rules." ></td>
	<td class="line x" title="171:203	Second, a large percentage of incorrect mentions extracted are due to partial templates at the rule left-hand-side." ></td>
	<td class="line x" title="172:203	Such rules are leaned because many binary templates have a more complex structure than paths between arguments." ></td>
	<td class="line x" title="173:203	As explained in Section 3.2 the unary template structure we use is more expressive, enabling to learn the correct rules." ></td>
	<td class="line x" title="174:203	For example, BInc learned take Y into custody  arrest Y while binaryDIRT learned X take Y X arrest Y." ></td>
	<td class="line x" title="175:203	System Level Analysis We manually analyzed the reasons for false positives (incorrect extractions) and false negatives (missed extractions) of BInc, at its best performing cutoff point (K=20), by sampling 200 extractions of each type." ></td>
	<td class="line x" title="176:203	From the false positives analysis (Table 2) we see that 39% of the errors are due to incorrect rules." ></td>
	<td class="line x" title="177:203	The main reasons for learning such rules are those discussed in Section 3.3: (a) related templates that are not entailing; (b) infrequent templates." ></td>
	<td class="line x" title="178:203	All learning methods suffer from these issues." ></td>
	<td class="line x" title="179:203	As was shown by our results, BInc provides a first step towards reducing these problems." ></td>
	<td class="line x" title="180:203	Yet, these issues require further research." ></td>
	<td class="line x" title="181:203	Apart from incorrectly learned rules, incorrect template matching (e.g. due to parse errors) and context mismatch contribute together 46% of the errors." ></td>
	<td class="line x" title="182:203	Context mismatches occur when the entailing template is matched in inappropriate contexts." ></td>
	<td class="line x" title="183:203	For example, slam Xattack X should not be applied when X is a ball, only when it is a person." ></td>
	<td class="line x" title="184:203	The rule-set net effect on system precision is better estimated by removing these errors and fixing the annotation errors, which yields 72% precision." ></td>
	<td class="line x" title="185:203	Binary DIRT Balanced Inclusion Correct 16 (70) 38 (91) Partial Template 27 (2665) 6 (81) Incorrect 157 (2584) 156 (787) Total 200 (5319) 200 (959) Table 1: Rule type distribution of a sample of 200 rules that extracted incorrect mentions." ></td>
	<td class="line x" title="186:203	The corresponding numbers of incorrect mentions extracted by the sampled rules is shown in parentheses." ></td>
	<td class="line x" title="187:203	Reason % mentions Incorrect Rule learned 39.0 Context mismatch 27.0 Match error 19.0 Annotation problem 15.0 Table 2: Distribution of reasons for false positives (incorrect argument extractions) by BInc at K=20." ></td>
	<td class="line x" title="188:203	Reason % mentions Rule not learned 61.5 Match error 25.0 Discourse analysis needed 12.0 Argument is predicative 1.5 Table 3: Distribution of reasons for false negatives (missed argument mentions) by BInc at K=20." ></td>
	<td class="line x" title="189:203	Table 3 presents the analysis of false negatives." ></td>
	<td class="line x" title="190:203	First, we note that 12% of the arguments cannot be extracted by rules alone, due to necessary discourse analysis." ></td>
	<td class="line x" title="191:203	Thus, a recall upper bound for entailment rules is 88%." ></td>
	<td class="line x" title="192:203	Many missed extractions are due to rules that were not learned (61.5%)." ></td>
	<td class="line x" title="193:203	However, 25% of the mentions were missed because of incorrect syntactic matching of correctly learned rules." ></td>
	<td class="line x" title="194:203	By assuming correct matches in these cases we isolate the recall of the rule-set (along with the seeds), which yields 39% recall." ></td>
	<td class="line x" title="195:203	6 Conclusions We presented two approaches for unsupervised acquisition of unary entailment rules from regular (non-comparable) corpora." ></td>
	<td class="line x" title="196:203	In the first approach, rules are directly learned based on distributional similarity measures." ></td>
	<td class="line x" title="197:203	The second approach derives unary rules from a given rule-base of binary rules." ></td>
	<td class="line x" title="198:203	Under the first approach we proposed a novel directional measure for scoring entailment rules, termed Balanced-Inclusion." ></td>
	<td class="line x" title="199:203	We tested the different approaches utilizing a standard IE test-set and compared them to binary rule learning." ></td>
	<td class="line x" title="200:203	Our results suggest the advantage of learning unary rules: (a) unary rule-bases perform 855 better than binary rules; (b) it is better to directly learn unary rules than to derive them from binary rule-bases." ></td>
	<td class="line x" title="201:203	In addition, the Balanced-Inclusion measure outperformed all other tested methods." ></td>
	<td class="line x" title="202:203	In future work, we plan to explore additional unary template structures and similarity scores, and to improve rule application utilizing context matching methods such as (Szpektor et al., 2008)." ></td>
	<td class="line x" title="203:203	Acknowledgements This work was partially supported by ISF grant 1095/05, the IST Programme of the European Community under the PASCAL Network of Excellence IST-2002-506778 and the NEGEV project (www.negev-initiative.org)." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1117
Using Three Way Data for Word Sense Discrimination
Van de Cruys, Tim;"></td>
	<td class="line x" title="1:212	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 929936 Manchester, August 2008 Using Three Way Data for Word Sense Discrimination Tim Van de Cruys Humanities Computing University of Groningen t.van.de.cruys@rug.nl Abstract In this paper, an extension of a dimensionality reduction algorithm called NONNEGATIVE MATRIX FACTORIZATION is presented that combines both bag of words data and syntactic data, in order to find semantic dimensions according to which both words and syntactic relations can be classified." ></td>
	<td class="line x" title="2:212	The use of three way data allows one to determine which dimension(s) are responsible for a certain sense of a word, and adapt the corresponding feature vector accordingly, subtracting one sense to discover another one." ></td>
	<td class="line x" title="3:212	The intuition in this is that the syntactic features of the syntax-based approach can be disambiguated by the semantic dimensions found by the bag of words approach." ></td>
	<td class="line x" title="4:212	The novel approach is embedded into clustering algorithms, to make it fully automatic." ></td>
	<td class="line x" title="5:212	The approach is carried out for Dutch, and evaluated against EuroWordNet." ></td>
	<td class="line x" title="6:212	1 Introduction Automatically acquiring semantics from text is a subject that has gathered a lot of attention for quite some time now." ></td>
	<td class="line x" title="7:212	As Manning and Schutze (Manning and Schutze, 2000) point out, most work on acquiring semantic properties of words has focused on semantic similarity." ></td>
	<td class="line x" title="8:212	Automatically acquiring a relative measure of how similar a word is to known words [] is much easier than determining what the actual meaning is. (Manning and Schutze, 2000,8.5) c2008." ></td>
	<td class="line x" title="9:212	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="10:212	Some rights reserved." ></td>
	<td class="line x" title="11:212	Most work on semantic similarity relies on the distributional hypothesis (Harris, 1985)." ></td>
	<td class="line x" title="12:212	This hypothesis states that words that occur in similar contexts tend to be similar." ></td>
	<td class="line x" title="13:212	With regard to the context used, two basic approaches exist." ></td>
	<td class="line x" title="14:212	One approach makes use of bag of words co-occurrence data; in this approach, a certain window around a word is used for gathering co-occurrence information." ></td>
	<td class="line x" title="15:212	The window may either be a fixed number of words, or the paragraph or document that a word appears in." ></td>
	<td class="line x" title="16:212	Thus, words are considered similar if they appear in similar windows (documents)." ></td>
	<td class="line x" title="17:212	One of the dominant methods using this method is LATENT SEMANTIC ANALYSIS (LSA)." ></td>
	<td class="line x" title="18:212	The second approach uses a more fine grained distributional model, focusing on the syntactic relations that words appear with." ></td>
	<td class="line x" title="19:212	Typically, a large text corpus is parsed, and dependency triples are extracted.1 Words are considered similar if they appear with similar syntactic relations." ></td>
	<td class="line x" title="20:212	Note that the former approach does not need any kind of linguistic annotation, whereas for the latter, some form of syntactic annotation is needed." ></td>
	<td class="line x" title="21:212	The results yielded by both approaches are typically quite different in nature: the former approach typically puts its finger on a broad, thematic kind of similarity, while the latter approach typically grasps a tighter, synonym-like similarity." ></td>
	<td class="line x" title="22:212	Example (1) shows the difference between both approaches; for each approach, the top ten most similar nouns to the Dutch noun muziek music are given." ></td>
	<td class="line x" title="23:212	In (a), the window-based approach is used, while (b) uses the syntax-based approach." ></td>
	<td class="line x" title="24:212	(a) shows indeed more thematic similarity, whereas (b) shows tighter similarity." ></td>
	<td class="line x" title="25:212	1e.g. dependency relations that qualify apple might be object of eat and adjective red." ></td>
	<td class="line x" title="26:212	This gives us dependency triples like < apple,obj,eat >." ></td>
	<td class="line x" title="27:212	929 (1) a. muziek music: gitaar guitar, jazz jazz, cd cd, rock rock, bas bass, song song, muzikant musician, musicus musician, drum drum, slagwerker drummer b. muziek music: dans dance, kunst art, klank sound, liedje song, geluid sound, poezie poetry, literatuur literature, popmuziek pop music, lied song, melodie melody Especially the syntax-based method has been adopted by many researchers, in order to find semantically similar words." ></td>
	<td class="line x" title="28:212	There is, however, one important problem with this kind of approach: the method is not able to cope with ambiguous words." ></td>
	<td class="line x" title="29:212	Take the examples: (2) een a oneven odd nummer number an odd number (3) een a steengoed great nummer number a great song The word nummer does not have the same meaning in these examples." ></td>
	<td class="line x" title="30:212	In example (2), nummer is used in the sense of designator of quantity." ></td>
	<td class="line x" title="31:212	In example (3), it is used in the sense of musical performance." ></td>
	<td class="line x" title="32:212	Accordingly, we would like the word nummer to be disambiguated into two senses, the first sense being similar to words like getal number, cijfer digit and the second to words like liedje song, song song." ></td>
	<td class="line x" title="33:212	While it is relatively easy for a human language user to distinguish between the two senses, this is a difficult task for a computer." ></td>
	<td class="line x" title="34:212	Even worse: the results get blurred because the attributes of both senses (in this example oneven and steengoed) are grouped together into one sense." ></td>
	<td class="line x" title="35:212	This is the main drawback of the syntax-based method." ></td>
	<td class="line x" title="36:212	On the other hand, methods that capture semantic dimensions are known to be useful in disambiguating different senses of a word." ></td>
	<td class="line x" title="37:212	Particularly, PROBABILISTIC LATENT SEMANTIC ANALYSIS (PLSA) is known to simultaneously encode various senses of words according to latent semantic dimensions (Hofmann, 1999)." ></td>
	<td class="line x" title="38:212	In this paper, we want to explore an approach that tries to remedy the shortcomings of the former, syntax-based approach with the benefits of the latter." ></td>
	<td class="line x" title="39:212	The intuition in this is that the syntactic features of the syntaxbased approach can be disambiguated by the latent semantic dimensions found by the windowbased approach." ></td>
	<td class="line x" title="40:212	2 Previous Work 2.1 Distributional Similarity There have been numerous approaches for computing the similarity between words from distributional data." ></td>
	<td class="line x" title="41:212	We mention some of the most important ones." ></td>
	<td class="line x" title="42:212	With regard to the first approach  using a context window  we already mentioned LSA (Landauer and Dumais, 1997)." ></td>
	<td class="line x" title="43:212	In LSA, a termdocument matrix is created, containing the frequency of each word in a specific document." ></td>
	<td class="line x" title="44:212	This matrix is then decomposed into three other matrices with a mathematical technique called SINGULAR VALUE DECOMPOSITION." ></td>
	<td class="line x" title="45:212	The most important dimensions that come out of the SVD allegedly represent latent semantic dimensions, according to which nouns and documents can be presented more efficiently." ></td>
	<td class="line x" title="46:212	LSA has been criticized for not being the most appropriate data reduction method for textual applications." ></td>
	<td class="line x" title="47:212	The SVD underlying the method assumes normally-distributed data, whereas textual count data (such as the term-document matrix) can be more appropriately modeled by other distributional models such as Poisson (Manning and Schutze, 2000,15.4.3)." ></td>
	<td class="line x" title="48:212	Successive methods such as PROBABILISTIC LATENT SEMANTIC ANALYSIS (PLSA) (Hofmann, 1999), try to remedy this shortcoming by imposing a proper latent variable model, according to which the values can be estimated." ></td>
	<td class="line x" title="49:212	The method we adopt in our research  NON-NEGATIVE MATRIX FACTORIZATION  is similar to PLSA, and adequately remedies this problem as well." ></td>
	<td class="line o" title="50:212	The second approach  using syntactic relations  has been adopted by many researchers, in order to acquire semantically similar words." ></td>
	<td class="line oc" title="51:212	One of the most important is Lins (1998)." ></td>
	<td class="line x" title="52:212	For Dutch, the approach has been applied by Van der Plas & Bouma (2005)." ></td>
	<td class="line x" title="53:212	2.2 Discriminating senses Schutze (1998) uses a disambiguation algorithm  called context-group discrimination  based on the clustering of the context of ambiguous words." ></td>
	<td class="line x" title="54:212	The clustering is based on second-order co-occurrence: the contexts of the ambiguous word are similar if the words they in turn co-occur with are similar." ></td>
	<td class="line x" title="55:212	Pantel and Lin (2002) present a clustering algorithm  coined CLUSTERING BY COMMITTEE (CBC)  that automatically discovers word senses 930 from text." ></td>
	<td class="line x" title="56:212	The key idea is to first discover a set of tight, unambiguous clusters, to which possibly ambiguous words can be assigned." ></td>
	<td class="line x" title="57:212	Once a word has been assigned to a cluster, the features associated with that particular cluster are stripped off the words vector." ></td>
	<td class="line x" title="58:212	This way, less frequent senses of the word can be discovered." ></td>
	<td class="line x" title="59:212	The former approach uses a window-based method; the latter uses syntactic data." ></td>
	<td class="line x" title="60:212	But none of the algorithms developed so far have combined both sources in order to discriminate among different senses of a word." ></td>
	<td class="line x" title="61:212	3 Methodology 3.1 Non-negative Matrix Factorization 3.1.1 Theory Non-negative matrix factorization (NMF) (Lee and Seung, 2000) is a group of algorithms in which a matrix V is factorized into two other matrices, W and H. VnmWnrHrm (1) Typically r is much smaller than n,m so that both instances and features are expressed in terms of a few components." ></td>
	<td class="line x" title="62:212	Non-negative matrix factorization enforces the constraint that all three matrices must be nonnegative, so all elements must be greater than or equal to zero." ></td>
	<td class="line x" title="63:212	The factorization turns out to be particularly useful when one wants to find additive properties." ></td>
	<td class="line x" title="64:212	Formally, the non-negative matrix factorization is carried out by minimizing an objective function." ></td>
	<td class="line x" title="65:212	Two kinds of objective function exist: one that minimizes the Euclidean distance, and one that minimizes the Kullback-Leibler divergence." ></td>
	<td class="line x" title="66:212	In this framework, we will adopt the latter, as  from our experience  entropy-based measures tend to work well for natural language." ></td>
	<td class="line x" title="67:212	Thus, we want to find the matrices W and H for which the KullbackLeibler divergence between V and WH (the multiplication of W and H) is the smallest." ></td>
	<td class="line x" title="68:212	Practically, the factorization is carried out through the iterative application of update rules." ></td>
	<td class="line x" title="69:212	Matrices W and H are randomly initialized, and the rules in 2 and 3 are iteratively applied  alternating between them." ></td>
	<td class="line x" title="70:212	In each iteration, each vector is adequately normalized, so that all dimension values sum to 1." ></td>
	<td class="line x" title="71:212	HaHa summationtext i Wia Vi (WH)isummationtext k Wka (2) WiaWia summationtext  Ha Vi (WH)isummationtext v Hav (3) 3.1.2 Example We can now straightforwardly apply NMF to create semantic word models." ></td>
	<td class="line x" title="72:212	NMF is applied to a frequency matrix, containing bag of words cooccurrence data." ></td>
	<td class="line x" title="73:212	The additive property of NMF ensures that semantic dimensions emerge, according to which the various words can be classified." ></td>
	<td class="line x" title="74:212	Two sample dimensions are shown in example (4)." ></td>
	<td class="line x" title="75:212	For each dimension, the words with the largest value on that dimension are given." ></td>
	<td class="line x" title="76:212	Dimension (a) can be qualified as a transport dimension, and dimension (b) as a cooking dimension." ></td>
	<td class="line x" title="77:212	(4) a. bus bus, taxi taxi, trein train, halte stop, reiziger traveler, perron platform, tram tram, station station, chauffeur driver, passagier passenger b. bouillon broth, slagroom cream, ui onion, eierdooier egg yolk, laurierblad bay leaf, zout salt, deciliter decilitre, boter butter, bleekselderij celery, saus sauce 3.2 Extending Non-negative Matrix Factorization We now propose an extension of NMF that combines both the bag of words approach and the syntactic approach." ></td>
	<td class="line x" title="78:212	The algorithm finds again latent semantic dimensions, according to which nouns, contexts and syntactic relations are classified." ></td>
	<td class="line x" title="79:212	Since we are interested in the classification of nouns according to both bag-of-words context and syntactic context, we first construct three matrices that capture the co-occurrence frequency information for each mode." ></td>
	<td class="line x" title="80:212	The first matrix contains co-occurrence frequencies of nouns crossclassified by dependency relations, the second matrix contains co-occurrence frequencies of nouns cross-classified by words that appear in the nouns context window, and the third matrix contains cooccurrence frequencies of dependency relations cross-classified by co-occurring context words." ></td>
	<td class="line x" title="81:212	We then apply NMF to the three matrices, but we interleave the separate factorizations: the results of the former factorization are used to initialize the factorization of the next matrix." ></td>
	<td class="line x" title="82:212	This implies that we need to initialize only three matrices at random; the other three are initialized by calculations of the 931 previous step." ></td>
	<td class="line x" title="83:212	The process is represented graphically in figure 1." ></td>
	<td class="line x" title="84:212	Figure 1: A graphical representation of the extended NMF In the example in figure 1, matrix H is initialized at random, and the update of matrix W is calculated." ></td>
	<td class="line x" title="85:212	The result of update W is then used to initialize matrix V , and the update of matrix G is calculated." ></td>
	<td class="line x" title="86:212	This matrix is used again to initialize matrix U, and the update of matrix F is calculated." ></td>
	<td class="line x" title="87:212	This matrix can be used to initialize matrix H, and the process is repeated until convergence." ></td>
	<td class="line x" title="88:212	In (5), an example is given of the kind of semantic dimensions found." ></td>
	<td class="line x" title="89:212	This dimension may be coined the transport dimension, as is shown by the top 10 nouns (a), context words (b) and syntactic relations (c)." ></td>
	<td class="line x" title="90:212	(5) a. auto car, wagen car, tram tram, motor motorbike, bus bus, metro subway, automobilist driver, trein trein, stuur steering wheel, chauffeur driver b. auto car, trein train, motor motorbike, bus bus, rij drive, chauffeur driver, fiets bike, reiziger reiziger, passagier passenger, vervoer transport c. viertrapsadj four pedal, verplaats metobj move with, toeteradj honk, tank in houdobj [parsing error], tanksubj refuel, tankobj refuel, rij voorbijsubj pass by, rij voorbijadj pass by, rij afsubj drive off, peperduuradj very expensive 3.3 Sense Subtraction Next, we want to use the factorization that has been created in the former step for word sense discrimination." ></td>
	<td class="line x" title="91:212	The intuition is that we switch off one dimension of an ambiguous word, to reveal possible other senses of the word." ></td>
	<td class="line x" title="92:212	From matrix H, we know the importance of each syntactic relation given a dimension." ></td>
	<td class="line x" title="93:212	With this knowledge, we can subtract the syntactic relations that are responsible for a certain dimension from the original noun vector: v new =v orig(1 h dim) (4) Equation 4 multiplies each feature (syntactic relation) of the original noun vector (v orig) with a scaling factor, according to the load of the feature on the subtracted dimension (h dim  the vector of matrix H containing the dimension we want to subtract)." ></td>
	<td class="line x" title="94:212	1 is a vector of ones, the size ofh dim." ></td>
	<td class="line x" title="95:212	3.4 A Clustering Framework The last step is to determine which dimension(s) are responsible for a certain sense of the word." ></td>
	<td class="line x" title="96:212	In order to do so, we embed our method in a clustering approach." ></td>
	<td class="line x" title="97:212	First, a specific word is assigned to its predominant sense (i.e. the most similar cluster)." ></td>
	<td class="line x" title="98:212	Next, the dominant semantic dimension(s) for this cluster are subtracted from the word vector (equation 4), and the resulting vector is fed to the clustering algorithm again, to see if other word senses emerge." ></td>
	<td class="line x" title="99:212	The dominant semantic dimension(s) can be identified by folding in the cluster centroid into our factorization (so we get a vectorw of dimension size r), and applying a threshold to the result (in our experiments a threshold of  = .05  so dimensions responsible for > 5% of the centroid are subtracted)." ></td>
	<td class="line x" title="100:212	We used two kinds of clustering algorithms to determine our initial centroids." ></td>
	<td class="line x" title="101:212	The first algorithm is a standard K-means algorithm." ></td>
	<td class="line x" title="102:212	The second one is the CBC algorithm by Pantel and Lin (2002)." ></td>
	<td class="line x" title="103:212	The initial vectors to be clustered are adapted with pointwise mutual information (Church and Hanks, 1990)." ></td>
	<td class="line x" title="104:212	3.4.1 K-means First, a standard K-means algorithm is applied to the nouns we want to cluster." ></td>
	<td class="line x" title="105:212	This yields a hard clustering, in which each noun is assigned to exactly one (dominant) cluster." ></td>
	<td class="line x" title="106:212	In the second step, we try to determine for each noun whether it can be assigned to other, less dominant clusters." ></td>
	<td class="line x" title="107:212	First, the salient dimension(s) of the centroid to which the noun is assigned are determined." ></td>
	<td class="line x" title="108:212	We compute the centroid of the cluster by averaging the frequencies of all cluster elements except for the target element we want to reassign, and adapt the centroid with pointwise mutual information." ></td>
	<td class="line x" title="109:212	After 932 subtracting the salient dimensions from the noun vector, we check whether the vector is reassigned to another cluster centroid (i.e. whether it is more similar to a different centroid)." ></td>
	<td class="line x" title="110:212	If this is the case, (another instance of) the noun is assigned to the cluster, and we repeat the second step." ></td>
	<td class="line x" title="111:212	If there is no reassignment, we continue with the next word." ></td>
	<td class="line x" title="112:212	The target element is removed from the centroid to make sure that we only subtract the dimensions associated with the sense of the cluster." ></td>
	<td class="line x" title="113:212	Note that K-means requires to set the number of clusters beforehand, so k is a parameter to be set." ></td>
	<td class="line x" title="114:212	3.4.2 CBC The second clustering algorithm operates in a similar vein, but instead of using simple K-means, we use Pantel and Lins CBC algorithm to find the initial centroids (coined COMMITTEES)." ></td>
	<td class="line x" title="115:212	In order to find committees, the top k nouns for each noun in the database are clustered with average-link clustering." ></td>
	<td class="line x" title="116:212	The clusters are scored and sorted in such a way that preference is given to tight, representative clusters." ></td>
	<td class="line x" title="117:212	If the committees do not cover all elements sufficiently, the algorithm recursively tries to find more committees." ></td>
	<td class="line x" title="118:212	An elaborate description of the algorithm can be found in (Pantel and Lin, 2002)." ></td>
	<td class="line x" title="119:212	In the second step, we start assigning elements to committees." ></td>
	<td class="line x" title="120:212	Once an element is assigned, the salient dimensions are subtracted from the noun vector in the same way as in 3.4.1 (only do we not have to remove any target word from the centroid; committees are supposed to represent tight, unambiguous clusters)." ></td>
	<td class="line x" title="121:212	CBC attempts to find the number of committees automatically from the data, so k does not have to be set." ></td>
	<td class="line x" title="122:212	4 Examples 4.1 Sense Subtraction In what follows, we will talk about semantic dimensions as, e.g., the music dimension or the city dimension." ></td>
	<td class="line x" title="123:212	In the vast majority of the cases, the dimensions are indeed as clear-cut as the transport dimension shown above, so that the dimensions can be rightfully labeled this way." ></td>
	<td class="line x" title="124:212	Two examples are given of how the semantic dimensions that have been found can be used for word sense discrimination." ></td>
	<td class="line x" title="125:212	We will consider two ambiguous nouns: pop, which can mean pop music as well as doll, and Barcelona, which can designate either the Spanish city or the Spanish football club." ></td>
	<td class="line x" title="126:212	First, we look up the top dimensions for each noun." ></td>
	<td class="line x" title="127:212	Next, we successively subtract the dimensions dealing with a particular sense of the noun, as described in 3.3." ></td>
	<td class="line x" title="128:212	This gives us three vectors for each noun: the original vector, and two vectors with one of the dimensions eliminated." ></td>
	<td class="line x" title="129:212	For each of these vectors, the top ten similar nouns are given, in order to compare the changes brought about." ></td>
	<td class="line x" title="130:212	(6) a. pop, rock, jazz, meubilair furniture, popmuziek pop music, heks witch, speelgoed toy, kast cupboard, servies [tea] service, vraagteken question mark b. pop, meubilair furniture, speelgoed toy, kast cupboard, servies [tea] service, heks witch, vraagteken question mark sieraad jewel, sculptuur sculpture, schoen shoe c. pop, rock, jazz, popmuziek pop music, heks witch, danseres dancer, servies [tea] service, kopje cup, house house music, aap monkey Example (6) shows the top similar words for the three vectors of pop." ></td>
	<td class="line x" title="131:212	In (a), the most similar words to the original vector are shown." ></td>
	<td class="line x" title="132:212	In (b), the top dimension (the music dimension) has been subtracted from (a), and in (c), the second highest dimension (a domestic items dimension) has been subtracted from (a)." ></td>
	<td class="line x" title="133:212	The differences between the three vectors are clear: in vector (a), both senses are mixed together, with pop music and doll items interleaved." ></td>
	<td class="line x" title="134:212	In (b), no more music items are present." ></td>
	<td class="line x" title="135:212	Only items related to the doll sense are among the top similar words." ></td>
	<td class="line x" title="136:212	In (c), the music sense emerges much more clearly, with rock, jazz and popmuziek being the most similar, and a new music term (house) showing up among the top ten." ></td>
	<td class="line x" title="137:212	Admittedly, in vector (c), not all items related to the doll sense are filtered out." ></td>
	<td class="line x" title="138:212	We believe this is due to the fact that this sense cannot be adequately filtered out by one dimension (in this case, a dimension of domestic items alone), whereas it is much easier to filter out the music sense with only one music dimension." ></td>
	<td class="line x" title="139:212	We will try to remedy this in our clustering framework, in which it is possible to subtract multiple dimensions related to one sense." ></td>
	<td class="line x" title="140:212	A second example, the ambiguous proper name Barcelona, is given in (7)." ></td>
	<td class="line x" title="141:212	(7) a. Barcelona, Arsenal, Inter, Juventus, Vitesse, Milaan Milan, Madrid, Parijs Paris, Wenen Vienna, Munchen Munich b. Barcelona, Milaan Milan, Munchen Mu933 nich, Wenen Vienna, Madrid, Parijs Paris, Bonn, Praag Prague, Berlijn Berlin, Londen London c. Barcelona, Arsenal, Inter, Juventus, Vitesse, Parma, Anderlecht, PSV, Feyenoord, Ajax In (a), the two senses of Barcelona are clearly mixed up, showing cities as well as football clubs among the most similar nouns." ></td>
	<td class="line x" title="142:212	In (b), where the football dimension has been subtracted, only cities show up." ></td>
	<td class="line x" title="143:212	In (c), where the city dimension has been subtracted, only football clubs remain." ></td>
	<td class="line x" title="144:212	4.2 Clustering Output In (8), an example of our clustering algorithm with initial K-means clusters is given." ></td>
	<td class="line x" title="145:212	(8) a. werk work beeld image foto photo schilderij painting tekening drawing doek canvas installatie installation afbeelding picture sculptuur sculpture prent picture illustratie illustration handschrift manuscript grafiek print aquarel aquarelle maquette scale-model collage collage ets etching b. werk work boek book titel title roman novel boekje booklet debuut debut biografie biography bundel collection toneelstuk play bestseller bestseller kinderboek child book autobiografie autobiography novelle short story c. werk work voorziening service arbeid labour opvoeding education kinderopvang child care scholing education huisvesting housing faciliteit facility accommodatie acommodation arbeidsomstandigheid working condition The example shows three different clusters to which the noun werk work is assigned." ></td>
	<td class="line x" title="146:212	In (a), werk refers to a work of art." ></td>
	<td class="line x" title="147:212	In (b), it refers to a written work." ></td>
	<td class="line x" title="148:212	In (c), the labour sense of werk emerges." ></td>
	<td class="line x" title="149:212	5 Evaluation 5.1 Methodology The clustering results are evaluated according to Dutch EuroWordNet (Vossen and others, 1999)." ></td>
	<td class="line x" title="150:212	Precision and recall are calculated by comparing the results to EuroWordNet synsets." ></td>
	<td class="line x" title="151:212	The precision is the number of clusters found that correspond to an actual sense of the word." ></td>
	<td class="line x" title="152:212	Recall is the number of word senses in EuroWordNet that are found by the algorithm." ></td>
	<td class="line x" title="153:212	Our evaluation method is largely the same as the one used by Pantel and Lin (2002)." ></td>
	<td class="line x" title="154:212	Both precision and recall are based on wordnet similarity." ></td>
	<td class="line o" title="155:212	A number of similarity measures have been developed to calculate semantic similarity in a hierarchical wordnet." ></td>
	<td class="line pc" title="156:212	Among these measures, the most important are Wu & Palmers (Wu and Palmer, 1994), Resniks (Resnik, 1995) and Lins (Lin, 1998)." ></td>
	<td class="line x" title="157:212	In this evaluation, Wu & Palmers (1994) measure will be adopted." ></td>
	<td class="line x" title="158:212	The similarity is calculated according to the formula in (5), in which N1 and N2 are the number of is-a links from A and B to their most specific common superclass C; N3 is the number of is-a links from C to the root of the taxonomy." ></td>
	<td class="line x" title="159:212	simWu&Palmer(A,B) = 2N3N 1 +N2 + 2N3 (5) iets object wezen organisme dier zoogdier vis hond zalm Figure 2: Extract from the Dutch EuroWordNet Hierarchy For example, the most common superclass of hond dog en zalm salmon is dier animal (as can be seen on the extract from Dutch EuroWordNet in figure 2)." ></td>
	<td class="line x" title="160:212	Consequently, N1 = 2, N2 = 2, N3 = 4 and simWP(hond,zalm) = 0.67." ></td>
	<td class="line x" title="161:212	To calculate precision, we apply the same methodology as Pantel and Lin (2002).2 Let S(w) be the set of EuroWordNet senses." ></td>
	<td class="line x" title="162:212	simW(s,u), the similarity between a synset s and a word u is then defined as the maximum similarity between s and a sense of u: simW(s,u) = max tS(u) sim(s,t) (6) Let ck be the top k-members of a cluster c, where these are the k most similar members to the centroid of c. simC(c,s), the similarity between s and c, is then defined as the average similarity between s and the top-k members of c: simC(s,c) = summationdisplay uck simW(s,u) k (7) 2Note, however, that our similarity measure is different." ></td>
	<td class="line oc" title="163:212	Where Pantel and Lin use Lins (1998) measure, we use Wu and Palmers (1994) measure." ></td>
	<td class="line x" title="164:212	934 An assigment of a word w to a cluster c can now be classified as correct if max sS(w) simC(s,c) >  (8) and the EuroWordNet sense of w that corresponds to c is argmax sS(w) simC(s,c) (9) When multiple clusters correspond to the same EuroWordNet sense, only one of them is counted as correct." ></td>
	<td class="line x" title="165:212	Precision of a word w is the percentage of correct clusters to which it is assigned." ></td>
	<td class="line x" title="166:212	Recall of a word w is the percentage of senses from EuroWordnet that have a corresponding cluster.3 Precision and recall of a clustering algorithm is the average precision and recall of all test words." ></td>
	<td class="line x" title="167:212	5.2 Experimental Design We have applied the interleaved NMF presented in section 3.2 to Dutch, using the TWENTE NIEUWS CORPUS (Ordelman, 2002), containing > 500M words of Dutch newspaper text." ></td>
	<td class="line x" title="168:212	The corpus is consistently divided into paragraphs, which have been used as the context window for the bag-of-words mode." ></td>
	<td class="line x" title="169:212	The corpus has been parsed by the Dutch dependency parser Alpino (van Noord, 2006), and dependency triples have been extracted." ></td>
	<td class="line x" title="170:212	Next, the three matrices needed for our method have been constructed: one containing nouns by dependency relations (5K  80K), one containing nouns by context words (5K 2K) and one containing dependency relations by context words (80K2K)." ></td>
	<td class="line x" title="171:212	We did 200 iterations of the algorithm, factorizing the matrices into 50 dimensions." ></td>
	<td class="line x" title="172:212	The NMF algorithm has been implemented in Matlab." ></td>
	<td class="line x" title="173:212	For the evaluation, we use all the words that appear in our original clustering input as well as in EuroWordNet." ></td>
	<td class="line x" title="174:212	This yields a test set of 3683 words." ></td>
	<td class="line x" title="175:212	5.3 Results Table 1 shows precision and recall figures for four different algorithms, according to two similarity thresholds  (equation 8)." ></td>
	<td class="line x" title="176:212	kmeansnmf describes the results of our algorithm with K-means clusters, as described in section 3.4.1." ></td>
	<td class="line x" title="177:212	CBC describes 3Our notion of recall is slightly different from the one used by Pantel and Lin, as they use the number of senses in which w was used in the corpus as gold standard." ></td>
	<td class="line x" title="178:212	This information, as they acknowledge, is difficult to get at, so we prefer to use the sense information in EuroWordNet." ></td>
	<td class="line x" title="179:212	the results of our algorithm with the CBC committees, as described in section 3.4.2." ></td>
	<td class="line x" title="180:212	For comparison, we have also included the results of a standard Kmeans clustering (kmeansorig, k = 600), and the original CBC algorithm (CBCorig) as described by Pantel and Lin (2002)." ></td>
	<td class="line x" title="181:212	threshold  .40 (%) .60 (%) kmeansnmf prec." ></td>
	<td class="line x" title="182:212	78.97 55.16 rec." ></td>
	<td class="line x" title="183:212	63.90 44.77 CBCnmf prec." ></td>
	<td class="line x" title="184:212	82.70 54.87 rec." ></td>
	<td class="line x" title="185:212	60.27 40.51 kmeansorig prec." ></td>
	<td class="line x" title="186:212	86.13 58.97 rec." ></td>
	<td class="line x" title="187:212	60.23 41.80 CBCorig prec." ></td>
	<td class="line x" title="188:212	44.94 29.74 rec." ></td>
	<td class="line x" title="189:212	69.61 48.00 Table 1: Precision and recall for four different algorithms according to two similarity thresholds The results show the same tendency across all similarity thresholds: kmeansnmf has a high precision, but lower recall compared to CBCorig." ></td>
	<td class="line x" title="190:212	Still the recall is higher compared to standard K-means, which indicates that the algorithm is able to find multiple senses of nouns, with high precision." ></td>
	<td class="line x" title="191:212	The results of CBCnmf are similar to the results of kmeansorig, indicating that few words are reassigned to multiple clusters when using CBC committees with our method." ></td>
	<td class="line x" title="192:212	Obviously, kmeansorig scores best with regard to precision, but worse with regard to recall." ></td>
	<td class="line x" title="193:212	CBCorig finds most senses (highest recall), but precision is considerably worse." ></td>
	<td class="line x" title="194:212	The fact that recall is already quite high with standard K-means clustering indicates that the evaluation is skewed towards nouns with only one sense, possibly due to a lack of coverage in EuroWordNet." ></td>
	<td class="line x" title="195:212	In future work, we specifically want to evaluate the discrimination of ambiguous words." ></td>
	<td class="line x" title="196:212	Also, we want to make use of the new Cornetto Database4, a successor of EuroWordNet for Dutch which is currently under development." ></td>
	<td class="line x" title="197:212	Still, the evaluation shows that our method provides a genuine way of finding multiple senses of words, while retaining high precision." ></td>
	<td class="line x" title="198:212	Especially the method using a simple K-means clustering per4http://www.let.vu.nl/onderzoek/ projectsites/cornetto/index.html 935 forms particularly well." ></td>
	<td class="line x" title="199:212	The three way data allows the algorithm to put its finger on the particular sense of a centroid, and adapt the feature vector of a possibly ambiguous noun accordingly." ></td>
	<td class="line x" title="200:212	6 Conclusion & Future Work In this paper, an extension of NMF has been presented that combines both bag of words data and syntactic data in order to find latent semantic dimensions according to which both words and syntactic relations can be classified." ></td>
	<td class="line x" title="201:212	The use of three way data allows one to determine which dimension(s) are responsible for a certain sense of a word, and adapt the corresponding feature vector accordingly, subtracting one sense to discover another one." ></td>
	<td class="line x" title="202:212	When embedded in a clustering framework, the method provides a fully automatic way to discriminate the various senses of words." ></td>
	<td class="line x" title="203:212	The evaluation against EuroWordNet shows that the algorithm is genuinely able to disambiguate the features of a given word, and accordingly its word senses." ></td>
	<td class="line x" title="204:212	We conclude with some issues for future work." ></td>
	<td class="line x" title="205:212	First of all, we would like to test the method that has been explored in this paper with other evaluation frameworks." ></td>
	<td class="line x" title="206:212	We already mentioned the focus on ambiguous nouns, and the use of the new Cornetto database for Dutch." ></td>
	<td class="line x" title="207:212	Next, we would like to work out a proper probabilistic framework for the subtraction of dimensions." ></td>
	<td class="line x" title="208:212	At this moment, the subtraction (using a cut-off) is somewhat ad hoc." ></td>
	<td class="line x" title="209:212	A probabilistic modeling of this intuition might lead to an improvement." ></td>
	<td class="line x" title="210:212	And finally, we would like to use the results of our method to learn selectional preferences." ></td>
	<td class="line x" title="211:212	Our method is able to discriminate the syntactic features that are linked to a particular word sense." ></td>
	<td class="line x" title="212:212	If we can use the results to improve a parsers performance, this will also provide an external evaluation of the algorithm." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="D08-1007
Discriminative Learning of Selectional Preference from Unlabeled Text
Bergsma, Shane;Lin, Dekang;Goebel, Randy;"></td>
	<td class="line x" title="1:260	Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 5968, Honolulu, October 2008." ></td>
	<td class="line x" title="2:260	c2008 Association for Computational Linguistics Discriminative Learning of Selectional Preference from Unlabeled Text Shane Bergsma Department of Computing Science University of Alberta Edmonton, Alberta Canada, T6G 2E8 bergsma@cs.ualberta.ca Dekang Lin Google, Inc. 1600 Amphitheatre Parkway Mountain View California, 94301 lindek@google.com Randy Goebel Department of Computing Science University of Alberta Edmonton, Alberta Canada, T6G 2E8 goebel@cs.ualberta.ca Abstract We present a discriminative method for learning selectional preferences from unlabeled text." ></td>
	<td class="line x" title="3:260	Positive examples are taken from observed predicate-argument pairs, while negatives are constructed from unobserved combinations." ></td>
	<td class="line x" title="4:260	We train a Support Vector Machine classifier to distinguish the positive from the negative instances." ></td>
	<td class="line x" title="5:260	We show how to partition the examples for efficient training with 57 thousand features and 6.5 million training instances." ></td>
	<td class="line x" title="6:260	The model outperforms other recent approaches, achieving excellent correlation with human plausibility judgments." ></td>
	<td class="line x" title="7:260	Compared to Mutual Information, it identifies 66% more verb-object pairs in unseen text, and resolves 37% more pronouns correctly in a pronoun resolution experiment." ></td>
	<td class="line x" title="8:260	1 Introduction Selectional preferences (SPs) tell us which arguments are plausible for a particular predicate." ></td>
	<td class="line x" title="9:260	For example, Table 2 (Section 4.4) lists plausible and implausible direct objects (arguments) for particular verbs (predicates)." ></td>
	<td class="line x" title="10:260	SPs can help resolve syntactic, word sense, and reference ambiguity (Clark and Weir, 2002), and so gathering them has received a lot of attention in the NLP community." ></td>
	<td class="line x" title="11:260	One way to determine SPs is from co-occurrences of predicates and arguments in text." ></td>
	<td class="line x" title="12:260	Unfortunately, no matter how much text we use, many acceptable pairs will be missing." ></td>
	<td class="line x" title="13:260	Bikel (2004) found that only 1.49% of the bilexical dependencies considered by Collins parser during decoding were observed during training." ></td>
	<td class="line x" title="14:260	In our parsed corpus (Section 4.1), for example, we find eat with nachos, burritos, and tacos, but not with the equally tasty quesadillas, chimichangas, or tostadas." ></td>
	<td class="line x" title="15:260	Rather than solely relying on co-occurrence counts, we would like to use them to generalize to unseen pairs." ></td>
	<td class="line x" title="16:260	In particular, we would like to exploit a number of arbitrary and potentially overlapping properties of predicates and arguments when we assign SPs." ></td>
	<td class="line x" title="17:260	We do this by representing these properties as features in a linear classifier, and training the weights using discriminative learning." ></td>
	<td class="line x" title="18:260	Positive examples are taken from observed predicate-argument pairs, while pseudo-negatives are constructed from unobserved combinations." ></td>
	<td class="line x" title="19:260	We train a Support Vector Machine (SVM) classifier to distinguish the positives from the negatives." ></td>
	<td class="line x" title="20:260	We refer to our models scores as Discriminative Selectional Preference (DSP)." ></td>
	<td class="line x" title="21:260	By creating training vectors automatically, DSP enjoys all the advantages of supervised learning, but without the need for manual annotation of examples." ></td>
	<td class="line x" title="22:260	We evaluate DSP on the task of assigning verbobject selectional preference." ></td>
	<td class="line x" title="23:260	We encode a nouns textual distribution as feature information." ></td>
	<td class="line x" title="24:260	The learned feature weights are linguistically interesting, yielding high-quality similar-word lists as latent information." ></td>
	<td class="line x" title="25:260	Despite its representational power, DSP scales to real-world data sizes: examples are partitioned by predicate, and a separate SVM is trained for each partition." ></td>
	<td class="line x" title="26:260	This allows us to efficiently learn with over 57 thousand features and 6.5 million examples." ></td>
	<td class="line x" title="27:260	DSP outperforms recently proposed alternatives in a range of experiments, and better correlates with human plausibility judgments." ></td>
	<td class="line x" title="28:260	It also shows strong gains over a Mutual Information-based co59 occurrence model on two tasks: identifying objects of verbs in an unseen corpus and finding pronominal antecedents in coreference data." ></td>
	<td class="line x" title="29:260	2 Related Work Most approaches to SPs generalize from observed predicate-argument pairs to semantically similar ones by modeling the semantic class of the argument, following Resnik (1996)." ></td>
	<td class="line x" title="30:260	For example, we might have a class Mexican Food and learn that the entire class is suitable for eating." ></td>
	<td class="line x" title="31:260	Usually, the classes are from WordNet (Miller et al., 1990), although they can also be inferred from clustering (Rooth et al., 1999)." ></td>
	<td class="line x" title="32:260	Brockmann and Lapata (2003) compare a number of WordNet-based approaches, including Resnik (1996), Li and Abe (1998), and Clark and Weir (2002), and found that the more sophisticated class-based approaches do not always outperform simple frequency-based models." ></td>
	<td class="line x" title="33:260	Another line of research generalizes using similar words." ></td>
	<td class="line x" title="34:260	Suppose we are calculating the probability of a particular noun, n, occurring as the object argument of a given verbal predicate, v. Let Pr(n|v) be the empirical maximum-likelihood estimate from observed text." ></td>
	<td class="line x" title="35:260	Dagan et al.(1999) define the similarity-weighted probability, PrSIM, to be: PrSIM(n|v) = summationdisplay vSIMS(v) Sim(v,v)Pr(n|v) (1) where Sim(v,v) returns a real-valued similarity between two verbs v and v (normalized over all pair similarities in the sum)." ></td>
	<td class="line x" title="37:260	In contrast, Erk (2007) generalizes by substituting similar arguments, while Wang et al.(2005) use the cross-product of similar pairs." ></td>
	<td class="line x" title="39:260	One key issue is how to define the set of similar words, SIMS(w)." ></td>
	<td class="line pc" title="40:260	Erk (2007) compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and Lin (1998a)s information-theoretic metric work best." ></td>
	<td class="line x" title="41:260	Similarity-smoothed models are simple to compute, potentially adaptable to new domains, and require no manually-compiled resources such as WordNet." ></td>
	<td class="line x" title="42:260	Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules (Pantel et al., 2007; Roberto et al., 2007)." ></td>
	<td class="line x" title="43:260	Inferences such as [X wins Y]  [X plays Y] are only valid for certain arguments X and Y. We follow Pantel et al.(2007) in using automatically-extracted semantic classes to help characterize plausible arguments." ></td>
	<td class="line x" title="45:260	Discriminative techniques are widely used in NLP and have been applied to the related tasks of word prediction and language modeling." ></td>
	<td class="line x" title="46:260	Even-Zohar and Roth (2000) use a classifier to predict the most likely word to fill a position in a sentence (in their experiments: a verb) from a set of candidates (sets of verbs), by inspecting the context of the target token (e.g., the presence or absence of a particular nearby word in the sentence)." ></td>
	<td class="line x" title="47:260	This approach can therefore learn which specific arguments occur with a particular predicate." ></td>
	<td class="line x" title="48:260	In comparison, our features are second-order: we learn what kinds of arguments occur with a predicate by encoding features of the arguments." ></td>
	<td class="line x" title="49:260	Recent distributed and latentvariable models also represent words with feature vectors (Bengio et al., 2003; Blitzer et al., 2005)." ></td>
	<td class="line x" title="50:260	Many of these approaches learn both the feature weights and the feature representation." ></td>
	<td class="line x" title="51:260	Vectors must be kept low-dimensional for tractability, while learning and inference on larger scales is impractical." ></td>
	<td class="line x" title="52:260	By partitioning our examples by predicate, we can efficiently use high-dimensional, sparse vectors." ></td>
	<td class="line x" title="53:260	Our technique of generating negative examples is similar to the approach of Okanohara and Tsujii (2007)." ></td>
	<td class="line x" title="54:260	They learn a classifier to disambiguate actual sentences from pseudo-negative examples sampled from an N-gram language model." ></td>
	<td class="line x" title="55:260	Smith and Eisner (2005) also automatically generate negative examples." ></td>
	<td class="line x" title="56:260	They perturb their input sequence (e.g. the sentence word order) to create a neighborhood of implicit negative evidence." ></td>
	<td class="line x" title="57:260	We create negatives by substitution rather than perturbation, and use corpuswide statistics to choose our negative instances." ></td>
	<td class="line x" title="58:260	3 Methodology 3.1 Creating Examples To learn a discriminative model of selectional preference, we create positive and negative training examples automatically from raw text." ></td>
	<td class="line x" title="59:260	To create the positives, we automatically parse a large corpus, and then extract the predicate-argument pairs that have a statistical association in this data." ></td>
	<td class="line x" title="60:260	We measure this association using pointwise Mutual Information (MI) (Church and Hanks, 1990)." ></td>
	<td class="line x" title="61:260	The MI between a 60 verb predicate, v, and its object argument, n, is: MI(v,n) = log Pr(v,n)Pr(v)Pr(n) = log Pr(n|v)Pr(n) (2) If MI>0, the probability v and n occur together is greater than if they were independently distributed." ></td>
	<td class="line x" title="62:260	We create sets of positive and negative examples separately for each predicate, v. First, we extract all pairs where MI(v,n)> as positives." ></td>
	<td class="line x" title="63:260	For each positive, we create pseudo-negative examples, (v,n), by pairing v with a new argument, n, that either has MI below the threshold or did not occur with v in the corpus." ></td>
	<td class="line x" title="64:260	We require each negative n to have a similar frequency to its corresponding n. This prevents our learning algorithm from focusing on any accidental frequency-based bias." ></td>
	<td class="line x" title="65:260	We mix in K negatives for each positive, sampling without replacement to create all the negatives for a particular predicate." ></td>
	<td class="line x" title="66:260	For each v, 1K+1 of its examples will be positive." ></td>
	<td class="line x" title="67:260	The threshold  represents a trade-off between capturing a large number of positive pairs and ensuring these pairs have good association." ></td>
	<td class="line x" title="68:260	Similarly, K is a tradeoff between the number of examples and the computational efficiency." ></td>
	<td class="line x" title="69:260	Ultimately, these parameters should be optimized for task performance." ></td>
	<td class="line x" title="70:260	Of course, some negatives will actually be plausible arguments that were unobserved due to sparseness." ></td>
	<td class="line x" title="71:260	Fortunately, modern discriminative methods like soft-margin SVMs can learn in the face of label error by allowing slack, subject to a tunable regularization penalty (Cortes and Vapnik, 1995)." ></td>
	<td class="line x" title="72:260	If MI is a sparse and imperfect model of SP, what can DSP gain by training on MIs scores?" ></td>
	<td class="line x" title="73:260	We can regard DSP as learning a view of SP that is orthogonal to MI, in a co-training sense (Blum and Mitchell, 1998)." ></td>
	<td class="line x" title="74:260	MI labels the data based solely on co-occurrence; DSP uses these labels to identify other regularities  ones that extend beyond cooccurring words." ></td>
	<td class="line x" title="75:260	For example, many instances of n where MI(eat,n)> also have MI(buy,n)> and MI(cook,n)>." ></td>
	<td class="line x" title="76:260	Also, compared to other nouns, a disproportionate number of eat-nouns are lowercase, single-token words, and they rarely contain digits, hyphens, or begin with a human first name like Bob." ></td>
	<td class="line x" title="77:260	DSP encodes these interdependent properties as features in a linear classifier." ></td>
	<td class="line x" title="78:260	This classifier can score any noun as a plausible argument of eat if indicative features are present; MI can only assign high plausibility to observed (eat,n) pairs." ></td>
	<td class="line x" title="79:260	Similarity-smoothed models can make use of the regularities across similar verbs, but not the finergrained stringand token-based features." ></td>
	<td class="line x" title="80:260	Our training examples are similar to the data created for pseudodisambiguation, the usual evaluation task for SP models (Erk, 2007; Keller and Lapata, 2003; Rooth et al., 1999)." ></td>
	<td class="line x" title="81:260	This data consists of triples (v,n,n) where v,n is a predicateargument pair observed in the corpus and v,n has not been observed." ></td>
	<td class="line x" title="82:260	The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones." ></td>
	<td class="line x" title="83:260	We refer to this as Pairwise Disambiguation." ></td>
	<td class="line x" title="84:260	Unlike this task, we classify each predicate-argument pair independently as plausible/implausible." ></td>
	<td class="line x" title="85:260	We also use MI rather than frequency to define the positive pairs, ensuring that the positive pairs truly have a statistical association, and are not simply the result of parser error or noise.1 3.2 Partitioning for Efficient Training After creating our positive and negative training pairs, we must select a feature representation for our examples." ></td>
	<td class="line x" title="86:260	Let  be a mapping from a predicateargument pair (v,n) to a feature vector,  : (v,n)  1k." ></td>
	<td class="line x" title="87:260	Predictions are made based on a weighted combination of the features, y = (v,n), where  is our learned weight vector." ></td>
	<td class="line x" title="88:260	We can make training significantly more efficient by using a special form of attribute-value features." ></td>
	<td class="line x" title="89:260	Let every feature i be of the form i(v,n) = v = vf(n)." ></td>
	<td class="line x" title="90:260	That is, every feature is an intersection of the occurrence of a particular predicate, v, and some feature of the argument f(n)." ></td>
	<td class="line x" title="91:260	For example, a feature for a verb-object pair might be, the verb is eat and the object is lower-case. In this representation, features for one predicate will be completely independent from those for every other predicate." ></td>
	<td class="line x" title="92:260	Thus rather than a single training procedure, we can actually partition the examples by predicate, and train a 1For a fixed verb, MI is proportional to Keller and Lapata (2003)s conditional probability scores for pseudodisambiguation of (v,n,n) triples: Pr(v|n) = Pr(v,n)/Pr(n), which was shown to be a better measure of association than co-occurrence frequency f(v,n)." ></td>
	<td class="line x" title="93:260	Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs." ></td>
	<td class="line x" title="94:260	MI was also recently used for inference-rule SPs by Pantel et al.(2007)." ></td>
	<td class="line x" title="96:260	61 classifier for each predicate independently." ></td>
	<td class="line x" title="97:260	The prediction becomes yv = v v(n), where v are the learned weights corresponding to predicate v and all features v(n)=f(n) depend on the argument only." ></td>
	<td class="line x" title="98:260	Some predicate partitions may have insufficient examples for training." ></td>
	<td class="line x" title="99:260	Also, a predicate may occur in test data that was unseen during training." ></td>
	<td class="line x" title="100:260	To handle these instances, we decided to cluster lowfrequency predicates." ></td>
	<td class="line x" title="101:260	In our experiments assigning SP to verb-object pairs, we cluster all verbs that have less than 250 positive examples, using clusters generated by the CBC algorithm (Pantel and Lin, 2002)." ></td>
	<td class="line x" title="102:260	For example, the low-frequency verbs incarcerate, parole, and court-martial are all mapped to the same partition, while more-frequent verbs like arrest and execute each have their own partition." ></td>
	<td class="line x" title="103:260	About 5.5% of examples are clustered, corresponding to 30% of the 7367 total verbs." ></td>
	<td class="line x" title="104:260	40% of verbs (but only 0.6% of examples) were not in any CBC cluster; these were mapped to a single backoff partition." ></td>
	<td class="line x" title="105:260	The parameters for each partition, v, can be trained with any supervised learning technique." ></td>
	<td class="line x" title="106:260	We use SVM (Section 4.1) because it is effective in similar high-dimensional, sparse-vector settings, and has an efficient implementation (Joachims, 1999)." ></td>
	<td class="line x" title="107:260	In SVM, the sign of yv gives the classification." ></td>
	<td class="line x" title="108:260	We can also use the scalar yv as our DSP score (i.e. the positive distance from the separating SVM hyperplane)." ></td>
	<td class="line x" title="109:260	3.3 Features This section details our argument features, f(n), for assigning verb-object selectional preference." ></td>
	<td class="line x" title="110:260	For a verb predicate (or partition) v and object argument n, the form of our classifier is yv =summationtexti vifi(n)." ></td>
	<td class="line x" title="111:260	3.3.1 Verb co-occurrence We provide features for the empirical probability of the noun occurring as the object argument of other verbs, Pr(n|v)." ></td>
	<td class="line x" title="112:260	If we were to only use these features (indexing the feature weights by each verb v), the form of our classifier would be: yv = summationdisplay v vvPr(n|v) (3) Note the similarity between Equation (3) and Equation (1)." ></td>
	<td class="line x" title="113:260	Now the feature weights, vv, take the role of the similarity function, Sim(v,v)." ></td>
	<td class="line x" title="114:260	Unlike Equation (1), however, these weights are not set by an external similarity algorithm, but are optimized to discriminate the positive and negative training examples." ></td>
	<td class="line x" title="115:260	We need not restrict ourselves to a short list of similar verbs; we include Probj(n|v) features for every verb that occurs more than 10 times in our corpus." ></td>
	<td class="line x" title="116:260	vv may be positive or negative, depending on the relation between v and v. We also include features for the probability of the noun occurring as the subject of other verbs, Prsubj(n|v)." ></td>
	<td class="line x" title="117:260	For example, nouns that can be the object of eat will also occur as the subject of taste and contain." ></td>
	<td class="line x" title="118:260	Other contexts, such as adjectival and nominal predicates, could also aid the prediction, but have not yet been investigated." ></td>
	<td class="line x" title="119:260	The advantage of tuning similarity to the application of interest has been shown previously by Weeds and Weir (2005)." ></td>
	<td class="line x" title="120:260	They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation." ></td>
	<td class="line x" title="121:260	Our approach, on the other hand, discriminatively sets millions of individual similarity values." ></td>
	<td class="line x" title="122:260	Like Weeds and Weir (2005), our similarity values are asymmetric." ></td>
	<td class="line x" title="123:260	3.3.2 String-based We include several simple character-based features of the noun string: the number of tokens, the case, and whether it contains digits, hyphens, an apostrophe, or other punctuation." ></td>
	<td class="line x" title="124:260	We also include a feature for the first and last token, and fire indicator features if any token in the noun occurs on in-house lists of given names, family names, cities, provinces, countries, corporations, languages, etc. We also fire a feature if a token is a corporate designation (like inc. or ltd.) or a human one (like Mr. or Sheik)." ></td>
	<td class="line x" title="125:260	3.3.3 Semantic classes Motivated by previous SP models that make use of semantic classes, we generated word clusters using CBC (Pantel and Lin, 2002) on a 10 GB corpus, giving 3620 clusters." ></td>
	<td class="line x" title="126:260	If a noun belongs in a cluster, a corresponding feature fires." ></td>
	<td class="line x" title="127:260	If a noun is in none of the clusters, a no-class feature fires." ></td>
	<td class="line x" title="128:260	As an example, CBC cluster 1891 contains: sidewalk, driveway, roadway, footpath, bridge, highway, road, runway, street, alley, path, Interstate, . . ." ></td>
	<td class="line x" title="129:260	In our training data, we have examples like widen highway, widen road and widen motorway." ></td>
	<td class="line x" title="130:260	If we 62 see that we can widen a highway, we learn that we can also widen a sidewalk, bridge, runway, etc. We also made use of the person-name/instance pairs automatically extracted by Fleischman et al.(2003).2 This data provides counts for pairs such as Edwin Moses, hurdler and William Farley, industrialist. We have features for all concepts and therefore learn their association with each verb." ></td>
	<td class="line oc" title="132:260	4 Experiments and Results 4.1 Set up We parsed the 3 GB AQUAINT corpus (Voorhees, 2002) using Minipar (Lin, 1998b), and collected verb-object and verb-subject frequencies, building an empirical MI model from this data." ></td>
	<td class="line x" title="133:260	Verbs and nouns were converted to their (possibly multi-token) root, and string case was preserved." ></td>
	<td class="line x" title="134:260	Passive subjects (the car was bought) were converted to objects (bought car)." ></td>
	<td class="line x" title="135:260	We set the MI-threshold, , to be 0, and the negative-to-positive ratio, K, to be 2." ></td>
	<td class="line x" title="136:260	Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times (Erk, 2007; Keller and Lapata, 2003; Rooth et al., 1999)." ></td>
	<td class="line x" title="137:260	Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness." ></td>
	<td class="line x" title="138:260	We wish to use our model on arguments of any frequency, including those that never occurred in the training corpus (and therefore have empty cooccurrence features (Section 3.3.1))." ></td>
	<td class="line x" title="139:260	We proceed as follows: first, we exclude pairs whenever the noun occurs less than 3 times in our corpus, removing many misspellings and other noun noise." ></td>
	<td class="line x" title="140:260	Next, we omit verb co-occurrence features for nouns that occur less than 10 times, and instead fire a low-count feature." ></td>
	<td class="line x" title="141:260	When we move to a new corpus, previouslyunseen nouns are treated like these low-count training nouns." ></td>
	<td class="line x" title="142:260	This processing results in a set of 6.8 million pairs, divided into 2318 partitions (192 of which are verb clusters (Section 3.2))." ></td>
	<td class="line x" title="143:260	For each partition, we take 95% of the examples for training, 2.5% for development and 2.5% for a final unseen test set." ></td>
	<td class="line x" title="144:260	We provide full results for two models: DSPcooc which only uses the verb co-occurrence features, and DSPall which uses all the features men2Available at http://www.mit.edu/mbf/instances.txt.gz tioned in Section 3.3." ></td>
	<td class="line x" title="145:260	Feature values are normalized within each feature type." ></td>
	<td class="line x" title="146:260	We train our (linear kernel) discriminative models using SVMlight (Joachims, 1999) on each partition, but set meta-parameters C (regularization) and j (cost of positive vs. negative misclassifications: max at j=2) on the macroaveraged score across all development partitions." ></td>
	<td class="line x" title="147:260	Note that we can not use the development set to optimize  and K because the development examples are obtained after setting these values." ></td>
	<td class="line x" title="148:260	4.2 Feature weights It is interesting to inspect the feature weights returned by our system." ></td>
	<td class="line x" title="149:260	In particular, the weights on the verb co-occurrence features (Section 3.3.1) provide a high-quality, argument-specific similarityranking of other verb contexts." ></td>
	<td class="line x" title="150:260	The DSP parameters for eat, for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish)." ></td>
	<td class="line oc" title="151:260	Lin (1998a)s similar word list for eat misses these but includes sleep (ranked 6) and sit (ranked 14), because these have similar subjects to eat." ></td>
	<td class="line nc" title="152:260	Discriminative, context-specific training seems to yield a better set of similar predicates, e.g. the highest-ranked contexts for DSPcooc on the verb join,3 lead 1.42, rejoin 1.39, form 1.34, belong to 1.31, found 1.31, quit 1.29, guide 1.19, induct 1.19, launch (subj) 1.18, work at 1.14 give a better SIMS(join) for Equation (1) than the top similarities returned by (Lin, 1998a): participate 0.164, lead 0.150, return to 0.148, say 0.143, rejoin 0.142, sign 0.142, meet 0.142, include 0.141, leave 0.140, work 0.137 Other features are also weighted intuitively." ></td>
	<td class="line x" title="153:260	Note that case is a strong indicator for some arguments, for example the weight on being lower-case is high for become (0.972) and eat (0.505), but highly negative for accuse (-0.675) and embroil (-0.573) which often take names of people and organizations." ></td>
	<td class="line x" title="154:260	4.3 Pseudodisambiguation We first evaluate DSP on disambiguating positives from pseudo-negatives, comparing to recently3Which all correspond to nouns occurring in the object position of the verb (e.g. Probj(n|lead)), except launch (subj) which corresponds to Prsubj(n|launch)." ></td>
	<td class="line x" title="155:260	63 System MacroAvg MicroAvg PairwiseP R F P R F Acc Cov Dagan et al.(1999) 0.36 0.90 0.51 0.68 0.92 0.78 0.58 0.98 Erk (2007) 0.49 0.66 0.56 0.70 0.82 0.76 0.72 0.83 Keller and Lapata (2003) 0.72 0.34 0.46 0.80 0.50 0.62 0.80 0.57 DSPcooc 0.53 0.72 0.61 0.73 0.94 0.82 0.77 1.00 DSPall 0.60 0.71 0.65 0.77 0.90 0.83 0.81 1.00 Table 1: Pseudodisambiguation results averaged across each example (MacroAvg), weighted by word frequency (MicroAvg), plus coverage and accuracy of pairwise competition (Pairwise)." ></td>
	<td class="line x" title="157:260	proposed systems that also require no manuallycompiled resources like WordNet." ></td>
	<td class="line x" title="158:260	We convert Dagan et al.(1999)s similarity-smoothed probability to MI by replacing the empirical Pr(n|v) in Equation (2) with the smoothed PrSIM from Equation (1)." ></td>
	<td class="line oc" title="160:260	We also test an MI model inspired by Erk (2007): MISIM(n,v) = log summationdisplay nSIMS(n) Sim(n,n) Pr(v,n ) Pr(v)Pr(n) We gather similar words using Lin (1998a), mining similar verbs from a comparable-sized parsed corpus, and collecting similar nouns from a broader 10 GB corpus of English text.4 We also use Keller and Lapata (2003)s approach to obtaining web-counts." ></td>
	<td class="line x" title="161:260	Rather than mining parse trees, this technique retrieves counts for the pattern V Det N in raw online text, where V is any inflection of the verb, Det is the, a, or the empty string, and N is the singular or plural form of the noun." ></td>
	<td class="line x" title="162:260	We compute a web-based MI by collecting Pr(n,v), Pr(n), and Pr(v) using all inflections, except we only use the root form of the noun." ></td>
	<td class="line x" title="163:260	Rather than using a search engine, we obtain counts from the Google Web 5-gram Corpus.5 All systems are thresholded at zero to make a classification." ></td>
	<td class="line x" title="164:260	Unlike DSP, the comparison systems may 4For both the similar-noun and similar-verb smoothing, we only smooth over similar pairs that occurred in the corpus." ></td>
	<td class="line x" title="165:260	While averaging over all similar pairs tends to underestimate the probability, averaging over only the observed pairs tends to overestimate it." ></td>
	<td class="line x" title="166:260	We tested both and adopt the latter because it resulted in better performance on our development set." ></td>
	<td class="line x" title="167:260	5Available from the LDC as LDC2006T13." ></td>
	<td class="line x" title="168:260	This collection was generated from approximately 1 trillion tokens of online text." ></td>
	<td class="line x" title="169:260	Unfortunately, tokens appearing less than 200 times have been mapped to the UNK symbol, and only N-grams appearing more than 40 times are included." ></td>
	<td class="line x" title="170:260	Unlike results from search engines, however, experiments with this corpus are replicable." ></td>
	<td class="line x" title="171:260	not be able to provide a score for each example." ></td>
	<td class="line x" title="172:260	The similarity-smoothed examples will be undefined if SIMS(w) is empty." ></td>
	<td class="line x" title="173:260	Also, the Keller and Lapata (2003) approach will be undefined if the pair is unobserved on the web." ></td>
	<td class="line x" title="174:260	As a reasonable default for these cases, we assign them a negative decision." ></td>
	<td class="line x" title="175:260	We evaluate disambiguation using precision (P), recall (R), and their harmonic mean, F-Score (F)." ></td>
	<td class="line x" title="176:260	Table 1 gives the results of our comparison." ></td>
	<td class="line x" title="177:260	In the MacroAvg results, we weight each example equally." ></td>
	<td class="line x" title="178:260	For MicroAvg, we weight each example by the frequency of the noun." ></td>
	<td class="line x" title="179:260	To more directly compare with previous work, we also reproduced Pairwise Disambiguation by randomly pairing each positive with one of the negatives and then evaluating each system by the percentage it ranks correctly (Acc)." ></td>
	<td class="line x" title="180:260	For the comparison approaches, if one score is undefined, we choose the other one." ></td>
	<td class="line x" title="181:260	If both are undefined, we abstain from a decision." ></td>
	<td class="line x" title="182:260	Coverage (Cov) is the percent of pairs where a decision was made.6 Our simple system with only verb co-occurrence features, DSPcooc, outperforms all comparison approaches." ></td>
	<td class="line x" title="183:260	Using the richer feature set in DSPall results in a statistically significant gain in performance, up to an F-Score of 0.65 and a pairwise disambiguation accuracy of 0.81.7 DSPall has both broader coverage and better accuracy than all competing approaches." ></td>
	<td class="line x" title="184:260	In the remainder of the experiments, we use DSPall and refer to it simply as DSP." ></td>
	<td class="line x" title="185:260	Some errors are because of plausible but unseen arguments being used as test-set pseudo-negatives." ></td>
	<td class="line x" title="186:260	For example, for the verb damage, DSPs three most high-scoring false positives are the nouns jetliner, carpet, and gear." ></td>
	<td class="line x" title="187:260	While none occur with damage in 6I.e. we use the half coverage condition from Erk (2007)." ></td>
	<td class="line x" title="188:260	7The differences between DSPall and all comparison systems are statistically significant (McNemars test, p<0.01)." ></td>
	<td class="line x" title="189:260	64  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  10  100  1000  10000  100000  1e+06 F-Score Noun Frequency DSPall Erk (2007) Keller and Lapata (2003) Figure 1: Disambiguation results by noun frequency." ></td>
	<td class="line x" title="190:260	our corpus, all intuitively satisfy the verbs SPs." ></td>
	<td class="line x" title="191:260	MacroAvg performance is worse than MicroAvg because all systems perform better on frequent nouns." ></td>
	<td class="line x" title="192:260	When we plot F-Score by noun frequency (Figure 1), we see that DSP outperforms comparison approaches across all frequencies, but achieves its biggest gains on the low-frequency nouns." ></td>
	<td class="line x" title="193:260	A richer feature set allows DSP to make correct inferences on examples that provide minimal co-occurrence data." ></td>
	<td class="line x" title="194:260	These are also the examples for which we would expect co-occurrence models like MI to fail." ></td>
	<td class="line x" title="195:260	As a further experiment, we re-trained DSP but with only the string-based features removed." ></td>
	<td class="line x" title="196:260	Overall macro-averaged F-score dropped from 0.65 to 0.64 (a statistically significant reduction in performance)." ></td>
	<td class="line x" title="197:260	The system scored nearly identically to DSP on the high-frequency nouns, but performed roughly 15% worse on the nouns that occurred less than ten times." ></td>
	<td class="line x" title="198:260	This shows that the string-based features are important for selectional preference, and particularly helpful for low-frequency nouns." ></td>
	<td class="line x" title="199:260	4.4 Human Plausibility Table 2 compares some of our systems on data used by Resnik (1996) (also Appendix 2 in Holmes et al.(1989))." ></td>
	<td class="line x" title="201:260	The plausibility of these pairs was initially judged based on the experimenters intuitions, and later confirmed in a human experiment." ></td>
	<td class="line x" title="202:260	We include the scores of Resniks system, and note that its errors were attributed to sense ambiguity and other limitations of class-based approaches (Resnik, 1996).8 8For example, warn-engine scores highly because engines are in the class entity, and physical entities (e.g. people) are often objects of warn." ></td>
	<td class="line x" title="203:260	Unlike DSP, Resniks approach cannot learn that for warn, the property of being a person is more Seen Criteria Unseen Verb-Object Freq.All = 1 = 2 = 3 > 3 MI > 0 0.44 0.33 0.57 0.70 0.82 Freq." ></td>
	<td class="line x" title="204:260	> 0 0.57 0.45 0.76 0.89 0.96 DSP > 0 0.73 0.69 0.80 0.85 0.88 Table 3: Recall on identification of Verb-Object pairs from an unseen corpus (divided by pair frequency)." ></td>
	<td class="line x" title="205:260	The other comparison approaches also make a number of mistakes, which can often be traced to a misguided choice of similar word to smooth with." ></td>
	<td class="line x" title="206:260	We also compare to our empirical MI model, trained on our parsed corpus." ></td>
	<td class="line x" title="207:260	Although Resnik (1996) reported that 10 of the 16 plausible pairs did not occur in his training corpus, all of them occurred in ours and hence MI gives very reasonable scores on the plausible objects." ></td>
	<td class="line x" title="208:260	It has no statistics, however, for many of the implausible ones." ></td>
	<td class="line x" title="209:260	DSP can make finer decisions than MI, recognizing that warning an engine is more absurd than judging a climate. 4.5 Unseen Verb-Object Identification We next compare MI and DSP on a much larger set of plausible examples, and also test how well the models generalize across data sets." ></td>
	<td class="line x" title="210:260	We took the MI and DSP systems trained on AQUAINT and asked them to rate observed (and thus likely plausible) verb-object pairs taken from an unseen corpus." ></td>
	<td class="line x" title="211:260	We extracted the pairs by parsing the San Jose Mercury News (SJM) section of the TIPSTER corpus (Harman, 1992)." ></td>
	<td class="line x" title="212:260	Each unique verb-object pair is a single instance in this evaluation." ></td>
	<td class="line x" title="213:260	Table 3 gives recall across all pairs (All) and grouped by pair-frequency in the unseen corpus (1, 2, 3, >3)." ></td>
	<td class="line x" title="214:260	DSP accepts far more pairs than MI (73% vs. 44%), even far more than a system that accepts any previously observed verb-object combination as plausible (57%)." ></td>
	<td class="line x" title="215:260	Recall is higher on more frequent verb-object pairs, but 70% of the pairs occurred only once in the corpus." ></td>
	<td class="line x" title="216:260	Even if we smooth MI by smoothing Pr(n|v) in Equation 2 using modified KN-smoothing (Chen and Goodman, 1998), the recall of MI>0 on SJM only increases from 44.1% to 44.9%, still far below DSP." ></td>
	<td class="line x" title="217:260	Frequency-based models have fundamentally low coverage." ></td>
	<td class="line x" title="218:260	As furimportant than the property of being an entity (Resnik, 1996)." ></td>
	<td class="line x" title="219:260	65 Verb Plaus./Implaus." ></td>
	<td class="line x" title="220:260	Resnik Dagan et al. Erk MI DSP see friend/method 5.79/-0.01 0.20/1.40* 0.46/-0.07 1.11/-0.57 0.98/0.02 read article/fashion 6.80/-0.20 3.00/0.11 3.80/1.90 4.00/ 2.12/-0.65 find label/fever 1.10/0.22 1.50/2.20* 0.59/0.01 0.42/0.07 1.61/0.81 hear story/issue 1.89/1.89* 0.66/1.50* 2.00/2.60* 2.99/-1.03 1.66/0.67 write letter/market 7.26/0.00 2.50/-0.43 3.60/-0.24 5.06/-4.12 3.08/-1.31 urge daughter/contrast 1.14/1.86* 0.14/1.60* 1.10/3.60* -0.95/ -0.34/-0.62 warn driver/engine 4.73/3.61 1.20/0.05 2.30/0.62 2.87/ 2.00/-0.99 judge contest/climate 1.30/0.28 1.50/1.90* 1.70/1.70* 3.90/ 1.00/0.51 teach language/distance 1.87/1.86 2.50/1.30 3.60/2.70 3.53/ 1.86/0.19 show sample/travel 1.44/0.41 1.60/0.14 0.40/-0.82 0.53/-0.49 1.00/-0.83 expect visit/mouth 0.59/5.93* 1.40/1.50* 1.40/0.37 1.05/-0.65 1.44/-0.15 answer request/tragedy 4.49/3.88 2.70/1.50 3.10/-0.64 2.93/ 1.00/0.01 recognize author/pocket 0.50/0.50* 0.03/0.37* 0.77/1.30* 0.48/ 1.00/0.00 repeat comment/journal 1.23/1.23* 2.30/1.40 2.90/ 2.59/ 1.00/-0.48 understand concept/session 1.52/1.51 2.70/0.25 2.00/-0.28 3.96/ 2.23/-0.46 remember reply/smoke 1.31/0.20 2.10/1.20 0.54/2.60* 1.13/-0.06 1.00/-0.42 Table 2: Selectional ratings for plausible/implausible direct objects (Holmes et al., 1989)." ></td>
	<td class="line x" title="221:260	Mistakes are marked with an asterisk (*), undefined scores are marked with a dash ()." ></td>
	<td class="line x" title="222:260	Only DSP is completely defined and completely correct." ></td>
	<td class="line x" title="223:260	0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0  0.2  0.4  0.6  0.8  1 Interpolated Precision Recall DSP>T MI>T DSP>0 MI>0 Figure 2: Pronoun resolution precision-recall on MUC." ></td>
	<td class="line x" title="224:260	ther evidence, if we build a model of MI on the SJM corpus and use it in our pseudodisambiguation experiment (Section 4.3), MI>0 gets a MacroAvg precision of 86% but a MacroAvg recall of only 12%.9 4.6 Pronoun Resolution Finally, we evaluate DSP on a common application of selectional preferences: choosing the correct antecedent for pronouns in text (Dagan and Itai, 1990; Kehler et al., 2004)." ></td>
	<td class="line x" title="225:260	We study the cases where a 9Recall that even the Keller and Lapata (2003) system, built on the worlds largest corpus, achieves only 34% recall (Table 1) (with only 48% of positives and 27% of all pairs previously observed, but see Footnote 5)." ></td>
	<td class="line x" title="226:260	pronoun is the direct object of a verb predicate, v. A pronouns antecedent must obey vs selectional preferences." ></td>
	<td class="line x" title="227:260	If we have a better model of SP, we should be able to better select pronoun antecedents." ></td>
	<td class="line x" title="228:260	We parsed the MUC-7 (1997) coreference corpus and extracted all pronouns in a direct object relation." ></td>
	<td class="line x" title="229:260	For each pronoun, p, modified by a verb, v, we extracted all preceding nouns within the current or previous sentence." ></td>
	<td class="line x" title="230:260	Thirty-nine anaphoric pronouns had an antecedent in this window and are used in the evaluation." ></td>
	<td class="line x" title="231:260	For each p, let N(p)+ by the set of preceding nouns coreferent with p, and let N(p) be the remaining non-coreferent nouns." ></td>
	<td class="line x" title="232:260	We take all (v,n+) where n+  N(p)+ as positive, and all other pairs (v,n), n  N(p) as negative." ></td>
	<td class="line x" title="233:260	We compare MI and DSP on this set, classifying every (v,n) with MI>T (or DSP>T) as positive." ></td>
	<td class="line x" title="234:260	By varying T, we get a precision-recall curve (Figure 2)." ></td>
	<td class="line x" title="235:260	Precision is low because, of course, there are many nouns that satisfy the predicates SPs that are not coreferent." ></td>
	<td class="line x" title="236:260	DSP>0 has both a higher recall and higher precision than accepting every pair previously seen in text (the right-most point on MI>T)." ></td>
	<td class="line x" title="237:260	The DSP>T system achieves higher precision than MI>T for points where recall is greater than 60% (where MI<0)." ></td>
	<td class="line x" title="238:260	Interestingly, the recall of MI>0 is 66 System Acc Most-Recent Noun 17.9% Maximum MI 28.2% Maximum DSP 38.5% Table 4: Pronoun resolution accuracy on nouns in current or previous sentence in MUC." ></td>
	<td class="line x" title="239:260	higher here than it is for general verb-objects (Section 4.5)." ></td>
	<td class="line x" title="240:260	On the subset of pairs with strong empirical association (MI>0), MI generally outperforms DSP at equivalent recall values." ></td>
	<td class="line x" title="241:260	We next compare MI and DSP as stand-alone pronoun resolution systems (Table 4)." ></td>
	<td class="line x" title="242:260	As a standard baseline, for each pronoun, we choose the most recent noun in text as the pronouns antecedent, achieving 17.9% resolution accuracy." ></td>
	<td class="line x" title="243:260	This baseline is quite low because many of the most-recent nouns are subjects of the pronouns verb phrase, and therefore resolution violates syntactic coreference constraints." ></td>
	<td class="line x" title="244:260	If instead we choose the previous noun with the highest MI as antecedent, we get an accuracy of 28.2%, while choosing the previous noun with the highest DSP achieves 38.5%." ></td>
	<td class="line x" title="245:260	DSP resolves 37% more pronouns correctly than MI." ></td>
	<td class="line x" title="246:260	We leave as future work a full-scale pronoun resolution system that incorporates both MI and DSP as backed-off, interpolated, or separate semantic features." ></td>
	<td class="line x" title="247:260	5 Conclusions and Future Work We have presented a simple, effective model of selectional preference based on discriminative training." ></td>
	<td class="line x" title="248:260	Supervised techniques typically achieve higher performance than unsupervised models, and we duplicate these gains with DSP." ></td>
	<td class="line x" title="249:260	Here, however, these gains come at no additional labeling cost, as training examples are generated automatically from unlabeled text." ></td>
	<td class="line x" title="250:260	DSP allows an arbitrary combination of features, including verb co-occurrence features that yield high-quality similar-word lists as latent output." ></td>
	<td class="line x" title="251:260	This work only scratches the surface of possible feature mining; information from WordNet relations, Wikipedia categories, or parallel corpora could also provide valuable clues to SP." ></td>
	<td class="line x" title="252:260	Also, if any other system were to exceed DSPs performance, it could also be included as one of DSPs features." ></td>
	<td class="line x" title="253:260	It would be interesting to expand our cooccurrence features, including co-occurrence counts across more grammatical relations and using counts from external, unparsed corpora like the world wide web." ></td>
	<td class="line x" title="254:260	We could also reverse the role of noun and verb in our training, having verb-specific features and discriminating separately for each argument noun." ></td>
	<td class="line x" title="255:260	The latent information would then be lists of similar nouns." ></td>
	<td class="line x" title="256:260	Finally, note that while we focused on word-word co-occurrences, sense-sense SPs can also be learned with our algorithm." ></td>
	<td class="line x" title="257:260	If our training corpus was senselabeled, we could run our algorithm over the senses rather than the words." ></td>
	<td class="line x" title="258:260	The resulting model would then require sense-tagged input if it were to be used within an application like parsing or coreference resolution." ></td>
	<td class="line x" title="259:260	Also, like other models of SP, our technique can also be used for sense disambiguations: the weightings on our semantic class features indicate, for a particular noun, which of its senses (classes) is most compatible with each verb." ></td>
	<td class="line x" title="260:260	Acknowledgments We gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada, the Alberta Ingenuity Fund, and the Alberta Informatics Circle of Research Excellence." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="D08-1048
Automatic induction of FrameNet lexical units
Pennacchiotti, Marco;De Cao, Diego;Basili, Roberto;Croce, Danilo;Roth, Michael;"></td>
	<td class="line x" title="1:235	Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 457465, Honolulu, October 2008." ></td>
	<td class="line x" title="2:235	c2008 Association for Computational Linguistics Automatic induction of FrameNet lexical units Marco Pennacchiotti(), Diego De Cao(), Roberto Basili(), Danilo Croce(), Michael Roth() () Computational Linguistics Saarland University Saarbrucken, Germany {pennacchiotti,mroth}@coli.uni-sb.de () DISP University of Roma Tor Vergata Roma, Italy {decao,basili,croce}@info.uniroma2.it Abstract Most attempts to integrate FrameNet in NLP systems have so far failed because of its limited coverage." ></td>
	<td class="line x" title="3:235	In this paper, we investigate the applicability of distributional and WordNetbased models on the task of lexical unit induction, i.e. the expansion of FrameNet with new lexical units." ></td>
	<td class="line x" title="4:235	Experimental results show that our distributional and WordNet-based models achieve good level of accuracy and coverage, especially when combined." ></td>
	<td class="line x" title="5:235	1 Introduction Most inference-based NLP tasks require a large amount of semantic knowledge at the predicateargument level." ></td>
	<td class="line x" title="6:235	This type of knowledge allows to identify meaning-preserving transformations, such as active/passive, verb alternations and nominalizations, which are crucial in several linguistic inferences." ></td>
	<td class="line x" title="7:235	Recently, the integration of NLP systems with manually-built resources at the predicate argument-level, such as FrameNet (Baker et al., 1998) and PropBank (Palmer et al., 2005) has received growing interest." ></td>
	<td class="line x" title="8:235	For example, Shen and Lapata (2007) show the potential improvement that FrameNet can bring on the performance of a Question Answering (QA) system." ></td>
	<td class="line x" title="9:235	Similarly, several other studies (e.g.(Bar-Haim et al., 2005; Garoufi, 2007)) indicate that frame semantics plays a central role in Recognizing Textual Entailment (RTE)." ></td>
	<td class="line x" title="11:235	Unfortunately, most attempts to integrate FrameNet or similar resources in QA and RTE systems have so far failed, as reviewed respectively in (Shen and Lapata, 2007) and (Burchardt and Frank, 2006)." ></td>
	<td class="line x" title="12:235	These studies indicate limited coverage as the main reason of insuccess." ></td>
	<td class="line x" title="13:235	Indeed, the FrameNet database only contains 10,000 lexical units (LUs), far less than the 210,000 entries in WordNet 3.0." ></td>
	<td class="line x" title="14:235	Also, frames are based on more complex information than word senses, so that their manual development is much more demanding (Burchardt et al., 2006; Subirats and Petruck, 2003)." ></td>
	<td class="line x" title="15:235	Therefore, there is nowadays a pressing need to adopt learning approaches to extend the coverage of the FrameNet lexicon by automatically acquiring new LUs, a task we call LU induction, as recently proposed at SemEval-2007 (Baker et al., 2007)." ></td>
	<td class="line x" title="16:235	Unfortunately, research in this area is still somehow limited and fragmentary." ></td>
	<td class="line x" title="17:235	The aim of our study is to pioneer in this field by proposing two unsupervised models for LU induction, one based on distributional techniques and one using WordNet as a support; and a combined model which mixes the two." ></td>
	<td class="line x" title="18:235	The goal is to investigate to what extent distributional and WordNet-based models can be used to induce frame semantic knowledge in order to safely extend FrameNet, thus limiting the high costs of manual annotation." ></td>
	<td class="line x" title="19:235	In Section 2 we introduce the LU induction task and present related work." ></td>
	<td class="line x" title="20:235	In Sections 3, 4 and 5 we present our distributional, WordNet-based and combined models." ></td>
	<td class="line x" title="21:235	Then, in Section 6 we report experimental results and comparative evaluations." ></td>
	<td class="line x" title="22:235	Finally, in Section 7 we draw final conclusions and outline future work." ></td>
	<td class="line x" title="23:235	2 Task Definition and Related Work As defined in (Fillmore, 1985), a frame is a conceptual structure modeling a prototypical situation, evoked in texts through the occurrence of its lexical units." ></td>
	<td class="line x" title="24:235	A lexical unit (LU) is a predicate that linguistically expresses the situation of the frame." ></td>
	<td class="line x" title="25:235	Lexical units of the same frame share semantic arguments." ></td>
	<td class="line x" title="26:235	For example the frame KILLING has lexical units such as assassin, assassinate, blood-bath, fatal, murderer, kill, suicide that share semantic arguments such as KILLER, INSTRUMENT, CAUSE, VICTIM." ></td>
	<td class="line x" title="27:235	Building on this frame-semantic model, the Berkeley FrameNet project (Baker et al., 1998) has been developing a frame-semantic lexicon for 457 the core vocabulary of English since 1997." ></td>
	<td class="line x" title="28:235	The current FrameNet release contains 795 frames and about 10,000 LUs." ></td>
	<td class="line x" title="29:235	Part of FrameNet is also a corpus of 135,000 annotated example sentences from the British National Corpus (BNC)." ></td>
	<td class="line x" title="30:235	LU induction is a fairly new task." ></td>
	<td class="line x" title="31:235	Formally, it can be defined as the task of assigning a generic lexical unit not yet present in the FrameNet database (hereafter called unknown LU) to the correct frame(s)." ></td>
	<td class="line x" title="32:235	As the number of frames is very large (about 800) the task is intuitively hard to solve." ></td>
	<td class="line x" title="33:235	A further complexity regards multiple assignments." ></td>
	<td class="line x" title="34:235	Lexical units are sometimes ambiguous and can then be mapped to more than one frame (for example the word tea could map both to FOOD and SOCIAL EVENT)." ></td>
	<td class="line x" title="35:235	Also, even unambiguous words can be assigned to more than one frame  e.g. child maps to both KINSHIP and PEOPLE BY AGE." ></td>
	<td class="line x" title="36:235	LU induction is relevant to many NLP tasks, such as the semi-automatic creation of new FrameNets, and semantic role labelling." ></td>
	<td class="line x" title="37:235	LU induction has been integrated at SemEval-2007 as part of the Frame Semantic Structure Extraction shared task (Baker et al., 2007), where systems are requested to assign the correct frame to a given LU, even when the LU is not yet present in FrameNet." ></td>
	<td class="line x" title="38:235	Johansson and Nugues (2007) approach the task as a machine learning problem: a Support Vector Machine trained on existing LUs is applied to assign unknown LUs to the correct frame, using features derived from the WordNet hierarchy." ></td>
	<td class="line x" title="39:235	Tested on the FrameNet gold standard, the method achieves an accuracy of 0.78, at the cost of a low coverage of 31% (i.e. many LUs are not assigned)." ></td>
	<td class="line x" title="40:235	Johansson and Nugues (2007) also experiment with a simple model based on standard WordNet similarity measures (Pedersen et al., 2004), achieving lower performance." ></td>
	<td class="line x" title="41:235	Burchardt and colleagues (2005) present Detour, a rule-based system using words in a WordNet relation with the unknown LU to find the correct frame." ></td>
	<td class="line x" title="42:235	The system achieves an accuracy of 0.39 and a coverage of 87%." ></td>
	<td class="line x" title="43:235	Unfortunately this algorithm requires the LU to be previously disambiguated, either by hand or using contextual information." ></td>
	<td class="line x" title="44:235	In a departure from previous work, our first model leverages distributional properties to induce LUs, instead of relying on pre-existing lexical resources as WordNet." ></td>
	<td class="line x" title="45:235	This guarantees two main advantages." ></td>
	<td class="line x" title="46:235	First, it can predict a frame for any unknown LU, while WordNet based approaches can be applied only to words having a WordNet entry." ></td>
	<td class="line x" title="47:235	Second, it allows to induce LUs in languages for which WordNet is not available or has limited coverage." ></td>
	<td class="line x" title="48:235	Our second WordNet-based model uses sense information to characterize the frame membership for unknown LU, by adopting a semantic similarity measure which is sensitive to all the known LUs of a frame." ></td>
	<td class="line x" title="49:235	3 Distributional model The basic idea behind the distributional approach is to induce new LUs by modelling existing frames and unknown LUs in a semantic space, where they are represented as distributional co-occurrence vectors computed over a corpus." ></td>
	<td class="line x" title="50:235	Semantic spaces are widely used in NLP for representing the meaning of words or other lexical entities." ></td>
	<td class="line pc" title="51:235	They have been successfully applied in several tasks, such as information retrieval (Salton et al., 1975) and harvesting thesauri (Lin, 1998)." ></td>
	<td class="line x" title="52:235	The intuition is that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis (Harris, 1964)), and that words with similar vectors are semantically related." ></td>
	<td class="line x" title="53:235	In our setting, the goal is to find a semantic space model able to capture the notion of frame  i.e. the property of being characteristic of a frame." ></td>
	<td class="line x" title="54:235	In such a model, an unknown LU is induced by first computing the similarity between its vector and the vectors of the existing frames, and then assigning the LU to the frame with the highest similarity." ></td>
	<td class="line x" title="55:235	3.1 Assigning unknown LUs to frames In our model, a LU l is represented by a vector vectorl whose dimensions represent the set of contexts C of the semantic space." ></td>
	<td class="line x" title="56:235	The value of each dimension is given by the co-occurrence value of the LU with a contextual feature c  C, computed over a large corpus using an association measure." ></td>
	<td class="line x" title="57:235	We experiment with two different association measures: normalized frequency and pointwise mutual information." ></td>
	<td class="line x" title="58:235	We approximate these measures by using Maximum Likelihood Estimation, as follows: 458 F(l,c) =MLE |l,c||,| MI(l,c) =MLE |l,c||,||,c||l,| (1) where |l,c| denotes the co-occurrence counts of the pair (l,c) in the corpus, |,c| =summationtext lL|l,c|, |l,| = summationtext cC |l,c| and finally |,| =summationtext lL,cC |l,c|." ></td>
	<td class="line x" title="59:235	A frame f is modeled by a vector vectorf, representing the distributional profile of the frame in the semantic space." ></td>
	<td class="line x" title="60:235	We here assume that a frame can be fully described by the set of its lexical units F. We implement this intuition by computing vectorf as the weighted centroid of the set F, as follows: vectorf = summationdisplay lF wlf vectorl (2) where wlf is a weighting factor, accounting for the relevance of a given lexical unit with respect to the frame, estimated as: wlf = |l|summationdisplay lF |l| (3) where |l| denotes the counts of l in the corpus." ></td>
	<td class="line x" title="61:235	From a more cognitive perspective, the vector vectorf represents the prototypical lexical unit of the frame." ></td>
	<td class="line x" title="62:235	Given the set of all framesN and an unknown lexical unit ul, we assign ul to the frame fmaxul which is distributionally most similar  i.e. we intuitively map an unknown lexical unit to the frame whose prototypical lexical unit vectorf has the highest similarity with vectorul: fmaxul = argmaxfNsimD(vectorul, vectorf) (4) In our model, we used the traditional cosine similarity: simcos(ul,f) = vectorul vectorf |vectorul||vectorf| (5) 3.2 Choosing the space Different types of contexts C define spaces with different semantic properties." ></td>
	<td class="line x" title="63:235	We are here looking for a space able to capture the properties which characterise a frame." ></td>
	<td class="line x" title="64:235	The most relevant of these properties is that LUs in the same frame tend to be either cooccurring or substitutional words (e.g. assassin/kill or assassinate/kill)  i.e. they are either in paradigmatic and syntagmatic relation." ></td>
	<td class="line x" title="65:235	In an ideal space, a high similarity value simD would be then given both to assassinate/kill and to assassin/kill." ></td>
	<td class="line x" title="66:235	We explore three spaces which seem to capture the above property well: Word-based space: Contexts are words appearing in a n-window of the lexical unit." ></td>
	<td class="line x" title="67:235	Such spaces model a generic notion of semantic relatedness." ></td>
	<td class="line x" title="68:235	Two LUs close in the space are likely to be related by some type of generic semantic relation, either paradigmatic (e.g. synonymy, hyperonymy, antonymy) or syntagmatic (e.g. meronymy, conceptual and phrasal association).1 Syntax-based space: Contexts are syntactic relations (e.g. X-VSubj-man where X is the LU), as described in (Pado, 2007)." ></td>
	<td class="line x" title="69:235	These spaces are good at modeling semantic similarity." ></td>
	<td class="line oc" title="70:235	Two LUs close in the space are likely to be in a paradigmatic relation, i.e. to be close in a is-a hierarchy (Budanitsky and Hirst, 2006; Lin, 1998; Pado, 2007)." ></td>
	<td class="line x" title="71:235	Indeed, as contexts are syntactic relations, targets with the same part of speech are much closer than targets of different types." ></td>
	<td class="line x" title="72:235	Mixed space: In a combination of the two above spaces, contexts are words connected to the LU by a dependency path of at most length n. Unlike wordbased spaces, contexts are selected in a more principled way: only syntactically related words are contexts, while other (possibly noisy) material is filtered out." ></td>
	<td class="line x" title="73:235	Unlike syntax-based spaces, the context c does not explicitly state the type of syntactic relation with the LU: this usually allows to capture both paradigmatic and syntagmatic relations." ></td>
	<td class="line x" title="74:235	4 WordNet-based model In a departure from previous work, our WordNetbased model does not rely on standard WordNet similarity measures (Pedersen et al., 2004), as these measures can only be applied to pairs of words, while we here need to capture the meaning of whole frames, which typically consist of larger sets of LUs." ></td>
	<td class="line x" title="75:235	Our intuition is that senses able to evoke a frame can be detected via WordNet, by jointly considering the WordNet synsets activated by all LUs of the frame." ></td>
	<td class="line x" title="76:235	We implement this intuition in a weaklysupervised model, where each frame f is represented as a set of specific sub-graphs of the WordNet 1See (Pado, 2007; Sahlgren, 2006) for an in depth analysis." ></td>
	<td class="line x" title="77:235	459 hyponymy hierarchy." ></td>
	<td class="line x" title="78:235	As different parts of speech have different WordNet hierarchies, we build a subgraph for each of them: Snf for nouns, Svf for verbs and Saf for adjectives.2 These sub-graphs represent the lexical semantic properties characterizing the frame." ></td>
	<td class="line x" title="79:235	An unknown LU ul of a given part of speech is assigned to the frame whose corresponding sub-graph is semantically most similar to one of the senses of ul: fmaxul = argmaxfNsimWN(ul,f) (6) where simWN is a WordNet-based similarity measure." ></td>
	<td class="line x" title="80:235	In the following subsections we will describe how we build sub-graphs and model the similarity measure for the different part of speech." ></td>
	<td class="line x" title="81:235	Figure 1 reports an excerpt of the noun subgraph for the frame PEOPLE BY AGE, covering the suitable senses of its nominal LUs {adult,baby,boy,kid,youngster,youth}." ></td>
	<td class="line x" title="82:235	The relevant senses (e.g. sense 1 of youth out of the 6 potential ones) are generally selected, as they share the most specific generalizations in WordNet with the other words." ></td>
	<td class="line x" title="83:235	Nouns." ></td>
	<td class="line x" title="84:235	To compute similarity for nouns we adopt conceptual density (cd) (Agirre and Rigau, 1996), a semantic similarity model previously applied to word sense disambiguation tasks." ></td>
	<td class="line x" title="85:235	Given a frame f and its set of nominal lexical units Fn, the nominal subgraph Snf is built as follows." ></td>
	<td class="line x" title="86:235	All senses of all words in Fn are activated in WordNet." ></td>
	<td class="line x" title="87:235	All hypernyms Hnf of these senses are then retrieved." ></td>
	<td class="line x" title="88:235	Every synset   Hnf is given a cd score, representing the density of the WordNet subhierarchy rooted at  in representing the set of nouns Fn." ></td>
	<td class="line x" title="89:235	The intuition behind this model is that the larger the number of LUs in Fn that are generalized by  is, the better it captures the lexical semantics intended by the frame f. Broader generalizations are penalized as they give rise to bigger hierarchies, not well correlated with the full set of targets Fn." ></td>
	<td class="line x" title="90:235	To build the final sub-graph Snf , we apply the greedy algorithm proposed by Basili and colleagues (2004)." ></td>
	<td class="line x" title="91:235	It first computes the set of WordNet synsets that generalize at least two LUs in Fn, and then selects the subset of most dense ones Snf  Hnf that 2Our WordNet model does not cover the limited number of LUs which are not nouns, verbs or adjectives." ></td>
	<td class="line x" title="92:235	cover Fn." ></td>
	<td class="line x" title="93:235	If a LU has no common hypernym with other members of Fn, it is not represented in Snf , and its similarity is set to 0 . Snf disambiguates words in Fn as only the lexical senses with at least one hypernym in Snf are considered." ></td>
	<td class="line x" title="94:235	Figure 1 shows the nominal sub-graph automatically derived using conceptual density for the frame PEOPLE BY AGE." ></td>
	<td class="line x" title="95:235	The word boy is successfully disambiguated, as its only hypernym in the sub-graph refers to its third sense (a male human offspring) which correctly maps to the given frame." ></td>
	<td class="line x" title="96:235	Notice that this model departs from the first sense heuristics largely successful in word sense disambiguation: most frames in fact are characterized by non predominant senses." ></td>
	<td class="line x" title="97:235	The only questionable disambiguation is for the word adult: the wrong sense (adult mammal) is selected." ></td>
	<td class="line x" title="98:235	However, even in these cases, the cd values are very low (about 104), so that they do not impact much on the quality of the resulting inference." ></td>
	<td class="line x" title="99:235	Figure 1: The noun sub-graph for the frame PEOPLE BY AGE as evoked by a subset of the words." ></td>
	<td class="line x" title="100:235	Sense numbers #n refers to WordNet 2.0." ></td>
	<td class="line x" title="101:235	Using this model, LU induction is performed as follows." ></td>
	<td class="line x" title="102:235	Given an unknown lexical unit ul, for each frame f  N we first build the sub-graph Snf from the set Fn {ul}." ></td>
	<td class="line x" title="103:235	We then compute simWN(f,ul) as the maximal cd of any synset   Snf that generalizes one of the lexical senses of ul." ></td>
	<td class="line x" title="104:235	In the example baby would receive a score of 0.117 according to its first sense in WordNet 2.0 (baby,babe,infant)." ></td>
	<td class="line x" title="105:235	In a final step, we assign the LU to the most similar frame, according to Eq." ></td>
	<td class="line x" title="106:235	6 Verbs and Adjectives." ></td>
	<td class="line x" title="107:235	As the conceptual density algorithm can be used only for nouns, we apply different similarity measures for verbs and adjectives." ></td>
	<td class="line x" title="108:235	460 For verbs we exploit the co-hyponymy relation: the sub-graph Svf is given by all hyponyms of all verbs Fv in the frame f. Similarity simWN(f,ul) is computed as follows: simWN(ul,f) =    1 iff K  F such that |K| >  AND l  K,l is a co-hyponym of ul epsilon1 otherwise (7) As for adjectives, WordNet does not provide a hyponymy hierarchy." ></td>
	<td class="line x" title="109:235	We then compute similarity simply on the basis of the synonymy relation, as follows: simWN(ul,f) =   1 iff l  F such that l is a synonym of ul epsilon1 otherwise (8) 5 Combined model The methods presented so far use two independent information sources to induce LUs: distributional similarity simD and WordNet similarity simWN." ></td>
	<td class="line x" title="110:235	We also build a joint model, leveraging both approaches: we expect the combination of different information to raise the overall performance." ></td>
	<td class="line x" title="111:235	We here choose to combine the two approaches using a simple back-off model, that uses the WordNet-based model as a default and backs-off to the distributional one when no frame is proposed by the former." ></td>
	<td class="line x" title="112:235	The intuition is that WordNet should guarantee the highest precision in the assignment, while distributional similarity should recover cases of low coverage." ></td>
	<td class="line x" title="113:235	6 Experiments In this section we present a comparative evaluation of our models on the task of inducing LUs, in a leave-one-out setting over a reference gold standard." ></td>
	<td class="line x" title="114:235	6.1 Experimental Setup Our gold standard is the FrameNet 1.3 database, containing 795 frames and a set L of 7,522 unique LUs (in all there are 10,196 LUs possibly assigned to more than one frame)." ></td>
	<td class="line x" title="115:235	Given a lexical unit l  L, we simulate the induction task by executing a leaveone-out procedure, similarly to Burchardt and colleagues (2005)." ></td>
	<td class="line x" title="116:235	First, we remove l from all its original frames." ></td>
	<td class="line x" title="117:235	Then, we ask our models to reassign it to the most similar frame(s) f, according to the similarity measure3." ></td>
	<td class="line x" title="118:235	We repeat this procedure for all lexical units." ></td>
	<td class="line x" title="119:235	Though our experiment is not completely realistic (we test over LUs already in FrameNet), it has the advantage of a reliable gold standard produced by expert annotators." ></td>
	<td class="line x" title="120:235	A second, more realistic, small-scale experiment is described in Section 6.2." ></td>
	<td class="line x" title="121:235	We compute accuracy as the fraction of LUs in L that are correctly re-assigned to the original frame." ></td>
	<td class="line x" title="122:235	Accuracy is computed at different levels k: a LU l is correctly assigned if its gold standard frame appears among the best-k frames f ranked by the model using the sim(l,f) measure." ></td>
	<td class="line x" title="123:235	As LUs can have more than one correct frame, we deem as correct an assignment for which at least one of the correct frames is among the best-k." ></td>
	<td class="line x" title="124:235	We also measure coverage, intended as the percentage of LUs that have been assigned to at least one frame by the model." ></td>
	<td class="line x" title="125:235	Notice that when no sense preference can be found above the threshold epsilon1, the WordNet-based model cannot predict any frame, thus decreasing coverage." ></td>
	<td class="line x" title="126:235	We present results for the following models and parametrizations (further parametrizations have revealed comparable performance)." ></td>
	<td class="line x" title="127:235	Dist-word : the word-based space described in Section 3." ></td>
	<td class="line x" title="128:235	Contextual features correspond to the set of the 4,000 most frequent words in the BNC.4 The association measure between LUs and contexts is the pointwise mutual information." ></td>
	<td class="line x" title="129:235	Valid contexts for LUs are fixed to a 20-window." ></td>
	<td class="line x" title="130:235	Dist-syntax : the syntax-based space described in Section 3." ></td>
	<td class="line x" title="131:235	Context features are the 10,000 most frequent syntactic relations in the BNC5." ></td>
	<td class="line x" title="132:235	As association measure we apply log-likelihood ratio (Dunning, 1993) to normalized frequency." ></td>
	<td class="line x" title="133:235	Syntactic relations are extracted using the Minipar parser." ></td>
	<td class="line x" title="134:235	Dist-mixed : the mixed space described in Sec3In the distributional model, we recompute the centroids for each frame f in which the LU appeared, applying Eq." ></td>
	<td class="line x" title="135:235	2 to the set F {l}." ></td>
	<td class="line x" title="136:235	4We didnt use the FrameNet corpus directly, as it is too small to obtain reliable statistics." ></td>
	<td class="line x" title="137:235	5Specifically, we use the minimum context selection function and the plain path value function described in Pado (2007)." ></td>
	<td class="line x" title="138:235	461 tion 3." ></td>
	<td class="line x" title="139:235	As for the Dist-word model, contextual features are 4,000 and pointwise mutual information is the association measure." ></td>
	<td class="line x" title="140:235	The maximal dependency path length for selecting each context word is 3." ></td>
	<td class="line x" title="141:235	Syntactic relations are extracted using Minipar." ></td>
	<td class="line x" title="142:235	WNet-full : the WordNet based model described in Section 4." ></td>
	<td class="line x" title="143:235	WNet-bsense : this model is computed as WNetfull but using only the most frequent sense for each LU as defined in WordNet." ></td>
	<td class="line x" title="144:235	Combined : the combined method presented in Section 5." ></td>
	<td class="line x" title="145:235	Specifically, it uses WNet-full as a default and Dist-word as back-off." ></td>
	<td class="line x" title="146:235	Baseline-rnd : a baseline model, randomly assigning LUs to frames." ></td>
	<td class="line x" title="147:235	Baseline-mostfreq : a model predicting as best-k frames the most likely ones in FrameNet  i.e. those containing the highest number of LUs." ></td>
	<td class="line x" title="148:235	6.2 Experimental Results Table 1 reports accuracy and coverage results for the different models, considering only 6792 LUs with frequency higher than 5 in the BNC, and frames with more than 2 lexical units (to allow better generalizations in all models)." ></td>
	<td class="line x" title="149:235	Results show that all our models largely outperform both baselines, achieving a good level of accuracy and high coverage." ></td>
	<td class="line x" title="150:235	In particular, accuracy for the best-10 frames is high enoungh to support tasks such as the semi-automatic creation of new FrameNets." ></td>
	<td class="line x" title="151:235	This claim is supported by a further task-driven experiment, in which we asked 3 annotators to assign 60 unknown LUs (from the Detour system log) to frames, with and without the support of the Dist-word models predictions as suggestions6." ></td>
	<td class="line x" title="152:235	We verified that our model guarantee an annotation speed-up of 25%  i.e. in average an annotator saves 25% of annotation time by using the systems suggestions." ></td>
	<td class="line x" title="153:235	Distributional vs. WordNet-based models." ></td>
	<td class="line x" title="154:235	WordNet-based models are significantly better than distributional ones, for several reasons." ></td>
	<td class="line x" title="155:235	First, distributional models acquire information only from the contexts in the corpus." ></td>
	<td class="line x" title="156:235	As we do not use a FrameNet annotated corpus, there is no guarantee that the usage of a LU in the texts reflects exactly the semantic 6For this purpose, the dataset is evenly split in two parts." ></td>
	<td class="line x" title="157:235	properties of the LU in FrameNet." ></td>
	<td class="line x" title="158:235	In the extreme cases of polysemous LUs, it may happen that the textual contexts refer to senses which are not accounted for in FrameNet." ></td>
	<td class="line x" title="159:235	In our study, we explicitly ignore the issue of polisemy, which is a notoriously hard task to solve in semantics spaces (see (Schutze, 1998)), as the occurrences of different word senses need to be clustered separately." ></td>
	<td class="line x" title="160:235	We will approach the problem in future work." ></td>
	<td class="line x" title="161:235	The WordNet-based model suffers from the problem of polisemy to a much lesser extent, as all senses are explicitly represented and separated in WordNet, including those related to the FrameNet gold standard." ></td>
	<td class="line x" title="162:235	A second issue regards data sparseness." ></td>
	<td class="line x" title="163:235	The vectorial representation of LUs with few occurrences in the corpus is likely to be semantically incomplete, as not enough statistical evidence is available." ></td>
	<td class="line x" title="164:235	Particularly skewed distributions can be found when some frames are very rarely represented in the corpus." ></td>
	<td class="line x" title="165:235	A more in-depth descussion on these two issues is given later in this section." ></td>
	<td class="line x" title="166:235	Regarding the WordNet-based models, WNet-full in most cases outperforms WNet-bsense." ></td>
	<td class="line x" title="167:235	The first sense heuristic does not seem to be as effective as in other tasks, such as Word Sense Disambiguation." ></td>
	<td class="line x" title="168:235	Although sense preferences (or predominance) across two general purpose resources, such as WordNet and FrameNet, should be a useful hint, the conceptual density algorithm seems to produce better distributions (i.e. higher accuracy), especially when several solutions are considered." ></td>
	<td class="line x" title="169:235	Indeed, for many LUs the first WordNet sense is not the one represented in the FrameNet database." ></td>
	<td class="line x" title="170:235	As for distributional models, results show that the Dist-word model performs best." ></td>
	<td class="line x" title="171:235	In general, syntactic relations (Dist-syntax model) do not help to capture frame semantic properties better than a simple window-based approach." ></td>
	<td class="line x" title="172:235	This seems to indicate that LUs in a same frame are related both by paradigmatic and syntagmatic relations, in accordance to the definition given in Section 3.2  i.e. they are mostly semantically related, but not similar." ></td>
	<td class="line x" title="173:235	Coverage." ></td>
	<td class="line x" title="174:235	Distributional models show a coverage 15% higher than WordNet-based ones." ></td>
	<td class="line x" title="175:235	Indeed, as far as corpus evidence is available (i.e. the unknown LU appears in the corpus), distributional methods are always able to predict a frame." ></td>
	<td class="line x" title="176:235	WordNet-based mod462 MODEL B-1 B-2 B-3 B-4 B-5 B-6 B-7 B-8 B-9 B-10 COVERAGE Dist-word 0.27 0.36 0.42 0.46 0.49 0.51 0.53 0.55 0.56 0.57 95% Dist-syntax 0.22 0.29 0.34 0.38 0.41 0.44 0.46 0.48 0.50 0.51 95% Dist-mixed 0.25 0.35 0.40 0.44 0.47 0.49 0.51 0.53 0.54 0.56 95% WNet-full 0.47 0.59 0.65 0.69 0.72 0.73 0.75 0.76 0.77 0.78 80% WNet-bsense 0.52 0.61 0.64 0.66 0.67 0.68 0.69 0.69 0.70 0.70 72% Combined 0.43 0.54 0.60 0.64 0.66 0.68 0.70 0.71 0.72 0.73 95% Baseline-rnd 0.02 0.03 0.05 0.06 0.08 0.10 0.11 0.12 0.14 0.15 Baseline-mostfreq 0.02 0.05 0.07 0.08 0.10 0.11 0.13 0.14 0.15 0.17 Table 1: Accuracy and coverage of different models on best-k ranking with frequency threshold 5 and frame threshold 2 els cannot make predictions in two specific cases." ></td>
	<td class="line x" title="177:235	First, when the LU is not present in WordNet." ></td>
	<td class="line x" title="178:235	Second, when the function simWN does not has sufficient relational information to find a similar frame." ></td>
	<td class="line x" title="179:235	This second factor is particularly evident for adjectives, as Eq." ></td>
	<td class="line x" title="180:235	8 assigns a frame only when a synonym of the unknown LU is found." ></td>
	<td class="line x" title="181:235	It is then not surprising that 68% of the missed assignment are indeed adjectives." ></td>
	<td class="line x" title="182:235	Results for the Combined model suggest that the integration of distributional and WordNet-based methods can offer a viable solution to the coverage problem, as it achieves an accuracy comparable to the pure WordNet approaches, while keeping the coverage high." ></td>
	<td class="line x" title="183:235	Figure 2: Dist-word model accuracy at different LU frequency cuts." ></td>
	<td class="line x" title="184:235	Data Sparseness." ></td>
	<td class="line x" title="185:235	A major issue when using distributional approaches is that words with low frequency tend to have a very sparse non-meaningful representation in the vector space." ></td>
	<td class="line x" title="186:235	This highly impacts on the accuracy of the models." ></td>
	<td class="line x" title="187:235	To measure the impact of data sparseness, we computed the accuracy at different frequency cuts  i.e. we exclude LUs below a given frequency threshold from centroid computation and evaluation." ></td>
	<td class="line x" title="188:235	Figure 2 reports the results for best-10 assignment at different cuts, for the Dist-word model." ></td>
	<td class="line x" title="189:235	As expected, accuracy improves by excluding infrequent LUs." ></td>
	<td class="line x" title="190:235	Only at a frequency cut of 200 performance becomes stable, as statistical evidence is enough for a reliable prediction." ></td>
	<td class="line x" title="191:235	Yet, in a real setting the improvement in accuracy implies a lower coverage, as the system would not classify LUs below the threshold." ></td>
	<td class="line x" title="192:235	For example, by discarding LUs occurring less than 200 times in the corpus, we obtain a +0.12 improvement in accuracy, but the coverage decreases to 57%." ></td>
	<td class="line x" title="193:235	However, uncovered LUs are also the most rare ones and their relevance in an application may be negligible." ></td>
	<td class="line x" title="194:235	Lexical Semantics, Ambiguity and Plausible Assignments." ></td>
	<td class="line x" title="195:235	The overall accuracies achieved by our methods are pessimistic, in the sense that they should be intended as lower-bounds." ></td>
	<td class="line x" title="196:235	Indeed, a qualitative analysis of erroneous predictions reveals that in many cases the frame assignments produced by the models are semantically plausible, even if they are considered incorrect in the leave-one-out test." ></td>
	<td class="line x" title="197:235	Consider for example the LU guerrilla, assigned in FrameNet to the frame PEOPLE BY VOCATION." ></td>
	<td class="line x" title="198:235	Our mixed model proposes as two most similar frames MILITARY and TERRORISM, which could still be considered plausible assignment." ></td>
	<td class="line x" title="199:235	The same holds for the LU caravan, for which the most similar frame is VEHICLE, while in FrameNet the LU is assigned only to the frame BUILDINGS." ></td>
	<td class="line x" title="200:235	These cases are due to the low FrameNet coverage, i.e LUs are not fully annotated and they appear only in a subset of their potential frames." ></td>
	<td class="line x" title="201:235	The real accuracy of our 463 models is therefore expected to be higher." ></td>
	<td class="line x" title="202:235	To explore the issue, we carried out a qualitative analysis of 5 words (i.e. abandon.v, accuse.v, body.n, charge.v and partner.n)." ></td>
	<td class="line x" title="203:235	For each of them, we randomly picked 60 sentences from the BNC corpus, and asked two human annotators to assign to the correct frame the occurrence of the word in the given sentence." ></td>
	<td class="line x" title="204:235	For 2 out of 5 words, no frame could be found for most of the sentences, suggesting that the most frequent frames for these words were missing from FrameNet7." ></td>
	<td class="line x" title="205:235	We can then conclude that 100% accuracy cannot be considered as the upperbound of our experiment, as word usage in texts is not well reflected in the FrameNet modelling." ></td>
	<td class="line x" title="206:235	Further experiments." ></td>
	<td class="line x" title="207:235	We also tested our models on a realistic gold-standard set of 24 unknown LUs extracted from the SemEval-2007 corpus (Baker et al., 2007)." ></td>
	<td class="line x" title="208:235	These are words not present in FrameNet 1.3 which have been assigned by human annotators to an existing frame8." ></td>
	<td class="line x" title="209:235	WNet-full achieves an accuracy of 0.25 for best-1 and 0.69 for best-10, with a coverage of 67%." ></td>
	<td class="line x" title="210:235	A qualitative analysis showed that the lower performance wrt to our main experiment is due to higher ambiguity of the LUs (e.g. we assign tea to SOCIAL EVENT instead of FOOD)." ></td>
	<td class="line x" title="211:235	Comparison to other approaches." ></td>
	<td class="line x" title="212:235	We compare our models to the system presented by Johansson and Nugues (2007) and Burchardt and colleagues (2005)." ></td>
	<td class="line x" title="213:235	Johansson and Nugues (2007) evaluate their machine learning system using 7,000 unique LUs to train the Support Vector Machine, and the remaining LUs as test." ></td>
	<td class="line x" title="214:235	They measure accuracy at different coverage levels." ></td>
	<td class="line x" title="215:235	At 80% coverage accuracy is about 0.42, 10 points below our best WordNetbased system." ></td>
	<td class="line x" title="216:235	At 90% coverage, the system shows an accuracy below 0.10 and is significantly outperformed by both our distributional and combined methods." ></td>
	<td class="line x" title="217:235	These results confirm that WordNet-based approaches, while being highly accurate wrt distributional ones, present strong weaknesses as far as coverage is concerned." ></td>
	<td class="line x" title="218:235	Furthermore, Johansson and Nugues (2007) show that their machine learn7Note that the need of new frames to account for semantic phenomena in free texts has been also demonstrated by the SemEval-2007 competition." ></td>
	<td class="line x" title="219:235	8The set does not contain 4 LUs which have no frame in FrameNet." ></td>
	<td class="line x" title="220:235	ing approach outperforms a simple approach based on WordNet similarity: thus, our results indirectly prove that our WordNet-based method is more effective than the application of the similarity measure presented in (Pedersen et al., 2004)." ></td>
	<td class="line x" title="221:235	We also compare our results to those reported by Burchardt and colleagues (2005) for Detour." ></td>
	<td class="line x" title="222:235	Though the experimental setting is slightly different (LU assignment is done at the text-level), they use the same gold standard and leave-one-out technique, reporting a best-1 accuracy of 0.38 and a coverage of 87%." ></td>
	<td class="line x" title="223:235	Our WordNet-based models significantly outperform Detour on best-1 accuracy, at the cost of lower coverage." ></td>
	<td class="line x" title="224:235	Yet,our combined model is significantly better both on accuracy (+5%) and coverage (+8%)." ></td>
	<td class="line x" title="225:235	Also, in most cases Detour cannot predict more than one frame (best-1), while our accuracies can be improved by relaxing to any best-k level." ></td>
	<td class="line x" title="226:235	7 Conclusions In this paper we presented an original approach for FrameNet LU induction." ></td>
	<td class="line x" title="227:235	Results show that models combining distributional and WordNet information offer the most viable solution to model the notion of frame, as they allow to achieve a reasonable trade-off between accuracy and coverage." ></td>
	<td class="line x" title="228:235	We also showed that in contrast to previous work, simple semantic spaces are more helpful than complex syntactic ones." ></td>
	<td class="line x" title="229:235	Results are accurate enough to support the creation and the development of new FrameNets." ></td>
	<td class="line x" title="230:235	As future work, we will evaluate new types of spaces (e.g. dimensionality reduction methods) to improve the generalization capabilities of the space models." ></td>
	<td class="line x" title="231:235	We will also address the data sparseness issue, by testing smoothing techniques to better model low frequency LUs." ></td>
	<td class="line x" title="232:235	Finally, we will implement the presented models in a complex architecture for semi-supervised FrameNets development, both for specializing the existing English FrameNet in specific domains, and for creating new FrameNets in other languages." ></td>
	<td class="line x" title="233:235	Acknowledgements This work has partly been funded by the German Research Foundation DFG (grant PI 154/9-3)." ></td>
	<td class="line x" title="234:235	Thanks to Richard Johansson and Aljoscha Burchardt for providing the data of their systems." ></td>
	<td class="line x" title="235:235	464" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="D08-1084
A Phrase-Based Alignment Model for Natural Language Inference
MacCartney, Bill;Galley, Michel;Manning, Christopher D.;"></td>
	<td class="line x" title="1:232	Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 802811, Honolulu, October 2008." ></td>
	<td class="line x" title="2:232	c2008 Association for Computational Linguistics A Phrase-Based Alignment Model for Natural Language Inference Bill MacCartney, Michel Galley, Christopher D. Manning Natural Language Processing Group, Stanford University {wcmac,mgalley,manning}@stanford.edu Abstract The alignment problemestablishing links between corresponding phrases in two related sentencesis as important in natural language inference (NLI) as it is in machine translation (MT)." ></td>
	<td class="line x" title="3:232	But the tools and techniques of MT alignment do not readily transfer to NLI, where one cannot assume semantic equivalence, and for which large volumes of bitext are lacking." ></td>
	<td class="line x" title="4:232	We present a new NLI aligner, the MANLI system, designed to address these challenges." ></td>
	<td class="line x" title="5:232	It uses a phrase-based alignment representation, exploits external lexical resources, and capitalizes on a new set of supervised training data." ></td>
	<td class="line x" title="6:232	We compare the performance of MANLI to existing NLI and MT aligners on an NLI alignment task over the well-known Recognizing Textual Entailment data." ></td>
	<td class="line x" title="7:232	We show that MANLI significantly outperforms existing aligners, achieving gains of 6.2% in F1 over a representative NLI aligner and 10.5% over GIZA++." ></td>
	<td class="line x" title="8:232	1 Introduction The problem of natural language inference (NLI) is to determine whether a natural-language hypothesis H can reasonably be inferred from a given premise textP." ></td>
	<td class="line x" title="9:232	In order to recognize that Kennedy was killed can be inferred from JFK was assassinated, one must first recognize the correspondence between Kennedy and JFK, and between killed and assassinated." ></td>
	<td class="line x" title="10:232	Consequently, most current approaches to NLI rely, implicitly or explicitly, on a facility for alignmentthat is, establishing links between corresponding entities and predicates in P and H. Recent entries in the annual Recognizing Textual Entailment (RTE) competition (Dagan et al., 2005) have addressed the alignment problem in a variety of ways, though often without distinguishing it as a separate subproblem." ></td>
	<td class="line x" title="11:232	Glickman et al.(2005) and Jijkoun and de Rijke (2005), among others, have explored approaches based on measuring the degree of lexical overlap between bags of words." ></td>
	<td class="line x" title="13:232	While ignoring structure, such methods depend on matching each word in H to the word in P with which it is most similarin effect, an alignment." ></td>
	<td class="line x" title="14:232	At the other extreme, Tatu and Moldovan (2007) and Bar-Haim et al.(2007) have formulated the inference problem as analogous to proof search, using inferential rules which encode (among other things) knowledge of lexical relatedness." ></td>
	<td class="line x" title="16:232	In such approaches, the correspondence between the words ofP andH is implicit in the steps of the proof." ></td>
	<td class="line x" title="17:232	Increasingly, however, the most successful RTE systems have made the alignment problem explicit." ></td>
	<td class="line x" title="18:232	Marsi and Krahmer (2005) and MacCartney et al.(2006) first advocated pipelined system architectures containing a distinct alignment component, a strategy crucial to the top-performing systems of Hickl et al.(2006) and Hickl and Bensley (2007)." ></td>
	<td class="line x" title="21:232	However, each of these systems has pursued alignment in idiosyncratic and poorly-documented ways, often using proprietary data, making comparisons and further development difficult." ></td>
	<td class="line x" title="22:232	In this paper we undertake the first systematic study of alignment for NLI." ></td>
	<td class="line x" title="23:232	We propose a new NLI alignment system which uses a phrase-based representation of alignment, exploits external resources for knowledge of semantic relatedness, and capitalizes on the recent appearance of new supervised training data for NLI alignment." ></td>
	<td class="line x" title="24:232	In addition, we examine the relation between NLI alignment and MT alignment, and investigate whether existing MT aligners can usefully be applied in the NLI setting." ></td>
	<td class="line x" title="25:232	2 NLI alignment vs. MT alignment The alignment problem is familiar in machine translation (MT), where recognizing that she came is a good translation for elle est venue requires establish802 ing a correspondence between she and elle, and between came and est venue." ></td>
	<td class="line x" title="26:232	The MT community has developed not only an extensive literature on alignment (Brown et al., 1993; Vogel et al., 1996; Marcu and Wong, 2002; DeNero et al., 2006), but also standard, proven alignment tools such as GIZA++ (Och and Ney, 2003)." ></td>
	<td class="line x" title="27:232	Can off-the-shelf MT aligners be applied to NLI?" ></td>
	<td class="line x" title="28:232	There is reason to be doubtful." ></td>
	<td class="line x" title="29:232	Alignment for NLI differs from alignment for MT in several important respects, including: 1." ></td>
	<td class="line x" title="30:232	Most obviously, it is monolingual rather than cross-lingual, opening the door to utilizing abundant (monolingual) sources of information on semantic relatedness, such as WordNet." ></td>
	<td class="line x" title="31:232	2." ></td>
	<td class="line x" title="32:232	It is intrinsically asymmetric: P is often much longer thanH, and commonly contains phrases or clauses which have no counterpart in H. 3." ></td>
	<td class="line x" title="33:232	Indeed, one cannot assume even approximate semantic equivalenceusually a given in MT. Because NLI problems include both valid and invalid inferences, the semantic content of H may diverge substantially from P. An NLI aligner must be designed to accommodate frequent unaligned words and phrases." ></td>
	<td class="line x" title="34:232	4." ></td>
	<td class="line x" title="35:232	Little training data is available." ></td>
	<td class="line x" title="36:232	MT alignment models are typically trained in unsupervised fashion, inducing lexical correspondences from massive quantities of sentencealigned bitexts." ></td>
	<td class="line x" title="37:232	While NLI aligners could in principle do the same, large volumes of suitable data are lacking." ></td>
	<td class="line x" title="38:232	NLI aligners must therefore depend on smaller quantities of supervised training data, supplemented by external lexical resources." ></td>
	<td class="line x" title="39:232	Conversely, while existing MT aligners can make use of dictionaries, they are not designed to harness other sources of information on degrees of semantic relatedness." ></td>
	<td class="line x" title="40:232	Consequently, the tools and techniques of MT alignment may not transfer readily to NLI alignment." ></td>
	<td class="line x" title="41:232	We investigate the matter empirically in section 5.2." ></td>
	<td class="line x" title="42:232	3 Data Until recently, research on alignment for NLI has been hampered by a paucity of high-quality, publicly available data from which to learn." ></td>
	<td class="line x" title="43:232	Happily, that has begun to change, with the release by Microsoft Research (MSR) of human-generated alignment annoIn most Pacific countries there are very few women in parliament . Wom en are poorlyrepresente d in parlia ment .Figure 1: The MSR gold-standard alignment for problem116 from the RTE2 development set." ></td>
	<td class="line x" title="44:232	tations (Brockett, 2007) for inference problems from the second Recognizing Textual Entailment (RTE2) challenge (Bar-Haim et al., 2006)." ></td>
	<td class="line x" title="45:232	To our knowledge, this work is the first to exploit this data for training and evaluation of NLI alignment models." ></td>
	<td class="line x" title="46:232	The RTE2 data consists of a development set and a test set, each containing 800 inference problems." ></td>
	<td class="line x" title="47:232	Each problem consists of a premise and a hypothesis." ></td>
	<td class="line x" title="48:232	The premises contain 29 words on average; the hypotheses, 11 words." ></td>
	<td class="line x" title="49:232	Each problem is marked as a valid or invalid inference (50% each); however, these annotations are ignored during alignment, since they would not be available during testing of a complete NLI system." ></td>
	<td class="line x" title="50:232	The MSR annotations use an alignment representation which is token-based, but many-to-many, and thus allows implicit alignment of multi-word phrases." ></td>
	<td class="line x" title="51:232	Figure 1 shows an example in which very few has been aligned with poorly represented." ></td>
	<td class="line x" title="52:232	In the MSR data, every alignment link is marked as SURE or POSSIBLE." ></td>
	<td class="line x" title="53:232	In making this distinction, the annotators have followed a convention common in MT, which permits alignment precision to be measured against both SURE and POSSIBLE links, while recall is measured against only SURE links." ></td>
	<td class="line x" title="54:232	In this work, however, we have chosen to ignore POSSIBLE links, embracing the argument made by (Fraser and Marcu, 2007) that their use has impeded progress in MT alignment models, and that SURE803 only annotation is to be preferred." ></td>
	<td class="line x" title="55:232	Each RTE2 problem was independently annotated by three people, following carefully designed annotation guidelines." ></td>
	<td class="line x" title="56:232	Inter-annotator agreement was high: Brockett (2007) reports Fleiss kappa1 scores of about 0.73 (substantial agreement) for mappings from H tokens to P tokens; and all three annotators agreed on 70% of proposed links, while at least two of three agreed on more than 99.7% of proposed links,2 attesting to the high quality of the annotation data." ></td>
	<td class="line x" title="57:232	For this work, we merged the three independent annotations, using majority rule,3 to obtain a gold-standard annotation containing an average of 7.3 links per RTE problem." ></td>
	<td class="line x" title="58:232	4 The MANLI aligner In this section, we describe the MANLI aligner, a new alignment system designed expressly for NLI alignment." ></td>
	<td class="line x" title="59:232	The MANLI system consists of four elements: (1) a phrase-based representation of alignment, (2) a feature-based linear scoring function for alignments, (3) a decoder which uses simulated annealing to find high-scoring alignments, and (4) perceptron learning to optimize feature weights." ></td>
	<td class="line x" title="60:232	4.1 A phrase-based alignment representation MANLI uses an alignment representation which is intrinsically phrase-based." ></td>
	<td class="line x" title="61:232	(Following the usage common in MT, we use phrase to mean any contiguous span of tokens, not necessarily corresponding to a syntactic phrase.)" ></td>
	<td class="line x" title="62:232	We represent an alignment E between a premise P and a hypothesis H as a set of phrase edits {e1,e2,}, each belonging to one of four types:  an EQ edit connects a phrase inP with an equal (by word lemmas) phrase in H  a SUB edit connects a phrase in P with an unequal phrase in H  a DEL edit covers an unaligned phrase in P  an INS edit covers an unaligned phrase in H For example, the alignment shown in figure 1 can be represented by the set {DEL(In1), 1Fleiss kappa generalizes Cohens kappa to the case where there are more than two annotators." ></td>
	<td class="line x" title="63:232	2The SURE/POSSIBLE distinction is taken as significant in computing all these figures." ></td>
	<td class="line x" title="64:232	3The handful of three-way disagreements were treated as POSSIBLE links, and thus were not used here." ></td>
	<td class="line x" title="65:232	DEL(most2), DEL(Pacific3), DEL(countries4), DEL(there5), EQ(are6, are2), SUB(very7 few8, poorly3 represented4), EQ(women9, Women1), EQ(in10, in5), EQ(parliament11, parliament6), EQ(.12, .7)}.4 Alignments are constrained to be one-to-one at the phrase level: every token in P and H belongs to exactly one phrase, which participates in exactly one edit (possibly DEL or INS)." ></td>
	<td class="line x" title="66:232	However, the phrase representation permits alignments which are manyto-many at the token level." ></td>
	<td class="line x" title="67:232	In fact, this is the chief motivation for the phrase-based representation: we can align very few and poorly represented as units, without being forced to make an arbitrary choice as to which word goes with which word." ></td>
	<td class="line x" title="68:232	Moreover, our scoring function can make use of lexical resources which have information about semantic relatedness of multi-word phrases, not merely individual words." ></td>
	<td class="line x" title="69:232	About 23% of the MSR gold-standard alignments are not one-to-one (at the token level), and are therefore technically unreachable for MANLI, which is constrained to generate one-to-one alignments." ></td>
	<td class="line x" title="70:232	However, by merging contiguous token links into phrase edits of size > 1, most MSR alignments (about 92%) can be straightforwardly converted into MANLI-reachable alignments." ></td>
	<td class="line x" title="71:232	For the purpose of model training (but not for the evaluation described in section 5.4), we generated a version of the MSR data in which all alignments were converted to MANLI-reachable form.5 4.2 A feature-based scoring function To score alignments, we use a simple feature-based linear scoring function, in which the score of an alignment is the sum of the scores of the edits it contains (including not only SUB and EQ edits, but also DEL and INS edits), and the score of an edit is the dot product of a vector encoding its features and a vector of weights." ></td>
	<td class="line x" title="72:232	If E is a set of edits constituting 4DEL and INS edits of size > 1 are possible in principle, but are not used in our training data." ></td>
	<td class="line x" title="73:232	5About 8% of the MSR alignments contain non-contiguous links, most commonly because P contains two references to an entity (e.g., Christian Democrats and CDU) which are both linked to a reference to the same entity in H (e.g., Christian Democratic Union)." ></td>
	<td class="line x" title="74:232	In such cases, one or more links must be eliminated to achieve a MANLI-reachable alignment." ></td>
	<td class="line x" title="75:232	We used a string-similarity heuristic to break such conflicts, but were obliged to make an arbitrary choice in about 2% of cases." ></td>
	<td class="line x" title="76:232	804 an alignment, and  is a vector of feature functions, the score s is given by: s(E) = summationdisplay eE s(e) = summationdisplay eE w(e) Well explain how the feature weights w are set in section 4.4." ></td>
	<td class="line x" title="77:232	The features used to characterize each edit are as follows: Edit type features." ></td>
	<td class="line x" title="78:232	We begin with boolean features encoding the type of each edit." ></td>
	<td class="line x" title="79:232	We expect EQs to score higher than SUBs, and (sinceP is commonly longer than H) DELs to score higher than INSs." ></td>
	<td class="line x" title="80:232	Phrase features." ></td>
	<td class="line x" title="81:232	Next, we have features which encode the sizes of the phrases involved in the edit, and whether these phrases are non-constituents (in syntactic parses of the sentences involved)." ></td>
	<td class="line x" title="82:232	Lexical similarity feature." ></td>
	<td class="line x" title="83:232	For SUB edits, a very important feature represents the lexical similarity of the substituends, as a real value in [0,1]." ></td>
	<td class="line pc" title="84:232	This similarity score is computed as a max over a number of component scoring functions, some based on external lexical resources, including:  various string similarity functions, of which most are applied to word lemmas  measures of synonymy, hypernymy, antonymy, and semantic relatedness, including a widelyused measure due to Jiang and Conrath (1997), based on manually constructed lexical resources such as WordNet and NomBank  a function based on the well-known distributional similarity metric of Lin (1998), which automatically infers similarity of words and phrases from their distributions in a very large corpus of English text The ability to leverage external lexical resources both manually and automatically constructedis critical to the success of MANLI." ></td>
	<td class="line x" title="85:232	Contextual features." ></td>
	<td class="line x" title="86:232	Even when the lexical similarity for a SUB edit is high, it may not be a good match." ></td>
	<td class="line x" title="87:232	If P or H contains multiple occurrences of the same wordwhich happens frequently with function words, and occasionally with content wordslexical similarity may not suffice to determine the right match." ></td>
	<td class="line x" title="88:232	To remedy this, we introduce contextual features for SUB and EQ edits." ></td>
	<td class="line x" title="89:232	A realvalued distortion feature measures the difference Inputs  an alignment problemP,H  a number of iterations N (e.g. 100)  initial temperature T0 (e.g. 40) and multiplier r (e.g. 0.9)  a bound on edit size max (e.g. 6)  an alignment scoring function, SCORE(E) Initialize  Let E be an empty alignment for P,H (containing only DEL and INS edits, no EQ or SUB edits)  Set E = E Repeat for i = 1 to N  Let {F1,F2,} be the set of possible successors of E. To generate this set:  Consider every possible edit f up to size max  Let C(E,f) be the set of edits in E which conflict with f (i.e., involve at least some of the same tokens as f)  Let F = E{f}\C(E,f)  Let s(F) be a map from successors of E to scores generated by SCORE  Set p(F) = exps(F), and then normalize p(F), transforming the score map to a probability distribution  Set Ti = rTi1  Set p(F) = p(F)1/Ti, smoothing or sharpening p(F)  Renormalize p(F)  Choose a new value for E by sampling from p(F)  If SCORE(E) > SCORE( E), set E = E Return E Figure 2: The MANLI-ALIGN algorithm between the relative positions of the substituends within their respective sentences, while boolean matching neighbors features indicate whether the tokens before and after the substituends are equal or similar." ></td>
	<td class="line x" title="90:232	4.3 Decoding using simulated annealing The problem of decodingthat is, finding a high-scoring alignment for a particular inference problemis made more complex by our choice of a phrase-based alignment representation." ></td>
	<td class="line x" title="91:232	For a model which uses a token-based representation (say, one which simply maps H tokens to P tokens), decoding is trivial, since each token can be aligned independently of its neighbors." ></td>
	<td class="line x" title="92:232	(This is the case for the bag-of-words aligner described in section 5.1.) But with a phrase-based representation, things are more complicated." ></td>
	<td class="line x" title="93:232	The segmentation into phrases is not given in advance, and every phrase pair considered for alignment must be consistent with its neighbors with respect to segmentation." ></td>
	<td class="line x" title="94:232	Consequently, the decoding problem cannot be factored into a number of 805 independent decisions." ></td>
	<td class="line x" title="95:232	To address this difficulty, we have devised a stochastic alignment algorithm, MANLI-ALIGN (figure 2), which uses a simulated annealing strategy." ></td>
	<td class="line x" title="96:232	Beginning from an arbitrary alignment, we make a series of local steps, at each iteration sampling from a set of possible successors according to scores assigned by our scoring function." ></td>
	<td class="line x" title="97:232	The sampling is controlled by a temperature which falls over time." ></td>
	<td class="line x" title="98:232	At the beginning of the process, successors are sampled with nearly uniform probability, which helps to ensure that the space of possibilities is explored and local maxima are avoided." ></td>
	<td class="line x" title="99:232	As the temperature falls, there is a ever-stronger bias toward high-scoring successors, so that the algorithm converges on a nearoptimal alignment." ></td>
	<td class="line x" title="100:232	Clever use of memoization helps to ensure that computational costs remain manageable." ></td>
	<td class="line x" title="101:232	Using the parameter values suggested in figure 2, aligning an average RTE problem takes about two seconds." ></td>
	<td class="line x" title="102:232	While MANLI-ALIGN is not guaranteed to produce optimal alignments, there is reason to believe that it usually comes very close." ></td>
	<td class="line x" title="103:232	After training, the alignment found by MANLI scored at least as high as the gold alignment for 99.6% of RTE problems.6 4.4 Perceptron learning To tune the parameters w of the model, we use an adaptation of the averaged perceptron algorithm (Collins, 2002), which has proven successful on a range of NLP tasks." ></td>
	<td class="line x" title="104:232	The algorithm is shown in figure 3." ></td>
	<td class="line x" title="105:232	After initializing w to 0, we perform N training epochs." ></td>
	<td class="line x" title="106:232	(Our experiments used N = 50.)" ></td>
	<td class="line x" title="107:232	In each epoch, we iterate through the training data, updating the weight vector at each training example according to the difference between the features of the target alignment and the features of the alignment produced by the decoder using the current weight vector." ></td>
	<td class="line x" title="108:232	The size of the update is controlled by a learning rate which decreases over time." ></td>
	<td class="line x" title="109:232	At the end of each epoch, the weight vector is normalized and stored." ></td>
	<td class="line x" title="110:232	The final result is the average of the stored 6This figure is based on the MANLI-reachable version of the gold-standard data described in section 4.1." ></td>
	<td class="line x" title="111:232	For the raw gold-standard data, the figure is 88.1%." ></td>
	<td class="line x" title="112:232	The difference is almost entirely attributable to unreachable gold alignments, which tend to score higher simply because they contain more edits (and because the learned weights are mostly positive)." ></td>
	<td class="line x" title="113:232	Inputs  training problemsPj,Hj, j = 1n  corresponding gold-standard alignments Ej  a number of learning epochs N (e.g. 50)  a burn-in period N0 < N (e.g. 10)  initial learning rate R0 (e.g. 1) and multiplier r (e.g. 0.8)  a vector of feature functions (E)  an alignment algorithm ALIGN(P,H;w) which finds a good alignment forP,Husing weight vector w Initialize  Set w = 0 Repeat for i = 1 to N  Set Ri = rRi1, reducing the learning rate  Randomly shuffle the training problems  For j = 1 to n:  Set Ej = ALIGN(Pj,Hj; w)  Set w = w + Ri((Ej)( Ej))  Set w = w/bardblwbardbl2 (L2 normalization)  Set w[i] = w, storing the weight vector for this epoch Return an averaged weight vector:  wavg = 1/(NN0)PNi=N0+1 w[i] Figure 3: The MANLI-LEARN algorithm weight vectors, omitting vectors from a fixed number of epochs at the beginning of the run (which tend to be of poor quality)." ></td>
	<td class="line x" title="114:232	Using the parameter values suggested in figure 3, training runs on the RTE2 development set required about 20 hours." ></td>
	<td class="line x" title="115:232	5 Evaluating aligners on MSR data In this section, we describe experiments designed to evaluate the performance of various alignment systems on the MSR gold-standard data described in section 3." ></td>
	<td class="line x" title="116:232	For each system, we report precision, recall, and F-measure (F1).7 Note that these are macro-averaged statistics, computed per problem by counting aligned token pairs,8 and then averaged over all problems in a problem set.9 We also re7MT researchers conventionally report results in terms of alignment error rate (AER)." ></td>
	<td class="line x" title="117:232	Since we use only SURE links in the gold-standard data (see section 3), AER is equivalent to 1F1." ></td>
	<td class="line x" title="118:232	8For phrase-based alignments like those generated by MANLI, two tokens are considered to be aligned iff they are contained within phrases which are aligned." ></td>
	<td class="line x" title="119:232	9MT evaluations conventionally use micro-averaging, which gives greater weight to problems containing more aligned pairs." ></td>
	<td class="line x" title="120:232	This makes sense in MT, where the purpose of alignment is to induce phrase tables." ></td>
	<td class="line x" title="121:232	But in NLI, where the ultimate goal is to maximize the number of inference problems answered correctly, it is more fitting to give all problems equal weight, and so we macro-average." ></td>
	<td class="line x" title="122:232	We have also generated all results using micro-averaging, and found that the relative comparisons are 806 port the exact match rate, that is, the proportion of problems in which the guessed alignment exactly matches the gold alignment." ></td>
	<td class="line x" title="123:232	The results are summarized in table 1." ></td>
	<td class="line x" title="124:232	5.1 A robust baseline: the bag-of-words aligner As a baseline, we use a simple alignment algorithm inspired by the lexical entailment model of Glickman et al.(2005), and similar to the simple heuristic model described in (Och and Ney, 2003)." ></td>
	<td class="line x" title="126:232	Each hypothesis word h is aligned to the premise word p to which it is most similar, according to a lexical similarity function sim(p,h) which returns scores in [0,1]." ></td>
	<td class="line x" title="127:232	While Glickman et al. used a function based on web co-occurrence statistics, we use a much simpler function based on string edit distance: sim(w1,w2) = 1 dist(lem(w1),lem(w2))max(|lem(w 1)|,|lem(w2)|) (Here lem(w) denotes the lemma of word w; dist() denotes Levenshtein string edit distance; and||denotes string length.)" ></td>
	<td class="line x" title="128:232	This model can be easily extended to generate an alignment score, which will be of interest in section 6." ></td>
	<td class="line x" title="129:232	We define the score for a specific hypothesis token h to be the log of its similarity with the premise token p to which it is aligned, and the score for the complete alignment of hypothesis H to premise P to be the sum of the scores of the tokens in H, weighted by inverse document frequency in a large corpus10 (so that common words get less weight), and normalized by the length of H: score(h|P) = logmax pP sim(p,h) score(H|P) = 1|H| summationdisplay hH idf(h)score(h|P) Despite the simplicity of this alignment model, its performance is fairly robust, with good recall." ></td>
	<td class="line x" title="130:232	Its precision, however, its mediocrechiefly because, by design, it aligns every h with some p. The model could surely be improved by allowing it to leave some H tokens unaligned, but this was not pursued." ></td>
	<td class="line x" title="131:232	not greatly affected." ></td>
	<td class="line x" title="132:232	10We use idf(w) = log(N/Nw), where N is the number of documents in the corpus, and Nw is the number of documents containing word w. System Data P % R % F1 % E % Bag-of-words dev 57.8 81.2 67.5 3.5 (baseline) test 62.1 82.6 70.9 5.3 GIZA++ dev 83.0 66.4 72.1 9.4 (using lex,) test 85.1 69.1 74.8 11.3 Cross-EM dev 67.6 80.1 72.1 1.3 (using lex,) test 70.3 81.0 74.1 0.8 Stanford RTE dev 81.1 61.2 69.7 0.5 test 82.7 61.2 70.3 0.3 Stanford RTE dev 81.1 75.8 78.4  (punct." ></td>
	<td class="line x" title="133:232	corr.)" ></td>
	<td class="line x" title="134:232	test 82.7 75.8 79.1  MANLI dev 83.4 85.5 84.4 21.7 (this work) test 85.4 85.3 85.3 21.3 Table 1: Performance of various aligners on the MSR RTE2 alignment data." ></td>
	<td class="line x" title="135:232	The columns show the data set used (800 problems each); average precision, recall, and F-measure; and the exact match rate (see text)." ></td>
	<td class="line x" title="136:232	5.2 MT aligners: GIZA++ and Cross-EM Given the importance of alignment for NLI, and the availability of standard, proven tools for MT alignment, an obvious question presents itself: why not use an off-the-shelf MT aligner for NLI?" ></td>
	<td class="line x" title="137:232	Although we have argued (section 2) that this is unlikely to succeed, to our knowledge, we are the first to investigate the matter empirically.11 The best-known MT aligner is undoubtedly GIZA++ (Och and Ney, 2003), which contains implementations of various IBM models (Brown et al., 1993), as well as the HMM model of Vogel et al.(1996)." ></td>
	<td class="line x" title="139:232	Most practitioners use GIZA++ as a black box, via the Moses MT toolkit (Koehn et al., 2007)." ></td>
	<td class="line x" title="140:232	We followed this practice, running with Moses default parameters on the RTE2 data to obtain asymmetric word alignments in both directions (P-to-H and H-to-P)." ></td>
	<td class="line x" title="141:232	We then performed symmetrization using the well-known INTERSECTION heuristic." ></td>
	<td class="line x" title="142:232	Unsurprisingly, the out-of-the-box performance was quite poor, with most words aligned apparently at random." ></td>
	<td class="line x" title="143:232	Precision was fair (72%) but recall was very poor (46%)." ></td>
	<td class="line x" title="144:232	Even equal words were usually not alignedbecause GIZA++ is designed for crosslinguistic use, it does not consider word equality between source and target sentences." ></td>
	<td class="line x" title="145:232	To remedy this, we supplied GIZA++ with a lexicon, using a trick 11However, Dolan et al.(2004) explore a closely-related topic: using an MT aligner to identify paraphrases." ></td>
	<td class="line x" title="147:232	807 common in MT: we supplemented the training data with synthetic data consisting of matched pairs of equal words." ></td>
	<td class="line x" title="148:232	This gives GIZA++ a better chance of learning that, e.g., man should align with man. The result was a big boost in recall (+23%), and a smaller gain in precision." ></td>
	<td class="line x" title="149:232	The results for GIZA++ shown in table 1 are based on using the lexicon and INTERSECTION." ></td>
	<td class="line x" title="150:232	With these settings, GIZA++ properly aligned most pairs of equal words, but continued to align other words apparently at random." ></td>
	<td class="line x" title="151:232	Next, we compared the performance of INTERSECTION with other symmetrization heuristics defined in Mosesincluding UNION, GROW, GROWDIAG, GROW-DIAG-FINAL (the default), and GROWDIAG-FINAL-ANDand with asymmetric alignments in both directions." ></td>
	<td class="line x" title="152:232	While all these alternatives achieved better recall than INTERSECTION, all showed substantially worse precision and F1." ></td>
	<td class="line x" title="153:232	On the RTE2 test set, the asymmetric alignment from H to P scored 68% in F1; GROW scored 58%; and all other alternatives scored below 52%." ></td>
	<td class="line x" title="154:232	As an additional experiment, we tested the CrossEM aligner (Liang et al., 2006) from the BerkeleyAligner package on the MSR data." ></td>
	<td class="line x" title="155:232	While this aligner is in many ways simpler than GIZA++ (it lacks any model of fertility, for example), its method of jointly training two simple asymmetric HMM models has outperformed GIZA++ on standard evaluations of MT alignment." ></td>
	<td class="line x" title="156:232	As with GIZA++, we experimented with a variety of symmetrization heuristics, and ran trials with and without a supplemental lexicon." ></td>
	<td class="line x" title="157:232	The results were broadly similar: INTERSECTION greatly outperformed alternative heuristics, and using a lexicon provided a big boost (up to 12% in F1)." ></td>
	<td class="line x" title="158:232	Under optimal settings, the CrossEM aligner showed better recall and worse precision than GIZA++, with F1 just slightly lower." ></td>
	<td class="line x" title="159:232	Like GIZA++, it did well at aligning equal words, but aligned most other words at random." ></td>
	<td class="line x" title="160:232	The mediocre performance of MT aligners on NLI alignment comes as no surprise, for reasons discussed in section 2." ></td>
	<td class="line x" title="161:232	Above all, the quantity of training data is simply too small for unsupervised learning to succeed." ></td>
	<td class="line x" title="162:232	A successful NLI aligner will need to exploit supervised training data, and will need access to additional sources of knowledge about lexical relatedness." ></td>
	<td class="line x" title="163:232	5.3 The Stanford RTE aligner A better comparison is thus to an alignment system expressly designed for NLI." ></td>
	<td class="line x" title="164:232	For this purpose, we used the alignment component of the Stanford RTE system (Chambers et al., 2007)." ></td>
	<td class="line x" title="165:232	The Stanford aligner performs decoding and learning in a similar fashion to MANLI, but uses a simpler, tokenbased alignment representation, along with a richer set of features for alignment scoring." ></td>
	<td class="line x" title="166:232	It represents alignments as an injective map from H tokens to P tokens." ></td>
	<td class="line x" title="167:232	Phrase alignments are not directly representable, although the effect can be approximated by a pre-processing step which collapses multi-token named entities and certain collocations into single tokens." ></td>
	<td class="line x" title="168:232	The features used for alignment scoring include not only measures of lexical similarity, but also syntactic features intended to promote the alignment of similar predicate-argument structures." ></td>
	<td class="line x" title="169:232	Despite this sophistication, the out-of-the-box performance of the Stanford aligner is mediocre, as shown in table 1." ></td>
	<td class="line x" title="170:232	The low recall figures are particularly noteworthy." ></td>
	<td class="line x" title="171:232	However, a partial explanation is readily available: by design, the Stanford system ignores punctuation.12 Because punctuation tokens constitute about 15% of the aligned pairs in the MSR data, this sharply reduces measured recall." ></td>
	<td class="line x" title="172:232	However, since punctuation matters little in inference, such recall errors probably should be forgiven." ></td>
	<td class="line x" title="173:232	Thus, table 1 also shows adjusted statistics for the Stanford system in which all recall errors involving punctuation are (generously) ignored." ></td>
	<td class="line x" title="174:232	Even after this adjustment, the recall figures are unimpressive." ></td>
	<td class="line x" title="175:232	Error analysis reveals that the Stanford aligner does a poor job of aligning function words." ></td>
	<td class="line x" title="176:232	About 13% of the aligned pairs in the MSR data are matching prepositions or articles; the Stanford aligner misses about 67% of such pairs." ></td>
	<td class="line x" title="177:232	(By contrast, MANLI misses only 10% of such pairs.)" ></td>
	<td class="line x" title="178:232	While function words matter less in inference than nouns and verbs, they are not irrelevant, and because sentences often contain multiple instances of a particular function word, matching them properly is by no means trivial." ></td>
	<td class="line x" title="179:232	If matching prepositions and articles were ignored (in addition to punctuation), the gap inF1 between the MANLI and Stanford systems 12In fact, it operates on a dependency-graph representation from which punctuation is omitted." ></td>
	<td class="line x" title="180:232	808 would narrow to about 2.8%." ></td>
	<td class="line x" title="181:232	Finally, the Stanford aligner is handicapped by its token-based alignment representation, often failing (partly or completely) to align multi-word phrases such as peace activists with protesters, or hackers with non-authorized personnel." ></td>
	<td class="line x" title="182:232	5.4 The MANLI aligner As table 1 indicates, the MANLI aligner was found to outperform all other aligners evaluated on every measure of performance, achieving an F1 score 10.5% higher than GIZA++ and 6.2% higher than the Stanford aligner (even with the punctuation correction).13 MANLI achieved a good balance between precision and recall, and matched more than 20% of the gold-standard alignments exactly." ></td>
	<td class="line x" title="183:232	Three factors seem to have contributed most to MANLIs success." ></td>
	<td class="line x" title="184:232	First, MANLI is able to outperform the MT aligners principally because it is able to leverage lexical resources to identify the similarity between pairs of words such as jail and prison, prevent and stop, or injured and wounded." ></td>
	<td class="line x" title="185:232	Second, MANLIs contextual features enable it to do better than the Stanford aligner at matching function words, a weakness of the Stanford aligner discussed in section 5.3." ></td>
	<td class="line x" title="186:232	Third, MANLI gains a marginal advantage because its phrase-based representation of alignment permits it to properly align phrase pairs such as death penalty and capital punishment, or abdicate and give up." ></td>
	<td class="line x" title="187:232	However, the phrase-based representation contributed far less than we had hoped." ></td>
	<td class="line x" title="188:232	Setting MANLIs maximum phrase size to 1 (effectively, restricting it to token-based alignments) caused F1 to fall by just 0.2%." ></td>
	<td class="line x" title="189:232	We do not interpret this to mean that phrase alignments are not usefulindeed, about 2.6% of the links in the gold-standard data involve phrases of size > 1." ></td>
	<td class="line x" title="190:232	Rather, we think it shows that we have failed to fully exploit the advantages of the phrase-based representation, chiefly because we lack lexical resources providing good information on similarity of multi-word phrases." ></td>
	<td class="line x" title="191:232	Error analysis suggests that there is ample room for improvement." ></td>
	<td class="line x" title="192:232	A large proportion of recall errors (perhaps 40%) occur because the lexical similarity function assigns too low a value to pairs of words 13Reported results for MANLI are averages over 10 runs." ></td>
	<td class="line x" title="193:232	or phrases which are clearly similar, such as conservation and protecting, server and computer networks, organization and agencies, or bone fragility and osteoporosis." ></td>
	<td class="line x" title="194:232	Better exploitation of lexical resources could help to reduce such errors." ></td>
	<td class="line x" title="195:232	Another important category of recall errors (about 12%) result from the failure to identify oneand multi-word versions of the name of some entity, such as Lennon and John Lennon, or Nike Inc. and Nike." ></td>
	<td class="line x" title="196:232	A specialpurpose similarity function could help here." ></td>
	<td class="line x" title="197:232	Note, however, that about 10% of recall errors are unavoidable, given our choice of alignment representation, since they involve cases where the gold standard aligns one or more tokens on one side to a noncontiguous set of tokens on the other side." ></td>
	<td class="line x" title="198:232	Precision errors may be harder to reduce." ></td>
	<td class="line x" title="199:232	These errors are dominated by cases where we mistakenly align two equal function words (49% of precision errors), two forms of the verb to be (21%), two equal punctuation marks (7%), or two words or phrases of other types having equal lemmas (18%)." ></td>
	<td class="line x" title="200:232	Because such errors often occur because the aligner is forced to choose between nearly equivalent alternatives, they may be difficult to eliminate." ></td>
	<td class="line x" title="201:232	The remaining 5% of precision errors result mostly from aligning words or phrases rightly judged to be highly similar, such as expanding and increasing, labor and birth, figures and number, or 223,000 and 220,000." ></td>
	<td class="line x" title="202:232	6 Using alignment to predict RTE answers In section 5, we evaluated the ability of aligners to recover gold-standard alignments." ></td>
	<td class="line x" title="203:232	But since alignment is just one component of the NLI problem, we might also examine the impact of different aligners on the ability to recognize valid inferences." ></td>
	<td class="line x" title="204:232	If a high-scoring alignment indicates a close correspondence between H and P, does this also indicate a valid inference?" ></td>
	<td class="line x" title="205:232	We have previously emphasized (MacCartney et al., 2006) that there is more to inferential validity than close lexical or structural correspondence: negations, modals, non-factive and implicative verbs, and other linguistic constructs can affect validity in ways hard to capture in alignment." ></td>
	<td class="line x" title="206:232	Nevertheless, alignment score can be a strong predictor of inferential validity, and some NLI systems (e.g., (Glickman et al., 2005)) rely entirely on some measure of alignment quality to predict validity." ></td>
	<td class="line x" title="207:232	809 System data acc % avgP % Bag-of-words aligner dev 61.3 61.5 test 57.9 58.9 Stanford RTE aligner dev 63.1 64.9 test 60.9 59.2 MANLI aligner dev 59.3 69.0 (this work) test 60.3 61.0 RTE2 entries (average) test 58.5 59.1 LCC (Hickl et al., 2006) test 75.4 80.8 Table 2: Performance of various aligners and complete RTE systems in predicting RTE2 answers." ></td>
	<td class="line x" title="208:232	The columns show the data set used, accuracy, and average precision (the recommended metric for RTE2)." ></td>
	<td class="line x" title="209:232	If an aligner generates real-valued alignment scores, we can use the RTE data to test its ability to predict inferential validity with the following simple method." ></td>
	<td class="line x" title="210:232	For a given RTE problem, we predict YES (valid) if its alignment score14 exceeds a threshold , and NO otherwise." ></td>
	<td class="line x" title="211:232	We tune  to maximize accuracy on the RTE2 development set, and then measure performance on the RTE2 test set using the same ." ></td>
	<td class="line x" title="212:232	Table 2 shows results for several NLI aligners, along with some results for complete RTE systems, including the LCC system (the top performer at RTE2) and an average of all systems participating in RTE2." ></td>
	<td class="line x" title="213:232	While none of the aligners rivals the performance of the LCC system, all achieve respectable results, and the Stanford and MANLI aligners outperform the average RTE2 entry." ></td>
	<td class="line x" title="214:232	Thus, even if alignment quality does not determine inferential validity, many NLI systems could be improved by harnessing a well-designed NLI aligner." ></td>
	<td class="line x" title="215:232	7 Related work Given the extensive literature on phrase-based MT, it may be helpful further to situate our phrase-based alignment model in relation to past work." ></td>
	<td class="line x" title="216:232	The standard approach to training a phrase-based MT system is to apply phrase extraction heuristics using wordaligned training sets (Och and Ney, 2003; Koehn et al., 2007)." ></td>
	<td class="line x" title="217:232	Unfortunately, word alignment models assume that source words are individually trans14For good results, it may be necessary to normalize the alignment score." ></td>
	<td class="line x" title="218:232	Scores from MANLI were normalized by the number of tokens in the problem." ></td>
	<td class="line x" title="219:232	The Stanford aligner performs a similar normalization internally." ></td>
	<td class="line x" title="220:232	lated into target words, which stands at odds with the key assumption in phrase-based systems that many translations are non-compositional." ></td>
	<td class="line x" title="221:232	More recently, several works (Marcu and Wong, 2002; DeNero et al., 2006; Birch et al., 2006; DeNero and Klein, 2008) have presented more unified phrasebased systems that jointly align and weight phrases, though these systems have not come close to the state of the art when evaluated in terms of MT performance." ></td>
	<td class="line x" title="222:232	We would argue that previous work in MT phrase alignment is orthogonal to our work." ></td>
	<td class="line x" title="223:232	In MANLI, the need for phrases arises when word-based representations are not appropriate for alignment (e.g., between close down and terminate), though longer phrases are not needed to achieve good alignment quality." ></td>
	<td class="line x" title="224:232	In MT phrase alignment, it is beneficial to account for arbitrarily large phrases, since the larger contexts offered by these phrases can help realize more dependencies among translated words (e.g., word order, agreement, subcategorization)." ></td>
	<td class="line x" title="225:232	Perhaps because MT phrase alignment is dealing with much larger contexts, no existing work in MT phrase alignment (to our knowledge) directly models word insertions and deletions, as in MANLI." ></td>
	<td class="line x" title="226:232	For example, in figure 1, MANLI can just skip In most Pacific countries there, while an MT phrase-based model would presumably align In most Pacific countries there are to Women are." ></td>
	<td class="line x" title="227:232	Hence, previous work is of limited applicability to our problem." ></td>
	<td class="line x" title="228:232	8 Conclusion While MT aligners succeed by unsupervised learning of word correspondences from massive amounts of bitext, NLI aligners are forced to rely on smaller quantities of supervised training data." ></td>
	<td class="line x" title="229:232	With the MANLI system, we have demonstrated how to overcome this lack of data by utilizing external lexical resources, and how to gain additional power from a phrase-based representation of alignment." ></td>
	<td class="line x" title="230:232	Acknowledgements The authors wish to thank the anonymous reviewers for their helpful comments on an earlier draft of this paper." ></td>
	<td class="line x" title="231:232	This paper is based on work funded in part by the Defense Advanced Research Projects Agency through IBM and in part by the CIA ATP as part of the OCCAM project." ></td>
	<td class="line x" title="232:232	810" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="D08-1103
Computing Word-Pair Antonymy
Mohammad, Saif;Dorr, Bonnie Jean;Hirst, Graeme;"></td>
	<td class="line x" title="1:257	Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 982991, Honolulu, October 2008." ></td>
	<td class="line x" title="2:257	c2008 Association for Computational Linguistics Computing Word-Pair Antonymy Saif Mohammad Bonnie Dorra0 Graeme Hirst a0 Laboratory for Computational Linguistics and Information Processing a0 Institute for Advanced Computer Studies and a0 Computer Science a0 University of Maryland and a0 Human Language Technology Center of Excellence a1 saif,bonnie a2 @umiacs.umd.edu Department of Computer Science University of Toronto gh@cs.toronto.edu Abstract Knowing the degree of antonymy between words has widespread applications in natural language processing." ></td>
	<td class="line x" title="3:257	Manually-created lexicons have limited coverage and do not include most semantically contrasting word pairs." ></td>
	<td class="line x" title="4:257	We present a new automatic and empirical measure of antonymy that combines corpus statistics with the structure of a published thesaurus." ></td>
	<td class="line x" title="5:257	The approach is evaluated on a set of closest-opposite questions, obtaining a precision of over 80%." ></td>
	<td class="line x" title="6:257	Along the way, we discuss what humans consider antonymous and how antonymy manifests itself in utterances." ></td>
	<td class="line x" title="7:257	1 Introduction Native speakers of a language intuitively recognize different degrees of antonymywhether two words are strongly antonymous (hotcold, good bad, friendenemy), just semantically contrasting (enemyfan, coldlukewarm, ascendslip) or not antonymous at all (penguinclown, coldchilly, boatrudder)." ></td>
	<td class="line x" title="8:257	Over the years, many definitions of antonymy have been proposed by linguists (Cruse, 1986; Lehrer and Lehrer, 1982), cognitive scientists (Kagan, 1984), psycholinguists (Deese, 1965), and lexicographers (Egan, 1984), which differ from each other in small and large respects." ></td>
	<td class="line x" title="9:257	In its strictest sense, antonymy applies to gradable adjectives, such as hotcold and tallshort, where the two words represent the two ends of a semantic dimension." ></td>
	<td class="line x" title="10:257	In a broader sense, it includes other adjectives, nouns, and verbs as well (lifedeath, ascenddescend, shoutwhisper)." ></td>
	<td class="line x" title="11:257	In its broadest sense, it applies to any two words that represent contrasting meanings." ></td>
	<td class="line x" title="12:257	We will use the term degree of antonymy to encompass the complete semantic rangea combined measure of the contrast in meaning conveyed by two words and the tendency of native speakers to call them opposites." ></td>
	<td class="line x" title="13:257	The higher the degree of antonymy between a target word pair, the greater the semantic contrast between them and the greater their tendency to be considered antonym pairs by native speakers." ></td>
	<td class="line x" title="14:257	Automatically determining the degree of antonymy between words has many uses including detecting and generating paraphrases (The dementors caught Sirius Black / Black could not escape the dementors) and detecting contradictions (Marneffe et al., 2008; Voorhees, 2008) (Kyoto has a predominantly wet climate / It is mostly dry in Kyoto)." ></td>
	<td class="line x" title="15:257	Of course, such contradictions may be a result of differing sentiment, new information, non-coreferent mentions, or genuinely contradictory statements." ></td>
	<td class="line x" title="16:257	Antonyms often indicate the discourse relation of contrast (Marcu and Echihabi, 2002)." ></td>
	<td class="line x" title="17:257	They are also useful for detecting humor (Mihalcea and Strapparava, 2005), as satire and jokes tend to have contradictions and oxymorons." ></td>
	<td class="line x" title="18:257	Lastly, it is useful to know which words are semantically contrasting to a target word, even if simply to filter them out." ></td>
	<td class="line x" title="19:257	For example, in the automatic creation of a thesaurus it is necessary to distinguish nearsynonyms from word pairs that are semantically contrasting." ></td>
	<td class="line x" title="20:257	Measures of distributional similarity fail to do so." ></td>
	<td class="line x" title="21:257	Detecting antonymous words is not sufficient to solve most of these problems, but it remains a crucial, and largely unsolved, component." ></td>
	<td class="line x" title="22:257	982 Lexicons of pairs of words that native speakers consider antonyms have been created for certain languages, but their coverage has been limited." ></td>
	<td class="line x" title="23:257	Further, as each term of an antonymous pair can have many semantically close terms, the contrasting word pairs far outnumber those that are commonly considered antonym pairs, and they remain unrecorded." ></td>
	<td class="line x" title="24:257	Even though a number of computational approaches have been proposed for semantic closeness, and some for hypernymyhyponymy (Hearst, 1992), measures of antonymy have been less successful." ></td>
	<td class="line x" title="25:257	To some extent, this is because antonymy is not as well understood as other classical lexical-semantic relations." ></td>
	<td class="line x" title="26:257	We first very briefly summarize insights and intuitions about this phenomenon, as proposed by linguists and lexicographers (Section 2)." ></td>
	<td class="line x" title="27:257	We discuss related work (Section 3)." ></td>
	<td class="line x" title="28:257	We describe the resources we use (Section 4) and present experiments that examine the manifestation of antonymy in text (Sections 5 and 6)." ></td>
	<td class="line x" title="29:257	We then propose a new empirical approach to determine the degree of antonymy between two words (Section 7)." ></td>
	<td class="line x" title="30:257	We compiled a dataset of 950 closest-opposite questions, which we used for evaluation (Section 8)." ></td>
	<td class="line x" title="31:257	We conclude with a discussion of the merits and limitations of this approach and outline future work." ></td>
	<td class="line x" title="32:257	2 The paradoxes of antonymy Antonymy, like synonymy and hyponymy, is a lexical-semantic relation that, strictly speaking, applies to two lexical unitscombinations of surface form and word sense." ></td>
	<td class="line x" title="33:257	(That said, for simplicity and where appropriate we will use the term antonymous words as a proxy for antonymous lexical units.)" ></td>
	<td class="line x" title="34:257	However, accepting this leads to two interesting and seemingly paradoxical questions (described below in the two subsections)." ></td>
	<td class="line x" title="35:257	2.1 Why are some pairs better antonyms?" ></td>
	<td class="line x" title="36:257	Native speakers of a language consider certain contrasting word pairs to be antonymous (for example, largesmall), and certain other seemingly equivalent word pairs as less so (for example, largelittle)." ></td>
	<td class="line x" title="37:257	A number of reasons have been suggested: (1) Cruse (1986) observes that if the meaning of the target words is completely defined by one semantic dimension and the words represent the two ends of this semantic dimension, then they tend to be considered antonyms." ></td>
	<td class="line x" title="38:257	We will refer to this semantic dimension as the dimension of opposition." ></td>
	<td class="line x" title="39:257	(2) If on the other hand, as Lehrer and Lehrer (1982) point out, there is more to the meaning of the antonymous words than the dimension of oppositionfor example, more semantic dimensions or added connotationsthen the two words are not so strongly antonymous." ></td>
	<td class="line x" title="40:257	Most people do not think of chubby as a direct antonym of thin because it has the additional connotation of being cute and informal." ></td>
	<td class="line x" title="41:257	(3) Cruse (1986) also postulates that word pairs are not considered strictly antonymous if it is difficult to identify the dimension of opposition (for example, cityfarm)." ></td>
	<td class="line x" title="42:257	(4) Charles and Miller (1989) claim that two contrasting words are identified as antonyms if they occur together in a sentence more often than chance." ></td>
	<td class="line x" title="43:257	However, Murphy and Andrew (1993) claim that the greater-thanchance co-occurrence of antonyms in sentences is because together they convey contrast well, which is rhetorically useful, and not really the reason why they are considered antonyms in the first place." ></td>
	<td class="line x" title="44:257	2.2 Are semantic closeness and antonymy opposites?" ></td>
	<td class="line x" title="45:257	Two words (more precisely, two lexical units) are considered to be close in meaning if there is a lexical-semantic relation between them." ></td>
	<td class="line x" title="46:257	Lexicalsemantic relations are of two kinds: classical and non-classical." ></td>
	<td class="line x" title="47:257	Examples of classical relations include synonymy, hyponymy, troponymy, and meronymy." ></td>
	<td class="line x" title="48:257	Non-classical relations, as pointed out by Morris and Hirst (2004), are much more common and include concepts pertaining to another concept (kind, chivalrous, formal pertaining to gentlemanly), and commonly co-occurring words (for example, problemsolution pairs such as homeless, shelter)." ></td>
	<td class="line x" title="49:257	Semantic distance (or closeness) in this broad sense is known as semantic relatedness." ></td>
	<td class="line x" title="50:257	Two words are considered to be semantically similar if they are associated via the synonymy, hyponymy hypernymy, or the troponymy relation." ></td>
	<td class="line x" title="51:257	So terms that are semantically similar (planeglider, doctor surgeon) are also semantically related, but terms that are semantically related may not always be semantically similar (planesky, surgeonscalpel)." ></td>
	<td class="line x" title="52:257	Antonymy is unique among these relations because it simultaneously conveys both a sense of 983 closeness and of distance (Cruse, 1986)." ></td>
	<td class="line x" title="53:257	Antonymous concepts are semantically related but not semantically similar." ></td>
	<td class="line x" title="54:257	3 Related work Charles and Miller (1989) proposed that antonyms occur together in a sentence more often than chance." ></td>
	<td class="line x" title="55:257	This is known as the co-occurrence hypothesis." ></td>
	<td class="line x" title="56:257	They also showed that this was empirically true for four adjective antonym pairs." ></td>
	<td class="line x" title="57:257	Justeson and Katz (1991) demonstrated the co-occurrence hypothesis for 35 prototypical antonym pairs (from an original set of 39 antonym pairs compiled by Deese (1965)) and also for an additional 22 frequent antonym pairs." ></td>
	<td class="line x" title="58:257	All of these pairs were adjectives." ></td>
	<td class="line x" title="59:257	Fellbaum (1995) conducted similar experiments on 47 noun, verb, adjective, and adverb pairs (nounnoun, nounverb, nounadjective, verbadverb and so on) pertaining to 18 concepts (for example, lose(v)gain(n) and loss(n)gain(n), where lose(v) and loss(n) pertain to the concept of failing to have/maintain)." ></td>
	<td class="line x" title="60:257	However, non-antonymous semantically related words such as hypernyms, holonyms, meronyms, and nearsynonyms also tend to occur together more often than chance." ></td>
	<td class="line x" title="61:257	Thus, separating antonyms from them has proven to be difficult." ></td>
	<td class="line x" title="62:257	Lin et al.(2003) used patterns such as from X to Y and either X or Y to separate antonym word pairs from distributionally similar pairs." ></td>
	<td class="line x" title="64:257	They evaluated their method on 80 pairs of antonyms and 80 pairs of synonyms taken from the Websters Collegiate Thesaurus (Kay, 1988)." ></td>
	<td class="line x" title="65:257	In this paper, we propose a method to determine the degree of antonymy between any word pair and not just those that are distributionally similar." ></td>
	<td class="line x" title="66:257	Turney (2008) proposed a uniform method to solve word analogy problems that require identifying synonyms, antonyms, hypernyms, and other lexical-semantic relations between word pairs." ></td>
	<td class="line x" title="67:257	However, the Turney method is supervised whereas the method proposed in this paper is completely unsupervised." ></td>
	<td class="line x" title="68:257	Harabagiu et al.(2006) detected antonyms for the purpose of identifying contradictions by using WordNet chainssynsets connected by the hypernymyhyponymy links and exactly one antonymy link." ></td>
	<td class="line x" title="70:257	Lucerto et al.(2002) proposed detecting antonym pairs using the number of words between two words in text and also cue words such as but, from, and and." ></td>
	<td class="line x" title="72:257	Unfortunately, they evaluated their method on only 18 word pairs." ></td>
	<td class="line x" title="73:257	Neither of these methods determines the degree of antonymy between words and they have not been shown to have substantial coverage." ></td>
	<td class="line x" title="74:257	Schwab et al.(2002) create antonymous vector for a target word." ></td>
	<td class="line x" title="76:257	The closer this vector is to the context vectors of the other target word, the more antonymous the two target words are." ></td>
	<td class="line x" title="77:257	However, the antonymous vectors are manually created." ></td>
	<td class="line x" title="78:257	Further, the approach is not evaluated beyond a handful of word pairs." ></td>
	<td class="line x" title="79:257	Work in sentiment detection and opinion mining aims at determining the polarity of words." ></td>
	<td class="line x" title="80:257	For example, Pang, Lee and Vaithyanathan (2002) detect that adjectives such as dazzling, brilliant, and gripping cast their qualifying nouns positively whereas adjectives such as bad, cliched, and boring portray the noun negatively." ></td>
	<td class="line x" title="81:257	Many of these gradable adjectives have antonyms." ></td>
	<td class="line x" title="82:257	but these approaches do not attempt to determine pairs of positive and negative polarity words that are antonyms." ></td>
	<td class="line x" title="83:257	4 Resources 4.1 Published thesauri Published thesauri, such as the Rogets and Macquarie, divide the vocabulary into about a thousand categories." ></td>
	<td class="line x" title="84:257	Words within a category tend to be nearsynonymous or semantically similar." ></td>
	<td class="line x" title="85:257	One may also find antonymous and semantically related words in the same category, but this is rare." ></td>
	<td class="line x" title="86:257	The intuition is that words within a category represent a coarse concept." ></td>
	<td class="line x" title="87:257	Words with more than one meaning may be found in more than one category; these represent its coarse senses." ></td>
	<td class="line x" title="88:257	Within a category, the words are grouped into paragraphs." ></td>
	<td class="line x" title="89:257	Words in the same paragraph tend to be closer in meaning than those in different paragraphs." ></td>
	<td class="line x" title="90:257	We will take advantage of the structure of the thesaurus in our approach." ></td>
	<td class="line x" title="91:257	4.2 WordNet Unlike the traditional approach to antonymy, WordNet encodes antonymy as a lexical relationshipa relation between two words (not concepts) (Gross et al., 1989)." ></td>
	<td class="line x" title="92:257	Even though a synset (a WordNet concept) may be represented by more than one word, individual words across synsets are marked as (di984 rect) antonyms." ></td>
	<td class="line x" title="93:257	Gross et al. argue that other words in the synsets form indirect antonyms." ></td>
	<td class="line x" title="94:257	Even after including the indirect antonyms, WordNets coverage is limited." ></td>
	<td class="line x" title="95:257	As Marcu and Echihabi (2002) point out, WordNet does not encode antonymy across part-of-speech (for example, legallyembargo)." ></td>
	<td class="line x" title="96:257	Further, the nounnoun, verbverb, and adjectiveadjective antonym pairs of WordNet largely ignore near-opposites as revealed by our experiments (Section 8 below)." ></td>
	<td class="line x" title="97:257	Also, WordNet (or any other manually-created repository of antonyms for that matter) does not encode the degree of antonymy between words." ></td>
	<td class="line x" title="98:257	Nevertheless, we investigate the usefulness of WordNet as a source of seed antonym pairs for our approach." ></td>
	<td class="line x" title="99:257	4.3 Co-occurrence statistics The distributional hypothesis of closeness states that words that occur in similar contexts tend to be semantically close (Firth, 1957)." ></td>
	<td class="line oc" title="100:257	Distributional measures of distance, such as those proposed by Lin (1998), quantify how similar the two sets of contexts of a target word pair are." ></td>
	<td class="line o" title="101:257	Equation 1 is a modified form of Lins measure that ignores syntactic dependencies and hence it estimates semantic relatedness rather than semantic similarity: Lina0 w1 a1 w2 a2a4a3 w a5 T a6 w1 a7a9a8 T a6 w2 a7 a0 Ia0 w1 a1 w a2a11a10 Ia0 w2 a1 w a2a12a2 w a13a14a5 T a6 w1 a7 Ia0 w1 a1 wa15 a2a16a10 w a13a13a17a5 T a6 w2 a7 Ia0 w2 a1 wa15 a15 a2 (1) Here w1 and w2 are the target words; Ia0 x a1 y a2 is the pointwise mutual information between x and y; and T a0 x a2 is the set of all words y that have positive pointwise mutual information with the word x (Ia0 x a1 y a2a19a18 0)." ></td>
	<td class="line x" title="102:257	Mohammad and Hirst (2006) showed that these distributional word-distance measures perform poorly when compared with WordNet-based concept-distance measures." ></td>
	<td class="line x" title="103:257	They argued that this is because the word-distance measures clump together the contexts of the different senses of the target words." ></td>
	<td class="line o" title="104:257	They proposed a way to obtain distributional distance between word senses, using any of the distributional measures such as cosine or that proposed by Lin, and showed that this approach performed markedly better than the traditional worddistance approach." ></td>
	<td class="line x" title="105:257	They used thesaurus categories as very coarse word senses." ></td>
	<td class="line o" title="106:257	Equation 2 shows how Lins formula is used to determine distributional distance between two thesaurus categories c1 and c2: Lina0 c1 a1 c2 a2a4a3 w a5 T a6 c1 a7a9a8 T a6 c2 a7 a0 Ia0 c1 a1 w a2a16a10 Ia0 c2 a1 w a2a12a2 w a13a17a5 T a6 c1 a7 Ia0 c1 a1 wa15 a2a11a10 wa13a13a17a5 T a6 c2 a7 Ia0 c2 a1 wa15a15 a2 (2) Here T a0 c a2 is the set of all words w that have positive pointwise mutual information with the thesaurus category c (Ia0 c a1 w a2a20a18 0)." ></td>
	<td class="line x" title="107:257	We adopt this method for use in our approach to determine word-pair antonymy." ></td>
	<td class="line x" title="108:257	5 The co-occurrence hypothesis of antonyms As a first step towards formulating our approach, we investigated the co-occurrence hypothesis on a significantly larger set of antonym pairs than those studied before." ></td>
	<td class="line x" title="109:257	We randomly selected a thousand antonym pairs (nouns, verbs, and adjectives) from WordNet and counted the number of times (1) they occurred individually and (2) they co-occurred in the same sentence within a window of five words, in the British National Corpus (BNC) (Burnard, 2000)." ></td>
	<td class="line x" title="110:257	We then calculated the mutual information for each of these word pairs and averaged it." ></td>
	<td class="line x" title="111:257	We randomly generated another set of a thousand word pairs, without regard to whether they were antonymous or not, and used it as a control set." ></td>
	<td class="line x" title="112:257	The average mutual information between the words in the antonym set was 0.94 with a standard deviation of 2.27." ></td>
	<td class="line x" title="113:257	The average mutual information between the words in the control set was 0.01 with a standard deviation of 0.37." ></td>
	<td class="line x" title="114:257	Thus antonymous word pairs occur together much more often than chance irrespective of their intended senses (p a21 0a22 01)." ></td>
	<td class="line x" title="115:257	Of course, a number of nonantonymous words also tend to co-occur more often than chancecommonly known as collocations." ></td>
	<td class="line x" title="116:257	Thus, strong co-occurrence is not a sufficient condition for detecting antonyms, but these results show that it can be a useful cue." ></td>
	<td class="line x" title="117:257	6 The substitutional and distributional hypotheses of antonyms Charles and Miller (1989) also proposed that in most contexts, antonyms may be interchanged." ></td>
	<td class="line x" title="118:257	The 985 meaning of the utterance will be inverted, of course, but the sentence will remain grammatical and linguistically plausible." ></td>
	<td class="line x" title="119:257	This came to be known as the substitutability hypothesis." ></td>
	<td class="line x" title="120:257	However, their experiments did not support this claim." ></td>
	<td class="line x" title="121:257	They found that given a sentence with the target adjective removed, most people did not confound the missing word with its antonym." ></td>
	<td class="line x" title="122:257	Justeson and Katz (1991) later showed that in sentences that contain both members of an antonymous adjective pair, the target adjectives do indeed occur in similar syntactic structures at the phrasal level." ></td>
	<td class="line x" title="123:257	From this (and to some extent from the co-occurrence hypothesis), we can derive the distributional hypothesis of antonyms: antonyms occur in similar contexts more often than non-antonymous words." ></td>
	<td class="line x" title="124:257	We used the same set of one thousand antonym pairs and one thousand control pairs as in the previous experiment to gather empirical proof of the distributional hypothesis." ></td>
	<td class="line oc" title="125:257	For each word pair from the antonym set, we calculated the distributional distance between each of their senses using Mohammad and Hirsts (2006) method of concept distance along with the modified form of Lins (1998) distributional measure (equation 2)." ></td>
	<td class="line x" title="126:257	The distance between the closest senses of the word pairs was averaged for all thousand antonyms." ></td>
	<td class="line x" title="127:257	The process was then repeated for the control set." ></td>
	<td class="line x" title="128:257	The control set had an average semantic closeness of 0.23 with a standard deviation of 0.11 on a scale from 0 (unrelated) to 1 (identical)." ></td>
	<td class="line x" title="129:257	On the other hand, antonymous word pairs had an average semantic closeness of 0.30 with a standard deviation of 0.23.1 This demonstrates that relative to other word pairs, antonymous words tend to occur in similar contexts (p a21 0a22 01)." ></td>
	<td class="line x" title="130:257	However, near-synonymous and similar word pairs also occur in similar contexts." ></td>
	<td class="line x" title="131:257	(the distributional hypothesis of closeness)." ></td>
	<td class="line x" title="132:257	Thus, just like the co-occurrence hypothesis, occurrence in similar contexts is not sufficient, but rather yet another useful cue towards detecting antonyms." ></td>
	<td class="line x" title="133:257	1It should be noted that absolute values in the range between 0 and 1 are meaningless by themselves." ></td>
	<td class="line x" title="134:257	However, if a set of word pairs is shown to consistently have higher values than another set, then we can conclude that the members of the former set tend to be semantically closer than those of the latter." ></td>
	<td class="line x" title="135:257	7 Our approach We now present an empirical approach to determine the degree of antonymy between words." ></td>
	<td class="line x" title="136:257	In order to maximize applicability and usefulness in natural language applications, we model the broad sense of antonymy." ></td>
	<td class="line x" title="137:257	Given a target word pair, the approach determines whether they are antonymous or not, and if they are antonymous whether they have a high, medium, or low degree of antonymy." ></td>
	<td class="line x" title="138:257	More precisely, the approach presents a way to determine whether one word pair is more antonymous than another." ></td>
	<td class="line x" title="139:257	The approach relies on the structure of the published thesaurus as well as the co-occurrence and distributional hypotheses." ></td>
	<td class="line x" title="140:257	As mentioned earlier, a thesaurus organizes words in sets representing concepts or categories." ></td>
	<td class="line x" title="141:257	We first determine pairs of thesaurus categories that are contrasting in meaning (Section 7.1)." ></td>
	<td class="line x" title="142:257	We then use the co-occurrence and distributional hypotheses to determine the degree of antonymy (Section 7.2)." ></td>
	<td class="line x" title="143:257	7.1 Detecting contrasting categories We propose two ways of detecting thesaurus category pairs that represent contrasting concepts (we will call these pairs contrasting categories): (1) using a seed set of antonyms and (2) using a simple heuristic that exploits how thesaurus categories are ordered." ></td>
	<td class="line x" title="144:257	7.1.1 Seed sets Affix-generated seed set Antonym pairs such as hotcold and darklight occur frequently in text, but in terms of type-pairs they are outnumbered by those created using affixes, such as un(clear unclear) and dis(honestdishonest)." ></td>
	<td class="line x" title="145:257	Further, this phenomenon is observed in most languages (Lyons, 1977)." ></td>
	<td class="line x" title="146:257	Table 1 lists sixteen morphological rules that tend to generate antonyms in English." ></td>
	<td class="line x" title="147:257	These rules were applied to each of the words in the Macquarie Thesaurus and if the resulting term was also a valid word in the thesaurus, then the word-pair was added to the affix-generated seed set." ></td>
	<td class="line x" title="148:257	These sixteen rules generated 2,734 word pairs." ></td>
	<td class="line x" title="149:257	Of course, not all of them are antonymous, for example sectinsect and coydecoy." ></td>
	<td class="line x" title="150:257	However, these are relatively few in 986 w1 w2 example pair w1 w2 example pair w1 w2 example pair X abX normalabnormal X misX fortunemisfortune imX exX implicitexplicit X antiX clockwiseanticlockwise X nonX alignednonaligned inX exX introvertextrovert X disX interestdisinterest X unX biasedunbiased upX downX uphilldownhill X imX possibleimpossible lX illX legalillegal overX underX overdoneunderdone X inX consistentinconsistent rX irX regularirregular Xless Xful harmlessharmful X malX adroitmaladroit Table 1: Sixteen affix rules to generate antonym pairs." ></td>
	<td class="line x" title="151:257	Here X stands for any sequence of letters common to both words w1 and w2." ></td>
	<td class="line x" title="152:257	number and were found to have only a small impact on the results." ></td>
	<td class="line x" title="153:257	WordNet seed set We compiled a list of 20,611 semantically contrasting word pairs from WordNet." ></td>
	<td class="line x" title="154:257	If two words from two synsets in WordNet are connected by an antonymy link, then every possible word pair across the two synsets was considered to be semantically contrasting." ></td>
	<td class="line x" title="155:257	A large number of them include multiword expressions." ></td>
	<td class="line x" title="156:257	For only 10,807 of the 20,611 pairs were both words found in the Macquarie Thesaurusthe vocabulary used for our experiments." ></td>
	<td class="line x" title="157:257	We will refer to them as the WordNet seed set." ></td>
	<td class="line x" title="158:257	Then, given these two seed sets, if any word in thesaurus category C1 is antonymous to any word in category C2 as per a seed antonym pair, then the two categories are marked as contrasting." ></td>
	<td class="line x" title="159:257	It should be noted, however, that the seed antonym pair may be antonymous only in certain senses." ></td>
	<td class="line x" title="160:257	For example, consider the antonym pair workplay." ></td>
	<td class="line x" title="161:257	Here, play is antonymous to work only in its ACTIVITY FOR FUN sense and not its DRAMA sense." ></td>
	<td class="line x" title="162:257	In such cases, we employ the distributional hypothesis of closeness: two words are antonymous to each other in those senses which are closest in meaning to each other." ></td>
	<td class="line x" title="163:257	Since the thesaurus category pertaining to WORK is relatively closer in meaning to the ACTIVITY FOR FUN sense than the DRAMA sense, those two categories will be considered contrasting and not the categories pertaining to WORK and DRAMA." ></td>
	<td class="line x" title="164:257	If no word in C1 is antonymous to any word in C2, then the categories are considered not contrasting." ></td>
	<td class="line x" title="165:257	As the seed sets, both automatically generated and manually created, are relatively large in comparison to the total number of categories in the Macquarie Thesaurus (812), this simple approach has reasonable coverage and accuracy." ></td>
	<td class="line x" title="166:257	7.1.2 Order of thesaurus categories Most published thesauri are ordered such that contrasting categories tend to be adjacent." ></td>
	<td class="line x" title="167:257	This is not a hard-and-fast rule, and often a category may be contrasting in meaning to several other categories." ></td>
	<td class="line x" title="168:257	Further, often adjacent categories are not semantically contrasting." ></td>
	<td class="line x" title="169:257	However, since this was an easyenough heuristic to implement, we investigated the usefulness of considering adjacent categories as contrasting." ></td>
	<td class="line x" title="170:257	We will refer to this as the adjacency heuristic." ></td>
	<td class="line x" title="171:257	7.2 Determining the degree of antonymy Once we know which category pairs are contrasting (using the methods from the previous subsection), we determine the degree of antonymy between the two categories (Section 7.2.1)." ></td>
	<td class="line x" title="172:257	The aim is to assign contrasting category pairs a non-zero value signifying the degree of contrast." ></td>
	<td class="line x" title="173:257	In turn, we will use that information to determine the degree of antonymy between any word pair whose members belong to two contrasting categories (Sections 7.2.2 and 7.2.3)." ></td>
	<td class="line x" title="174:257	7.2.1 Category level Using the distributional hypothesis of antonyms, we claim that the degree of antonymy between two contrasting concepts (thesaurus categories) is directly proportional to the distributional closeness of the two concepts." ></td>
	<td class="line x" title="175:257	In other words, the more the words representing two contrasting concepts occur in similar contexts, the more the two concepts are considered to be antonymous." ></td>
	<td class="line oc" title="176:257	Again we used Mohammad and Hirsts (2006) method along with Lins (1998) distributional measure to determine the distributional closeness of two thesaurus concepts." ></td>
	<td class="line x" title="177:257	Co-occurrence statistics required for the approach were computed from the 987 BNC." ></td>
	<td class="line x" title="178:257	Words that occurred within a window of 5 words were considered to co-occur." ></td>
	<td class="line x" title="179:257	7.2.2 Lexical unit level Recall that strictly speaking, antonymy (like other lexical-semantic relations) applies to lexical units (a combination of surface form and word sense)." ></td>
	<td class="line x" title="180:257	If two words are used in senses pertaining to contrasting categories (as per the methods described in Section 7.1), then we will consider them to be antonymous (degree of antonymy is greater than zero)." ></td>
	<td class="line x" title="181:257	If two words are used in senses pertaining to noncontrasting senses, then we will consider them to be not antonymous (degree of antonymy is equal to 0)." ></td>
	<td class="line x" title="182:257	If the target words belong to the same thesaurus paragraphs as any of the seed antonyms linking the two contrasting categories, then the words are considered to have a high degree of antonymy." ></td>
	<td class="line x" title="183:257	This is because words that occur in the same thesaurus paragraph tend to be semantically very close in meaning." ></td>
	<td class="line x" title="184:257	Relying on the co-occurrence hypothesis, we claim that for word pairs listed in contrasting categories, the greater their tendency to co-occur in text, the higher their degree of antonymy." ></td>
	<td class="line x" title="185:257	We use mutual information to capture the tendency of wordword co-occurrence." ></td>
	<td class="line x" title="186:257	If the target words do not both belong to the same paragraphs as a seed antonym pair, but occur in contrasting categories, then the target words are considered to have a low or medium degree of antonymy (less antonymous than the word pairs discussed above)." ></td>
	<td class="line x" title="187:257	Such word pairs that have a higher tendency to co-occur are considered to have a medium degree of antonymy, whereas those that have a lower tendency to co-occur are considered to have a low degree of antonymy." ></td>
	<td class="line x" title="188:257	Co-occurrence statistics for this purpose were collected from the Google n-gram corpus (Brants and Franz, 2006).2 Words that occurred within a window of 5 words were considered to be co-occurring." ></td>
	<td class="line x" title="189:257	7.2.3 Word level Even though antonymy applies to pairs of word and sense combinations, most available texts are not 2We used the Google n-gram corpus is created from a text collection of over 1 trillion words." ></td>
	<td class="line x" title="190:257	We intend to use the same corpus (and not the BNC) to determine semantic distance as well, in the near future." ></td>
	<td class="line x" title="191:257	sense-annotated." ></td>
	<td class="line x" title="192:257	If antonymous occurrences are to be exploited for any of the purposes listed in the beginning of this paper, then the text must be sense disambiguated." ></td>
	<td class="line x" title="193:257	However, word sense disambiguation is a hard problem." ></td>
	<td class="line x" title="194:257	Yet, and to some extent because unsupervised word sense disambiguation systems perform poorly, much can be gained by using simple heuristics." ></td>
	<td class="line x" title="195:257	For example, it has been shown that cohesive text tends to have words that are close in meaning rather than unrelated words." ></td>
	<td class="line x" title="196:257	This, along with the distributional hypothesis of antonyms, and the findings by Justeson and Katz (1991) (antonymous concepts tend to occur more often than chance in the same sentence), suggests that if we find a word pair in a sentence such that two of its senses are strongly contrasting (as per the algorithm described in Section 7.2.2), then it is probable that the two words are used in those contrasting senses." ></td>
	<td class="line x" title="197:257	8 Evaluation 8.1 Task and data In order to best evaluate a computational measure of antonymy, we need a task that not only requires knowing whether two words are antonymous but also whether one word pair is more antonymous than another pair." ></td>
	<td class="line x" title="198:257	Therefore, we evaluated our system on a set of closest-opposite questions." ></td>
	<td class="line x" title="199:257	Each question has one target word and five alternatives." ></td>
	<td class="line x" title="200:257	The objective is to identify that alternative which is the closest opposite of the target." ></td>
	<td class="line x" title="201:257	For example, consider: adulterate: a. renounce b. forbid c. purify d. criticize e. correct Here the target word is adulterate." ></td>
	<td class="line x" title="202:257	One of the alternatives provided is correct, which as a verb has a meaning that contrasts with that of adulterate; however, purify has a greater degree of antonymy with adulterate than correct does and must be chosen in order for the instance to be marked as correctly answered." ></td>
	<td class="line x" title="203:257	This evaluation is similar to how others have evaluated semantic distance algorithms on TOEFL synonym questions (Turney, 2001), except that in those cases the system had to choose the alternative which is closest in meaning to the target." ></td>
	<td class="line x" title="204:257	We looked on the World Wide Web for large sets of closest antonym questions." ></td>
	<td class="line x" title="205:257	We found two independent sets of questions designed to prepare stu988 development data test data P R F P R F a. random baseline 0.20 0.20 0.20 0.20 0.20 0.20 b. affix-generated seeds only 0.72 0.53 0.61 0.71 0.51 0.60 c. WordNet seeds only 0.79 0.52 0.63 0.75 0.50 0.60 d. both seed sets 0.77 0.65 0.70 0.73 0.60 0.65 e. adjacency heuristic only 0.81 0.43 0.56 0.83 0.46 0.59 f. affix seed set + heuristic 0.75 0.60 0.67 0.76 0.61 0.68 g. both seed sets + heuristic 0.76 0.66 0.70 0.76 0.64 0.70 Table 2: Results obtained on closest-opposite questions." ></td>
	<td class="line x" title="206:257	dents for the Graduate Record Examination.3 The first set consists of 162 questions." ></td>
	<td class="line x" title="207:257	We used this set to develop our approach and will refer to it as the development set." ></td>
	<td class="line x" title="208:257	Even though the algorithm does not have any tuned parameters per se, the development set helped determine which cues of antonymy were useful and which were not." ></td>
	<td class="line x" title="209:257	The second set has 1208 closest-opposite questions." ></td>
	<td class="line x" title="210:257	We discarded questions that had a multiword target or alternative." ></td>
	<td class="line x" title="211:257	After removing duplicates we were left with 950 questions, which we used as the unseen test set." ></td>
	<td class="line x" title="212:257	Interestingly, the data contains many instances that have the same target word used in different senses." ></td>
	<td class="line x" title="213:257	For example: (1) obdurate: a. meager b. unsusceptible c. right d. tender e. intelligent (2) obdurate: a. yielding b. motivated c. moribund d. azure e. hard (3) obdurate: a. transitory b. commensurate c. complaisant d. similar e. uncommunicative In (1), obdurate is used in the HARDENED IN FEELINGS sense and the closest opposite is tender." ></td>
	<td class="line x" title="214:257	In (2), it is used in the RESISTANT TO PERSUASION sense and the closest opposite is yielding." ></td>
	<td class="line x" title="215:257	In (3), it is used in the PERSISTENT sense and the closest opposite is transitory." ></td>
	<td class="line x" title="216:257	The datasets also contain questions in which one or more of the alternatives is a near-synonym of the target word." ></td>
	<td class="line x" title="217:257	For example: astute: a. shrewd b. foolish c. callow d. winning e. debating Observe that shrewd is a near-synonym of astute." ></td>
	<td class="line x" title="218:257	The closest-opposite of astute is foolish." ></td>
	<td class="line x" title="219:257	A manual check of a randomly selected set of 100 test-set questions revealed that, on overage, one in four had 3Both datasets are apparently in the public domain and will be made available on request." ></td>
	<td class="line x" title="220:257	a near-synonym as one of the alternative." ></td>
	<td class="line x" title="221:257	8.2 Experiments We used the algorithm proposed in Section 7 to automatically solve the closest-opposite questions." ></td>
	<td class="line x" title="222:257	Since individual words may have more than one meaning, we relied on the hypothesis that the intended sense of the alternatives are those which are most antonymous to one of the senses of the target word." ></td>
	<td class="line x" title="223:257	(This follows from the discussion earlier in Section 7.2.3.) So for each of the alternatives we used the target word as context (but not the other alternatives)." ></td>
	<td class="line x" title="224:257	We think that using a larger context to determine antonymy will be especially useful when the target words are found in sentences and natural textsomething we intend to explore in the future." ></td>
	<td class="line x" title="225:257	Table 2 presents results obtained on the development and test data using different combinations of the seed sets and the adjacency heuristic." ></td>
	<td class="line x" title="226:257	If the system did not find any evidence of antonymy between the target and any of its alternatives, then it refrained from attempting that question." ></td>
	<td class="line x" title="227:257	We therefore report precision (number of questions answered correctly / number of questions attempted), recall (number of questions answered correctly / total number of questions), and F-score values (2 a0 P a0 Ra1a3a2 P a4 Ra5 )." ></td>
	<td class="line x" title="228:257	Observe that all results are well above the random baseline of 0.20 (obtained when a system randomly guesses one of the five alternatives to be the answer)." ></td>
	<td class="line x" title="229:257	Also, using only the small set of sixteen affix rules, the system performs almost as well as when it uses 10,807 WordNet antonym pairs." ></td>
	<td class="line x" title="230:257	Using both the affix-generated and the WordNet seed sets, the system obtains markedly improved precision and coverage." ></td>
	<td class="line x" title="231:257	Using only the adjacency heuristic gave best precision values (upwards of 0.8) with substan989 tial coverage (attempting close to half the questions)." ></td>
	<td class="line x" title="232:257	However, best overall performance was obtained using both seed sets and the adjacency heuristic (Fscore of 0.7)." ></td>
	<td class="line x" title="233:257	8.3 Discussion These results show that, to some degree, the automatic approach does indeed mimic human intuitions of antonymy." ></td>
	<td class="line x" title="234:257	In tasks that require higher precision, using only the adjacency heuristic is best, whereas in tasks that require both precision and coverage, the seed sets may be included." ></td>
	<td class="line x" title="235:257	Even when both seed sets were included, only four instances in the development set and twenty in the test set had targetanswer pairs that matched a seed antonym pair." ></td>
	<td class="line x" title="236:257	For all remaining instances, the approach had to generalize to determine the closest opposite." ></td>
	<td class="line x" title="237:257	This also shows that even the seemingly large number of direct and indirect antonyms from WordNet (more than 10,000) are by themselves insufficient." ></td>
	<td class="line x" title="238:257	The comparable performance obtained using the affix rules alone suggests that even in languages without a wordnet, substantial accuracies may be achieved." ></td>
	<td class="line x" title="239:257	Of course, improved results when using WordNet antonyms as well suggests that the information they provide is complementary." ></td>
	<td class="line x" title="240:257	Error analysis revealed that at times the system failed to identify that a category pertaining to the target word contrasted with a category pertaining to the answer." ></td>
	<td class="line x" title="241:257	Additional methods to identify seed antonym pairs will help in such cases." ></td>
	<td class="line x" title="242:257	Certain other errors occurred because one or more alternatives other than the official answer were also antonymous to the target." ></td>
	<td class="line x" title="243:257	For example, the system chose accept as the opposite of chasten instead of reward." ></td>
	<td class="line x" title="244:257	9 Conclusion We have proposed an empirical approach to antonymy that combines corpus co-occurrence statistics with the structure of a published thesaurus." ></td>
	<td class="line x" title="245:257	The method can determine the degree of antonymy or contrast between any two thesaurus categories (sets of words representing a coarse concept) and between any two word pairs." ></td>
	<td class="line x" title="246:257	We evaluated the approach on a large set of closest-opposite questions wherein the system not only identified whether two words are antonymous but also distinguished between pairs of antonymous words of different degrees." ></td>
	<td class="line x" title="247:257	It achieved an F-score of 0.7 in this task where the random baseline was only 0.2." ></td>
	<td class="line x" title="248:257	When aiming for high precision it scores over 0.8, but there is some drop in the number of questions attempted." ></td>
	<td class="line x" title="249:257	In the process of developing this approach we validated the co-occurrence hypothesis proposed by Charles and Miller (1989) on a large set of 1000 noun, verb, and adjective pairs." ></td>
	<td class="line x" title="250:257	We also gave empirical proof that antonym pairs tend to be used in similar contexts the distributional hypothesis for antonyms." ></td>
	<td class="line x" title="251:257	Our future goals include porting this approach to a cross-lingual framework in order to determine antonymy in a resource-poor language by combining its text with a thesaurus from a resource-rich language." ></td>
	<td class="line x" title="252:257	We will use antonym pairs to identify contrast relations between sentences to in turn improve automatic summarization." ></td>
	<td class="line x" title="253:257	We also intend to use the approach proposed here in tasks where keyword matching is especially problematic, for example, separating paraphrases from contradictions." ></td>
	<td class="line x" title="254:257	Acknowledgments We thank Smaranda Muresan, Siddharth Patwardhan, members of the CLIP lab at the University of Maryland, College Park, and the anonymous reviewers for their valuable feedback." ></td>
	<td class="line x" title="255:257	This work was supported, in part, by the National Science Foundation under Grant No." ></td>
	<td class="line x" title="256:257	IIS-0705832, in part, by the Human Language Technology Center of Excellence, and in part, by the Natural Sciences and Engineering Research Council of Canada." ></td>
	<td class="line x" title="257:257	Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsor." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I08-1021
Modeling Context in Scenario Template Creation
Qiu, Long;Kan, Min-Yen;Chua, Tat-Seng;"></td>
	<td class="line x" title="1:178	Modeling Context in Scenario Template Creation Long Qiu, Min-Yen Kan, Tat-Seng Chua Department of Computer Science National University of Singapore Singapore, 117590 fqiul,kanmy,chuatsg@comp.nus.edu.sg Abstract We describe a graph-based approach to Scenario Template Creation, which is the task of creating a representation of multiple related events, such as reports of different hurricane incidents." ></td>
	<td class="line x" title="2:178	We argue that context is valuable to identify important, semantically similar text spans from which template slots could be generalized." ></td>
	<td class="line x" title="3:178	To leverage context, we represent the input as a set of graphs where predicate-argument tuples are vertices and their contextual relations are edges." ></td>
	<td class="line x" title="4:178	A context-sensitive clustering framework is then applied to obtain meaningful tuple clusters by examining their intrinsic and extrinsic similarities." ></td>
	<td class="line x" title="5:178	The clustering framework uses Expectation Maximization to guide the clustering process." ></td>
	<td class="line x" title="6:178	Experiments show that: 1) our approach generates high quality clusters, and 2) information extracted from the clusters is adequate to build high coverage templates." ></td>
	<td class="line x" title="7:178	1 Introduction Scenario template creation (STC) is the problem of generating a common semantic representation from a set of input articles." ></td>
	<td class="line x" title="8:178	For example, given multiple newswire articles on different hurricane incidents, an STC algorithm creates a template that may include slots for the storms name, current location, direction of travel and magnitude." ></td>
	<td class="line x" title="9:178	Slots in such a scenario template are often to be  lled by salient entities in the scenario instance (e.g.,  Hurricane Charley or  the coast area ) but some can also be  lled by prominent clauses, verbs or adjectives that describe these salient entities." ></td>
	<td class="line x" title="10:178	Here, we use the term salient aspect (SA) to refer to any of such slot  llers that people would regard as important to describe a particular scenario." ></td>
	<td class="line x" title="11:178	Figure 1 shows such a manuallybuilt scenario template in which details about important actions, actors, time and locations are coded as slots." ></td>
	<td class="line x" title="12:178	STC is an important task that has tangible bene ts for many downstream applications." ></td>
	<td class="line x" title="13:178	In the Message Understanding Conference (MUC), manuallygenerated STs were provided to guide Information Extraction (IE)." ></td>
	<td class="line x" title="14:178	An ST can also be viewed as regularizing a set of similar articles as a set of attribute/value tuples, enabling multi-document summarization from  lled templates." ></td>
	<td class="line x" title="15:178	Despite these bene ts, STC has not received much attention by the community." ></td>
	<td class="line x" title="16:178	We believe this is because it is considered a dif cult task that requires deep NL understanding of the source articles." ></td>
	<td class="line x" title="17:178	A problem in applications requiring semantic similarity is that the same word in different contexts may have different senses and play different roles." ></td>
	<td class="line x" title="18:178	Conversely, different words in similar contexts may play similar roles." ></td>
	<td class="line x" title="19:178	This problem makes approaches that rely on word similarity alone inadequate." ></td>
	<td class="line x" title="20:178	We propose a new approach to STC that incorporates the use of contextual information to address this challenge." ></td>
	<td class="line x" title="21:178	Unlike previous approaches that concentrate on the intrinsic similarity of candidate slot  llers, our approach explicitly models contextual evidence." ></td>
	<td class="line x" title="22:178	And unlike approaches to word sense disambiguation (WSD) and other semantic analyses that 157 use neighboring or syntactically related words as contextual evidence, we de ne contexts by semantic relatedness which extends beyond sentence boundaries." ></td>
	<td class="line x" title="23:178	Figure 2 illustrates a case in point with two excerpts from severe storm reports." ></td>
	<td class="line x" title="24:178	Here, although the intrinsic similarity of the main verbs  hit and  land is low, their contextual similarity is high as both are followed by clauses sharing similar subjects (hurricanes) and the same verbs." ></td>
	<td class="line x" title="25:178	Our approach encodes such contextual information as graphs, mapping the STC problem into a general graph overlay problem that is solvable by a variant of Expectation Maximization (EM)." ></td>
	<td class="line x" title="26:178	Our work also contributes resources for STC research." ></td>
	<td class="line x" title="27:178	Until now, few scenario templates have been publicly available (as part of MUC), rendering any potential evaluation of automated STC statistically insigni cant." ></td>
	<td class="line x" title="28:178	As part of our study, we have compiled a set of input articles with annotations that we are making available to the research community." ></td>
	<td class="line x" title="29:178	Scenario Template: Storm Storm Name Charley Storm Action landed Location Floridas Gulf coast Time Friday at 1950GMT Speed 145 mph Victim Category 1 13 people Action died Victim Category 2 over one million Action affected Figure 1: An example scenario template ( lled)." ></td>
	<td class="line x" title="30:178	2 Related Work A natural way to automate the process of STC is to cluster similar text spans in the input article set." ></td>
	<td class="line x" title="31:178	SAs then emerge through clustering; if a cluster of text spans is large enough, the aspects contained in it will be considered as SAs." ></td>
	<td class="line x" title="32:178	Subsequently, these SAs will be generalized into one or more slots in the template, depending on the de nition of the text span." ></td>
	<td class="line x" title="33:178	Assuming scenarios are mainly de ned by actions, the focus should be on  nding appropriate clusters for text spans each of which represents an action." ></td>
	<td class="line x" title="34:178	Most of the related work (although they may not directly address STC) shares this assumption and performs Charley landed further south on Floridas Gulf coast than predicted,  The hurricane  has weakened and is moving over South Carolina." ></td>
	<td class="line x" title="35:178	At least 21 others are missing after the storm hit on Wednesday." ></td>
	<td class="line x" title="36:178	But Tokage had weakened by the time it passed over Japans capital, Tokyo, where it left little damage before moving out to sea." ></td>
	<td class="line x" title="37:178	Figure 2: Contextual evidence of similarity." ></td>
	<td class="line x" title="38:178	Curved lines indicate similar contexts, providing evidence that  land and  hit from two articles are semantically similar." ></td>
	<td class="line x" title="39:178	action clustering accordingly." ></td>
	<td class="line x" title="40:178	While the target application varies, most systems that need to group text spans by similarity measures are verb-centric." ></td>
	<td class="line x" title="41:178	In addition to the verb, many systems expand their representation by including named entity tags (Collier, 1998; Yangarber et al., 2000; Sudo et al., 2003; Filatova et al., 2006), as well as restricting matches (using constraints on subtrees (Sudo et al., 2003; Filatova et al., 2006), predicate argument structures (Collier, 1998; Riloff and Schmelzenbach, 1998; Yangarber et al., 2000; Harabagiu and Maiorano, 2002) or semantic roles)." ></td>
	<td class="line x" title="42:178	Given these representations, systems then cluster similar text spans." ></td>
	<td class="line x" title="43:178	To our knowledge, all current systems use a binary notion of similarity, in which pairs of spans are either similar or not." ></td>
	<td class="line x" title="44:178	How they determine similarity is tightly coupled with their text span representation." ></td>
	<td class="line x" title="45:178	One criterion used is pattern overlap: for example, (Collier, 1998; Harabagiu and Lacatusu, 2005) judge text spans to be similar if they have similar verbs and share the same verb arguments." ></td>
	<td class="line x" title="46:178	Working with tree structures, Sudo et al. and Filatova et al. instead require shared subtrees." ></td>
	<td class="line x" title="47:178	Calculating text span similarity ultimately boils down to calculating word phrase similarity." ></td>
	<td class="line x" title="48:178	Approaches such as Yangarbers or Riloff and Schmelzenbachs do not employ a thesaurus and thus are easier to implement, but can suffer from overor under-generalization." ></td>
	<td class="line x" title="49:178	In certain cases, either the same actor is involved in different actions or different verbs realize the same action." ></td>
	<td class="line x" title="50:178	Other systems (Collier, 1998; Sudo et al., 2003) do employ 158 lexical similarity but threshold it to obtain binary judgments." ></td>
	<td class="line x" title="51:178	Systems then rank clusters by cluster size and correlation with the relevant article set and equate top clusters as output scenario slots." ></td>
	<td class="line x" title="52:178	3 Context-Sensitive Clustering (CSC) Automating STC requires handling a larger degree of variations than most previous work we have surveyed." ></td>
	<td class="line x" title="53:178	Note that the actors involved in actions in a scenario generally differ from event to event, which makes most related work on text span similarity calculation unsuitable." ></td>
	<td class="line x" title="54:178	Also, action participants are not limited to named entities, so our approach needs to process all NPs." ></td>
	<td class="line x" title="55:178	As both actions and actors may be realized using different words, a similarity thesaurus is necessary." ></td>
	<td class="line oc" title="56:178	Our approach to STC uses a thesaurus based on corpus statistics (Lin, 1998) for real-valued similarity calculation." ></td>
	<td class="line x" title="57:178	In contrast to previous approaches, we do not threshold word similarity results; we retain their fractional values and incorporate these values holistically." ></td>
	<td class="line x" title="58:178	Finally, as the same action can be realized in different constructions, the semantic (not just syntactic) roles of verb arguments must be considered, lest agent and patient roles be confused." ></td>
	<td class="line x" title="59:178	For these reasons, we use a semantic role labeler (Pradhan et al., 2004) to provide and delimit the text spans that contain the semantic arguments of a predicate." ></td>
	<td class="line x" title="60:178	We term the obtained text spans as predicate argument tuples (tuples) throughout the paper." ></td>
	<td class="line x" title="61:178	The semantic role labeler reportedly achieves an F1 measure equal to 68:7% on identi cationclassi cation of predicates and core arguments on a newswire text corpus (LDC, 2002)." ></td>
	<td class="line x" title="62:178	Within the con nes of our study, we  nd it is able to capture most of the tuples of interest." ></td>
	<td class="line x" title="63:178	Our approach explicitly captures contextual evidence." ></td>
	<td class="line x" title="64:178	We de ne a tuples contexts as other tuples in the same article segment where no topic shift occurs." ></td>
	<td class="line x" title="65:178	This de nition re nes the n-surrounding word constraint commonly used in spelling correction (for example, (Hirst and Budanitsky, 2005)), Word Sense Disambiguation ((Preiss, 2001), (Lee and Ng, 2002), for instance), etc. while still ensures the relatedness between a tuple and its contexts." ></td>
	<td class="line x" title="66:178	Speci cally, a tuple is contextually related to other tuples by two quanti able contextual relations: argument-similarity and position-similarity." ></td>
	<td class="line x" title="67:178	For our experiments, we use the leads of newswire articles as they normally summarize the news." ></td>
	<td class="line x" title="68:178	We also assume a lead quali es as a single article segment, thus making all of its tuples as potential contexts to each other." ></td>
	<td class="line x" title="69:178	from A2 from A1 weakened(storm) v21 hit(storm) v22 moving(storm) v23 weakened(hurricane) v11 landed(hurricane) v12 moving(hurricane) v13 e21;2 e22;1 e21;3 e23;1 e22;3 e23;2 e11;2 e12;1 e11;3 e13;1 e12;3 e13;2 Figure 3: Being similar contexts,  weakened and  moving provide contextual evidence that  land and  hit are similar." ></td>
	<td class="line x" title="70:178	First, we split the input article leads into sentences and perform semantic role labeling immediately afterwards." ></td>
	<td class="line x" title="71:178	Our system could potentially bene t from additional pre-processing such as co-reference resolution." ></td>
	<td class="line x" title="72:178	Currently these pre-processing steps have not been properly integrated with the rest of the system, and thus we have not yet measured their impact." ></td>
	<td class="line x" title="73:178	We then transform each lead Ai into a graph Gi = fV i;Eig." ></td>
	<td class="line x" title="74:178	As shown in Figure 3, vertices V i = fvijg(j = 1;:::;N) are the N predicate argument tuples extracted from the ith article, and directed edges Ei = feim;n = (vim;vin)g re ect contextual relations between tuple vim and vin." ></td>
	<td class="line x" title="75:178	Edges only connect tuples from the same article, i.e., within each graph Gi." ></td>
	<td class="line x" title="76:178	We differentiate between two types of edges." ></td>
	<td class="line x" title="77:178	One is argument-similarity, where the two tuples have semantically similar arguments." ></td>
	<td class="line x" title="78:178	This models tuple cohesiveness, where the edge weight is determined by the similarity score of the most similar inter-tuple argument pair." ></td>
	<td class="line x" title="79:178	The other is positionsimilarity, represented as the offset of the ending tuple with respect to the other, measured in sentences." ></td>
	<td class="line x" title="80:178	This edge type is directional to account for simple causality." ></td>
	<td class="line x" title="81:178	Given this set of graphs, the clustering task is to  nd an optimal alignment of all graphs (i.e., superimposing the set of article graphs to maximize vertex overlap, constrained by the edges)." ></td>
	<td class="line x" title="82:178	We adapt Expectation Maximization (Dempster et al., 1977) to  nd 159 an optimal clustering." ></td>
	<td class="line x" title="83:178	This process assigns tuples to suitable clusters where they are semantically similar and share similar contexts with other tuples." ></td>
	<td class="line x" title="84:178	Algorithm 1 outlines this alignment process." ></td>
	<td class="line x" title="85:178	Algorithm 1 Graph Alignment(G) /*Gis a set of graphfGig*/ T  all tuples inG C highly cohesive tuples clusters other remaining tuples semantically connected with C C[C:length] other repeat /*E step*/ for each i such that i < C:length do for each j such that j < C:length do if i == j then continue; re-estimate parameters[C[i];C[j]] /*distribution parameters of edges between two clusters*/ tupleReassigned = false /*reset*/ /*M step*/ for each i such that i < T:length do aBestLikelihood = T[i]:likelihood; /*likelihood of being in its current cluster*/ for each tuple tcontxt that contextually related with T[i] do for each cluster ccand, any candidate cluster that contextually related with tcontxt:cluster do P(T[i]2ccand) = comb(Ps;Pc) likelihood = log(P(T[i]2ccand)) if likelihood > aBestLikelihood then aBestLikelihood = likelihood T[i]:cluster = ccand tupleReassigned = true until tupleReassigned == false /*alignment stable*/ return During initialization, tuples whose pairwise similarity higher than a threshold  are merged to form highly cohesive seed clusters." ></td>
	<td class="line x" title="86:178	To compute a continuous similarity Sim(ta;tb) of tuples ta and tb, we use the similarity measure described in (Qiu et al., 2006), which linearly combines similarities between the semantic roles shared by the two tuples." ></td>
	<td class="line x" title="87:178	Some other tuples are related to these seed clusters by argument-similarity." ></td>
	<td class="line x" title="88:178	These related tuples are temporarily put into a special  other cluster." ></td>
	<td class="line x" title="89:178	The cluster membership of these related tuples, together with those currently in the seed clusters, are to be further adjusted." ></td>
	<td class="line x" title="90:178	The  other cluster is so called because a tuple will end up being assigned to it if it is not found to be similar to any other tuple." ></td>
	<td class="line x" title="91:178	Tuples that are neither similar to nor contextually related by argument-similarity to another tuple are termed singletons and excluded from being clustered." ></td>
	<td class="line x" title="92:178	We then iteratively (re-)estimate clusters of tuples across the set of article graphs G. In the E-step of the EM algorithm, all contextual relations between each pair of clusters are collected as two set of edges." ></td>
	<td class="line x" title="93:178	Here we assume argument-similarity and positionsimilarity are independent and thus we differentiate them in the computation." ></td>
	<td class="line x" title="94:178	Accordingly, there are two sets: edgesas and edgesps." ></td>
	<td class="line x" title="95:178	For simplicity, we assume independent normal distributions for the strength of each set (inter-tuple argument similarity for edgesas and sentence distance for edgesps)." ></td>
	<td class="line x" title="96:178	The edge strength distribution parameters for both sets between each pair of clusters are re-estimated based on current edges in edgesas and edgesps." ></td>
	<td class="line x" title="97:178	In the M-step, we examine each tuples  tness for belonging to its cluster and relocate some tuples to new clusters to maximize the likelihood given the latest estimated edge strength distributions." ></td>
	<td class="line x" title="98:178	In the following equations, we denote the proposition that predicate argument tuple ta belongs to cluster cm as ta2cm; a typical tuple (the centroid) of the cluster cm as tcm; and the cluster of ta as cta." ></td>
	<td class="line x" title="99:178	The objective function to maximize is: Obj(G) = X ta2G log(P(ta2cta)); (1) where P(ta2cm) = 2Ps(ta2cm) Pc(ta2cm)P s(ta2cm) + Pc(ta2cm) : (2) Equation 2 takes the harmonic mean of two factors: a contextual factor Pc and and a semantic factor Ps: Pc(ta2cm) = maxfP(edges(ta;tb)j tb:edges(ta;tb)6=null edges(cm;ctb))g; (3) Ps(ta2cm) = ( simdefault; cm = cother; Sim(ta;tcm); otherwise: (4) Here the contextual factor Pc models how likely ta belongs to cm according to the contextual information, i.e., the conditional probability of the contextual relations between cm and ctb given the contextual relations between ta and one particular context tb, which maximizes this probability." ></td>
	<td class="line x" title="100:178	According to Bayes theorem, it is computed as shown in Equation 3." ></td>
	<td class="line x" title="101:178	In practice, we multiply two conditional probabilities: P(edgeas(ta;tb)jedgesas(cm;ctb)) and P(edgeps(ta;tb)jedgesps(cm;ctb)), assuming independence between edgesas and edgesps." ></td>
	<td class="line x" title="102:178	We assume there are still singleton tuples that are not semantically similar to another tuple and should belong to the special  other cluster." ></td>
	<td class="line x" title="103:178	Given that they 160 are dissimilar to each other, we set simdefault to a small nonzero value in Equation 4 to prevent the  other cluster from expelling them based on their low semantic similarity." ></td>
	<td class="line x" title="104:178	Tuples cluster memberships are recalculated, and the parameters describing the contextual relations between clusters are reestimated." ></td>
	<td class="line x" title="105:178	New EM iterations are performed as long as one or more tuple relocations occur." ></td>
	<td class="line x" title="106:178	Once the EM halts, clusters of equivalent tuples are formed." ></td>
	<td class="line x" title="107:178	Among these clusters, some correspond to salient actions that, together with their actors, are all SAs to be generalized into template slots." ></td>
	<td class="line x" title="108:178	Cluster size is a good indicator of salience, and each large cluster (excluding the  other cluster) can be viewed as containing instances of a salient action." ></td>
	<td class="line x" title="109:178	Formulating the clustering process as a variant of iterative EM is well-motivated as we consider the similarity scores as noisy and having missing observations." ></td>
	<td class="line x" title="110:178	Calculating semantic similarity is at best inaccurate." ></td>
	<td class="line x" title="111:178	Thus it is dif cult to cluster tuples correctly based only on their semantic similarity." ></td>
	<td class="line x" title="112:178	Also to check whether a tuple shares contexts with a cluster of tuples, the cluster has to be relatively clean." ></td>
	<td class="line x" title="113:178	An iterative EM as we have proposed naturally improve the cleanness of these tuple clusters gradually as new similarity information comes to light." ></td>
	<td class="line x" title="114:178	4 Evaluation For STC, we argue that it is crucial to cluster tuples with high recall so that an SAs various surface forms can be captured and the size of clusters can serve as a salience indicator." ></td>
	<td class="line x" title="115:178	Meanwhile, precision should not be sacri ced, as more noise will hamper the downstream generalization process which outputs template slots." ></td>
	<td class="line x" title="116:178	We conduct experiments designed to answer two relevant research questions: 1) Cluster Quality: Whether using contexts (in CSC) produces better clustering results than ignoring it (in the K-means baseline); and 2) Template Coverage: Whether slots generalized from CSC clusters cover human-de ned templates." ></td>
	<td class="line x" title="117:178	4.1 Data Set and Baseline A straightforward evaluation of a STC system would compare its output against manually-prepared gold standard templates, such as those found in MUC." ></td>
	<td class="line x" title="118:178	Unfortunately, such scenario templates are severely limited and do not provide enough instances for a proper evaluation." ></td>
	<td class="line x" title="119:178	To overcome this problem, we have prepared a balanced news corpus, where we have manually selected articles covering 15 scenarios." ></td>
	<td class="line x" title="120:178	Each scenario is represented by a total of 45 to 50 articles which describe 10 different events." ></td>
	<td class="line x" title="121:178	Our baseline is a standard K-means clusterer." ></td>
	<td class="line x" title="122:178	Its input is identical to that of CSC  the tuples extracted from relevant news articles and are not excluded from being clustered by CSC in the initialization stage (refer to Section 3)  and employs the same tuple similarity measure (Qiu et al., 2006)." ></td>
	<td class="line x" title="123:178	The differentiating factor between CSC and K-means is the use of contextual evidence." ></td>
	<td class="line x" title="124:178	A standard K-means clusterer requires a k to be speci ed." ></td>
	<td class="line x" title="125:178	For each scenario, we set its k as the number of clusters generated by CSC for direct comparison." ></td>
	<td class="line x" title="126:178	We  x the test set for each scenario as ten randomly selected news articles, each reporting a different instance of the scenario; the development set (which also serves as the training set for determining the EM initialization threshold  and simdefault in Equation 4) is a set of ten articles from the  AirlinerCrash scenario, which are excluded from the test set." ></td>
	<td class="line x" title="127:178	Both systems analyze the  rst 15 sentences of each article, and sentences generate 2 to 3 predicate argument tuples on average, resulting in a total of 10  15  (2 to 3) = 300 to 450 tuples for each scenario." ></td>
	<td class="line x" title="128:178	4.2 Cluster Quality This experiment compares the clustering results of CSC and K-means." ></td>
	<td class="line x" title="129:178	We use the standard clustering metrics of purity and inverse purity (Hotho et al., 2003)." ></td>
	<td class="line x" title="130:178	The  rst author manually constructed the gold standard clusters for each scenario using a GUI before conducting any experiments." ></td>
	<td class="line x" title="131:178	A special cluster, corresponding to the  other cluster in the CSC clusters, was created to hold the singleton tuples for each scenario." ></td>
	<td class="line x" title="132:178	Table 1 shows this under the column  #Gold Standard Clusters . Using the manual clusters as the gold standard, we obtain the purity (P) and inverse purity (IP) scores of CSC and K-means on each scenario." ></td>
	<td class="line x" title="133:178	In Table 1, we see that CSC outperforms K-means on 10 of 15 scenarios for both P and IP." ></td>
	<td class="line x" title="134:178	For the remaining 5 scenarios, where CSC and K-means have comparable 161 P scores, the IP scores of CSC are all signi cantly higher than that of K-means." ></td>
	<td class="line x" title="135:178	This suggests clusters tend to be split apart more in K-means than in CSC when they have similar purity." ></td>
	<td class="line x" title="136:178	One thing worth mentioning here is that the  other cluster normally is relatively large for each scenario, and thus may skew the results." ></td>
	<td class="line x" title="137:178	To remove this effect, we excluded tuples belonging to the CSC  other cluster from the K-means input, generating one fewer cluster." ></td>
	<td class="line x" title="138:178	Running the evaluation again, the resulting P-IP scores again show that CSC outperforms the baseline Kmeans." ></td>
	<td class="line x" title="139:178	We only report the results for all tuples in our paper for simplicity." ></td>
	<td class="line x" title="140:178	#Gold Std." ></td>
	<td class="line x" title="141:178	CSC K-means Scenario Clusters P IP P IP AirlinerCrash 23 .61 .42 .52 .28 Earthquake 18 .60 .44 .53 .30 Election 10 .77 .49 .75 .21 Fire 14 .65 .44 .64 .26 LaunchEvent 12 .77 .37 .73 .22 Layoff 10 .71 .28 .70 .19 LegalCase 8 .75 .37 .75 .18 Nobel 6 .77 .28 .77 .19 Obituary 7 .85 .46 .81 .28 RoadAccident 20 .61 .49 .56 .40 SoccerFinal 5 .88 .39 .88 .15 Storm 14 .61 .31 .61 .22 Tennis 6 .87 .19 .87 .12 TerroristAttack 14 .64 .48 .62 .25 Volcano 16 .68 .38 .66 .17 Average 12.2 .72 .39 .69 .23 Table 1: CSC outperforms K-means with respect to the purity (P) and inverse purity (IP) scores." ></td>
	<td class="line x" title="142:178	A close inspection of the results reveals some problematic cases." ></td>
	<td class="line x" title="143:178	One issue worth mentioning is that for certain actions both CSC and K-means produce split clusters." ></td>
	<td class="line x" title="144:178	In the CSC case, we traced this problem back to the thesaurus, where predicates for one action seem to belong to two or more totally dissimilar semantic categories." ></td>
	<td class="line x" title="145:178	The corresponding tuples are thus assigned to different clusters as their low semantic similarity forces the tuples to remain separate, despite the shared contexts trying to join them." ></td>
	<td class="line x" title="146:178	One example is  blast (off) and  lift (off) in the  Launch Event scenario." ></td>
	<td class="line x" title="147:178	The thesaurus shows the two verbs are dissimilar and the corresponding tuples end up being in two split clusters." ></td>
	<td class="line x" title="148:178	This can not be solved easily without an improved thesaurus." ></td>
	<td class="line x" title="149:178	We are considering adding a prior to model the optimal size for clusters, which may help to compact such cases." ></td>
	<td class="line x" title="150:178	4.3 Template Coverage We also assess how well the resulting, CSCgenerated tuple clusters serve in creating good scenario template slots." ></td>
	<td class="line x" title="151:178	We start from the top largest clusters from each scenario, and decompose each of them into six sets: the predicates, agents, patients, predicate modi ers, agent modi ers and patient modi ers." ></td>
	<td class="line x" title="152:178	For each of the  rst three sets for each cluster, we create a generalized term to represent it using an extended version of a generalization algorithm (Tseng et al., 2006)." ></td>
	<td class="line x" title="153:178	These terms are deemed output slots, and are put into the template with their agent-predicate-patient relations preserved." ></td>
	<td class="line x" title="154:178	The size of the template may increase when more clusters are generalized, as new slots may result." ></td>
	<td class="line x" title="155:178	We manually compare the slots that are output from the system with those de ned in existing scenario templates in MUC." ></td>
	<td class="line x" title="156:178	The results here are only indicative and not conclusive, as there are only two MUC7 templates available for comparison: Aviation Disaster and Launch Event." ></td>
	<td class="line x" title="157:178	Template semantic role general term action crash cluster 1 agent aircraft patient action kill cluster 2 agent heavier-thanair-craft patient people Figure 4: Automated scenario template of  AviationDisaster . Figure 4 shows an excerpt of the automatically generated template  AviationDisaster ( AirlinerCrash in our corpus) where the semantic roles in the top two biggest clusters have been generalized." ></td>
	<td class="line x" title="158:178	Their modi ers are quite semantically diverse, as shown in Table 2." ></td>
	<td class="line x" title="159:178	Thus, generalization (probably after a categorization operation) remains as a challenging problem." ></td>
	<td class="line x" title="160:178	Nonetheless, the information contained in these semantic roles and their modi ers covers human162 semantic role modi er head samples agent:aircraft A, U.N., The, Swiss, Canadianbuilt, AN, China, CRJ-200, military, Iranian, Air, refueling, US,  action:crash Siberia, mountain, rain, Tuesday,  ight, Sharjah,  ames, Sunday, board, Saturday, 225, Rockaway, approach, United, mountain, hillside patient:people all, 255, 71 Table 2: Sample automatically detected modi er heads of different semantic roles." ></td>
	<td class="line x" title="161:178	AviationDisaster LaunchEvent * AIRCRAFT * VEHICLE * AIRLINE * VEHICLE TYPE DEPARTURE POINT * VEHICLE OWNER DEPARTURE DATE * PAYLOAD * AIRCRAFT TYPE PAYLOAD TYPE * CRASH DATE PAYLOAD FUNC * CRASH SITE * PAYLOAD OWNER CAUSE INFO PAYLOAD ORIGIN * VICTIMS NUM * LAUNCH DATE * LAUNCH SITE MISSION TYPE MISSION FUNCTION MISSION STATUS Figure 5: MUC-7 template coverage: asterisks marking all the slots that could be automatically generated." ></td>
	<td class="line x" title="162:178	de ned scenario templates quite well." ></td>
	<td class="line x" title="163:178	The two MUC7 templates are shown as a list of slots in Figure 5, where horizontal lines delimit slots about different semantic roles, and asterisks mark all the slots that could be automatically generated by our system once it has an improved generalizer." ></td>
	<td class="line x" title="164:178	We can see substantial amount of overlap, indicating that a STC system powered by CSC is able to capture scenarios important facts." ></td>
	<td class="line x" title="165:178	5 Conclusion We have introduced a new context-sensitive approach to the scenario template creation (STC) problem." ></td>
	<td class="line x" title="166:178	Our method leverages deep NL processing, using semantic role labelers structured semantic tuples as input." ></td>
	<td class="line x" title="167:178	Despite the use of deeper semantics, we believe that intrinsic semantic similarity by itself is not suf cient for clustering." ></td>
	<td class="line x" title="168:178	We have shown this through examples and argue that an approach that considers contextual similarity is necessary." ></td>
	<td class="line x" title="169:178	A key aspect of our work is the incorporation of such contextual information." ></td>
	<td class="line x" title="170:178	Our approach uses a notion of context that combines two aspects: positional similarity (when two tuples are adjacent in the text), and argument similarity (when they have similar arguments)." ></td>
	<td class="line x" title="171:178	The set of relevant articles are represented as graphs where contextual evidence is encoded." ></td>
	<td class="line x" title="172:178	By mapping our problem into a graphical formalism, we cast the STC clustering problem as one of multiple graph alignment." ></td>
	<td class="line x" title="173:178	Such a graph alignment is solved by an adaptation of EM, which handles contexts and real-valued similarity by treating both as noisy and potentially unreliable observations." ></td>
	<td class="line x" title="174:178	While scenario template creation (STC) is a dif cult problem, its evaluation is arguably more dif cult due to the dearth of suitable resources." ></td>
	<td class="line x" title="175:178	We have compiled and released a corpus of over 700 newswire articles that describe different instances of 15 scenarios, as a suitable input dataset for further STC research." ></td>
	<td class="line x" title="176:178	Using this dataset, we have evaluated and analyzed our context-sensitive approach." ></td>
	<td class="line x" title="177:178	While our results are indicative, they show that considering contextual evidence improves performance." ></td>
	<td class="line x" title="178:178	Acknowledgments The authors are grateful to Kathleen R. McKeown and Elena Filatova at Columbia University for their stimulating discussions and comments over different stages of the preparation of this paper." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I08-1060
Bilingual Synonym Identification with Spelling Variations
Tsunakawa, Takashi;Tsujii, Jun'ichi;"></td>
	<td class="line x" title="1:163	Bilingual Synonym Identication with Spelling Variations Takashi Tsunakawa Junichi Tsujiiyz Department of Computer Science, Graduate School of Information Science and Technology, University of Tokyo 7-3-1, Hongo, Bunkyo-ku, Tokyo, 113-0033 Japan ySchool of Computer Science, University of Manchester Oxford Road, Manchester, M13 9PL, UK zNational Centre for Text Mining 131 Princess Street, Manchester, M1 7DN, UK {tuna, tsujii}@is.s.u-tokyo.ac.jp Abstract This paper proposes a method for identifying synonymous relations in a bilingual lexicon, which is a set of translation-equivalent term pairs." ></td>
	<td class="line x" title="2:163	We train a classier for identifying those synonymous relations by using spelling variations as main clues." ></td>
	<td class="line x" title="3:163	We compared two approaches: the direct identication of bilingual synonym pairs, and the merger of two monolingual synonyms." ></td>
	<td class="line x" title="4:163	We showed that our approach achieves a high pair-wise precision and recall, and outperforms the baseline method." ></td>
	<td class="line x" title="5:163	1 Introduction Automatically collecting synonyms from language resources is an ongoing task for natural language processing (NLP)." ></td>
	<td class="line x" title="6:163	Most NLP systems have difculties in dealing with synonyms, which are different representations that have the same meaning in a language." ></td>
	<td class="line x" title="7:163	Information retrieval (IR) could leverage synonyms to improve the coverage of search results (Qiu and Frei, 1993)." ></td>
	<td class="line x" title="8:163	For example, when we input the query transportation in India into an IR system, the system can expand the query to its synonyms; e.g. transport and railway, to nd more documents." ></td>
	<td class="line x" title="9:163	This paper proposes a method for the automatic identication of bilingual synonyms in a bilingual lexicon, with spelling variation clues." ></td>
	<td class="line x" title="10:163	A bilingual synonym set is a set of translation-equivalent term pairs sharing the same meaning." ></td>
	<td class="line x" title="11:163	Although a number of studies have aimed at identifying synonyms, this is the rst study that simultaneously nds synonyms in two languages, to our best knowledge." ></td>
	<td class="line x" title="12:163	Let us consider the case where a user enters the Japanese query kflojflo (	, industrial plant) into a cross-lingual IR system to nd English documents." ></td>
	<td class="line x" title="13:163	After translating the query into the English translation equivalent, plant, the cross-lingual IR system may expand the query to its English synonyms, e.g. factory, and workshop, and retrieve documents that include the expanded terms." ></td>
	<td class="line x" title="14:163	However, the term plant is ambiguous; the system may also expand the query to vegetable, and the system is prevented by the term which is different from our intention." ></td>
	<td class="line x" title="15:163	In contrast, the system can easily reject the latter expansion, vegetable, if we are aware of bilingual synonyms, which indicate synonymous relationsoverbilinguallexicons: (kflojflo, plant)(kflojflo, factory) and (shokubutsu1, plant)  (shokubutsu, vegetable)2 (See Figure 1)." ></td>
	<td class="line x" title="16:163	The expression of the translation equivalent, (kflojflo, plant), helps a crosslingual IR system to retrieve documents that include the term plant, used in the meaning for kflojflo, or industrial plants." ></td>
	<td class="line x" title="17:163	We present a supervised machine learning approach for identifying bilingual synonyms." ></td>
	<td class="line x" title="18:163	Designing features for bilingual synonyms such as spelling variations and bilingual associations, we train a classier with a manually annotated bilingual lexicon with synonymous information." ></td>
	<td class="line x" title="19:163	In order to evaluate the performance of our method, we carried out experiments to identify bilingual synonyms by two approaches: the direct identication of bilingual synonym pairs, and bilingual synonym pairs merged from two monolingual synonym lists." ></td>
	<td class="line x" title="20:163	Experimental results show that our approach achieves the F-scores 1Shokubutsu (	) means botanical plant." ></td>
	<td class="line x" title="21:163	2 represents the synonymous relation." ></td>
	<td class="line x" title="22:163	457 Figure 1: An example of an ambiguous term plant, and the synonyms and translation equivalents (TE) 89.3% in the former approach and 91.4% in the latter, thus outperforming the baseline method that employs only bilingual relations as its clues." ></td>
	<td class="line x" title="23:163	The remainder of this paper is organized as follows." ></td>
	<td class="line x" title="24:163	The next section describes related work on synonym extraction and spelling variations." ></td>
	<td class="line x" title="25:163	Section 3 describes the overview and denition of bilingual synonyms, the proposed method and employed features." ></td>
	<td class="line x" title="26:163	In Section 4 we evaluate our method and conclude this paper." ></td>
	<td class="line x" title="27:163	2 Related work There have been many approaches for detecting synonyms and constructing thesauri." ></td>
	<td class="line x" title="28:163	Two main resources for synonym extraction are large text corpora and dictionaries." ></td>
	<td class="line x" title="29:163	Many studies extract synonyms from large monolingual corpora by using context information around targetterms(CroachandYang, 1992; ParkandChoi, 1996; Waterman, 1996; Curran, 2004)." ></td>
	<td class="line oc" title="30:163	Some researchers (Hindle, 1990; Grefenstette, 1994; Lin, 1998) classify terms by similarities based on their distributional syntactic patterns." ></td>
	<td class="line o" title="31:163	These methods often extract not only synonyms, but also semantically related terms, such as antonyms, hyponyms and coordinate terms such as cat and dog. Some studies make use of bilingual corpora or dictionaries to nd synonyms in a target language (Barzilay and McKeown, 2001; Shimohata and Sumita, 2002; Wu and Zhou, 2003; Lin et al., 2003)." ></td>
	<td class="line x" title="32:163	Lin et al.(2003) chose a set of synonym candidates for a term by using a bilingual dictionary and computing distributional similarities in the candidate set to extract synonyms." ></td>
	<td class="line x" title="34:163	They adopt the bilingual information to exclude non-synonyms (e.g., antonyms and hyponyms) that may be used in the similar contexts." ></td>
	<td class="line x" title="35:163	Although they make use of bilingual dictionaries, this study aims at nding bilingual synonyms directly." ></td>
	<td class="line x" title="36:163	In the approaches based on monolingual dictionaries, the similarities of denitions of lexical items are important clues for identifying synonyms (Blondel et al., 2004; Muller et al., 2006)." ></td>
	<td class="line x" title="37:163	For instance, Blondel et al.(2004) constructed an associated dictionary graph whose vertices are the terms, and whose edges from v1 to v2 represent occurrence of v2 in the denition for v1." ></td>
	<td class="line x" title="39:163	They choose synonyms from the graph by collecting terms pointed to and from the same terms." ></td>
	<td class="line x" title="40:163	Another strategy for nding synonyms is to consider the terms themselves." ></td>
	<td class="line x" title="41:163	We divide it into two approaches: rule-based and distance-based." ></td>
	<td class="line x" title="42:163	Rule-based approaches implement rules with language-specic patterns and detect variations by applying rules to terms." ></td>
	<td class="line x" title="43:163	Stemming (Lovins, 1968; Porter, 1980) is one of the rule-based approaches, which cuts morphological sufx inections, and obtains the stems of words." ></td>
	<td class="line x" title="44:163	There are other types of variations for phrases; for example, insertion, deletion or substitution of words, and permutation of words such as view point and point of view are such variations (Daille et al., 1996)." ></td>
	<td class="line x" title="45:163	Distance-based approaches model the similarity or dissimilarity measure between two terms to nd similar terms." ></td>
	<td class="line x" title="46:163	The edit distance (Levenshtein, 1966) is the most widely-used measure, based on the minimum number of operations of insertion, deletion, or substitution of characters for transforming one term into another." ></td>
	<td class="line x" title="47:163	It can be efciently calculated by using 458 Term pairs Concept p1 = (shflomei (	), light) c1 p2 = (shflomei, lights) c1 p3 = (karui (0M), light) c2 p4 = (raito (), light) c1,c2 p5 = (raito, lights) c1 p6 = (raito, right) c3 p7 = (migi (), right) c3 p8 = (raito, right elder) c4 p9 = (kenri (Vb), right) c5 p10 = (kenri, rights) c5 Table 1: An Example of a bilingual lexicon and synonym sets (concepts) J terms E terms Description c1 shflomei, raito light, lights illumination c2 karui, raito light lightweight c3 migi, raito right right-side c4 raito right elder (baseball) c5 kenri right, rights privilege Table 2: The concepts in Table 1 a dynamic programming algorithm, and we can set the costs/weights for each character type." ></td>
	<td class="line x" title="48:163	3 Bilingual Synonyms and Translation Equivalents This section describes the notion of bilingual synonyms and our method for identifying the synonymous pairs of translation equivalents." ></td>
	<td class="line x" title="49:163	We consider a bilingual synonym as a set of translation-equivalent term pairs referring to the same concept." ></td>
	<td class="line x" title="50:163	Tables 1 and 2 are an example of bilingual synonym sets." ></td>
	<td class="line x" title="51:163	There are ten Japanese-English translation-equivalent term pairs and ve bilingual synonym sets in this example." ></td>
	<td class="line x" title="52:163	A Japanese term raito is the phonetic transcription of both light and right, and it covers four concepts described by the three English terms." ></td>
	<td class="line x" title="53:163	Figure 2 illustrates the relationship among these terms." ></td>
	<td class="line x" title="54:163	The synonymous relation and the translation equivalence are considered to be similar in that two terms share the meanings." ></td>
	<td class="line x" title="55:163	Following synonymous relation between terms in one language, we deal with the synonymous relation between bilingual translation-equivalent term pairs Figure 2: Relations among terms in Table 2 Solid lines show that two terms are translation equivalents, while dotted lines show that two terms are (monolingual) synonyms." ></td>
	<td class="line x" title="56:163	as bilingual synonyms." ></td>
	<td class="line x" title="57:163	The advantage of managing the lexicon in the format of bilingual synonyms is that we can facilitate to tie the concepts and the terms." ></td>
	<td class="line x" title="58:163	3.1 Denitions Let E and F be monolingual lexicons." ></td>
	<td class="line x" title="59:163	We rst assume that a term e  E (or f  F) refers to one or more concepts, and dene that a term e is a synonym3 of e0( E) if and only if e and e0 share an identical concept4." ></td>
	<td class="line x" title="60:163	Let  represent the synonymous relation, and this relation is not transitive because a term often has several concepts: e  e0  e0  e00 6= e  e00." ></td>
	<td class="line x" title="61:163	(1) We dene a synonym set (synset) Ec as a set whose elements share an identical concept c: Ec = {e  E|e refers to c}." ></td>
	<td class="line x" title="62:163	For a term set Ec( E), Ec is a synonym set (synset) = e,e0  Ec e  e0 (2) is true, but the converse is not necessarily true, because of the ambiguity of terms." ></td>
	<td class="line x" title="63:163	Note that one term can belong to multiple synonym sets from the denition." ></td>
	<td class="line x" title="64:163	Let D( F  E) be a bilingual lexicon dened as a set of term pairs (f,e) (f  F,e  E) satisfying that f and e refer to an identical concept." ></td>
	<td class="line x" title="65:163	We 3For distinguishing from bilingual synonyms, we often call the synonym a monolingual synonym." ></td>
	<td class="line x" title="66:163	4The denition of concepts, that is, the criteria of deciding whether two terms are synonymous or not, is beyond the focus of this paper." ></td>
	<td class="line x" title="67:163	We do not assume that related terms such as hypernyms, hyponyms and coordinates are kinds of synonyms." ></td>
	<td class="line x" title="68:163	In our experiments the criteria depend on manual annotation of synonym IDs in the training data." ></td>
	<td class="line x" title="69:163	459 call these pairs translation equivalents, which refer to concepts that both f and e refer to." ></td>
	<td class="line x" title="70:163	We dene that two bilingual lexical items p and p0( D) are bilingual synonyms if and only if p and p0 refer to an identical concept in common with the denition of (monolingual) synonyms." ></td>
	<td class="line x" title="71:163	This relation is not transitive again, and if e  e0 and f  f0, it is not necessarily true that p  p0: e  e0  f  f0 6= p  p0 (3) because of the ambiguity of terms." ></td>
	<td class="line x" title="72:163	Similarly, we can dene a bilingual synonym set (synset) Dc as a set whose elements share an identical meaning c: Dc = {p  D|p refers to c}." ></td>
	<td class="line x" title="73:163	For a set of translation eqiuvalents Dc, Dc is a bilingual synonym set (synset) = p,p0  Dc p  p0 (4) is true, but the converse is not necessarily true." ></td>
	<td class="line x" title="74:163	3.2 Identifying bilingual synonym pairs In this section, we describe an algorithm to identify bilingual synonym pairs by using spelling variation clues." ></td>
	<td class="line x" title="75:163	After identifying the pairs, we can construct bilingual synonym sets by assuming that the converse of the condition (4) is true, and nding sets of bilingual lexical items in which all paired items are bilingual synonyms." ></td>
	<td class="line x" title="76:163	We can see this method as the complete-linkage clustering of translationequivalent term pairs." ></td>
	<td class="line x" title="77:163	We can adopt another option to construct them by assuming also that the bilingual synonymous relation has transitivity: p  p0 p0  p00 = p  p00, and this can be seen as simplelinkage clustering." ></td>
	<td class="line x" title="78:163	This simplied method ignores the ambiguity of terms, and it may construct a bilingual synonym sets which includes many senses." ></td>
	<td class="line x" title="79:163	In spite of the risk, it is effective to nd large synonym sets in case the bilingual synonym pairs are not sufciently detected." ></td>
	<td class="line x" title="80:163	In this paper we focus only on identifying bilingual synonym pairs and evaluating the performance of the identication." ></td>
	<td class="line x" title="81:163	We employ a supervised machine learning technique with features related to spelling variations and so on." ></td>
	<td class="line x" title="82:163	Figure 3 shows the framework for this method." ></td>
	<td class="line x" title="83:163	At rst we prepare a bilingual lexicon with synonymous information as training data, and generate a list consisting of all bilingual lexical item Figure 3: Overview of our framework pairs in the bilingual lexicon." ></td>
	<td class="line x" title="84:163	The presence or absence of bilingual synonymous relations is attached to each element of the list." ></td>
	<td class="line x" title="85:163	Then, we build a classier learned by training data, using a maximum entropy model (Berger et al., 1996) and the features related to spelling variations in Table 3." ></td>
	<td class="line x" title="86:163	We apply some preprocessings for extracting some features." ></td>
	<td class="line x" title="87:163	For English, we transform all terms into lower-case, and do not apply any other transformations such as tokenization by symbols." ></td>
	<td class="line x" title="88:163	For Japanese, we apply a morphological analyzer JUMAN (Kurohashi et al., 1994) and obtain hiragana representations5 as much as possible6." ></td>
	<td class="line x" title="89:163	We may require other language-specic preprocessings for applying this method to other languages." ></td>
	<td class="line x" title="90:163	We employed binary or real-valued features described in Table 3." ></td>
	<td class="line x" title="91:163	Moreover, we introduce the following combinatorial features: h1F  h1E, h2F h2E, h3F h3E, h5E  h5F, h6  h2F and h7 h2E." ></td>
	<td class="line x" title="92:163	3.2.1 Two approaches for identifying bilingual synonym pairs There are two approaches for identifying bilingual synonym pairs: one is directly identifying whether two bilingual lexical items are bilingual synonyms (bilingual method), and another is rst 5Hiragana is one of normalized representations of Japanese terms, which denotes how to pronounce the term." ></td>
	<td class="line x" title="93:163	Japanese vocabularyhasmanyofhomonyms, whicharesemanticallydifferent but have the same pronunciation." ></td>
	<td class="line x" title="94:163	Despite the risk of classifying homonyms into synonyms, we do not use original forms of Japanese terms because they are typically too short to extract character similarities." ></td>
	<td class="line x" title="95:163	6We keep unknown terms of JUMAN unchanged." ></td>
	<td class="line x" title="96:163	460 h1F,h1E: Agreement of the rst characters Whether the rst characters match or not h2F,h2E: Normalized edit distance 1 ED(w,w0)max(jwj,jw0j), where ED(w,w0) is a non-weighted edit distance between w and w0 and |w| is the number of characters in w h3F,h3E: Bigram similarity jbigram(w)\bigram(w0)jmax(jwj,jw0j)1 , where bigram(w) is a multiset of character-based bigrams in w h4F,h4E: Agreement or known synonymous relation of word sub-sequences The count that sub-sequences of the target terms match as known terms or are in known synonymous relation h5F,h5E: Existence of crossing bilingual lexical items For bilingual lexical items (f1,e1) and (f2,e2), whether (f1,e2) (for h5F) or (f2,e1) (for h5E) is in the bilingual lexicon of the training set h6: Acronyms Whether one English term is an acronym for another (Schwartz and Hearst, 2003) h7: Katakana variants Whether one Japanese term is a katakana variant for another (Masuyama et al., 2004) Table 3: Features used for identifying bilingual synonym pairs hiF is the feature value when the terms w and w0( F) are compared in the i-th feature and so as hiE." ></td>
	<td class="line x" title="97:163	h6 is only for English and h7 is only for Japanese." ></td>
	<td class="line x" title="98:163	identifying monolingual synonyms in each language and then merging them according to the bilingual items (monolingual method)." ></td>
	<td class="line x" title="99:163	We implement these two approaches and compare the results." ></td>
	<td class="line x" title="100:163	For identifying monolingual synonyms, we use features with bilingual items as follows: For a term pair e1 and e2, we obtain all the translation candidates F1 = {f|(f,e1)  D} and F2 = {f0|(f0,e2)  D}, and calculate feature values related to F1 and/or F2 by obtaining the maximum feature value using F1 and/or F2." ></td>
	<td class="line x" title="101:163	After that, if all the following four conditions (p1 = (f1,e1)  D, p2 = (f2,e2)  D, f1  e1 and f2  e2) are satised, we assume that p1 and p2 are bilingual synonym pairs7." ></td>
	<td class="line x" title="102:163	4 Experiment 4.1 Experimental settings We performed experiments to identify bilingual synonym pairs by using the Japanese-English lexicon with synonymous information8." ></td>
	<td class="line x" title="103:163	The lexicon consists of translation-equivalent term pairs extracted from titles and abstracts of scientic papers published in Japan." ></td>
	<td class="line x" title="104:163	It contains many spelling variations and synonyms for constructing and maintaining the 7Actually, these conditions are not sufcient to derive the bilingual synonym pairs described in Section 3.1." ></td>
	<td class="line x" title="105:163	We assume this approximation because there seems to be few counter examples in actual lexicons." ></td>
	<td class="line x" title="106:163	8This data was edited and provided by Japan Science and Technology Agency (JST)." ></td>
	<td class="line x" title="107:163	Total train dev." ></td>
	<td class="line x" title="108:163	test |D| 210647 168837 20853 20957 |J| 136128 108325 13937 13866 |E| 115002 91057 11862 12803 Synsets 50710 40568 5071 5071 Pairs 814524 651727 77706 85091 Table 5: Statistics of the bilingual lexicon for our experiment |D|,|J|, and |E| are the number of bilingual lexical items, the number of Japanese vocabularies, and the number of English vocabularies, respectively." ></td>
	<td class="line x" title="109:163	Synsets and Pairs are the numbers of synonym sets and synonym pairs, respectively." ></td>
	<td class="line x" title="110:163	thesaurus of scientic terms and improving the coverage." ></td>
	<td class="line x" title="111:163	Table 4 illustrates this lexicon." ></td>
	<td class="line x" title="112:163	Table 5 shows the statistics of the dictionary." ></td>
	<td class="line x" title="113:163	We used information only synonym IDs and Japanese and English representations." ></td>
	<td class="line x" title="114:163	We extract pairs of bilingual lexical items, and treat them as events for training of the maximum entropy method." ></td>
	<td class="line x" title="115:163	The parameters were adjusted so that the performance is the best for the development set." ></td>
	<td class="line x" title="116:163	For a monolingual method, we used Tb = 0.8, and for a bilingual method, we used Tb = 0.7." ></td>
	<td class="line x" title="117:163	4.2 Evaluation We evaluated the performance of identifying bilingual synonym pairs by the pair-wise precision P, 461 Synset ID J term E term 130213 . (shintai-bui) Body Regions 130213 . (shintai-bui) body part 130213 . (shintai-bui) body region 130213 .  (shintai-bubun) body part 130217 Douglas0(Douglas-ka) Douglas Pouch 130217 DouglasT(Douglas-ka) Douglas Pouch 1302170(Dagurasu-ka) pouch of Douglas 130217T(Dagurasu-ka) pouch of Douglas 130217v0(chokuchflo-shikyflu-ka) rectouterine pouch 130217vT(chokuchflo-shikyflu-ka) rectouterine pouch Table 4: A part of the lexicon used Each bilingual synonym set consists of items that have the same synset ID.  (bubun) is a synonym of  (bui).T(ka) is a hiragana representation of0(ka).(Dagurasu) is a Japanese transcription of Douglas." ></td>
	<td class="line x" title="118:163	recall R and F-score F dened as follows: P = CT ,R = CN,F = 2PRP +R, (5) where C,T and N are the number of correctly predicted pairs as synonyms, predicted pairs to become synonyms, and synonym pairs in the lexicon9, respectively." ></td>
	<td class="line x" title="119:163	We compared the results with the baseline and the upper bound." ></td>
	<td class="line x" title="120:163	The baseline assumes that each bilingual lexical item is a bilingual synonym if either the Japanese or English terms are identical." ></td>
	<td class="line x" title="121:163	The upper bound assumes that all the monolingual synonyms are known and each bilingual item is a bilingual synonym if the Japanese terms and the English terms are synonymous." ></td>
	<td class="line x" title="122:163	The baseline represents the performance when we do not consider spelling variations, and the upper bound shows the limitation of the monolingual approach." ></td>
	<td class="line x" title="123:163	4.3 Result Table 6 shows the evaluation scores of our experiments." ></td>
	<td class="line x" title="124:163	The monolingual and bilingual methods are described in Section 3.2.1." ></td>
	<td class="line x" title="125:163	We obtained high precision and recall scores, although we used features primarily with spelling variations." ></td>
	<td class="line x" title="126:163	Both methods signicantly outperform the baseline, and show the importance of considering spelling variations." ></td>
	<td class="line x" title="127:163	9N includes the number of synonym pairs ltered out from training set by the bigram similarity threshold Tb." ></td>
	<td class="line x" title="128:163	Set Method Precision Recall F-score dev." ></td>
	<td class="line x" title="129:163	baseline 0.977 (31845/32581) 0.410 (31845/77706) 0.577 monolingual 0.911 (74263/81501) 0.956 (74263/77706) 0.932 bilingual 0.879 (72782/82796) 0.937 (72782/77706) 0.907 upper bound 0.984 (77706/78948) 1 0.992 test baseline 0.972 (33382/34347) 0.392 (33382/85091) 0.559 monolingual 0.900 (79099/87901) 0.930 (79099/85091) 0.914 bilingual 0.875 (77640/88714) 0.912 (77640/85091) 0.893 upper bound 0.979 (85091/86937) 1 0.989 Table 6: Evaluation scores The monolingual method achieved higher precision and recall than the bilingual method." ></td>
	<td class="line x" title="130:163	It indicates that monolingual synonym identication is effective in nding bilingual synonyms." ></td>
	<td class="line x" title="131:163	The upper bound shows that there are still a few errors by the assumption used by the monolingual method." ></td>
	<td class="line x" title="132:163	However, the high precision of the upper bound represents the well-formedness of the lexicon we used." ></td>
	<td class="line x" title="133:163	We need more experiments on other bilingual lexicons to conclude that our method is available for 462 Features Precision Recall F-score All 0.911 0.956 0.932 h1F,h1E 0.911 0.974 0.941 h2F,h2E 0.906 0.947 0.926 h3F,h3E 0.939 0.930 0.934 h4F,h4E 0.919 0.734 0.816 h5F,h5E 0.869 0.804 0.831 h6,h7 0.940 0.934 0.937 combs." ></td>
	<td class="line x" title="134:163	0.936 0.929 0.932 Table 7: Evaluation scores of the bilingual method with removing features on the development set h represents removing the feature h and combinatorial features using h. combs." ></td>
	<td class="line x" title="135:163	represents removing all the combinatorial features." ></td>
	<td class="line x" title="136:163	many kinds of lexicons." ></td>
	<td class="line x" title="137:163	To investigate the effectiveness of each feature, we compared the scores when we remove several features." ></td>
	<td class="line x" title="138:163	Table 7 shows these results." ></td>
	<td class="line x" title="139:163	Contrary to our intuition, we found that features of agreement of the rst characters (h1) remarkably degraded the recall without gains in precision." ></td>
	<td class="line x" title="140:163	One of the reasons for such results is that there are many cases of non-synonyms that have the same rst character." ></td>
	<td class="line x" title="141:163	We need to investigate more effective combinations of features or to apply other machine learning techniques for improving the performance." ></td>
	<td class="line x" title="142:163	From these results, we consider that the features of h4 are effective for improving the recall, and that the features of h2 and h5 contribute improvement of both the precision and the recall." ></td>
	<td class="line x" title="143:163	h3, h6, h7, and combinatorial features seem to improve the recall at the expense of precision." ></td>
	<td class="line x" title="144:163	Which measure is important depends on the importance of our target for using this technique." ></td>
	<td class="line x" title="145:163	It depends on the requirements that we emphasize, but in general the recall is more important for nding more bilingual synonyms." ></td>
	<td class="line x" title="146:163	5 Conclusion and future work This paper proposed a method for identifying bilingual synonyms in a bilingual lexicon by using clues of spelling variations." ></td>
	<td class="line x" title="147:163	We described the notion of bilingual synonyms, and presented two approaches for identifying them: one is to directly predict the relation, and another is to merge monolingual synonyms identied, according to the bilingual lexicon." ></td>
	<td class="line x" title="148:163	Our experiments showed that the proposed method signicantly outperformed the method that did not use features primarily with spelling variations; the proposed method extracted bilingual synonyms with high precision and recall." ></td>
	<td class="line x" title="149:163	In addition, we found that merging monolingual synonyms by the dictionary is effective for nding bilingual synonyms; there occur few errors through the assumption described in Section 3.2.1." ></td>
	<td class="line x" title="150:163	Our future work contains implementing more features for identifying synonymous relations, constructing bilingual synonym sets, and evaluating our methodforspecictaskssuchasthesaurusconstruction or cross-lingual information retrieval." ></td>
	<td class="line x" title="151:163	Currently, the features used do not include other clues with spelling variations, such as the weighted edit distance, transformation patterns, stemming and so on." ></td>
	<td class="line x" title="152:163	Another important clue is distributional information, such as the context." ></td>
	<td class="line x" title="153:163	We can use both monolingual and bilingual corpora for extracting distributions of terms, and bilingual corpora are expected to be especially effective for our goal." ></td>
	<td class="line x" title="154:163	We did not perform an experiment to construct bilingual synonym sets from synonym pairs in this paper." ></td>
	<td class="line x" title="155:163	Described in Section 3.1, bilingual synonym sets can be constructed from bilingual synonym pairs by assuming some approximations." ></td>
	<td class="line x" title="156:163	The approximation that permits transitivity of bilingual synonymous relations increases identied bilingual synonyms, and thus causes an increase in recall and decrease in precision." ></td>
	<td class="line x" title="157:163	It is an open problem to nd appropriate strategies for constructing bilingual synonym sets." ></td>
	<td class="line x" title="158:163	Finally, we plan to evaluate our method for specic tasks." ></td>
	<td class="line x" title="159:163	For data-driven machine translation, it is expected that data sparseness problem is alleviated by merging the occurrences of low-frequency terms." ></td>
	<td class="line x" title="160:163	Another application is cross-lingual information retrieval, which can be improved by using candidate expanded queries from bilingual synonym sets." ></td>
	<td class="line x" title="161:163	Acknowledgments This work was partially supported by Grant-in-Aid for Specially Promoted Research (MEXT, Japan) and Japanese/Chinese Machine Translation Project in Special Coordination Funds for Promoting Science and Technology (MEXT, Japan)." ></td>
	<td class="line x" title="162:163	We thank 463 Japan Science and Technology Agency (JST) for providing a useful bilingual lexicon with synonymous information." ></td>
	<td class="line x" title="163:163	We acknowledge the anonymous reviewers for helpful comments and suggestions." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I08-1072
Context Feature Selection for Distributional Similarity
Hagiwara, Masato;Ogawa, Yasuhiro;Toyama, Katsuhiko;"></td>
	<td class="line x" title="1:114	Context Feature Selection for Distributional Similarity Masato Hagiwara, Yasuhiro Ogawa, and Katsuhiko Toyama Graduate School of Information Science, Nagoya University Furo-cho, Chikusa-ku, Nagoya, JAPAN 464-8603 {hagiwara, yasuhiro, toyama}@kl.i.is.nagoya-u.ac.jp Abstract Distributional similarity is a widely used concept to capture the semantic relatedness ofwordsinvariousNLPtasks." ></td>
	<td class="line x" title="2:114	However, accurate similarity calculation requires a large number of contexts, which leads to impractically high computational complexity." ></td>
	<td class="line x" title="3:114	To alleviate the problem, we have investigated the effectiveness of automatic context selection by applying feature selection methods explored mainly for text categorization." ></td>
	<td class="line x" title="4:114	Our experiments on synonym acquisition have shown that while keeping or sometimes increasing the performance, we can drastically reduce the unique contexts up to 10% of the original size." ></td>
	<td class="line x" title="5:114	We have also extended the measures so that they cover context categories." ></td>
	<td class="line x" title="6:114	The result shows a considerable correlation between the measures and the performance, enabling the automatic selection of effective context categories for distributional similarity." ></td>
	<td class="line x" title="7:114	1 Introduction Semantic similarity of words is one of the most important lexical knowledge for NLP tasks including word sense disambiguation and synonym acquisition." ></td>
	<td class="line x" title="8:114	To measure the semantic relatedness of words, a concept called distributional similarity has been widely used." ></td>
	<td class="line x" title="9:114	Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts." ></td>
	<td class="line pc" title="10:114	A wide range of contextual information, such as surrounding words (Lowe and McDonald, 2000; Curran and Moens, 2002a), dependency or case structure (Hindle, 1990; Ruge, 1997; Lin, 1998), and dependency path (Lin and Pantel, 2001; Pado and Lapata, 2007), has been utilized for similarity calculation, and achieved considerable success." ></td>
	<td class="line n" title="11:114	However, amajorproblemwhichariseswhenadopting distributional similarity is that it easily yields a huge amount of unique contexts." ></td>
	<td class="line x" title="12:114	This can lead to high dimensionality of context space, often up to the orderoftensorhundredsofthousands, whichmakes the calculation computationally impractical." ></td>
	<td class="line x" title="13:114	Because not all of the contexts are useful, it is strongly required for the efciency to eliminate the unwanted contexts to ease the expensive cost." ></td>
	<td class="line x" title="14:114	To tackle this issue, Curran and Moens (2002b) suggest assigning an index vector of canonical attributes, i.e., a small number of representative elements extracted from the original vector, to each word." ></td>
	<td class="line x" title="15:114	Whenthecomparisonisperformed, canonical attributes of two target words are rstly consulted, and the original vectors are referred to only if the attributes have a match between them." ></td>
	<td class="line x" title="16:114	However, it is not clear whether the condition for canonical attributes they adopted, i.e., that the attributes must be the most weighted subject, direct object, or indirect object, is optimal in terms of the performance." ></td>
	<td class="line x" title="17:114	There are also some existing studies which paid attention to the comparison of context categories for synonym acquisition (Curran and Moens, 2002a; Hagiwara et al., 2006)." ></td>
	<td class="line x" title="18:114	However, they have conductedonlyaposterioricomparisonbasedonperformance evaluation, and we are afraid that these nd553 ings are somewhat limited to their own experimental settings which may not be applicable to completely new settings, e.g., one with a new set of contexts extracted from different sources." ></td>
	<td class="line x" title="19:114	Therefore, general quantitative measures which can be used for reduction and selection of any kind of contexts and context categories are strongly required." ></td>
	<td class="line x" title="20:114	Shifting our attention from word similarity to other areas, a great deal of studies on feature selection has been conducted in the literature, especially for text categorization (Yang and Pedersen, 1997) and gene expression classication (Ding and Peng, 2003)." ></td>
	<td class="line x" title="21:114	Whereas these methods have been successful in reducing feature size while keeping classication performance, the problem of distributional similarity is radically different from that of classication, and whether the same methods are applicable and effective for automatic context selection in the similarity problem is yet to be investigated." ></td>
	<td class="line x" title="22:114	In this paper, we rstly introduce existing quantitative methods for feature selection, namely, DF, TS, MI, IG, CHI2, and show how to apply them to the distributional similarity problem to measure the context importance." ></td>
	<td class="line x" title="23:114	We then extracted dependency relations as context from the corpus, and conducted automatic synonym acquisition experiments to evaluate the context selection performance, reducing the unimportant contexts based on the feature selection methods." ></td>
	<td class="line x" title="24:114	Finally we extend the context importance to cover context categories (RASP2 grammatical relations), and show that the above methods are also effective in selecting categories." ></td>
	<td class="line x" title="25:114	This paper is organized as follows: in Section 2, ve existing context selection methods are introduced, and how to apply classication-based selection methods to distributional similarity is described." ></td>
	<td class="line x" title="26:114	In Section 3 and 4, the synonym acquisition method and evaluation measures, AP and CC, employed in the evaluation experiments are detailed." ></td>
	<td class="line x" title="27:114	Section 5 includes two main experiments and their results: context reduction and context category selection, along with experimental settings and discussions." ></td>
	<td class="line x" title="28:114	Section 6 concludes this paper." ></td>
	<td class="line x" title="29:114	2 Context Selection Methods In this section, context selection methods proposed for text categorization or information retrieval are introduced." ></td>
	<td class="line x" title="30:114	In the following, n and m represent the number of unique words and unique contexts, respectively, and N(w,c) denotes the number of cooccurrence of word w and context c. 2.1 Document Frequency (DF) Document frequency (DF), commonly used for weighting in information retrieval, is the number of documents a term co-occur with." ></td>
	<td class="line x" title="31:114	However, in the distributional similarity settings, DF corresponds to word frequency, i.e., thenumberofuniquewordsthe context co-occurs with: df(c) = |{w|N(w,c) > 0}|." ></td>
	<td class="line x" title="32:114	ThemotivationofadoptingDFasacontextselection criterion is the assumption that the contexts shared by many words should be informative." ></td>
	<td class="line x" title="33:114	It is to note, however, that the contexts with too high DF are not always useful, since there are some exceptions including so-called stopwords." ></td>
	<td class="line x" title="34:114	2.2 Term Strength (TS) Term strength (TS), proposed by Wilbur and Sirotkin (1992) and applied to text categorization by Yang and Wilbur (1996), measures how likely a term is to appear in  similar documents, and it is shown to achieve a successful outcome in reducing the amount of vocabulary for text retrieval." ></td>
	<td class="line x" title="35:114	For distributional similarity, TS is dened as: s(c) = P(c  C(w2)|c  C(w1)), where (w1,w2) is a related word pair and C(w) is a set of contexts co-occurring with the word w, i.e., C(w) = {c|N(w,c) > 0}." ></td>
	<td class="line x" title="36:114	s(c) is calculated, letting PH be a set of related word pairs, as s(c) = |{(w1,w2)  PH|c  C(w1) C(w2)}||{(w 1,w2)  PH|c  C(w1)}| . What makes TS different from DF is that it requires a training set PH consisting of related word pairs." ></td>
	<td class="line x" title="37:114	We used the test set for class s = 1 as PH described in the next section." ></td>
	<td class="line x" title="38:114	2.3 Formalization of Distributional Similarity The following methods, MI, IG, and CHI2, are radically different from the above ones, in that they are 554 designed essentially for  class classication problems." ></td>
	<td class="line x" title="39:114	Thus we formalize distributional similarity as a classication problem as described below." ></td>
	<td class="line x" title="40:114	First of all, we deal with word pairs, instead of words, asthetargetsofclassication, anddenefeatures f1,,fm corresponding to contexts c1,,cm, for each pair." ></td>
	<td class="line x" title="41:114	The feature fj = 1 if the two words of the pair has the context cj in common, and fj = 0 otherwise." ></td>
	<td class="line x" title="42:114	Then, we dene target class s, so that s = 1 when the pair is semantically related, and s = 0 if not." ></td>
	<td class="line x" title="43:114	These dened, distributional similarity is formalized as a binary classication problem which assigns the word pairs to the class s  {0,1} based on the features c1,,cm." ></td>
	<td class="line x" title="44:114	Finally, to calculate the specic values of the following feature importance measures, we prepare two test sets of related word pairs for class s = 1 and unrelated ones for class s = 0." ></td>
	<td class="line x" title="45:114	This enables us to apply existing feature selection methods designed for classication problems to the automatic context selection." ></td>
	<td class="line x" title="46:114	The two test sets, related and unrelated one, are prepared using the reference sets described in Section 4." ></td>
	<td class="line x" title="47:114	More specically, we created 5,000 related word pairs by extracting from synonym pairs in the referenceset,and5,000unrelatedonesbyrstlycreatingrandompairsofLDV,whosedetailisdescribed later, and then manually making sure that no related pairs are included in these random pairs." ></td>
	<td class="line x" title="48:114	2.4 Mutual Information (MI) Mutual information (MI), commonly used for word association and co-occurrence weighing in statistical NLP, is the measure of the degree of dependence between two events." ></td>
	<td class="line x" title="49:114	The pointwise MI value of feature f and class s is calculated as: I(f,s) = log P(f,s)P(f)P(s)." ></td>
	<td class="line x" title="50:114	To obtain the nal context importance, we combine the MI value over both of the classes as Imax(cj) = maxs{0,1} I(fj,s)." ></td>
	<td class="line x" title="51:114	Note that, here we employed the maximum value of pointwise MI values since it is claimed to be the best in (Yang and Pedersen, 1997), although there can be other combination ways such as weighted average." ></td>
	<td class="line x" title="52:114	2.5 Information Gain (IG) Information gain (IG), often employed in the machine learning eld as a criterion for feature importance, is the amount of gained information of an event by knowing the outcome of the other event, and is calculated as the weighted sum of the pointwise MI values over all the event combinations: G(cj) =  fj{0,1}  s{0,1} P(fj,s)log P(fj,s)P(f j)P(s) . 2.6 2 Statistic (CHI2) 2 statistic (CHI2) estimates the lack of independence between classes and features, which is equal to the summed difference of observed and expected frequency over the contingency table cells." ></td>
	<td class="line x" title="53:114	More specically,lettingFjnm(n,m  {0,1})bethenumber of word pairs with fj = n and s = m, and the number of all pairs be N, 2 statistic is dened as: 2(cj) = N(F11F00 F01F10)(F 11 + F01)(F10 + F00)(F11 + F10)(F01 + F00) . 3 Synonym Acquisition Method This section describes the synonym acquisition method, a major and important application of distributional similarity, which we employed for the evaluation of automatic context selection." ></td>
	<td class="line x" title="54:114	Here we mention how to extract the original contexts from corpora in detail, as well as the calculation of weight and similarity between words." ></td>
	<td class="line pc" title="55:114	3.1 Context Extraction We adopted dependency structure as the context of words since it is the most widely used and wellperforming contextual information in the past studies (Ruge, 1997; Lin, 1998)." ></td>
	<td class="line x" title="56:114	As the extraction of accurateandcomprehensivedependencystructureisin itself a difcult task, the sophisticated parser RASP Toolkit 2 (Briscoe et al., 2006) was utilized to extract this kind of word relations." ></td>
	<td class="line x" title="57:114	Take the following sentence for example: Shipments have been relatively level since January, the Commerce Department noted." ></td>
	<td class="line x" title="58:114	555 RASP outputs the extracted dependency structure as n-ary relations as follows, which are called grammatical relations." ></td>
	<td class="line x" title="59:114	Annotations regarding sufx, part of speech tags, offsets for individual words are omitted for simplicity." ></td>
	<td class="line x" title="60:114	(ncsubj be Shipment _) (aux be have) (xcomp _ be level) (ncmod _ be relatively) (ccomp _ level note) (ncmod _ note since) (ncsubj note Department _) (det Department the) (ncmod _ Department Commerce) (dobj since January) While the RASP outputs are n-ary relations in general, what we need here is co-occurrences of words and contexts, so we extract the set of cooccurrences of stemmed words and contexts by taking out the target word from the relation and replacing the slot by an asterisk  * : (words) (contexts) Shipment ncsubj:be:*_ have aux:be:* be ncsubj:*:Shipment:_ be aux:*:have be xcomp:_:*:level be ncmod:_:*:relatively relatively ncmod:_:be:* level xcomp:_:be:* level ccomp:_:*:note  Summing all these up produces the raw cooccurrence count N(w,c) of word w and context c. 3.2 Similarity Calculation Although it is possible to use the raw count acquired above for the similarity calculation, directly using the raw count may cause performance degradation, thus we need an appropriate weighting measure." ></td>
	<td class="line x" title="61:114	In response to the preliminary experiment results, we employed pointwise mutual information as weight: wgt(w,c) = log P(w,c)P(w)P(c) Here we made a small modication to bind the weight to non-negative such that wgt(w,c)  0, because negative weight values sometimes worsen the performance (Curran and Moens, 2002b)." ></td>
	<td class="line x" title="62:114	The weightingbyPMIisappliedafterthepre-processing including frequency cutoff and context selection." ></td>
	<td class="line x" title="63:114	Asforthesimilaritymeasure,weusedJaccardcoefcient, which is widely adopted to capture overlap proportion of two sets:  cC(w1)C(w2) min(wgt(w1,c),wgt(w2,c)) cC(w1)C(w2) max(wgt(w1,c),wgt(w2,c)) . 4 Evaluation Measures This section describes the two evaluation methods we employed  average precision (AP) and correlation coefcient (CC)." ></td>
	<td class="line x" title="64:114	4.1 Average Precision (AP) The rst evaluation measure, average precision (AP), is a common evaluation scheme for information retrieval, which evaluates how accurately the methods are able to extract synonyms." ></td>
	<td class="line x" title="65:114	We rst prepare a set of query words, for which synonyms are obtained to evaluate the precision." ></td>
	<td class="line x" title="66:114	We adopted the Longman Dening Vocabulary (LDV) 1 as the candidate set of query words." ></td>
	<td class="line x" title="67:114	For each word in LDV, three existing thesauri are consulted: Rogets Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998)." ></td>
	<td class="line x" title="68:114	The union of synonyms obtained when the LDV word is looked up as a noun is used as the reference set, except for words marked as  idiom,  informal,  slang and phrases comprised of two or more words." ></td>
	<td class="line x" title="69:114	The LDV words for which no noun synonyms are found in any of the reference thesauri are omitted." ></td>
	<td class="line x" title="70:114	From the remaining 771 LDV words, 100 query words are randomly extracted, and for eachofthemtheelevenprecisionvaluesat0%,10%, , and 100% recall levels are averaged to calculate the nal AP value." ></td>
	<td class="line x" title="71:114	4.2 Correlation Coefcient (CC) The second evaluation measure is correlation coefcient (CC) between the target similarity and the reference similarity, i.e., the answer value of similarity for word pairs." ></td>
	<td class="line x" title="72:114	The reference similarity is calculated based on the closeness of two words in the tree structure of WordNet." ></td>
	<td class="line x" title="73:114	More specically, the similarity between word w with senses w1,,wm1 andwordv withsensesv1,,vm2 isobtainedasfollows." ></td>
	<td class="line x" title="74:114	Let the depth of node wi and vj be di and dj, 1http://www.cs.utexas.edu/users/kbarker/working notes/ ldoce-vocab.html 556 and the depth of the deepest common ancestors of both nodes be ddca." ></td>
	<td class="line x" title="75:114	The similarity is then sim(w,v) = maxi,j sim(wi,vj) = maxi,j 2 ddcad i + dj , which takes the value between 0.0 and 1.0." ></td>
	<td class="line x" title="76:114	Then, the value of CC is calculated as the correlation coefcient of reference similarities r = (r1,r2,,rn) and target similarities s = (s1,s2,,sn) over the word pairs in sample set Ps, which is created by choosing the most similar 2,000 word pairs from 4,000 randomly created pairs from LDV." ></td>
	<td class="line x" title="77:114	To avoid test-set dependency, all the CC values presented in this paper are the average values of three trials using different test sets." ></td>
	<td class="line x" title="78:114	5 Experiments Now we describe the experimental settings and the evaluation results of context selection methods." ></td>
	<td class="line x" title="79:114	5.1 Experimental Settings As for the corpus, New York Times section of English Gigaword 2, consisting of around 914 million words and 1.3 million documents was analyzed to obtainword-contextco-occurrences." ></td>
	<td class="line x" title="80:114	Frequencycutoff was applied as a pre-processing in order to lter out any words and contexts with low frequency and to reduce computational cost." ></td>
	<td class="line x" title="81:114	More specically, any words w such that c tf(w,c) <  f and any contexts c such thatw tf(w,c) <  f, with  f = 40, were removed from the co-occurrence data." ></td>
	<td class="line x" title="82:114	Since we set our purpose here to the automatic acquisition of synonymous nouns, only the nouns except for proper nouns were selected." ></td>
	<td class="line x" title="83:114	To distinguish nouns, using POS tags annotated by RASP2, any words with POS tags APP, ND, NN, NP, PN, PP were labeled as nouns." ></td>
	<td class="line x" title="84:114	This left a total of 40,461 unique words and 139,618 unique context, which corresponds to the number of vectors and the dimensionality of semantic space, respectively." ></td>
	<td class="line x" title="85:114	5.2 Context Reduction In the rst experiment, we show the effectiveness of the ve contextual selection methods introduced in Section 2 for context reduction problem." ></td>
	<td class="line x" title="86:114	The ve 2http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?" ></td>
	<td class="line x" title="87:114	catalogId=LDC2003T05 measures were calculated for each context, and contextsweresortedbytheirimportance." ></td>
	<td class="line x" title="88:114	Thechangeof performance, AP and CC, was calculated on eliminating the low-ranked contexts and varying the proportion of remaining ones, until only 0.2% (279 in number) of the unique contexts are left." ></td>
	<td class="line x" title="89:114	The result is displayed in Figure 1." ></td>
	<td class="line x" title="90:114	The overall observation is that the performance not only kept the original level but also slightly improved even during the  aggressive reduction when more than 80% of the original contexts were eliminated and less than 20,000 contexts were left." ></td>
	<td class="line x" title="91:114	It was not until 90% (approx." ></td>
	<td class="line x" title="92:114	10,000 remaining) elimination that the AP values began to fall." ></td>
	<td class="line x" title="93:114	The tendency of performance change was almost the same for AP and CC, but we observe a slight difference regarding which of the ve measures were effective." ></td>
	<td class="line x" title="94:114	More specically, TS, IG and CHI2 worked well for AP, and DF, TS, while CHI2 did for CC." ></td>
	<td class="line x" title="95:114	On the whole, TS and CHI2 were performing the best, whereas the performance of MI quickly worsened." ></td>
	<td class="line x" title="96:114	Although the task is different, this experiment showed a very consistent result compared with the one of Yang and Pedersens (1997)." ></td>
	<td class="line x" title="97:114	This means that feature selection methods are also effective for context selection in distributional similarity, and our formalization of the problem described in Section 2 turned out to be appropriate for the purpose." ></td>
	<td class="line x" title="98:114	5.3 Context Category Selection We are then naturally interested in what kinds of contexts are included in these top-ranked effective ones and how much they affect the overall performance." ></td>
	<td class="line x" title="99:114	To investigate this, we rstly built a set of elite contexts, by gathering each top 10% (13,961 in number) contexts chosen by DF, TS, IG, and CHI2, and obtaining the intersection of these four top-rankedcontexts." ></td>
	<td class="line x" title="100:114	Itwasfoundthatthesefourhad a great deal of overlap among them, the number of which turned out to be 6,440." ></td>
	<td class="line x" title="101:114	Secondly, to measure the degree of effect a context category has, we dened category importance as the sum of all IG values of the contexts which belong to the category." ></td>
	<td class="line x" title="102:114	The reason is that, (a) IG was one of the best-performing criteria as the previous experiment showed, and (b) IG value for a set of contexts can be calculated as the sum of IG values of individual elements, assuming that all the contexts 557 0.10 0.15 0.20 0.25 020000400006000080000100000120000 Number of Unique Context Correlation Coefficient (CC) DFTS MIIG CHI2 ` (c) 6.0% 8.0% 10.0% 12.0% 14.0% 020000400006000080000100000120000 Number of Unique Context Average Precision (AP) DFTS MIIG CHI2 (a) 0.10 0.15 0.20 0.25 05000100001500020000 Number of Unique Context Correlation Coefficient (CC) DFTS IGCHI2 ` (d) 6.0% 8.0% 10.0% 12.0% 14.0% 05000100001500020000 Number of Unique Context Average Precision (AP) DFTS IGCHI2 (b) Figure 1: Performance of synonym acquisition on automatic context reduction (a) The overall view and (b) the close-up of 0 to 20,000 unique contexts for AP, and (c) the overall view and (b) the close-up for CC are mutually independent, which is a naive but practical assumption because of the high independence of acquired contexts from corpora." ></td>
	<td class="line x" title="103:114	For the categories: ncsubj, dobj, obj, obj2, ncmod, xmod, cmod, ccomp, det, ta, based on the RASP2 grammatical relations which occur frequently (more than 1.0%) in the corpus, their category importance within the elite context set was computed and showed in Figure 2." ></td>
	<td class="line x" title="104:114	The graph also shows the performance of individual context categories, calculated when each category was separately extracted from the entire corpus." ></td>
	<td class="line x" title="105:114	The result indicates that there is a considerable correlation (r = 0.760) between category importance and performance, which means it is possible to predict the nal performance of any context categories by calculating their category importance values in the limited size of selected context set." ></td>
	<td class="line x" title="106:114	Asforthequalitativedifferenceofcategorytypes, the result also shows the effectiveness of modication (ncmod) category, which is consistent with the result (Hagiwara et al., 2006) that mod is more contributing than subj and obj, which have been extensively used in the past." ></td>
	<td class="line x" title="107:114	However, it can be seen that the reason why the ncmod performs well may be only because it is the largest category in size (2,515 558 0% 2% 4% 6% 8% 10%12%14% ncsubj dobj obj obj2 ncmod xmod cmod ccomp det ta Average Precision (AP) 0 2 4 6 8 10Category Importance (CI) APCI Figure 2: Performance of synonym acquisition vs context category importance in the elite contexts)." ></td>
	<td class="line x" title="108:114	The investigation of the relations between context size and performance should be conducted in the future." ></td>
	<td class="line x" title="109:114	6 Conclusion In this study, we rstly introduced feature selection methods, previously proposed for text categorization, and showed how to apply them for automatic context selection for distributional similarity by formalizing the similarity problem as classication." ></td>
	<td class="line x" title="110:114	We then extracted dependency-based context from the corpus, and conducted evaluation experiments on automatic synonym acquisition." ></td>
	<td class="line x" title="111:114	The experimental results showed that while keeping or even improving the original performance, it is possible to eliminate a large proportion of contexts (almost up to 90%)." ></td>
	<td class="line x" title="112:114	We also extended the context importance to cover context categories based on RASP2grammaticalrelations, andshowedaconsiderable correlation between the importance and the actual performance, suggesting the possibility of automatic context category selection." ></td>
	<td class="line x" title="113:114	As the future works, we should further discuss other kinds of formalization of distributional similarity and their impact, because we introduced and only briey described a quite simple formalization model in Section 2.3." ></td>
	<td class="line x" title="114:114	More detailed investigations on the contributions of sub-categories of contexts, and other contexts than dependency structure, such as surrounding words and dependency path, is also the future work." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I08-1073
Gloss-Based Semantic Similarity Metrics for Predominant Sense Acquisition
Iida, Ryu;McCarthy, Diana;Koeling, Rob;"></td>
	<td class="line x" title="1:164	Gloss-Based Semantic Similarity Metrics for Predominant Sense Acquisition Ryu Iida Nara Institute of Science and Technology 8916-5 Takayama, Ikoma, Nara, 630-0192, Japan ryu-i@is.naist.jp Diana McCarthy and Rob Koeling University of Sussex Falmer, East Sussex BN1 9QH, UK fdianam,robkg@sussex.ac.uk Abstract In recent years there have been various approaches aimed at automatic acquisition of predominant senses of words." ></td>
	<td class="line x" title="2:164	This information can be exploited as a powerful backoff strategy for word sense disambiguation given the zipan distribution of word senses." ></td>
	<td class="line x" title="3:164	Approaches which do not require manually sense-tagged data have been proposed for English exploiting lexical resources available, notably WordNet." ></td>
	<td class="line x" title="4:164	In these approaches distributional similarity is coupled with a semanticsimilaritymeasurewhichtiesthedistributionally related words to the sense inventory." ></td>
	<td class="line x" title="5:164	The semantic similarity measures that have been used have all taken advantage of the hierarchical information in WordNet." ></td>
	<td class="line x" title="6:164	We investigate the applicability to Japanese and demonstrate the feasibility of a measure which uses only information in the dictionary denitions, in contrast with previous work on English which uses hierarchical information in addition to dictionary definitions." ></td>
	<td class="line x" title="7:164	We extend the denition based semantic similarity measure with distributional similarity applied to the words in different denitions." ></td>
	<td class="line x" title="8:164	This increases the recall of our method and in some cases, precision as well." ></td>
	<td class="line x" title="9:164	1 Introduction Word sense disambiguation (WSD) has been an active area of research over the last decade because many researches believe it will be important for applications which require, or would benet from, some degree of semantic interpretation." ></td>
	<td class="line x" title="10:164	There has been considerable skepticism over whether WSD will actually improve performance of applications, but we are now starting to see improvement in performance due to WSD in cross-lingual information retrieval (Clough and Stevenson, 2004; Vossen et al., 2006) and machine translation (Carpuat and Wu, 2007; Chan et al., 2007) and we hope that other applications such as question-answering, text simplication and summarisation might also benet as WSD methods improve." ></td>
	<td class="line x" title="11:164	In addition to contextual evidence, most WSD systems exploit information on the most likely meaning of a word regardless of context." ></td>
	<td class="line x" title="12:164	This is a powerful back-off strategy given the skewed nature of word sense distributions." ></td>
	<td class="line x" title="13:164	For example, in the English coarse grained all words task (Navigli et al., 2007) at the recent SemEval Workshop the baseline of choosing the most frequent sense using the rst WordNet sense attained precision and recall of 78.9%whichisonlyafewpercentlowerthanthetop scoring system which obtained 82.5%." ></td>
	<td class="line x" title="14:164	This nding is in line with previous results (Snyder and Palmer, 2004)." ></td>
	<td class="line x" title="15:164	Systems using a rst sense heuristic have relied on sense-tagged data or lexicographer judgmentastowhichisthepredominantsenseofaword." ></td>
	<td class="line x" title="16:164	However sense-tagged data is expensive and furthermore the predominant sense of a word will vary depending on the domain (Koeling et al., 2005; Chan and Ng, 2007)." ></td>
	<td class="line x" title="17:164	One direction of research following McCarthy et al.(2004) has been to learn the most predominant 561 sense of a word automatically." ></td>
	<td class="line x" title="19:164	McCarthy et als method relies on two methods of similarity." ></td>
	<td class="line x" title="20:164	Firstly, distributional similarity is used to estimate the predominance of a sense from the number of distributionally similar words and the strength of their distributional similarity to the target word." ></td>
	<td class="line x" title="21:164	This is done on the premise that more prevalent meanings have more evidence in the corpus data used for the distributional similarity calculations and the distributionally similar words (nearest neighbours) to a target reect the more predominant meanings as a consequence." ></td>
	<td class="line x" title="22:164	Secondly, the senses in the sense inventory are linked to the nearest neighbours using semantic similarity which incorporates information from the sense inventory." ></td>
	<td class="line x" title="23:164	It is this semantic similarity measure which is the focus of our paper in the context of the method for acquiring predominant senses." ></td>
	<td class="line x" title="24:164	Whilst the McCarthy et al.s method works well for English, other inventories do not always have WordNet style resources to tie the nearest neighbours to the sense inventory." ></td>
	<td class="line x" title="25:164	WordNet has many semantic relations as well as glosses associated with its synsets (near synonym sets)." ></td>
	<td class="line x" title="26:164	While traditional dictionaries do not organise senses into synsets, they do typically have sense denitions associated with the senses." ></td>
	<td class="line x" title="27:164	McCarthy et al.(2004) suggest that dictionary denitions can be used with their method, however in the implementation of the measure based ondictionarydenitionsthattheyuse, thedictionary denitionsareextendedtothoseofrelatedwordsusing the hierarchical structure of WordNet (Banerjee and Pedersen, 2002)." ></td>
	<td class="line x" title="29:164	This extension to the original method (Lesk, 1986) was proposed because there is not always sufcient overlap of the individual words for which semantic similarity is being computed." ></td>
	<td class="line x" title="30:164	In this paper we refer to the original method (Lesk, 1986) as lesk and the extended measure proposed by Banerjee and Pedersen as Elesk." ></td>
	<td class="line x" title="31:164	This paper investigates the potential of using the overlap of dictionary denitions with the McCarthy et al.s method." ></td>
	<td class="line x" title="32:164	We test the method for obtaining a rst sense heuristic using two publicly available datasets of sense-tagged data in Japanese, EDR (NICT, 2002) and the SENSEVAL-2 Japanese dictionarytask(Shirai, 2001)." ></td>
	<td class="line x" title="33:164	Wecontrastanimplementation of lesk (Lesk, 1986) which uses only dictionary denitions with the Jiang-Conrath measure (jcn) (Jiang and Conrath, 1997) which uses manually produced hyponym links and was used previously for this purpose on English datasets (McCarthy et al., 2004)." ></td>
	<td class="line x" title="34:164	The jcn measure is only applicable to the EDR dataset because the dictionary has hyponymy links which are not available in the SENSEVAL-2 Japanese dictionary task." ></td>
	<td class="line x" title="35:164	We also propose a new extension to lesk which does not require hand-crafted hyponym links but instead uses distributional similarity to increase the possibilities for overlap of the word denitions." ></td>
	<td class="line x" title="36:164	We refer to this new measure as DSlesk." ></td>
	<td class="line x" title="37:164	We compare this to the original lesk on both datasets and show that it increases recall, and sometimes precision too whilst not requiring hyponym links." ></td>
	<td class="line x" title="38:164	Inthenextsectionweplaceourcontributioninrelation to previous work." ></td>
	<td class="line x" title="39:164	In section 3 we summarise the methods we adopt from previous work, and describe our proposal for a semantic similarity method that can supplement the information from dictionary denitions with information from raw text." ></td>
	<td class="line x" title="40:164	In section 4 we describe the experiments on EDR and the SENSEVAL-2 Japanese dictionary task and we conclude in section 5." ></td>
	<td class="line oc" title="41:164	2 Related Work ThisworkbuildsuponthatofMcCarthyetal.(2004) which acquires predominant senses for target words from a large sample of text using distributional similarity (Lin, 1998) to provide evidence for predominance." ></td>
	<td class="line o" title="42:164	The evidence from the distributional similarity is allocated to the senses using semantic similarityfromWordNet(PatwardhanandPedersen, 2003)." ></td>
	<td class="line x" title="43:164	We will describe the method more fully below in section 3." ></td>
	<td class="line x" title="44:164	McCarthy et al.(2004) reported results for English using their automatically acquired rst sense heuristic on SemCor (Miller et al., 1993) and the SENSEVAL-2 English all words dataset (Snyder and Palmer, 2004)." ></td>
	<td class="line x" title="46:164	The results from this are promising, given that hand-labelled data is not required." ></td>
	<td class="line x" title="47:164	On polysemous nouns from SemCor they obtained 48% WSD using their method with Elesk and 46% with jcn where the random baseline was 24% and the upper-bound was 67% (derived from the SemCor test data itself)." ></td>
	<td class="line x" title="48:164	On SENSEVAL-2 all words dataset using the jcn measure 1 they obtained 63% recall which is encouraging compared to the 1They did not apply lesk to this dataset." ></td>
	<td class="line x" title="49:164	562 SemCor heuristic which obtained 68% but requires hand-labelled data." ></td>
	<td class="line x" title="50:164	The upper-bound on the dataset was 72% from the test data itself." ></td>
	<td class="line x" title="51:164	These results crucially depend on the information in the sense inventory WordNet." ></td>
	<td class="line x" title="52:164	WordNet contains hierarchical relations between word senses which are used in both jcn and Elesk." ></td>
	<td class="line x" title="53:164	There is an issue that such information may not be available in other sense inventories, and other inventories will be needed for other languages." ></td>
	<td class="line x" title="54:164	In this paper, we implement the lesk semantic similarity (Lesk, 1986) for the two Japanese lexicons used in our test datasets, i) the EDR dictionary (NICT, 2002) ii) the Iwanami Kokugo Jiten Dictionary (Nishio et al., 1994)." ></td>
	<td class="line x" title="55:164	We investigate the potential of lesk and jcn, where the latter is applicable." ></td>
	<td class="line x" title="56:164	In addition to implementing the original lesk measure, we propose an extension to the method inspired by Mihalcea et al.(2006)." ></td>
	<td class="line x" title="58:164	Mihalcea et al.(2006) used various text based similarity measures, including WordNet and corpus based similarity methods, to determine if two phrases are paraphrases." ></td>
	<td class="line x" title="60:164	They contrasted this approach with previous methods which used overlap of the words between the candidate paraphrases." ></td>
	<td class="line x" title="61:164	For each word in each of the two texts they obtain the maximum similarity between the word and any of the words from the putative paraphrase." ></td>
	<td class="line x" title="62:164	The similarity scores for each word of both phrases contribute to an overall semantic similarity between 0 and 1 and a threshold of 0.5 is used to decide if the candidate phrases are paraphrases." ></td>
	<td class="line x" title="63:164	In our work, we compare glosses of words senses (senses of the target word and senses of the nearest neighbour) rather than paraphrases." ></td>
	<td class="line oc" title="64:164	In this approach we extend the denition overlap by considering the distributional similarity (Lin, 1998) rather than identify of the words in the two denitions." ></td>
	<td class="line x" title="65:164	In addition to McCarthy et al.(2004) there are other approaches to nding predominant senses." ></td>
	<td class="line x" title="67:164	Chan and Ng (2005) use parallel data to provide estimates for sense frequency distributions to feed into a supervised WSD system." ></td>
	<td class="line x" title="68:164	Mohammad and Hirst (2006) propose an approach to acquiring predominant senses from corpora which makes use of the category information in the Macquarie Thesaurus (Barnard, 1986)." ></td>
	<td class="line x" title="69:164	Lexical chains (Galley and McKeown, 2003) may also provide a useful rst sense heuristic (Brody et al., 2006) but are produced usingWordNetrelations." ></td>
	<td class="line x" title="70:164	WeusetheMcCarthyetal." ></td>
	<td class="line x" title="71:164	approach because this is applicable without aligned corpusdata, semanticcategoryandrelationinformation and is applicable to any language assuming the minimum requirements of i) dictionary denitions associated with the sense inventory and ii) raw corpus data." ></td>
	<td class="line x" title="72:164	We adapt their technique to remove the reliance on hyponym links." ></td>
	<td class="line x" title="73:164	3 Gloss-based semantic similarity We rst summarise the McCarthy et al. method and the WordNet based semantic similarity functions (jcn and Elesk) that they use for automatic acquisition of a rst sense heuristic applied to disambiguation of English WordNet datasets." ></td>
	<td class="line x" title="74:164	We then describe the additional semantic similarity method that we propose for comparison with lesk and jcn." ></td>
	<td class="line oc" title="75:164	McCarthy et al. use a distributional similarity thesaurus acquired from corpus data using the method of Lin (1998) for nding the predominant sense of a word where the senses are dened by WordNet." ></td>
	<td class="line o" title="76:164	The thesaurus provides the k nearest neighbours to each target word, along with the distributional similarity score between the target word and its neighbour." ></td>
	<td class="line x" title="77:164	The WordNet similarity package (Patwardhan and Pedersen, 2003) is used to weight the contribution that each neighbour makes to the various senses of the target word." ></td>
	<td class="line oc" title="78:164	Let w be a target word and Nw = fn1,n2nkg be the ordered set of the top scoring k neighbours of w from the thesaurus with associated distributional similarity scores fdss(w,n1),dss(w,n2),dss(w,nk)g using (Lin, 1998)." ></td>
	<td class="line x" title="79:164	Let senses(w) be the set of senses of w for each sense of w (wsi 2 senses(w)) a ranking is obtained using: Prevalence Score(wsi)=  nj2Nw dss(w,nj) wnss(wsi,nj) wsi02senses(w)wnss(wsi0,nj) (1) where wnss is the maximum WordNet similarity score between wsi and the WordNet sense of the neighbour (nj) that maximises this score." ></td>
	<td class="line x" title="80:164	McCarthy et al. compare two different WordNet similarity scores, jcn and Elesk." ></td>
	<td class="line x" title="81:164	jcn (Jiang and Conrath, 1997) uses corpus data to estimate a frequency distribution over the classes 563 (synsets) in the WordNet hierarchy." ></td>
	<td class="line x" title="82:164	Each synset, is incremented with the frequency counts from the corpus of all words belonging to that synset, directly or via the hyponymy relation." ></td>
	<td class="line x" title="83:164	The frequency data is used to calculate the  information content (IC) of a class or sense (s): IC(s)=log(p(s)) Jiang and Conrath specify a distance measure between two senses (s1,s2): Djcn(s1,s2)= IC(s1)+IC(s2)2IC(s3) where the third class (s3) is the most informative, or most specic, superordinate synset of the two senses s1 and s2." ></td>
	<td class="line x" title="84:164	This is transformed from a distance measure in the WordNet Similarity package by taking the reciprocal: jcn(s1,s2)= 1/Djcn(s1,s2) McCarthy et al. use the above measure with wsi as s1 and whichever sense of the neigbour (nj) that maximises this WordNet similarity score." ></td>
	<td class="line x" title="85:164	Elesk (Banerjee and Pedersen, 2002) extends the original lesk algorithm (Lesk, 1986) so we describe that original algorithm lesk rst." ></td>
	<td class="line x" title="86:164	This simply calculates the overlap of the content words in the denitions, frequently referred to as glosses, of the two word senses." ></td>
	<td class="line x" title="87:164	lesk(s1,s2)= a2g1 member(a,g2) member(a,g2)= { 1 if a appears in g2 0 otherwise where g1 istheglossofwordsense s1, g2 isthegloss of s2 and a is one of words appearing in g1." ></td>
	<td class="line x" title="88:164	In Elesk which McCarthy et al. use the measure is extended by considering related synsets to s1 and s2, again where s1 is wsi and s2 is the sense from all senses of nj that maximises the Elesk WordNet similarity score." ></td>
	<td class="line x" title="89:164	Elesk relies heavily on the relationships that are encoded in WordNet such as hyponymy and meronymy." ></td>
	<td class="line x" title="90:164	Not all languages have resources supplied with these relations, and where they are supplied there may not be as much detail as there is in WordNet." ></td>
	<td class="line x" title="91:164	In this paper we will examine the use of jcn and the original lesk in Japanese on the EDR dataset to see how well the pure denition based measure fares compared to one using hyponym links." ></td>
	<td class="line x" title="92:164	EDR has hyponym links so we can make this comparison." ></td>
	<td class="line x" title="93:164	The performance of jcn will depend on the coverage of the hyponym links." ></td>
	<td class="line x" title="94:164	For lesk meanwhile there is an issue that using only overlap of sense denitions may give poor results because the sense denitions are usually succinct and the overlap of words may be low." ></td>
	<td class="line x" title="95:164	For example, given the glosses for the words pigeon and bird:2 pigeon: a fat grey and white bird with short legs." ></td>
	<td class="line x" title="96:164	bird: a creature that is covered with feathers and has wings and two legs." ></td>
	<td class="line x" title="97:164	If only content words are considered then there is only one word (leg) which overlaps in the two glosses, so the resultant lesk score is low (1) even though the word pigeon is intuitively similar to bird." ></td>
	<td class="line x" title="98:164	The Elesk extension addressed this issue using WordNet relations to extend the denitions over which the overlap is calculated for a given pair of senses." ></td>
	<td class="line x" title="99:164	We propose addressing the same issue using corpus data to supplement the lesk overlap measure." ></td>
	<td class="line oc" title="100:164	We propose using distributional similarity (using (Lin, 1998)) as an approximation of semantic distancebetweenthewordsinthetwoglosses,rather than requiring an exact match." ></td>
	<td class="line x" title="101:164	We refer to this measure as DSlesk as dened: DSlesk(s1,s2)= 1ja 2 g 1j  a2g1 max b2g2 dss(a,b) (2) where g1 istheglossofwordsense s1, g2 isthegloss of s2, again s1 is the target word sense wsi in equation 1 for which we are obtaining the predominance rankingscoreands2iswhicheversenseoftheneighbour(nj)inequation1whichmaximisesthissemantic similarity score, as McCarthy et al. did with the wnss in equation 1." ></td>
	<td class="line x" title="102:164	a (b) is a word appearing in g1 (g2)." ></td>
	<td class="line x" title="103:164	In the calculation of equation (2), we rst extract the most similar word b from g2 to each word (a) in 2These two glosses are dened in OXFORD Advanced Learners Dictionary." ></td>
	<td class="line x" title="104:164	564 dss(bird,creature)= 0.84, dss(bird, feather)= 0.77, dss(bird,wing)= 0.55, dss(bird,leg)= 0.43, dss(leg,creature)= 0.56, dss(leg, feather)= 0.66, dss(leg,wing)= 0.74, dss(leg,leg)= 1.00 Figure 1: Examples of distributional similarity the gloss of s1." ></td>
	<td class="line x" title="105:164	We then output the average of the maximum distributional similarity of all the words in g1 to any of the words in g2 as the similarity score between s1 and s2." ></td>
	<td class="line x" title="106:164	We acknowledge that DSlesk is not symmetrical since it depends on the number of words in the gloss of s1, but not s2." ></td>
	<td class="line x" title="107:164	Also our summationisoverthesewordsins1andwearenotlooking for identity but maximum distributional similarity with any of the words in g2 so the summation will not give the same result as if we did the summation over the words in g2." ></td>
	<td class="line x" title="108:164	It is perfectly reasonable to have a semantic similarity measure which is not symmetrical." ></td>
	<td class="line x" title="109:164	One may want a measure where a more specic sense, such as the meat sense of chicken is closer to the  animal esh used as food sense of meat than vice versa." ></td>
	<td class="line x" title="110:164	We do not believe that this asymmetry is problematic for our application as all the senses of w which we are ranking are all treated equally with respect to the neighbour n, and the ranking measure is concerned with nding evidence for the meaning of w, which we do by focusing on its denitions, and not the meaning of n. It would however be worthwhile investigating symmetrical versions of the score in the future." ></td>
	<td class="line x" title="111:164	Here is an example given the denitions of bird and pigeon above and the distributional similarity scoresofallcombinationsofthetwonounsasshown in Figure 1." ></td>
	<td class="line x" title="112:164	In this case, the similarity is estimated as 1/2(0.84+1.00)= 0.92." ></td>
	<td class="line x" title="113:164	4 Experiments To investigate how well the McCarthy et al. method ports to other language, we conduct empirical evaluation of word sense disambiguation by using the two available sense-tagged datasets, EDR and the SENSEVAL-2 Japanese dictionary task." ></td>
	<td class="line x" title="114:164	In the experiments, we compare the three semantic similarities, jcn, lesk and DSlesk3, for use in the method to 3Elesk can be used when several semantic relations such as hypnoymy and meronomy are available." ></td>
	<td class="line x" title="115:164	However, we cannot directly apply Elesk as it was used in (McCarthy et al., 2004) to nd the most likely sense in the set of word senses dened in each inventory following the approach of McCarthy et al.(2004)." ></td>
	<td class="line x" title="117:164	For the thesaurus construction we used <verb, case, noun> triplets extracted from Japanese newspaper articles (9 years of the Mainichi Shinbun (1991-1999) and 10 years of the Nihon Keizai Shinbun (1991-2000)) and parsed by CaboCha (Kudo and Matsumoto, 2002)." ></td>
	<td class="line x" title="118:164	This resulted in 53 million triplet instances for acquiring the distributional thesaurus." ></td>
	<td class="line oc" title="119:164	We adopt the similarity score proposed by Lin (1998) as the distributional similarity score and use 50 nearest neighbours in line with McCarthy et al. For the random baseline we select one word sense at random for each word token and average the precision over 100 trials." ></td>
	<td class="line x" title="120:164	For contrast with a supervised approach we show the performance if we use handlabelled training data for obtaining the predominant sense of the test words." ></td>
	<td class="line x" title="121:164	This method usually outperforms an automatic approach, but crucially relies on there being hand-labelled data which is expensive to produce." ></td>
	<td class="line x" title="122:164	The method cannot be applied where there is no hand-labelled training data, it will be unreliable for low frequency data and a general dataset may not be applicable when one moves to domain specic text (Koeling et al., 2005)." ></td>
	<td class="line x" title="123:164	Since we are not using context for disambiguation, but just a rst sense heuristic, we also give the upper-bound which is the rst sense heuristic calculated from the test data itself." ></td>
	<td class="line x" title="124:164	4.1 EDR We conduct empirical evaluation using 3,836 polysemous nouns in the sense-tagged corpus provided with EDR (183,502 instances) where the glosses are dened in the EDR dictionary." ></td>
	<td class="line x" title="125:164	We evaluated on this datasetusing WSD precisionandrecallofthiscorpus using only our rst-sense heuristic (no context)." ></td>
	<td class="line x" title="126:164	The results are shown in Table 1." ></td>
	<td class="line x" title="127:164	The WSD performance of all the automatic methods is much lower than the supervised method, however, the main point of this paper is to compare the McCarthy et al. method for nding a rst sense in Japanese using jcn, lesk and our experiments because the meronomy relation is not dened in the EDR dictionary." ></td>
	<td class="line x" title="128:164	In the experiments reported here we focus on the comparison of the three similarity measures jcn, lesk and DSlesk for use in the method to determine the predominant sense of each word." ></td>
	<td class="line x" title="129:164	We leave further exploration of other adaptations of semantic similarity scores for future work." ></td>
	<td class="line x" title="130:164	565 Table 1: Results of EDR recall precision baseline 0.402 0.402 jcn 0.495 0.495 lesk 0.474 0.488 DSlesk 0.495 0.495 upper-bound 0.745 0.745 supervised 0.731 0.731 Table 2: Precision on EDR at low frequencies all freq  10 freq  5 baseline 0.402 0.405 0.402 jcn 0.495 0.445 0.431 lesk 0.474 0.448 0.426 DSlesk 0.495 0.453 0.433 upper-bound 0.745 0.674 0.639 supervised 0.731 0.519 0.367 DSlesk." ></td>
	<td class="line x" title="131:164	Table 1 shows that DSlesk is comparable to jcn without the requirement for semantic relations such as hyponymy." ></td>
	<td class="line x" title="132:164	Furthermore, we evaluate precision of each method at low frequencies of words ( 10,  5), shown in Table 2." ></td>
	<td class="line x" title="133:164	Table 2 shows that all methods for nding a predominant sense outperform the supervised one for items with little data ( 5), indicating that these methods robustly work even for low frequency data where hand-tagged data is unreliable." ></td>
	<td class="line x" title="134:164	Whilst the results are signicantly different to the baseline 4 we note that the difference to the random baseline is less than for McCarthy et al. who obtained 48% for Elesk on polysemous nouns in SemCor and 46% for jcn against a random baseline of 24%." ></td>
	<td class="line x" title="135:164	These differences are probably explained by differences in the lexical resources." ></td>
	<td class="line x" title="136:164	Both Elesk and jcn rely on semantic relations including hyponymy with Elesk also using the glosses." ></td>
	<td class="line x" title="137:164	jcn in both approaches use the hyponym links." ></td>
	<td class="line x" title="138:164	WordNet 1.6 (used by McCarthy et al.) has 66025 synsets with 66910 hyponym links between these 5." ></td>
	<td class="line x" title="139:164	For EDR there are 166868 nodes (word sense groupings) and 53747 4For signicance testing we used McNemars test =0.05." ></td>
	<td class="line x" title="140:164	5These gures are taken from http://www.lsi.upc.es/ batalla/wnstats.html#wn16 Table 3: Results of SENSEVAL-2 precision = recall ne coarse baseline 0.282 0.399 lesk 0.344 0.501 DSlesk 0.386 0.593 upper-bound 0.747 0.834 supervised 0.742 0.842 hyponym links." ></td>
	<td class="line x" title="141:164	So in EDR the ratio of these links to the nodes is much lower." ></td>
	<td class="line x" title="142:164	This and other differences between EDR and WordNet are likely to be the reason for the difference in results." ></td>
	<td class="line x" title="143:164	4.2 SENSEVAL-2 WealsoevaluatetheperformanceusingtheJapanese dictionary task in SENSEVAL-2 (Shirai, 2001)." ></td>
	<td class="line x" title="144:164	In this experiment, we use 50 nouns (5,000 instances)." ></td>
	<td class="line x" title="145:164	For this task, since semantic relations such as hyponym links are not dened, use of jcn is not possible." ></td>
	<td class="line x" title="146:164	Therefore, we just compare lesk and DSlesk along with our random baseline, the supervised approach and the upper-bound as before." ></td>
	<td class="line x" title="147:164	The results are evaluated in two ways; one is for ne-grainedsensesintheoriginaltaskdenitionand the other is coarse-grained version which is evaluated discarding the ner categorical information of eachdenition." ></td>
	<td class="line x" title="148:164	TheresultsareshowninTable 3." ></td>
	<td class="line x" title="149:164	As with the EDR results, all unsupervised methods signicantly outperform the baseline method, though the supervised methods still outperform the unsupervised ones." ></td>
	<td class="line x" title="150:164	In this experiment, DSlesk is also signicantly better than lesk in both ne and coarsegrained evaluations." ></td>
	<td class="line x" title="151:164	It indicates that applying distributional similarity score to calculating inter-gloss similarities improves performance." ></td>
	<td class="line x" title="152:164	5 Conclusion In this paper, we examined different measures of semantic similarity for nding a rst sense heuristic for WSD automatically in Japanese." ></td>
	<td class="line x" title="153:164	We dened a new gloss-based similarity (DSlesk) and evaluated the performance on two Japanese WSD datasets, outperforming lesk and achieving a performance comparable to the jcn method which relies on hyponym links which are not always available." ></td>
	<td class="line x" title="154:164	566 There are several issues for future directions of automatic detection of a rst sense heuristic." ></td>
	<td class="line x" title="155:164	In this paper, we proposed an adaptation of the lesk measure of gloss-based similarity, by using the average similarity between nouns in the two glosses under comparison in a bag-of-words approach without recourse to other information." ></td>
	<td class="line x" title="156:164	However, it would be worthwhile exploring other information in the glosses, such as words of other PoS and predicate argument relations." ></td>
	<td class="line x" title="157:164	We also hope to investigate applying alignment techniques introduced for entailment recognition (Hickl and Bensley, 2007)." ></td>
	<td class="line x" title="158:164	Another important issue in WSD is to group negrained word senses into clusters, making the task suitable for NLP applications (Ide and Wilks, 2006)." ></td>
	<td class="line x" title="159:164	We believe that our gloss-based similarity DSlesk might be very suitable for this task and we plan to investigate the possibility." ></td>
	<td class="line x" title="160:164	There are other approaches we would like to explore in future." ></td>
	<td class="line x" title="161:164	Mihalcea (2005) uses dictionary definitions alongside graphical algorithms for unsupervised WSD." ></td>
	<td class="line x" title="162:164	Whilst the results are not directly comparable to ours because we have not included contextual evidence in our models, it would be worthwhile exploring if unsupervised graphical models using only the denitions we have in our lexical resources can perform WSD on a document and give more reliable rst sense heuristics." ></td>
	<td class="line x" title="163:164	Acknowledgements This work was supported by the UK EPSRC project EP/C537262 Ranking Word Senses for Disambiguation: Models and Applications, and a UK Royal Society Dorothy Hodgkin Fellowship to the second author." ></td>
	<td class="line x" title="164:164	We would like to thank John Carroll for several useful discussions on this work." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I08-2102
Summarization by Analogy: An Example-based Approach for News Articles
Makino, Megumi;Yamamoto, Kazuhide;"></td>
	<td class="line x" title="1:159	Summarization by Analogy: An Example-based Approach for News Articles Megumi Makino and Kazuhide Yamamoto Dept. of Electrical Engineering, Nagaoka University of Technology 1603-1 Kamitomioka, Nagaoka, Niigata 940-2188 Japan {makino,ykaz}@nlp.nagaokaut.ac.jp Abstract Automatic summarization is an important task as a form of human support technology." ></td>
	<td class="line x" title="2:159	We propose in this paper a new summarization method that is based on example-based approach." ></td>
	<td class="line x" title="3:159	Using example-based approach for the summarization task has the following three advantages: high modularity, absence of the necessity to score importance for each word, and high applicability to local context." ></td>
	<td class="line x" title="4:159	Experimental results have proven that the summarization system attains approximately 60% accuracy by human judgment." ></td>
	<td class="line x" title="5:159	1 Introduction The example-based approach generates language by imitating instances, which originated in the machine translation method based on the analogy (Nagao, 1984)." ></td>
	<td class="line x" title="6:159	The idea is derived from the observation that a human being translates according to past translation experiences." ></td>
	<td class="line x" title="7:159	In the machine translation task, this approach has been implemented, and has so far achieved efficient results (Sumita, 1998; Imamura, 2004)." ></td>
	<td class="line x" title="8:159	In summarization, a human being also summarizes with his own knowledge and experiences." ></td>
	<td class="line x" title="9:159	For this reason, we focus on a summarization method which is based on analogy, example-based summarization." ></td>
	<td class="line x" title="10:159	The example-based method summarizes the input text in three steps." ></td>
	<td class="line x" title="11:159	First, it retrieves a similar instance to the input text." ></td>
	<td class="line x" title="12:159	Second, it links equivalent phrases between the input text and the similar instance." ></td>
	<td class="line x" title="13:159	Finally, a summary is acquired with combination of some corresponding phrases." ></td>
	<td class="line x" title="14:159	Here, we employed a Japanese news article as the input text and utilized news headlines as the instances." ></td>
	<td class="line x" title="15:159	The news headline consists of one brief sentence which describes the main point." ></td>
	<td class="line x" title="16:159	We assert that the example-based summarization has the following advantages: (1)High modularity Easy improvement and maintenance are required to formulate a useful system in general." ></td>
	<td class="line x" title="17:159	An example-based framework makes it easy for us to improve a system by only adding instances." ></td>
	<td class="line x" title="18:159	Besides, the addition of instances causes few side-effects." ></td>
	<td class="line x" title="19:159	(2)Use of similarity rather than importance Almost all previous work on summarization has focused on a sentence extraction." ></td>
	<td class="line x" title="20:159	These works compute importance for each word to extract a sentence." ></td>
	<td class="line x" title="21:159	However, it is difficult to compute the importance which correlates with human sense." ></td>
	<td class="line x" title="22:159	Example-based summarization means there is no need to measure the importance, and it computes the similarity instead." ></td>
	<td class="line x" title="23:159	We think it is easier to assess the similarity between two expressions rather than the importance of one expression." ></td>
	<td class="line x" title="24:159	(3)High applicability to local context The statistical method, in general, attempts to compute the probability of each word appearing in the summary corpus (Knight and Marcu, 2002; Witbrock and Mittal, 1999)." ></td>
	<td class="line x" title="25:159	This may increase difficulties in maintaining local context, since the statistical approach focuses on the global probability." ></td>
	<td class="line x" title="26:159	However, the example-based approach attempts to find most locally similar instance out of the instance collection, which may increase the fitness of input contexts." ></td>
	<td class="line x" title="27:159	For the three reasons given above, this paper explains the system which summarizes a Japanese news article to a one-sentence summary by imitating the similar instance." ></td>
	<td class="line x" title="28:159	739 As related work, Nguyen et al.(2004) have proposed an example-based sentence reduction model." ></td>
	<td class="line x" title="30:159	They deal with the compression of one sentence, while we summarize some sentences into a onesentence summary." ></td>
	<td class="line x" title="31:159	Thus, our summarization ratio is inevitably lower than theirs, as it is considered to be more difficult as a summarization task." ></td>
	<td class="line x" title="32:159	Many studies have summarized some sentences, such as a news article, into a one-sentence summary." ></td>
	<td class="line x" title="33:159	Most of them extract the important sentence and contract it." ></td>
	<td class="line x" title="34:159	In contrast, our method generates a onesentence summary by combining phrases in some sentences." ></td>
	<td class="line x" title="35:159	Consequently, we can obtain high compression summaries that include information from many positions of the source." ></td>
	<td class="line x" title="36:159	2 Instance Collection Our example-based summarization regards news headlines as the instance collection." ></td>
	<td class="line x" title="37:159	A news headline is a short sentence in which the primary point is written." ></td>
	<td class="line x" title="38:159	The following example is Japanese news headlines: Example (1) : ~	xzp	;	 \{ (Mitsubishi Motors Corp. produces passenger cars in China.)" ></td>
	<td class="line x" title="39:159	We use Japanese news headlines, like the above examples, as instances." ></td>
	<td class="line x" title="40:159	Besides, as we have noted, only news headlines are used as instances; that is, the pairs formed by an original sentence and its summarized sentence are not used." ></td>
	<td class="line x" title="41:159	3 Example-based Summarization 3.1 Overview Our example-based summarization system summarizes a lengthy news article into a one-sentence summary by using instances." ></td>
	<td class="line x" title="42:159	The overall process is illustrated in figure 1." ></td>
	<td class="line x" title="43:159	The system is composed of the following three processes in this order: 1." ></td>
	<td class="line x" title="44:159	Retrieve a similar instance to an input news article from the instance collection." ></td>
	<td class="line x" title="45:159	2." ></td>
	<td class="line x" title="46:159	Align corresponding phrases between the input news article and the similar instance." ></td>
	<td class="line x" title="47:159	3." ></td>
	<td class="line x" title="48:159	Combine the corresponding phrases to form a summary." ></td>
	<td class="line x" title="49:159	Detail of each process is described hereafter." ></td>
	<td class="line x" title="50:159	3.2 Retrieval of Similar Instance The system measures a similarity between the input and each instance in the instance collection when it retrieves a similar instance." ></td>
	<td class="line x" title="51:159	If many words are shared between two expressions, we regard two expressions as similar." ></td>
	<td class="line x" title="52:159	Hence, the similarity is calculated on basis of the overlaps of content words between the input news article I and the instance E, defined as follows: Sim(E,I)= n  i=1 Score(i){w||Tv 1 (E)Tv i (I)|| +||To 1 (E)To i (I)||} (1) where, n : the number of sentences in input, Tv i () : the verbs set in the last phrase of the i-th sentence, To i () : the set of content words in the i-th sentence, ||Tv 1 (E) Tv i (I)|| : the number of overlaps between Tv 1 (E) and Tv i (I)." ></td>
	<td class="line x" title="53:159	In the equation, Score(i) and w are designed to give a higher score if words indicating the main topic of the input article are matched with words in the instance." ></td>
	<td class="line x" title="54:159	We have found that words have different contributions, depending on the sentence position, to the main topic." ></td>
	<td class="line x" title="55:159	Therefore, we apply Score(i) which depends on the sentence position i, and we use the following experimentally-determined score as Score(i)." ></td>
	<td class="line x" title="56:159	Score(i)= braceleftbigg 5.15 if i = 1 2.78/i 0.28 otherwise (2) The score indicates an agreement rate of content words depending on the sentence position, which is calculated by using 5000 pairs of newspapers body and its title 1 We have also found that the verbs in the last phrase are appropriate for the main topic of the input article." ></td>
	<td class="line x" title="57:159	For that reason, we determine the weight w=3 by our experiment." ></td>
	<td class="line x" title="58:159	Example 2 shows the similar instance obtained by measuring the similarity." ></td>
	<td class="line x" title="59:159	Example (2) : Input news article gsrw6=f`Own XqU 24 zq5`h{ (skip the 1 We used the same kind of newspaper as data set in section 4.1 for calculating Score(i)." ></td>
	<td class="line x" title="60:159	740 Figure 1: Overview of example-based summarization rest.)" ></td>
	<td class="line x" title="61:159	(The Manufacturing Council held a meeting on the 24th, which discusses the hard-hitting strategy for quality management." ></td>
	<td class="line x" title="62:159	) Obtained similar instance =U 18 z	 p	sq Mh{ (The committee for the privatization of the Public Roads Administration held the first meeting on the 18th at the prime ministers office.)" ></td>
	<td class="line x" title="63:159	3.3 Phrase Alignment We compare the phrases in the input with those in the similar instance, and the system aligns the corresponding phrases." ></td>
	<td class="line x" title="64:159	Here, the correspondence refers to the link of the equivalent phrases between the input and its similar instance." ></td>
	<td class="line x" title="65:159	The detail of phrase alignment procedures are shown in the following." ></td>
	<td class="line x" title="66:159	To begin with, sentences both in the input and in the similar instance are analyzed using a Japanese syntactic parser CaboCha 1) . The sentences are split into phrases and named entities (NEs), such as PERSON, LOCATION, DATE, are recognized by the tool." ></td>
	<td class="line x" title="67:159	Then the adnominal phrases in the similar instance are deleted." ></td>
	<td class="line x" title="68:159	This is because the adnominal phrases are of many types, depending on the modified noun; accordingly, the adnominal phrase should be used only if the modified nouns are exactly matched between the input and the similar instance." ></td>
	<td class="line x" title="69:159	Finally, the system links the corresponding phrases." ></td>
	<td class="line x" title="70:159	Here, phrase correspondence is one-tomany, not one-to-one, and therefore a phrase in a similar instance has some corresponding phrases in the input." ></td>
	<td class="line x" title="71:159	In order to compare phrases, the following four measures are employed: (i) agreement of grammatical case, (ii) agreement of NE, (iii) similarity with enhanced edit distance, and (iv) similarity by means of mutual information." ></td>
	<td class="line x" title="72:159	The measure of (i) focuses on functional words, whereas the measures of (ii)-(iv) note content words." ></td>
	<td class="line x" title="73:159	Let us explain the measures using example 2." ></td>
	<td class="line x" title="74:159	(i) Agreement of Grammatical Case If there is a phrase which has the same grammatical case 2 in the input and in the similar instance, we regard the phrase as the corresponding phrase." ></td>
	<td class="line x" title="75:159	In example 2, for example, the phrases 6=f  (the hard-hitting strategy obj 3 ), q  (the meeting obj) in the input corresponds the phrase 	sq  (the first meeting obj) in the similar instance." ></td>
	<td class="line x" title="76:159	(ii) Agreement of Named Entity Provided the input has the same NE tag as the similar instance, the phrase involving its tag links the corresponding phrase." ></td>
	<td class="line x" title="77:159	For example, in example 2, the phrase 24  [DATE] (on the 24th.) in the input corresponds the phrase 18  [DATE] (on the 18th.) in the similar instance." ></td>
	<td class="line x" title="78:159	(iii) Similarity with Enhanced Edit Distance We adopt the enhanced edit distance to link phrases including the same characters, because Japanese abbreviation tends to include the same characters as the original." ></td>
	<td class="line x" title="79:159	For example, the abbreviation of  2 Comma is also regarded as grammatical case (i.e., null case) here." ></td>
	<td class="line x" title="80:159	3 obj is an object case marker." ></td>
	<td class="line x" title="81:159	741  (Bank of Japan) is  ." ></td>
	<td class="line x" title="82:159	The enhanced edit distance is proposed by Yamamoto et al.(2003)." ></td>
	<td class="line x" title="84:159	The distance is a measure of similarity by counting matching characters between two phrases." ></td>
	<td class="line x" title="85:159	Moreover, the distance is assigned a different similarity weight according to the type of matched characters." ></td>
	<td class="line x" title="86:159	We apply 1.0 to the weight only if Chinese-derived characters (Kanji) are matched." ></td>
	<td class="line x" title="87:159	We link phrases as corresponding phrases, where the phrases are the top three similar to a phrase in the similar instance." ></td>
	<td class="line x" title="88:159	(iv) Similarity with Mutual Information We finally compute the similarity with mutual information to link syntactically similar phrases." ></td>
	<td class="line x" title="89:159	For example, given the following two expressions: q ^X (to hold a meeting) and GqX (to hold a convention), we regardq^ (a meeting) and Gq (a convention) as similar." ></td>
	<td class="line oc" title="90:159	We use the similarity proposed by Lin (1998)." ></td>
	<td class="line o" title="91:159	The method uses mutual information and dependency relationships as the phrase features." ></td>
	<td class="line o" title="92:159	We extend the method to Japanese by using a particle as the dependency relationships." ></td>
	<td class="line x" title="93:159	We link phrases as corresponding phrases, where the phrases are the top three similar to a phrase in the similar instance." ></td>
	<td class="line x" title="94:159	3.4 Combination of the Corresponding Phrases Our system forms the one-sentence summary by combining the corresponding phrases." ></td>
	<td class="line x" title="95:159	Let us explain this process by using figure 2." ></td>
	<td class="line x" title="96:159	We arrange the phrase of the input on the node, where the phrases is judged as the correspondence to the phrase in the similar instance." ></td>
	<td class="line x" title="97:159	For example, in figure 2, the second nodes e and d denote the corresponding phrases in the input, which correspond to the second phrase had in the similar instance." ></td>
	<td class="line x" title="98:159	We assign the similarity between corresponding phrases as the weight of node." ></td>
	<td class="line x" title="99:159	In addition to this, we employ phrase connection score to the weight of edge." ></td>
	<td class="line x" title="100:159	The score indicates the connectivity of consecutive two phrases, e.g. two nodes such as node d and node e in figure 2." ></td>
	<td class="line x" title="101:159	If you want to obtain a fine summary, i.e., a summary that contains similar phrases to the similar instance, and that is correct grammatically, you have to search the best path  W p for path sequence W p ={w 0 ,w 1 ,w 2 ,,w m }, where the best path maximizes the score." ></td>
	<td class="line x" title="102:159	 W p =W p s.t. argmax p Score p (W p ) (3) Figure 2: Optimal path problem that depends on combination of the corresponding phrases 4 . The best path  W p is a one-sentence summary which is generated by our system." ></td>
	<td class="line x" title="103:159	Take the case of the thick line in figure 2,  W p is indicated as  W p = {a,d,e,g,k,m,n}, namely, generated summary is formed the phrases {a,d,e,g,k,m,n}." ></td>
	<td class="line x" title="104:159	In eq.3, Score p (W p ) is given by Score p (W p )= m  i=0 N(w i )+(1) m  i=1 E(w i1 ,w i ) (4) where  is the balancing factor among the weights of node and edge." ></td>
	<td class="line x" title="105:159	We score  = 0.6by our experiment." ></td>
	<td class="line x" title="106:159	m indicates the last number of the phrase in the similar instance, N(w i ) is given as follows: N(w i )=max braceleftbigg 0.5if(grammatical case or NE tag is matched) 1/rank otherwise (5) where, rank indicates the rank order of the similarity with the enhanced edit distance or mutual information to the phrase w i . N(w i ) illustrates the similarity between corresponding two phrases." ></td>
	<td class="line x" title="107:159	The node score, shown above, is determined by the preliminary experiment." ></td>
	<td class="line x" title="108:159	The edge score E(w i1 ,w i ) is given by E(w i1 ,w i )= 1 |loc(w i1 )loc(w i )|+1 (6) where, loc(w i ) denotes where the location of the sentence contains the phrase w i in the input." ></td>
	<td class="line x" title="109:159	The edge score means that if w i1 and w i are located closely to each other, a higher score is given, since a good connection is expected in this case." ></td>
	<td class="line x" title="110:159	4 The nodes, a, b, c,, n, indicate the corresponding phrases to the phrase in the similar sentence." ></td>
	<td class="line x" title="111:159	For example, the nodes, b, c, d correspond to The PRA Committee. i is a phrase number in the similar sentence." ></td>
	<td class="line x" title="112:159	742 4 Evaluation and Discussion 4.1 The Corpus We used 26,784 news headlines as instances, which were collected from the Nikkei-goo mail service 2) for 2001-2006." ></td>
	<td class="line x" title="113:159	In order to adjust the weight w in the eq.1 and the balancing parameter  in eq.4, 150 input news articles were used as the tuning set." ></td>
	<td class="line x" title="114:159	A different group of 134 news articles were used for evaluation." ></td>
	<td class="line x" title="115:159	We used Nihon Keizai Shimbun, a Japanese newspaper 3) , from 1999 through 2000 as tuning and test data." ></td>
	<td class="line x" title="116:159	4.2 Summarization Ratio To calculate summarization ratio, we have compared the number of characters in the input news articles with that in the output summary." ></td>
	<td class="line x" title="117:159	As the result, we obtained a summarization ratio of 5%; namely, 95% characters in the input were reduced." ></td>
	<td class="line x" title="118:159	From the summarization ratio, our approach made it possible to summarize sentences into one-sentence summary with high compression." ></td>
	<td class="line x" title="119:159	4.3 Sectional Evaluation We evaluated each part of our system by human judgment 5 . We first evaluated the process by retrieving similar instance." ></td>
	<td class="line x" title="120:159	Next, we evaluated the processes of phrase alignment and the combination by assessing whether the output summaries were appropriate." ></td>
	<td class="line x" title="121:159	 Retrieving Process An examinee evaluated the similar instances obtained." ></td>
	<td class="line x" title="122:159	Given an input news article and the similar instance to the input, the examinee rates the following scale from one to four, based on how similar the similar instance obtained is to the summary which the examinee generated from the input news article: 1) quite similar 2) slightly similar 3) not very similar 4) not similar Out of 134 input articles, 77 inputs were ranked either 1) quite similar or 2) slightly similar." ></td>
	<td class="line x" title="123:159	As a consequence, the accuracy of similar instance obtained is approximately 57%, which indicates that the similarity calculation for obtaining similar instance is feasible." ></td>
	<td class="line x" title="124:159	5 One examinee judged the parts of our system." ></td>
	<td class="line x" title="125:159	 Phrase Alignment and Combination We also evaluated parts of phrase alignment and the combination by human judgment." ></td>
	<td class="line x" title="126:159	The examinee compared 77 output summaries with their input." ></td>
	<td class="line x" title="127:159	Here, we limited 77 outputs judged as good similar instances in evaluation of the process of retrieving similar instance, because we evaluate specifically the parts of phrase alignment and combination." ></td>
	<td class="line x" title="128:159	The examinee categorized them based on how proper the output summary is to the input news article: 1) quite proper 2) slightly proper 3) not very proper 4) not proper As a result of judgment, 48 outputs out of 77 are evaluated either 1) quite proper or 2) slightly proper." ></td>
	<td class="line x" title="129:159	Both a statistical method by Knight and Marcu (2002) and an example-based method by Nguyen et al.(2004) contracted one-sentence with a summarization ratio of approximately 60-70%." ></td>
	<td class="line x" title="131:159	Both papers indicated that a score of 7-8 on a scale from one to ten was obtained." ></td>
	<td class="line x" title="132:159	They deal with the compression of one sentence, while we summarize some sentences into a one-sentence summary." ></td>
	<td class="line x" title="133:159	Thus, our summarization ratio is lower than theirs, as it is considered to be more difficult as a summarization task." ></td>
	<td class="line x" title="134:159	Despite this, we obtained the ratio that 62% (48 out of 77 results) were judged proper." ></td>
	<td class="line x" title="135:159	Although direct comparison of the performance is impossible, it is considered that our proposed method obtains a competitive accuracy." ></td>
	<td class="line x" title="136:159	4.4 Discussions  Examples of Output Summary Figure 3 shows some examples of the output summary." ></td>
	<td class="line x" title="137:159	From figure 3, we can see that the similar instances were effectively used, and the appropriate summaries to the input are generated." ></td>
	<td class="line x" title="138:159	For example, the second summary in the figure is judged as a fine summary contracting information of two sentences according to the similar instance." ></td>
	<td class="line x" title="139:159	 Analysis of Summarization Errors In the course of our summarization, we have observed errors due to erroneous correspondences." ></td>
	<td class="line x" title="140:159	In Japanese, sometimes two or more phrases are contracted into one phrase, as in the example below." ></td>
	<td class="line x" title="141:159	We now only attempt to correspond two phrases one by 743 Input news article   ]/ww	wOjz	z	B/Bw	B kEpI ^hi	n*z w{ QU	Gz#KpTh{Uox{ o(`o<ty	PVZsrz 	tSZ w^t	ahqssrqg sk`z  tD{`h{ (skip the rest.)" ></td>
	<td class="line x" title="142:159	(The prosecution made Kawanos closing arguments on the 21st in the trial at the Yokohama District Court." ></td>
	<td class="line x" title="143:159	The ex-sergeant Suguru Kawano is accused of gang-bashing by Atsugi Police Stations patrol group in a string of scandals of Kanagawa Prefectural Police." ></td>
	<td class="line x" title="144:159	The prosecutors demanded one and half year in a prison." ></td>
	<td class="line x" title="145:159	) Obtained similar instance GUKp 22 z 8 UX [qslh>	t	E w{QUTzUoxPt{ `h{ (The prosecution made Takumas closing arguments on the 22nd in the trial at the Osaka District Court, and asked for the death penalty.) " ></td>
	<td class="line x" title="146:159	Output summary # Kp	Gz{ QUTzUox   tD{`h{ (The prosecution made Kawanos closing arguments on the 21st in the trial and demanded one and half years in prison.)" ></td>
	<td class="line x" title="147:159	Figure 3: The examples of generated summary one, and we thus can not deal with many-to-one correspondences." ></td>
	<td class="line x" title="148:159	Example (3) :  Dt / 6  z  D z / (compare with the same month last year) 5 D /t  5 D / (in May) We expect that this kind of phenomenon can be solved by paraphrasing an input summary as well as summary instance." ></td>
	<td class="line x" title="149:159	Recently, several works on paraphrasing techniques have been proposed in Japanese, hence such pre-processing before alignment would be feasible." ></td>
	<td class="line x" title="150:159	5 Conclusion and Future Work We have presented an example-based technique that has been applied to the summarization task." ></td>
	<td class="line x" title="151:159	The essence of the proposed method is to generate a onesentence summary by combining instances each of which imitates the given input." ></td>
	<td class="line x" title="152:159	As the result of human judgment, the retrieval process of a similarity sentence attained 57% accuracy." ></td>
	<td class="line x" title="153:159	And our method generated summary in which 62% were judged proper." ></td>
	<td class="line x" title="154:159	We have confirmed by our observation that the summaries were generated by combining the phrases in many positions of the input, while those summaries are not given just by 6 / indicates a phrase boundary." ></td>
	<td class="line x" title="155:159	common methods such as sentence extraction methods and sentence compression methods." ></td>
	<td class="line x" title="156:159	The sectional evaluation and the inspection of example output show that this system works well." ></td>
	<td class="line x" title="157:159	However, larger scale evaluation and comparison of its accuracy remain to be future work." ></td>
	<td class="line x" title="158:159	Tools and language resources 1) CaboCha, Ver.0.53, Matsumoto Lab., Nara Institute of Science and Technology." ></td>
	<td class="line x" title="159:159	http://chasen.org/taku/software/cabocha/ 2) Nikkei News Mail, NIKKEI-goo, http://nikkeimail.goo.ne.jp/ 3) Nihon Keizai Shimbun Newspaper Corpus, years 1999 2000, Nihon Keizai Shimbun, Inc." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="Data not found"></td>
	<td class="line x" title="1:134	Coling 2008: Proceedings of the workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), pages 18 Manchester, August 2008 Comparing Lexical Relationships Observed within Japanese Collocation Data and Japanese Word Association Norms Terry Joyce School of Global Studies, Tama University, 802 Engyo, Fujisawa, Kanagawa, 252-0805, JAPAN terry@tama.ac.jp Irena Srdanovi Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo 152-8552, JAPAN srdanovic.i.ab@m.titech.ac.jp  Abstract 1  While large-scale corpora and various corpus query tools have long been recognized as essential language resources, the value of word association norms as language resources has been largely overlooked." ></td>
	<td class="line x" title="2:134	This paper conducts some initial comparisons of the lexical relationships observed within Japanese collocation data extracted from a large corpus using the Japanese language version of the Sketch Engine (SkE) tool (Srdanovi et al., 2008) and the relationships found within Japanese word association sets taken from the large-scale Japanese Word Association Database (JWAD) under ongoing construction by Joyce (2005, 2007)." ></td>
	<td class="line x" title="3:134	The comparison results indicate that while some relationships are common to both linguistic resources, many lexical relationships are only observed in one resource." ></td>
	<td class="line x" title="4:134	These findings suggest that both resources are necessary in order to more adequately cover the diverse range of lexical relationships." ></td>
	<td class="line x" title="5:134	Finally, the paper reflects briefly on the implementation of association-based word-search strategies into electronic dictionaries proposed by Zock and Bilac (2004) and Zock (2006)." ></td>
	<td class="line x" title="6:134	1 Introduction Large-scale corpora and various corpus query tools have long been recognized as extremely important language resources." ></td>
	<td class="line x" title="7:134	The impact of   2008." ></td>
	<td class="line x" title="8:134	Licensed under the Creative Commons AttributionNoncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="9:134	Some rights reserved." ></td>
	<td class="line x" title="10:134	corpora and corpus query tools has been particularly significant in the area of compiling and developing lexicographic materials (Kilgarriff and Rundell, 2002) and in the area of creating various kinds of lexical resources, such as WordNet (Fellbaum, 1998) and FrameNet (Atkins et al., 2003; Fillmore et al., 2003)." ></td>
	<td class="line x" title="11:134	In contrast, although the significance of databases of free word association norms have long been recognized within psychology in providing insights into higher cognitive processes (Cramer, 1968; Deese, 1965; Nelson et al., 1998; Steyvers and Tenenbaum, 2005), their value as a language resource has been largely overlooked." ></td>
	<td class="line x" title="12:134	However, as Sinopalnikova and Pavel (2004) point out, databases of word association norms represent an extremely useful supplement to the range of traditional language resources, such as large-scale corpora, thesauri, and dictionaries, and can potentially contribute greatly to the development of more sophisticated linguistic resources." ></td>
	<td class="line x" title="13:134	This paper seeks to demonstrate the potential value of word association databases as language resources." ></td>
	<td class="line x" title="14:134	Specifically, we conduct some initial comparisons of the lexical relationships observed within Japanese collocation data, as extracted from a large corpus with the Japanese language version of the Sketch Engine (SkE) tool (Srdanovi et al., 2008), with those found within Japanese word association sets, which were created through the ongoing construction of the large-scale Japanese Word Association Database (JWAD) (Joyce, 2005, 2007)." ></td>
	<td class="line x" title="15:134	Interesting similarities and differences between the two language resources in terms of captured lexical relationships affirm the value of word association databases as rich linguistic resources." ></td>
	<td class="line x" title="16:134	In concluding, we speculate briefly on how the wider range of lexical relationships identifiable through the combination of collocation data and word associ1 ation databases could be utilized in organizing lexical entries within electronic dictionaries in ways that are cognitively salient." ></td>
	<td class="line x" title="17:134	While we fully acknowledge that the challenges involved are formidable ones (Zock, 2006), the principled incorporation of word association knowledge within electronic dictionaries could greatly facilitate the development of more flexible and userfriendly navigation and search strategies (Zock and Bilac, 2004)." ></td>
	<td class="line x" title="18:134	2 Basic Concepts: Word Sketches and Word Association Norms This section briefly provides some background information about SkE, which is the corpus query tool used in this study to extract and display word collocation data, and about word association norms as gathered through psychological experimentation." ></td>
	<td class="line x" title="19:134	2.1 Sketch Engine (SkE): Word Sketches and Thesaurus Tools Sketch Engine (SkE) (Kilgarriff et al. 2004) is a web-based corpus query tool that supports a number of functions." ></td>
	<td class="line x" title="20:134	These include fast concordancing, grammatical processing, word sketching (one-page summaries of a words grammatical and collocation behavior), a distributional thesaurus, and robot use." ></td>
	<td class="line x" title="21:134	SkE has been applied to a number of languages." ></td>
	<td class="line x" title="22:134	In this study, we utilize the Word Sketches and Thesaurus functions for the Japanese language." ></td>
	<td class="line x" title="23:134	As both tools process raw collocation data by organizing words according to grammatical and lexical relationships, they are particularly suited to the conducted comparisons with the word association data." ></td>
	<td class="line x" title="24:134	Word Sketches (Kilgarriff and Tugwell, 2001) present the most frequent and statistically-salient collocations and grammatical relations for a given word." ></td>
	<td class="line x" title="25:134	These relations are derived as the results of grammatical analysis (a gramrel file) that employs regular expressions over PoS-tags." ></td>
	<td class="line x" title="26:134	The distributional thesaurus groups together words that occur in similar contexts and have common collocation words." ></td>
	<td class="line x" title="27:134	Estimations of semantic similarity are based on shared triples." ></td>
	<td class="line x" title="28:134	For example, <read a book> and <read a magazine> share the same triple pattern of <read a ?>, and because book and magazine exhibit high salience for the triple, they are both assumed to belong to the same thesaurus category." ></td>
	<td class="line oc" title="29:134	This approach is similar to conventional techniques for automatic thesaurus construction (Lin, 1998)." ></td>
	<td class="line x" title="30:134	2.2 Word Association Norms In contrast to the Word Sketch collocation and thesaurus tools that take the corpus as the basic input language resource, databases of word association norms are the results of psychological experiments." ></td>
	<td class="line x" title="31:134	The free word association task typically asks the respondent to respond with the first semantically-related word that comes to mind on presentation of a stimulus word." ></td>
	<td class="line x" title="32:134	The collection of word association normative data can be traced back to the seminal study by Kent and Rosanoff (1910) which gathered word association responses for a list of 100 stimulus words." ></td>
	<td class="line x" title="33:134	However, despite the insightful remarks of Deese (1965) and Cramer (1968) that word associations closely mirror the structured patterns of relations that exist among conceptsclaims that undoubtedly warrant further investigation there are, unfortunately, still relatively few largescale databases of word association norms." ></td>
	<td class="line x" title="34:134	The notable exceptions for the English language include the Edinburgh Association Thesaurus (EAT) (Kiss et al., 1973), which consists of approximately 56,000 responses to a stimulus list of 8,400 words, and the University of South Florida Word Association, Rhyme, and Word Fragment Norms compiled by Nelson et al.(1998), consisting of nearly three-quarters of a million responses to 5,019 stimulus words." ></td>
	<td class="line x" title="36:134	Another database deserving mention is the Russian Association Thesaurus compiled by Karaulov et al.(1994, 1996, 1998) which has approximately 23,000 responses for 8,000 stimulus words (cited in Sinopalnikova and Pavel, 2004)." ></td>
	<td class="line x" title="38:134	3 Japanese Language Resources This section introduces the Japanese language resources utilized in this study: namely, the Japanese Word Sketches and Thesaurus (Srdanovi et al., 2008) and the Japanese Word Association Database (Joyce, 2005, 2007)." ></td>
	<td class="line x" title="39:134	3.1 Japanese Word Sketches and Thesaurus The Japanese version of SkE is based on JpWaC (Erjavec et al., 2007; Srdanovi et al., 2008), which is a 400-million word Japanese web corpus that has been morphologically analyzed and POS-tagged with the ChaSen tool (http://chasen.naist.jp/)." ></td>
	<td class="line x" title="40:134	The Word Sketches are based on Japanese grammatical analysis results (gramrel file), where 22 grammatical relations are defined based on ChaSen PoS tags and tokens (Srdanovi et al 2008)." ></td>
	<td class="line x" title="41:134	Figure 1 presents 2 parts of word sketches for the noun fuyu ( winter), showing adjective modifications and two verb relations involving the particles of wa ( topic marker) and ni ( time marker), respectively." ></td>
	<td class="line x" title="42:134	Figure 1." ></td>
	<td class="line x" title="43:134	Parts of the Word Sketch results for the noun fuyu ( winter)." ></td>
	<td class="line x" title="44:134	3.2 Japanese Word Association Database To an even greater extent than for the English language, there has been a serious lack of word association norms for the Japanese language." ></td>
	<td class="line x" title="45:134	While Umemotos (1969) survey collected associations from 1,000 university students, the limited set of just 210 words merely underscores the deficient." ></td>
	<td class="line x" title="46:134	More recently, Okamoto and Ishizaki (2001) compiled an Associative Concept Dictionary (ACD) consisting of 33,018 word association responses provided by 10 respondents for 1,656 nouns." ></td>
	<td class="line x" title="47:134	However, it should be noted that the ACD is not strictly free association data because response category was specified as part of the task." ></td>
	<td class="line x" title="48:134	Under ongoing construction by Joyce (2005, 2007), the Japanese Word Association Database (JWAD) aims to eventually develop into a very large-scale database of free word association norms for the Japanese language in terms of both the number of stimulus items and the numbers of association responses collected." ></td>
	<td class="line x" title="49:134	The present JWAD stimulus list consists of 5,000 basic Japanese kanji and words." ></td>
	<td class="line x" title="50:134	The currently available JWAD Version 1 (JWAD-V1) consists of 104,800 free word association responses collected through a paper questionnaire survey with a sample of 2,099 items presented to up to 50 respondents." ></td>
	<td class="line x" title="51:134	The association sets compared with work sketch profiles in the subsequent sections are from JWAD-V1." ></td>
	<td class="line x" title="52:134	4 Conducted Comparisons This section presents the results of our initial comparison for the lexical relationships observed within the Japanese collocation data with those in the Japanese word association sets." ></td>
	<td class="line x" title="53:134	The comparisons focused on approximately 350 word association responses constituting the association sets for the two verbs of kizuku ( to notice) and sagasu ( to search for), the adjective of omoshiroi ( interesting), and the three nouns of jitensha ( bicycle), natsu ( summer), and yama ( mountain), as examples of basic Japanese vocabulary." ></td>
	<td class="line x" title="54:134	Taking into account the considerable degree of orthographic variation present with the Japanese writing system, all possible orthographic variations were searched for in the SkE, such as kizuku (/ ) and omoshiroi (/)." ></td>
	<td class="line x" title="55:134	4.1 Word Sketches and Thesaurus Versus Word Association Norms The Japanese SkE employs a large-scale Japanese corpus and detailed grammatical analysis based on ChaSen POS tags." ></td>
	<td class="line x" title="56:134	Accordingly, numerous lexical relationships are identified in the word sketches and thesaurus results." ></td>
	<td class="line x" title="57:134	For example, kizuku appears 12,134 times in the corpus in approximately 200 collocation examples in total, which are grouped under 12 different collocation and grammatical relations and sorted according to the statistical salience of the relations frequency within the corpus (note that searches were conducted with the default setting of only including collocations with frequencies of five or more)." ></td>
	<td class="line x" title="58:134	The thesaurus function also yields numerous results, typically displaying around 60 salient relations that are clustered into five semantic groups." ></td>
	<td class="line x" title="59:134	In contrast, while JWAD-V1 is quite large-scale for a word association databases, it is naturally far smaller than the Japanese SkE corpus." ></td>
	<td class="line x" title="60:134	As already noted, it consists of word association collected from about 50 respondents (although there are 100 respondents in the case of kizuku), and where some responses would obviously be provided by multiple respondents." ></td>
	<td class="line x" title="61:134	Comparisons of the SkE results with the sets of word association responses revealed that there is considerable overlap in the range of lexical relationships observed in the two linguistics resources." ></td>
	<td class="line x" title="62:134	However, the comparisons also identified many lexical relationships that are only present in one of the language resources." ></td>
	<td class="line x" title="63:134	3 Because of the large differences in the overall sizes of the association responses in JWAD-V1 and the collocations in SkE, it is not surprising that the word association data does not cover the numerous collocation words present in the SkE results." ></td>
	<td class="line x" title="64:134	(In future studies, we plan to examine the kinds of relationships that are extracted from the corpora but which are not observed in the word association database)." ></td>
	<td class="line x" title="65:134	However, it is very interesting to note that a considerable number of the JWAD word associations were not present in the SkE results, even though the tool is drawing on a much larger resource." ></td>
	<td class="line x" title="66:134	In this study, we concentrate on describing these lexical relationships." ></td>
	<td class="line x" title="67:134	Table 1." ></td>
	<td class="line x" title="68:134	The numbers of word association norms present (+) and absent (-) in the Word Sketches (WS) and the Thesaurus (T) results Norms Ass." ></td>
	<td class="line x" title="69:134	Freq  2 Ass." ></td>
	<td class="line x" title="70:134	Freq = 1 WS+ WST+ WS+ WST+ omoshiroi 6 5 2 1 16 2 kizuku 6 8 3 9 44 2 sagasu 4 8 1 2 13 1 jitensha 7 13 0 2 10 0 natsu 3 4 1 5 13 1 yama 6 3 2 8 7 2  Table 1 shows that considerable numbers of word association responses with frequencies of two or more, as well as many with frequencies of one, are not observed in the word sketches and thesaurus results." ></td>
	<td class="line x" title="71:134	While these results could be indicating a need to consider new methods or approaches to corpus-extraction in addition to those currently employed, these findings also strongly suggest that some of the lexical relationships might be unique to the normative word association data." ></td>
	<td class="line x" title="72:134	Both resources unquestionably tap into fundamental aspects of lexical relationships, but the resources would seem to be quite different in nature." ></td>
	<td class="line x" title="73:134	Accordingly, the present results suggest that investigations into lexical relationships would do well to employ both corpus-based results and databases of word association norms in complementary ways, in order to provide more comprehensive coverage of the diverse range of lexical relationships." ></td>
	<td class="line x" title="74:134	The thesaurus function only outputs lexical relationships between words of the same word class." ></td>
	<td class="line x" title="75:134	This function also yields synonym relationships that are also found in the word association norms, and are rated as being highly salient for the thesaurus results." ></td>
	<td class="line x" title="76:134	For example, tanoshii and kyomibukai ( interesting) are word association responses for omoshiroi." ></td>
	<td class="line x" title="77:134	4.2 Lexical Relationships that are Common to Both the Corpus-Based Results and the Word Association Norms This section discusses some of the lexical relationships common to the two resources." ></td>
	<td class="line x" title="78:134	The most frequent of these are presented in Table 2." ></td>
	<td class="line x" title="79:134	The first coord group includes kawa ( river) with the noun of yama, tanoshii ( pleasant) with the adjective of omoshiroi, and odoroku ( to be surprised) with the verb of kizuku." ></td>
	<td class="line x" title="80:134	Other frequent relationships are verbal phrases involving appropriate particles (such as nounNI (e.g., jitensha ni noru ( to ride a bicycle), noPronom, nounWO (e.g., michi wo sagasu ( to look for a road), deVerb, niVerb)." ></td>
	<td class="line x" title="81:134	Table 2 also includes a number of modification relationships (modifier_Adv, modifier_Ai (e.g., atsui natsu ( hot summer))." ></td>
	<td class="line x" title="82:134	Note that these terms are those employed in the Word Sketch results." ></td>
	<td class="line x" title="83:134	Table 2." ></td>
	<td class="line x" title="84:134	Lexical relationships common to both the Word Sketch (WS) results and the word association norms Relationship WS Example Coord 15 (yama/kawa),  (omoshiroi/tanoshii),  (kizuku/ odoroku) nounNI 8  (machigai ni kizuku) noPronom 7  (jitensha no kagi)  (yama no midori) gaAdj 5  (yama ga kirei) nounWO 4  (michi wo sagasu) waAdj 4  (natsu wa suki) waVerb 4  (jitensha wa hashiru) deVerb 3  (jitensha de korobu) modifier_Adv 3  (futo kizuku) modifier_Ai 3  (atsui natsu) niVerb 3 (jitensha ni noru) nounWA 3  (hanashi wa omoshiroi) woVerb 3  (jitensha wo kogu)  4 4.3 Relations Specific to Association Norms While acknowledging that it could be beneficial to examine the types of lexical relationships observed in the corpus-based results but not in the word association data, given the relative differences in the sizes of the two resources, the present study focuses on the relationships that were only present in the database of word association norms." ></td>
	<td class="line x" title="85:134	Briefly, these relationships can be classified under six categories." ></td>
	<td class="line x" title="86:134	(1) Relationships involving a specific concept related to the stimulus word and its contextual meaning." ></td>
	<td class="line x" title="87:134	In Table 3 below, many of these are classified as typically associated words." ></td>
	<td class="line x" title="88:134	Examples include omoshiroi and warai (  laughter), kizuku and ch i ( attention), and natsu and taiy  ( sun)." ></td>
	<td class="line x" title="89:134	These relationships are neither collocational nor grammatical in nature, and so the grammatical analysis currently employed in the word sketches cannot identify them." ></td>
	<td class="line x" title="90:134	On the other hand, while they are semantically related, because they often belong to different word classes, the thesaurus function also fails to identify them." ></td>
	<td class="line x" title="91:134	(2) Relationships that are semantically similar (could be regarded as close synonyms) but do not belong to the same word class." ></td>
	<td class="line x" title="92:134	Examples include sagasu and tanky  ( search) and kizuku andkikubari ( care, attention)." ></td>
	<td class="line x" title="93:134	While these are not grammatical or collocational relations, again, the thesaurus function is also unable to find them because they belong to different word classes." ></td>
	<td class="line x" title="94:134	(3) Association responses consisting of more than one word." ></td>
	<td class="line x" title="95:134	Examples include explanatory phrases such as kibun ga ii ( lit." ></td>
	<td class="line x" title="96:134	feeling is good, comfortable) as response to omoshiroi, as well as concepts denoted by phrases, such as hito no kao ( human faces), also a response to omoshiroi." ></td>
	<td class="line x" title="97:134	(4) Relationships that could be recognized by the SkE, but which the present version fails to detect." ></td>
	<td class="line x" title="98:134	These would seem to reflect limitations with the present ChaSen dictionary (e.g., it does not list chari / charinko ( casual words for bicycle) or morphological/POStagging errors with ChaSen, or relationships that are not regarded as being sufficiently salient within the complete corpus, because they may appear frequently as both independent words and as constituents of many poly-morpheme words (e.g., omoshiroi hito ( interesting person))." ></td>
	<td class="line x" title="99:134	(5) Relationships that can be identified when search is executed for orthographic variants of the word, such as tsumaranai ( boring) being found when omoshiori is written in hiragana (as )." ></td>
	<td class="line x" title="100:134	(6) Word association responses that are rather idiosyncratic in nature, often reflecting private experiences of a single respondent." ></td>
	<td class="line x" title="101:134	The importance of such responses in word association databases should be judged on the size of the database, although one also should be cautious about sampling issues with lower respondent numbers." ></td>
	<td class="line x" title="102:134	While it would certainly be interesting to conduct further comparisons between the association norms and other kinds of corpora, such as literary works, newspapers, or more balanced corpora, processed by the SkE, the main purpose of the present paper is to draw attention to the value of word association databases as linguistic resources." ></td>
	<td class="line x" title="103:134	Although the lexical relationships in categories 1 and 2 were not observed in the present corpus-based results, they are unquestionably of great relevance to efforts to develop more principled organizations of the lexicon for navigational purposes, and would enhance existing lexical resources, such as WordNet." ></td>
	<td class="line x" title="104:134	With trends to increasingly include multiple word idioms and phrases within various dictionaries and linguistic resources, the multiple-word association responses of category 3 may provide further insights into how such items are stored and processed." ></td>
	<td class="line x" title="105:134	Moreover, categories 4 and 5 clearly suggest that free word association norms can be a very useful resource for evaluating and further improving morphological analyzers, as well as corpus query tools." ></td>
	<td class="line x" title="106:134	5 Lexicographical Implications: Organizing Lexicons According to Association Relationships As the merits of SkE and its significant contributions to the compilation of a number of major dictionaries are discussed in detail elsewhere (e.g., Kilgarriff and Rundell, 2002), and because Srdanovi and Nishina (2008) outline some possible lexicographical applications of the Japanese language version of the SkE, in this section, we focus on the lexical relationships observed within the JWAD and their lexicographical implications for realizing a principled association-based organization of the lexicon." ></td>
	<td class="line x" title="107:134	5 Table 3." ></td>
	<td class="line x" title="108:134	Tentative classification of the word association responses elicited for fuyu ( winter) Relationship Description Examples Modification Attribute: Temperate  (samui cold) Modification Attribute: Color  (shiroi white) Modification Attribute: Emotion  (setsunai bitter, severe) Lexical siblings Hyponyms of seasons  (natsu summer),  (haru spring) Typically associated Meteorological phenomena   (yuki snow),  (koori ice) Typically associated Activity  (t min hibernation),  (ett  passing of winter),  (ky kei rest),  (yasumi rest, holiday) Typically associated Cultural artifacts  (kotatsu quilt for lower body when sitting around low table),  (kamakura snow hut) Typically associated Time  (t ji winter solstice) Typically associated Location  (kita north) Typically associated Animal  (kuma bear) Typically associated Cultural symbolization  (fuyu-sh gun General Winter; hard winter; Jack Frost)  5.1 Linguistic Approaches to Association Data and Its Potential As previously commented, Deese (1965) and Cramer (1968) have both argued that word associations closely mirror the structured patterns of relations that exist among concepts." ></td>
	<td class="line x" title="109:134	Indeed, as Sinopalnikova and Pavel (2004) note, Deese (1965) was the first to conduct linguistic analyses of word association norms, such as measurements of semantic similarity based on his convictions that similar words evoke similar word association responsesan approach that is somewhat reminiscent of Church and Hanks (1990) notion of mutual information." ></td>
	<td class="line x" title="110:134	However, as we have also remarked already, the linguistic value of word association data has, regrettably, been largely overlooked." ></td>
	<td class="line x" title="111:134	In a similar spirit to Hirsts (2004) claim that, notwithstanding certain caveats on the complex relationships between them, a lexicon can often serve as a useful basis for developing a practical ontology, we believe that a very promising approach to organizing the lexicon would be to more fully appreciate and utilize the rich variety of associative relationships that exist within word association norms." ></td>
	<td class="line x" title="112:134	While the required, more thoroughgoing investigation into how to appropriately classify the complex nature of associative relationships is beyond the scope of this present study, in the next sub-section, we attempt to highlight the potential contributions that word association norms could provide to efforts seeking to explore lexical knowledge." ></td>
	<td class="line x" title="113:134	5.2 Tentative Classification of Association Relationships To illustrate some of the issues for developing a comprehensive, yet a parsimonious, classification of associative relationships, it is useful to briefly consider the notion proposed by Zock and Bilac (2004) and Zock (2006) of word search strategies in electronic dictionaries based on associations." ></td>
	<td class="line x" title="114:134	Their outline of how such a look-up system might function employs three kinds of basic association relationships; namely, a kind of (AKO), subtype (ISA), and typically involved object, relation or actor (TIORA)." ></td>
	<td class="line x" title="115:134	While we accept that the limited set of just three types was probably motivated primarily in the interests of simplicity, given Zocks (2006) suggestion to enhance the navigability of the system by categorizing relationships, clearly the classification of association relationships is a fundamental issue." ></td>
	<td class="line x" title="116:134	Table 3 presents a tentative classification of the word association responses for the noun winter." ></td>
	<td class="line x" title="117:134	As the comparisons introduced in Section 4 clearly demonstrate, it is usually possible to extract the modification and lexical sibling relationships included in Table 3 from corpora with corpus query tools such as SkE." ></td>
	<td class="line x" title="118:134	However, the comparisons also highlighted the fact that it is far more difficult to identify the kinds of relationships classified in Table 3 as typically associated with such linguistic resources alone." ></td>
	<td class="line x" title="119:134	While highly provisional in nature, we believe that the attempt to classify the association relationships within the association responses for fuyu can 6 serve to highlight some important issues for Zock and Bilacs (2004) approach." ></td>
	<td class="line x" title="120:134	While the lexical siblings relationships between fuyu and the two response words of natsu ( summer) and haru ( spring) could feasibly be represented by AKO or ISA relationship links to shiki ( the four seasons) outside of the association set itself, having to rely on external references would not be a very satisfactory approach to classifying the direct association relationships." ></td>
	<td class="line x" title="121:134	Incidentally, although the hyponyms of seasons description would seem fairly natural from the perspective of a thesaurus, the absence of aki ( autumn) from the set would indicate that the strengths of associations can vary even among lexical siblings (although the absence of aki from the present data could simply be due to sampling issues)." ></td>
	<td class="line x" title="122:134	Given that fuyu is a noun, the presence of several modification relationships is not very surprising, at least not for the prime associate of samui ( cold), but the idea of fuyu having a color attribute is perhaps initially more startling (while one many not expect winter to have a default color slot within its range of attributes, the association of shiroi ( white) with fuyu is initiatively appealing)." ></td>
	<td class="line x" title="123:134	For the fuyu association set, the most relevant of the association relationships specified by Zock and Bilac (2004) is the TIORA relationship." ></td>
	<td class="line x" title="124:134	However, even for this relatively small association set containing just 11 main relationship types, because seven of them can be initially classified as typically associated, clearly this designation alone is too encompassing to be a useful classification category." ></td>
	<td class="line x" title="125:134	The inclusion of the description field in Table 3 is an attempt to further define meaningful sub-categories." ></td>
	<td class="line x" title="126:134	In the case of the sub-category meteorological phenomena, it would seem to be well motivated to explain the associations between fuyu as the stimulus word and yuki ( snow) and k ri ( ice) as two response words." ></td>
	<td class="line x" title="127:134	However, while the subcategory of cultural artifacts clearly goes some way to pinpointing the underlying association between fuyu and kotatsu (), it does rely on a certain cultural familiarity with the kind of quilted kind of blanket that are used for keeping ones legs warm when sitting around a low family table during winter." ></td>
	<td class="line x" title="128:134	A natural association for anyone who has ever lived in Japan during the winter months, but typically associated + cultural artifact seems to miss something of the naturalness." ></td>
	<td class="line x" title="129:134	6 Conclusions This paper has compared the lexical relationships observed within Japanese collocation data extracted from a large corpus using the Japanese language version of the Sketch Engine (SkE) tool and the relationships found within Japanese word association sets taken from the large-scale Japanese Word Association Database (JWAD)." ></td>
	<td class="line x" title="130:134	The comparison results indicate that while many lexical relationships are common to both linguistic resources, a number of lexical relationships were only observed in one of the resources." ></td>
	<td class="line x" title="131:134	The fact that some lexical relationships might be unique to word association norms demonstrates the value of word association databases as linguistic resources." ></td>
	<td class="line x" title="132:134	The present findings suggest that both resources can be effectively used in combination in order to provide more comprehensive coverage of the wide range of lexical relationships." ></td>
	<td class="line x" title="133:134	Finally, we presented a tentative classification of the association relationships in the association set for fuyu." ></td>
	<td class="line x" title="134:134	Our brief discussion of the classification sought to reflect on some of the challenges to realizing a principled association-based organization of the lexicon as a fundamental step toward implementing cognitively-salient wordsearch strategies based on associations in electronic dictionaries." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="Data not found"></td>
	<td class="line x" title="1:228	Coling 2008: Proceedings of the workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), pages 917 Manchester, August 2008 Lexical Access Based on Underspecified Input Michael ZOCK LIF-CNRS Equipe TALEP 163, Avenue de Luminy F-13288 Marseille Cedex 9 michael.zock@lif.univ-mrs.fr Didier SCHWAB Groupe GETALP Laboratoire dInformatique de Grenoble 385 avenue de la Bibliothque BP 53 F-38041 Grenoble Cedex 9 didier.schwab@imag.fr Abstract Words play a major role in language production, hence finding them is of vital importance, be it for speaking or writing." ></td>
	<td class="line x" title="2:228	Words are stored in a dictionary, and the general belief holds, the bigger the better." ></td>
	<td class="line x" title="3:228	Yet, to be truly useful the resource should contain not only many entries and a lot of information concerning each one of them, but also adequate means to reveal the stored information." ></td>
	<td class="line x" title="4:228	Information access depends crucially on the organization of the data (words) and on the navigational tools." ></td>
	<td class="line x" title="5:228	It also depends on the grouping, ranking and indexing of the data, a factor too often overlooked." ></td>
	<td class="line x" title="6:228	We will present here some preliminary results, showing how an existing electronic dictionary could be enhanced to support language producers to find the word they are looking for." ></td>
	<td class="line x" title="7:228	To this end we have started to build a corpus-based association matrix, composed of target words and access keys (meaning elements, related concepts/words), the two being connected at their intersection in terms of weight and type of link, information used subsequently for grouping, ranking and navigation." ></td>
	<td class="line x" title="8:228	1 Context and problem When speaking or writing we encounter basically either of the following two situations: one where everything works automatically, somehow like magic, words popping up one after another c2008." ></td>
	<td class="line x" title="9:228	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="10:228	Some rights reserved." ></td>
	<td class="line x" title="11:228	like spring water, and another where we look deliberately and often painstakingly for a specific, possibly known word." ></td>
	<td class="line x" title="12:228	We will be concerned here with this latter situation: a speaker/ writer using an electronic dictionary to look for such a word." ></td>
	<td class="line x" title="13:228	Unfortunately, alphabetically organized dictionaries are not well suited for this kind of reverse lookup where the inputs are meanings (elements of the words definition) or conceptually related elements (collocations, associations), and the outputs the target words." ></td>
	<td class="line x" title="14:228	Without any doubt, lexicographers have made considerable efforts to assist language users, building huge resources, composed of many words and lots of information associated with each one of them." ></td>
	<td class="line x" title="15:228	Still, it is not unfair to say most dictionaries have been conceived from the readers point of view." ></td>
	<td class="line x" title="16:228	The lexicographers have hardly taken into account the language producers perspective,1 considering conceptual input, incomplete as it may be, as starting point." ></td>
	<td class="line x" title="17:228	While readers start with words, looking generally for their corresponding meanings, speakers or writers usually start with the opposite, meanings or concepts,2 which should be the entry points of a dictionary, which ideally is neutral in terms of access direction.3 The problem is that we still dont know very well what concepts are, whether they are compositional and if so, how many primitives there are (Wilks, 1977; Wierzbicka, 1996; Goddard, 1998)." ></td>
	<td class="line x" title="18:228	1Rogets thesaurus (Roget, 1852), Miller and Fellbaums WordNet (Fellbaum, 1998) and Longmans Language Activator (Summers, 1993), being notable exceptions (For more details, see next section)." ></td>
	<td class="line x" title="19:228	2Of course, this does not preclude, that we may have to use words to refer to them in a concept-based query." ></td>
	<td class="line x" title="20:228	3While we agree with Polgu`ere theoretically when he pleads for dictionary neutrality with regard to lexical access (Polgu`ere, 2006), from a practical point of view the situation is obviously quite different for the speaker and listener, even if both of them draw on the same resource." ></td>
	<td class="line x" title="21:228	9 Neither do we know how to represent them." ></td>
	<td class="line x" title="22:228	Yet, there are ways around this problem as we will show." ></td>
	<td class="line x" title="23:228	Whether concepts and words are organized and accessed differently is a question we cannot answer here." ></td>
	<td class="line x" title="24:228	We can agree though on the fact that getting information concerning words is fairly unproblematic when reading, at least in the case of most western languages." ></td>
	<td class="line x" title="25:228	Words can generally be found easily in a dictionary, provided the user knows the spelling, the alphabet and how to build lemma starting from an inflected form." ></td>
	<td class="line x" title="26:228	Unlike words, which are organized alphabetically (in western languages) or by form (stroke counts in Chinese), concepts are organized topically: they are clustered into functional groups according to their role in real world, or our perception of it." ></td>
	<td class="line x" title="27:228	Psychologist have studied the difficulties people have when trying to produce or access words (Aitchinson, 2003)." ></td>
	<td class="line x" title="28:228	In particular, they have studied the tip-of-the-tongue phenomenon (Brown and McNeill, 1996) and the effects an input can have on the quality of an output (error analysis (Cutler, 1982)) and on the ease of its production: positive or negative priming effect (activation/inhibition)." ></td>
	<td class="line x" title="29:228	Obviously, these findings allow certain conclusions, and they might guide us when developing tools to help people find the needed word." ></td>
	<td class="line x" title="30:228	In particular, they reveal two facts highly relevant for our goal: 1." ></td>
	<td class="line x" title="31:228	even if people fail to access a given word, they might know a lot about it: origin, meaning (word definition, role played in a given situation), part of speech, number of syllables, similar sounding words, etc. Yet, despite all this knowledge, they seem to lack some crucial information to be able to produce the phonetic form." ></td>
	<td class="line x" title="32:228	The word gets blocked at the very last moment, even though it has reached the tip-of-the-tongue." ></td>
	<td class="line x" title="33:228	This kind of nuisance is all the more likely as the target word is rare and primed by a similar sounding word." ></td>
	<td class="line x" title="34:228	2." ></td>
	<td class="line x" title="35:228	unlike words in printed or electronic dictionaries, words in our mind may be inexistent as tokens." ></td>
	<td class="line x" title="36:228	What we seem to have in our minds are decomposed, abstract entities which need to be synthesized over time.4 Ac4This may be very surprising, yet, this need not be the case if we consider the fact that speech errors are nearly always due to competing elements from the same level or an adjacent one, unless they are the result of a surrounding concept which has been activated, or which is about to be translated cording to Levelt (Levelt, 1996) the generation of words (synthesis) involves the following stages: conceptual preparation, lexical selection, phonologicaland phonetic encoding, articulation." ></td>
	<td class="line x" title="37:228	Bear in mind that having performed lexical selection does not imply access to the phonetic form (see the experiments on the tip-of-the-tongue phenomenon)." ></td>
	<td class="line x" title="38:228	What can be concluded from these observations?" ></td>
	<td class="line x" title="39:228	It seems that underspecified input is sufficiently frequent to be considered as normal." ></td>
	<td class="line x" title="40:228	Hence we should accept it, and make the best out of it by using whatever information is available (accessible), no matter how incomplete, since it may still contribute to find the wanted information, be it by reducing the search space." ></td>
	<td class="line x" title="41:228	Obviously, the more information we have the better, as this reduces the number of words among which to choose." ></td>
	<td class="line x" title="42:228	2 Related work and goal While more dictionaries have been built for the reader than for the writer, there have been some onomasiological attempts as early as in the middle of the 19th century." ></td>
	<td class="line x" title="43:228	For example, Rogets Thesaurus (Roget, 1852), Tongs Chinese and English instructor (Tong, 1862), or Boissieres analogical dictionary (Boissi`ere, 1862).5 Newer work includes Melcuks ECD (Melcuk et al., 1999), Miller and Fellbaums WordNet (Fellbaum, 1998), Richardson and Dolans MindNet (Richardson et al., 1998), Dongs HowNet (Dong and Dong, 2006) and Longmans Language Activator (Summers, 1993)." ></td>
	<td class="line x" title="44:228	There is also the work of into words." ></td>
	<td class="line x" title="45:228	Put differently, we do not store words at all in our mind, at least not in the laymans or lexicographers sense who consider word-forms and their meanings as one." ></td>
	<td class="line x" title="46:228	If we are right, than rather continue to consider the human mind as a word store we could consider it as a word factory." ></td>
	<td class="line x" title="47:228	Indeed, by looking at some of the work done by psychologists who try to emulate the mental lexicon (for a good survey see (Harley, 2004), pages 359-374) one gets the impression that words are synthesized rather than located and read out." ></td>
	<td class="line x" title="48:228	Taking a look at all this work, generally connectionist models, one may conclude that, rather than having words in our mind we have a set of more or less abstract features (concepts, syntactic information, phonemes), distributed across various layers, which need to be synthesized over time." ></td>
	<td class="line x" title="49:228	To do so we proceed from abstract meanings to concrete sounds, which at some point were also just abstract features." ></td>
	<td class="line x" title="50:228	By propagating energy rather than data (as there is no message passing, transformation or cumulation of information, there is only activation spreading, that is, changes of energy levels, call it weights, electronic impulses, or whatever), that we propagate signals, activating ultimately certain peripheral organs (larynx, tongue, mouth, lips, hands) in such a way as to produce movements or sounds, that, not knowing better, we call words." ></td>
	<td class="line x" title="51:228	5For a more recent proposal see (Robert et al., 1993)." ></td>
	<td class="line x" title="52:228	10 (Fontenelle, 1997; Sierra, 2000; Moerdijk, 2008), various collocation dictionaries (BBI, OECD) and Bernsteins Reverse Dictionary.6 Finally, there is M. Rundells MEDAL, a thesaurus produced with the help of Kilgariffs Sketch Engine (Kilgarriff et al., 2004)." ></td>
	<td class="line x" title="53:228	As one can see, a lot of progress has been accomplished over the last few years, yet more can be done, especially with regard to unifying linguistic and encyclopedic knowledge." ></td>
	<td class="line x" title="54:228	Lets take an example to illustrate our point." ></td>
	<td class="line x" title="55:228	Suppose, you were looking for a word expressing the following ideas: superior dark coffee made from beans from Arabia, and that you knew that the target word was neither espresso nor cappuccino." ></td>
	<td class="line x" title="56:228	While none of this would lead you directly to the intended word, mocha, the information at hand, i.e. the words definition or some of its elements, could certainly be used." ></td>
	<td class="line x" title="57:228	In addition, people draw on knowledge concerning the role a concept (or word) plays in language and in real world, i.e. the associations it evokes." ></td>
	<td class="line x" title="58:228	For example, they may know that they are looking for a noun standing for a beverage that people take under certain circumstances, that the liquid has certain properties, etc. In sum, people have in their mind an encyclopedia: all words, concepts or ideas being highly connected." ></td>
	<td class="line x" title="59:228	Hence, any one of them has the potential to evoke the others." ></td>
	<td class="line x" title="60:228	The likelihood for this to happen depends, of course, on factors such as frequency (associative strength), distance (direct vs. indirect access), prominence (saliency), etc. How is this supposed to work for a dictionary user?" ></td>
	<td class="line x" title="61:228	Suppose you were looking for the word mocha (target word: tw), yet the only token coming to your mind were computer (source word: sw)." ></td>
	<td class="line x" title="62:228	Taking this latter as starting point, the system would show all the connected words, for example, Java, Perl, Prolog (programing languages), mouse, printer (hardware), Mac, PC (type of machines), etc. querying the user to decide on the direction of search by choosing one of these words." ></td>
	<td class="line x" title="63:228	After all, s/he knows best which of them comes closest to the tw." ></td>
	<td class="line x" title="64:228	Having started from the sw computer, and knowing that the tw is neither some kind of software nor a type of computer, s/he would probably choose Java, which is not only a programming language but also an island." ></td>
	<td class="line x" title="65:228	Taking this latter as the 6There is also at least one electronic incarnation of a dictionary with reverse access, combining a dictionary (WordNet) and an encyclopedia (Wikipedia) (http://www.onelook.com/reverse-dictionary.shtml)." ></td>
	<td class="line x" title="66:228	new starting point s/he might choose coffee (since s/he is looking for some kind of beverage, possibly made from an ingredient produced in Java, coffee), and finally mocha, a type of beverage made from these beans." ></td>
	<td class="line x" title="67:228	Of course, the word Java might just as well trigger Kawa which not only rhymes with the sw, but also evokes Kawa Igen, a javanese volcano, or familiar word of coffee in French." ></td>
	<td class="line x" title="68:228	As one can see, this approach allows word access via multiple routes: there are many ways leading to Rome." ></td>
	<td class="line x" title="69:228	Also, while the distance covered in our example is quite unusual, it is possible to reach the goal quickly." ></td>
	<td class="line x" title="70:228	It took us actually very few moves, four, to find an indirect link, between two, fairly remotely related terms: computer and mocha." ></td>
	<td class="line x" title="71:228	Of course, cyber-coffee fans might be even quicker in reaching their goal." ></td>
	<td class="line x" title="72:228	3 The lexical matrix revisited The main question that we are interested in here is how, or in what terms, to index the dictionary in order to allow for quick and intuitive access to words." ></td>
	<td class="line x" title="73:228	Access should be possible on the basis of meaning (or meaning elements), various kinds of associations (most prominently syntagmatic ones) and, more generally speaking, underspecified input." ></td>
	<td class="line x" title="74:228	To this end we have started to build an association matrix (henceforth AM), akin to, yet different from G. Millers initial proposal of WN (Miller et al., 1990)." ></td>
	<td class="line x" title="75:228	He suggested to build a lexical matrix by putting on one axis all the forms, i.e. words of the language, and on the other, their corresponding meanings." ></td>
	<td class="line x" title="76:228	The latter being defined in terms of synsets." ></td>
	<td class="line x" title="77:228	The corresponding meaningform relations are signaled via a boolean (presence/absence)." ></td>
	<td class="line x" title="78:228	Hence, looking at the intersection of meanings and forms, one can see which meanings are expressed by, or converge toward what forms, or conversely, what form expresses which meanings." ></td>
	<td class="line x" title="79:228	Whether this is the way WN is actually implemented is not clear to us, though we believe that it is not." ></td>
	<td class="line x" title="80:228	Anyhow, our approach is different, and we hope the reader will understand in a moment the reasons why." ></td>
	<td class="line x" title="81:228	We will also put on one axis all the form elements, i.e. the lemmata or expressions of a given language (we refer to them as target words, henceforth tw)." ></td>
	<td class="line x" title="82:228	On the other axis we will place the triggers or access-words (henceforth aw), that is, the words or concepts capable and likely to evoke the tw." ></td>
	<td class="line x" title="83:228	These are typically the kind of words psy11 chologists have gathered in their association experiments (Jung and Riklin, 1906; Deese, 1965; Schvaneveldt, 1989)." ></td>
	<td class="line x" title="84:228	Note, that instead of putting a boolean value at the intersection of the tw and the aw, we will put weights and the type of link holding between the co-occurring terms." ></td>
	<td class="line x" title="85:228	This gives us quadruplets." ></td>
	<td class="line x" title="86:228	For example, an utterance like this is the key of the door might yield the aw (key), the tw(door), the link type lt(part of), and a weight (lets say 15)." ></td>
	<td class="line x" title="87:228	The fact that we have these two kinds of information is very important later on, as it allows the search engine to cluster by type the possible answers to be given in response to a user query (word(s) provided as input) and to rank them." ></td>
	<td class="line x" title="88:228	Since the number of hits, i.e. words from which the user must choose, may be substantial (depending on the degree of specification of the input), it is important to group and rank them to ease navigation, allowing the user to find directly and quickly the desired word, or at least the word with which to continue search." ></td>
	<td class="line x" title="89:228	Obviously, different word senses (homographs), require different entries (bank-money vs bankriver), but so will synonyms, as every word-form, synonym or not, is likely to be evoked by a different keyor access-word (similarity of sound).7 Also, we will need a new line for every different relation between a aw and a tw." ></td>
	<td class="line x" title="90:228	Whether more than one line is needed in the case of identical links being expressed by different linguistic resources (the lock of the door vs. the doors lock vs. the door has a lock) remains an open empirical question." ></td>
	<td class="line x" title="91:228	Let us see quickly how our AM is supposed to work." ></td>
	<td class="line x" title="92:228	Imagine you wanted to find the word for the following concept: hat of a bishop." ></td>
	<td class="line x" title="93:228	In such a case, any of the following concepts or words might come to your mind: church, Vatican, abbot, monk, monastery, ceremony, ribbon, and of course rhyming words like: brighter, fighter, lighter, righter, tighter, writer,8 as, indeed, any of them could remind us of the tw: mitre." ></td>
	<td class="line x" title="94:228	Hence, all of them are possible aw." ></td>
	<td class="line x" title="95:228	Once this resource is built, access is quite straightforward." ></td>
	<td class="line x" title="96:228	The user gives as input all the words coming to his mind when thinking of a given 7Take, for example, the nouns rubbish and garbage which can be considered as synonyms." ></td>
	<td class="line x" title="97:228	Yet, while the former may remind you of a rabbit or (horse)-radish, the latter may evoke the word cabbage." ></td>
	<td class="line x" title="98:228	8The question, whether rhyming words should be computed is not crucial at this stage." ></td>
	<td class="line x" title="99:228	idea or concept,9 and the system will display all connected words." ></td>
	<td class="line x" title="100:228	If the user can find the item he is looking for in this list, search stops, otherwise it will continue, the user giving other words of the list, or words evoked by them." ></td>
	<td class="line x" title="101:228	Of course, remains the question of how to build this resource, in particular, how to populate the axis devoted to the trigger words, i.e. accesskeys." ></td>
	<td class="line x" title="102:228	At present we consider three approaches: one, where we use the words occurring in word definitions (see also, (Dutoit and Nugues, 2002; Bilac et al., 2004)), the other is to mine a wellbalanced corpus, to find co-occurrences within a given window (Ferret and Zock, 2006), the size depending a bit on the text type (encyclopedia) or type of corpus." ></td>
	<td class="line x" title="103:228	Still another solution would be to draw on the association lists produced by psychologists, see for example http://www.usf.edu/, or http://www.eat.rl.ac.uk." ></td>
	<td class="line x" title="104:228	Of course, the idea of using matrices in linguistics is not new." ></td>
	<td class="line x" title="105:228	There are at least two authors who have proposed its use: M. Gross (Gross, 1984) used it for coding the syntactic behavior of lexical items, hence the term lexicon-grammar, and G. Miller, the father of WN (Miller et al., 1990) suggested it to support lexical access." ></td>
	<td class="line x" title="106:228	While the former work is not relevant for us here, Millers proposal is. What are the differences between his proposal and ours?" ></td>
	<td class="line x" title="107:228	There are basically four main differences: 1." ></td>
	<td class="line x" title="108:228	we use, collocations or access-words, i.e aws rather than synsets; Hence, any of the following aws (cat, grey, computer device, cheese, Speedy Gonzales) could point toward the tw mouse, none of them are part of the meaning, leave alone synonyms." ></td>
	<td class="line x" title="109:228	2." ></td>
	<td class="line x" title="110:228	we mark explicitly the weight and the type of link between the tw and the aw (isa, part of, etc.),10 whereas WN uses only a binary value." ></td>
	<td class="line x" title="111:228	Both the weight and link are necessary information for ranking and grouping, i.e. navigation." ></td>
	<td class="line x" title="112:228	3." ></td>
	<td class="line x" title="113:228	our AM is corpus-sensitive (see below), hence, we can, at least in principle, accommo9The quantifier all shouldnt be taken too literally." ></td>
	<td class="line x" title="114:228	What we have in mind are salient words available in the speakers mind at a given moment 10Hence, if several links are possible between the tw and the aw, several cells will be used." ></td>
	<td class="line x" title="115:228	Think of the many possible relations between a city and a country, example: Paris and France (part of, biggest city of, located in, etc.) 12 date the fact that a speaker is changing topics, adapting the weight of a given word or find a more adequate aw in this new context." ></td>
	<td class="line x" title="116:228	Think of piano in the contexts of a concert or moving your household." ></td>
	<td class="line x" title="117:228	Only the latter would evoke the notion of weight." ></td>
	<td class="line x" title="118:228	4." ></td>
	<td class="line x" title="119:228	relying on a corpus, we can take advantage of syntagmatic associations (often encyclopedic knowledge), something which is difficult to obtain for WN." ></td>
	<td class="line x" title="120:228	4 Keep the set of lexical candidates small Here and in the next section we describe how the idea of the AM has been computationally dealt with." ></td>
	<td class="line x" title="121:228	The goal is to reduce the number of hits, i.e. possible tws (output), as a function of the input, i.e, the number of relevant aws given by the speaker/writer." ></td>
	<td class="line x" title="122:228	To achieve this goal we apply lexical functions to the aws, considering the intersection of the obtained sets to be the relevant tws." ></td>
	<td class="line x" title="123:228	4.1 Lexical Functions The usefulness of lexical functions for linguistics in general and for language production in particular has been shown by Melcuk (Melcuk, 1996)." ></td>
	<td class="line x" title="124:228	We will use them here, as they seem to fit also our needs of information extraction or lexical access." ></td>
	<td class="line x" title="125:228	Melcuk has coined the term lexical functions to refer to the fact that two terms are systematically related." ></td>
	<td class="line x" title="126:228	For example, the lexical function Gener refers to the fact that some term (lets say arrowhookleftcatarrowhookright) can be replaced by a more general term (lets say arrowhookleftanimalarrowhookright)." ></td>
	<td class="line x" title="127:228	Lexical functions encode the combinability of words." ></td>
	<td class="line x" title="128:228	While big and strong express the same idea (intensity, magnitude), they cannot be combined freely with any noun: strong can be associated with fever, whereas big cannot." ></td>
	<td class="line x" title="129:228	Of course, this kind of combinability between lexical terms is language specific, because unlike in English, in French one can say grosse fi`evre or forte fi`evre, both being correct (Schwab and Lafourcade, 2007)." ></td>
	<td class="line x" title="130:228	Our AM handles, of course these kind of functions." ></td>
	<td class="line x" title="131:228	Here is a list of some of them: paradigmatic associations: hypernymy (arrowhookleftcatarrowhookright arrowhookleftanimalarrowhookright), hyponymy, synonymy, or antonymy,." ></td>
	<td class="line x" title="132:228	; syntagmatic associations: collocations (arrowhookleftfeararrowhookright being associated with arrowhookleftstrongarrowhookright or arrowhookleftlittlearrowhookright); morphological relations ie." ></td>
	<td class="line x" title="133:228	terms being derived from another part of speech: applying the change-part-of-speech lexical function fcpos to arrowhookleftgardenarrowhookright will yield: fcpos(arrowhookleftgardenarrowhookright) = {arrowhookleftto gardenarrowhookright, arrowhookleftgardenerarrowhookright, . . .}" ></td>
	<td class="line x" title="134:228	sound-related items: homophones, rhymes." ></td>
	<td class="line x" title="135:228	4.2 Assumptions concerning search The purpose of using lexical functions is to reduce the number of possible outcomes from which the user must choose." ></td>
	<td class="line x" title="136:228	The list contains either the tw or another promising aw the user may want use to continue search." ></td>
	<td class="line x" title="137:228	Hence, lexical functions are useful for search provided that: 1." ></td>
	<td class="line x" title="138:228	the speaker/writer is able to specify the kind of relations s/he wants to use." ></td>
	<td class="line x" title="139:228	The problem here lies in the nature and number of the functions, some of them being very well specified, while others are not." ></td>
	<td class="line x" title="140:228	2." ></td>
	<td class="line x" title="141:228	the larger the number of trigger words the smaller the list of words from which to choose: the speaker/writer can add or delete words to broaden or narrow the scope of his/her query." ></td>
	<td class="line x" title="142:228	These hypotheses are being modeled by using set properties of lexical functions." ></td>
	<td class="line x" title="143:228	The idea is to apply all functions, or a selection of them, to the aws and to give the speaker/writer the intersection as result (see section 5.3.5 for an example) 5 Experiment We have started with a simple, preliminary experiment." ></td>
	<td class="line x" title="144:228	Only one lexical function was used: neighborhood (henceforth fneig)." ></td>
	<td class="line x" title="145:228	Let fneig be the function producing the set of co-occurring terms within a given window (sentence or a paragraph).11 The result produced by the system and returned to the user is the intersection of the application of fneig to the aws." ></td>
	<td class="line x" title="146:228	In the next section we explain how this function is applied to two corpora (Wordnet and Wikipedia), to show their respective qualities and shortcomings for this specific task." ></td>
	<td class="line x" title="147:228	5.1 WordNet 5.1.1 Description WordNet (henceforth WN) is a lexical database for English developed under the guidance of G. 11The scope or window size will vary with the text type (normal text vs. encyclopedia)." ></td>
	<td class="line x" title="148:228	The optimal size is at this point still an empirical question." ></td>
	<td class="line x" title="149:228	13 Miller (Miller et al., 1990)." ></td>
	<td class="line x" title="150:228	One of his goals was to support lexical access akin to the human mind, association-based." ></td>
	<td class="line x" title="151:228	Knowledge is stored in a network composed of nodes and links (nodes being words or concepts and the links are the means of connecting them) and access to knowledge, i.e. search, takes place by entering the network at some point and follow the links until one has reached the goal (unless one has given up before)." ></td>
	<td class="line x" title="152:228	This kind of navigation in a huge conceptual/lexical network can be considered equivalent to spreading activation taking place in our brain." ></td>
	<td class="line x" title="153:228	Of course, such a network has to be built, and navigational support must be provided to find the location where knowledge or words are stored." ></td>
	<td class="line x" title="154:228	This is what Miller and his coworkers did by building WN." ></td>
	<td class="line x" title="155:228	The resource has been built manually, and it contains at present about 150.000 entries." ></td>
	<td class="line x" title="156:228	The structure of the dictionary is different from conventional, alphabetical resources." ></td>
	<td class="line x" title="157:228	Words are organized in WN in two ways." ></td>
	<td class="line x" title="158:228	Semantically similar words, i.e. synonyms, are grouped as clusters." ></td>
	<td class="line x" title="159:228	These sets of synonyms, called synsets, are then linked in various ways, depending on the kind of relationship they entertain with the adjacent synset." ></td>
	<td class="line x" title="160:228	For example, their neighbors can be more general or specific (hyperonymy vs. hyponymy), they can be part of some reference object (meronymy: car-motor), they can be the opposite (antonymy: hot-cold), etc. While WN is a resource it can also be seen as a corpus." ></td>
	<td class="line x" title="161:228	5.1.2 Using WN as a corpus There are many good reasons to use WN for learning fn." ></td>
	<td class="line x" title="162:228	For one, there are many extensions, and second, the one we are using, eXtended WN (Mihalcea and Moldovan, 2001) spares us the trouble of having to address issues like: (a) segmentation: we do not need to identify sentence boundaries ; (b) semantic ambiguity: words being tagged, we get good precision; (c) lemmatization: since only verbs, nouns, adjectives and adverbs are tagged, we need neither a stoplist nor a lemmatizer." ></td>
	<td class="line x" title="163:228	Despite all these qualities, two important problems remain nevertheless for this kind of corpus: (a) size: though, all words are tagged, the corpus remains small as it contains only 63.941 different words; (b) in consequence, the corpus lacks many syntagmatic associations encoding encyclopedic knowledge." ></td>
	<td class="line x" title="164:228	5.2 Using Wikipedia as corpus Wikipedia is a free, multilingual encyclopedia, accessible on the Web.12 For our experiment we have chosen the English version which of this day (12th of may 2008) contains 2,369,180 entries." ></td>
	<td class="line x" title="165:228	Wikipedia has exactly the opposite properties of WN." ></td>
	<td class="line x" title="166:228	While it covers well encyclopedic relations, it is only raw text." ></td>
	<td class="line x" title="167:228	Hence problems like text segmentation, lemmatisation and stoplist definition need to be addressed." ></td>
	<td class="line x" title="168:228	Our experiments with Wikipedia were very rudimentary, given that we considered only 1000 documents." ></td>
	<td class="line x" title="169:228	These latter were obtained in response to the term arrowhookleftwinearrowhookright, by following the links obtained for about 72.000 words." ></td>
	<td class="line x" title="170:228	5.3 Prototype 5.3.1 Building the resource and using it." ></td>
	<td class="line x" title="171:228	Building the resource requires processing a corpus and building the database." ></td>
	<td class="line x" title="172:228	Given a corpus we apply our neighborhood function to a predetermined window (a paragraph in the case of encyclopedias).13 The result, i.e. the co-occurrences, will be stored in the database, together with their weight, i.e. number of times two terms appear together, and the type of link." ></td>
	<td class="line x" title="173:228	As mentionned above, both kinds of information are needed later on for ranking and navigation.14 At present, cooccurences are stored as triplets (tw, aw, times), where times represents the number of times the two terms cooccur in the corpus, the scope of coccurence being here the paragraph." ></td>
	<td class="line x" title="174:228	5.3.2 Processing of the Wikipedia page For each Wikipedia page, a preprocessor converts HTML pages into plain text." ></td>
	<td class="line x" title="175:228	Next, a part-of-speech tagger (http://www.ims.unistuttgart.de/projekte/corplex/TreeTagger/) is used to annotate all the words of the paragraph under consideration." ></td>
	<td class="line x" title="176:228	This allows the filtering of all irrelevant words, to keep but a bag of words, that is, the nouns, adjectives, verbs and adverbs occuring in the paragraph." ></td>
	<td class="line x" title="177:228	These words will be used to fill the triplets of our database." ></td>
	<td class="line x" title="178:228	12http://www.wikipedia.org 13The optimal window-size depends probably on the text type (encyclopedia vs. unformatted text)." ></td>
	<td class="line x" title="179:228	Yet, in the absence of clear criteria, we consider the optimal window-size as an open, empirical question." ></td>
	<td class="line x" title="180:228	14This latter aspect is not implemented yet, but will be added in the future, as it is a necessary component for easy navigation (Zock and Bilac, 2004; Zock, 2006; Zock, 2007)." ></td>
	<td class="line x" title="181:228	14 5.3.3 Corpus Building We start arbitrarily from some page (for our experiment, we have chosen wine as input), apply the algorithm outlined here above and pick then randomly a noun within this page to fetch with this input a new page on Wikipedia." ></td>
	<td class="line x" title="182:228	This process is repeated until a given sample size is obtained (in our case 1000 pages)." ></td>
	<td class="line x" title="183:228	Of course, instead of picking randomly a noun, we could have decided to process all the nouns of a given page, and to add then incrementally the nouns of the next pages." ></td>
	<td class="line x" title="184:228	Yet, doing this would have led us to privilege a specific topic (in our case wine) instead of a more general one." ></td>
	<td class="line x" title="185:228	5.3.4 Usage We have developed a website in Java as a servlet." ></td>
	<td class="line x" title="186:228	Interactions with humans are simple: people can add or delete a word from the current list (see Input in the figure on top of the next page)." ></td>
	<td class="line x" title="187:228	The example presented shows that with very few words, hence very quickly, we can obtain the desired word." ></td>
	<td class="line x" title="188:228	Given some input, the system provides the user with a list of words cooccuring with the aws." ></td>
	<td class="line x" title="189:228	The output is an ordered list of words, the order depending on the overall score, i.e. number of cooccurrences between the aw and the tw." ></td>
	<td class="line x" title="190:228	For example, if the aws wine and harvest co-occur with the tw bunch respectively 5 and 8 times, then the overall score of cooccurence of bunch is 13: ((wine, harvest), bunch, 13)." ></td>
	<td class="line x" title="191:228	Hence, all words with a higher score will precede it, while those with a lower score will follow it." ></td>
	<td class="line x" title="192:228	5.3.5 Examples and Comparison of the results of the two corpora Here below are the examples extracted from the WN corpus (see figure-1)." ></td>
	<td class="line x" title="193:228	Our goal was to find the word arrowhookleftvintagearrowhookright." ></td>
	<td class="line x" title="194:228	Trigger words are arrowhookleftwinearrowhookright and arrowhookleftharvestarrowhookright, yielding respectively 488 and 30 hits, i.e. words." ></td>
	<td class="line x" title="195:228	As one can see arrowhookleftharvestarrowhookright is a better access term than arrowhookleftwinearrowhookright." ></td>
	<td class="line x" title="196:228	Combining the two will reduce the list to 6 items." ></td>
	<td class="line x" title="197:228	Please note that the tw arrowhookleftvintagearrowhookright is not among them, eventhough it exists in WordNet, which illustrates nicely the fact that storage does not guarantee accessibility (Sinopalnikova and Smrz, 2006)." ></td>
	<td class="line x" title="198:228	Looking at figure-1 you will see that the results have improved considerably with Wikipedia." ></td>
	<td class="line x" title="199:228	The same input, arrowhookleftwinearrowhookright evokes many more words (1845 as opposed to 488)." ></td>
	<td class="line x" title="200:228	For arrowhookleftharvestarrowhookright we get 983 hits inInput WordNet Wikipedia 488 words 1845 words grape sweet alcoholic country serve france god characteristics wine small fruit regulation grape dry bottle appellation system produce red bottled like bread hold christian track . . ." ></td>
	<td class="line x" title="201:228	30 words 983 words month fish produce grain grape revolutionary autumn farms calendar festival energy cut harvest butterfish dollar combine ground person make balance rain wine first amount rich . . ." ></td>
	<td class="line x" title="202:228	6 words 45 words make grape grape vintage wine fish someone bottle produce +harvest commemorate person fermentation juice . . ." ></td>
	<td class="line x" title="203:228	Beaujolais taste viticulture France Bordeaux vineyard . . ." ></td>
	<td class="line x" title="204:228	Figure 1: Comparing two corpora (eXtended WordNet and Wikipedia) with various inputs stead of 30 (the intersection containing 62 words)." ></td>
	<td class="line x" title="205:228	Combining the two reduces the set to 45 items among which we will find, of course, the target word." ></td>
	<td class="line x" title="206:228	We hope that this example is clear enough to convince the reader that it makes sense to use real text as corpus to extract from it the kind of information (associations) people are likely to give when looking for a word." ></td>
	<td class="line x" title="207:228	6 Conclusion and perspectives We have addressed in this paper the problem of word finding for speakers or writers." ></td>
	<td class="line x" title="208:228	Concluding that most dictionaries are not well suited to allow for this kind of reverse access based on meanings (or meaning related elements, associations), we looked at work done by psychologists to get some inspiration." ></td>
	<td class="line x" title="209:228	Next we tried to clarify which of these findings could help us build the dictionary of tomorrow, that is, a tool integrating linguistic and encyclopedic knowledge, allowing navigation by taking either or as starting point." ></td>
	<td class="line x" title="210:228	While linguistic knowledge is more prominent for analysis (reading), encyclopedic facts are more relevant for production." ></td>
	<td class="line x" title="211:228	Weve presented then our ideas of how to build a resource, allowing lexical access based 15 on underspecified, i.e. imperfect input." ></td>
	<td class="line x" title="212:228	To achieve this goal weve started building an AM composed of form elements (the words and expressions of a given language) and aws." ></td>
	<td class="line x" title="213:228	The role of the latter being to lead to or to evoke the tw." ></td>
	<td class="line x" title="214:228	In the last part weve described briefly the results obtained by comparing two resources (WN and Wikipedia) and various inputs." ></td>
	<td class="line x" title="215:228	Given the fact that the project is still quite young, only preliminary results can be shown at this point." ></td>
	<td class="line oc" title="216:228	Our next steps will be to take a closer look at the following work: clustering of similar words (Lin, 1998), topic signatures (Lin and Hovy, 2000) and Kilgariffs sketch engine (Kilgarriff et al., 2004)." ></td>
	<td class="line x" title="217:228	We plan also to add other lexical functions to enrich our database with aws." ></td>
	<td class="line x" title="218:228	We plan to experiment with corpora, trying to find out which ones are best for our purpose15 and we will certainly experiment with the window size 16 to see which size is best for which text type." ></td>
	<td class="line x" title="219:228	Finally, we plan to insert in our AM the relations holding between the aw and the tw." ></td>
	<td class="line x" title="220:228	As these links are contained in our corpus, we should be able to identify and type them." ></td>
	<td class="line x" title="221:228	The question is, to what extent this can be done automatically." ></td>
	<td class="line x" title="222:228	Obviously, the success of our resource will depend on the quality of the corpus, the quality of the aws, weights and links, and the representativity of all this for a given population." ></td>
	<td class="line x" title="223:228	While we do believe in the justification of our intuitions, more work is needed to reveal the true potential of the approach." ></td>
	<td class="line x" title="224:228	The ultimate judge being, of course, the future user." ></td>
	<td class="line x" title="225:228	15For example, we could consider a resource like ConceptNet of the Open Mind Common-Sense project (Liuh and Singh, 2004)." ></td>
	<td class="line x" title="226:228	16For example, it would have been interesting to consider coocurrences beyond the scope of the paragraph, by considering the logical structure of the Wikipedia document." ></td>
	<td class="line x" title="227:228	Anyhow, our experiment needs to be redone with more data than just 1000 pages, the size chosen here for lack of time." ></td>
	<td class="line x" title="228:228	Indeed one could consider using the entire corpus of Wikipedia or mixed corpora" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="Data not found"></td>
	<td class="line x" title="1:191	Coling 2008: Proceedings of 3rd Textgraphs workshop on Graph-Based Algorithms in Natural Language Processing, pages 3340 Manchester, August 2008 Graph-based Clustering for Semantic Classication of Onomatopoetic Words Kenichi Ichioka Interdiscipli nary Graduate School of Medicine and Engineering University of Yamanashi, Japan g07mk001@yamanashi.ac.jp Fumiyo Fukumoto Interdiscipl inary Graduate School of Medicine and Engineering University of Yamanashi, Japan fukumoto@yamanashi.ac.jp Abstract This paper presents a method for semantic classication of onomatopoe tic words like uni3072.891uni3085.910uni30FC.660uni3072.891uni3085.910uni30FC.660 (hum) and uni304B.852uni3089.914uni3093.924 uni3053.860uni308D.918uni3093.924 (clip clop) which exist in every language, especially Japanese being rich in onomat opoetic words." ></td>
	<td class="line x" title="2:191	We used a graph-based clustering algorithm called Newman clustering." ></td>
	<td class="line x" title="3:191	The algorithm calculates a simple quality function to test whether a particular division is meaning ful." ></td>
	<td class="line x" title="4:191	The quality function is calculated based on the weights of edges between nodes." ></td>
	<td class="line x" title="5:191	We combin ed two different similarity measure s, distributional similarit y, and orthographic similarity to calculate weights . The results obtained by using the Web data showed a 9.0% improvement over the baseline single distributional similarity measure . 1 Introduction Onomatop oeia which we call onomato poetic word (ono word) is the formati on of words whose sound is imitative of the sound of the noise or action designated, such as hiss (McLeod, 1991)." ></td>
	<td class="line x" title="6:191	It is one of the linguistic features of Japanese." ></td>
	<td class="line x" title="7:191	Consider two sentences from Japanese." ></td>
	<td class="line x" title="8:191	(1) uni79C1.2226uni306F.888uni5ECA.4051uni4E0B.1340uni306E.887uni30B9.949uni30EA.998uni30C3.959uni30D1.973uni306E.887uni97F3.1339uni3067.880uni8D77.1609uni3053.860uni3055.862uni308C.917uni305F.872uni306E.887uni3067.880uni3001.634 uni3068.881uni3066.879uni3082.907uni7720.3774uni3044.845uni3002.635 Im too sleepy because I awoke to the slippers in the hall. c2008." ></td>
	<td class="line x" title="9:191	Licensed under the Creative Commons Attribution-Noncommer cial-Sh are Alike 3.0 Unported license (http://creati vecommon s.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="10:191	Some rights reserved." ></td>
	<td class="line x" title="11:191	(2) uni79C1.2226uni306F.888uni5ECA.4051uni4E0B.1340uni3092.923uni3071.890uni305F.872uni3071.890uni305F.872uni8D70.2808uni308B.916uni30B9.949uni30EA.998uni30C3.959uni30D1.973uni306E.887uni97F3.1339uni3067.880uni8D77.1609 uni3053.860uni3055.862uni308C.917uni305F.872uni306E.887uni3067.880uni3001.634uni3068.881uni3066.879uni3082.907uni7720.3774uni3044.845uni3002.635 Im too sleepy because I awoke to the pit-apat of slippers in the hall. Sentenc es (1) and (2) are almost the same sense." ></td>
	<td class="line x" title="12:191	However, sentence (2) which includes ono word, uni3071.890uni305F.872uni3071.890uni305F.872 (pit-a-pat) is much better to make the scene alive, or represents an image clearly." ></td>
	<td class="line x" title="13:191	Therefo re large-scale semantic resource of ono words is indispensable for not only NLP, but also many semantic-oriented applications such as Questio n Answerin g, Paraphras ing, and MT systems." ></td>
	<td class="line x" title="14:191	Although several machine-readable dictionaries which are ne-grained and large-scale semantic knowledge like WordNet, COMLEX, and EDR dictionary exist, there are none or few onomatopo etic thesaurus." ></td>
	<td class="line x" title="15:191	Because (i) it is easy to understand its sense of ono word for Japanese, and (ii) it is a fast-changing linguistic expressions, as it is a vogue word." ></td>
	<td class="line x" title="16:191	Therefor e, considering this resource scarcity problem, semantic classication of ono words which do not appear in the resource but appear in corpora is very importa nt." ></td>
	<td class="line x" title="17:191	In this paper, we focus on Japanese onomatopoetic words, and propose a method for classifying them into a set with similar meanin g. We used the Web as a corpus to collect ono words, as they appear in different genres of dialogues including broadcast news, novels and comics, rather than a well-edi ted, balanced corpus like newspaper articles." ></td>
	<td class="line x" title="18:191	The problem using a large, heterogeneous collection of Web data is that the Web counts are far more noisy than counts obtained from textual corpus." ></td>
	<td class="line x" title="19:191	We thus used a graph-based clustering algorithm, called Newman clustering for classifying ono words." ></td>
	<td class="line x" title="20:191	The algorithm does not simply calculate the number of shortest paths between pairs of nodes, but instead calculates a quality function 33 of how good a cluster structure found by an algorithm is, and thus makes the computation far more efcient." ></td>
	<td class="line x" title="21:191	The efcacy of the algorithm depends on a quality function which is calculated by using the weights of edges between nodes." ></td>
	<td class="line x" title="22:191	We combined two different similarity measures, and used them to calculate weights." ></td>
	<td class="line x" title="23:191	One is co-occurrence based distributional similarity measure . We tested mutual informa tion (MI) and a  2 statistic as a similarity measure . Another is orthographic similarity which is based on a feature of ono words called sound symbolism." ></td>
	<td class="line x" title="24:191	Sound symbol ism indicates that phonemes or phonetic sequences express their senses." ></td>
	<td class="line x" title="25:191	As ono words imitate the sounds associated with the objects or actions they refer to, their phonetic sequences provide semantic clues for classication." ></td>
	<td class="line x" title="26:191	The empirical results are encouraging, and showed a 9.0% improvement over the baseline single distributio nal similarity measure . 2 Previous Work There are quite a lot of work on semant ic classication of words with corpus-based approach." ></td>
	<td class="line oc" title="27:191	The earliest work in this direction are those of (Hindle, 1990), (Lin, 1998), (Dagan et al., 1999), (Chen and Chen, 2000), (Geffet and Dagan, 2004) and (Weeds and Weir, 2005)." ></td>
	<td class="line o" title="28:191	They used distributional similarity." ></td>
	<td class="line x" title="29:191	Similarity measure s based on distributional hypothesis compar e a pair of weighte d feature vectors that characterize two words." ></td>
	<td class="line x" title="30:191	Features typically correspond to other words that co-occur with the characterized word in the same context." ></td>
	<td class="line oc" title="31:191	Lin (1998) proposed a word similarity measure based on the distributio nal pattern of words which allows to construct a thesaurus using a parsed corpus." ></td>
	<td class="line o" title="32:191	He compared the result of automat ically created thesaurus with WordNet and Roget, and reported that the result was signicantly closer to WordNet than Roget Thesaurus was." ></td>
	<td class="line x" title="33:191	Graph representations for word similarity have also been proposed by several researchers (Jannink and Wiederhold, 1999; Galley and McKeown, 2003; Muller et al., 2006)." ></td>
	<td class="line x" title="34:191	Sinha and Mihalcea (2007) proposed a graph-based algorithm for unsupervised word sense disambiguation which combines several semanti c similarity measures including Resniks metric (Resnik , 1995), and algorithms for graph centrality." ></td>
	<td class="line x" title="35:191	They reported that the results using the SENSEVAL-2 and SENSEVAL-3 English all-words data sets lead to relative error rate reductions of 5  8% as compar ed to the previous work (Mihalcea, 2005)." ></td>
	<td class="line x" title="36:191	In the context of graph-based clustering of words, Widdows and Dorow (2002) used a graph model for unsupervised lexical acquisition." ></td>
	<td class="line x" title="37:191	The graph structure is built by linking pairs of words which participate in particular syntactic relationships." ></td>
	<td class="line x" title="38:191	An incremen tal cluster-building algorithm using the graph structure achieved 82% accuracy at a lexical acquisition task, evaluated against WordNet 10 classes, and each class consists of 20 words." ></td>
	<td class="line x" title="39:191	Matsuo et al.(2006) proposed a method of word clustering based on a word similarity measure by Web counts." ></td>
	<td class="line x" title="41:191	They used Newman clustering for clustering algorithm." ></td>
	<td class="line x" title="42:191	They evaluated their method using two sets of word classes." ></td>
	<td class="line x" title="43:191	One is derived from the Web data, and another is from WordNet." ></td>
	<td class="line x" title="44:191	1 Each set consists of 90 noun words." ></td>
	<td class="line x" title="45:191	They reported that the results obtained by Newman clustering were better than those obtained by average-link agglomerative clustering." ></td>
	<td class="line x" title="46:191	Our work is similar to their method in the use of Newman clustering." ></td>
	<td class="line x" title="47:191	However, they classied Japanese noun words, while our work is the rst to aim at detecting semantic classication of onomato poetic words." ></td>
	<td class="line x" title="48:191	Moreover, they used only a single similarity metric, cooccurrence based similarity, while Japanese, especially kanji characters of noun words provide semantic clues for classifying words." ></td>
	<td class="line x" title="49:191	3 System Description The method consists of three steps: retrieving cooccurrences using the Web, calculating similarity between ono words, and classifying ono words by using Newman clustering." ></td>
	<td class="line x" title="50:191	3.1 Retrieving Co-occurrence using the Web One criterion for calculating semantic similarity between ono words is co-occurrence based similarity." ></td>
	<td class="line x" title="51:191	We retrieved frequency of two ono words occurring together by using the Web search engine, Google." ></td>
	<td class="line x" title="52:191	The similarity between them is calculated based on their co-occurrence frequency." ></td>
	<td class="line x" title="53:191	Like much previous work on semant ic classication of the lexicons, our assumption is that semantically similar words appear in similar contexts." ></td>
	<td class="line x" title="54:191	A lot of strategies for searching words are provided in Google." ></td>
	<td class="line x" title="55:191	Of these we focused on two method s: Boolean search AND and phrase-based search." ></td>
	<td class="line x" title="56:191	1 They used WordNet hypernym information." ></td>
	<td class="line x" title="57:191	It consists of 10 classes." ></td>
	<td class="line x" title="58:191	They assigned 90 Japanese noun words to each class." ></td>
	<td class="line x" title="59:191	34 When we use AND boolean search, i.e., (O i O j ) where O i and O j are ono words, we can retrieve the number of documents which include both O i and O j . In contrast, phrase-based search, i.e., (O i O j ) retrieves documents which include two adjacent words O i and O j . 3.2 Similarity Measures The second step is to calculate semantic similar ity between ono words." ></td>
	<td class="line x" title="60:191	We combined two different similar ity measur es: the co-occurrence frequency based similarity and orthographic similarit y measures." ></td>
	<td class="line x" title="61:191	3.2.1 Co-occurrence based Similarit y Measure We focused on two popular measures : the mutual information (MI) and  2 statistics." ></td>
	<td class="line x" title="62:191	1." ></td>
	<td class="line x" title="63:191	Mutual Informatio n Church and Hanks (1990) discussed the use of the mutual information statistics as a way to identify a variety of interesting linguistic phenomena, ranging from semanti c relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence preferences between verbs and prepositions (content word/function word)." ></td>
	<td class="line x" title="64:191	Let O i and O j be ono words retrieved from the Web." ></td>
	<td class="line x" title="65:191	The mutual information MI(O i , O j ) is dened as: MI(O i , O j ) = log S all  f(O i , O j ) S O i  S O j , (1) where S O i = summationdisplay kO all f(O i , O k ), (2) S all = summationdisplay O i O all S O i ." ></td>
	<td class="line x" title="66:191	(3) In Eq." ></td>
	<td class="line x" title="67:191	(1), f(O i , O j ) refers to the frequency of O i and O j occurring together, and O all is a set of all ono words retrieved from the Web." ></td>
	<td class="line x" title="68:191	2." ></td>
	<td class="line x" title="69:191	 2 statistic The  2 (O i , O j ) is dened as:  2 (O i , O j ) = f(O i , O j )  E(O i , O j ) E(O i , O j ) , (4) where E(O i , O j ) = S O i  S O j S all ." ></td>
	<td class="line x" title="70:191	(5) S O i and S all in Eq." ></td>
	<td class="line x" title="71:191	(5) refer to Eq." ></td>
	<td class="line x" title="72:191	(2) and (3), respectively." ></td>
	<td class="line x" title="73:191	A major difference between  2 and MI is that the former is a normali zed value." ></td>
	<td class="line x" title="74:191	3.2.2 Orthographic Similarity Measure Orthogr aphic similarity has been widely used in spell checking and speech recognition systems (Damerau, 1964)." ></td>
	<td class="line x" title="75:191	Our orthographic similar ity measure is based on a unit of phonetic sequence." ></td>
	<td class="line x" title="76:191	The key steps of the similarit y between two ono words is dened as: 1." ></td>
	<td class="line x" title="77:191	Convert each ono word into phonetic sequences." ></td>
	<td class="line x" title="78:191	The hiragana characters of ono word are converted into phonetic sequences by a unique rule." ></td>
	<td class="line x" title="79:191	Basically, there are 19 consonants and 5 vowels, as listed in Table 1." ></td>
	<td class="line x" title="80:191	Table 1: Japanese consonants and vowels Conson ant , N, Q, h, hy, k, ky, m, my, n, ny, r, ry, s, sy, t, ty, w, y Vowel a, i, u, e, o Conside r phonetic sequences hyu-hyu- of ono word uni3072.891uni3085.910uni30FC.660uni3072.891uni3085.910uni30FC.660 (hum)." ></td>
	<td class="line x" title="81:191	It is segmented into 4 consonants hy, -, hy and -, and two vowels, u and u." ></td>
	<td class="line x" title="82:191	2." ></td>
	<td class="line x" title="83:191	Form a vector in n-dimens ional space." ></td>
	<td class="line x" title="84:191	Each ono word is represented as a vector of consonants(vowels), where each dimension of the vector corresponds to each consonant and vowel, and each value of the dimension is frequencies of its corresponding consonant(vowel)." ></td>
	<td class="line x" title="85:191	3." ></td>
	<td class="line x" title="86:191	Calculat e orthographic similar ity." ></td>
	<td class="line x" title="87:191	The orthographic similar ity between ono words, O i and O j is calculated based on the consonant and vowel distributio ns." ></td>
	<td class="line x" title="88:191	We used two popular measure s, i.e., the cosine similarity, and -skew divergence." ></td>
	<td class="line x" title="89:191	The cosine measures the similarity of the two vectors by calculating the cosine of the angle between vectors." ></td>
	<td class="line x" title="90:191	-skew divergence is dened as: div(x, y) = D(y ||   x + (1  )  y), where D(x||y) refers to Kullback-Leibler and dened as: D(x||y) = n summationdisplay i=1 x i  log x i y i ." ></td>
	<td class="line x" title="91:191	(6) 35 Lee (1999) reported the best results with  = 0.9." ></td>
	<td class="line x" title="92:191	We used the same value." ></td>
	<td class="line x" title="93:191	We dened a similari ty metric by combini ng co-occurrence based and orthographic similarit y measures 2 : Sim(O i , O j ) = MI(O i , O j )  (Cos(O i , O j ) + 1) (7) 3.3 The Newman Clustering Algorithm We classied ono words collected from the WWW." ></td>
	<td class="line x" title="94:191	Therefo re, the clustering algorithm should be efcient and effective even in the very high dimensional spaces." ></td>
	<td class="line x" title="95:191	For this purpose, we chose a graphbased clustering algorithm, called Newman clustering." ></td>
	<td class="line x" title="96:191	The Newman clustering is a hierarchical clustering algorithm which is based on Network structure (Newman, 2004)." ></td>
	<td class="line x" title="97:191	The network structure consists of nodes within which the node-node connections are edges." ></td>
	<td class="line x" title="98:191	It produces some division of the nodes into communiti es, regardless of whether the network structure has any natural such division." ></td>
	<td class="line x" title="99:191	Here, communit y or cluster have in common that they are groups of densely interconnected nodes that are only sparsely connected with the rest of the network." ></td>
	<td class="line x" title="100:191	To test whether a particular division is meaning ful a quality function Q is dened: Q = summationdisplay i (e ii  a 2 i ) where e ij is the sum of the weight of edges between two commun ities i and j divided by the sum of the weight of all edges, and a i = summationtext j e ij , i.e., the expected fraction of edges within the cluster." ></td>
	<td class="line x" title="101:191	Here are the key steps of that algorithm: 1." ></td>
	<td class="line x" title="102:191	Given a set of n ono words S = {O 1 ,   , O n }." ></td>
	<td class="line x" title="103:191	Create a network structure which consists of nodes O 1 ,   , O n , and edges." ></td>
	<td class="line x" title="104:191	Here, the weight of an edge betwee n O i and O j is a similarity value obtained by Eq." ></td>
	<td class="line x" title="105:191	(7)." ></td>
	<td class="line x" title="106:191	If the network density of ono words is smaller than the parameter , we cut the edge." ></td>
	<td class="line x" title="107:191	Here, network density refers to a ratio selected from the topmost edges." ></td>
	<td class="line x" title="108:191	For example , if it 2 When we used  2 statistic as a co-occurren ce based similarity, MI in Eq." ></td>
	<td class="line x" title="109:191	(7) is replaced by  2 . In a similar way, Cos(O i , O j ) is replaced by max  div(x, y), where max is the maximum value among all div(x, y) values." ></td>
	<td class="line x" title="110:191	was 0.9, we used the topmost 90% of all edges and cut the remain s, where edges are sorted in the descending order of their similarity values." ></td>
	<td class="line x" title="111:191	2." ></td>
	<td class="line x" title="112:191	Starting with a state in which each ono word is the sole member of one of n communi ties, we repeatedly joined communiti es together in pairs, choosing at each step the join that results in the greatest increase." ></td>
	<td class="line x" title="113:191	3." ></td>
	<td class="line x" title="114:191	Suppose that two communit ies are merged into one by a join operation." ></td>
	<td class="line x" title="115:191	The change in Q upon joining two communiti es i and j is given by: triangleQ ij = e ij + e ji  2a i a j = 2(e ij  a i a j ) 4." ></td>
	<td class="line x" title="116:191	Apply step 3." ></td>
	<td class="line x" title="117:191	to every pair of communi ties." ></td>
	<td class="line x" title="118:191	5." ></td>
	<td class="line x" title="119:191	Join two commun ities such that triangleQ is maximum and create one communit y. If triangleQ < 0, go to step 7." ></td>
	<td class="line x" title="120:191	6. Re-calcu late e ij and a i of the joined community, and go to step 3." ></td>
	<td class="line x" title="121:191	7. Words within the same community are regarded as semantically similar." ></td>
	<td class="line x" title="122:191	The computational cost of the algorithm is known as O((m + n)n) or O(n 2 ), where m and n are the number of edges and nodes, respectively." ></td>
	<td class="line x" title="123:191	4 Experimen ts 4.1 Experimental Setup The data for the classication of ono words have been taken from the Japanese ono dictionary (Ono, 2007) that consisted of 4,500 words." ></td>
	<td class="line x" title="124:191	Of these, we selected 273 words, which occurred at least 5,000 in the docume nt URLs from the WWW." ></td>
	<td class="line x" title="125:191	The minimum frequency of a word was found to be 5,220, while the maximum was about 26 million." ></td>
	<td class="line x" title="126:191	These words are classied into 10 classes." ></td>
	<td class="line x" title="127:191	Word classes and examples of ono words from the dictionary are listed in Table 2." ></td>
	<td class="line x" title="128:191	Id denotes id number of each class." ></td>
	<td class="line x" title="129:191	Sense refers to each sense of ono word within the same class, and Num is the number of words which should be assigned to each class." ></td>
	<td class="line x" title="130:191	Each word 36 Table 2: Onomatop oetic words and # of words in each class Id Sense Num Onomatopo etic words 1 laugh 63 uni3042.843uni3063.876uni306F.888uni3063.876uni306F.888 (a,Q,h,a,Q,h,a), uni3042.843uni306F.888uni306F.888 (a,h,a,h,a), uni308F.920uni306F.888uni306F.888 (w,a,h,a,h,a) uni3042.843uni306F.888uni3042.843uni306F.888 (a,h,a,a,h,a), uni3044.845uni3072.891uni3072.891 (i,h,i,h,i), uni3046.847uni3063.876uni3057.864uni3063.876uni3057.864 (u,Q,s,i,Q,s,i),    2 cry 34 uni3042.843uni30FC.660uni3093.924 (a,,N), uni3046.847uni308F.920uni30FC.660uni3093.924 (u,w,a,,N), uni3042.843uni3093.924uni3042.843uni3093.924 (a,N,a,N), uni3048.849uni3093.924uni3048.849uni3093.924 (e,N,e,N) uni3046.847uni308B.916uni3046.847uni308B.916 (u,r,u,u,r,u), uni3046.847uni308B.916uni308B.916uni3093.924 (u,r,u,r,u,N), uni3046.847uni308B.916uni3063.876(u,r,u,Q), uni3048.849uni30FC.660uni3093.924 (e,,N),    3 pain 34 uni3044.845uni304C.853uni3044.845uni304C.853 (i,k,a,i,k,a), uni3072.891uni308A.915uni3072.891uni308A.915 (h,i,r,i,h,i,r,i), uni304C.853uni3058.865uni304C.853uni3058.865 (k,a,s,i,k,a,s,i) uni304C.853uni3093.924uni304C.853uni3093.924 (k,a,N,k,a,N),    4 anger 33 uni304B.852uni30FC.660uni3063.876(k,a,,Q), uni304B.852uni3061.874uni3093.924 (k,a,t,i,N), uni304B.852uni3064.877uni3093.924 (k,a,t,u,N), uni304B.852uni3063.876(k,a,Q), uni304B.852uni3063.876uni304B.852 (k,a,Q,k,a), uni304C.853uni307F.904uni304C.853uni307F.904 (k,a,m,i,k,a,m, i), uni304B.852uni308A.915uni304B.852uni308A.915 (k,a,r,i,k,a,r,i), uni304B.852uni3093.924uni304B.852uni3093.924 (k,a,N,k,a,N),    5 spook 31 uni3042.843uni308F.920uni308F.920 (a,w,a,w,a), uni3046.847uni304E.855uni3083.908uni30FC.660 (u,ky,a,), uni304C.853uni30FC.660uni3093.924 (k,a,,N), uni304E.855uni304F.856 (k,i,k,u) uni304E.855uni304F.856uni3063.876(k,i,k,u,Q), uni304E.855uni304F.856uni308A.915 (k,i,k,u,r,i), uni304E.855uni304F.856uni3093.924 (k,i,k,u,N),    6 panic 25 uni3042.843uni304F.856uni305B.868uni304F.856 (a,k,u,s,e,k,u), uni3042.843uni305F.872uni3075.894uni305F.872 (a,t,a,h,u,t,a), uni3042.843uni3063.876uni3077.896uni3042.843uni3063.876uni3077.896 (a,Q,h,u,a,Q,h,u), uni3042.843uni308F.920uni3042.843uni308F.920 (a,w,a,a,w,a)   7 bloodless 27 uni304B.852uni304F.856uni3063.876(k,a,k,u,Q), uni304C.853uni304F.856uni3063.876(k,a,k,u,Q), uni304C.853uni3063.876uni304B.852uni308A.915 (k,a,Q,k,a,r ,i), uni304C.853uni3063.876uni304F.856uni308A.915 (k,a,Q,k,u,r ,i) uni304B.852uni304F.856uni3093.924 (k,a,k,u,N), uni304E.855uni3083.908uni3075.894uni3093.924 (ky,a,h,u,N), uni304E.855uni3085.910uni30FC.660 (ky,u,),    8 deem 13 uni3046.847uni3063.876uni3068.881uni308A.915 (u,Q,t,o,r,i), uni304D.854uni3085.910uni30FC.660uni3093.924 (ky,u,,N), uni304D.854uni3085.910uni3093.924 (ky,u,N) uni3064.877uni304F.856uni3065.878uni304F.856 (t,u,k,u,t,u,k,u),    9 feel delight 6 uni3046.847uni3057.864uni3046.847uni3057.864 (u,s,i,u,s,i ), uni304D.854uni3083.908uni3074.893uni304D.854uni3083.908uni3074.893 (ky,a,h,i,ky,a,h,i) uni3046.847uni306F.888uni3046.847uni306F.888 (u,,h,a,,u,,h,a), uni307B.900uni3044.845uni307B.900uni3044.845 (h,o,i,h,o,i), uni308B.916uni3093.924uni308B.916uni3093.924 (r,u,N,r,u,N),    10 balk 7 uni3044.845uni3058.865uni3044.845uni3058.865 (i,s,i,i,s,i), uni3046.847uni3058.865uni3046.847uni3058.865 (u,s,i,u,s,i), uni304A.851uni305A.867uni304A.851uni305A.867 (o,s,u,o,s,u) uni3050.857uni3060.873uni3050.857uni3060.873 (k,u,t,a,k,u,t,a), uni3082.907uni3058.865uni3082.907uni3058.865 (m,o,s,i,m,o,s,i),    Total 273 marked with bracket denotes phonetic sequences consisting of consonants and vowels." ></td>
	<td class="line x" title="131:191	We retrieved co-occurrences of ono words shown in Table 2 using the search engine, Google." ></td>
	<td class="line x" title="132:191	We applied Newman clustering to the input words." ></td>
	<td class="line x" title="133:191	For comparison, we implemen ted standard kmeans which is often used as a baseline, as it is one of the simplest unsupervised clustering algorithms, and compare d the results to those obtained by our method." ></td>
	<td class="line x" title="134:191	We used Euclidean distance (L 2 norm) as a distance metric used in the k-means." ></td>
	<td class="line x" title="135:191	For evaluation of classication, we used Precisio n(P rec), Recall(Rec), and F-measur e which is a measure that balances precision and recall (Bilenko et al., 2004)." ></td>
	<td class="line x" title="136:191	The precise denitions of these measur es are given below: P rec = #P airsCorrectlyP redictedInSamecluster #T otalP airsP redictedInSameCluster (8) Rec = #P airsCorrectlyP redictedInSameCluster #T otalP airsInSameCluster (9) F  measure = 2  P rec Rec (P rec + Rec) (10) 4.2 Results The results are shown in Table 3." ></td>
	<td class="line x" title="137:191	Co-occ . & Sounds  in Data refers to the results obtained by our method." ></td>
	<td class="line x" title="138:191	Co-oc c. denotes the results obtained by a single measur e, co-occurrence based distributional similarity measure, and Sound s shows the results obtained by orthographic similarity." ></td>
	<td class="line x" title="139:191	 in Table 3 shows a paramet er  used in the Newman clustering." ></td>
	<td class="line x" title="140:191	3 Table 3 shows best performance of each method against  values." ></td>
	<td class="line x" title="141:191	The best result was obtained when we used phrase-based search and a combin ed measure of co-occurrence(MI) and sounds (cos), and F-score was 0.451." ></td>
	<td class="line x" title="142:191	4.2.1 AND vs phrase-based search Table 3 shows that overall the results using phrase-based search were better than those of AND search, and the maximum difference of Fscore betwee n them was 20.6% when we used a combin ed measure . We note that AND boolean search did not consider the position of a word in a document, while our assumpt ion was that semantica lly similar words appeared in similar contexts." ></td>
	<td class="line x" title="143:191	As a result, two ono words which were not semant ically similar were often retrieved by AND boolean search." ></td>
	<td class="line x" title="144:191	For example , consider two antonymous words, a,h,a,h ,a (grinning broadly) and w,a,,N (Wah, Wah)." ></td>
	<td class="line x" title="145:191	The co-occurrence frequency obtained by AND was 5,640, while that of phrase-based search was only one." ></td>
	<td class="line x" title="146:191	The observation shows that we nd phrase-based search to be a good choice." ></td>
	<td class="line x" title="147:191	3 In case of k-means, we used the weights which satises network density." ></td>
	<td class="line x" title="148:191	37 Table 3: Classication results Data Algo." ></td>
	<td class="line x" title="149:191	Sim (Co-occ.)" ></td>
	<td class="line x" title="150:191	Sim (Sounds) Search method  Prec Rec F # of clusters  2 AND .050 .134 .799 .229 10 cos Phrase .820 .137 .880 .236 10 MI AND .050 .134 .562 .216 10 k-means Phrase .150 .190 .618 .289 10  2 AND .680 .134 .801 .229 10 div Phrase .280 .138 .882 .238 10 MI AND .040 .134 .602 .219 10 Co-occ." ></td>
	<td class="line x" title="151:191	& Sounds Phrase .140 .181 .677 .285 10  2 AND .170 .182 .380 .246 9 cos Phrase .100 .322 .288 .304 14 MI AND .050 .217 .282 .245 13 Newman Phrase .080 .397 .520 .451 7  2 AND .130 .212 .328 .258 9 div Phrase .090 .414 .298 .347 17 MI AND .090 .207 .325 .253 6 Phrase .160 .372 .473 .417 8  2 AND .460 .138 .644 .227 10 k-means  Phrase .110 .136 .870 .236 10 MI AND .040 .134 .599 .219 10 Co-occ." ></td>
	<td class="line x" title="152:191	Phrase .150 .191 .588 .286 10  2 AND .700 .169 .415 .240 8 Newman  Phrase .190 .301 .273 .286 14 MI AND .590 .159 .537 .245 3 Phrase .140 .275 .527 .361 5 k-means  cos  .050 .145 .321 .199 10 Sounds div  .020 .126 .545 .204 10 Newman  cos  .270 .151 .365 .213 4 div  .350 .138 .408 .206 3 4.2.2 A single vs combined similarity measure To examine the effectiveness of the combined similarity measure, we used a single measur e as a quality function of the Newman clustering, and compar ed these results with those obtained by our method . As shown in Table 3, the results with combin ing similarity measur es improved overall performance." ></td>
	<td class="line x" title="153:191	In the phrase-based search, for example, the F-score using a combine d measur e Coocc(MI) & Sounds( cos) was 23.8% better than the baseline single measure Sounds(cos), and 9.0% better a single measure Co-occ(MI)." ></td>
	<td class="line x" title="154:191	Figure 1 shows F-score by Co-occ(MI) & Sounds (cos) and Co-occ (MI) against changes in ." ></td>
	<td class="line x" title="155:191	These curves were obtained by phrasebased search." ></td>
	<td class="line x" title="156:191	We can see from Figure 1 that the F-score by a combined measure Co-occ(MI) & Sounds (cos) was better than Co-occ (MI) with  value ranged from .001 to .25." ></td>
	<td class="line x" title="157:191	One possible reason for the difference of F-score between them is the edges selected by varying ." ></td>
	<td class="line x" title="158:191	Figure 2 shows the results obtained by each single measure , and a combin ed measur e to examine how the edges selected by varying  affect overall performance, Fmeasur e. Precision in Figure 2 refers to the ratio of correct ono word pairs (edges) divided by the total number of edges." ></td>
	<td class="line x" title="159:191	Here, correct ono word pairs were created by using the Japanese ono dictionary, i.e., we extracted word pairs within the same sense of the dictionary." ></td>
	<td class="line x" title="160:191	Surprisingly, there were no signicant difference between a combine d measure Co-occ (MI) & Sounds(cos) and a single measure Co-oc c(MI) curves, while the precision of a single measur e Sounds was constantly worse than that obtained by a combin ed measure . Another possible reason for the difference of F-score is due to product of MI and Cos in Eq." ></td>
	<td class="line x" title="161:191	(7)." ></td>
	<td class="line x" title="162:191	Further work is needed to analyze these results in detail." ></td>
	<td class="line x" title="163:191	4.2.3 k-means vs Newman algorithms We examined the results obtained by standard kmeans and Newman clustering algorithms." ></td>
	<td class="line x" title="164:191	As can be seen clearly from Table 3, the results with Newman clustering were better than those of the standard k-means at all search and similarity measures , especially the result obtained by Newman clustering showed a 16.2 % improvement over the kmeans when we used Co-occ.( MI) & Sounds(cos) & phrase-based search." ></td>
	<td class="line x" title="165:191	We recall that we used 273 ono words for clustering." ></td>
	<td class="line x" title="166:191	However, Newman clustering is applicable for a large number of nodes and edges without decreasing accuracy too much, as it does not simply calculate the number of short38  0.1  0.15  0.2  0.25  0.3  0.35  0.4  0.45  0.5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1 F-measure Lower bound values Co-occ(MI) Co-occ(MI) & Sounds(cos) Figure 1: F-score against  values  0.1  0.15  0.2  0.25  0.3  0.35  0.4  0.45  0.5  0.55  0.6  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1 Precision Lower bound values Co-occ(MI) Co-occ(MI) & Sounds(cos) Sounds(cos) Figure 2: Precision against  values est paths between pairs of nodes, but instead calculates a simple quality function." ></td>
	<td class="line x" title="167:191	Quantitative evaluation by applying the method to larger data from the Web is worth trying for future work." ></td>
	<td class="line x" title="168:191	4.3 Qualitati ve Analysis of Errors Finally, to provide feedback for further development of our classication approach, we performed a qualitative analysis of errors." ></td>
	<td class="line x" title="169:191	Consider the following clusters (the Newman output for Co-occ .(MI), Sounds(cos) and phrase-based search), where each parenthetic sequences denotes ono word: A1: (t,o,Q) (t,o,Q,t,o) (t,o,Q,k, i,N,t,o,Q,k ,i,N) A2: (o,h,o,h,o), (e,h,e,h,e), (h,e,h,e,h,e), (o,-,o,-) A3: (u,s,i,u,s, i), (m,o,s,i,m,o,s,i), (m,o,s,o,m,o,s,o) Three main error types were identied: 1." ></td>
	<td class="line x" title="170:191	Morpho logical idiosyncrasy: This was the most frequent error type, exemplied in A1, where (t,o,Q,k,i,N,t,o,Q,k,i,N) (pain sense) was incorrectly clustered with other two words (laugh sense) merely because orthographic similarit y between them was large, as the phonetics sequences of (t,o,Q,k,i,N,t,o,Q,k,i,N) included t and o." ></td>
	<td class="line x" title="171:191	2." ></td>
	<td class="line x" title="172:191	Sparse data: Many of the low frequency ono words performed poorly." ></td>
	<td class="line x" title="173:191	In A2, (o,-,o,-) (cry sense) was classied with other three words (laugh sense) because it occurred few in our data." ></td>
	<td class="line x" title="174:191	3." ></td>
	<td class="line x" title="175:191	Problems of polysemy: In A3, (m,o,s,o,m,o,s,o) (pain sense) was clustered with other two words (balk sense) of its gold standard class." ></td>
	<td class="line x" title="176:191	However, the ono word has another sense, balk sense when it co-occurred with action verbs." ></td>
	<td class="line x" title="177:191	5 Conclusion We have focused on onomatopoetic words, and proposed a method for classifying them into a set of semant ically similar words." ></td>
	<td class="line x" title="178:191	We used a graphbased clustering algorithm, called Newman clustering with a combined different similar ity measures." ></td>
	<td class="line x" title="179:191	The results obtained by using the Web data showed a 9.0% improvement over the baseline single distributional similarity measure." ></td>
	<td class="line x" title="180:191	There are number of interesting directions for future research." ></td>
	<td class="line x" title="181:191	The distributional similarit y measure we used is the basis of the ono words, while other content words such as verbs and adverbs are also effective for classifying ono words." ></td>
	<td class="line x" title="182:191	In the future, we plan to investigate the use of these words and work on improving the accuracy of classication." ></td>
	<td class="line x" title="183:191	As shown in Table 2, many of the ono words consist of duplicative character sequences such as h and a of a,h,a,h,a, and h and i of i,h,i,h,i . Moreover, characters which consist of ono words within the same class match." ></td>
	<td class="line x" title="184:191	For example, the hiragana character uni306F.888 (h,a) frequently appears in laugh sense class." ></td>
	<td class="line x" title="185:191	These observations indicate that integrating edit-distance and our current similar ity measure will improve overall performance." ></td>
	<td class="line x" title="186:191	Another interesting direction is a problem of polysemy." ></td>
	<td class="line x" title="187:191	It clearly supports the classication of (Ono, 2007) to insist that some ono words belong to more than one cluster." ></td>
	<td class="line x" title="188:191	For example, (i,s,o,i,s,o)  has at least two senses, panic and feel delight sense." ></td>
	<td class="line x" title="189:191	In order to accommodate this, we 39 should apply an appropriate soft clustering technique (Tishby et al., 1999; Reichardt and Bornholdt, 2006; Zhang et al., 2007)." ></td>
	<td class="line x" title="190:191	Acknowledgment s We would like to thank the anonymous reviewers for their helpful suggestions." ></td>
	<td class="line x" title="191:191	This material is supported in part by the Grant-in-aid for the Japan Society for the Promotion of Science(JSPS)." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="Data not found"></td>
	<td class="line x" title="1:189	From Predicting Predominant Senses to Local Context for Word Sense Disambiguation Rob Koeling Diana McCarthy University of Sussex (UK) email: robk@sussex.ac.uk Abstract Recentworkonautomaticallypredictingthepredominantsense ofa word hasproventobepromising(McCarthyetal.,2004)." ></td>
	<td class="line x" title="2:189	Itcanbeapplied(asa first sense heuristic) to Word Sense Disambiguation(WSD) tasks, without needing expensive hand-annotated data sets." ></td>
	<td class="line x" title="3:189	Due to the big skew in the sense distribution of many words (Yarowsky and Florian, 2002), the First Sense heuristic for WSD is often hardto beat." ></td>
	<td class="line x" title="4:189	However,the local context of an ambiguousword can give importantclues to which of its senses was intended." ></td>
	<td class="line x" title="5:189	The sense ranking method proposed by McCarthy et al.(2004) uses a distributional similarity thesaurus." ></td>
	<td class="line x" title="7:189	The k nearest neighbours in the thesaurus are used to establish the predominant sense of a word." ></td>
	<td class="line x" title="8:189	In this paper we report on a first investigation on how to use the grammatical relations the target word is involved with, in order to select a subset of the neighboursfrom the automatically created thesaurus, to take the local context into account." ></td>
	<td class="line x" title="9:189	This unsupervised method is quantitatively evaluated on SemCor." ></td>
	<td class="line x" title="10:189	We found a slight improvement in precision over using the predicted first sense." ></td>
	<td class="line x" title="11:189	Finally, we discuss strengths and weaknesses of the method and suggest ways to improve the results in the future." ></td>
	<td class="line x" title="12:189	129 130 Koeling and McCarthy 1 Introduction In recent years, a lot of research was done on establishing the predominant sense of ambiguous words automatically using untagged texts (McCarthy et al., 2004, 2007)." ></td>
	<td class="line x" title="13:189	The motivation for that work is twofold: on the one hand it builds on the strength of the first sense heuristic in Word Sense Disambiguation (WSD) (i.e. the heuristic of choosingthemostcommonlyusedsenseofaword,irrespectiveofthecontextinwhich the word occurs) and on the other hand it recognizes that manually created resources for establishing word sense distributions are expensive to create and therefore hard to find." ></td>
	<td class="line x" title="14:189	The one resource that is used most widely, SemCor (Miller et al., 1993), is only available for English and only representative for general (non domain specific) text." ></td>
	<td class="line x" title="15:189	McCarthy et als method was successfully applied to a corpusof modern English text (the BNC (Leech, 1992)) and the predicted predominant senses compared well with the gold standard given by SemCor." ></td>
	<td class="line x" title="16:189	Other experiments showed that the method can successfully be adapted to domain specific text (Koeling et al., 2005) and other languages (for example, Japanese (Iida et al., 2008))." ></td>
	<td class="line x" title="17:189	Even though the first sense heuristic is powerful, it would be preferable to only use it for WSD, when either the sense distribution is so skewed that the most commonly used sense is by far the most dominant, or as a back-off when few other clues are available to decide otherwise." ></td>
	<td class="line x" title="18:189	The use of local context is ultimately necessary to find evidence for the intended sense of an ambiguous word." ></td>
	<td class="line x" title="19:189	In this paper we investigate how we can exploit results from intermediate steps taken when calculating the predominantsenses to this end." ></td>
	<td class="line x" title="20:189	The work on automatically finding predominant senses1 was partly inspired by the observationthatyoucanidentifywordsensesbylookingatthe nearestneighboursofa target word in a distributional thesaurus." ></td>
	<td class="line x" title="21:189	For example, consider the following (simplified) entryfor the word plant in such a thesaurus(omittingthe scores fordistributional similarity): (9) plant : factory, industry, facility, business, company, species, tree, crop, engine, flower, farm, leaf, market, garden, field, seed, shrub Just by looking at the neighbours you can identify two main groups of neighbours, each pointing at separate senses of the word." ></td>
	<td class="line x" title="22:189	First there is the set of words consisting of factory, industry, facility, business, company, engine that hint at the industrial plant sense of the word and then there is the set consisting of tree, crop, flower, leaf, species, garden, field, seed, shrub that are more closely related to the flora sense of the word." ></td>
	<td class="line x" title="23:189	A few words, like farm and possibly market could be associated equally strongly with either sense." ></td>
	<td class="line x" title="24:189	The idea behind sense ranking is, that the right mix of 1." ></td>
	<td class="line x" title="25:189	numberof neighbourswith a strongassociationswith oneor more of the senses, 2." ></td>
	<td class="line x" title="26:189	the strength of the association (semantic similarity) between neighbour and sense and 1McCarthy et al.(2004) concentrates on evaluating the predominant sense, but the method does in fact rank all the senses in order of frequency of use." ></td>
	<td class="line x" title="28:189	From Predicting Predominant Senses to Local Context for WSD 131 3." ></td>
	<td class="line x" title="29:189	the strengthof the distributionalsimilarity of the contributingneighbourandthe target word, will allow us to estimate the relative importance (i.e. frequency of use) of each sense." ></td>
	<td class="line x" title="30:189	What we want to explore here, is how we can use the local context of an occurrence of the target word, to select a subset of these neighbours." ></td>
	<td class="line x" title="31:189	This subset should consist of words that are related more strongly to the sense of the word in the target sentence." ></td>
	<td class="line x" title="32:189	For example, consider the word plant in a sentence like: (10) The gardener grows plants from vegetable seeds." ></td>
	<td class="line x" title="33:189	Plant is used in this sentence as the subject of grow." ></td>
	<td class="line x" title="34:189	A simple way of zooming in on potentially relevant neighboursis by using the most informative contexts shared between neighbours and the word in the target sentence." ></td>
	<td class="line x" title="35:189	This is implemented by selecting just those words that occur in the same grammatical context (i.e. as subject of the verb grow) in a reference corpus2." ></td>
	<td class="line x" title="36:189	If we apply that to the example in 9, we end up with the following subset: business, industry, species, tree, crop, flower, seed, shrub." ></td>
	<td class="line x" title="37:189	Even though the first two words are still associated with the industrial plant sense, we can see that the majority of the words in this subset is strongly associated with the intended sense." ></td>
	<td class="line x" title="38:189	In the next section we first give a quick introduction to the sense ranking algorithm introducedin McCarthyetal." ></td>
	<td class="line x" title="39:189	(2004)." ></td>
	<td class="line x" title="40:189	Thenwe explainhowwe can use thedatabaseof grammatical relations that we used for creating the thesaurus, for selecting a subset of neighboursin the thesaurus." ></td>
	<td class="line x" title="41:189	The following section describes an evaluation performed on the SemCor data." ></td>
	<td class="line x" title="42:189	In the last two sections we discuss the results and especially why both recall and precision are lower than we had hoped and what can be done to improve the results." ></td>
	<td class="line x" title="43:189	2 Predominant Senses and Local Context For a full review of McCarthy et als ranking method, we refer to McCarthy et al.(2004) or McCarthy et al.(2007)." ></td>
	<td class="line x" title="46:189	Here we give a short description of the method." ></td>
	<td class="line x" title="47:189	Since we need the grammatical relations used for building the thesaurus, for selecting a subset of the neighbours, we explain the procedure for building the thesaurus in 2.2." ></td>
	<td class="line x" title="48:189	In the last part of this section we explain how we exploit local context for SD." ></td>
	<td class="line x" title="49:189	2.1 Finding Predominant Senses We usethemethoddescribedinMcCarthyetal." ></td>
	<td class="line x" title="50:189	(2004)forfindingpredominantsenses from raw text." ></td>
	<td class="line x" title="51:189	It can be applied to all parts of speech, but the experiments in this paper all focus on nouns only." ></td>
	<td class="line x" title="52:189	The method uses a thesaurus obtained from the text by parsing, extracting grammatical relations and then listing each word (w) with its top k nearest neighbours, where k is a constant." ></td>
	<td class="line oc" title="53:189	Like McCarthy et al.(2004) we use k = 50 and obtain our thesaurus using the distributional similarity metric described by Lin (1998)." ></td>
	<td class="line x" title="55:189	We use WordNet (WN) as our sense inventory." ></td>
	<td class="line x" title="56:189	The senses of a word w are each assigned a ranking score which sums over the distributional similarity scores of 2We use the same corpus used for generating the thesaurus as for the reference corpus (in all our experiments)." ></td>
	<td class="line x" title="57:189	132 Koeling and McCarthy the neighbours and weights each neighbours score by a WN Similarity score (Patwardhan and Pedersen, 2003) between the sense of w and the sense of the neighbour that maximises the WN Similarity score." ></td>
	<td class="line x" title="58:189	This weight is normalised by the sum of such WN similarity scores between all senses of w and and the senses of the neighbour that maximises this score." ></td>
	<td class="line x" title="59:189	We use the WN Similarity jcn score on nouns (Jiang and Conrath, 1997) since this gave reasonable results for McCarthy et al. and it is efficient at run time given precompilation of frequency information." ></td>
	<td class="line x" title="60:189	The jcn measure needs word frequency information, which we obtained from the British National Corpus (BNC) (Leech, 1992)." ></td>
	<td class="line x" title="61:189	The distributionalthesaurus was constructed using subject, direct object adjective modifier and noun modifier relations." ></td>
	<td class="line oc" title="62:189	Thus we rank each sense wsi WSw using Prevalence Score wsi = (11)  njNw dssnj  wnss(wsi,nj) wsiWSw wnss(wsi,nj) where the WordNet similarity score (wnss) is defined as: wnss(wsi,nj)= max nsxNSnj (wnss(wsi,nsx)) 2.2 Building the Thesaurus The thesaurus was acquired using the method described by Lin (1998)." ></td>
	<td class="line x" title="63:189	For input we used grammatical relation data extracted using an automatic parser (Briscoe and Carroll, 2002)." ></td>
	<td class="line x" title="64:189	For the experiments in this paper we used the 90 million words of written English from the BNC." ></td>
	<td class="line x" title="65:189	For each noun we considered the co-occurring verbs in the direct object and subject relation, the modifying nounsin noun-nounrelations and the modifyingadjectivesin adjective-nounrelations." ></td>
	<td class="line x" title="66:189	This limited set of grammaticalrelations was chosen since accuracy of the parser is particularly high for these 4 relations." ></td>
	<td class="line x" title="67:189	We could easily extend the set of relations to more in the future." ></td>
	<td class="line x" title="68:189	A noun,w, is thus described by a set of co-occurrence triples < w,r,x > and associated frequencies, where r is a grammatical relation and x is a possible co-occurrence with w in that relation." ></td>
	<td class="line oc" title="69:189	For every pair of nouns, where each noun had a total frequency in the triple data of 10 or more, we computed their distributional similarity using the measure given by Lin (1998)." ></td>
	<td class="line x" title="70:189	If T(w) is the set of co-occurrence types (r,x) such that I(w,r,x) is positive then the similarity between two nouns, w and n, can be computed as: (12) (r,x)T(w)T(n)(I(w,r,x)+I(n,r,x)) (r,x)T(w)I(w,r,x)+(r,x)T(n)I(n,r,x) where I(w,r,x) = log P(x|wr)P(x|r) A thesaurusentryof size k fora targetnounw can thenbe definedas the k mostsimilar nouns to noun w. 2.3 Local Context The basis for building the distributional similarity thesaurus, is the set of grammatical relations that the target word shares with other words." ></td>
	<td class="line x" title="71:189	For example, if we look at the thesaurus entry for the noun bike, then we see that the closest neighbours are (the synonym) bicycle and the closely related motorbike (and motorcycle)." ></td>
	<td class="line x" title="72:189	The next 10 closest neighbours are all other vehicles (car, van, boat, bus, etc.)." ></td>
	<td class="line x" title="73:189	This is something From Predicting Predominant Senses to Local Context for WSD 133 wewouldexpecttosee, sinceallthesewordsdooccurinsimilargrammaticalcontexts." ></td>
	<td class="line x" title="74:189	We travel by bike, as well as by motorcycle, car and bus." ></td>
	<td class="line x" title="75:189	We park them, drive_off with them, hire them, abandon them and repair them." ></td>
	<td class="line x" title="76:189	Many of these relations can be applied to a wide range of vehicles (or even a wider range of objects)." ></td>
	<td class="line x" title="77:189	However, some relations are more specific to two-wheeled vehicles." ></td>
	<td class="line x" title="78:189	For example, it is quite common to mount a bike or a motorbike, whereas it is less common to mount a car or a van." ></td>
	<td class="line x" title="79:189	(Motor)bikes are chained to stop people from stealing them and it is probably more common to ride a (motor)bike as opposed to driving a car or truck." ></td>
	<td class="line x" title="80:189	Of course there are many other more general things you can do with these vehicles: buy, sell, steal them; there are yellow bikes, cars and boats, just like other objects." ></td>
	<td class="line x" title="81:189	Therefore,we can see many other types of objects lower in the list of neighbours that share these more general grammatical relations, but not those that are specific to, say, vehicles or even the sub-category of two-wheeled vehicles." ></td>
	<td class="line x" title="82:189	Consider the following sentence containing the ambiguous noun body: (13) Regular exercise keeps the body healthy. (14) The funding body approved the final report. We would like our algorithm to be able to recognize that Wordnets first sense of the word body (the entire physical structure of an organism (especially an animal or human being)) is the most appropriate for sentence 13 and the third sense (a group of persons associated by some common tie or occupation and regarded as an entity) for sentence 14." ></td>
	<td class="line x" title="83:189	If we calculate the most likely sense using all of the first 50 nearest neighbours in the thesaurus, we predict that sense 4 is the most frequently used sense (the body excluding the head and neck and limbs)." ></td>
	<td class="line x" title="84:189	However, the two uses of the target word in 13 and 14 appear each in a very specific grammaticalcontext." ></td>
	<td class="line x" title="85:189	How can we exploitthis localcontextto single outa certain subset of the 50 nearest neighbours, containing those words that are particularly relevant for (or more closely related to) the grammatical relation that the target word is involved in this particular sentence." ></td>
	<td class="line x" title="86:189	The idea we pursue here is to look at those neighbours in the thesaurus that occur in the same grammatical relation as our target word and share a high mutual information (i.e. word and grammatical relation do not only occur frequently together, but also when you see one, there is a high probability that you see the other)." ></td>
	<td class="line x" title="87:189	While creating the thesaurus we consider all the words that co-occur with a certain target word (where co-occur means that it appears in the same grammatical relation)." ></td>
	<td class="line x" title="88:189	We also calculate the mutual information of both the target word and the co-occurring word and the grammatical relation." ></td>
	<td class="line x" title="89:189	Instead of throwing this information away after finishing an entry in the thesaurus, we now store this information in the grammatical relation database." ></td>
	<td class="line x" title="90:189	Since this database grows to enormous proportions (in the order of 200GB for the one built up while processing the BNC), we need to reduce its size to be able to work with it." ></td>
	<td class="line x" title="91:189	If we only keep those entries in the database that involve the words in the thesaurus and their 50 neighbours, we can reduce the database to manageable proportions." ></td>
	<td class="line x" title="92:189	We experimented with reducing the number of entries in the database even further by limiting the number of entries per grammatical relations to the ones 134 Koeling and McCarthy with the highest mutual information scores, but this only had a negative effect on the recall, without improving the precision." ></td>
	<td class="line x" title="93:189	As we will see later, data sparseness is a serious issue and it is therefore not advisable to cut-out any usable information that we have at our disposal." ></td>
	<td class="line x" title="94:189	The word sense disambiguation procedure that uses the local context is then straightforward: 1." ></td>
	<td class="line x" title="95:189	Parse the sentence with the target word (the word to be disambiguated)." ></td>
	<td class="line x" title="96:189	2." ></td>
	<td class="line x" title="97:189	If the target word is not involved with any of the 4 grammatical relations we considered for building up the thesaurus, local context can not be used." ></td>
	<td class="line x" title="98:189	3." ></td>
	<td class="line x" title="99:189	Otherwise, consult the database to retrieve the co-occurring words:  Let GR be the set of triples < w,r,x > from equation 12 in Section 2.2 for target word w.  Let NGR be the set of triples < nj,r,x > from equation 12 for any neighbour nj  Nw  For all w  T and all top 50 n  Nw, keep entries with < ,r,x > in database." ></td>
	<td class="line x" title="100:189	 Let SGR be the set of relations < r,x > in the target sentence, where I < w,r,x > and I < n,r,x > are both positive (i.e. r,x are both in the target sentence and have high MI in BNC for both w and n.)" ></td>
	<td class="line x" title="101:189	4." ></td>
	<td class="line x" title="102:189	Compute the ranking score for each sense by applying to a modified version of the ranking equation (15) (compared to the original given in (11)), where the k nearest neighbours are replaced by the subset found in the step 3." ></td>
	<td class="line x" title="103:189	(15) Prevalence Score ws_lci =njNw MIdssnj  wnss(wsi,nj)ws iWSw wnss(wsi,nj) where the WordNet similarity score (wnss) is defined as before and let MI be I < n,r,x >, i.e. the Mutual Information given by the events of seeing the grammatical relation in question and seeing the neighbour." ></td>
	<td class="line x" title="104:189	2.4 An example The fact that a subset of the neighbours in the thesaurus share some specific relations with the target word in a particular sentence is something that we wish to exploit for Word Sense Disambiguation." ></td>
	<td class="line x" title="105:189	Let us have a closer look at the two example sentences 13 and 14 that we introduced in the previous section." ></td>
	<td class="line x" title="106:189	The grammatical relations that our target word body is involved with are (from sentences 13 and 14 respectively):3 (16) body object of keep for sentence 13 and (17) body subject of approved and body modified by the noun funding for sentence 14 3At the moment we only take 4 grammatical relations into account: Verb-Subject, Verb-Object, AdjNoun and Noun-Noun modifier." ></td>
	<td class="line x" title="107:189	From Predicting Predominant Senses to Local Context for WSD 135 Table 1: Results of evaluation on the nouns in SemCor Method Attempted Correct Wrong Precision Recall Local Context 23,235 11,904 11,331 0.512 0.161 First sense 23,235 11,795 11,440 0.508  Sincekeepis afairlygeneralverb,itisnotsurprisingthatquitea fewofthe neighbours occur as object of keep." ></td>
	<td class="line x" title="108:189	As a matter of fact, 28 of the first 50 neighbours share this relation." ></td>
	<td class="line x" title="109:189	However, the good news is, that pretty much all the words associated with body-parts (such as arm, hand, leg, face and head) are among them." ></td>
	<td class="line x" title="110:189	The two grammatical relations that body is involved with in sentence 14, are more specific." ></td>
	<td class="line x" title="111:189	There are just 6 neighbours that share the subject of approve relation with body and another5 that are used to modify the noun body." ></td>
	<td class="line x" title="112:189	Among these words are the highly relevant words organisation, institution and board." ></td>
	<td class="line x" title="113:189	3 Evaluation on SemCor The example in the last section shows that in certain cases the method performs the way we envisaged." ></td>
	<td class="line x" title="114:189	However, we need a quantitative evaluation to get a proper picture of the methodsusefulness." ></td>
	<td class="line x" title="115:189	We performeda full evaluationon SemCor." ></td>
	<td class="line x" title="116:189	In this experiment we limited our attention to nouns only." ></td>
	<td class="line x" title="117:189	We furthereliminated Proper Names and multi-word units from the test set." ></td>
	<td class="line x" title="118:189	Since the nouns in both these categories are mostly monosemous, they are less interesting as test material and apart from that, they introduce problems(mostly parser related) that have little to do with the proposed method." ></td>
	<td class="line x" title="119:189	A total of 73,918words were left to evaluate." ></td>
	<td class="line x" title="120:189	Table 1 summarizes the results." ></td>
	<td class="line x" title="121:189	The figure for recallforthe First Sense methodis notgiven,because we wantto contrastthe local context method with the first sense method." ></td>
	<td class="line x" title="122:189	Whilst the first sense method will return an answer in most cases, the local context method proposed in this paper will not." ></td>
	<td class="line x" title="123:189	Here we want to focus on how we can improve on using the first sense heuristic by taking local contextinto account, rather than give complete results for a WSD task." ></td>
	<td class="line x" title="124:189	There are several things to say about these results." ></td>
	<td class="line x" title="125:189	First of all, even though the results for local context are slightly better than for first sense, we expected more from it." ></td>
	<td class="line x" title="126:189	We had identified quite a few cases like 13 and 14 above, where the local context seemed to be able to help to identify the right neigbours in order to make the difference." ></td>
	<td class="line x" title="127:189	Below, we will discuss a few cases where the grammatical relations involved are so general, that the subset of neighbours is large and most importantly, notdiscriminativeenough." ></td>
	<td class="line x" title="128:189	It seems to be reasonableto expectthatthe latter cases will notinfluencetheprecisiontoo much(i.e. a smallergroupofneighbourswilloftengive a different result, but some better, some worse)." ></td>
	<td class="line x" title="129:189	The recall is also lower than expected." ></td>
	<td class="line x" title="130:189	The first thought was that data sparseness was the main problemhere, but additionalexperimentsshowed us that thatis unlike to be the case." ></td>
	<td class="line x" title="131:189	In one experiment we took a part of the GigaWord corpus (Graff, 2003), similar in size to the written part of the BNC (used in our original experiment) and built our grammatical relation database using the combined corpus." ></td>
	<td class="line x" title="132:189	The recall went up a little, but at the price of a slightly lower precision." ></td>
	<td class="line x" title="133:189	136 Koeling and McCarthy 4 Discussion Themainproblemcausingthelowrecallseemsto bethesmallnumberofgrammatical relations that we use for building the thesaurus." ></td>
	<td class="line x" title="134:189	The four relations used (verb-subject, verb-object, noun-noun-modifier and adjective-noun-modifier) were chosen because of the parsers high accuracy for these." ></td>
	<td class="line x" title="135:189	For building the thesaurus, these grammatical relations suffice, since every word will occur in one of these relations sooner or later." ></td>
	<td class="line x" title="136:189	However, whenever in a sentence the target word occurs outside these four relations, we are notable to look it up in our database." ></td>
	<td class="line x" title="137:189	Nounswithin prepositionalphrases seem to be a major victim here." ></td>
	<td class="line x" title="138:189	It should be straightforward to experiment with including prepositional phrase related grammatical relations." ></td>
	<td class="line x" title="139:189	We will have to evaluate the influence of the introduced noise on creating the thesaurus." ></td>
	<td class="line x" title="140:189	Alternatively, it is possible to use the four relations as before for creating the thesaurus and store the extra relations in our database just for look-up." ></td>
	<td class="line x" title="141:189	A second cause for missing target words is parser errors." ></td>
	<td class="line x" title="142:189	Even though RASP will produce partial parses whenever a full parse of a sentence is not available, some loss is inevitable." ></td>
	<td class="line x" title="143:189	This is a harder problem to solve." ></td>
	<td class="line x" title="144:189	One way of solving this problem might be by using a proximity thesaurus instead of a thesaurus build using grammatical relatons." ></td>
	<td class="line x" title="145:189	McCarthy et al.(2007) reported promising results for using proximity based thesaurus for predicting predominant senses, with accuracy figures closely behind those achieved with a dependency based thesaurus." ></td>
	<td class="line x" title="147:189	One plausible reason why the method is not working in many cases, is the fact that the word to be disambiguated in the target sentence often occurs in a very general grammatical relation." ></td>
	<td class="line x" title="148:189	For example, subject of or direct object of a verb like have." ></td>
	<td class="line x" title="149:189	In these cases, most of the neighbors in the thesaurus will be selected." ></td>
	<td class="line x" title="150:189	Even though it is clear that that would minimize the positive effect, it is not immediately obviousthat this would have a negative effect." ></td>
	<td class="line x" title="151:189	It might therefore be the case that the number of cases where the grammatical relation is a good selection criterion, is just lower than we thought (although this is not the impression that you get when you look at the data)." ></td>
	<td class="line x" title="152:189	We will need to establish a way of quantitatively evaluating this." ></td>
	<td class="line x" title="153:189	The Mutual Information score gives us a measure of the dependence between the grammatical relation and the word (neighbour of the target word) we are interested it." ></td>
	<td class="line x" title="154:189	It gives us a handle on generality of the combination of seeing both events." ></td>
	<td class="line x" title="155:189	This means that for a very common grammatical relation, many words will be expected to co-occurwith a frequencycomparableto their generalfrequencyin texts." ></td>
	<td class="line x" title="156:189	The contrast with relation/word combinations for which this is not the case might be usable for identifying the cases that we want to exclude here." ></td>
	<td class="line x" title="157:189	5 Conclusions In this paper we propose a completely unsupervised method for Word Sense Disambiguation that takes the local context of the target word into account." ></td>
	<td class="line x" title="158:189	The starting point for this method is a method for automatically predicting the predominantsenses of words." ></td>
	<td class="line x" title="159:189	The grammatical relations that were used to create the distributional similarity thesaurus is exploited to select a subset of the k neighbours in the thesaurus, to focus on those neighbours that are used in the same grammatical context as the word we want to disambiguate in the target sentence." ></td>
	<td class="line x" title="160:189	From Predicting Predominant Senses to Local Context for WSD 137 Even though the precision of our proposed method is slightly higher than for the predominant sense method, we are disappointed by the current results." ></td>
	<td class="line x" title="161:189	We do believe thatthereismoremileagetobehadfromthemethodwesuggest." ></td>
	<td class="line x" title="162:189	Improvementofboth recall and precision is on the agenda for future research." ></td>
	<td class="line x" title="163:189	As we stated in the previous section, we believe that the lower than expected recall can be addressed fairly easily, by considering more grammatical relations." ></td>
	<td class="line x" title="164:189	This is straightforward to implement and results can be expected in the near future." ></td>
	<td class="line x" title="165:189	A second approach, involving a thesaurus built on proximity, rather than grammatical relations will also be investigated." ></td>
	<td class="line x" title="166:189	Considering the expected lower precision for this approach, we plan to use the proximity-based thesaurus as a back off solution in case we fail to produce an answer with the dependency-based thesaurus." ></td>
	<td class="line x" title="167:189	When the proximity-based thesaurus is in place, we plan to perform a full evaluation of the dependency versus the proximity approach." ></td>
	<td class="line x" title="168:189	Before we can deal with improving the local context methods precision, we need to have a better idea of the circumstances in which the method gets it wrong." ></td>
	<td class="line x" title="169:189	We have identified a large group of examples, where it is unlikely that the method will be successful." ></td>
	<td class="line x" title="170:189	A first step will be to develop a method to identify these cases automatically and eliminate those from the targets that we are attempting to try." ></td>
	<td class="line x" title="171:189	In the previous section, we sketched how we think that we can achieve this by applying a Pointwise Mutual Information threshold." ></td>
	<td class="line x" title="172:189	If we are successful, this will at least give us the opportunity to focus on the strengths and weaknesses of the method." ></td>
	<td class="line x" title="173:189	At the moment, the virtues of the method seem to be obscured too much by dealing with cases that should not be considered." ></td>
	<td class="line x" title="174:189	More insight in the method can also be gained from trying to identify in which situations the method is more likely to get it right." ></td>
	<td class="line x" title="175:189	At the moment we havent broken down the results yet in terms of the target words polysemy and/or frequency of use." ></td>
	<td class="line x" title="176:189	Some grammatical relations might be more useful for identifying the intended sense than other." ></td>
	<td class="line x" title="177:189	A detailed analysis could give us these insights." ></td>
	<td class="line x" title="178:189	We do believe there is a strong case to be made for using unsupervised methods for Word Sense Disambiguation (apart from McCarthy et al.(2004)s predominant sense method, other approaches include e.g. Basili et al.(2006))." ></td>
	<td class="line x" title="181:189	The predominant sense method has proven to be successful." ></td>
	<td class="line x" title="182:189	However, applying the first sense heuristic should be limited to certain cases." ></td>
	<td class="line x" title="183:189	We can think of the cases where the dominance of the predominant sense is so strong, that there is little to gain from doing a proper attempt to disambiguation or to the cases where everything else fails." ></td>
	<td class="line x" title="184:189	Ultimately, our goal is to find a balance between the dominance of the predominantsense and the strength of the evidence from the supporting context." ></td>
	<td class="line x" title="185:189	If we are able to recognize the correct clues from the local context and use these clues to focus on those words with a high distributional similarity to the target word in the context in which the word is actually used, we can build on work on predicting predominantsenses, to rely less on the first sense heuristic." ></td>
	<td class="line x" title="186:189	This would be a good step forward for unsupervised WSD." ></td>
	<td class="line x" title="187:189	Acknowledgments ThisworkwasfundedbyUKEPSRCprojectEP/C537262Ranking Word Senses for Disambiguation: Models and Applications, and by a UK Royal Society Dorothy Hodgkin Fellowship to the second author." ></td>
	<td class="line x" title="188:189	We would like to thank Siddharth Patwardhan and Ted Pedersen for making the WN Similarity package available and Julie Weeds for the thesaurus software." ></td>
	<td class="line x" title="189:189	138 Koeling and McCarthy" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="D09-1028
Geo-mining: Discovery of Road and Transport Networks Using Directional Patterns
Davidov, Dmitry;Rappoport, Ari;"></td>
	<td class="line x" title="1:250	Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 267275, Singapore, 6-7 August 2009." ></td>
	<td class="line x" title="2:250	c 2009 ACL and AFNLP Geo-mining: Discovery of Road and Transport Networks Using Directional Patterns Dmitry Davidov ICNC The Hebrew University of Jerusalem dmitry@alice.nc.huji.ac.il Ari Rappoport Institute of Computer Science The Hebrew University of Jerusalem arir@cs.huji.ac.il Abstract One of the most desired information types when planning a trip to some place is the knowledge of transport, roads and geographical connectedness of prominent sites in this place." ></td>
	<td class="line x" title="3:250	While some transport companies or repositories make some of this information accessible, it is not easy to find, and the majority of information about uncommon places can only be found in web free text such as blogs and forums." ></td>
	<td class="line x" title="4:250	In this paper we present an algorithmic framework which allows an automated acquisition of map-like information from the web, based on surface patterns like from X to Y." ></td>
	<td class="line x" title="5:250	Given a set of locations as initial seeds, we retrieve from the web an extended set of locations and produce a map-like network which connects these locations using transport type edges." ></td>
	<td class="line x" title="6:250	We evaluate our framework in several settings, producing meaningful and precise connection sets." ></td>
	<td class="line x" title="7:250	1 Introduction Textual geographical information such as location descriptions, directions, travel guides and transport tables is extensively used by people." ></td>
	<td class="line x" title="8:250	Discovering such information automatically can assist NLP applications such as question answering (Santos and Cardoso, 2008), and can be useful for a variety of other applications, including automatic map annotation." ></td>
	<td class="line x" title="9:250	Some textual geographical information can be found in web sites of transport companies, tourist sites and repositories such as Wikipedia." ></td>
	<td class="line x" title="10:250	Such sites usually utilize structured information such as machine-readable meta-data, tables, schedule forms or lists, which are relatively convenient for processing." ></td>
	<td class="line x" title="11:250	However, automatic utilization of such information is limited." ></td>
	<td class="line x" title="12:250	Even on these sites, only a small fraction of the available geographical information is stored in a well-structured and freely accessible form." ></td>
	<td class="line x" title="13:250	With the growth of the web, information can be frequently found in ordinary web pages such as forums, travelogues or news." ></td>
	<td class="line x" title="14:250	In such sites, information is usually noisy, unstructured and present in the form of free text." ></td>
	<td class="line x" title="15:250	This type of information can be addressed by lexical patterns." ></td>
	<td class="line x" title="16:250	Patterns were shown to be very useful in all sorts of lexical acquisition tasks, giving high precision results at relatively low computational costs (Pantel et al., 2004)." ></td>
	<td class="line x" title="17:250	Patterndriven search engine queries allow to access such information and gather the required data very efficiently (Davidov et al., 2007)." ></td>
	<td class="line x" title="18:250	In this paper we present a framework that given a few seed locations as a specification of a region, discovers additional locations (including alternate location names) and map-like travel paths through this region labeled by transport type labels." ></td>
	<td class="line x" title="19:250	The type of output produced by our framework here differs from that in previous pattern-based studies." ></td>
	<td class="line x" title="20:250	Unlike mainstream pattern-based web mining, it does not target some specific two-slot relationship and attempts to extract word tuples for this relationship." ></td>
	<td class="line x" title="21:250	Instead, it discovers geographical networks of transport or access connections." ></td>
	<td class="line x" title="22:250	Such networks are not unstructured sets of word pairs, but a structured graph with labeled edges." ></td>
	<td class="line x" title="23:250	Our algorithm utilizes variations of the basic pre-defined pattern [Transport] from Location1 to Location2 which allows location names and connections to be captured starting from the given seed location set." ></td>
	<td class="line x" title="24:250	We acquire search engine snippets and extract contexts where location names coappear." ></td>
	<td class="line x" title="25:250	Next we construct a location graph and merge transport edges to identify main transport group types." ></td>
	<td class="line x" title="26:250	Finally, we improve the obtained data by reducing transitive connections and identifying key locations." ></td>
	<td class="line x" title="27:250	267 The obtained location data can be used as a draft for preparation of travel resources and ondemand travel plans." ></td>
	<td class="line x" title="28:250	It can also be used for question answering systems and for automated enrichment and verification of existing geographical resources." ></td>
	<td class="line x" title="29:250	We evaluate our framework on three different regions of different scale and type: Annapurna in Nepal, the south Israel area and the Cardiff area in England." ></td>
	<td class="line x" title="30:250	In our evaluation we estimated precision and the amount of discovered locations and transport edges, and examined the quality of the obtained map as a whole by visually comparing the overall connectedness of the graph to an actual road or transport map." ></td>
	<td class="line x" title="31:250	2 Related Work In this paper we utilize a pattern-based lexical acquisition framework for the discovery of geographical information." ></td>
	<td class="line x" title="32:250	Due to the importance of lexical databases for many NLP tasks, substantial research has been done on direct or indirect automated acquisition of concepts (sets of terms sharing a significant aspect of their meaning) and concept relationships in the form of graphs connecting concepts or terms inside concepts into usually hierarchical or bipartite networks." ></td>
	<td class="line x" title="33:250	In the case of geo-mining, concepts can include sets of alternative names for some place, or sets of all locations of the same type (e.g., all countries)." ></td>
	<td class="line x" title="34:250	Geographical relationships can include nearness of two locations and entity-location relationships such as instituteaddress, capital-country, tourist site-city etc. The major differences between relationship acquisition frameworks come from the types and annotation requirements of the supplied input and the basic algorithmic approach used to process this input." ></td>
	<td class="line x" title="35:250	A first major algorithmic approach is to represent word contexts as vectors in some space and use distributional measures and automatic clustering in that space." ></td>
	<td class="line oc" title="36:250	Curran (2002) and Lin (1998) use syntactic features in the vector definition." ></td>
	<td class="line x" title="37:250	Caraballo (1999) uses conjunction and appositive annotations in the vector representation.While efforts have been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they remain data and computation intensive." ></td>
	<td class="line x" title="38:250	The second major algorithmic approach is to use lexico-syntactic patterns, which have been shown to produce more accurate results than feature vectors at a lower computational cost on large corpora (Pantel et al., 2004)." ></td>
	<td class="line x" title="39:250	Most related work deals with discovery of hypernymy (Hearst, 1992; Pantel and Lin, 2002) and synonymy (Widdows and Dorow, 2002; Davidov and Rappoport, 2006)." ></td>
	<td class="line x" title="40:250	Some studies deal with the discovery of more specific relation sub-types, including inter-verb relations (Chklovski and Pantel, 2004) and semantic relations between nominals (Davidov and Rappoport, 2008)." ></td>
	<td class="line x" title="41:250	Extensive frameworks were proposed for iterative discovery of pre-specified (e.g., (Riloff and Jones, 1999)) and unspecified (e.g., (Agichtein and Gravano, 2000)) relation types." ></td>
	<td class="line x" title="42:250	Some concepts and relationships examined by seed-based discovery methods were of a geographical nature." ></td>
	<td class="line x" title="43:250	For example, (Etzioni et al., 2004) discovered a set of countries and (Davidov et al., 2007) discovered diverse country relationships, including location relationships between a country and its capital and a country and its rivers." ></td>
	<td class="line x" title="44:250	As noted in Section 1, the type of output that we produce here is not an unstructured collection of word pairs but a labeled network." ></td>
	<td class="line x" title="45:250	As such, our task here is much more complex." ></td>
	<td class="line x" title="46:250	Our study is related to geographical information retrieval (GIR) systems." ></td>
	<td class="line x" title="47:250	However, our problem is very far from classic GIR problem settings." ></td>
	<td class="line x" title="48:250	In GIR, the goal is to classify or retrieve possibly multilingual documents in response to queries in the form theme, spatial relationship, location, e.g., mountains near New York (Purves et al., 2006)." ></td>
	<td class="line x" title="49:250	Our goal, in contrast, is not document retrieval, but the generation of a structured information resource, a labeled location graph." ></td>
	<td class="line x" title="50:250	Spatial relationships used in natural language tend to be qualitative and descriptive rather than quantitative." ></td>
	<td class="line x" title="51:250	The concept of Naive Geography, which reflects the way people think and write about geographical space, is described in (Egenhofer and Shariff, 1995)." ></td>
	<td class="line x" title="52:250	Later in (Egenhofer and Shariff, 1998) they proposed a way to convert coordinate-based relationships between spatial entities to natural language using terms as crosses, goes through or runs into." ></td>
	<td class="line x" title="53:250	Such terms can be potentially used in patterns to extract geographical information from text." ></td>
	<td class="line x" title="54:250	In this paper we start from a different pattern, from  to, which helps in discovering transport or connectedness relationships between places, e.g., bus from X to Y and road from X to Y." ></td>
	<td class="line x" title="55:250	The majority of geographical data mining 268 frameworks utilize structured data such as available gazetteers and Wikipedia metadata." ></td>
	<td class="line x" title="56:250	Several other studies utilize semi-structured data like Wikipedia links (Overell and Ruger, 2007) or substructures in web pages, including addresses and phone numbers (Borges et al., 2007)." ></td>
	<td class="line x" title="57:250	The recent Schockaert et al.( 2008) framework for extraction of topological relationships from the web has some similarities to our study." ></td>
	<td class="line x" title="58:250	In both cases the algorithm produces map-like structures using the web." ></td>
	<td class="line x" title="59:250	However, there are significant differences." ></td>
	<td class="line x" title="60:250	They utilize relatively structured address data on web pages and rely on the order of named entities in address data for extracting containment relationships." ></td>
	<td class="line x" title="61:250	They also use co-appearances in addresses (e.g., R1 / R2 and R1 & R2 as in Newport & Gabalfa, Cardiff) to deduce location boundaries." ></td>
	<td class="line x" title="62:250	This allows them to get high precision data for modern and heavily populated regions like Cardiff, where the majority of offices have available well-formatted web pages." ></td>
	<td class="line x" title="63:250	However, in less populated regions (a major target for tourist information requests), this strategy could be problematic since a major information source about these places would be not local web sites (in which local addresses are likely to be found) but foreign visitor sites, web forums and news." ></td>
	<td class="line x" title="64:250	We rely on free text available in all types of web pages, which allows us to capture unstructured information which contains a significant portion of the web-available geographical knowledge." ></td>
	<td class="line x" title="65:250	Our goals are also different from Schockaert et al.( 2008), since we focus on obtaining information based on paths and transport between locations, while in their work the goal is to find a network representing nearness of places rather than their connectivity by means of transport or walking." ></td>
	<td class="line x" title="66:250	Nevertheless, in one of our evaluation settings we targeted the area of Cardiff as in (Schockaert et al., 2008)." ></td>
	<td class="line x" title="67:250	This allowed us to make an indirect comparison of a relevant part of our results to previous work, achieving state-of-the-art performance." ></td>
	<td class="line x" title="68:250	3 The Algorithm As input to our algorithm we are given a seed of a few location names specifiying some geographical region." ></td>
	<td class="line x" title="69:250	In this section we describe the algorithm which, given these names, extracts the labeled structure of connections between entities in the desired region." ></td>
	<td class="line x" title="70:250	We first use a predefined pattern for recursive extraction of the first set of entities." ></td>
	<td class="line x" title="71:250	Then we discover additional patterns from co-appearing location pairs and use them to get more terms." ></td>
	<td class="line x" title="72:250	Next, we label and merge the obtained location pairs." ></td>
	<td class="line x" title="73:250	Finally, we construct and refine the obtained graph." ></td>
	<td class="line x" title="74:250	3.1 Pattern-based discovery with web queries In order to obtain the first set of location connections, we use derivatives of the basic pattern from X to Y." ></td>
	<td class="line x" title="75:250	Using Yahoo!" ></td>
	<td class="line x" title="76:250	BOSS, we have utilized the APIs ability to search for phrases with wildcards." ></td>
	<td class="line x" title="77:250	Given a location name L we start the search with patterns from * to L, from * * to L." ></td>
	<td class="line x" title="78:250	These are Yahoo!" ></td>
	<td class="line x" title="79:250	BOSS queries where enclosing words in  means searching for an exact phrase and * means a wildcard for exactly one arbitrary word." ></td>
	<td class="line x" title="80:250	This pattern serves a few goals beyond the discovery of connectedness." ></td>
	<td class="line x" title="81:250	Thus putting *s inside the pattern rather than using from L to allowed us to avoid arbitrary truncation of multiword expressions as in from Moscow to St. Petersburg and reduced the probability of capturing unrelated sentence parts like from Moscow to cover deficit." ></td>
	<td class="line x" title="82:250	Location names are usually ambiguous and this type of web queries can lead to a significant amount of noise or location mix." ></td>
	<td class="line x" title="83:250	There are two types of ambiguity." ></td>
	<td class="line x" title="84:250	First, as in from Billericay to Stock, stock can be a location or a verb." ></td>
	<td class="line x" title="85:250	We filter most such cases by allowing only capitalized location names." ></td>
	<td class="line x" title="86:250	Besides, such an ambiguity is rarely captured by from * to L patterns." ></td>
	<td class="line x" title="87:250	The second type is location ambiguity." ></td>
	<td class="line x" title="88:250	Thus Moscow refers to at least 5 location names including farms in Africa and Australia and a locality in Ireland." ></td>
	<td class="line x" title="89:250	In order to reduce mixing of locations we use the following simple disambiguation technique." ></td>
	<td class="line x" title="90:250	Before performing fromto queries, we downloaded up to 100 web pages pointed by each possible pair from the given seed locations, generating from a location pair L1,L2 a conjunctive query L1 * L2." ></td>
	<td class="line x" title="91:250	Then we extracted the most informative terms using a simple probabilistic metric: Rank(w) = P(w|QueryCorpus)P(w|GeneralCorpus), comparing word distribution in the downloaded QueryCorpus to a large general purpose offline GeneralCorpus1." ></td>
	<td class="line x" title="92:250	We thus obtained a set of 1We used the DMOZ corpus (Gabrilovich and Markovitch, 2005)." ></td>
	<td class="line x" title="93:250	269 query-specific disambiguating words." ></td>
	<td class="line x" title="94:250	Then we added to all queries the same most frequent word (DW) out of the ten words with highest ranks." ></td>
	<td class="line x" title="95:250	Thus for the seed set {Moscow, St. Petersburg}, an example of a query is <from * to Moscow Russia>." ></td>
	<td class="line x" title="96:250	3.2 Iterative location retrieval We retrieved all search engine snippets for each of these initial queries2." ></td>
	<td class="line x" title="97:250	If we succeeded to get more than 50 snippets, we did not download the complete documents." ></td>
	<td class="line x" title="98:250	In case where only a handful of snippets were obtained, the algorithm downloaded up to 25 documents pointed by these snippets in an attempt to get more pattern instances." ></td>
	<td class="line x" title="99:250	In the majority of tested cases, snippets provide enough information for our task, and this information was not significantly extended by downloading the whole documents." ></td>
	<td class="line x" title="100:250	Once we retrieve snippets we identify terms appearing in the snippets in wildcard slots." ></td>
	<td class="line x" title="101:250	For example, if the query is <from * to Moscow Russia> and we encounter a snippet from Vladivostok to Moscow, we add Vladivostok to our set of seeds." ></td>
	<td class="line x" title="102:250	We then continue the search in a breadth first search setting, stopping the search on three conditions: (1) runaway detected  the total frequency of newly obtained terms through some terms patterns is greater than the total frequency of previously discovered terms+seeds." ></td>
	<td class="line x" title="103:250	In this case we stop exploration through the problematic term and continue exploration through other terms3; (2) we reached a predefined maximal depth D4; (3) no new terms discovered." ></td>
	<td class="line x" title="104:250	At the end of this stage we get the extended set of terms using the set of snippets where these terms co-appear in patterns." ></td>
	<td class="line x" title="105:250	3.3 Enhancement of initial pattern set In order to get more data, we enhance the pattern set both by discovery of new useful secondary patterns and by narrowing existing patterns." ></td>
	<td class="line x" title="106:250	After obtaining the new pattern set we repeat the extraction stage described in Section 3.2." ></td>
	<td class="line x" title="107:250	2Yahoo!" ></td>
	<td class="line x" title="108:250	Boss allows downloading up to a 1000 descriptions, up to 50 in each request." ></td>
	<td class="line x" title="109:250	Thus for each seed word, we have performed a few dozen search requests." ></td>
	<td class="line x" title="110:250	3Note that the problematic term may be the central term in the region we focus upon  if this happen it means that the seeds do not specify the region well." ></td>
	<td class="line x" title="111:250	4Depth is a function of the richness of transport links in the domain." ></td>
	<td class="line x" title="112:250	For connected domains (Cardiff, Israel) we used 4, for less connected ones (Nepal) we used 10." ></td>
	<td class="line x" title="113:250	Adding secondary patterns." ></td>
	<td class="line x" title="114:250	As in a number of previous studies, we improve our results discovering additional patterns from the obtained term set." ></td>
	<td class="line x" title="115:250	The algorithm selects a subset of up to 50 discovered (t1,t2) term pairs appearing in from t1 to t2 patterns and performs the set of additional queries of the form <t1 * t2 DW>." ></td>
	<td class="line x" title="116:250	We then extract from the obtained snippets the patterns of the form Prefix t1 Infix t2 Postfix, where Prefix and Postfix should contain either a punctuation symbol or 1-3 words." ></td>
	<td class="line x" title="117:250	Prefix/Postfix should also be bounded from left/right by a punctuation or one of the 50 most frequent words in the language (based on word counts in the offline general corpus)." ></td>
	<td class="line x" title="118:250	Infix should contain 1-3 words with the possible addition of punctuation symbols5." ></td>
	<td class="line x" title="119:250	We examine patterns and select useful ones according to the following ranking scheme, based on how well each pattern captures named entities." ></td>
	<td class="line x" title="120:250	For each discovered pattern we scan the obtained snippets and offline general corpus for instances where this pattern connects one of the original or discovered location terms to some other term." ></td>
	<td class="line x" title="121:250	Let T be the set of all one to three word terms in the language, Td  T the set of discovered terms, Tc  T the set of all capitalized terms and Pat(t1,t2) indicates one or more co-appearances of t1 and t2 in pattern Pat in the retrieved snippets or offline general corpus." ></td>
	<td class="line x" title="122:250	The rank R of pattern Pat is defined by: R(Pat) = |{Pat|Pat(t1,t2),t1  Tc,t2  Td}||{Pat|Pat(t 1,t2),t1  T,t2  Td}| In other words, we rank patterns according to the percentage of capitalized words connected by this pattern." ></td>
	<td class="line x" title="123:250	We sort patterns by rank and select the top 20% patterns." ></td>
	<td class="line x" title="124:250	Once we have discovered a new pattern set, we repeat the term extraction in Section 3.2." ></td>
	<td class="line x" title="125:250	We do this only once and not reiterate this loop in order to avoid potential runaway problems." ></td>
	<td class="line x" title="126:250	Obtained secondary patterns include different from/to templates to X from Y by bus; time/distance combinations X -N km busY, X (bus, N min) Y or patterns in different languages with English location/transport names." ></td>
	<td class="line x" title="127:250	Narrowing existing patterns." ></td>
	<td class="line x" title="128:250	When available data volume is high, we would like to take advantage of more data by utilizing more specific pattern 5Search engines do not support punctuation in queries, hence these symbols were omitted in web requests and considered only when processing the retrieved snippets." ></td>
	<td class="line x" title="129:250	270 sets." ></td>
	<td class="line x" title="130:250	Since Yahoo!" ></td>
	<td class="line x" title="131:250	allows to obtain only the first 1K snippets, in case we get more than 10K hits, we extend our queries by adding the most common term sequences appearing before or after the pattern." ></td>
	<td class="line x" title="132:250	Thus if for the query from * to Moscow we got more than 10K hits and among the snippets we see  bus from X to Moscow we create an extended pattern bus from * to Moscow and use the term extraction in Section 3.2 to get additional terms." ></td>
	<td class="line x" title="133:250	Unlike the extraction of secondary patterns, this narrowing process can be repeated recursively as long as a query brings more than 10K results." ></td>
	<td class="line x" title="134:250	3.4 Extraction of labeled connections At the end of the discovery stage we get an extended set of patterns and a list of search engine snippets discovered using these patterns." ></td>
	<td class="line x" title="135:250	Each snippet which captures terms t1,t2 in either primary from t1 to t2 or secondary patterns represents a potential connection between entities." ></td>
	<td class="line x" title="136:250	Using an observed property of the primary pattern, we select as a label a term or set of terms appearing directly before from and delimited with some high frequency word or punctuation." ></td>
	<td class="line x" title="137:250	For example, labels for snippets based on fromto patterns and containing the road from, got a bus from, a TransSiberian train from would be road, bus and TransSiberian train." ></td>
	<td class="line x" title="138:250	Once we acquire labels for the primary patterns, we also attempt to find labels in snippets obtained for secondary patterns discovered as described in Section 3.3." ></td>
	<td class="line x" title="139:250	We first locate some already labeled pairs in secondary patterns snippets where we can see both label and the labeled term pair." ></td>
	<td class="line x" title="140:250	Then, based on the labels position in this snippet, we define a label slot position for this type of snippet." ></td>
	<td class="line x" title="141:250	Suppose that during the labeling of primary pattern snippets we assigned the label bus to the pair (Novgorod, Moscow) and during the pattern extension stage the algorithm discovered a pattern Pnew = ride to t2 from t1, with a corresponding snippet  getting bus ride to Moscow from Novgorod." ></td>
	<td class="line x" title="142:250	Then using the labeled pair our algorithm defines the label slot in such a snippet type: getting [label] ride to t2 from t1." ></td>
	<td class="line x" title="143:250	Once a label slot is defined, all other pairs captured by Pnew can be successfully labeled." ></td>
	<td class="line x" title="144:250	3.5 Merging connection labels Some labels may denote the same type of connection." ></td>
	<td class="line x" title="145:250	Also, large sets of connections can share the same set of transport types." ></td>
	<td class="line x" title="146:250	In this case it is desired to assign a single label for a shared set of transports." ></td>
	<td class="line x" title="147:250	We do this by a simple merging technique." ></td>
	<td class="line x" title="148:250	Let C1,C2 be sets of pairs assigned to labels L1,L2." ></td>
	<td class="line x" title="149:250	We merge two labels if one of the following conditions holds: (1)|C1 C2| > 0.75min(|C1|,|C2|) (2)|C1 C2| > 0.45max(|C1|,|C2|) Thus, either one group is nearly included in the other or each group shares nearly half with the other group." ></td>
	<td class="line x" title="150:250	We apply this rule only once and do not iterate recursively." ></td>
	<td class="line x" title="151:250	At this stage we also dismiss weakly populated labels, keeping the 10 most populated labels." ></td>
	<td class="line x" title="152:250	3.6 Processing of connection graph Now once we have merged and assigned the labels we create a pattern graph for each label and attempt to clean the graph of noise and unnecessary edges." ></td>
	<td class="line x" title="153:250	Our graph definition follows (Widdows and Dorow, 2002)." ></td>
	<td class="line x" title="154:250	In our pattern graph for label L, nodes represent terms and directed edges represent co-appearance of two terms in some pattern in snippet labeled by L. We do not add unlabeled snippets to the graph." ></td>
	<td class="line x" title="155:250	Now we use a set of techniques to reduce noise and unnecessary edges." ></td>
	<td class="line x" title="156:250	3.6.1 Transitivity elimination One of the main problems with the pattern-based graph is transitivity of connections." ></td>
	<td class="line x" title="157:250	Thus if location A is connected to B and B to C, we frequently acquire a shortcut edge connecting A to C. Such an edge diminishes our ability to create a clear and meaningful spatial graph." ></td>
	<td class="line x" title="158:250	In order to reduce such edges we employ the following two strategies." ></td>
	<td class="line x" title="159:250	First, neighboring places frequently form fully connected subgraphs." ></td>
	<td class="line x" title="160:250	We would like to simplify such cliques to reduce the amount of transitive connections." ></td>
	<td class="line x" title="161:250	If three overlapping sets of nodes {A1 An2},{A2 An1},{A3 An} form three different cliques, then we remove all edges between A1 and the nodes in the third clique and between An and the nodes in the first clique." ></td>
	<td class="line x" title="162:250	Second, in paths obtained by directional patterns, it is common that if there is a path A1  A2  An where A1 and An are some major key locations6, then each of the nodes A2  An1 tend to be connected both to A1 and 6Such locations will be shown in double circles in the evaluation." ></td>
	<td class="line x" title="163:250	271 to An while intermediate nodes are usually connected only to their close neighbors." ></td>
	<td class="line x" title="164:250	We would like to eliminate such transitive edges leaving only the inter-neighbor connections." ></td>
	<td class="line x" title="165:250	We define as key nodes in a graph, nodes whose degree is more than 1.5 times the average graph degree." ></td>
	<td class="line x" title="166:250	Then we eliminate the transitive connections: if A1 is a key node and A1 is connected to each of the nodes A2 An1, and i  {2n  1},Ai is connected to Ai+1, then we remove the connection of A1 to all nodes A3 An1 , leaving A1 only connected to A2." ></td>
	<td class="line x" title="167:250	3.6.2 Clearing noise and merging names Finally we remove potential noise which accidentally connects remote graph parts." ></td>
	<td class="line x" title="168:250	If some edge discovered through a single pattern instance connects distant (distance>3) parts of the graph we remove it." ></td>
	<td class="line x" title="169:250	Additionally, we would like to merge common name alternations and misspellings of places." ></td>
	<td class="line x" title="170:250	We merge two nodes A and B into one node if either (1) A, B have exactly the same edges, and their edge count is greater than 2; or (2) edges of A are subset of Bs edges and the string edit distance between A and B is less than a third of min(StringLength(A), StringLength(B))." ></td>
	<td class="line x" title="171:250	4 Evaluation Since our problem definition differs significantly from available related work, it is not possible to make direct comparisons." ></td>
	<td class="line x" title="172:250	We selected three different cases (in Nepal, Israel, Wales) where the obtained information can be reliably verified, and applied our framework on these settings." ></td>
	<td class="line x" title="173:250	As a development set, we used the Russian rail network." ></td>
	<td class="line x" title="174:250	We have estimated the quality of our framework using several measures and observations." ></td>
	<td class="line x" title="175:250	First, we calculated the precision and quantity of obtained locations using map information." ></td>
	<td class="line x" title="176:250	Then we manually estimated precision of the proposed edges and their labels, comparing them with factual information obtained from maps7, transport companies and tourist sites." ></td>
	<td class="line x" title="177:250	Finally we visually compared a natural drawing of the obtained graph with a real map." ></td>
	<td class="line x" title="178:250	In addition, while our goals differ, the third evaluation setting has deliberate significant similarities to (Schockaert et al., 2008), which allows us to make some comparisons." ></td>
	<td class="line x" title="179:250	7We recognize that in case of some labels, e.g. walk, the precision measure is subjective." ></td>
	<td class="line x" title="180:250	Nevertheless it provides a good indication for the quality of our results." ></td>
	<td class="line x" title="181:250	4.1 The Annapurna trek area One of the most famous sites in Nepal is the Annapurna trekking circuit." ></td>
	<td class="line x" title="182:250	This is a 14-21 day walking path which passes many villages." ></td>
	<td class="line x" title="183:250	Most of the tourists going through this path spend weeks in prior information mining and preparations." ></td>
	<td class="line x" title="184:250	However, even when using the most recent maps and guides, they discover that available geographical knowledge is far from being complete and precise." ></td>
	<td class="line x" title="185:250	This trek is a good example of a case when formal information is lacking while free-text shared experience in the web is abundant." ></td>
	<td class="line x" title="186:250	Our goal was to test whether the algorithm can discover such knowledge automatically starting from few seed location names (we used Pokhara, which is one of the central cities in the area, and Khudi, a small village)." ></td>
	<td class="line x" title="187:250	The quality of results for this task was very good." ></td>
	<td class="line x" title="188:250	While even crude recall estimation is very hard for this type of task, we have discovered 100% of the Annapurna trek settlements with population over 1K, all of the flight and bus connections, and about 80% of the walking connections." ></td>
	<td class="line x" title="189:250	On Figure 1 we can compare the real map and the obtained map8." ></td>
	<td class="line x" title="190:250	This discovered map includes a partial map9 for 4 labels  flights, trek, bus and jeep." ></td>
	<td class="line x" title="191:250	You can see on the map different lines for each label." ></td>
	<td class="line x" title="192:250	The algorithm discovered 132 entities, all of them Annapurna-related locations." ></td>
	<td class="line x" title="193:250	This includes correctly recognized typos and alternative spellings, and the average was 1.2 names per place." ></td>
	<td class="line x" title="194:250	For example for Besisahar and Pokhara the following spellings were recognized based both on string distance and spatial collocation: Besishahar, Bensisahar, BesiSahar, Besi Sahar, Beshishahar, Beisahar, Phokra, Pohkala, Pokahara, Pokhara, Pokhar, Pokra, Pokhura, Pokhra." ></td>
	<td class="line x" title="195:250	We estimated correctness of edges comparing to existing detailed maps." ></td>
	<td class="line x" title="196:250	95% of the edges were correctly placed and labeled." ></td>
	<td class="line x" title="197:250	Results were good since this site is well covered and also not very interconnected  most of it is connected in a single possible way." ></td>
	<td class="line x" title="198:250	After the elimination process described in the previous section, only 6% of the nodes participate in 3-cliques." ></td>
	<td class="line x" title="199:250	Thus, due to the linearity of the original path, our method success8Graph nodes were manually positioned such that edges do not intersect." ></td>
	<td class="line x" title="200:250	Recall that our goal is to build a network graph, which is an abstract structure." ></td>
	<td class="line x" title="201:250	The 2-D embedding of the graph shown here is only for illustrative purposes and is not part of our algorithm." ></td>
	<td class="line x" title="202:250	9A few dozens of correctly discovered places were omitted to make the picture readable." ></td>
	<td class="line x" title="203:250	272 Figure 1: Real path map of Annapurna circuit (above) compared to automatically acquired graph (below)." ></td>
	<td class="line x" title="204:250	The graph nodes were manually positioned such that edges do not cross each other." ></td>
	<td class="line x" title="205:250	Dozens of correctly discovered places were omitted for readability." ></td>
	<td class="line x" title="206:250	Double circles indicate key nodes as explained in section 3.6.1 fully avoided the problem of mixing transitively connected nodes into one large clique." ></td>
	<td class="line x" title="207:250	4.2 The Israeli south The southern part of Israel (mostly the Negev desert) is a sparsely populated region containing a few main roads and a few dozen towns." ></td>
	<td class="line x" title="208:250	There is a limited number of tourists sites in the Negev and hence little web information is supposed to be available." ></td>
	<td class="line x" title="209:250	Our goal was to see if the algorithm can successfully detect at least major entities and to discover their connectedness." ></td>
	<td class="line x" title="210:250	We discovered 56 names of different places, of them 50 correctly belong to the region, where the region is defined as south from the AshquelonJerusalem-Yericho line, the other 6 were Israeli cities/locations outside the region (Tiberias, Metulla, Ben Gurion, Tel Aviv, Ashdod, Haifa)." ></td>
	<td class="line x" title="211:250	In addition we discovered 23 alternative names for some of the 56 places." ></td>
	<td class="line x" title="212:250	We also constructed the corresponding connectedness graphs." ></td>
	<td class="line x" title="213:250	We tested the usefulness of this data attempting to find the discovered terms in the NGA GEOnet Names Server10 which is considered one of the most exhaustive geographical resources." ></td>
	<td class="line x" title="214:250	We could find in the database only 60% of the correctly discovered English terms denoting towns, so 40% of the terms were discovered by us and ignored by this huge coverage database." ></td>
	<td class="line x" title="215:250	We also tested the quality of edges, and found that 80% of the discovered edges were correctly placed and labeled." ></td>
	<td class="line x" title="216:250	Figure 2 shows a partial graph of the places obtained for the road label." ></td>
	<td class="line x" title="217:250	Figure 2: Partial graph for Israel south settings." ></td>
	<td class="line x" title="218:250	4.3 The Cardiff area Cardiff is the capital, largest city and most populous county in Wales." ></td>
	<td class="line x" title="219:250	Our goal was to see if we can discover basic means of transport and corresponding locations connected to and inside Cardiff." ></td>
	<td class="line x" title="220:250	This exploration also allowed us to compare some of our results to related studies." ></td>
	<td class="line x" title="221:250	We executed our algorithm using as seeds Grangetown, Cardiff and Barry." ></td>
	<td class="line x" title="222:250	Table 1 shows the most utilized merged labels obtained for most edge-populated graphs together with graph size and estimated precision." ></td>
	<td class="line x" title="223:250	In case of flights, treks and trains, precision was estimated using exact data." ></td>
	<td class="line x" title="224:250	In other cases we estimated precision based on reading relevant web pages." ></td>
	<td class="line x" title="225:250	We can see that the majority of connectivity sets are meaningful and the precision obtained for most of these sets is high." ></td>
	<td class="line x" title="226:250	Figure 3 shows a partial graph for walking-type labels and Figure 10http://earth-info.nga.mil/gns/html/ 273 Nodes Edges(Prec) Label 88 120(81) walking,walk,cycling,short ride taxis, Short bus ride,short walk 131 140(95) flights, airlines,# flights a day 12 16(100) foot path, trek, walking # miles 36 51(89) train, railway, rail travel,rail 32 98(65) bus, road, drive,direct bus Table 1: The merged labels obtained for 5 most edge-populated graphs, including number of nodes and edges for each label." ></td>
	<td class="line x" title="227:250	The estimated precision according to each label definition is shown in parentheses." ></td>
	<td class="line x" title="228:250	4 shows such a graph for train labels11." ></td>
	<td class="line x" title="229:250	Comparing the obtained map with real map data we notice a definite correlation between actual and induced relative connection of discovered places." ></td>
	<td class="line x" title="230:250	(Schockaert et al., 2008) used their framework to discover neighborhoods of Cardiff." ></td>
	<td class="line x" title="231:250	In our case, the most appropriate relation which connects neighborhood locations is walking/cycling." ></td>
	<td class="line x" title="232:250	Hence, comparing the results to previous work, we have examined the results obtained for the walking label in details." ></td>
	<td class="line x" title="233:250	(Schockaert et al., 2008) report discovery of 68 locations, of them 7 are alternate entries, 4 can be considered vernacular or colloquial, 10 are not considered to be neighborhoods, and 5 are either close to, but not within, Cardiff, or are areas within Cardiff that are not recognized neighborhoods." ></td>
	<td class="line x" title="234:250	In our set we have discovered 88 neighborhood names, of them 18 are alternate entries of correct neighborhoods, 4 can be considered vernacular or colloquial, 3 are not considered to be neighborhoods, and 15 are areas outside the Cardiff area." ></td>
	<td class="line x" title="235:250	Considering alternate entries as hits, we got superior precision of 66/88 = 0.75 in comparison to 49/68 = 0.72." ></td>
	<td class="line x" title="236:250	It should be noted however that we found many more alternative names possibly due to our larger coverage." ></td>
	<td class="line x" title="237:250	Also both our framework and the goal were substantially different." ></td>
	<td class="line x" title="238:250	5 Discussion In this paper we presented a framework which, given a small set of seed terms describing a geographical region, discovers an underlying connectivity and transport graph together with the extraction of common and alternative location names in this region." ></td>
	<td class="line x" title="239:250	Our framework is based on the 11Spatial position of displayed graph components is arbitrary, we only made sure that there are no intersecting edges." ></td>
	<td class="line x" title="240:250	Figure 3: Partial graph of the obtained Cardiff region for the walk/walking/cycling label." ></td>
	<td class="line x" title="241:250	Figure 4: Partial graph of the obtained Cardiff region for the railway/train label." ></td>
	<td class="line x" title="242:250	observation that fromto-like patterns can encode connectedness in very precise manner." ></td>
	<td class="line x" title="243:250	In our framework, we have combined iterative patternand web-based relationship acquisition with the discovery of new patterns and refinement of the location graph." ></td>
	<td class="line x" title="244:250	In our evaluation we showed that our framework is capable of extracting high quality non-trivial information from free text given very restricted input and not relying on any heavy preprocessing techniques such as parsing or NER." ></td>
	<td class="line x" title="245:250	The success of the proposed framework opens many challenging directions for its enhancement." ></td>
	<td class="line x" title="246:250	Thus we would like to incorporate in our network patterns which allow traveling times and distances to be extracted, such as N miles from X to Y." ></td>
	<td class="line x" title="247:250	While in this paper we focus on specific type of geographical relationships, similar frameworks can be useful for a wider class of spatial relationships." ></td>
	<td class="line x" title="248:250	Automated acquisition of spatial data can significantly help many NLP tasks, e.g., question answering." ></td>
	<td class="line x" title="249:250	We would also like to incorporate some patterns based on (Egenhofer and Shariff, 1998), such as crosses, goes through or runs into, which may allow automated acquisition of complex spatial relationships." ></td>
	<td class="line x" title="250:250	Finally, we would like to incorporate in our framework mod274 ules which may allow recognition of structured data, like those developed by (Schockaert et al., 2008)." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="D09-1084
A Relational Model of Semantic Similarity between Words using Automatically Extracted Lexical Pattern Clusters from the Web
Bollegala, Danushka;Matsuo, Yutaka;Ishizuka, Mitsuru;"></td>
	<td class="line x" title="1:275	Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 803812, Singapore, 6-7 August 2009." ></td>
	<td class="line x" title="2:275	c 2009 ACL and AFNLP A Relational Model of Semantic Similarity between Words using Automatically Extracted Lexical Pattern Clusters from the Web Danushka Bollegala  danushka@mi.ci.i. u-tokyo.ac.jp Yutaka Matsuo matsuo@biz-model." ></td>
	<td class="line x" title="3:275	t.u-tokyo.ac.jp The University of Tokyo 7-3-1, Hongo, Tokyo, 113-8656, Japan Mitsuru Ishizuka ishizuka@i. u-tokyo.ac.jp Abstract Semantic similarity is a central concept that extends across numerous fields such as artificial intelligence, natural language processing, cognitive science and psychology." ></td>
	<td class="line x" title="4:275	Accurate measurement of semantic similarity between words is essential for various tasks such as, document clustering, information retrieval, and synonym extraction." ></td>
	<td class="line x" title="5:275	We propose a novel model of semantic similarity using the semantic relations that exist among words." ></td>
	<td class="line x" title="6:275	Given two words, first, we represent the semantic relations that hold between those words using automatically extracted lexical pattern clusters." ></td>
	<td class="line x" title="7:275	Next, the semantic similarity between the two words is computed using a Mahalanobis distance measure." ></td>
	<td class="line x" title="8:275	We compare the proposed similarity measure against previously proposed semantic similarity measures on Miller-Charles benchmark dataset and WordSimilarity353 collection." ></td>
	<td class="line x" title="9:275	The proposed method outperforms all existing web-based semantic similarity measures, achieving a Pearson correlation coefficient of 0.867 on the Millet-Charles dataset." ></td>
	<td class="line x" title="10:275	1 Introduction Similarity is a fundamental concept in theories of knowledge and behavior." ></td>
	<td class="line x" title="11:275	Psychological experiments have shown that similarity acts as an organizing principle by which individuals classify objects, and make generalizations (Goldstone, 1994)." ></td>
	<td class="line x" title="12:275	For example, a biologist would classify a newly found animal specimen based upon the properties that it shares with existing categories of animals." ></td>
	<td class="line x" title="13:275	We can then make additional inferences on the new specimen using the properties Research Fellow of the Japan Society for the Promotion of Science (JSPS) known for the existing category." ></td>
	<td class="line x" title="14:275	As the similarity between two objects X and Y increases, so does the probability of correctly inferring that Y has the property T upon knowing that X has T (Tenenbaum, 1999)." ></td>
	<td class="line oc" title="15:275	Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002)." ></td>
	<td class="line x" title="16:275	In information retrieval, similar or related words are used to expand user queries to improve recall (Sahami and Heilman, 2006)." ></td>
	<td class="line x" title="17:275	Semantic similarity is a context dependent and dynamic phenomenon." ></td>
	<td class="line x" title="18:275	New words are constantly being created and existing words are assigned with new senses on the Web." ></td>
	<td class="line x" title="19:275	To decide whether two words are semantically similar, it is important to know the semantic relations that hold between the words." ></td>
	<td class="line x" title="20:275	For example, the words horse and cow can be considered semantically similar because both horses and cows are useful animals in agriculture." ></td>
	<td class="line x" title="21:275	Similarly, a horse and a car can be considered semantically similar because cars, and historically horses, are used for transportation." ></td>
	<td class="line x" title="22:275	Semantic relations such as X and Y are used in agriculture, or X and Y are used for transportation, exist between two words X and Y in these examples." ></td>
	<td class="line x" title="23:275	We use bold-italics, X, to denote the slot of a word X in a lexical pattern." ></td>
	<td class="line x" title="24:275	We propose a relational model to compute the semantic similarity between two words." ></td>
	<td class="line x" title="25:275	First, using snippets retrieved from a web search engine, we present an automatic lexical pattern extraction algorithm to represent the semantic relations that exist between two words." ></td>
	<td class="line x" title="26:275	For example, given two words ostrich and bird, we extract X is a Y, X is a large Y, and X is a flightless Y from the Web." ></td>
	<td class="line x" title="27:275	Using a set of semantically related words as training data, we evaluate the confidence of a lexical 803 pattern as an indicator of semantic similarity." ></td>
	<td class="line x" title="28:275	For example, the pattern X is a Y is a better indicator of semantic similarity between X and Y than the pattern X and Y. Consequently, we would like to emphasize the former pattern by assigning it a higher confidence score." ></td>
	<td class="line x" title="29:275	It is noteworthy that all lexical patterns are not independent  multiple lexical patterns can express the same semantic relation." ></td>
	<td class="line x" title="30:275	For example, the pattern X is a large Y subsumes the more general pattern X is a Y and they both indicate a hypernymic relationship between X and Y. By clustering the semantically related patterns into groups, we can both overcome the data sparseness problem, and reduce the number of parameters during training." ></td>
	<td class="line x" title="31:275	To identify semantically related patterns, we use a sequential pattern clustering algorithm that is based on the distributional hypothesis (Harris, 1954)." ></td>
	<td class="line x" title="32:275	We represent two words by a feature vector defined over the clusters of patterns." ></td>
	<td class="line x" title="33:275	Finally, the semantic similarity is computed as the Mahalanobis distance between points corresponding to the feature vectors." ></td>
	<td class="line x" title="34:275	By using Mahalanobis distance instead of Euclidean distance, we can account for the inter-dependence between semantic relations." ></td>
	<td class="line x" title="35:275	2 Related Work Geometric models, such as multi-dimensional scaling has been used in psychological experiments analyzing the properties of similarity (Krumhansl, 1978)." ></td>
	<td class="line x" title="36:275	These models represent objects as points in some coordinate space such that the observed dissimilarities between objects correspond to the metric distances between the respective points." ></td>
	<td class="line x" title="37:275	Geometric models assume that objects can be adequately represented as points in some coordinate space and that dissimilarity behaves like a metric distance function satisfying minimality, symmetry, and triangle inequality assumptions." ></td>
	<td class="line x" title="38:275	However, both dimensional and metric assumptions are open to question." ></td>
	<td class="line x" title="39:275	Tversky (1977) proposed the contrast model of similarity to overcome the problems in geometric models." ></td>
	<td class="line x" title="40:275	The contrast model relies on featural representation of objects, and it is used to compute the similarity between the representations of two objects." ></td>
	<td class="line x" title="41:275	Similarity is defined as an increasing function of common features (i.e. features in common to the two objects), and as a decreasing function of distinctive features (i.e. features that apply to one object but not the other)." ></td>
	<td class="line x" title="42:275	The attributes of objects are primal to contrast model and it does not explicitly incorporate the relations between objects when measuring similarity." ></td>
	<td class="line x" title="43:275	Hahn et al.(2003) define similarity between two representations as the complexity required to transform one representation into the other." ></td>
	<td class="line x" title="45:275	Their model of similarity is based on the Representational Distortion theory, which aims to provide a theoretical framework of similarity judgments." ></td>
	<td class="line x" title="46:275	Their experiments using pattern sequences and geometric shapes show an inverse correlation between the number of transformations required to convert one pattern (or shape) to another, and the perceived similarity ratings by human subjects." ></td>
	<td class="line x" title="47:275	How to represent an object, which transformations are allowed on a representation, and how to measure the complexity of a transformation, are all important decisions in the transformational model of similarity." ></td>
	<td class="line x" title="48:275	Although distance measures such as edit distance have been used to find approximate matches in a dictionary, it is not obvious how to compute semantic similarity between words using representational distortion theory." ></td>
	<td class="line x" title="49:275	Given a taxonomy of concepts, a straightforward method to calculate similarity between two words (or concepts) is to find the length of the shortest path connecting the two words in the taxonomy (Rada et al., 1989)." ></td>
	<td class="line x" title="50:275	If a word is polysemous (i.e. has more than one sense) then multiple paths might exist between the two words." ></td>
	<td class="line x" title="51:275	In such cases, only the shortest path between any two senses of the words is considered for calculating similarity." ></td>
	<td class="line x" title="52:275	A problem that is frequently acknowledged with this approach is that it relies on the notion that all links in the taxonomy represent a uniform distance." ></td>
	<td class="line x" title="53:275	As a solution to this problem, Schickel-Zuber and Faltings (2007) propose ontology structure based similarity (OSS) between two concepts in an ontology, which is an asymmetric distance function." ></td>
	<td class="line x" title="54:275	Resnik (1995) proposed a similarity measure using information content." ></td>
	<td class="line x" title="55:275	He defined the similarity between two concepts C1 and C2 in the taxonomy as the maximum of the information content of all concepts C that subsume both C1 and C2." ></td>
	<td class="line x" title="56:275	Then the similarity between two words is defined as the maximum of the similarity between any concepts that the words belong to." ></td>
	<td class="line x" title="57:275	He used WordNet as the taxonomy; information content is calculated using the Brown corpus." ></td>
	<td class="line x" title="58:275	Li et al., (2003) combined structural seman804 tic information from a lexical taxonomy, and information content from a corpus, in a nonlinear model." ></td>
	<td class="line x" title="59:275	They proposed a similarity measure that uses shortest path length, depth and local density in a taxonomy." ></td>
	<td class="line x" title="60:275	Their experiments reported a Pearson correlation coefficient of 0.8914 on the MillerCharles benchmark dataset (Miller and Charles, 1998)." ></td>
	<td class="line oc" title="61:275	Lin (1998b) defined the similarity between two concepts as the information that is in common to both concepts and the information contained in each individual concept." ></td>
	<td class="line x" title="62:275	Cilibrasi and Vitanyi (2007) proposed a distance metric between words using page-counts retrieved from a web search engine." ></td>
	<td class="line x" title="63:275	The proposed metric is named Normalized Google Distance (NGD) and is defined as the normalized information distance (Li et al., 2004) between two strings." ></td>
	<td class="line x" title="64:275	They evaluate NGD in a word classification task." ></td>
	<td class="line x" title="65:275	Unfortunately NGD only uses page-counts of words and ignores the context in which the words appear." ></td>
	<td class="line x" title="66:275	Therefore, it produces inaccurate similarity scores when one or both words between which similarity is computed are polysemous." ></td>
	<td class="line x" title="67:275	Sahami and Heilman (2006) measured semantic similarity between two queries using snippets returned for those queries by a search engine." ></td>
	<td class="line x" title="68:275	For each query, they collect snippets from a search engine and represent each snippet as a TF-IDFweighted term vector." ></td>
	<td class="line x" title="69:275	Each vector is L2 normalized and the centroid of the set of vectors is computed." ></td>
	<td class="line x" title="70:275	Semantic similarity between two queries is then defined as the inner product between the corresponding centroid vectors." ></td>
	<td class="line x" title="71:275	They did not compare their similarity measure with taxonomybased similarity measures." ></td>
	<td class="line x" title="72:275	Chen et al., (2006) propose a web-based doublechecking model to compute the semantic similarity between words." ></td>
	<td class="line x" title="73:275	For two words X and Y , they collect snippets for each word from a web search engine." ></td>
	<td class="line x" title="74:275	Then they count the number of occurrences of X in the snippets for Y , and Y in the snippets for X. The two values are combined nonlinearly to compute the similarity between X and Y . This method heavily depends on the search engines ranking algorithm." ></td>
	<td class="line x" title="75:275	Although two words X and Y may be very similar, there is no reason to believe that one can find Y in the snippets for X, or vice versa." ></td>
	<td class="line x" title="76:275	This observation is confirmed by the experimental results in their paper which reports 0 similarity scores for many pairs of words in the Miller-Charles dataset." ></td>
	<td class="line x" title="77:275	In our previous work (Bollegala et al., 2007), we proposed a semantic similarity measure using page counts and snippets retrieved from a Web search engine." ></td>
	<td class="line x" title="78:275	To compute the similarity between two words X and Y , we queried a web search engine using the query X AND Y and extract lexical patterns that combine X and Y from snippets." ></td>
	<td class="line x" title="79:275	A feature vector is formed using frequencies of 200 lexical patterns in snippets and four co-occurrence measures: Dice coefficient, overlap coefficient, Jaccard coefficient and pointwise mutual information." ></td>
	<td class="line x" title="80:275	We trained a two-class support vector machine using automatically selected synonymous and non-synonymous word pairs from WordNet." ></td>
	<td class="line x" title="81:275	This method reports a Pearson correlation coefficient of 0.837 with Miller-Charles ratings." ></td>
	<td class="line x" title="82:275	However, it does not consider the relatedness between patterns." ></td>
	<td class="line x" title="83:275	Gabrilovich and Markovitch (2007) represent words using weighted vectors of Wikipedia-based concepts, and define the similarity between words as the cosine of the angle between the corresponding vectors." ></td>
	<td class="line x" title="84:275	Their method can be used to compute similarity between words as well as between texts." ></td>
	<td class="line x" title="85:275	Although Wikipedia is growing in popularity, not all concepts found on the Web have articles in Wikipedia." ></td>
	<td class="line x" title="86:275	Specially, novel or not very popular concepts are not adequately covered by Wikipedia." ></td>
	<td class="line x" title="87:275	Moreover, their method requires the concepts to be independent." ></td>
	<td class="line x" title="88:275	For non-independent, hierarchical taxonomies such as open directory project (ODP)1, their method produces suboptimal results." ></td>
	<td class="line x" title="89:275	3 Relational Model of Similarity We propose a model to compute the semantic similarity between two words a and b using the set of semantic relations R(a,b) that hold between a and b. We call the proposed model the relational model of semantic similarity and it is defined by the following equation, sim(a,b) = (R(a,b))." ></td>
	<td class="line x" title="90:275	(1) Here, sim(a,b) is the semantic similarity between the two words a and b, and  is a weighting function defined over the set of semantic relations R(a,b)." ></td>
	<td class="line x" title="91:275	Given that a particular set of semantic relations are known to hold between two words, the function  expresses our confidence on those words being semantically similar." ></td>
	<td class="line x" title="92:275	1http://www.dmoz.org 805 A semantic relation can be expressed in a number of ways." ></td>
	<td class="line x" title="93:275	For example, given a taxonomy of words such as the WordNet, semantic relations (i.e. hypernymy, meronymy, synonymy etc.) between words can be directly looked up in the taxonomy." ></td>
	<td class="line x" title="94:275	Alternatively, the labels of the edges in the path connecting two words can be used as semantic relations." ></td>
	<td class="line x" title="95:275	However, in this paper we do not assume the availability of manually created resources such as dictionaries or taxonomies." ></td>
	<td class="line x" title="96:275	We represent semantic relations using automatically extracted lexical patterns." ></td>
	<td class="line x" title="97:275	Lexical patterns have been successfully used to represent various semantic relations between words such as hypernymy (Hearst, 1992), and meronymy (Berland and Charniak, 1999)." ></td>
	<td class="line x" title="98:275	Following these previous approaches, we represent R(a,b) as a set of lexical patterns." ></td>
	<td class="line x" title="99:275	Moreover, we denote the frequency of a lexical pattern r for a word pair (a,b) by f(r,a,b)." ></td>
	<td class="line x" title="100:275	So far we have not defined the functional form of ." ></td>
	<td class="line x" title="101:275	A straightforward approach is to use a linearly weighted combination of relations as shown below, (R(a,b)) = summationdisplay riR(a,b) wi f(ri,a,b)." ></td>
	<td class="line x" title="102:275	(2) Here, wi is the weight associated with the lexical pattern ri and can be determined using training data." ></td>
	<td class="line x" title="103:275	However, this formulation has two fundamental drawbacks." ></td>
	<td class="line x" title="104:275	First, the number of weight parameters wi is equal to the number of lexical patterns." ></td>
	<td class="line x" title="105:275	Typically two words can co-occur in numerous patterns." ></td>
	<td class="line x" title="106:275	Consequently, we end up with a large number of parameters in the model." ></td>
	<td class="line x" title="107:275	Complex models with a large number of parameters are difficult to train because they tend to overfit to the training data." ></td>
	<td class="line x" title="108:275	Second, the linear combination given in Equation 2 assumes the lexical patterns to be mutually independent." ></td>
	<td class="line x" title="109:275	However, in practice this is not true." ></td>
	<td class="line x" title="110:275	For example, both patterns X is a Y and Y such as X indicate a hypernymic relation between X and Y. To overcome the above mentioned limitations, we first cluster the lexical patterns to identify the semantically related patterns." ></td>
	<td class="line x" title="111:275	Our clustering algorithm is detailed in section 3.2." ></td>
	<td class="line x" title="112:275	Next, we define  using the formed clusters as follows, (R(a,b)) = xTab." ></td>
	<td class="line x" title="113:275	(3) Here, xab is a feature vector representing the words a and b. Each formed cluster contributes a feature in vector xab as described later in Section 5." ></td>
	<td class="line x" title="114:275	The vector  is a prototypical vector representing synonymous word pairs." ></td>
	<td class="line x" title="115:275	We compute  as the centroid of feature vectors representing synonymous word pairs." ></td>
	<td class="line x" title="116:275	 is the inter-cluster correlation matrix." ></td>
	<td class="line x" title="117:275	The (i,j)-th element of matrix  denotes the correlation between the two clusters ci and cj." ></td>
	<td class="line x" title="118:275	Matrix  is expected to capture the dependence between semantic relations." ></td>
	<td class="line x" title="119:275	Intuitively, if two clusters i and j are highly correlated, then the (i,j)-th element of  will be closer to 1." ></td>
	<td class="line x" title="120:275	Equation 3 computes the similarity between a word pair (a,b) and a set of synonymous word pairs." ></td>
	<td class="line x" title="121:275	Intuitively, if the relations that exist between a and b are typical relations that hold between synonymous word pairs, then Equation 3 returns a high similarity score for a and b. The proposed relational model of semantic similarity differs from feature models of similarity, such as the contrast model (Tversky, 1977), in that it is defined over the set of semantic relations that exist between two words instead of the set of features for each word." ></td>
	<td class="line x" title="122:275	Specifically, in contrast model, the similarity S(a,b) between two objects a and b is defined in terms of the features common to a and b, AB, the features that are distinctive to a, AB, and the features that are distinctive to b, B A. The contrast model is formalized in the following equation, S(a,b) = f(AB)f(AB)f(B A)." ></td>
	<td class="line x" title="123:275	(4) Here, the function f measures the salience of a particular set of features, and non-negative parameters , , and  determine the relative weights assigned to the different components." ></td>
	<td class="line x" title="124:275	However, in the relational model of similarity we do not focus on features of individual words but on relations between two words." ></td>
	<td class="line x" title="125:275	Modeling similarity as a phenomenon of relations between objects rather than features of individual objects is central to computational models of analogy-making such as the structure mapping theory (SMT) (Falkenhainer et al., 1989)." ></td>
	<td class="line x" title="126:275	SMT claims that an analogy is a mapping of knowledge from one domain (base) into another (target) which conveys that a system of relations known to hold in the base also holds in the target." ></td>
	<td class="line x" title="127:275	The target objects do not have to resemble their corresponding base objects." ></td>
	<td class="line x" title="128:275	During the mapping process, features of individual objects are dropped and only relations are mapped." ></td>
	<td class="line x" title="129:275	The proposed relational model of similarity uses this relational view 806 Ostrich, a large, flightless bird that lives in the dry grasslands of Africa." ></td>
	<td class="line x" title="130:275	Figure 1: A snippet returned for the query ostrich * * * * * bird." ></td>
	<td class="line x" title="131:275	of similarity to compute semantic similarity between words." ></td>
	<td class="line x" title="132:275	3.1 Extracting Lexical Patterns To compute semantic similarity between two words using the relational model (Equation 3), we must first extract the numerous lexical patterns from contexts in which those two words appear." ></td>
	<td class="line x" title="133:275	For this purpose, we propose a pattern extraction algorithm using snippets retrieved from a web search engine." ></td>
	<td class="line x" title="134:275	The proposed method requires no language-dependent preprocessing such as part-of-speech tagging or dependency parsing, which can be both time consuming at Web scale, and likely to produce incorrect results because of the fragmented and ill-formed snippets." ></td>
	<td class="line x" title="135:275	Given two words a and b, we query a web search engine using the wildcard query a * * * * * b and download snippets." ></td>
	<td class="line x" title="136:275	The * operator matches one word or none in a web page." ></td>
	<td class="line x" title="137:275	Therefore, our wildcard query retrieves snippets in which a and b appear within a window of seven words." ></td>
	<td class="line x" title="138:275	We attempt to approximate the local context of two words using wildcard queries." ></td>
	<td class="line x" title="139:275	For example, Figure 1 shows a snippet retrieved for the query ostrich * * * * * bird." ></td>
	<td class="line x" title="140:275	For a snippet S, retrieved for a word pair (a,b), first, we replace the two words a and b, respectively, with two variables X and Y. We replace all numeric values by D, a marker for digits." ></td>
	<td class="line x" title="141:275	Next, we generate all subsequences of words from S that satisfy all of the following conditions." ></td>
	<td class="line x" title="142:275	(i)." ></td>
	<td class="line x" title="143:275	A subsequence must contain exactly one occurrence of each X and Y (ii)." ></td>
	<td class="line x" title="144:275	The maximum length of a subsequence is L words." ></td>
	<td class="line x" title="145:275	(iii)." ></td>
	<td class="line x" title="146:275	A subsequence is allowed to have gaps." ></td>
	<td class="line x" title="147:275	However, we do not allow gaps of more than g number of words." ></td>
	<td class="line x" title="148:275	Moreover, the total length of all gaps in a subsequence should not exceed G words." ></td>
	<td class="line x" title="149:275	(iv)." ></td>
	<td class="line x" title="150:275	We expand all negation contractions in a context." ></td>
	<td class="line x" title="151:275	For example, didnt is expanded to did not." ></td>
	<td class="line x" title="152:275	We do not skip the word not when generating subsequences." ></td>
	<td class="line x" title="153:275	For example, this condition ensures that from the snippet X is not a Y, we do not produce the subsequence X is a Y. Finally, we count the frequency of all generated subsequences and only use subsequences that occur more than N times as lexical patterns." ></td>
	<td class="line x" title="154:275	The parameters L, g, G and N are set experimentally, as explained later in Section 6." ></td>
	<td class="line x" title="155:275	It is noteworthy that the proposed pattern extraction algorithm considers all the words in a snippet, and is not limited to extracting patterns only from the mid-fix (i.e., the portion of text in a snippet that appears between the queried words)." ></td>
	<td class="line x" title="156:275	Moreover, the consideration of gaps enables us to capture relations between distant words in a snippet." ></td>
	<td class="line x" title="157:275	We use a modified version of the prefixspan algorithm (Pei et al., 2004) to generate subsequences from a text snippet." ></td>
	<td class="line x" title="158:275	Specifically, we use the constraints (ii)(iv) to prune the search space of candidate subsequences." ></td>
	<td class="line x" title="159:275	For example, if a subsequence has reached the maximum length L, or contains the maximum number of gaps G, then we will not extend it further." ></td>
	<td class="line x" title="160:275	By pruning the search space, we can speed up the pattern generation process." ></td>
	<td class="line x" title="161:275	However, none of these modifications affect the accuracy of the proposed semantic similarity measure because the modified version of the prefixspan algorithm still generates the exact set of patterns that we would obtain if we used the original prefixspan algorithm (i.e. without pruning) and subsequently remove patterns that violate the above mentioned constraints." ></td>
	<td class="line x" title="162:275	For example, some patterns extracted form the snippet shown in Figure 1 are: X, a large Y, X a flightless Y, and X, large Y lives." ></td>
	<td class="line x" title="163:275	3.2 Clustering Lexical Patterns A semantic relation can be expressed using more than one pattern." ></td>
	<td class="line x" title="164:275	By grouping the semantically related patterns, we can both reduce the model complexity in Equation 2, and consider the dependence among semantic relations in Equation 3." ></td>
	<td class="line x" title="165:275	We use the distributional hypothesis (Harris, 1954) to find semantically related lexical patterns." ></td>
	<td class="line x" title="166:275	The distributional hypothesis states that words that occur in the same context have similar meanings." ></td>
	<td class="line x" title="167:275	If two lexical patterns are similarly distributed over a set of word pairs, then from the distributional hypothesis it follows that the two patterns must be similar." ></td>
	<td class="line x" title="168:275	We represent a pattern p by a vector p in which 807 the i-th element is the frequency f(ai,bi,p) of p in a word pair (ai,bi)." ></td>
	<td class="line x" title="169:275	Given a set P of patterns and a similarity threshold , Algorithm 1 returns clusters of similar patterns." ></td>
	<td class="line x" title="170:275	First, the function SORT sorts the patterns in the descending order of their total occurrences in all word pairs." ></td>
	<td class="line x" title="171:275	The total occurrences of a pattern p is defined as (p), and is given by, (p) = summationdisplay (a,b)W f(a,b,p)." ></td>
	<td class="line x" title="172:275	(5) Here, W is the set of word pairs." ></td>
	<td class="line x" title="173:275	Then the outer for-loop (starting at line 3), repeatedly takes a pattern pi from the ordered set P, and in the inner forloop (starting at line 6), finds the cluster, c ( C) that is most similar to pi." ></td>
	<td class="line x" title="174:275	Similarity between pi and the cluster centroid cj is computed using cosine similarity." ></td>
	<td class="line x" title="175:275	The centroid vector cj of cluster cj is defined as the vector sum of all pattern vectors for patterns in that cluster (i.e. cj = summationtextpcj p)." ></td>
	<td class="line x" title="176:275	If the maximum similarity exceeds the threshold , we append pi to c (line 14)." ></td>
	<td class="line x" title="177:275	Here, the operator  denotes vector addition." ></td>
	<td class="line x" title="178:275	Otherwise, we form a new cluster {pi} and append it to C, the set of clusters." ></td>
	<td class="line x" title="179:275	After all patterns are clustered, we compute the (i,j) element of the inter-cluster correlation matrix  (Equation 3) as the innerproduct between the centroid vectors ci and cj of the corresponding clusters i and j. The parameter  ( [0,1]) determines the purity of the formed clusters and is set experimentally in Section 5." ></td>
	<td class="line x" title="180:275	Algorithm 1 scales linearly with the number of patterns." ></td>
	<td class="line x" title="181:275	Moreover, sorting the patterns by their total word pair frequency prior to clustering ensures that the final set of clusters contains the most common relations in the dataset." ></td>
	<td class="line x" title="182:275	4 Evaluation Procedure Evaluating a semantic similarity measure is difficult because the notion of semantic similarity is subjective." ></td>
	<td class="line x" title="183:275	Miller-Charles (1998) dataset has been frequently used to benchmark semantic similarity measures." ></td>
	<td class="line x" title="184:275	Miller-Charles dataset contains 30 word pairs rated by a group of 38 human subjects." ></td>
	<td class="line x" title="185:275	The word pairs are rated on a scale from 0 (no similarity) to 4 (perfect synonymy)." ></td>
	<td class="line x" title="186:275	Because of the omission of two word pairs in earlier versions of WordNet, most researchers had used only 28 pairs for evaluations." ></td>
	<td class="line x" title="187:275	The degree of correlation between the human ratings in the benchmark dataset and the similarity scores produced by an automatic semantic similarity measure, can be considered as a Algorithm 1 Sequential pattern clustering algorithm." ></td>
	<td class="line x" title="188:275	Input: patterns P = {p1,,pn}, threshold  Output: clusters C 1: SORT(P) 2: C {} 3: for pattern pi  P do 4: max  5: c  null 6: for cluster cj  C do 7: sim  cosine(pi,cj) 8: if sim > max then 9: max  sim 10: c  cj 11: end if 12: end for 13: if max   then 14: c  c pi 15: else 16: C  C {pi} 17: end if 18: end for 19: return C measurement of how well the semantic similarity measure captures the notion of semantic similarity held by humans." ></td>
	<td class="line x" title="189:275	In addition to Miller-Charles dataset we also evaluate on the WordSimilarity353 (Finkelstein et al., 2002) dataset." ></td>
	<td class="line x" title="190:275	In contrast to Miller-Charles dataset which has only 30 word pairs, WordSimilarity-353 dataset contains 353 word pairs." ></td>
	<td class="line x" title="191:275	Each pair has 13-16 human judgments, which were averaged for each pair to produce a single relatedness score." ></td>
	<td class="line x" title="192:275	Following the previous work, we use both Miller-Charles dataset and WordSimilarity-353 dataset to evaluate the proposed semantic similarity measure." ></td>
	<td class="line x" title="193:275	5 Computing Semantic Similarity To extract lexical patterns that express numerous semantic relations, we first select synonymous words from WordNet synsets." ></td>
	<td class="line x" title="194:275	A synset is a set of synonymous words assigned for a particular sense of a word in WordNet." ></td>
	<td class="line x" title="195:275	We randomly select 2000 synsets of nouns from WordNet." ></td>
	<td class="line x" title="196:275	From each synset, a pair of synonymous words is selected." ></td>
	<td class="line x" title="197:275	For polysemous nouns, we selected synonyms from the dominant sense." ></td>
	<td class="line x" title="198:275	To perform a fair evaluation, we do not select any words that appear in the Miller-Charles dataset or the WordSimilarity-353 808  0.3 0.4  0.5 0.6  0.7 0.8  0.9 1  1.1 1.2  1.3 1.4  0  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Average Similarity Clustering Threshold Figure 2: Average similarity vs. clustering threshold   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1  0  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Cluster Sparsity Clustering Threshold Figure 3: Sparsity vs. clustering threshold  dataset, which are used later for evaluation purposes." ></td>
	<td class="line x" title="199:275	As we describe later, the clustering threshold  is tuned using this set of 2000 word pairs selected from the WordNet." ></td>
	<td class="line x" title="200:275	We use the YahooBOSS API2 and download 1000 snippets for each of those word pairs." ></td>
	<td class="line x" title="201:275	Experimentally, we set the values for the parameters in the pattern extraction algorithm (Section 3.1): L = 5, g = 2, G = 4, and extract 5,238,637 unique patterns." ></td>
	<td class="line x" title="202:275	However, only 1,680,914 of those patterns occur more than twice." ></td>
	<td class="line x" title="203:275	Low frequency patterns often contain misspellings and are not suitable for training." ></td>
	<td class="line x" title="204:275	Therefore, we selected patterns that occur at least 10 times in the snippet collection." ></td>
	<td class="line x" title="205:275	Moreover, we remove very long patterns (ca." ></td>
	<td class="line x" title="206:275	over 20 characters)." ></td>
	<td class="line x" title="207:275	The final set contains 140,691 unique lexical patterns." ></td>
	<td class="line x" title="208:275	The remainder of the experiments described in the paper use those patterns." ></td>
	<td class="line x" title="209:275	2http://developer.yahoo.com/search/boss/ We use the clustering Algorithm 1 to cluster the extracted patterns." ></td>
	<td class="line x" title="210:275	The only parameter in Algorithm 1, the clustering threshold , is set as follows." ></td>
	<td class="line x" title="211:275	We vary the value of theta  from 0 to 1, and use Algorithm 1 to cluster the extracted set of patterns." ></td>
	<td class="line x" title="212:275	We use the resultant set of clusters to represent a word pair by a feature vector." ></td>
	<td class="line x" title="213:275	We compute a feature from each cluster as follows." ></td>
	<td class="line x" title="214:275	First, we assign a weight wij to a pattern pi that is in a cluster cj as follows, wij = (pi)summationtext qcj (q) ." ></td>
	<td class="line x" title="215:275	(6) Here, (q) is the total frequency of a pattern, and it is given by Equation 5." ></td>
	<td class="line x" title="216:275	Because we perform a hard clustering on patterns, a pattern can belong to only one cluster (i.e. wij = 0 for pi / cj)." ></td>
	<td class="line x" title="217:275	Finally, we compute the value of the j-th feature in the feature vector for word pair (a,b) as follows, summationdisplay picj wijf(a,b,pi)." ></td>
	<td class="line x" title="218:275	(7) For each set of clusters, we compute the element ij of the corresponding inter-cluster correlation matrix  by the cosine similarity between the centroid vectors for clusters ci and cj." ></td>
	<td class="line x" title="219:275	The prototype vector  in Equation 3 is computed as the vector sum of individual feature vectors for the synonymous word pairs selected from the WordNet as described above." ></td>
	<td class="line x" title="220:275	We then use Equation 3 to compute the average of similarity scores for synonymous word pairs we selected from WordNet." ></td>
	<td class="line x" title="221:275	We select the  that maximizes the average similarity score between those synonymous word pairs." ></td>
	<td class="line x" title="222:275	Formally, the optimal value of ,  is given by the following Equation,  = argmax[0,1] parenleftbigg 1 |W| summationdisplay (a,b)Wsim(a,b) parenrightbigg ." ></td>
	<td class="line x" title="223:275	(8) Here, W is the set of synonymous word pairs (a,b), |W| is the total number of synonymous word pairs (i.e. 2000 in our experiments), and sim(a,b) is given by Equation 3." ></td>
	<td class="line x" title="224:275	Because the averages are taken over 2000 word pairs this procedure gives a reliable estimate for ." ></td>
	<td class="line x" title="225:275	Moreover, this method does not require negative training instances such as, non-synonymous word pairs, which are difficult to create manually." ></td>
	<td class="line x" title="226:275	Average similarity scores for various  values are shown in Figure 2." ></td>
	<td class="line x" title="227:275	From Figure 2, we see that initially average similarity increases when  is increased." ></td>
	<td class="line x" title="228:275	809 This is because clustering of semantically related patterns reduces the sparseness in feature vectors." ></td>
	<td class="line x" title="229:275	Average similarity is stable within a range of  values between 0.5 and 0.7." ></td>
	<td class="line x" title="230:275	However, increasing  beyond 0.7 results in a rapid drop of average similarity." ></td>
	<td class="line x" title="231:275	To explain this behavior consider Figure 3 where we plot the sparsity of the set of clusters (i.e. the ratio between singletons to total clusters) against threshold ." ></td>
	<td class="line x" title="232:275	As seen from Figure 3, high  values result in a high percentage of singletons because only highly similar patterns will form clusters." ></td>
	<td class="line x" title="233:275	Consequently, feature vectors for different word pairs do not have many features in common." ></td>
	<td class="line x" title="234:275	The maximum average similarity score of 1.303 is obtained with  = 0.7, corresponding to 17,015 total clusters out of which 12,476 are singletons with exactly one pattern (sparsity = 0.733)." ></td>
	<td class="line x" title="235:275	For the remainder of the experiments in this paper we set  to this optimal value and use the corresponding set of clusters to compute semantic similarity by Equation 3." ></td>
	<td class="line x" title="236:275	Similarity scores computed using Equation 3 can be greater than 1 (see Figure 2) because of the terms corresponding to the nondiagonal elements in ." ></td>
	<td class="line x" title="237:275	We do not normalize the similarity scores to [0,1] range in our experiments because the evaluation metrics we use are insensitive to linear transformations of similarity scores." ></td>
	<td class="line x" title="238:275	6 Experiments Table 1 compares the proposed method against Miller-Charles ratings (MC), and previously proposed web-based semantic similarity measures: Jaccard, Dice, Overlap, PMI (Bollegala et al., 2007), Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007), Sahami and Heilman (SH) (2006), co-occurrence double checking model (CODC) (Chen et al., 2006), and support vector machine-based (SVM) approach (Bollegala et al., 2007)." ></td>
	<td class="line x" title="239:275	The bottom row of Table 1 shows the Pearson correlation coefficient of similarity scores produced by each algorithm with MC." ></td>
	<td class="line x" title="240:275	All similarity scores, except for the human-ratings in MillerCharles dataset, are normalized to [0,1] range for the ease of comparison." ></td>
	<td class="line x" title="241:275	It is noteworthy that the Pearson correlation coefficient is invariant under a linear transformation." ></td>
	<td class="line x" title="242:275	All similarity scores shown in Table 1 except for the proposed method are taken from the original published papers." ></td>
	<td class="line x" title="243:275	The highest correlation is reported by the proposed semantic similarity measure." ></td>
	<td class="line x" title="244:275	The improvement of the proposed method is statistically significant (confidence interval [0.73,0.93]) against all the similarity measures compared in Table 1 except against the SVM approach." ></td>
	<td class="line x" title="245:275	From Table 1 we see that measures that use contextual information from snippets (e.g. SH, CODC, SVM, and proposed) outperform the ones that use only cooccurrence statistics (e.g. Jaccard, overlap, Dice, PMI, and NGD) such as page-counts." ></td>
	<td class="line x" title="246:275	This is because similarity measures that use contextual information are better equipped to compute the similarity between polysemous words." ></td>
	<td class="line x" title="247:275	Although both SVM and proposed methods use lexical patterns, unlike the proposed method, the SVM method does not consider the relatedness between patterns." ></td>
	<td class="line x" title="248:275	The superior performance of the proposed method is attributable to its consideration of relatedness of patterns." ></td>
	<td class="line x" title="249:275	Table 2 summarizes the previously proposed WordNet-based semantic similarity measures." ></td>
	<td class="line x" title="250:275	Despite the fact that the proposed method does not use manually compiled resources such as WordNet for computing similarity, its performance is comparable to similarity measures that use WordNet." ></td>
	<td class="line x" title="251:275	We believe that the proposed method will be useful to compute the semantic similarity between named-entities for which manually created resources are either incomplete or do not exist." ></td>
	<td class="line x" title="252:275	We evaluate the proposed method using the WordSimilarity-353 dataset." ></td>
	<td class="line x" title="253:275	Experimental results are presented in Table 3." ></td>
	<td class="line x" title="254:275	Following previous work, we use Spearman rank correlation coefficient, which does not require ratings to be linearly dependent, for the evaluations on this dataset." ></td>
	<td class="line x" title="255:275	Likewise with the Miller-Charles ratings, we measure the correlation between the similarity scores produced by the proposed method for word pairs in the WordSimilarity-353 dataset and the human ratings." ></td>
	<td class="line x" title="256:275	A higher Spearman correlation coefficient (value=0.504, confidence interval [0.422,0.578]) indicates a better agreement with the human notion of semantic similarity." ></td>
	<td class="line x" title="257:275	From Table 3 we can see that the proposed method outperforms a wide variety of semantic similarity measures developed using numerous resources including lexical resources such as WordNet and knowledge sources such as Wikipedia (i.e. WikiRelate!)." ></td>
	<td class="line x" title="258:275	In contrast to the Miller-Charles dataset which only contains common English words selected from the WordNet, the WordSimilarity-353 dataset contains word pairs where one or both words are named entities (e.g.(Maradona, foot810 Table 1: Semantic similarity scores on Miller-Charles dataset Word Pair MC Jaccrad Dice Overlap PMI NGD SH CODC SVM Proposed automobile-car 3.920 0.650 0.664 0.831 0.427 0.466 0.225 0.008 0.980 0.918 journey-voyage 3.840 0.408 0.424 0.164 0.468 0.556 0.121 0.005 0.996 1.000 gem-jewel 3.840 0.287 0.300 0.075 0.688 0.566 0.052 0.012 0.686 0.817 boy-lad 3.760 0.177 0.186 0.593 0.632 0.456 0.109 0.000 0.974 0.958 coast-shore 3.700 0.783 0.794 0.510 0.561 0.603 0.089 0.006 0.945 0.975 asylum-madhouse 3.610 0.013 0.014 0.082 0.813 0.782 0.052 0.000 0.773 0.794 magician-wizard 3.500 0.287 0.301 0.370 0.863 0.572 0.057 0.008 1.000 0.997 midday-noon 3.420 0.096 0.101 0.116 0.586 0.687 0.069 0.010 0.819 0.987 furnace-stove 3.110 0.395 0.410 0.099 1.000 0.638 0.074 0.011 0.889 0.878 food-fruit 3.080 0.751 0.763 1.000 0.449 0.616 0.045 0.004 0.998 0.940 bird-cock 3.050 0.143 0.151 0.144 0.428 0.562 0.018 0.006 0.593 0.867 bird-crane 2.970 0.227 0.238 0.209 0.516 0.563 0.055 0.000 0.879 0.846 implement-tool 2.950 1.000 1.000 0.507 0.297 0.750 0.098 0.005 0.684 0.496 brother-monk 2.820 0.253 0.265 0.326 0.623 0.495 0.064 0.007 0.377 0.265 crane-implement 1.680 0.061 0.065 0.100 0.194 0.559 0.039 0.000 0.133 0.056 brother-lad 1.660 0.179 0.189 0.356 0.645 0.505 0.058 0.005 0.344 0.132 car-journey 1.160 0.438 0.454 0.365 0.205 0.410 0.047 0.004 0.286 0.165 monk-oracle 1.100 0.004 0.005 0.002 0.000 0.579 0.015 0.000 0.328 0.798 food-rooster 0.890 0.001 0.001 0.412 0.207 0.568 0.022 0.000 0.060 0.018 coast-hill 0.870 0.963 0.965 0.263 0.350 0.669 0.070 0.000 0.874 0.356 forest-graveyard 0.840 0.057 0.061 0.230 0.495 0.612 0.006 0.000 0.547 0.442 monk-slave 0.550 0.172 0.181 0.047 0.611 0.698 0.026 0.000 0.375 0.243 coast-forest 0.420 0.861 0.869 0.295 0.417 0.545 0.060 0.000 0.405 0.150 lad-wizard 0.420 0.062 0.065 0.050 0.426 0.657 0.038 0.000 0.220 0.231 cord-smile 0.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006 glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050 rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052 noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000 Correlation 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867 Table 2: Comparison with WordNet-based similarity measures." ></td>
	<td class="line oc" title="260:275	Method Correlation Edge-counting 0.664 Jiang & Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al.(2003) 0.891 ball) and (Jerusalem, Israel))." ></td>
	<td class="line x" title="262:275	Because the proposed method use snippets retrieved from a web search engine, it is capable of extracting expressive lexical patterns that can explicitly state the relationship between two entities." ></td>
	<td class="line x" title="263:275	If we must compare n objects using a feature model of similarity, then we only need to define features for each of those n objects." ></td>
	<td class="line x" title="264:275	However, in the proposed relational model we must define relations between all pairs of objects." ></td>
	<td class="line x" title="265:275	In the case where all n objects are different, this requires us to define relations for n(n1)/2 object pairs." ></td>
	<td class="line x" title="266:275	Defining relations for all pairs can be computationally costly for large n values." ></td>
	<td class="line x" title="267:275	Efficiently comparing n objects using a relational model is an interesting future research direction of the current work." ></td>
	<td class="line x" title="268:275	Table 3: Results on WordSimilarity-353 dataset." ></td>
	<td class="line x" title="269:275	Method Correlation WordNet Edges (Jarmasz, 1993) 0.27 Hirst & St-Onge (1997) 0.34 Jiang & Conrath (1998) 0.34 WikiRelate!" ></td>
	<td class="line oc" title="270:275	(Strube and Ponzetto, 2006) 0.19-0.48 Leacock & Chodrow (1998) 0.36 Lin (1998b) 0.36 Resnik (1995) 0.37 Proposed 0.504 7 Conclusion We proposed a relational model to measure the semantic similarity between two words." ></td>
	<td class="line x" title="271:275	First, to represent the numerous semantic relations that exist between two words, we extract lexical patterns from snippets retrieved from a web search engine." ></td>
	<td class="line x" title="272:275	Second, we cluster the extracted patterns to identify the semantically related patterns." ></td>
	<td class="line x" title="273:275	Third, using the pattern clusters we define a feature vector to represent two words and compute the semantic similarity by taking into account the inter-cluster correlation." ></td>
	<td class="line x" title="274:275	The proposed method outperformed all existing web-based semantic similarity measures on two benchmark datasets." ></td>
	<td class="line x" title="275:275	811" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="D09-1089
Enhancement of Lexical Concepts Using Cross-lingual Web Mining
Davidov, Dmitry;Rappoport, Ari;"></td>
	<td class="line x" title="1:251	Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 852861, Singapore, 6-7 August 2009." ></td>
	<td class="line x" title="2:251	c 2009 ACL and AFNLP Enhancement of Lexical Concepts Using Cross-lingual Web Mining Dmitry Davidov ICNC The Hebrew University of Jerusalem dmitry@alice.nc.huji.ac.il Ari Rappoport Institute of Computer Science The Hebrew University of Jerusalem arir@cs.huji.ac.il Abstract Sets of lexical items sharing a significant aspect of their meaning (concepts) are fundamental in linguistics and NLP." ></td>
	<td class="line x" title="3:251	Manual concept compilation is labor intensive, error prone and subjective." ></td>
	<td class="line x" title="4:251	We present a web-based concept extension algorithm." ></td>
	<td class="line x" title="5:251	Given a set of terms specifying a concept in some language, we translate them to a wide range of intermediate languages, disambiguate the translations using web counts, and discover additional concept terms using symmetric patterns." ></td>
	<td class="line x" title="6:251	We then translate the discovered terms back into the original language, score them, and extend the original concept by adding backtranslations having high scores." ></td>
	<td class="line x" title="7:251	We evaluate our method in 3 source languages and 45 intermediate languages, using both human judgments and WordNet." ></td>
	<td class="line x" title="8:251	In all cases, our cross-lingual algorithm significantly improves high quality concept extension." ></td>
	<td class="line x" title="9:251	1 Introduction A concept (or lexical category) is a set of lexical items sharing a significant aspect of their meanings (e.g., types of food, tool names, etc)." ></td>
	<td class="line x" title="10:251	Concepts are fundamental in linguistics and NLP, in thesauri, dictionaries, and various applications such as textual entailment and question answering." ></td>
	<td class="line x" title="11:251	Great efforts have been invested in manual preparation of concept resources such as WordNet (WN)." ></td>
	<td class="line x" title="12:251	However, manual preparation is labor intensive, which means it is both costly and slow to update." ></td>
	<td class="line x" title="13:251	Applications needing data on some very specific domain or on a recent news-related event may find such resources lacking." ></td>
	<td class="line x" title="14:251	In addition, manual preparation is error-prone and susceptible to subjective concept membership decisions, frequently resulting in concepts whose terms do not belong to the same level of granularity1." ></td>
	<td class="line x" title="15:251	As a result, there is a need to find methods for automatic improvement of concept coverage and quality." ></td>
	<td class="line x" title="16:251	The web is a huge up-to-date corpus covering many domains, so using it for concept extension has the potential to address the above problems." ></td>
	<td class="line x" title="17:251	The majority of web pages are written in a few salient languages, hence most of the web-based information retrieval studies are done on these languages." ></td>
	<td class="line x" title="18:251	However, due to the substantial growth of the multilingual web2, languages in which concept terms are expressed in the most precise manner frequently do not match the language where information is needed." ></td>
	<td class="line x" title="19:251	Moreover, representations of the same concept in different languages may complement each other." ></td>
	<td class="line x" title="20:251	In order to benefit from such cross-lingual information, concept acquisition systems should be able to gather concept terms from many available languages and convert them to the desired language." ></td>
	<td class="line x" title="21:251	In this paper we present such an algorithm." ></td>
	<td class="line x" title="22:251	Given a set of words specifying a concept in some source language, we translate them to a range of intermediate languages and disambiguate the translations using web counts." ></td>
	<td class="line x" title="23:251	Then we discover additional concept terms using symmetric patterns and translate the discovered terms back into the original language." ></td>
	<td class="line x" title="24:251	Finally we score the backtranslations using their intermediate languages properties, and extend the original concept by adding back-translations having high scores." ></td>
	<td class="line x" title="25:251	The only language-specific resource required by the algorithm are multilingual dictionaries, and its processing times are very modest." ></td>
	<td class="line x" title="26:251	We performed thorough evaluation for 24 concepts in 3 source languages (Hebrew, English and Russian) and 45 intermediate languages." ></td>
	<td class="line x" title="27:251	Concept definitions were taken from existing WordNet subtrees, and the obtained new terms were manually 1See Section 5.1.1." ></td>
	<td class="line x" title="28:251	2http://www.internetworldstats.com/stats7.htm 852 scored by human judges." ></td>
	<td class="line x" title="29:251	In all cases we have significantly extended the original concept set with high precision." ></td>
	<td class="line x" title="30:251	We have also performed a fully automatic evaluation with 150 concepts, showing that the algorithm can re-discover WN concepts with high precision and recall when given only partial lists as input." ></td>
	<td class="line x" title="31:251	Section 2 discusses related work, Section 3 details the algorithm, Section 4 describes the evaluation protocol and Section 5 presents our results." ></td>
	<td class="line x" title="32:251	2 Related work One of the main goals of this paper is the extension or automated creation of lexical databases such as WN." ></td>
	<td class="line x" title="33:251	Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al., 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008))." ></td>
	<td class="line x" title="34:251	The majority of this research was done on extending the tree structure (finding new synsets (Snow et al., 2006) or enriching WN with new relationships (Cuadros and Rigau, 2008)) rather than improving the quality of existing concept/synset nodes." ></td>
	<td class="line x" title="35:251	Other related studies develop concept acquisition frameworks for on-demand tasks where concepts are defined by user-provided seeds or patterns (Etzioni et al., 2005; Davidov et al., 2007), or for fully unsupervised database creation where concepts are discovered from scratch (Banko et al., 2007; Davidov and Rappoport, 2006)." ></td>
	<td class="line x" title="36:251	Some papers directly target specific applications, and build lexical resources as a side effect." ></td>
	<td class="line x" title="37:251	Named Entity Recognition can be viewed as an instance of the concept acquisition problem where the desired concepts contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types." ></td>
	<td class="line x" title="38:251	The two main algorithmic approaches to the problem are pattern-based concept discovery and clustering of context feature vectors." ></td>
	<td class="line x" title="39:251	The latter approach represents word contexts as vectors in some space and uses similarity measures and automatic clustering in that space (Deerwester et al., 1990)." ></td>
	<td class="line oc" title="40:251	Pereira et al.(1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition." ></td>
	<td class="line x" title="41:251	Pantel and Lin (2002) improves on the latter by clustering by committee." ></td>
	<td class="line x" title="42:251	Caraballo (1999) uses conjunction and appositive annotations in the vector representation." ></td>
	<td class="line n" title="43:251	While great effort has been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they still remain data and computation intensive." ></td>
	<td class="line x" title="44:251	The second major algorithmic approach is to use lexico-syntactic patterns." ></td>
	<td class="line x" title="45:251	Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004)." ></td>
	<td class="line x" title="46:251	In concept acquisition, pattern-based methods were shown to outperform LSA by a large margin (Widdows and Dorow, 2002)." ></td>
	<td class="line x" title="47:251	Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns in order to acquire relationships, numerous patternbased methods have been proposed for the discovery of concepts from seeds (Pantel et al., 2004; Davidov et al., 2007; Pasca et al., 2006)." ></td>
	<td class="line x" title="48:251	Most of these studies were done for English, while some show the applicability of their methods to other languages, including Greek, Czech, Slovene and French." ></td>
	<td class="line x" title="49:251	Most of these papers attempt to discover concepts from data available in some specific language." ></td>
	<td class="line x" title="50:251	Recently several studies have proposed to utilize a second language or several specified languages in order to extract or extend concepts (Vintar and Fiser, 2008; van der Plas and Tiedemann, 2006) or paraphrases (Bosma and Callison-Burch, 2007)." ></td>
	<td class="line x" title="51:251	However, these methods usually require the availability of parallel corpora, which limits their usefulness." ></td>
	<td class="line x" title="52:251	Most of these methods utilize distributional measures, hence they do not possess the advantages of the pattern-based framework." ></td>
	<td class="line x" title="53:251	Unlike in the majority of recent studies, where the framework is designed with specific languages in mind, in our task, in order to take advantage of information from diverse languages, the algorithm should be able to deal well with a wide variety of possible intermediate languages without any manual adaptations." ></td>
	<td class="line x" title="54:251	Relying solely on multilingual dictionaries and the web, our algorithm should be able to discover language-specific patterns and concept terms." ></td>
	<td class="line x" title="55:251	While some of the proposed frameworks could potentially be languageindependent, little research has been done to confirm this." ></td>
	<td class="line x" title="56:251	There are a few obstacles that may hinder applying common pattern-based methods to other languages." ></td>
	<td class="line x" title="57:251	Many studies utilize parsing or POS tagging, which frequently depend on the availability and quality of language-specific tools." ></td>
	<td class="line x" title="58:251	Some studies specify seed patterns in advance, and 853 it is not clear whether translated patterns can work well on different languages." ></td>
	<td class="line x" title="59:251	Also, the absence of clear word segmentation in some languages (e.g., Chinese) can make many methods inapplicable." ></td>
	<td class="line x" title="60:251	A few recently proposed concept acquisition methods require only a handful of seed words and no pattern pre-specification (Davidov et al., 2007; Pasca and Van Durme, 2008)." ></td>
	<td class="line x" title="61:251	While these studies avoid some of the obstacles above, it still remains open whether such methods are indeed languageindependent." ></td>
	<td class="line x" title="62:251	In the translation to intermediate languages part of our framework, we adapt the algorithms in (Davidov and Rappoport, 2006; Davidov et al., 2007) to suit diverse languages (including ones without explicit word segmentation)." ></td>
	<td class="line x" title="63:251	We also develop a method for efficient automated disambiguation and translation of terms to and from any available intermediate language." ></td>
	<td class="line x" title="64:251	Our study is related to cross-language information retrieval (CLIR/CLEF) frameworks." ></td>
	<td class="line x" title="65:251	Both deal with information extracted from a set of languages." ></td>
	<td class="line x" title="66:251	However, the majority of CLIR studies pursue different targets." ></td>
	<td class="line x" title="67:251	One of the main CLIR goals is the retrieval of documents based on explicit queries, when the document language is not the query language (Volk and Buitelaar, 2002)." ></td>
	<td class="line x" title="68:251	These frameworks usually develop language-specific tools and algorithms including parsers and taggers in order to integrate multilingual queries and documents (Jagarlamudi and Kumaran, 2007)." ></td>
	<td class="line x" title="69:251	Our goal is to develop a languageindependent method using cross-lingual information, for the extension and improvement of concepts rather than the retrieval of documents." ></td>
	<td class="line x" title="70:251	Besides, unlike in many CLIR frameworks, intermediate languages are not specified in advance and the language of requested data is the same as the language of request, while available information may be found in many different intermediate languages." ></td>
	<td class="line x" title="71:251	3 The Algorithm Our algorithm is comprised of the following stages: (1) given a set of words in a source language as a specification for some concept, we automatically translate them to a diverse set of intermediate languages, using multilingual dictionaries; (2) the translations are disambiguated using web counts; (3) for each language, we retrieve a set of web snippets where these translations coappear and apply a pattern-based concept extension algorithm for discovering additional terms; (4) we translate the discovered terms back to the source language, and disambiguate them; (5) we score the back-translated terms using data on their behavior in the intermediate languages, and merge the sets obtained from different languages into a single one, retaining terms whose score passes a certain threshold." ></td>
	<td class="line x" title="72:251	Stages 1-3 of the algorithm have been described in (Davidov and Rappoport, 2009), where the goal was to translate a concept given in one language to other languages." ></td>
	<td class="line x" title="73:251	The framework presented here includes the new stages 4-5, and its goal and evaluation methods are completely different." ></td>
	<td class="line x" title="74:251	3.1 Concept specification and translation We start from a set of words denoting a concept in a given source language." ></td>
	<td class="line x" title="75:251	Thus we may use words like (apple, banana, ) as the definition of the concept of fruit or (bear, wolf, fox, ) as the definition of wild animals." ></td>
	<td class="line x" title="76:251	In order to reduce noise, we limit the length (in words) of multiword expressions considered as terms." ></td>
	<td class="line x" title="77:251	To calculate this limit for a language, we randomly take 100 terms from the appropriate dictionary and set a limit as Limmwe = round(avg(length(w))) where length(w) is the number of words in term w. For languages like Chinese without inherent word segmentation, length(w) is the number of characters in w. While for many languages Limmwe = 1, some languages like Vietnamese usually require two or more words to express terms." ></td>
	<td class="line x" title="78:251	3.2 Disambiguation of translated terms One of the problems in utilization of multilingual information is ambiguity of translation." ></td>
	<td class="line x" title="79:251	First, in order to apply the concept acquisition algorithm, at least some of the given concept terms must be automatically translated to each intermediate language." ></td>
	<td class="line x" title="80:251	In order to avoid reliance on parallel corpora, which do not exist or are extremely small for most of our language pairs, we use bilingual dictionaries." ></td>
	<td class="line x" title="81:251	Such dictionaries usually provide many translations, one or more for each sense, so this translation is inherently fuzzy." ></td>
	<td class="line x" title="82:251	Second, once we acquire translated term lists for each intermediate language, we need to translate them back to the source language and such back-translations are also fuzzy." ></td>
	<td class="line x" title="83:251	In both cases, we need to select the appropriate translation for each term." ></td>
	<td class="line x" title="84:251	While our desire would be to work with as many languages as possible, in practice, some or even 854 most of the concept terms may be absent from the appropriate dictionary." ></td>
	<td class="line x" title="85:251	Such concept terms are ignored." ></td>
	<td class="line x" title="86:251	One way to deal with ambiguity is by applying distributional methods, usually requiring a large single-language corpus or, more frequently, parallel corpora." ></td>
	<td class="line x" title="87:251	However, such corpora are not readily available for many languages and domains." ></td>
	<td class="line x" title="88:251	Extracting such statistical information on-demand is also computationally demanding, limiting its usability." ></td>
	<td class="line x" title="89:251	Hence, we take a simple but effective query-based approach." ></td>
	<td class="line x" title="90:251	This approach, while being powerful as we show in the evaluation, only relies on a few web queries and does not rely on any language-specific resources or data." ></td>
	<td class="line x" title="91:251	We use the conjecture that terms of the same concept tend to co-appear more frequently than ones belonging to different concepts3." ></td>
	<td class="line x" title="92:251	Thus, we select a translation of a term co-appearing most frequently with some translation of a different term of the same concept." ></td>
	<td class="line x" title="93:251	We estimate how well translations of different terms are connected to each other." ></td>
	<td class="line x" title="94:251	Let C = {Ci} be the given seed words for some concept." ></td>
	<td class="line x" title="95:251	Let Tr(Ci,n) be the n-th available translation of word Ci and Cnt(s) denote the web count of string s obtained by a search engine." ></td>
	<td class="line x" title="96:251	We select a translation Tr(Ci) according to: F(w1,w2) = Cnt(w1 w2)Cnt(w2 w1)Cnt(w 1)Cnt(w2) Tr(Ci) = argmaxs i parenleftBigg max sj jnegationslash=i (F(Tr(Ci,si),Tr(Cj,sj))) parenrightBigg We utilize the Yahoo!" ></td>
	<td class="line x" title="97:251	x * y,x * * y wildcards that allow to count only co-appearances where x and y are separated by a single word or word pair." ></td>
	<td class="line x" title="98:251	As a result, we obtain a set of disambiguated term translations." ></td>
	<td class="line x" title="99:251	This method is used both in order to translate from the source language to each intermediate language and to backtranslate the newly discovered concept terms from the intermediate to the source language." ></td>
	<td class="line x" title="100:251	The number of queries in this stage depends on the ambiguity of the concept terms translations." ></td>
	<td class="line x" title="101:251	In order to decrease the amount of queries, if there are more than three possible senses we sort them by frequency4 and take three senses with medium frequency." ></td>
	<td class="line x" title="102:251	This allows us to skip the most ambiguous and rare senses without any significant effect on performance." ></td>
	<td class="line x" title="103:251	Also, if the number of combina3Our results here support this conjecture." ></td>
	<td class="line x" title="104:251	4Frequency is estimated by web count for a given word." ></td>
	<td class="line x" title="105:251	tions is still too high (>30), we randomly sample at most 30 of the possible combinations." ></td>
	<td class="line x" title="106:251	3.3 Pattern-based extension of concept terms in intermediate languages We first mine the web for contexts containing the translations." ></td>
	<td class="line x" title="107:251	Then we extract from the retrieved snippets contexts where translated terms co-appear, and detect patterns where they coappear symmetrically." ></td>
	<td class="line x" title="108:251	Then we use the detected patterns to discover additional concept terms." ></td>
	<td class="line x" title="109:251	In order to define word boundaries, for each language we manually specify boundary characters such as punctuation/space symbols." ></td>
	<td class="line x" title="110:251	This data, along with dictionaries, is the only language-specific data in our framework." ></td>
	<td class="line x" title="111:251	Web mining for translation contexts." ></td>
	<td class="line x" title="112:251	In order to get language-specific data, we need to restrict web mining each time to the processed intermediate language." ></td>
	<td class="line x" title="113:251	This restriction is straightforward if the alphabet or term translations are languagespecific or if the search API supports restriction to this language5." ></td>
	<td class="line x" title="114:251	In case where there are no such natural restrictions, we attempt to detect and add to our queries a few language-specific frequent words." ></td>
	<td class="line x" title="115:251	Using our dictionaries, we find 13 of the 15 most frequent words in a desired language that are unique to that language, and we and them with the queries to ensure proper language selection." ></td>
	<td class="line x" title="116:251	This works well for almost all languages (Esperanto being a notable exception)." ></td>
	<td class="line x" title="117:251	For each pair A,B of disambiguated term translations, we construct and execute the following two queries: {A * B, B * A}6." ></td>
	<td class="line x" title="118:251	When we have 3 or more terms we also add{A B C D}-like conjunction queries which include 3-5 words." ></td>
	<td class="line x" title="119:251	For languages with Limmwe > 1, we also construct queries with several * wildcards between terms." ></td>
	<td class="line x" title="120:251	For each query we collect snippets containing text fragments of web pages." ></td>
	<td class="line x" title="121:251	Such snippets frequently include the search terms." ></td>
	<td class="line x" title="122:251	Since Yahoo!" ></td>
	<td class="line x" title="123:251	Boss allows retrieval of up to the 1000 first results (50 in each query), we collect several thousands snippets." ></td>
	<td class="line x" title="124:251	For most of the intermediate languages, only a few dozen queries (40 on the average) are required to obtain sufficient data, and queries can be parallelized." ></td>
	<td class="line x" title="125:251	Thus the relevant data can be downloaded 5Yahoo!" ></td>
	<td class="line x" title="126:251	allows restriction for 42 languages." ></td>
	<td class="line x" title="127:251	6These are Yahoo!" ></td>
	<td class="line x" title="128:251	queries where enclosing words in  means searching for an exact phrase and * means a wildcard for exactly one arbitrary word." ></td>
	<td class="line x" title="129:251	855 in seconds." ></td>
	<td class="line x" title="130:251	This makes our approach practical for on-demand retrieval or concept verification tasks." ></td>
	<td class="line x" title="131:251	Meta-patterns." ></td>
	<td class="line x" title="132:251	Following (Davidov et al., 2007), we seek symmetric patterns to retrieve concept terms." ></td>
	<td class="line x" title="133:251	We use two meta-pattern types." ></td>
	<td class="line x" title="134:251	First, a Two-Slot pattern type constructed as follows: [Prefix] C1 [Infix] C2 [Postfix] Ci are slots for concept terms." ></td>
	<td class="line x" title="135:251	We allow up to Limmwe space-separated7 words to be in a single slot." ></td>
	<td class="line x" title="136:251	Infix may contain punctuation, spaces, and up to Limmwe 4 words." ></td>
	<td class="line x" title="137:251	Prefix and Postfix are limited to contain punctuation characters and/or Limmwe words." ></td>
	<td class="line x" title="138:251	Terms of the same concept frequently co-appear in lists." ></td>
	<td class="line x" title="139:251	To utilize this, we introduce two additional List pattern types8: [Prefix] C1 [Infix] (Ci [Infix])+ (1) [Infix] (Ci [Infix])+ Cn [Postfix] (2) Following (Widdows and Dorow, 2002), we define a pattern graph." ></td>
	<td class="line x" title="140:251	Nodes correspond to terms and patterns to edges." ></td>
	<td class="line x" title="141:251	If term pair (w1,w2) appears in pattern P, we add nodes Nw1,Nw2 to the graph and a directed edge EP(Nw1,Nw2) between them." ></td>
	<td class="line x" title="142:251	Symmetric patterns." ></td>
	<td class="line x" title="143:251	We consider only symmetric patterns." ></td>
	<td class="line x" title="144:251	We define a symmetric pattern as a pattern where some concept terms Ci,Cj appear both in left-to-right and right-toleft order." ></td>
	<td class="line x" title="145:251	For example, if we consider the terms{apple,pineapple}we select a List pattern (oneCi,)+andCn. if we find both one apple, one pineapple, one guava and orange. and one watermelon, one pineapple and apple.." ></td>
	<td class="line x" title="146:251	If no such patterns are found, we turn to a weaker definition, considering as symmetric those patterns where the same terms appear in the corpus in at least two different slots." ></td>
	<td class="line x" title="147:251	Thus, we select a pattern for C1 and C2 if we see both for apple and guava, and for orange and apple,." ></td>
	<td class="line x" title="148:251	Retrieving concept terms." ></td>
	<td class="line x" title="149:251	We collect terms in two stages." ></td>
	<td class="line x" title="150:251	First, we obtain high-quality core terms and then we retrieve potentially more noisy ones." ></td>
	<td class="line x" title="151:251	At the first stage we collect all terms9 that 7As before, for languages without space-based word separation Limmwe limits the number of characters instead." ></td>
	<td class="line x" title="152:251	8(E)+ means one or more instances of E. 9We do not consider as terms the 50 most frequent words." ></td>
	<td class="line x" title="153:251	are bidirectionally connected to at least two different original translations, and call them core concept terms Ccore." ></td>
	<td class="line x" title="154:251	We also add the original ones as core terms." ></td>
	<td class="line x" title="155:251	Then we detect the rest of the terms Crest that are connected to the core stronger than to the remaining words, as follows: Gin(c)={wCcore|E(Nw,Nc)E(Nc,Nw)} Gout(c)={w/Ccore|E(Nw,Nc)E(Nc,Nw)} Crest={c||Gin(c)|>|Gout(c)|} For the sake of simplicity, we do not attempt to discover more patterns/instances iteratively by requerying the web." ></td>
	<td class="line x" title="156:251	If we have enough data, we use windowing to improve result quality." ></td>
	<td class="line x" title="157:251	If we obtain more than 400 snippets for some concept, we divide the data into equal parts, each containing up to 400 snippets." ></td>
	<td class="line x" title="158:251	We apply our algorithm independently to each part and select only the words that appear in more than one part." ></td>
	<td class="line x" title="159:251	3.4 Back-translation and disambiguation At the concept acquisition phase of our framework we obtained sets of terms for each intermediate language, each set representing a concept." ></td>
	<td class="line x" title="160:251	In order to be useful for the enhancement of the original concept, these terms are now back-translated to the source language." ></td>
	<td class="line x" title="161:251	We disambiguate each backtranslated term using the process described in Section 3.2." ></td>
	<td class="line x" title="162:251	Having sets of back-translated terms for each intermediate language, our goal is to combine these into a single set." ></td>
	<td class="line x" title="163:251	3.5 Scoring and merging the back translations We do this merging using the following scoring strategy, assigning for each proposed term tprime in concept C the score S(tprime,C), and selecting terms with S(tprime,C) > H where H is a predefined threshold." ></td>
	<td class="line x" title="164:251	Our scoring is based on the two following considerations." ></td>
	<td class="line x" title="165:251	First, we assume that terms extracted from more languages tend to be less noisy and language-dependent." ></td>
	<td class="line x" title="166:251	Second, we would like to favor languages with less resources for a given concept, since noise empirically appears to be less prominent in such languages10." ></td>
	<td class="line x" title="167:251	For language L and concept C = {t1 tk} we get a disambiguated set of translations {Tr(t1,L)Tr(tk,L)}." ></td>
	<td class="line x" title="168:251	We define relative lan10Preliminary experimentation, as well as the evaluation results presented in this paper, support both of these considerations." ></td>
	<td class="line x" title="169:251	856 guage frequency by LFreq(L,C) = summationtext tiC(Freq(Tr(ti,L)))summationtext Lprime,tiC(Freq(Tr(ti,Lprime)) where Freq(Tr(ti,L)) is a frequency of terms ti translation to language L estimated by the number of web hits." ></td>
	<td class="line x" title="170:251	Thus languages in which translated concept terms appear more times will get higher relative frequency, potentially indicating a greater concept translation ambiguity." ></td>
	<td class="line x" title="171:251	Now, for each new term tprime discovered through LNum(tprime) different languages L1 LLNum(tprime) we calculate a term score 11 S(tprime,C): S(tprime,C) = LNum(tprime) parenleftBigg 1 summationdisplay i LFreq(Li,C) parenrightBigg For each discovered term tprime, S(tprime,C)  [0,LNum(tprime)], while discovery of tprime in less frequent languages will cause the score to be closer to LNum(tprime)." ></td>
	<td class="line x" title="172:251	So terms appearing in a greater number of infrequent languages will get higher scores." ></td>
	<td class="line x" title="173:251	After the calculation of score for each proposed term, we retain terms whose scores are above the predefined threshold H. In our experiments we have used H = 3, usually meaning that acquisition of a term through 3-4 uncommon intermediate languages should be enough to accept it." ></td>
	<td class="line x" title="174:251	The same score measure can also be used to filter out bad terms in an already existing concept." ></td>
	<td class="line x" title="175:251	4 Experimental Setup We describe here the languages, concepts and dictionaries we used in our experiments." ></td>
	<td class="line x" title="176:251	4.1 Languages and concepts One of the main goals in this research is to take advantage of concept data in every possible language." ></td>
	<td class="line x" title="177:251	As intermediate languages, we used 45 languages including major west European languages like French or German, Slavic languages like Russian, Semitic languages as Hebrew and Arabic, and diverse Asian languages such as Chinese and Persian." ></td>
	<td class="line x" title="178:251	To configure parameters we have used a set of 10 concepts in Russian as a development set." ></td>
	<td class="line x" title="179:251	These concepts were not used in evaluation." ></td>
	<td class="line x" title="180:251	We examined a wide variety of concepts and for each of them we used all languages with available translations." ></td>
	<td class="line x" title="181:251	Table 1 shows the resulting top 10 most utilized languages in our experiments." ></td>
	<td class="line x" title="182:251	11In this expression i runs only on languages with term tprime hence the summation is not 1." ></td>
	<td class="line x" title="183:251	English Russian Hebrew German(68%) English(70%) English(66%) French(60%) German(62%) German(65%) Italian(60%) French(62%) Italian(61%) Portuguese(57%) Spanish(58%) French(59%) Spanish(55%) Italian(56%) Spanish(57%) Turkish(51%) Portuguese(54%) Portuguese(57%) Russian(50%) Korean(50%) Korean(48%) Korean(46%) Turkish(49%) Russian(43%) Chinese(45%) Chinese(47%) Turkish(43%) Czech(42%) Polish (44%) Czech(40%) Table 1: The ten most utilized intermediate languages in our experiments." ></td>
	<td class="line x" title="184:251	In parentheses we show the percentage of new terms that these languages helped discover." ></td>
	<td class="line x" title="185:251	We have used the English, Hebrew (Ordan and Winter, 2008) and Russian (Gelfenbeynand et al., 2003) WordNets as sources for concepts and for the automatic evaluation." ></td>
	<td class="line x" title="186:251	Our concept set selection was based on English WN subtrees." ></td>
	<td class="line x" title="187:251	To perform comparable experiments with Russian and Hebrew, we have selected the same subtrees in the Hebrew and Russian WN." ></td>
	<td class="line x" title="188:251	Concept definitions given to human judges for evaluation were based on the corresponding WN glosses." ></td>
	<td class="line x" title="189:251	For automated evaluation we selected 150 synsets/subtrees containing at least 10 single word terms (existing in all three tested languages)." ></td>
	<td class="line x" title="190:251	For manual evaluation we used a subset of 24 of these concepts." ></td>
	<td class="line x" title="191:251	In this subset we tried to select generic concepts manually, such that no domain expert knowledge was required to check their correctness." ></td>
	<td class="line x" title="192:251	Ten of these concepts were identical to ones used in (Widdows and Dorow, 2002; Davidov and Rappoport, 2006), which allowed us to compare our results to recent work in case of English." ></td>
	<td class="line x" title="193:251	Table 2 shows these 10 concepts along with the sample terms." ></td>
	<td class="line x" title="194:251	While the number of tested concepts is not very large, it provides a good indication for the quality of our approach." ></td>
	<td class="line x" title="195:251	Concept Sample terms Musical instruments guitar, flute, piano Vehicles/transport train, bus, car Academic subjects physics, chemistry, psychology Body parts hand, leg, shoulder Food egg, butter, bread Clothes pants, skirt, jacket Tools hammer, screwdriver, wrench Places park, castle, garden Crimes murder, theft, fraud Diseases rubella, measles, jaundice Table 2: Ten of the selected concepts with sample terms." ></td>
	<td class="line x" title="196:251	857 4.2 Multilingual dictionaries We developed tools for automatic access to a number of dictionaries." ></td>
	<td class="line x" title="197:251	We used Wikipedia crosslanguage links as our main source (> 60%) for offline translation." ></td>
	<td class="line x" title="198:251	These links include translation of Wikipedia terms into dozens of languages." ></td>
	<td class="line x" title="199:251	The main advantage of using Wikipedia is its wide coverage of concepts and languages." ></td>
	<td class="line x" title="200:251	However, one problem it has is that it frequently encodes too specific senses and misses common ones (bear is translated as family Ursidae, missing its common wild animal sense)." ></td>
	<td class="line x" title="201:251	To overcome these difficulties, we also used Wiktionary and complemented these offline resources with automated queries to several (25) online dictionaries." ></td>
	<td class="line x" title="202:251	We start with Wikipedia definitions, then Wiktionary, and then, if not found, we turn to online dictionaries." ></td>
	<td class="line x" title="203:251	5 Evaluation and Results Potential applications of our framework include both the extension of existing lexical databases and the construction of new databases from a small set of seeds for each concept." ></td>
	<td class="line x" title="204:251	Consequently, in our evaluation we aim to check both the ability to extend nearly complete concepts and the ability to discover most of the concept given a few seeds." ></td>
	<td class="line x" title="205:251	Since in our current framework we extend a small subset of concepts rather than the whole database, we could not utilize application-based evaluation strategies such as performance in WSD tasks (Cuadros and Rigau, 2008)." ></td>
	<td class="line x" title="206:251	5.1 Human judgment evaluation In order to check how well we can extend existing concepts, we count and verify the quality of new concept terms discovered by the algorithm given complete concepts from WN." ></td>
	<td class="line x" title="207:251	Performing an automatic evaluation of such new terms is a challenging task, since there are no exhaustive term lists available." ></td>
	<td class="line x" title="208:251	Thus, in order to check how well newly added terms fit the concept definition, we have to use human judges." ></td>
	<td class="line x" title="209:251	We provided four human subjects with 24 lists of newly discovered terms, together with original concept definitions (written as descriptive natural language sentences) and asked them to rank (1-10, 10 being best) how well each of these terms fits the given definition." ></td>
	<td class="line x" title="210:251	We have instructed judges to accept common misspellings and reject words that are too general/narrow for the provided definition." ></td>
	<td class="line x" title="211:251	We mixed the discovered terms with equal amounts of terms from three control sets: (1) terms from the original WN concept; (2) randomly selected WN terms; (3) terms obtained by applying the single-language concept acquisition algorithm described in Section 3.3 in the source language." ></td>
	<td class="line x" title="212:251	Kappa inter-annotator agreement scores were above 0.6 for all tests below." ></td>
	<td class="line x" title="213:251	5.1.1 WordNet concept extension The middle column of Table 3 shows the judge scores and average amount of added terms for each source language." ></td>
	<td class="line x" title="214:251	In this case the algorithm was provided with complete term lists as concept definitions, and was requested to extend these lists." ></td>
	<td class="line x" title="215:251	We can see that while the scores for original WN terms are not perfect (7/10), single-language and cross-lingual concept extension achieve nearly the same scores." ></td>
	<td class="line x" title="216:251	However, the latter discovers many more new concept terms without reducing quality." ></td>
	<td class="line x" title="217:251	The difference becomes more substantial for Hebrew, which is a resource-poor source language, heavily affecting the performance of single-language concept extension methods." ></td>
	<td class="line x" title="218:251	The low ranks for WN reflect the ambiguity of definition of some of its classification subtrees." ></td>
	<td class="line x" title="219:251	Thus, for the body part concept defined in WordNet as any part of an organism such as an organ or extremity (which is not supposed to require domain-specific knowledge to identify) low scores were given (correctly) by judges to generic terms such as tissue, system, apparatus and process (process defined in WN as a natural prolongation or projection from a part of an organism), positioned in WN as direct hyponyms of body parts." ></td>
	<td class="line x" title="220:251	Low scores were also given to very specific terms like saddle (posterior part of the back of a domestic fowl) or very ambiguous terms like small (the slender part of the back)." ></td>
	<td class="line x" title="221:251	5.1.2 Seed-based concept extension The rightmost column of Table 3 shows similar information to the middle column, but when only the three most frequent terms from the original WN concept were given as concept definitions." ></td>
	<td class="line x" title="222:251	We can see that even given three words as seeds, the cross-lingual framework allows to discover many new terms." ></td>
	<td class="line x" title="223:251	Surprisingly, terms extracted by the cross-lingual framework achieve significantly higher scores not only in comparison to the singlelanguage algorithm but also in comparison to existing WN terms." ></td>
	<td class="line x" title="224:251	Thus while the native WN concept and single-language concept extension re858 sults get a score of 7/10, terms obtained by the cross-lingual framework obtain an average score of nearly 9/10." ></td>
	<td class="line x" title="225:251	This suggests that our cross-lingual framework can lead to better (from a human judgment point of view) assignment of terms to concepts, even in comparison to manual annotation." ></td>
	<td class="line x" title="226:251	Input all terms 3 terms English WordNet 7.2 7.2 Random 1.8 1.8 SingleLanguage 7.0(10) 7.8(18) Crosslingual 6.9(19) 8.8(26) Russian WordNet 7.8 7.8 Random 1.9 1.9 SingleLanguage 7.4(10) 8.1(16) Crosslingual 7.6(21) 9.0(29) Hebrew WordNet 7.0 7.0 Random 1.3 1.3 SingleLanguage 6.5(4) 7.5(6) Crosslingual 6.8(18) 8.9(24) Table 3: Human judgment scores for concept extension in three languages (110, 10 is best)." ></td>
	<td class="line x" title="227:251	The WordNet, Random and SingleLanguage rows provide corresponding baselines." ></td>
	<td class="line x" title="228:251	Average count of newly added terms are shown in parentheses." ></td>
	<td class="line x" title="229:251	Average original WN concept size in this set was 36 for English, 32 for Russian and 27 for Hebrew." ></td>
	<td class="line x" title="230:251	5.2 WordNet-based evaluation While human judgment evaluation provides a good indication for the quality of our framework, it has severe limitations." ></td>
	<td class="line x" title="231:251	Thus terms in many concepts require domain expertise to be properly labeled." ></td>
	<td class="line x" title="232:251	We have complemented human judgment evaluation with automated WN-based evaluation with a greater (150) number of concepts." ></td>
	<td class="line x" title="233:251	For each of the 150 concepts, we have applied our framework on a subset of the available terms, and estimated precision and recall of the resulting term list in comparison to the original WN term list." ></td>
	<td class="line x" title="234:251	The evaluation protocol and metrics were very similar to (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) which allowed us to do indirect comparison to previous work." ></td>
	<td class="line x" title="235:251	Table 4 shows precision and recall for this task comparing single-language concept extension and the cross-lingual framework." ></td>
	<td class="line x" title="236:251	We can see that in all cases, utilization of the latter greatly improves recall." ></td>
	<td class="line x" title="237:251	It also significantly outperforms the single-language pattern-based method introduced by (Davidov and Rappoport, 2006), which achieves average precision of 79.3 on a similar set in English (in comparison to 86.7 in this study)." ></td>
	<td class="line x" title="238:251	We can also see a decrease in precision when the algorithm is provided with 50% of the concept terms as input and had to discover the remaining 50%." ></td>
	<td class="line x" title="239:251	However, careful examination of the results shows that this decrease is due to discovery of additional correct terms not present in WordNet." ></td>
	<td class="line x" title="240:251	Input 50% terms 3 terms P R F P R F English SingleLanguage 89.2 75.9 82.0 80.6 15.2 25.6 CrossLingual 86.5 91.1 88.7 86.7 60.2 71.1 Russian SingleLanguage 91.3 69.0 78.6 82.1 18.3 29.9 CrossLingual 84.9 86.2 85.5 85.3 62.1 71.9 Hebrew SingleLanguage 93.8 38.6 54.7 90.2 5.7 10.7 CrossLingual 86.5 82.4 84.4 93.9 55.6 69.8 Table 4: WordNet-based precision (P) and recall (R) for concept extension." ></td>
	<td class="line x" title="241:251	5.3 Contribution of each language Each of the 45 languages we used influences the score of at least 5% of the discovered terms." ></td>
	<td class="line x" title="242:251	However, it is not apparent if all languages are indeed beneficial or if only a handful of languages can be used." ></td>
	<td class="line x" title="243:251	In order to check this point we have performed partial automated tests as described in Section 5.2, removing one language at a time." ></td>
	<td class="line x" title="244:251	We also tried to remove random subsets of 2-3 languages, comparing them to removal of one of them." ></td>
	<td class="line x" title="245:251	We saw that in each case removal of more languages caused a consistent (while sometimes minor) decrease both in precision and recall metrics." ></td>
	<td class="line x" title="246:251	Thus, each language contributes to the system." ></td>
	<td class="line x" title="247:251	6 Discussion We proposed a framework which given a set of terms defining a concept in some language, utilizes multilingual information available on the web in order to extend this list." ></td>
	<td class="line x" title="248:251	This method allows to take advantage of web data in many languages, requiring only multilingual dictionaries." ></td>
	<td class="line x" title="249:251	Our method was able to discover a substantially greater number of terms than state-of-the-art single language pattern-based concept extension methods, while retaining high precision." ></td>
	<td class="line x" title="250:251	We also showed that concepts obtained by this method tend to be more coherent in comparison to corresponding concepts in WN, a manually prepared resource." ></td>
	<td class="line x" title="251:251	Due to its relative language-independence and modest data requirements, this framework allows gathering required 859 concept information from the web even if it is scattered among different and relatively uncommon or resource-poor languages." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="E09-1077
Semi-Supervised Polarity Lexicon Induction
Rao, Delip;Ravichandran, Deepak;"></td>
	<td class="line x" title="1:202	Proceedings of the 12th Conference of the European Chapter of the ACL, pages 675682, Athens, Greece, 30 March  3 April 2009." ></td>
	<td class="line x" title="2:202	c2009 Association for Computational Linguistics Semi-Supervised Polarity Lexicon Induction Delip Rao Department of Computer Science Johns Hopkins University Baltimore, MD delip@cs.jhu.edu Deepak Ravichandran Google Inc. 1600 Amphitheatre Parkway Mountain View, CA deepakr@google.com Abstract We present an extensive study on the problem of detecting polarity of words." ></td>
	<td class="line x" title="3:202	We consider the polarity of a word to be either positive or negative." ></td>
	<td class="line x" title="4:202	For example, words such as good, beautiful, and wonderful are considered as positive words; whereas words such as bad, ugly, and sad are considered negative words." ></td>
	<td class="line x" title="5:202	We treat polarity detection as a semi-supervised label propagation problem in a graph." ></td>
	<td class="line x" title="6:202	In the graph, each node represents a word whose polarity is to be determined." ></td>
	<td class="line x" title="7:202	Each weighted edge encodes a relation that exists between two words." ></td>
	<td class="line x" title="8:202	Each node (word) can have two labels: positive or negative." ></td>
	<td class="line x" title="9:202	We study this framework in two different resource availability scenarios using WordNet and OpenOffice thesaurus when WordNet is not available." ></td>
	<td class="line x" title="10:202	We report our results on three different languages: English, French, and Hindi." ></td>
	<td class="line x" title="11:202	Our results indicate that label propagation improves significantly over the baseline and other semisupervised learning methods like Mincuts and Randomized Mincuts for this task." ></td>
	<td class="line x" title="12:202	1 Introduction Opinionated texts are characterized by words or phrases that communicate positive or negative sentiment." ></td>
	<td class="line x" title="13:202	Consider the following example of two movie reviews1 shown in Figure 1." ></td>
	<td class="line x" title="14:202	The positive review is peppered with words such as enjoyable, likeable, decent, breathtakingly and the negative Work done as a summer intern at Google Inc. 1Source: Live Free or Die Hard, rottentomatoes.com Figure 1: Movie Reviews with positive (left) and negative (right) sentiment." ></td>
	<td class="line x" title="15:202	comment uses words like ear-shattering, humorless, unbearable." ></td>
	<td class="line x" title="16:202	These terms and prior knowledge of their polarity could be used as features in a supervised classification framework to determine the sentiment of the opinionated text (E.g., (Esuli and Sebastiani, 2006))." ></td>
	<td class="line x" title="17:202	Thus lexicons indicating polarity of such words are indispensable resources not only in automatic sentiment analysis but also in other natural language understanding tasks like textual entailment." ></td>
	<td class="line x" title="18:202	This motivation was seen in the General Enquirer effort by Stone et al.(1966) and several others who manually construct such lexicons for the English language.2 While it is possible to manually build these resources for a language, the ensuing effort is onerous." ></td>
	<td class="line x" title="20:202	This motivates the need for automatic language-agnostic methods for building sentiment lexicons." ></td>
	<td class="line x" title="21:202	The importance of this problem has warranted several efforts in the past, some of which will be reviewed here." ></td>
	<td class="line x" title="22:202	We demonstrate the application of graph-based semi-supervised learning for induction of polarity lexicons." ></td>
	<td class="line x" title="23:202	We try several graph-based semi2The General Inquirer tries to classify English words along several dimensions, including polarity." ></td>
	<td class="line x" title="24:202	675 supervised learning methods like Mincuts, Randomized Mincuts, and Label Propagation." ></td>
	<td class="line x" title="25:202	In particular, we define a graph with nodes consisting of the words or phrases to be classified either as positive or negative." ></td>
	<td class="line x" title="26:202	The edges between the nodes encode some notion of similarity." ></td>
	<td class="line x" title="27:202	In a transductive fashion, a few of these nodes are labeled using seed examples and the labels for the remaining nodes are derived using these seeds." ></td>
	<td class="line x" title="28:202	We explore natural word-graph sources like WordNet and exploit different relations within WordNet like synonymy and hypernymy." ></td>
	<td class="line x" title="29:202	Our method is not just confined to WordNet; any source listing synonyms could be used." ></td>
	<td class="line x" title="30:202	To demonstrate this, we show the use of OpenOffice thesaurus  a free resource available in several languages.3 We begin by discussing some related work in Section 2 and briefly describe the learning methods we use, in Section 3." ></td>
	<td class="line x" title="31:202	Section 4 details our evaluation methodology along with detailed experiments for English." ></td>
	<td class="line x" title="32:202	In Section 5 we demonstrate results in French and Hindi, as an example of how the method could be easily applied to other languages as well." ></td>
	<td class="line x" title="33:202	2 Related Work The literature on sentiment polarity lexicon induction can be broadly classified into two categories, those based on corpora and the ones using WordNet." ></td>
	<td class="line x" title="34:202	2.1 Corpora based approaches One of the earliest work on learning polarity of terms was by Hatzivassiloglou and McKeown (1997) who deduce polarity by exploiting constraints on conjoined adjectives in the Wall Street Journal corpus." ></td>
	<td class="line x" title="35:202	For example, the conjunction and links adjectives of the same polarity while but links adjectives of opposite polarity." ></td>
	<td class="line x" title="36:202	However the applicability of this method for other important classes of sentiment terms like nouns and verbs is yet to be demonstrated." ></td>
	<td class="line x" title="37:202	Further they assume linguistic features specific to English." ></td>
	<td class="line oc" title="38:202	Wiebe (2000) uses Lin (1998a) style distributionally similar adjectives in a cluster-and-label process to generate sentiment lexicon of adjectives." ></td>
	<td class="line x" title="39:202	In a different work, Riloff et al.(2003) use manually derived pattern templates to extract subjective nouns by bootstrapping." ></td>
	<td class="line oc" title="41:202	3http://www.openoffice.org Another corpora based method due to Turney and Littman (2003) tries to measure the semantic orientation O(t) for a term t by O(t) = summationdisplay tiS+ PMI(t,ti) summationdisplay tjS PMI(t,tj) where S+ and S are minimal sets of polar terms that contain prototypical positive and negative terms respectively, and PMI(t,ti) is the pointwise mutual information (Lin, 1998b) between the terms t and ti." ></td>
	<td class="line x" title="42:202	While this method is general enough to be applied to several languages our aim was to develop methods that exploit more structured sources like WordNet to leverage benefits from the rich network structure." ></td>
	<td class="line x" title="43:202	Kaji and Kitsuregawa (2007) outline a method of building sentiment lexicons for Japanese using structural cues from HTML documents." ></td>
	<td class="line x" title="44:202	Apart from being very specific to Japanese, excessive dependence on HTML structure makes their method brittle." ></td>
	<td class="line x" title="45:202	2.2 WordNet based approaches These approaches use lexical relations defined in WordNet to derive sentiment lexicons." ></td>
	<td class="line x" title="46:202	A simple but high-precision method proposed by Kim and Hovy (2006) is to add all synonyms of a polar word with the same polarity and its antonyms with reverse polarity." ></td>
	<td class="line x" title="47:202	As demonstrated later, the method suffers from low recall and is unsuitable in situations when the seed polar words are too few  not uncommon in low resource languages." ></td>
	<td class="line x" title="48:202	In line with Turneys work, Kamps et." ></td>
	<td class="line x" title="49:202	al." ></td>
	<td class="line x" title="50:202	(2004) try to determine sentiments of adjectives in WordNet by measuring relative distance of the term from exemplars, such as good and bad." ></td>
	<td class="line x" title="51:202	The polarity orientation of a term t is measured as follows O(t) = d(t,good) d(t,bad)d(good,bad) where d(.)" ></td>
	<td class="line x" title="52:202	is a WordNet based relatedness measure (Pedersen et al., 2004)." ></td>
	<td class="line x" title="53:202	Again they report results for adjectives alone." ></td>
	<td class="line x" title="54:202	Another relevant example is the recent work by Mihalcea et." ></td>
	<td class="line x" title="55:202	al." ></td>
	<td class="line x" title="56:202	(2007) on multilingual sentiment analysis using cross-lingual projections." ></td>
	<td class="line x" title="57:202	This is achieved by using bridge resources like dictionaries and parallel corpora to build sentence subjectivity classifiers for the target language (Romanian)." ></td>
	<td class="line x" title="58:202	An interesting result from their work is that 676 only a small fraction of the lexicon entries preserve their polarities under translation." ></td>
	<td class="line x" title="59:202	The primary contributions of this paper are :  An application of graph-based semisupervised learning methods for inducing sentiment lexicons from WordNet and other thesauri." ></td>
	<td class="line x" title="60:202	The label propagation method naturally allows combining several relations from WordNet." ></td>
	<td class="line x" title="61:202	 Our approach works on all classes of words and not just adjectives  Though we report results for English, Hindi, and French, our methods can be easily replicated for other languages where WordNet is available.4 In the absence of WordNet, any thesaurus listing synonyms could be used." ></td>
	<td class="line x" title="62:202	We present one such result using the OpenOffice thesaurus  a freely available multilingual resource scarcely used in NLP literature." ></td>
	<td class="line x" title="63:202	3 Graph based semi-supervised learning Most natural language data has some structure that could be exploited even in the absence of fully annotated data." ></td>
	<td class="line x" title="64:202	For instance, documents are similar in the terms they contain, words could be synonyms of each other, and so on." ></td>
	<td class="line x" title="65:202	Such information can be readily encoded as a graph where the presence of an edge between two nodes would indicate a relationship between the two nodes and, optionally, the weight on the edge could encode strength of the relationship." ></td>
	<td class="line x" title="66:202	This additional information aids learning when very few annotated examples are present." ></td>
	<td class="line x" title="67:202	We review three well known graph based semi-supervised learning methods  mincuts, randomized mincuts, and label propagation  that we use in induction of polarity lexicons." ></td>
	<td class="line x" title="68:202	3.1 Mincuts A mincut of a weighted graph G(V,E) is a partitioning the vertices V into V1 and V2 such that sum of the edge weights of all edges between V1 and V2 is minimal (Figure 2)." ></td>
	<td class="line x" title="69:202	Mincuts for semi-supervised learning proposed by Blum and Chawla (2001) tries to classify datapoints by partitioning the similarity graph such that it minimizes the number of similar points being labeled differently." ></td>
	<td class="line x" title="70:202	Mincuts have been used 4As of this writing, WordNet is available for more than 40 world languages (http://www.globalwordnet.org) Figure 2: Semi-supervised classification using mincuts in semi-supervised learning for various tasks, including document level sentiment analysis (Pang and Lee, 2004)." ></td>
	<td class="line x" title="71:202	We explore the use of mincuts for the task of sentiment lexicon learning." ></td>
	<td class="line x" title="72:202	3.2 Randomized Mincuts An improvement to the basic mincut algorithm was proposed by Blum et." ></td>
	<td class="line x" title="73:202	al." ></td>
	<td class="line x" title="74:202	(2004)." ></td>
	<td class="line x" title="75:202	The deterministic mincut algorithm, solved using max-flow, produces only one of the several possible mincuts." ></td>
	<td class="line x" title="76:202	Some of these cuts could be skewed thereby negatively effecting the results." ></td>
	<td class="line x" title="77:202	As an extreme example consider the graph in Figure 3a." ></td>
	<td class="line x" title="78:202	Let the nodes with degree one be labeled as positive and negative respectively, and for the purpose of illustration let all edges be of the same weight." ></td>
	<td class="line x" title="79:202	The graph in Figure 3a." ></td>
	<td class="line x" title="80:202	can be partitioned in four equal cost cuts  two of which are shown in (b) and (c)." ></td>
	<td class="line x" title="81:202	The minFigure 3: Problem with mincuts cut algorithm, depending on the implementation, will return only one of the extreme cuts (as in (b)) while the desired classification might be as shown in Figure 3c." ></td>
	<td class="line x" title="82:202	The randomized mincut approach tries to address this problem by randomly perturbing the adjacency matrix by adding random noise.5 Mincut is then performed on this perturbed graph." ></td>
	<td class="line x" title="83:202	This is 5We use a Gaussian noise N(0,1)." ></td>
	<td class="line x" title="84:202	677 repeated several times and unbalanced partitions are discarded." ></td>
	<td class="line x" title="85:202	Finally the remaining partitions are used to deduce the final classification by majority voting." ></td>
	<td class="line x" title="86:202	In the unlikely event of the voting resulting in a tie, we refrain from making a decision thus favoring precision over recall." ></td>
	<td class="line x" title="87:202	3.3 Label propagation Another semi-supervised learning method we use is label propagation by Zhu and Ghahramani (2002)." ></td>
	<td class="line x" title="88:202	The label propagation algorithm is a transductive learning framework which uses a few examples, or seeds, to label a large number of unlabeled examples." ></td>
	<td class="line x" title="89:202	In addition to the seed examples, the algorithm also uses a relation between the examples." ></td>
	<td class="line x" title="90:202	This relation should have two requirements: 1." ></td>
	<td class="line x" title="91:202	It should be transitive." ></td>
	<td class="line x" title="92:202	2." ></td>
	<td class="line x" title="93:202	It should encode some notion of relatedness between the examples." ></td>
	<td class="line x" title="94:202	To name a few, examples of such relations include, synonymy, hypernymy, and similarity in some metric space." ></td>
	<td class="line x" title="95:202	This relation between the examples can be easily encoded as a graph." ></td>
	<td class="line x" title="96:202	Thus every node in the graph is an example and the edge represents the relation." ></td>
	<td class="line x" title="97:202	Also associated with each node, is a probability distribution over the labels for the node." ></td>
	<td class="line x" title="98:202	For the seed nodes, this distribution is known and kept fixed." ></td>
	<td class="line x" title="99:202	The aim is to derive the distributions for the remaining nodes." ></td>
	<td class="line x" title="100:202	Consider a graph G(V,E,W) with vertices V , edges E, and an n  n edge weight matrix W = [wij], where n = |V|." ></td>
	<td class="line x" title="101:202	The label propagation algorithm minimizes a quadratic energy function E = 12 summationdisplay (i,j)  E wij(yi yj)2 where yi and yj are the labels assigned to the nodes i and j respectively.6 Thus, to derive the labels at yi, we set yiE = 0 to obtain the following update equation yi = summationdisplay (i,j)E wijyj summationdisplay (i,j)E wij In practice, we use the following iterative algorithm as noted by Zhu and Ghahramani (2002)." ></td>
	<td class="line x" title="102:202	A 6For binary classification yk  {1,+1}." ></td>
	<td class="line x" title="103:202	nn stochastic transition matrix T is derived by row-normalizing W as follows: Tij = P(j  i) = wijsummationtextn k=1 wkj where Tij can be viewed as the transition probability from node j to node i. The algorithm proceeds as follows: 1." ></td>
	<td class="line x" title="104:202	Assign a n C matrix Y with the initial assignment of labels, where C is the number of classes." ></td>
	<td class="line x" title="105:202	2." ></td>
	<td class="line x" title="106:202	Propagate labels for all nodes by computing Y = TY 3." ></td>
	<td class="line x" title="107:202	Row-normalize Y such that each row adds up to one." ></td>
	<td class="line x" title="108:202	4." ></td>
	<td class="line x" title="109:202	Clamp the seed examples in Y to their original values 5." ></td>
	<td class="line x" title="110:202	Repeat 2-5 until Y converges." ></td>
	<td class="line x" title="111:202	There are several points to be noted." ></td>
	<td class="line x" title="112:202	First, we add a special label DEFAULT to existing set of labels and set P(DEFAULT| node = u) = 1 for all unlabeled nodes u. For all the seed nodes s with class label Lwe define P(L|node = s) = 1." ></td>
	<td class="line x" title="113:202	This ensures nodes that cannot be labeled at all7 will retain P(DEFAULT) = 1 thereby leading to a quick convergence." ></td>
	<td class="line x" title="114:202	Second, the algorithm produces a probability distribution over the labels for all unlabeled points." ></td>
	<td class="line x" title="115:202	This makes this method specially suitable for classifier combination approaches." ></td>
	<td class="line x" title="116:202	For this paper, we simply select the most likely label as the predicted label for the point." ></td>
	<td class="line x" title="117:202	Third, the algorithm eventually converges." ></td>
	<td class="line x" title="118:202	For details on the proof for convergence we refer the reader to Zhu and Ghahramani (2002)." ></td>
	<td class="line x" title="119:202	4 Evaluation and Experiments We use the General Inquirer (GI)8 data for evaluation." ></td>
	<td class="line x" title="120:202	General Inquirer is lexicon of English words hand-labeled with categorical information along several dimensions." ></td>
	<td class="line x" title="121:202	One such dimension is called valence, with 1915 words labeled Positiv (sic) and 2291 words labeled Negativ for words with positive and negative sentiments respectively." ></td>
	<td class="line x" title="122:202	Since we want to evaluate the performance of the 7As an example of such a situation, consider a disconnected component of unlabeled nodes with no seed in it." ></td>
	<td class="line x" title="123:202	8http://www.wjh.harvard.edu/inquirer/ 678 algorithms alone and not the recall issues in using WordNet, we only consider words from GI that also occur in WordNet." ></td>
	<td class="line x" title="124:202	This leaves us the distribution of words as enumerated in Table 1." ></td>
	<td class="line x" title="125:202	PoS type No." ></td>
	<td class="line x" title="126:202	of Positives No." ></td>
	<td class="line x" title="127:202	of Negatives Nouns 517 579 Verbs 319 562 Adjectives 547 438 Table 1: English evaluation data from General Inquirer All experiments reported in Sections 4.1 to 4.5 use the data described above with a 50-50 split so that the first half is used as seeds and the second half is used for test." ></td>
	<td class="line x" title="128:202	Note that all the experiments described below did not involve any parameter tuning thus obviating the need for a separate development test set." ></td>
	<td class="line x" title="129:202	The effect of number of seeds on learning is described in Section 4.6." ></td>
	<td class="line x" title="130:202	4.1 Kim-Hovy method and improvements Kim and Hovy (2006) enrich their sentiment lexicon from WordNet as follows." ></td>
	<td class="line x" title="131:202	Synonyms of a positive word are positive while antonyms are treated as negative." ></td>
	<td class="line x" title="132:202	This basic version suffers from a very poor recall as shown in the Figure 4 for adjectives (see iteration 1)." ></td>
	<td class="line x" title="133:202	The recall can be improved for a slight trade-off in precision if we re-run the above algorithm on the output produced at the previous level." ></td>
	<td class="line x" title="134:202	This could be repeated iteratively until there is no noticeable change in precision/recall." ></td>
	<td class="line x" title="135:202	We consider this as the best possible F1-score produced by the Kim-Hovy method." ></td>
	<td class="line x" title="136:202	The classwise F1 for this method is shown in Table 2." ></td>
	<td class="line x" title="137:202	We use these scores as our baseline." ></td>
	<td class="line x" title="138:202	Figure 4: Kim-Hovy method PoS type P R F1 Nouns 92.59 21.43 34.80 Verbs 87.89 38.31 53.36 Adjectives 92.95 31.71 47.28 Table 2: Precision/Recall/F1-scores for KimHovy method 4.2 Using prototypes We now consider measuring semantic orientation from WordNet using prototypical examples such as good and bad similar to Kamps et al.(2004)." ></td>
	<td class="line x" title="140:202	Kamps et." ></td>
	<td class="line x" title="141:202	al., report results only for adjectives though their method could be used for other part-of-speech types." ></td>
	<td class="line x" title="142:202	The results for using prototypes are listed in Table 3." ></td>
	<td class="line x" title="143:202	Note that the seed data was fully unused except for the examples good and bad." ></td>
	<td class="line x" title="144:202	We still test on the same test data as earlier for comparing results." ></td>
	<td class="line x" title="145:202	Also note that the recall need not be 100 in this case as we refrain from making a decision when d(t,good) = d(t,bad)." ></td>
	<td class="line x" title="146:202	PoS type P R F1 Nouns 48.03 99.82 64.86 Verbs 58.12 100.00 73.51 Adjectives 57.35 99.59 72.78 Table 3: Precision/Recall/F1-scores for prototype method 4.3 Using mincuts and randomized mincuts We now report results for mincuts and randomized mincuts algorithm using the WordNet synonym graph." ></td>
	<td class="line x" title="147:202	As seen in Table 4, we only observed a marginal improvement (for verbs) over mincuts by using randomized mincuts." ></td>
	<td class="line x" title="148:202	But the overall improvement of using graphbased semi-supervised learning methods over the Kim-Hovy and Prototype methods is quite significant." ></td>
	<td class="line x" title="149:202	4.4 Using label propagation We extract the synonym graph from WordNet with an edge between two nodes being defined iff one is a synonym of the other." ></td>
	<td class="line x" title="150:202	When label propagation is performed on this graph results in Table 5 are observed." ></td>
	<td class="line x" title="151:202	The results presented in Tables 2-5 need deeper inspection." ></td>
	<td class="line x" title="152:202	The iterated KimHovy method suffers from poor recall." ></td>
	<td class="line x" title="153:202	However both mincut methods and the prototype method by 679 P R F1 Nouns Mincut 68.25 100.00 81.13 RandMincut 68.32 99.09 80.08 Verbs Mincut 72.34 100.00 83.95 RandMincut 73.06 99.02 84.19 Adjectives Mincut 73.78 100.00 84.91 RandMincut 73.58 100.00 84.78 Table 4: Precision/Recall/F1-scores using mincuts and randomized mincuts PoS type P R F1 Nouns 82.55 58.58 58.53 Verbs 81.00 85.94 83.40 Adjectives 84.76 64.02 72.95 Table 5: Precision/Recall/F1-scores for Label Propogation Kamps et." ></td>
	<td class="line x" title="154:202	al., have high recall as they end up classifying every node as either positive or negative." ></td>
	<td class="line x" title="155:202	Note that the recall for randomized mincut is not 100 as we do not make a classification decision when there is a tie in majority voting (refer Section 3.2)." ></td>
	<td class="line x" title="156:202	Observe that the label propagation method performs significantly better than previous graph based methods in precision." ></td>
	<td class="line x" title="157:202	The reason for lower recall is attributed to the lack of connectivity between plausibly related nodes, thereby not facilitating the spread of labels from the labeled seed nodes to the unlabeled nodes." ></td>
	<td class="line x" title="158:202	We address this problem by adding additional edges to the synonym graph in the next section." ></td>
	<td class="line x" title="159:202	4.5 Incorporating hypernyms The main reason for low recall in label propagation is that the WordNet synonym graph is highly disconnected." ></td>
	<td class="line x" title="160:202	Even nodes which are logically related have paths missing between them." ></td>
	<td class="line x" title="161:202	For example the positive nouns compliment and laud belong to different synonym subgraphs without a path between them." ></td>
	<td class="line x" title="162:202	But incorporating the hypernym edges the two are connected by the noun praise." ></td>
	<td class="line x" title="163:202	So, we incorporated hypernyms of every node to improve connectivity." ></td>
	<td class="line x" title="164:202	Performing label propagation on this combined graph gives much better results (Table 6) with much higher recall and even slightly better precision." ></td>
	<td class="line x" title="165:202	In Table 6., we do not report results for adjectives as WordNet does not define hypernyms for adjectives." ></td>
	<td class="line x" title="166:202	A natural quesPoS type P R F1 Nouns 83.88 99.64 91.08 Verbs 85.49 100.00 92.18 Adjectives N/A N/A N/A Table 6: Effect of adding hypernyms tion to ask is if we can use other WordNet relations too." ></td>
	<td class="line x" title="167:202	We will defer this until section 6." ></td>
	<td class="line x" title="168:202	4.6 Effect of number of seeds The results reported in Sections 4.1 to 4.5 fixed the number of seeds." ></td>
	<td class="line x" title="169:202	We now investigate the performance of the various methods on the number of seeds used." ></td>
	<td class="line x" title="170:202	In particular, we are interested in performance under conditions when the number of seeds are few  which is the motivation for using semi-supervised learning in the first place." ></td>
	<td class="line x" title="171:202	Figure 5 presents our results for English." ></td>
	<td class="line x" title="172:202	Observe that Label Propagation performs much better than our baseline even when the number of seeds is as low as ten." ></td>
	<td class="line x" title="173:202	Thus label propagation is especially suited when annotation data is extremely sparse." ></td>
	<td class="line x" title="174:202	One reason for mincuts performing badly with few seeds is because they generate degenrate cuts." ></td>
	<td class="line x" title="175:202	5 Adapting to other languages In order to demonstrate the ease of adaptability of our method for other languages, we used the Hindi WordNet9 to derive the adjective synonym graph." ></td>
	<td class="line x" title="176:202	We selected 489 adjectives at random from a list of 10656 adjectives and this list was annotated by two native speakers of the language." ></td>
	<td class="line x" title="177:202	The annotated list was then split 50-50 into seed and test sets." ></td>
	<td class="line x" title="178:202	Label propagation was performed using the seed list and evaluated on the test list." ></td>
	<td class="line x" title="179:202	The results are listed in Table 7." ></td>
	<td class="line x" title="180:202	Hindi P R F1 90.99 95.10 93.00 Table 7: Evaluation on Hindi dataset WordNet might not be freely available for all languages or may not exist." ></td>
	<td class="line x" title="181:202	In such cases building graph from an existing thesaurus might also suffice." ></td>
	<td class="line x" title="182:202	As an example, we consider French." ></td>
	<td class="line x" title="183:202	Although the French WordNet is available10, we 9http://www.cfilt.iitb.ac.in/wordnet/webhwn/ 10http://www.illc.uva.nl/EuroWordNet/consortiumewn.html 680 Figure 5: Effect of number of seeds on the F-score for Nouns, Verbs, and Adjectives." ></td>
	<td class="line x" title="184:202	The X-axis is number of seeds and the Y-axis is the F-score." ></td>
	<td class="line x" title="185:202	found the cost prohibitive to obtain it." ></td>
	<td class="line x" title="186:202	Observe that if we are using only the synonymy relation in WordNet then any thesaurus can be used instead." ></td>
	<td class="line x" title="187:202	To demonstrate this, we consider the OpenOffice thesaurus for French, that is freely available." ></td>
	<td class="line x" title="188:202	The synonym graph of French adjectives has 9707 vertices and 1.6M edges." ></td>
	<td class="line x" title="189:202	We manually annotated a list of 316 adjectives and derived seed and test sets using a 50-50 split." ></td>
	<td class="line x" title="190:202	The results of label propagation on such a graph is shown in Table 8." ></td>
	<td class="line x" title="191:202	French P R F1 73.65 93.67 82.46 Table 8: Evaluation on French dataset The reason for better results in Hindi compared to French can be attributed to (1) higher interannotator agreement ( = 0.7) in Hindi compared that in French ( = 0.55).11 (2) The Hindi experiment, like English, used WordNet while the French experiment was performed on graphs derived from the OpenOffice thesaurus due lack of freely available French WordNet." ></td>
	<td class="line x" title="192:202	11We do not have  scores for English dataset derived from the Harvard Inquirer project." ></td>
	<td class="line x" title="193:202	6 Conclusions and Future Work This paper demonstrated the utility of graph-based semi-supervised learning framework for building sentiment lexicons in a variety of resource availability situations." ></td>
	<td class="line x" title="194:202	We explored how the structure of WordNet could be leveraged to derive polarity lexicons." ></td>
	<td class="line x" title="195:202	The paper combines, for the first time, relationships like synonymy and hypernymy to improve label propagation results." ></td>
	<td class="line x" title="196:202	All of our methods are independent of language as shown in the French and Hindi cases." ></td>
	<td class="line x" title="197:202	We demonstrated applicability of our approach on alternative thesaurus-derived graphs when WordNet is not freely available, as in the case of French." ></td>
	<td class="line x" title="198:202	Although our current work uses WordNet and other thesauri, in resource poor situations when only monolingual raw text is available we can perform label propagation on nearest neighbor graphs derived directly from raw text using distributional similarity methods." ></td>
	<td class="line x" title="199:202	This is work in progress." ></td>
	<td class="line x" title="200:202	We are also currently working on the possibility of including WordNet relations other than synonymy and hypernymy." ></td>
	<td class="line x" title="201:202	One relation that is interesting and useful is antonymy." ></td>
	<td class="line x" title="202:202	Antonym edges cannot be added in a straight-forward way to the 681 graph for label propagation as antonymy encodes negative similarity (or dissimilarity) and the dissimilarity relation is not transitive." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N09-2059
Estimating and Exploiting the Entropy of Sense Distributions
Jin, Peng;McCarthy, Diana;Koeling, Rob;Carroll, John;"></td>
	<td class="line x" title="1:78	Proceedings of NAACL HLT 2009: Short Papers, pages 233236, Boulder, Colorado, June 2009." ></td>
	<td class="line x" title="2:78	c 2009 Association for Computational Linguistics Estimating and Exploiting the Entropy of Sense Distributions Peng Jin Institute of Computational Linguistics Peking University Beijing China jandp@pku.edu.cn Diana McCarthy, Rob Koeling and John Carroll University of Sussex Falmer, East Sussex BN1 9QJ, UK {dianam,robk,johnca}@sussex.ac.uk Abstract Word sense distributions are usually skewed." ></td>
	<td class="line x" title="3:78	Predicting the extent of the skew can help a word sense disambiguation (WSD) system determine whether to consider evidence from the local context or apply the simple yet effective heuristic of using the first (most frequent) sense." ></td>
	<td class="line x" title="4:78	In this paper, we propose a method to estimate the entropy of a sense distribution to boost the precision of a first sense heuristic by restricting its application to words with lower entropy." ></td>
	<td class="line x" title="5:78	We show on two standard datasets that automatic prediction of entropy can increase the performance of an automatic first sense heuristic." ></td>
	<td class="line x" title="6:78	1 Introduction Word sense distributions are typically skewed and WSD systems do best when they exploit this tendency." ></td>
	<td class="line x" title="7:78	This is usually done by estimating the most frequent sense (MFS) for each word from a training corpus and using that sense as a back-off strategy for a word when there is no convincing evidence from the context." ></td>
	<td class="line x" title="8:78	This is known as the MFS heuristic 1 and is very powerful since sense distributions are usually skewed." ></td>
	<td class="line x" title="9:78	The heuristic becomes particularly hard to beat for words with highly skewed sense distributions (Yarowsky and Florian, 2002)." ></td>
	<td class="line x" title="10:78	Although the MFS can be estimated from tagged corpora, there are always cases where there is insufficient data, or where the data is inappropriate, for example because 1It is also referred to as the first sense heuristic in the WSD literature and in this paper." ></td>
	<td class="line x" title="11:78	it comes from a very different domain." ></td>
	<td class="line x" title="12:78	This has motivated some recent work attempting to estimate the distributions automatically (McCarthy et al., 2004; Lapata and Keller, 2007)." ></td>
	<td class="line x" title="13:78	This paper examines the case for determining the skew of a word sense distribution by estimating entropy and then using this to increase the precision of an unsupervised first sense heuristic by restricting application to those words where the system can automatically detect that it has the most chance." ></td>
	<td class="line x" title="14:78	We use a method based on that proposed by McCarthy et al.(2004) as this approach does not require hand-labelled corpora." ></td>
	<td class="line x" title="16:78	The method could easily be adapted to other methods for predicing predominant sense." ></td>
	<td class="line x" title="17:78	2 Method Given a listing of senses from an inventory, the method proposed by McCarthy et al.(2004) provides a prevalence ranking score to produce a MFS heuristic." ></td>
	<td class="line x" title="19:78	We make a slight modification to McCarthy et al.s prevalence score and use it to estimate the probability distribution over the senses of a word." ></td>
	<td class="line x" title="20:78	We use the same resources as McCarthy et al.(2004): a distributional similarity thesaurus and a WordNet semantic similarity measure." ></td>
	<td class="line oc" title="22:78	The thesaurus was produced using the metric described by Lin (1998) with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002)." ></td>
	<td class="line x" title="23:78	The thesaurus consists of entries for each word (w) with the top 50 nearest neighbours to w, where the neighbours are words ranked by the distributional similarity that 233 they share with w. The WordNet similarity score is obtained with the jcn measure (Jiang and Conrath, 1997) using the WordNet Similarity Package 0.05 (Patwardhan and Pedersen, 2003) and WordNet version 1.6." ></td>
	<td class="line x" title="24:78	The jcn measure needs word frequency information, which we obtained from the BNC." ></td>
	<td class="line x" title="25:78	2.1 Estimates of Predominance, Probability and Entropy Following McCarthy et al.(2004), we calculate prevalence of each sense of the word (w) using a weighted sum of the distributional similarity scores of the top 50 neighbours of w. The sense of w that has the highest value is the automatically detected MFS (predominant sense)." ></td>
	<td class="line x" title="27:78	The weights are determined by the WordNet similarity between the sense in question and the neighbour." ></td>
	<td class="line x" title="28:78	We make a modification to the original method by multiplying the weight by the inverse rank of the neighbour from the list of 50 neighbours." ></td>
	<td class="line x" title="29:78	This modification magnifies the contribution to each sense depending on the rank of the neighbour while still allowing a neighbour to contribute to all senses that it relates too." ></td>
	<td class="line x" title="30:78	We verified the effect of this change compared to the original ranking score by measuring cross-entropy." ></td>
	<td class="line x" title="31:78	2 Let Nw = n1,n2 nk denote the ordered set of the top k = 50 neighbours of w according to the distributional similarity thesaurus, senses(w) is the set of senses of w and dss(w,nj) is the distributional similarity score of a word w and its jth neighbour." ></td>
	<td class="line x" title="32:78	Let wsi be a sense of w then wnss(wsi,nj) is the maximum WordNet similarity score between wsi and the WordNet sense of the neighbour (nj) that maximises this score." ></td>
	<td class="line x" title="33:78	The prevalence score is calculated as follows with 1rankn j being our modification to McCarthy et al. Prevalence Score(wsi) =njNw dss(w,nj) wnss(wsi,nj) wsiprimesenses(w)wnss(wsiprime,nj) 1 ranknj (1) To turn this score into a probability estimate we sum the scores over all senses of a word and the probability for a sense is the original score divided by this sum: 2Our modified version of the score gave a lower crossentropy with SemCor compared to that in McCarthy et al. The result was highly significant with p < 0.01 on the t-test." ></td>
	<td class="line x" title="34:78	p(wsi) = prevalence score(wsi) wsjw prevalence score(wsj) (2) To smooth the data, we evenly distribute 1/10 of the smallest prevalence score to all senses with a undefined prevalence score values." ></td>
	<td class="line x" title="35:78	Entropy is measured as: H(senses(w)) =  wsisenses(w) p(wsi)log(p(wsi)) using our estimate ( p) for the probability distribution p over the senses of w. 3 Experiments We conducted two experiments to evaluate the benefit of using our estimate of entropy to restrict application of the MFS heuristic." ></td>
	<td class="line x" title="36:78	The two experiments are conducted on the polysemous nouns in SemCor and the nouns in the SENSEVAL-2 English all words task (we will refer to this as SE2-EAW)." ></td>
	<td class="line x" title="37:78	3.1 SemCor For this experiment we used all the polysemous nouns in Semcor 1.6 (excluding multiwords and proper nouns)." ></td>
	<td class="line x" title="38:78	We depart slightly from (McCarthy et al., 2004) in including all polysemous nouns whereas they limited the experiment to those with a frequency in SemCor of 3 or more and where there is one sense with a higher frequency than the others." ></td>
	<td class="line x" title="39:78	Table 1 shows the precision of finding the predominant sense using equation 1 with respect to different entropy thresholds." ></td>
	<td class="line x" title="40:78	At each threshold, the MFS in Semcor provides the upper-bound (UB)." ></td>
	<td class="line x" title="41:78	The random baseline (RBL) is computed by selecting one of the senses of the target word randomly as the predominant sense." ></td>
	<td class="line x" title="42:78	As we hypothesized, precision is higher when the entropy of the sense distribution is lower, which is an encouraging result given that the entropy is automatically estimated." ></td>
	<td class="line x" title="43:78	The performance of the random baseline is higher at lower entropy which shows that the task is easier and involves a lower degree of polysemy of the target words." ></td>
	<td class="line x" title="44:78	However, the gains over the random baseline are greater at lower entropy levels indicating that the merits of detecting the skew of the distribution cannot all be due to lower polysemy levels." ></td>
	<td class="line x" title="45:78	234 H precision # () eq 1 RBL UB tokens 0.5 0 0.9 80.3 50.0 84.8 466 0.95 85.1 50.0 90.9 1360 1 68.5 50.0 87.4 9874 1.5 67.6 42.6 86.9 11287 2 58.0 36.7 79.5 25997 2.5 55.7 34.4 77.6 31599 3.0 50.2 30.6 73.4 41401 4.0 47.6 28.5 70.8 46987 5.0 (all) 47.3 27.3 70.5 47539 Table 1: First sense heuristic on SemCor Freq P #tokens 1 45.9 1132 5 50.1 5765 10 50.7 10736 100 49.4 39543 1000(all) 47.3 47539 #senses P #tokens 2 67.2 10736 5 55.4 31181 8 50.1 41393 12 47.8 46041 30(all) 47.3 47539 Table 2: Precision (P) of equation 1 on SemCor with respect to frequency and polysemy We also conducted a frequency and polysemy analysis shown in Table 2 to demonstrate that the increase in precision is not all due to frequency or polysemy." ></td>
	<td class="line x" title="46:78	This is important, since both frequency and polysemy level (assuming a predefined sense inventory) could be obtained without the need for automatic estimation." ></td>
	<td class="line x" title="47:78	As we can see, while precision is higher for lower polysemy, the automatic estimate of entropy can provide a greater increase in precision than polysemy, and frequency does not seem to be strongly correlated with precision." ></td>
	<td class="line x" title="48:78	3.2 SENSEVAL-2 English All Words Dataset The SE2-EAW task provides a hand-tagged test suite of 5,000 words of running text from three articles from the Penn Treebank II (Palmer et al., 2001)." ></td>
	<td class="line x" title="49:78	Again, we examine whether precision of the MFS H precision # () eq 1 RBL SC UB tokens 0.5 0 0.9 1 50.0 1 1 7 0.95 94.7 50.0 94.7 1 19 1 69.6 50.0 81.3 94.6 112 1.5 68.0 49.0 81.3 93.8 128 2 69.6 34.7 68.2 87.7 421 2.5 65.0 33.0 65.0 86.5 488 3.0 56.6 27.5 60.8 80.1 687 4.0 52.6 25.6 58.8 79.2 766 5.0 (all) 51.5 25.6 58.5 79.3 769 Table 3: First sense heuristic on SE2-EAW heuristic can be increased by restricting application depending on entropy." ></td>
	<td class="line x" title="50:78	We use the same resources as for the SemCor experiment." ></td>
	<td class="line x" title="51:78	3 Table 3 gives the results." ></td>
	<td class="line x" title="52:78	The most frequent sense (MFS) from SE2-EAW itself provides the upper-bound (UB)." ></td>
	<td class="line x" title="53:78	We also compare performance with the Semcor MFS (SC)." ></td>
	<td class="line x" title="54:78	Performance is close to the Semcor MFS while not relying on any manual tagging." ></td>
	<td class="line x" title="55:78	As before, precision increases significantly for words with low estimated entropy, and the gains over the random baseline are higher compared to the gains including all words." ></td>
	<td class="line x" title="56:78	4 Related Work There is promising related work on determining the predominant sense for a MFS heuristic (Lapata and Keller, 2007; Mohammad and Hirst, 2006) but our work is the first to use the ranking score to estimate entropy and apply it to determine the confidence in the MFS heuristic." ></td>
	<td class="line x" title="57:78	It is likely that these methods would also have increased precision if the ranking scores were used to estimate entropy." ></td>
	<td class="line x" title="58:78	We leave such investigations for further work." ></td>
	<td class="line x" title="59:78	Chan and Ng (2005) estimate word sense distributions and demonstrate that sense distribution estimation improves a supervised WSD classifier." ></td>
	<td class="line x" title="60:78	They use three sense distribution methods, including that of McCarthy et al.(2004)." ></td>
	<td class="line x" title="62:78	While the other two methods outperform the McCarthy et al. method, 3We also used a tool for mapping from WordNet 1.7 to WordNet 1.6 (Daude et al., 2000) to map the SE2-EAW noun data (originally distributed with 1.7 sense numbers) to 1.6 sense numbers." ></td>
	<td class="line x" title="63:78	235 they rely on parallel training data and are not applicable on 9.6% of the test data for which there are no training examples." ></td>
	<td class="line x" title="64:78	Our method does not require parallel training data." ></td>
	<td class="line x" title="65:78	Agirre and Martnez (2004) show that sense distribution estimation is very important for both supervised and unsupervised WSD." ></td>
	<td class="line x" title="66:78	They acquire tagged examples on a large scale by querying Google with monosemous synonyms of the word senses in question." ></td>
	<td class="line x" title="67:78	They show that the method of McCarthy et al.(2004) can be used to produce a better sampling technique than relying on the bias from web data or randomly selecting the same number of examples for each sense." ></td>
	<td class="line x" title="69:78	Our work similarly shows that the automatic MFS is an unsupervised alternative to SemCor but our work does not focus on sampling but on an estimation of confidence in an automatic MFS heuristic." ></td>
	<td class="line x" title="70:78	5 Conclusions We demonstrate that our variation of the McCarthy et al.(2004) method for finding a MFS heuristic can be used for estimating the entropy of a sense distribution which can be exploited to boost precision." ></td>
	<td class="line x" title="72:78	Words which are estimated as having lower entropy in general get higher precision." ></td>
	<td class="line x" title="73:78	This suggests that automatic estimation of entropy is a good criterion for getting higher precision." ></td>
	<td class="line x" title="74:78	This is in agreement with Kilgarriff and Rosenzweig (2000) who demonstrate that entropy is a good measure of the difficulty of WSD tasks, though their measure of entropy was taken from the gold-standard distribution itself." ></td>
	<td class="line x" title="75:78	As future work, we want to compare this approach of estimating entropy with other methods for estimating sense distributions which do not require hand-labelled data or parallel texts." ></td>
	<td class="line x" title="76:78	Currently, we disregard local context." ></td>
	<td class="line x" title="77:78	We wish to couple the confidence in the MFS with contextual evidence and investigate application on coarse-grained datasets." ></td>
	<td class="line x" title="78:78	Acknowledgements This work was funded by the China Scholarship Council, the National Grant Fundamental Research 973 Program of China: Grant No. 2004CB318102, the UK EPSRC project EP/C537262 Ranking Word Senses for Disambiguation, and a UK Royal Society Dorothy Hodgkin Fellowship to the second author." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-1031
A Metric-based Framework for Automatic Taxonomy Induction
Yang, Hui;Callan, James P.;"></td>
	<td class="line x" title="1:255	Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 271279, Suntec, Singapore, 2-7 August 2009." ></td>
	<td class="line x" title="2:255	c2009 ACL and AFNLP A Metric-based Framework for Automatic Taxonomy Induction   Hui Yang Language Technologies Institute School of Computer Science Carnegie Mellon University huiyang@cs.cmu.edu Jamie Callan Language Technologies Institute School of Computer Science Carnegie Mellon University callan@cs.cmu.edu   Abstract This paper presents a novel metric-based framework for the task of automatic taxonomy induction." ></td>
	<td class="line x" title="3:255	The framework incrementally clusters terms based on ontology metric, a score indicating semantic distance; and transforms the task into a multi-criteria optimization based on minimization of taxonomy structures and modeling of term abstractness." ></td>
	<td class="line x" title="4:255	It combines the strengths of both lexico-syntactic patterns and clustering through incorporating heterogeneous features." ></td>
	<td class="line x" title="5:255	The flexible design of the framework allows a further study on which features are the best for the task under various conditions." ></td>
	<td class="line x" title="6:255	The experiments not only show that our system achieves higher F1-measure than other state-of-the-art systems, but also reveal the interaction between features and various types of relations, as well as the interaction between features and term abstractness." ></td>
	<td class="line x" title="7:255	1 Introduction Automatic taxonomy induction is an important task in the fields of Natural Language Processing, Knowledge Management, and Semantic Web." ></td>
	<td class="line x" title="8:255	It has been receiving increasing attention because semantic taxonomies, such as WordNet (Fellbaum, 1998), play an important role in solving knowledge-rich problems, including question answering (Harabagiu et al., 2003) and textual entailment (Geffet and Dagan, 2005)." ></td>
	<td class="line x" title="9:255	Nevertheless, most existing taxonomies are manually created at great cost." ></td>
	<td class="line x" title="10:255	These taxonomies are rarely complete; it is difficult to include new terms in them from emerging or rapidly changing domains." ></td>
	<td class="line x" title="11:255	Moreover, manual taxonomy construction is time-consuming, which may make it unfeasible for specialized domains and personalized tasks." ></td>
	<td class="line x" title="12:255	Automatic taxonomy induction is a solution to augment existing resources and to produce new taxonomies for such domains and tasks." ></td>
	<td class="line x" title="13:255	Automatic taxonomy induction can be decomposed into two subtasks: term extraction and relation formation." ></td>
	<td class="line x" title="14:255	Since term extraction is relatively easy, relation formation becomes the focus of most research on automatic taxonomy induction." ></td>
	<td class="line x" title="15:255	In this paper, we also assume that terms in a taxonomy are given and concentrate on the subtask of relation formation." ></td>
	<td class="line x" title="16:255	Existing work on automatic taxonomy induction has been conducted under a variety of names, such as ontology learning, semantic class learning, semantic relation classification, and relation extraction." ></td>
	<td class="line x" title="17:255	The approaches fall into two main categories: pattern-based and clusteringbased." ></td>
	<td class="line x" title="18:255	Pattern-based approaches define lexicalsyntactic patterns for relations, and use these patterns to discover instances of relations." ></td>
	<td class="line x" title="19:255	Clustering-based approaches hierarchically cluster terms based on similarities of their meanings usually represented by a vector of quantifiable features." ></td>
	<td class="line x" title="20:255	Pattern-based approaches are known for their high accuracy in recognizing instances of relations if the patterns are carefully chosen, either manually (Berland and Charniak, 1999; Kozareva et al., 2008) or via automatic bootstrapping (Hearst, 1992; Widdows and Dorow, 2002; Girju et al., 2003)." ></td>
	<td class="line x" title="21:255	The approaches, however, suffer from sparse coverage of patterns in a given corpus." ></td>
	<td class="line x" title="22:255	Recent studies (Etzioni et al., 2005; Kozareva et al., 2008) show that if the size of a corpus, such as the Web, is nearly unlimited, a pattern has a higher chance to explicitly appear in the corpus." ></td>
	<td class="line x" title="23:255	However, corpus size is often not that large; hence the problem still exists." ></td>
	<td class="line x" title="24:255	Moreover, since patterns usually extract instances in pairs, the approaches suffer from the problem of inconsistent concept chains after connecting pairs of instances to form taxonomy hierarchies." ></td>
	<td class="line x" title="25:255	Clustering-based approaches have a main advantage that they are able to discover relations 271 which do not explicitly appear in text." ></td>
	<td class="line x" title="26:255	They also avoid the problem of inconsistent chains by addressing the structure of a taxonomy globally from the outset." ></td>
	<td class="line x" title="27:255	Nevertheless, it is generally believed that clustering-based approaches cannot generate relations as accurate as pattern-based approaches." ></td>
	<td class="line x" title="28:255	Moreover, their performance is largely influenced by the types of features used." ></td>
	<td class="line oc" title="29:255	The common types of features include contextual (Lin, 1998), co-occurrence (Yang and Callan, 2008), and syntactic dependency (Pantel and Lin, 2002; Pantel and Ravichandran, 2004)." ></td>
	<td class="line x" title="30:255	So far there is no systematic study on which features are the best for automatic taxonomy induction under various conditions." ></td>
	<td class="line x" title="31:255	This paper presents a metric-based taxonomy induction framework." ></td>
	<td class="line x" title="32:255	It combines the strengths of both pattern-based and clustering-based approaches by incorporating lexico-syntactic patterns as one type of features in a clustering framework." ></td>
	<td class="line x" title="33:255	The framework integrates contextual, co-occurrence, syntactic dependency, lexical-syntactic patterns, and other features to learn an ontology metric, a score indicating semantic distance, for each pair of terms in a taxonomy; it then incrementally clusters terms based on their ontology metric scores." ></td>
	<td class="line x" title="34:255	The incremental clustering is transformed into an optimization problem based on two assumptions: minimum evolution and abstractness." ></td>
	<td class="line x" title="35:255	The flexible design of the framework allows a further study of the interaction between features and relations, as well as that between features and term abstractness." ></td>
	<td class="line x" title="36:255	2 Related Work There has been a substantial amount of research on automatic taxonomy induction." ></td>
	<td class="line x" title="37:255	As we mentioned earlier, two main approaches are patternbased and clustering-based." ></td>
	<td class="line x" title="38:255	Pattern-based approaches are the main trend for automatic taxonomy induction." ></td>
	<td class="line x" title="39:255	Though suffering from the problems of sparse coverage and inconsistent chains, they are still popular due to their simplicity and high accuracy." ></td>
	<td class="line x" title="40:255	They have been applied to extract various types of lexical and semantic relations, including is-a, part-of, sibling, synonym, causal, and many others." ></td>
	<td class="line x" title="41:255	Pattern-based approaches started from and still pay a great deal of attention to the most common is-a relations." ></td>
	<td class="line x" title="42:255	Hearst (1992) pioneered using a hand crafted list of hyponym patterns as seeds and employing bootstrapping to discover is-a relations." ></td>
	<td class="line x" title="43:255	Since then, many approaches (Mann, 2002; Etzioni et al., 2005; Snow et al., 2005) have used Hearst-style patterns in their work on is-a relations." ></td>
	<td class="line x" title="44:255	For instance, Mann (2002) extracted is-a relations for proper nouns by Hearststyle patterns." ></td>
	<td class="line x" title="45:255	Pantel et al.(2004) extended is-a relation acquisition towards terascale, and automatically identified hypernym patterns by minimal edit distance." ></td>
	<td class="line x" title="47:255	Another common relation is sibling, which describes the relation of sharing similar meanings and being members of the same class." ></td>
	<td class="line x" title="48:255	Terms in sibling relations are also known as class members or similar terms." ></td>
	<td class="line x" title="49:255	Inspired by the conjunction and appositive structures, Riloff and Shepherd (1997), Roark and Charniak (1998) used cooccurrence statistics in local context to discover sibling relations." ></td>
	<td class="line x" title="50:255	The KnowItAll system (Etzioni et al., 2005) extended the work in (Hearst, 1992) and bootstrapped patterns on the Web to discover siblings; it also ranked and selected the patterns by statistical measures." ></td>
	<td class="line x" title="51:255	Widdows and Dorow (2002) combined symmetric patterns and graph link analysis to discover sibling relations." ></td>
	<td class="line x" title="52:255	Davidov and Rappoport (2006) also used symmetric patterns for this task." ></td>
	<td class="line x" title="53:255	Recently, Kozareva et al.(2008) combined a double-anchored hyponym pattern with graph structure to extract siblings." ></td>
	<td class="line x" title="55:255	The third common relation is part-of." ></td>
	<td class="line x" title="56:255	Berland and Charniak (1999) used two meronym patterns to discover part-of relations, and also used statistical measures to rank and select the matching instances." ></td>
	<td class="line x" title="57:255	Girju et al.(2003) took a similar approach to Hearst (1992) for part-of relations." ></td>
	<td class="line x" title="59:255	Other types of relations that have been studied by pattern-based approaches include questionanswer relations (such as birthdates and inventor) (Ravichandran and Hovy, 2002), synonyms and antonyms (Lin et al., 2003), general purpose analogy (Turney et al., 2003), verb relations (including similarity, strength, antonym, enablement and temporal) (Chklovski and Pantel, 2004), entailment (Szpektor et al., 2004), and more specific relations, such as purpose, creation (Cimiano and Wenderoth, 2007), LivesIn, and EmployedBy (Bunescu and Mooney , 2007)." ></td>
	<td class="line x" title="60:255	The most commonly used technique in pattern-based approaches is bootstrapping (Hearst, 1992; Etzioni et al., 2005; Girju et al., 2003; Ravichandran and Hovy, 2002; Pantel and Pennacchiotti, 2006)." ></td>
	<td class="line x" title="61:255	It utilizes a few man-crafted seed patterns to extract instances from corpora, then extracts new patterns using these instances, and continues the cycle to find new instances and new patterns." ></td>
	<td class="line x" title="62:255	It is effective and scalable to large datasets; however, uncontrolled bootstrapping 272 soon generates undesired instances once a noisy pattern brought into the cycle." ></td>
	<td class="line x" title="63:255	To aid bootstrapping, methods of pattern quality control are widely applied." ></td>
	<td class="line x" title="64:255	Statistical measures, such as point-wise mutual information (Etzioni et al., 2005; Pantel and Pennacchiotti, 2006) and conditional probability (Cimiano and Wenderoth, 2007),   have been shown to be effective to rank and select patterns and instances." ></td>
	<td class="line x" title="65:255	Pattern quality control is also investigated by using WordNet (Girju et al., 2006), graph structures built among terms (Widdows and Dorow, 2002; Kozareva et al., 2008), and pattern clusters (Davidov and Rappoport, 2008)." ></td>
	<td class="line oc" title="66:255	Clustering-based approaches usually represent word contexts as vectors and cluster words based on similarities of the vectors (Brown et al., 1992; Lin, 1998)." ></td>
	<td class="line x" title="67:255	Besides contextual features, the vectors can also be represented by verb-noun relations (Pereira et al., 1993), syntactic dependency (Pantel and Ravichandran, 2004; Snow et al., 2005), co-occurrence (Yang and Callan, 2008), conjunction and appositive features (Caraballo, 1999)." ></td>
	<td class="line x" title="68:255	More work is described in (Buitelaar et al., 2005; Cimiano and Volker, 2005)." ></td>
	<td class="line x" title="69:255	Clustering-based approaches allow discovery of relations which do not explicitly appear in text." ></td>
	<td class="line x" title="70:255	Pantel and Pennacchiotti (2006), however, pointed out that clustering-based approaches generally fail to produce coherent cluster for small corpora." ></td>
	<td class="line x" title="71:255	In addition, clustering-based approaches had only applied to solve is-a and sibling relations." ></td>
	<td class="line x" title="72:255	Many clustering-based approaches face the challenge of appropriately labeling non-leaf clusters." ></td>
	<td class="line x" title="73:255	The labeling amplifies the difficulty in creation and evaluation of taxonomies." ></td>
	<td class="line x" title="74:255	Agglomerative clustering (Brown et al., 1992; Caraballo, 1999; Rosenfeld and Feldman, 2007; Yang and Callan, 2008) iteratively merges the most similar clusters into bigger clusters, which need to be labeled." ></td>
	<td class="line x" title="75:255	Divisive clustering, such as CBC (Clustering By Committee) which constructs cluster centroids by averaging the feature vectors of a subset of carefully chosen cluster members (Pantel and Lin, 2002; Pantel and Ravichandran, 2004), also need to label the parents of split clusters." ></td>
	<td class="line x" title="76:255	In this paper, we take an incremental clustering approach, in which terms and relations are added into a taxonomy one at a time, and their parents are from the existing taxonomy." ></td>
	<td class="line x" title="77:255	The advantage of the incremental approach is that it eliminates the trouble of inventing cluster labels and concentrates on placing terms in the correct positions in a taxonomy hierarchy." ></td>
	<td class="line x" title="78:255	The work by Snow et al.(2006) is the most similar to ours because they also took an incremental approach to construct taxonomies." ></td>
	<td class="line x" title="80:255	In their work, a taxonomy grows based on maximization of conditional probability of relations given evidence; while in our work based on optimization of taxonomy structures and modeling of term abstractness." ></td>
	<td class="line x" title="81:255	Moreover, our approach employs heterogeneous features from a wide range; while their approach only used syntactic dependency." ></td>
	<td class="line x" title="82:255	We compare system performance between (Snow et al., 2006) and our framework in Section 5." ></td>
	<td class="line x" title="83:255	3 The Features The features used in this work are indicators of semantic relations between terms." ></td>
	<td class="line x" title="84:255	Given two input terms yx cc , , a feature is defined as a function generating a single numeric score ),( yx cch  or a vector of numeric scores ),( yx cch n. The features include contextual, co-occurrence, syntactic dependency, lexicalsyntactic patterns, and miscellaneous." ></td>
	<td class="line x" title="85:255	The first set of features captures contextual information of terms." ></td>
	<td class="line x" title="86:255	According to Distributional Hypothesis (Harris, 1954), words appearing in similar contexts tend to be similar." ></td>
	<td class="line x" title="87:255	Therefore, word meanings can be inferred from and represented by contexts." ></td>
	<td class="line x" title="88:255	Based on the hypothesis, we develop the following features: (1) Global Context KL-Divergence: The global context of each input term is the search results collected through querying search engines against several corpora (Details in Section 5.1)." ></td>
	<td class="line x" title="89:255	It is built into a unigram language model without smoothing for each term." ></td>
	<td class="line x" title="90:255	This feature function measures the Kullback-Leibler divergence (KL divergence) between the language models associated with the two inputs." ></td>
	<td class="line x" title="91:255	(2) Local Context KL-Divergence: The local context is the collection of all the left two and the right two words surrounding an input term." ></td>
	<td class="line x" title="92:255	Similarly, the local context is built into a unigram language model without smoothing for each term; the feature function outputs KL divergence between the models." ></td>
	<td class="line x" title="93:255	The second set of features is co-occurrence." ></td>
	<td class="line x" title="94:255	In our work, co-occurrence is measured by pointwise mutual information between two terms: )()( ),(log),( yx yx yx cCountcCount ccCountccpmi = where Count(.)" ></td>
	<td class="line x" title="95:255	is defined as the number of documents or sentences containing the term(s); or n as in Results 1-10 of about n for term appearing on the first page of Google search results for a term or the concatenation of a term pair." ></td>
	<td class="line x" title="96:255	Based 273 on different definitions of Count(.), we have (3) Document PMI, (4) Sentence PMI, and (5) Google PMI as the co-occurrence features." ></td>
	<td class="line x" title="97:255	The third set of features employs syntactic dependency analysis." ></td>
	<td class="line x" title="98:255	We have (6) Minipar Syntactic Distance to measure the average length of the shortest syntactic paths (in the first syntactic parse tree returned by Minipar1) between two terms in sentences containing them, (7) Modifier Overlap, (8) Object Overlap, (9) Subject Overlap, and (10) Verb Overlap to measure the number of overlaps between modifiers, objects, subjects, and verbs, respectively, for the two terms in sentences containing them." ></td>
	<td class="line x" title="99:255	We use Assert2 to label the semantic roles." ></td>
	<td class="line x" title="100:255	The fourth set of features is lexical-syntactic patterns." ></td>
	<td class="line x" title="101:255	We have (11) Hypernym Patterns based on patterns proposed by (Hearst, 1992) and (Snow et al., 2005), (12) Sibling Patterns which are basically conjunctions, and (13) Part-of Patterns based on patterns proposed by (Girju et al., 2003) and (Cimiano and Wenderoth, 2007)." ></td>
	<td class="line x" title="102:255	Table 1 lists all patterns." ></td>
	<td class="line x" title="103:255	Each feature function returns a vector of scores for two input terms, one score per pattern." ></td>
	<td class="line x" title="104:255	A score is 1 if two terms match a pattern in text, 0 otherwise." ></td>
	<td class="line x" title="105:255	The last set of features is miscellaneous." ></td>
	<td class="line x" title="106:255	We have (14) Word Length Difference to measure the length difference between two terms, and (15) Definition Overlap to measure the number of word overlaps between the term definitions obtained by querying Google with define:term." ></td>
	<td class="line x" title="107:255	These heterogeneous features vary from simple statistics to complicated syntactic dependency features, basic word length to comprehensive Web-based contextual features." ></td>
	<td class="line x" title="108:255	The flexible design of our learning framework allows us to use all of them, and even allows us to use different sets of them under different conditions, for instance, different types of relations and different abstraction levels." ></td>
	<td class="line x" title="109:255	We study the interaction be 1 http://www.cs.ualberta.ca/lindek/minipar.htm." ></td>
	<td class="line x" title="110:255	2 http://cemantix.org/assert." ></td>
	<td class="line x" title="111:255	tween features and relations and that between features and abstractness in Section 5." ></td>
	<td class="line x" title="112:255	4 The Metric-based Framework This section presents the metric-based framework which incrementally clusters terms to form taxonomies." ></td>
	<td class="line x" title="113:255	By minimizing the changes of taxonomy structures and modeling term abstractness at each step, it finds the optimal position for each term in a taxonomy." ></td>
	<td class="line x" title="114:255	We first introduce definitions, terminologies and assumptions about taxonomies; then, we formulate automatic taxonomy induction as a multi-criterion optimization and solve it by a greedy algorithm; lastly, we show how to estimate ontology metrics." ></td>
	<td class="line x" title="115:255	4.1 Taxonomies, Ontology Metric, Assumptions, and Information Functions We define a taxonomy T as a data model that represents a set of terms C and a set of relations R between these terms." ></td>
	<td class="line x" title="116:255	T can be written as T(C,R)." ></td>
	<td class="line x" title="117:255	Note that for the subtask of relation formation, we assume that the term set C is given." ></td>
	<td class="line x" title="118:255	A full taxonomy is a tree containing all the terms in C. A partial taxonomy is a tree containing only a subset of terms in C. In our framework, automatic taxonomy induction is the process to construct a full taxonomy T given a set of terms C and an initial partial taxonomy ),( 000 RST , where CS 0 . Note that T0 is possibly empty." ></td>
	<td class="line x" title="119:255	The process starts from the initial partial taxonomy T0 and randomly adds terms from C to T0 one by one, until a full taxonomy is formed, i.e., all terms in C are added." ></td>
	<td class="line x" title="120:255	Ontology Metric We define an ontology metric as a distance measure between two terms (cx,cy) in a taxonomy T(C,R)." ></td>
	<td class="line x" title="121:255	Formally, it is a function CCd : +, where C is the set of terms in T.  An ontology metric d on a taxonomy T with edge weights w for any term pair (cx,cy)C is the sum of all edge weights along the shortest path between the pair:   = ),( ,),( , )(),( yxPe yxyxwT yx ewccd Hypernym Patterns Sibling Patterns NPx (,)?and/or other NPy NPx and/or NPy such NPy as NPx Part-of Patterns NPy (,)?" ></td>
	<td class="line x" title="122:255	such as NPx NPx of NPy NPy (,)?" ></td>
	<td class="line x" title="123:255	including NPx NPys NPx NPy (,)?" ></td>
	<td class="line x" title="124:255	especially NPx NPy has/had/have NPx NPy like NPx NPy is made (up)?" ></td>
	<td class="line x" title="125:255	of NPx NPy called NPx NPy comprises NPx NPx is a/an NPy NPy consists of NPx NPx , a/an NPy Table 1." ></td>
	<td class="line x" title="126:255	Lexico-Syntactic Patterns." ></td>
	<td class="line x" title="127:255	Figure 1." ></td>
	<td class="line x" title="128:255	Illustration of Ontology Metric." ></td>
	<td class="line x" title="129:255	274 where ),( yxP  is the set of edges defining the shortest path from term cx to cy . Figure 1 illustrates ontology metrics for a 5-node taxonomy." ></td>
	<td class="line x" title="130:255	Section 4.3 presents the details of learning ontology metrics." ></td>
	<td class="line x" title="131:255	Information Functions The amount of information in a taxonomy T is measured and represented by an information function Info(T)." ></td>
	<td class="line x" title="132:255	An information function is defined as the sum of the ontology metrics among a set of term pairs." ></td>
	<td class="line x" title="133:255	The function can be defined over a taxonomy, or on a single level of a taxonomy." ></td>
	<td class="line x" title="134:255	For a taxonomy T(C,R), we define its information function as:  < = Cycxcyx yx ccdTInfo ,, ),()(   (1) Similarly, we define the information function for an abstraction level Li as:  < = iLycxcyx yxii ccdLInfo ,, ),()(   (2) where Li is the subset of terms lying at the ith level of a taxonomy T. For example, in Figure 1, node 1 is at level L1, node 2 and node 5 level L2." ></td>
	<td class="line x" title="135:255	Assumptions Given the above definitions about taxonomies, we make the following assumptions: Minimum Evolution Assumption." ></td>
	<td class="line x" title="136:255	Inspired by the minimum evolution tree selection criterion widely used in phylogeny (Hendy and Penny, 1985), we assume that a good taxonomy not only minimizes the overall semantic distance among the terms but also avoid dramatic changes." ></td>
	<td class="line x" title="137:255	Construction of a full taxonomy is proceeded by adding terms one at a time, which yields a series of partial taxonomies." ></td>
	<td class="line x" title="138:255	After adding each term, the current taxonomy Tn+1 from the previous taxonomy Tn is one that introduces the least changes between the information in the two taxonomies: ),(minarg ' ' 1 TTInfoT n T n =+ where the information change function is |)()(| ),( baba TInfoTInfoTTInfo = . Abstractness Assumption." ></td>
	<td class="line x" title="139:255	In a taxonomy, concrete concepts usually lay at the bottom of the hierarchy while abstract concepts often occupy the intermediate and top levels." ></td>
	<td class="line x" title="140:255	Concrete concepts often represent physical entities, such as basketball and mercury pollution." ></td>
	<td class="line x" title="141:255	While abstract concepts, such as science and economy, do not have a physical form thus we must imagine their existence." ></td>
	<td class="line x" title="142:255	This obvious difference suggests that there is a need to treat them differently in taxonomy induction." ></td>
	<td class="line x" title="143:255	Hence we assume that terms at the same abstraction level have common characteristics and share the same Info(.)" ></td>
	<td class="line x" title="144:255	function." ></td>
	<td class="line x" title="145:255	We also assume that terms at different abstraction levels have different characteristics; hence they do not necessarily share the same Info(.)" ></td>
	<td class="line x" title="146:255	function." ></td>
	<td class="line x" title="147:255	That is to say, ,concept  Tc , leveln abstractio TLi   (.)." ></td>
	<td class="line x" title="148:255	uses ii InfocLc  4.2 Problem Formulation The Minimum Evolution Objective Based on the minimum evolution assumption, we define the goal of taxonomy induction is to find the optimal full taxonomy T  such that the information changes are the least since the initial partial taxonomy T0, i.e., to find: ),(minarg '0 ' TTInfoT T =   (3) where 'T  is a full taxonomy, i.e., the set of terms in 'T  equals C. To find the optimal solution for Equation (3), T , we need to find the optimal term set C and the optimal relation set R . Since the optimal term set for a full taxonomy is always C, the only unknown part left is R . Thus, Equation (3) can be transformed equivalently into: )),(),,((minarg 000'' ' RSTRCTInfoR R = Note that in the framework, terms are added incrementally into a taxonomy." ></td>
	<td class="line x" title="149:255	Each term insertion yields a new partial taxonomy T. By the minimum evolution assumption, the optimal next partial taxonomy is one gives the least information change." ></td>
	<td class="line x" title="150:255	Therefore, the updating function for the set of relations 1+nR after a new term z is inserted can be calculated as: )),(),},{((minarg ' ' nnn R RSTRzSTInfoR =  By plugging in the definition of the information change function (.,.)Info in Section 4.1 and Equation (1), the updating function becomes: |),(),(|minarg ,}{,'   = nSycxc yx znSycxc yx R ccdccdR  The above updating function can be transformed into a minimization problem: yx ccdccdu ccdccdu u znSycxc yx nSycxc yx nSycxc yx znSycxc yx <       }{,, ,}{, ),(),( ),(),(    subject to  min  The minimization follows the minimum evolution assumption; hence we call it the minimum evolution objective." ></td>
	<td class="line x" title="151:255	275 The Abstractness Objective The abstractness assumption suggests that term abstractness should be modeled explicitly by learning separate information functions for terms at different abstraction levels." ></td>
	<td class="line x" title="152:255	We approximate an information function by a linear interpolation of some underlying feature functions." ></td>
	<td class="line x" title="153:255	Each abstraction level Li is characterized by its own information function Infoi(.)." ></td>
	<td class="line x" title="154:255	The least square fit of Infoi(.)" ></td>
	<td class="line x" title="155:255	is: .|)(|min 2iTiii HWLInfo  By plugging Equation (2) and minimizing over every abstraction level, we have: 2 ,, , )),(),((min yxji j ji i iLycxc yx cchwccd     where jih , (.,.)" ></td>
	<td class="line x" title="156:255	is the jth underlying feature function for term pairs at level Li, jiw , is the weight for jih , (.,.)." ></td>
	<td class="line x" title="157:255	This minimization follows the abstractness assumption; hence we call it the abstractness objective." ></td>
	<td class="line x" title="158:255	The Multi-Criterion Optimization Algorithm We propose that both minimum evolution and abstractness objectives need to be satisfied." ></td>
	<td class="line x" title="159:255	To optimize multiple criteria, the Pareto optimality needs to be satisfied (Boyd and Vandenberghe, 2004)." ></td>
	<td class="line x" title="160:255	We handle this by introducing g2019 g1488 g4670uni0030uni002Cuni0031g4671 to control the contribution of each objective." ></td>
	<td class="line x" title="161:255	The multi-criterion optimization function is: yx cchwccdv ccdccdu ccdccdu vu yxji j ji i Lcc yx zScc yx Scc yx Scc yx zScc yx iyx n yx n yx nyxnyx < =   +        2)),(),(( ),(),( ),(),(      subject to )1(min ,, , }{,, ,}{,  The above optimization can be solved by a greedy optimization algorithm." ></td>
	<td class="line x" title="162:255	At each term insertion step, it produces a new partial taxonomy by adding to the existing partial taxonomy a new term z, and a new set of relations R(z,.)." ></td>
	<td class="line x" title="163:255	z is attached to every nodes in the existing partial taxonomy; and the algorithm selects the optimal position indicated by R(z,.), which minimizes the multicriterion objective function." ></td>
	<td class="line x" title="164:255	The algorithm is: );,( )};)1((min{arg ; \ RST vuRR {z}SS SCz (z,.)R Output    foreach  +    The above algorithm presents a general incremental clustering procedure to construct taxonomies." ></td>
	<td class="line x" title="165:255	By minimizing the taxonomy structure changes and modeling term abstractness at each step, it finds the optimal position of each term in the taxonomy hierarchy." ></td>
	<td class="line x" title="166:255	4.3 Estimating Ontology Metric Learning a good ontology metric is important for the multi-criterion optimization algorithm." ></td>
	<td class="line x" title="167:255	In this work, the estimation and prediction of ontology metric are achieved by ridge regression (Hastie et al., 2001)." ></td>
	<td class="line x" title="168:255	In the training data, an ontology metric d(cx,cy) for a term pair (cx,cy) is generated by assuming every edge weight as 1 and summing up all the edge weights along the shortest path from cx to cy." ></td>
	<td class="line x" title="169:255	We assume that there are some underlying feature functions which measure the semantic distance from term cx to cy." ></td>
	<td class="line x" title="170:255	A weighted combination of these functions approximates the ontology metric for (cx,cy): = ),(),( yxjjj cchwyxd where jw  is the jth weight for ),( yxj cch , the jth feature function." ></td>
	<td class="line x" title="171:255	The feature functions are generated as mentioned in Section 3." ></td>
	<td class="line x" title="172:255	5 Experiments 5.1 Data The gold standards used in the evaluation are hypernym taxonomies extracted from WordNet and ODP (Open Directory Project), and meronym taxonomies extracted from WordNet." ></td>
	<td class="line x" title="173:255	In WordNet taxonomy extraction, we only use the word senses within a particular taxonomy to ensure no ambiguity." ></td>
	<td class="line x" title="174:255	In ODP taxonomy extraction, we parse the topic lines, such as Topic r:id=`Top/Arts/Movies, in the XML databases to obtain relations, such as is_a(movies, arts)." ></td>
	<td class="line x" title="175:255	In total, there are 100 hypernym taxonomies, 50 each extracted from WordNet3 and ODP4, and 50 meronym taxonomies from WordNet5." ></td>
	<td class="line x" title="176:255	Table 2  3 WordNet hypernym taxonomies are from 12 topics: gathering, professional, people, building, place, milk, meal, water, beverage, alcohol, dish, and herb." ></td>
	<td class="line x" title="177:255	4 ODP hypernym taxonomies are from 16 topics: computers, robotics, intranet, mobile computing, database, operating system, linux, tex, software, computer science, data communication, algorithms, data formats, security multimedia, and artificial intelligence." ></td>
	<td class="line x" title="178:255	5 WordNet meronym taxonomies are from 15 topics: bed, car, building, lamp, earth, television, body, drama, theatre, water, airplane, piano, book, computer, and watch." ></td>
	<td class="line x" title="179:255	Statistics WN/is-a ODP/is-a WN/part-of #taxonomies 50 50 50 #terms 1,964 2,210 1,812 Avg #terms 39 44 37 Avg depth 6 6 5 Table 2." ></td>
	<td class="line x" title="180:255	Data Statistics." ></td>
	<td class="line x" title="181:255	276 summarizes the data statistics." ></td>
	<td class="line x" title="182:255	We also use two Web-based auxiliary datasets to generate features mentioned in Section 3:  Wikipedia corpus." ></td>
	<td class="line x" title="183:255	The entire Wikipedia corpus is downloaded and indexed by Indri6." ></td>
	<td class="line x" title="184:255	The top 100 documents returned by Indri are the global context of a term when querying with the term." ></td>
	<td class="line x" title="185:255	 Google corpus." ></td>
	<td class="line x" title="186:255	A collection of the top 1000 documents by querying Google using each term, and each term pair." ></td>
	<td class="line x" title="187:255	Each top 1000 documents are the global context of a query term." ></td>
	<td class="line x" title="188:255	Both corpora are split into sentences and are used to generate contextual, co-occurrence, syntactic dependency and lexico-syntactic pattern features." ></td>
	<td class="line x" title="189:255	5.2 Methodology We evaluate the quality of automatic generated taxonomies by comparing them with the gold standards in terms of precision, recall and F1measure." ></td>
	<td class="line x" title="190:255	F1-measure is calculated as 2*P*R/ (P+R), where P is precision, the percentage of correctly returned relations out of the total returned relations, R is recall, the percentage of correctly returned relations out of the total relations in the gold standard." ></td>
	<td class="line x" title="191:255	Leave-one-out cross validation is used to average the system performance across different training and test datasets." ></td>
	<td class="line x" title="192:255	For each 50 datasets from WordNet hypernyms, WordNet meronyms or ODP hypernyms, we randomly pick 49 of them to generate training data, and test on the remaining dataset." ></td>
	<td class="line x" title="193:255	We repeat the process for 50 times, with different training and test sets at each  6 http://www.lemurproject.org/indri/." ></td>
	<td class="line x" title="194:255	time, and report the averaged precision, recall and F1-measure across all 50 runs." ></td>
	<td class="line x" title="195:255	We also group the fifteen features in Section 3 into six sets: contextual, co-concurrence, patterns, syntactic dependency, word length difference and definition." ></td>
	<td class="line x" title="196:255	Each set is turned on one by one for experiments in Section 5.4 and 5.5." ></td>
	<td class="line x" title="197:255	5.3 Performance of Taxonomy Induction In this section, we compare the following automatic taxonomy induction systems: HE, the system by Hearst (1992) with 6 hypernym patterns; GI, the system by Girju et al.(2003) with 3 meronym patterns; PR, the probabilistic framework by Snow et al.(2006); and ME, the metric-based framework proposed in this paper." ></td>
	<td class="line x" title="200:255	To have a fair comparison, for PR, we estimate the conditional probability of a relation given the evidence P(Rij|Eij), as in (Snow et al. 2006), by using the same set of features as in ME. Table 3 shows precision, recall, and F1measure of each system for WordNet hypernyms (is-a), WordNet meronyms (part-of) and ODP hypernyms (is-a)." ></td>
	<td class="line x" title="201:255	Bold font indicates the best performance in a column." ></td>
	<td class="line x" title="202:255	Note that HE is not applicable to part-of, so is GI to is-a." ></td>
	<td class="line x" title="203:255	Table 3 shows that systems using heterogeneous features (PR and ME) achieve higher F1measure than systems only using patterns (HE and GI) with a significant absolute gain of >30%." ></td>
	<td class="line x" title="204:255	Generally speaking, pattern-based systems show higher precision and lower recall, while systems using heterogeneous features show lower precision and higher recall." ></td>
	<td class="line x" title="205:255	However, when considering both precision and recall, using heterogeneous features is more effective than just using patterns." ></td>
	<td class="line x" title="206:255	The proposed system ME consistently produces the best F1-measure for all three tasks." ></td>
	<td class="line x" title="207:255	The performance of the systems for ODP/is-a is worse than that for WordNet/is-a." ></td>
	<td class="line x" title="208:255	This may be because there is more noise in ODP than in WordNet/is-a System Precision Recall F1-measure HE 0.85 0.32 0.46 GI n/a n/a n/a PR 0.75 0.73 0.74 ME 0.82 0.79 0.82 ODP/is-a System Precision Recall F1-measure HE 0.31 0.29 0.30 GI n/a n/a n/a PR 0.60 0.72 0.65 ME 0.64 0.70 0.67 WordNet/part-of System Precision Recall F1-measure HE n/a n/a n/a GI 0.75 0.25 0.38 PR 0.68 0.52 0.59 ME 0.69 0.55 0.61 Table 3." ></td>
	<td class="line x" title="209:255	System Performance." ></td>
	<td class="line x" title="210:255	Feature  is-a sibling partof Benefited Relations Contextual 0.21 0.42 0.12 sibling Co-occur." ></td>
	<td class="line x" title="211:255	0.48 0.41 0.28 All Patterns 0.46 0.41 0.30 All Syntactic 0.22 0.36 0.12 sibling Word Leng." ></td>
	<td class="line x" title="212:255	0.16 0.16 0.15 All but limited Definition 0.12 0.18 0.10 Sibling but limited Best Features Cooccur., patterns Contextual, co-occur., patterns Cooccur., patterns  Table 4." ></td>
	<td class="line x" title="213:255	F1-measure for Features vs. Relations: WordNet." ></td>
	<td class="line x" title="214:255	277 WordNet." ></td>
	<td class="line x" title="215:255	For example, under artificial intelligence, ODP has neural networks, natural language and academic departments." ></td>
	<td class="line x" title="216:255	Clearly, academic departments is not a hyponym of artificial intelligence." ></td>
	<td class="line x" title="217:255	The noise in ODP interferes with the learning process, thus hurts the performance." ></td>
	<td class="line x" title="218:255	5.4 Features vs. Relations This section studies the impact of different sets of features on different types of relations." ></td>
	<td class="line x" title="219:255	Table 4 shows F1-measure of using each set of features alone on taxonomy induction for WordNet is-a, sibling, and part-of relations." ></td>
	<td class="line x" title="220:255	Bold font means a feature set gives a major contribution to the task of automatic taxonomy induction for a particular type of relation." ></td>
	<td class="line x" title="221:255	Table 4 shows that different relations favor different sets of features." ></td>
	<td class="line x" title="222:255	Both co-occurrence and lexico-syntactic patterns work well for all three types of relations." ></td>
	<td class="line x" title="223:255	It is interesting to see that simple co-occurrence statistics work as good as lexico-syntactic patterns." ></td>
	<td class="line x" title="224:255	Contextual features work well for sibling relations, but not for is-a and part-of." ></td>
	<td class="line x" title="225:255	Syntactic features also work well for sibling, but not for is-a and part-of." ></td>
	<td class="line x" title="226:255	The similar behavior of contextual and syntactic features may be because that four out of five syntactic features (Modifier, Subject, Object, and Verb overlaps) are just surrounding context for a term." ></td>
	<td class="line x" title="227:255	Comparing the is-a and part-of columns in Table 4 and the ME rows in Table 3, we notice a significant difference in F1-measure." ></td>
	<td class="line x" title="228:255	It indicates that combination of heterogeneous features gives more rise to the system performance than a single set of features does." ></td>
	<td class="line x" title="229:255	5.5 Features vs. Abstractness This section studies the impact of different sets of features on terms at different abstraction levels." ></td>
	<td class="line x" title="230:255	In the experiments, F1-measure is evaluated for terms at each level of a taxonomy, not the whole taxonomy." ></td>
	<td class="line x" title="231:255	Table 5 and 6 demonstrate F1measure of using each set of features alone on each abstraction levels." ></td>
	<td class="line x" title="232:255	Columns 2-6 are indices of the levels in a taxonomy." ></td>
	<td class="line x" title="233:255	The larger the indices are, the lower the levels." ></td>
	<td class="line x" title="234:255	Higher levels contain abstract terms, while lower levels contain concrete terms." ></td>
	<td class="line x" title="235:255	L1 is ignored here since it only contains a single term, the root." ></td>
	<td class="line x" title="236:255	Bold font indicates good performance in a column." ></td>
	<td class="line x" title="237:255	Both tables show that abstract terms and concrete terms favor different sets of features." ></td>
	<td class="line x" title="238:255	In particular, contextual, co-occurrence, pattern, and syntactic features work well for terms at L4L6, i.e., concrete terms; co-occurrence works well for terms at L2-L3, i.e., abstract terms." ></td>
	<td class="line x" title="239:255	This difference indicates that terms at different abstraction levels have different characteristics; it confirms our abstractness assumption in Section 4.1." ></td>
	<td class="line x" title="240:255	We also observe that for abstract terms in WordNet, patterns work better than contextual features; while for abstract terms in ODP, the conclusion is the opposite." ></td>
	<td class="line x" title="241:255	This may be because that WordNet has a richer vocabulary and a more rigid definition of hypernyms, and hence is-a relations in WordNet are recognized more effectively by using lexico-syntactic patterns; while ODP contains more noise, and hence it favors features requiring less rigidity, such as the contextual features generated from the Web." ></td>
	<td class="line x" title="242:255	6 Conclusions This paper presents a novel metric-based taxonomy induction framework combining the strengths of lexico-syntactic patterns and clustering." ></td>
	<td class="line x" title="243:255	The framework incrementally clusters terms and transforms automatic taxonomy induction into a multi-criteria optimization based on minimization of taxonomy structures and modeling of term abstractness." ></td>
	<td class="line x" title="244:255	The experiments show that our framework is effective; it achieves higher F1measure than three state-of-the-art systems." ></td>
	<td class="line x" title="245:255	The paper also studies which features are the best for different types of relations and for terms at different abstraction levels." ></td>
	<td class="line x" title="246:255	Most prior work uses a single rule or feature function for automatic taxonomy induction at all levels of abstraction." ></td>
	<td class="line x" title="247:255	Our work is a more general framework which allows a wider range of features and different metric functions at different abstraction levels." ></td>
	<td class="line x" title="248:255	This more general framework has the potential to learn more complex taxonomies than previous approaches." ></td>
	<td class="line x" title="249:255	Acknowledgements This research was supported by NSF grant IIS0704210." ></td>
	<td class="line x" title="250:255	Any opinions, findings, conclusions, or recommendations expressed in this paper are of the authors, and do not necessarily reflect those of the sponsor." ></td>
	<td class="line x" title="251:255	Feature  L2 L3 L4 L5 L6 Contextual 0.29 0.31 0.35 0.36 0.36 Co-occurrence 0.47 0.56 0.45 0.41 0.41 Patterns 0.47 0.44 0.42 0.39 0.40 Syntactic 0.31 0.28 0.36 0.38 0.39 Word Length 0.16 0.16 0.16 0.16 0.16 Definition 0.12 0.12 0.12 0.12 0.12 Table 5." ></td>
	<td class="line x" title="252:255	F1-measure for Features vs. Abstractness: WordNet/is-a." ></td>
	<td class="line x" title="253:255	Feature  L2 L3 L4 L5 L6 Contextual 0.30 0.30 0.33 0.29 0.29 Co-occurrence 0.34 0.36 0.34 0.31 0.31 Patterns 0.23 0.25 0.30 0.28 0.28 Syntactic 0.18 0.18 0.23 0.27 0.27 Word Length 0.15 0.15 0.15 0.14 0.14 Definition 0.13 0.13 0.13 0.12 0.12 Table 6." ></td>
	<td class="line x" title="254:255	F1-measure for Features vs. Abstractness: ODP/is-a." ></td>
	<td class="line x" title="255:255	278" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-1051
Extracting Lexical Reference Rules from Wikipedia
Shnarch, Eyal;Barak, Libby;Dagan, Ido;"></td>
	<td class="line x" title="1:229	Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 450458, Suntec, Singapore, 2-7 August 2009." ></td>
	<td class="line x" title="2:229	c2009 ACL and AFNLP Extracting Lexical Reference Rules from Wikipedia Eyal Shnarch Computer Science Department Bar-Ilan University Ramat-Gan 52900, Israel shey@cs.biu.ac.il Libby Barak Dept. of Computer Science University of Toronto Toronto, Canada M5S 1A4 libbyb@cs.toronto.edu Ido Dagan Computer Science Department Bar-Ilan University Ramat-Gan 52900, Israel dagan@cs.biu.ac.il Abstract This paper describes the extraction from Wikipedia of lexical reference rules, identifying references to term meanings triggered by other terms." ></td>
	<td class="line x" title="3:229	We present extraction methods geared to cover the broad range of the lexical reference relation and analyze them extensively." ></td>
	<td class="line x" title="4:229	Most extraction methods yield high precision levels, and our rule-base is shown to perform better than other automatically constructed baselines in a couple of lexical expansion and matching tasks." ></td>
	<td class="line x" title="5:229	Our rule-base yields comparable performance to WordNet while providing largely complementary information." ></td>
	<td class="line x" title="6:229	1 Introduction A most common need in applied semantic inference is to infer the meaning of a target term from other terms in a text." ></td>
	<td class="line x" title="7:229	For example, a Question Answering system may infer the answer to a question regarding luxury cars from a text mentioning Bentley, which provides a concrete reference to the sought meaning." ></td>
	<td class="line x" title="8:229	Aiming to capture such lexical inferences we followed (Glickman et al., 2006), which coined the term lexical reference (LR) to denote references in text to the specific meaning of a target term." ></td>
	<td class="line x" title="9:229	They further analyzed the dataset of the First Recognizing Textual Entailment Challenge (Dagan et al., 2006), which includes examples drawn from seven different application scenarios." ></td>
	<td class="line x" title="10:229	It was found that an entailing text indeed includes a concrete reference to practically every term in the entailed (inferred) sentence." ></td>
	<td class="line x" title="11:229	The lexical reference relation between two terms may be viewed as a lexical inference rule, denoted LHSRHS." ></td>
	<td class="line x" title="12:229	Such rule indicates that the left-hand-side term would generate a reference, in some texts, to a possible meaning of the right hand side term, as the Bentleyluxury car example." ></td>
	<td class="line x" title="13:229	In the above example the LHS is a hyponym of the RHS." ></td>
	<td class="line x" title="14:229	Indeed, the commonly used hyponymy, synonymy and some cases of the meronymy relations are special cases of lexical reference." ></td>
	<td class="line x" title="15:229	However, lexical reference is a broader relation." ></td>
	<td class="line x" title="16:229	For instance, the LR rule physician  medicine may be useful to infer the topic medicine in a text categorization setting, while an information extraction system may utilize the rule Margaret Thatcher  United Kingdom to infer a UK announcement from the text Margaret Thatcher announced." ></td>
	<td class="line x" title="17:229	To perform such inferences, systems need large scale knowledge bases of LR rules." ></td>
	<td class="line x" title="18:229	A prominent available resource is WordNet (Fellbaum, 1998), from which classical relations such as synonyms, hyponyms and some cases of meronyms may be used as LR rules." ></td>
	<td class="line x" title="19:229	An extension to WordNet was presented by (Snow et al., 2006)." ></td>
	<td class="line x" title="20:229	Yet, available resources do not cover the full scope of lexical reference." ></td>
	<td class="line x" title="21:229	This paper presents the extraction of a largescale rule base from Wikipedia designed to cover a wide scope of the lexical reference relation." ></td>
	<td class="line x" title="22:229	As a starting point we examine the potential of definition sentences as a source for LR rules (Ide and Jean, 1993; Chodorow et al., 1985; Moldovan and Rus, 2001)." ></td>
	<td class="line x" title="23:229	When writing a concept definition, one aims to formulate a concise text that includes the most characteristic aspects of the defined concept." ></td>
	<td class="line x" title="24:229	Therefore, a definition is a promising source for LR relations between the defined concept and the definition terms." ></td>
	<td class="line x" title="25:229	In addition, we extract LR rules from Wikipedia redirect and hyperlink relations." ></td>
	<td class="line x" title="26:229	As a guideline, we focused on developing simple extraction methods that may be applicable for other Web knowledge resources, rather than focusing on Wikipedia-specific attributes." ></td>
	<td class="line x" title="27:229	Overall, our rule base contains about 8 million candidate lexical ref450 erence rules." ></td>
	<td class="line x" title="28:229	1 Extensive analysis estimated that 66% of our rules are correct, while different portions of the rule base provide varying recall-precision tradeoffs." ></td>
	<td class="line x" title="29:229	Following further error analysis we introduce rule filtering which improves inference performance." ></td>
	<td class="line x" title="30:229	The rule base utility was evaluated within two lexical expansion applications, yielding better results than other automatically constructed baselines and comparable results to WordNet." ></td>
	<td class="line x" title="31:229	A combination with WordNet achieved the best performance, indicating the significant marginal contribution of our rule base." ></td>
	<td class="line x" title="32:229	2 Background Many works on machine readable dictionaries utilized definitions to identify semantic relations between words (Ide and Jean, 1993)." ></td>
	<td class="line x" title="33:229	Chodorow et al.(1985) observed that the head of the defining phrase is a genus term that describes the defined concept and suggested simple heuristics to find it." ></td>
	<td class="line x" title="35:229	Other methods use a specialized parser or a set of regular expressions tuned to a particular dictionary (Wilks et al., 1996)." ></td>
	<td class="line x" title="36:229	Some works utilized Wikipedia to build an ontology." ></td>
	<td class="line x" title="37:229	Ponzetto and Strube (2007) identified the subsumption (IS-A) relation from Wikipedias category tags, while in Yago (Suchanek et al., 2007) these tags, redirect links and WordNet were used to identify instances of 14 predefined specific semantic relations." ></td>
	<td class="line x" title="38:229	These methods depend on Wikipedias category system." ></td>
	<td class="line x" title="39:229	The lexical reference relation we address subsumes most relations found in these works, while our extractions are not limited to a fixed set of predefined relations." ></td>
	<td class="line x" title="40:229	Several works examined Wikipedia texts, rather than just its structured features." ></td>
	<td class="line x" title="41:229	Kazama and Torisawa (2007) explores the first sentence of an article and identifies the first noun phrase following the verb be as a label for the article title." ></td>
	<td class="line x" title="42:229	We reproduce this part of their work as one of our baselines." ></td>
	<td class="line x" title="43:229	Toral and Munoz (2007) uses all nouns in the first sentence." ></td>
	<td class="line x" title="44:229	Gabrilovich and Markovitch (2007) utilized Wikipedia-based concepts as the basis for a high-dimensional meaning representation space." ></td>
	<td class="line x" title="45:229	Hearst (1992) utilized a list of patterns indicative for the hyponym relation in general texts." ></td>
	<td class="line x" title="46:229	Snow et al.(2006) use syntactic path patterns as features for supervised hyponymy and synonymy 1For download see Textual Entailment Resource Pool at the ACL-wiki (http://aclweb.org/aclwiki) classifiers, whose training examples are derived automatically from WordNet." ></td>
	<td class="line x" title="48:229	They use these classifiers to suggest extensions to the WordNet hierarchy, the largest one consisting of 400K new links." ></td>
	<td class="line x" title="49:229	Their automatically created resource is regarded in our paper as a primary baseline for comparison." ></td>
	<td class="line x" title="50:229	Many works addressed the more general notion of lexical associations, or association rules (e.g.(Ruge, 1992; Rapp, 2002))." ></td>
	<td class="line x" title="52:229	For example, The Beatles, Abbey Road and Sgt. Pepper would all be considered lexically associated." ></td>
	<td class="line x" title="53:229	However this is a rather loose notion, which only indicates that terms are semantically related and are likely to co-occur with each other." ></td>
	<td class="line x" title="54:229	On the other hand, lexical reference is a special case of lexical association, which specifies concretely that a reference to the meaning of one term may be inferred from the other." ></td>
	<td class="line x" title="55:229	For example, Abbey Road provides a concrete reference to The Beatles, enabling to infer a sentence like I listened to The Beatles from I listened to Abbey Road, while it does not refer specifically to Sgt. Pepper." ></td>
	<td class="line x" title="56:229	3 Extracting Rules from Wikipedia Our goal is to utilize the broad knowledge of Wikipedia to extract a knowledge base of lexical reference rules." ></td>
	<td class="line x" title="57:229	Each Wikipedia article provides a definition for the concept denoted by the title of the article." ></td>
	<td class="line x" title="58:229	As the most concise definition we take the first sentence of each article, following (Kazama and Torisawa, 2007)." ></td>
	<td class="line x" title="59:229	Our preliminary evaluations showed that taking the entire first paragraph as the definition rarely introduces new valid rules while harming extraction precision significantly." ></td>
	<td class="line x" title="60:229	Since a concept definition usually employs more general terms than the defined concept (Ide and Jean, 1993), the concept title is more likely to refer to terms in its definition rather than vice versa." ></td>
	<td class="line x" title="61:229	Therefore the title is taken as the LHS of the constructed rule while the extracted definition term is taken as its RHS." ></td>
	<td class="line x" title="62:229	As Wikipedias titles are mostly noun phrases, the terms we extract as RHSs are the nouns and noun phrases in the definition." ></td>
	<td class="line x" title="63:229	The remainder of this section describes our methods for extracting rules from the definition sentence and from additional Wikipedia information." ></td>
	<td class="line x" title="64:229	Be-Comp Following the general idea in (Kazama and Torisawa, 2007), we identify the ISA pattern in the definition sentence by extracting nominal complements of the verb be, taking 451 No." ></td>
	<td class="line x" title="65:229	Extraction Rule James Eugene Jim Carrey is a Canadian-American actor and comedian 1 Be-Comp Jim CarreyCanadian-American actor 2 Be-Comp Jim Carreyactor 3 Be-Comp Jim Carreycomedian Abbey Road is an album released by The Beatles 4 All-N Abbey RoadThe Beatles 5 Parenthesis Graphmathematics 6 Parenthesis Graphdata structure 7 Redirect CPUCentral processing unit 8 Redirect Receptors IgGAntibody 9 Redirect HypertensionElevated blood-pressure 10 Link petDomesticated Animal 11 Link GestaltistGestalt psychology Table 1: Examples of rule extraction methods them as the RHS of a rule whose LHS is the article title." ></td>
	<td class="line oc" title="66:229	While Kazama and Torisawa used a chunker, we parsed the definition sentence using Minipar (Lin, 1998b)." ></td>
	<td class="line x" title="67:229	Our initial experiments showed that parse-based extraction is more accurate than chunk-based extraction." ></td>
	<td class="line x" title="68:229	It also enables us extracting additional rules by splitting conjoined noun phrases and by taking both the head noun and the complete base noun phrase as the RHS for separate rules (examples 13 in Table 1)." ></td>
	<td class="line x" title="69:229	All-N The Be-Comp extraction method yields mostly hypernym relations, which do not exploit the full range of lexical references within the concept definition." ></td>
	<td class="line x" title="70:229	Therefore, we further create rules for all head nouns and base noun phrases within the definition (example 4)." ></td>
	<td class="line x" title="71:229	An unsupervised reliability score for rules extracted by this method is investigated in Section 4.3." ></td>
	<td class="line x" title="72:229	Title Parenthesis A common convention in Wikipedia to disambiguate ambiguous titles is adding a descriptive term in parenthesis at the end of the title, as in The Siren (Musical), The Siren (sculpture) and Siren (amphibian)." ></td>
	<td class="line x" title="73:229	From such titles we extract rules in which the descriptive term inside the parenthesis is the RHS and the rest of the title is the LHS (examples 56)." ></td>
	<td class="line x" title="74:229	Redirect As any dictionary and encyclopedia, Wikipedia contains Redirect links that direct different search queries to the same article, which has a canonical title." ></td>
	<td class="line x" title="75:229	For instance, there are 86 different queries that redirect the user to United States (e.g. U.S.A., America, Yankee land)." ></td>
	<td class="line x" title="76:229	Redirect links are hand coded, specifying that both terms refer to the same concept." ></td>
	<td class="line x" title="77:229	We therefore generate a bidirectional entailment rule for each redirect link (examples 79)." ></td>
	<td class="line x" title="78:229	Link Wikipedia texts contain hyper links to articles." ></td>
	<td class="line x" title="79:229	For each link we generate a rule whose LHS is the linking text and RHS is the title of the linked article (examples 1011)." ></td>
	<td class="line x" title="80:229	In this case we generate a directional rule since links do not necessarily connect semantically equivalent entities." ></td>
	<td class="line x" title="81:229	We note that the last three extraction methods should not be considered as Wikipedia specific, since many Web-like knowledge bases contain redirects, hyper-links and disambiguation means." ></td>
	<td class="line x" title="82:229	Wikipedia has additional structural features such as category tags, structured summary tablets for specific semantic classes, and articles containing lists which were exploited in prior work as reviewed in Section 2." ></td>
	<td class="line x" title="83:229	As shown next, the different extraction methods yield different precision levels." ></td>
	<td class="line x" title="84:229	This may allow an application to utilize only a portion of the rule base whose precision is above a desired level, and thus choose between several possible recallprecision tradeoffs." ></td>
	<td class="line x" title="85:229	4 Extraction Methods Analysis We applied our rule extraction methods over a version of Wikipedia available in a database constructed by (Zesch et al., 2007)2." ></td>
	<td class="line x" title="86:229	The extraction yielded about 8 million rules altogether, with over 2.4 million distinct RHSs and 2.8 million distinct LHSs." ></td>
	<td class="line x" title="87:229	As expected, the extracted rules involve mostly named entities and specific concepts, typically covered in encyclopedias." ></td>
	<td class="line x" title="88:229	4.1 Judging Rule Correctness Following the spirit of the fine-grained human evaluation in (Snow et al., 2006), we randomly sampled 800 rules from our rule-base and presented them to an annotator who judged them for correctness, according to the lexical reference notion specified above." ></td>
	<td class="line x" title="89:229	In cases which were too difficult to judge the annotator was allowed to abstain, which happened for 20 rules." ></td>
	<td class="line x" title="90:229	66% of the remaining rules were annotated as correct." ></td>
	<td class="line x" title="91:229	200 rules from the sample were judged by another annotator for agreement measurement." ></td>
	<td class="line x" title="92:229	The resulting Kappa score was 0.7 (substantial agreement (Landis and 2English version from February 2007, containing 1.6 million articles." ></td>
	<td class="line x" title="93:229	www.ukp.tu-darmstadt.de/software/JWPL 452 Extraction Per Method Accumulated Method P Est." ></td>
	<td class="line x" title="94:229	#Rules P %obtained Redirect 0.87 1,851,384 0.87 31 Be-Comp 0.78 1,618,913 0.82 60 Parenthesis 0.71 94,155 0.82 60 Link 0.7 485,528 0.80 68 All-N 0.49 1,580,574 0.66 100 Table 2: Manual analysis: precision and estimated number of correct rules per extraction method, and precision and % of correct rules obtained of rule-sets accumulated by method." ></td>
	<td class="line x" title="95:229	Koch, 1997)), either when considering all the abstained rules as correct or as incorrect." ></td>
	<td class="line x" title="96:229	The middle columns of Table 2 present, for each extraction method, the obtained percentage of correct rules (precision) and their estimated absolute number." ></td>
	<td class="line x" title="97:229	This number is estimated by multiplying the number of annotated correct rules for the extraction method by the sampling proportion." ></td>
	<td class="line x" title="98:229	In total, we estimate that our resource contains 5.6 million correct rules." ></td>
	<td class="line x" title="99:229	For comparison, Snows published extension to WordNet3, which covers similar types of terms but is restricted to synonyms and hyponyms, includes 400,000 relations." ></td>
	<td class="line x" title="100:229	The right part of Table 2 shows the performance figures for accumulated rule bases, created by adding the extraction methods one at a time in order of their precision." ></td>
	<td class="line x" title="101:229	% obtained is the percentage of correct rules in each rule base out of the total number of correct rules extracted jointly by all methods (the union set)." ></td>
	<td class="line x" title="102:229	We can see that excluding the All-N method all extraction methods reach quite high precision levels of 0.7-0.87, with accumulated precision of 0.84." ></td>
	<td class="line x" title="103:229	By selecting only a subset of the extraction methods, according to their precision, one can choose different recall-precision tradeoff points that suit application preferences." ></td>
	<td class="line x" title="104:229	The less accurate All-N method may be used when high recall is important, accounting for 32% of the correct rules." ></td>
	<td class="line x" title="105:229	An examination of the paths in All-N reveals, beyond standard hyponymy and synonymy, various semantic relations that satisfy lexical reference, such as Location, Occupation and Creation, as illustrated in Table 3." ></td>
	<td class="line x" title="106:229	Typical relations covered by Redirect and Link rules include 3http://ai.stanford.edu/rion/swn/ 4As a non-comparable reference, Snows fine-grained evaluation showed a precision of 0.84 on 10K rules and 0.68 on 20K rules; however, they were interested only in the hyponym relation while we evaluate our rules according to the broader LR relation." ></td>
	<td class="line x" title="107:229	synonyms (NY State Trooper  New York State Police), morphological derivations (irritateirritation), different spellings or naming (Pytagoras Pythagoras) and acronyms (AISAlarm Indication Signal)." ></td>
	<td class="line x" title="108:229	4.2 Error Analysis We sampled 100 rules which were annotated as incorrect and examined the causes of errors." ></td>
	<td class="line x" title="109:229	Figure 1 shows the distribution of error types." ></td>
	<td class="line x" title="110:229	Wrong NP part The most common error (35% of the errors) is taking an inappropriate part of a noun phrase (NP) as the rule right hand side (RHS)." ></td>
	<td class="line x" title="111:229	As described in Section 3, we create two rules from each extracted NP, by taking both the head noun and the complete base NP as RHSs." ></td>
	<td class="line x" title="112:229	While both rules are usually correct, there are cases in which the left hand side (LHS) refers to the NP as a whole but not to part of it." ></td>
	<td class="line x" title="113:229	For example, Margaret Thatcher refers to United Kingdom but not to Kingdom." ></td>
	<td class="line x" title="114:229	In Section 5 we suggest a filtering method which addresses some of these errors." ></td>
	<td class="line x" title="115:229	Future research may exploit methods for detecting multi-words expressions." ></td>
	<td class="line x" title="116:229	All-N patt ern errors 13%Transp arent hea d 11% Wrong N P part 35% Technica l errors 10% D ates and Places 5% Link errors 5% Redirect errors 5% Related b ut not Referring 16% Figure 1: Error analysis: type of incorrect rules Related but not Referring Although all terms in a definition are highly related to the defined concept, not all are referred by it." ></td>
	<td class="line x" title="117:229	For example the origin of a person (*The BeatlesLiverpool5) or family ties such as daughter of or sire of." ></td>
	<td class="line x" title="118:229	All-N errors Some of the articles start with a long sentence which may include information that is not directly referred by the title of the article." ></td>
	<td class="line x" title="119:229	For instance, consider *Interstate 80  California from Interstate 80 runs from California to New Jersey." ></td>
	<td class="line x" title="120:229	In Section 4.3 we further analyze this type of error and point at a possible direction for addressing it." ></td>
	<td class="line x" title="121:229	Transparent head This is the phenomenon in which the syntactic head of a noun phrase does 5The asterisk denotes an incorrect rule 453 Relation Rule Path Pattern Location LovekCambodia Lovek city in Cambodia Occupation Thomas H. Cormencomputer science Thomas H. Cormen professor of computer science Creation Genocidal HealerJames White Genocidal Healer novel by James White Origin Willem van AelstDutch Willem van Aelst Dutch artist Alias Dean MoriartyBenjamin Linus Dean Moriarty is an alias of Benjamin Linus on Lost." ></td>
	<td class="line x" title="122:229	Spelling EgushawaAgushaway Egushawa, also spelled Agushaway Table 3: All-N rules exemplifying various types of LR relations not bear its primary meaning, while it has a modifier which serves as the semantic head (Fillmore et al., 2002; Grishman et al., 1986)." ></td>
	<td class="line x" title="123:229	Since parsers identify the syntactic head, we extract an incorrect rule in such cases." ></td>
	<td class="line x" title="124:229	For instance, deriving *Prince William  member instead of Prince William  British Royal Family from Prince William is a member of the British Royal Family." ></td>
	<td class="line x" title="125:229	Even though we implemented the common solution of using a list of typical transparent heads, this solution is partial since there is no closed set of such phrases." ></td>
	<td class="line x" title="126:229	Technical errors Technical extraction errors were mainly due to erroneous identification of the title in the definition sentence or mishandling nonEnglish texts." ></td>
	<td class="line x" title="127:229	Dates and Places Dates and places where a certain person was born at, lived in or worked at often appear in definitions but do not comply to the lexical reference notion (*Galileo Galilei  15 February 1564)." ></td>
	<td class="line x" title="128:229	Link errors These are usually the result of wrong assignment of the reference direction." ></td>
	<td class="line x" title="129:229	Such errors mostly occur when a general term, e.g. revolution, links to a more specific albeit typical concept, e.g. French Revolution." ></td>
	<td class="line x" title="130:229	Redirect errors These may occur in some cases in which the extracted rule is not bidirectional." ></td>
	<td class="line x" title="131:229	E.g. *Anti-globalization  Movement of Movements is wrong but the opposite entailment direction is correct, as Movement of Movements is a popular term in Italy for Anti-globalization." ></td>
	<td class="line x" title="132:229	4.3 Scoring All-N Rules We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them (which was exploited also in (Snow et al., 2006))." ></td>
	<td class="line x" title="133:229	For instance, the path produced by Minipar for example 4 in Table 1 is title subjalbumvrelreleased bysubj bypcompn noun." ></td>
	<td class="line x" title="134:229	In order to estimate the likelihood that a syntactic path indicates lexical reference we collected from Wikipedia all paths connecting a title to a noun phrase in the definition sentence." ></td>
	<td class="line x" title="135:229	We note that since there is no available resource which covers the full breadth of lexical reference we could not obtain sufficiently broad supervised training data for learning which paths correspond to correct references." ></td>
	<td class="line x" title="136:229	This is in contrast to (Snow et al., 2005) which focused only on hyponymy and synonymy relations and could therefore extract positive and negative examples from WordNet." ></td>
	<td class="line x" title="137:229	We therefore propose the following unsupervised reference likelihood score for a syntactic path p within a definition, based on two counts: the number of times p connects an article title with a noun in its definition, denoted by Ct(p), and the total number of ps occurrences in Wikipedia definitions, C(p)." ></td>
	<td class="line x" title="138:229	The score of a path is then defined as Ct(p)C(p) . The rational for this score is that C(p)Ct(p) corresponds to the number of times in which the path connects two nouns within the definition, none of which is the title." ></td>
	<td class="line x" title="139:229	These instances are likely to be non-referring, since a concise definition typically does not contain terms that can be inferred from each other." ></td>
	<td class="line x" title="140:229	Thus our score may be seen as an approximation for the probability that the two nouns connected by an arbitrary occurrence of the path would satisfy the reference relation." ></td>
	<td class="line x" title="141:229	For instance, the path of example 4 obtained a score of 0.98." ></td>
	<td class="line x" title="142:229	We used this score to sort the set of rules extracted by the All-N method and split the sorted list into 3 thirds: top, middle and bottom." ></td>
	<td class="line x" title="143:229	As shown in Table 4, this obtained reasonably high precision for the top third of these rules, relative to the other two thirds." ></td>
	<td class="line x" title="144:229	This precision difference indicates that our unsupervised path score provides useful information about rule reliability." ></td>
	<td class="line x" title="145:229	It is worth noting that in our sample 57% of AllN errors, 62% of Related but not Referring incorrect rules and all incorrect rules of type Dates and 454 Extraction Per Method Accumulated Method P Est." ></td>
	<td class="line x" title="146:229	#Rules P %obtained All-Ntop 0.60 684,238 0.76 83 All-Nmiddle 0.46 380,572 0.72 90 All-Nbottom 0.41 515,764 0.66 100 Table 4: Splitting All-N extraction method into 3 sub-types." ></td>
	<td class="line x" title="147:229	These three rows replace the last row of Table 2 Places were extracted by the All-Nbottom method and thus may be identified as less reliable." ></td>
	<td class="line x" title="148:229	However, this split was not observed to improve performance in the application oriented evaluations of Section 6." ></td>
	<td class="line x" title="149:229	Further research is thus needed to fully exploit the potential of the syntactic path as an indicator for rule correctness." ></td>
	<td class="line x" title="150:229	5 Filtering Rules Following our error analysis, future research is needed for addressing each specific type of error." ></td>
	<td class="line x" title="151:229	However, during the analysis we observed that all types of erroneous rules tend to relate terms that are rather unlikely to co-occur together." ></td>
	<td class="line x" title="152:229	We therefore suggest, as an optional filter, to recognize such rules by their co-occurrence statistics using the common Dice coefficient: 2C(LHS,RHS) C(LHS) +C(RHS) where C(x) is the number of articles in Wikipedia in which all words of x appear." ></td>
	<td class="line x" title="153:229	In order to partially overcome the Wrong NP part error, identified in Section 4.2 to be the most common error, we adjust the Dice equation for rules whose RHS is also part of a larger noun phrase (NP): 2(C(LHS,RHS)C(LHS,NPRHS)) C(LHS) +C(RHS) where NPRHS is the complete NP whose part is the RHS." ></td>
	<td class="line x" title="154:229	This adjustment counts only cooccurrences in which the LHS appears with the RHS alone and not with the larger NP." ></td>
	<td class="line x" title="155:229	This substantially reduces the Dice score for those cases in which the LHS co-occurs mainly with the full NP." ></td>
	<td class="line x" title="156:229	Given the Dice score rules whose score does not exceed a threshold may be filtered." ></td>
	<td class="line x" title="157:229	For example, the incorrect rule *aerial tramwaycar was filtered, where the correct RHS for this LHS is the complete NP cable car." ></td>
	<td class="line x" title="158:229	Another filtered rule is magiccryptography which is correct only for a very idiosyncratic meaning.6 We also examined another filtering score, the cosine similarity between the vectors representing the two rule sides in LSA (Latent Semantic Analysis) space (Deerwester et al., 1990)." ></td>
	<td class="line x" title="159:229	However, as the results with this filter resemble those for Dice we present results only for the simpler Dice filter." ></td>
	<td class="line x" title="160:229	6 Application Oriented Evaluations Our primary application oriented evaluation is within an unsupervised lexical expansion scenario applied to a text categorization data set (Section 6.1)." ></td>
	<td class="line x" title="161:229	Additionally, we evaluate the utility of our rule base as a lexical resource for recognizing textual entailment (Section 6.2)." ></td>
	<td class="line x" title="162:229	6.1 Unsupervised Text Categorization Our categorization setting resembles typical query expansion in information retrieval (IR), where the category name is considered as the query." ></td>
	<td class="line x" title="163:229	The advantage of using a text categorization test set is that it includes exhaustive annotation for all documents." ></td>
	<td class="line x" title="164:229	Typical IR datasets, on the other hand, are partially annotated through a pooling procedure." ></td>
	<td class="line x" title="165:229	Thus, some of our valid lexical expansions might retrieve non-annotated documents that were missed by the previously pooled systems." ></td>
	<td class="line x" title="166:229	6.1.1 Experimental Setting Our categorization experiment follows a typical keywords-based text categorization scheme (McCallum and Nigam, 1999; Liu et al., 2004)." ></td>
	<td class="line x" title="167:229	Taking a lexical reference perspective, we assume that the characteristic expansion terms for a category should refer to the term (or terms) denoting the category name." ></td>
	<td class="line x" title="168:229	Accordingly, we construct the categorys feature vector by taking first the category name itself, and then expanding it with all lefthand sides of lexical reference rules whose righthand side is the category name." ></td>
	<td class="line x" title="169:229	For example, the category Cars is expanded by rules such as Ferrari F50car." ></td>
	<td class="line x" title="170:229	During classification cosine similarity is measured between the feature vector of the classified document and the expanded vectors of all categories." ></td>
	<td class="line x" title="171:229	The document is assigned to the category which yields the highest similarity score, following a single-class classification approach (Liu et al., 2004)." ></td>
	<td class="line x" title="172:229	6Magic was the United States codename for intelligence derived from cryptanalysis during World War II." ></td>
	<td class="line x" title="173:229	455 Rule Base R P F1 Baselines: No Expansion 0.19 0.54 0.28 WikiBL 0.19 0.53 0.28 Snow400K 0.19 0.54 0.28 Lin 0.25 0.39 0.30 WordNet 0.30 0.47 0.37 Extraction Methods from Wikipedia: Redirect + Be-Comp 0.22 0.55 0.31 All rules 0.31 0.38 0.34 All rules + Dice filter 0.31 0.49 0.38 Union: WordNet + WikiAll rules+Dice 0.35 0.47 0.40 Table 5: Results of different rule bases for 20 newsgroups category name expansion It should be noted that keyword-based text categorization systems employ various additional steps, such as bootstrapping, which generalize to multi-class settings and further improve performance." ></td>
	<td class="line x" title="174:229	Our basic implementation suffices to evaluate comparatively the direct impact of different expansion resources on the initial classification." ></td>
	<td class="line x" title="175:229	For evaluation we used the test set of the bydate version of the 20-News Groups collection,7 which contains 18,846 documents partitioned (nearly) evenly over the 20 categories8." ></td>
	<td class="line x" title="176:229	6.1.2 Baselines Results We compare the quality of our rule base expansions to 5 baselines (Table 5)." ></td>
	<td class="line x" title="177:229	The first avoids any expansion, classifying documents based on cosine similarity with category names only." ></td>
	<td class="line x" title="178:229	As expected, it yields relatively high precision but low recall, indicating the need for lexical expansion." ></td>
	<td class="line x" title="179:229	The second baseline is our implementation of the relevant part of the Wikipedia extraction in (Kazama and Torisawa, 2007), taking the first noun after a be verb in the definition sentence, denoted as WikiBL." ></td>
	<td class="line x" title="180:229	This baseline does not improve performance at all over no expansion." ></td>
	<td class="line x" title="181:229	The next two baselines employ state-of-the-art lexical resources." ></td>
	<td class="line x" title="182:229	One uses Snows extension to WordNet which was mentioned earlier." ></td>
	<td class="line x" title="183:229	This resource did not yield a noticeable improvement, ei7www.ai.mit.edu/people/jrennie/20Newsgroups." ></td>
	<td class="line x" title="184:229	8The keywords used as category names are: atheism; graphic; microsoft windows; ibm,pc,hardware; mac,hardware; x11,x-windows; sale; car; motorcycle; baseball; hockey; cryptography; electronics; medicine; outer space; christian(noun & adj); gun; mideast,middle east; politics; religion ther over the No Expansion baseline or over WordNet when joined with its expansions." ></td>
	<td class="line oc" title="185:229	The second uses Lin dependency similarity, a syntacticdependency based distributional word similarity resource described in (Lin, 1998a)9." ></td>
	<td class="line x" title="186:229	We used various thresholds on the length of the expansion list derived from this resource." ></td>
	<td class="line x" title="187:229	The best result, reported here, provides only a minor F1 improvement over No Expansion, with modest recall increase and significant precision drop, as can be expected from such distributional method." ></td>
	<td class="line x" title="188:229	The last baseline uses WordNet for expansion." ></td>
	<td class="line x" title="189:229	First we expand all the senses of each category name by their derivations and synonyms." ></td>
	<td class="line x" title="190:229	Each obtained term is then expanded by its hyponyms, or by its meronyms if it has no hyponyms." ></td>
	<td class="line x" title="191:229	Finally, the results are further expanded by their derivations and synonyms.10 WordNet expansions improve substantially both Recall and F1 relative to No Expansion, while decreasing precision." ></td>
	<td class="line x" title="192:229	6.1.3 Wikipedia Results We then used for expansion different subsets of our rule base, producing alternative recallprecision tradeoffs." ></td>
	<td class="line x" title="193:229	Table 5 presents the most interesting results." ></td>
	<td class="line x" title="194:229	Using any subset of the rules yields better performance than any of the other automatically constructed baselines (Lin, Snow and WikiBL)." ></td>
	<td class="line x" title="195:229	Utilizing the most precise extraction methods of Redirect and Be-Comp yields the highest precision, comparable to No Expansion, but just a small recall increase." ></td>
	<td class="line x" title="196:229	Using the entire rule base yields the highest recall, while filtering rules by the Dice coefficient (with 0.1 threshold) substantially increases precision without harming recall." ></td>
	<td class="line x" title="197:229	With this configuration our automaticallyconstructed resource achieves comparable performance to the manually built WordNet." ></td>
	<td class="line x" title="198:229	Finally, since a dictionary and an encyclopedia are complementary in nature, we applied the union of WordNet and the filtered Wikipedia expansions." ></td>
	<td class="line x" title="199:229	This configuration yields the best results: it maintains WordNets precision and adds nearly 50% to the recall increase of WordNet over No Expansion, indicating the substantial marginal contribution of Wikipedia." ></td>
	<td class="line x" title="200:229	Furthermore, with the fast growth of Wikipedia the recall of our resource is expected to increase while maintaining its precision." ></td>
	<td class="line x" title="201:229	9Downloaded from www.cs.ualberta.ca/lindek/demos.htm 10We also tried expanding by the entire hyponym hierarchy and considering only the first sense of each synset, but the method described above achieved the best performance." ></td>
	<td class="line x" title="202:229	456 Category Name Expanding Terms Politics opposition, coalition, whip(a) Cryptography adversary, cryptosystem, key Mac PowerBook, Radius(b), Grab(c) Religion heaven, creation, belief, missionary Medicine doctor, physician, treatment, clinical Computer Graphics radiosity(d), rendering, siggraph(e) Table 6: Some Wikipedia rules not in WordNet, which contributed to text categorization." ></td>
	<td class="line x" title="203:229	(a) a legislator who enforce leadership desire (b) a hardware firm specializing in Macintosh equipment (c) a Macintosh screen capture software (d) an illumination algorithm (e) a computer graphics conference Configuration Accuracy Accuracy Drop WordNet + Wikipedia 60.0 % Without WordNet 57.7 % 2.3 % Without Wikipedia 58.9 % 1.1 % Table 7: RTE accuracy results for ablation tests." ></td>
	<td class="line x" title="204:229	Table 6 illustrates few examples of useful rules that were found in Wikipedia but not in WordNet." ></td>
	<td class="line x" title="205:229	We conjecture that in other application settings the rules extracted from Wikipedia might show even greater marginal contribution, particularly in specialized domains not covered well by WordNet." ></td>
	<td class="line x" title="206:229	Another advantage of a resource based on Wikipedia is that it is available in many more languages than WordNet." ></td>
	<td class="line x" title="207:229	6.2 Recognizing Textual Entailment (RTE) As a second application-oriented evaluation we measured the contributions of our (filtered) Wikipedia resource and WordNet to RTE inference (Giampiccolo et al., 2007)." ></td>
	<td class="line x" title="208:229	To that end, we incorporated both resources within a typical basic RTE system architecture (Bar-Haim et al., 2008)." ></td>
	<td class="line x" title="209:229	This system determines whether a text entails another sentence based on various matching criteria that detect syntactic, logical and lexical correspondences (or mismatches)." ></td>
	<td class="line x" title="210:229	Most relevant for our evaluation, lexical matches are detected when a Wikipedia rules LHS appears in the text and its RHS in the hypothesis, or similarly when pairs of WordNet synonyms, hyponyms-hypernyms and derivations appear across the text and hypothesis." ></td>
	<td class="line x" title="211:229	The systems weights were trained on the development set of RTE-3 and tested on RTE-4 (which included this year only a test set)." ></td>
	<td class="line x" title="212:229	To measure the marginal contribution of the two resources we performed ablation tests, comparing the accuracy of the full system to that achieved when removing either resource." ></td>
	<td class="line x" title="213:229	Table 7 presents the results, which are similar in nature to those obtained for text categorization." ></td>
	<td class="line x" title="214:229	Wikipedia obtained a marginal contribution of 1.1%, about half of the analogous contribution of WordNets manuallyconstructed information." ></td>
	<td class="line x" title="215:229	We note that for current RTE technology it is very typical to gain just a few percents in accuracy thanks to external knowledge resources, while individual resources usually contribute around 0.52% (Iftene and BalahurDobrescu, 2007; Dinu and Wang, 2009)." ></td>
	<td class="line x" title="216:229	Some Wikipedia rules not in WordNet which contributed to RTE inference are Jurassic Park  Michael Crichton, GCCGulf Cooperation Council." ></td>
	<td class="line x" title="217:229	7 Conclusions and Future Work We presented construction of a large-scale resource of lexical reference rules, as useful in applied lexical inference." ></td>
	<td class="line x" title="218:229	Extensive rule-level analysis showed that different recall-precision tradeoffs can be obtained by utilizing different extraction methods." ></td>
	<td class="line x" title="219:229	It also identified major reasons for errors, pointing at potential future improvements." ></td>
	<td class="line x" title="220:229	We further suggested a filtering method which significantly improved performance." ></td>
	<td class="line x" title="221:229	Even though the resource was constructed by quite simple extraction methods, it was proven to be beneficial within two different application setting." ></td>
	<td class="line x" title="222:229	While being an automatically built resource, extracted from a knowledge-base created for human consumption, it showed comparable performance to WordNet, which was manually created for computational purposes." ></td>
	<td class="line x" title="223:229	Most importantly, it also provides complementary knowledge to WordNet, with unique lexical reference rules." ></td>
	<td class="line x" title="224:229	Future research is needed to improve resources precision, especially for the All-N method." ></td>
	<td class="line x" title="225:229	As a first step, we investigated a novel unsupervised score for rules extracted from definition sentences." ></td>
	<td class="line x" title="226:229	We also intend to consider the rule base as a directed graph and exploit the graph structure for further rule extraction and validation." ></td>
	<td class="line x" title="227:229	Acknowledgments The authors would like to thank Idan Szpektor for valuable advices." ></td>
	<td class="line x" title="228:229	This work was partially supported by the NEGEV project (www.negevinitiative.org), the PASCAL-2 Network of Excellence of the European Community FP7-ICT-20071-216886 and by the Israel Science Foundation grant 1112/08." ></td>
	<td class="line x" title="229:229	457" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-1052
Employing Topic Models for Pattern-based Semantic Class Discovery
Zhang, Huibin;Zhu, Mingjie;Shi, Shuming;Wen, Ji-Rong;"></td>
	<td class="line x" title="1:246	Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 459467, Suntec, Singapore, 2-7 August 2009." ></td>
	<td class="line x" title="2:246	c2009 ACL and AFNLP Employing Topic Models for Pattern-based Semantic Class Discovery   Huibin Zhang1*     Mingjie Zhu2*     Shuming Shi3     Ji-Rong Wen3 1Nankai University 2University of Science and Technology of China 3Microsoft Research Asia {v-huibzh, v-mingjz, shumings, jrwen}@microsoft.com    Abstract  A semantic class is a collection of items (words or phrases) which have semantically peer or sibling relationship." ></td>
	<td class="line x" title="3:246	This paper studies the employment of topic models to automatically construct semantic classes, taking as the source data a collection of raw semantic classes (RASCs), which were extracted by applying predefined patterns to web pages." ></td>
	<td class="line x" title="4:246	The primary requirement (and challenge) here is dealing with multi-membership: An item may belong to multiple semantic classes; and we need to discover as many as possible the different semantic classes the item belongs to." ></td>
	<td class="line x" title="5:246	To adopt topic models, we treat RASCs as documents, items as words, and the final semantic classes as topics." ></td>
	<td class="line x" title="6:246	Appropriate preprocessing and postprocessing are performed to improve results quality, to reduce computation cost, and to tackle the fixed-k constraint of a typical topic model." ></td>
	<td class="line x" title="7:246	Experiments conducted on 40 million web pages show that our approach could yield better results than alternative approaches." ></td>
	<td class="line x" title="8:246	1 Introduction Semantic class construction (Lin and Pantel, 2001; Pantel and Lin, 2002; Pasca, 2004; Shinzato and Torisawa, 2005; Ohshima et al., 2006) tries to discover the peer or sibling relationship among terms or phrases by organizing them into semantic classes." ></td>
	<td class="line x" title="9:246	For example, {red, white, black} is a semantic class consisting of color instances." ></td>
	<td class="line x" title="10:246	A popular way for semantic class discovery is pattern-based approach, where predefined patterns (Table 1) are applied to a   This work was performed when the authors were interns at Microsoft Research Asia collection of web pages or an online web search engine to produce some raw semantic classes (abbreviated as RASCs, Table 2)." ></td>
	<td class="line x" title="11:246	RASCs cannot be treated as the ultimate semantic classes, because they are typically noisy and incomplete, as shown in Table 2." ></td>
	<td class="line x" title="12:246	In addition, the information of one real semantic class may be distributed in lots of RASCs (R2 and R3 in Table 2)." ></td>
	<td class="line x" title="13:246	Type Pattern SENT NP {, NP}*{,} (and|or) {other} NP TAG <UL>  <LI>item</LI>     <LI>item</LI>  </UL> TAG <SELECT> <OPTION>item <OPTION>item </SELECT> * SENT: Sentence structure patterns; TAG: HTML Tag patterns Table 1." ></td>
	<td class="line x" title="14:246	Sample patterns  R1: {gold, silver, copper, coal, iron, uranium} R2: {red, yellow, color, gold, silver, copper} R3: {red, green, blue, yellow} R4: {HTML, Text, PDF, MS Word, Any file type} R5: {Today, Tomorrow, Wednesday, Thursday, Friday, Saturday, Sunday} R6: {Bush, Iraq, Photos, USA, War} Table 2." ></td>
	<td class="line x" title="15:246	Sample raw semantic classes (RASCs)  This paper aims to discover high-quality semantic classes from a large collection of noisy RASCs." ></td>
	<td class="line x" title="16:246	The primary requirement (and challenge) here is to deal with multi-membership, i.e., one item may belong to multiple different semantic classes." ></td>
	<td class="line x" title="17:246	For example, the term Lincoln can simultaneously represent a person, a place, or a car brand name." ></td>
	<td class="line x" title="18:246	Multi-membership is more popular than at a first glance, because quite a lot of English common words have also been borrowed as company names, places, or product names." ></td>
	<td class="line x" title="19:246	For a given item (as a query) which belongs to multiple semantic classes, we intend to return the semantic classes separately, rather than mixing all their items together." ></td>
	<td class="line x" title="20:246	Existing pattern-based approaches only provide very limited support to multi-membership." ></td>
	<td class="line x" title="21:246	For example, RASCs with the same labels (or hypernyms) are merged in (Pasca, 2004) to gen459 erate the ultimate semantic classes." ></td>
	<td class="line x" title="22:246	This is problematic, because RASCs may not have (accurate) hypernyms with them." ></td>
	<td class="line x" title="23:246	In this paper, we propose to use topic models to address the problem." ></td>
	<td class="line x" title="24:246	In some topic models, a document is modeled as a mixture of hidden topics." ></td>
	<td class="line x" title="25:246	The words of a document are generated according to the word distribution over the topics corresponding to the document (see Section 2 for details)." ></td>
	<td class="line x" title="26:246	Given a corpus, the latent topics can be obtained by a parameter estimation procedure." ></td>
	<td class="line x" title="27:246	Topic modeling provides a formal and convenient way of dealing with multi-membership, which is our primary motivation of adopting topic models here." ></td>
	<td class="line x" title="28:246	To employ topic models, we treat RASCs as documents, items as words, and the final semantic classes as topics." ></td>
	<td class="line x" title="29:246	There are, however, several challenges in applying topic models to our problem." ></td>
	<td class="line x" title="30:246	To begin with, the computation is intractable for processing a large collection of RASCs (our dataset for experiments contains 2.7 million unique RASCs extracted from 40 million web pages)." ></td>
	<td class="line x" title="31:246	Second, typical topic models require the number of topics (k) to be given." ></td>
	<td class="line x" title="32:246	But it lacks an easy way of acquiring the ideal number of semantic classes from the source RASC collection." ></td>
	<td class="line x" title="33:246	For the first challenge, we choose to apply topic models to the RASCs containing an item q, rather than the whole RASC collection." ></td>
	<td class="line x" title="34:246	In addition, we also perform some preprocessing operations in which some items are discarded to further improve efficiency." ></td>
	<td class="line x" title="35:246	For the second challenge, considering that most items only belong to a small number of semantic classes, we fix (for all items q) a topic number which is slightly larger than the number of classes an item could belong to." ></td>
	<td class="line x" title="36:246	And then a postprocessing operation is performed to merge the results of topic models to generate the ultimate semantic classes." ></td>
	<td class="line x" title="37:246	Experimental results show that, our topic model approach is able to generate higher-quality semantic classes than popular clustering algorithms (e.g., K-Medoids and DBSCAN)." ></td>
	<td class="line x" title="38:246	We make two contributions in the paper: On one hand, we find an effective way of constructing high-quality semantic classes in the patternbased category which deals with multimembership." ></td>
	<td class="line x" title="39:246	On the other hand, we demonstrate, for the first time, that topic modeling can be utilized to help mining the peer relationship among words." ></td>
	<td class="line x" title="40:246	In contrast, the general related relationship between words is extracted in existing topic modeling applications." ></td>
	<td class="line x" title="41:246	Thus we expand the application scope of topic modeling." ></td>
	<td class="line x" title="42:246	2 Topic Models In this section we briefly introduce the two widely used topic models which are adopted in our paper." ></td>
	<td class="line x" title="43:246	Both of them model a document as a mixture of hidden topics." ></td>
	<td class="line x" title="44:246	The words of every document are assumed to be generated via a generative probability process." ></td>
	<td class="line x" title="45:246	The parameters of the model are estimated from a training process over a given corpus, by maximizing the likelihood of generating the corpus." ></td>
	<td class="line x" title="46:246	Then the model can be utilized to inference a new document." ></td>
	<td class="line x" title="47:246	pLSI: The probabilistic Latent Semantic Indexing Model (pLSI) was introduced in Hofmann (1999), arose from Latent Semantic Indexing (Deerwester et al., 1990)." ></td>
	<td class="line x" title="48:246	The following process illustrates how to generate a document d in pLSI: 1." ></td>
	<td class="line x" title="49:246	Pick a topic mixture distribution  ( | )." ></td>
	<td class="line x" title="50:246	2." ></td>
	<td class="line x" title="51:246	For each word wi in d a. Pick a latent topic z with the probability  ( | ) for wi b. Generate wi with probability  (  | ) So with k latent topics, the likelihood of generating a document d is   ( ) =           ( | )   (2.1) LDA (Blei et al., 2003): In LDA, the topic mixture is drawn from a conjugate Dirichlet prior that remains the same for all documents (Figure 1)." ></td>
	<td class="line x" title="52:246	The generative process for each document in the corpus is, 1." ></td>
	<td class="line x" title="53:246	Choose document length N from a Poisson distribution Poisson( )." ></td>
	<td class="line x" title="54:246	2." ></td>
	<td class="line x" title="55:246	Choose   from a Dirichlet distribution with parameter  . 3." ></td>
	<td class="line x" title="56:246	For each of the N words wi." ></td>
	<td class="line x" title="57:246	a. Choose a topic z from a Multinomial distribution with parameter  . b. Pick a word wi from       ,  . So the likelihood of generating a document is   ( ) =   ( | )     ( | )      ,      (2.2)   Figure 1." ></td>
	<td class="line x" title="58:246	Graphical model representation of LDA, from Blei et al.(2003)  w z  N M 460 3 Our Approach The source data of our approach is a collection (denoted as CR) of RASCs extracted via applying patterns to a large collection of web pages." ></td>
	<td class="line x" title="60:246	Given an item as an input query, the output of our approach is one or multiple semantic classes for the item." ></td>
	<td class="line x" title="61:246	To be applicable in real-world dataset, our approach needs to be able to process at least millions of RASCs." ></td>
	<td class="line x" title="62:246	3.1 Main Idea As reviewed in Section 2, topic modeling provides a formal and convenient way of grouping documents and words to topics." ></td>
	<td class="line x" title="63:246	In order to apply topic models to our problem, we map RASCs to documents, items to words, and treat the output topics yielded from topic modeling as our semantic classes (Table 3)." ></td>
	<td class="line x" title="64:246	The motivation of utilizing topic modeling to solve our problem and building the above mapping comes from the following observations." ></td>
	<td class="line x" title="65:246	1) In our problem, one item may belong to multiple semantic classes; similarly in topic modeling, a word can appear in multiple topics." ></td>
	<td class="line x" title="66:246	2) We observe from our source data that some RASCs are comprised of items in multiple semantic classes." ></td>
	<td class="line x" title="67:246	And at the same time, one document could be related to multiple topics in some topic models (e.g., pLSI and LDA)." ></td>
	<td class="line x" title="68:246	Topic modeling Semantic class construction word item (word or phrase) document RASC topic semantic class Table 3." ></td>
	<td class="line x" title="69:246	The mapping from the concepts in topic modeling to those in semantic class construction  Due to the above observations, we hope topic modeling can be employed to construct semantic classes from RASCs, just as it has been used in assigning documents and words to topics." ></td>
	<td class="line x" title="70:246	There are some critical challenges and issues which should be properly addressed when topic models are adopted here." ></td>
	<td class="line x" title="71:246	Efficiency: Our RASC collection CR contains about 2.7 million unique RASCs and 26 million (1 million unique) items." ></td>
	<td class="line x" title="72:246	Building topic models directly for such a large dataset may be computationally intractable." ></td>
	<td class="line x" title="73:246	To overcome this challenge, we choose to apply topic models to the RASCs containing a specific item rather than the whole RASC collection." ></td>
	<td class="line x" title="74:246	Please keep in mind that our goal in this paper is to construct the semantic classes for an item when the item is given as a query." ></td>
	<td class="line x" title="75:246	For one item q, we denote CR(q) to be all the RASCs in CR containing the item." ></td>
	<td class="line x" title="76:246	We believe building a topic model over CR(q) is much more effective because it contains significantly fewer documents, words, and topics." ></td>
	<td class="line x" title="77:246	To further improve efficiency, we also perform preprocessing (refer to Section 3.4 for details) before building topic models for CR(q), where some lowfrequency items are removed." ></td>
	<td class="line x" title="78:246	Determine the number of topics: Most topic models require the number of topics to be known beforehand1." ></td>
	<td class="line x" title="79:246	However, it is not an easy task to automatically determine the exact number of semantic classes an item q should belong to." ></td>
	<td class="line x" title="80:246	Actually the number may vary for different q. Our solution is to set (for all items q) the topic number to be a fixed value (k=5 in our experiments) which is slightly larger than the number of semantic classes most items could belong to." ></td>
	<td class="line x" title="81:246	Then we perform postprocessing for the k topics to produce the final properly semantic classes." ></td>
	<td class="line x" title="82:246	In summary, our approach contains three phases (Figure 2)." ></td>
	<td class="line x" title="83:246	We build topic models for every CR(q), rather than the whole collection CR." ></td>
	<td class="line x" title="84:246	A preprocessing phase and a postprocessing phase are added before and after the topic modeling phase to improve efficiency and to overcome the fixed-k problem." ></td>
	<td class="line x" title="85:246	The details of each phase are presented in the following subsections." ></td>
	<td class="line x" title="86:246	Figure 2." ></td>
	<td class="line x" title="87:246	Main phases of our approach  3.2 Adopting Topic Models For an item q, topic modeling is adopted to process the RASCs in CR(q) to generate k semantic classes." ></td>
	<td class="line x" title="88:246	Here we use LDA as an example to  1 Although there is study of non-parametric Bayesian models (Li et al., 2007) which need no prior knowledge of topic number, the computational complexity seems to exceed our efficiency requirement and we shall leave this to future work." ></td>
	<td class="line x" title="89:246	R580 R1 R2 CR Item q Preprocessing  400  1  2 T5 T1 T2 C3 C1 C2 Topic modeling Postprocessing T3 T4 CR(q) 461 illustrate the process." ></td>
	<td class="line x" title="90:246	The case of other generative topic models (e.g., pLSI) is very similar." ></td>
	<td class="line x" title="91:246	According to the assumption of LDA and our concept mapping in Table 3, a RASC (document) is viewed as a mixture of hidden semantic classes (topics)." ></td>
	<td class="line x" title="92:246	The generative process for a RASC R in the corpus CR(q) is as follows, 1) Choose a RASC size (i.e., the number of items in R): NR ~ Poisson( )." ></td>
	<td class="line x" title="93:246	2) Choose a k-dimensional vector    from a Dirichlet distribution with parameter  . 3) For each of the NR items an: a) Pick a semantic class    from a multinomial distribution with parameter   . b) Pick an item an from  (  |  , ) , where the item probabilities are parameterized by the matrix  . There are three parameters in the model:   (a scalar),   (a k-dimensional vector), and   (a     matrix where V is the number of distinct items in CR(q))." ></td>
	<td class="line x" title="94:246	The parameter values can be obtained from a training (or called parameter estimation) process over CR(q), by maximizing the likelihood of generating the corpus." ></td>
	<td class="line x" title="95:246	Once   is determined, we are able to compute  ( | , ), the probability of item a belonging to semantic class z. Therefore we can determine the members of a semantic class z by selecting those items with high      ,   values." ></td>
	<td class="line x" title="96:246	The number of topics k is assumed known and fixed in LDA." ></td>
	<td class="line x" title="97:246	As has been discussed in Section 3.1, we set a constant k value for all different CR(q)." ></td>
	<td class="line x" title="98:246	And we rely on the postprocessing phase to merge the semantic classes produced by the topic model to generate the ultimate semantic classes." ></td>
	<td class="line x" title="99:246	When topic modeling is used in document classification, an inference procedure is required to determine the topics for a new document." ></td>
	<td class="line x" title="100:246	Please note that inference is not needed in our problem." ></td>
	<td class="line x" title="101:246	One natural question here is: Considering that in most topic modeling applications, the words within a resultant topic are typically semantically related but may not be in peer relationship, then what is the intuition that the resultant topics here are semantic classes rather than lists of generally related words?" ></td>
	<td class="line x" title="102:246	The magic lies in the documents we used in employing topic models." ></td>
	<td class="line x" title="103:246	Words co-occurred in real documents tend to be semantically related; while items co-occurred in RASCs tend to be peers." ></td>
	<td class="line x" title="104:246	Experimental results show that most items in the same output semantic class have peer relationship." ></td>
	<td class="line x" title="105:246	It might be noteworthy to mention the exchangeability or bag-of-words assumption in most topic models." ></td>
	<td class="line x" title="106:246	Although the order of words in a document may be important, standard topic models neglect the order for simplicity and other reasons2." ></td>
	<td class="line x" title="107:246	The order of items in a RASC is clearly much weaker than the order of words in an ordinary document." ></td>
	<td class="line x" title="108:246	In some sense, topic models are more suitable to be used here than in processing an ordinary document corpus." ></td>
	<td class="line x" title="109:246	3.3 Preprocessing and Postprocessing Preprocessing is applied to CR(q) before we build topic models for it." ></td>
	<td class="line x" title="110:246	In this phase, we discard from all RASCs the items with frequency (i.e., the number of RASCs containing the item) less than a threshold h. A RASC itself is discarded from CR(q) if it contains less than two items after the item-removal operations." ></td>
	<td class="line x" title="111:246	We choose to remove low-frequency items, because we found that low-frequency items are seldom important members of any semantic class for q. So the goal is to reduce the topic model training time (by reducing the training data) without sacrificing results quality too much." ></td>
	<td class="line x" title="112:246	In the experiments section, we compare the approaches with and without preprocessing in terms of results quality and efficiency." ></td>
	<td class="line x" title="113:246	Interestingly, experimental results show that, for some small threshold values, the results quality becomes higher after preprocessing is performed." ></td>
	<td class="line x" title="114:246	We will give more discussions in Section 4." ></td>
	<td class="line x" title="115:246	In the postprocessing phase, the output semantic classes (topics) of topic modeling are merged to generate the ultimate semantic classes." ></td>
	<td class="line x" title="116:246	As indicated in Sections 3.1 and 3.2, we fix the number of topics (k=5) for different corpus CR(q) in employing topic models." ></td>
	<td class="line x" title="117:246	For most items q, this is a larger value than the real number of semantic classes the item belongs to." ></td>
	<td class="line x" title="118:246	As a result, one real semantic class may be divided into multiple topics." ></td>
	<td class="line x" title="119:246	Therefore one core operation in this phase is to merge those topics into one semantic class." ></td>
	<td class="line x" title="120:246	In addition, the items in each semantic class need to be properly ordered." ></td>
	<td class="line x" title="121:246	Thus main operations include, 1) Merge semantic classes 2) Sort the items in each semantic class Now we illustrate how to perform the operations." ></td>
	<td class="line x" title="122:246	Merge semantic classes: The merge process is performed by repeatedly calculating the simi 2 There are topic model extensions considering word order in documents, such as Griffiths et al.(2005)." ></td>
	<td class="line x" title="124:246	462 larity between two semantic classes and merging the two ones with the highest similarity until the similarity is under a threshold." ></td>
	<td class="line x" title="125:246	One simple and straightforward similarity measure is the Jaccard coefficient,       1, 2 =   1   2   1   2  (3.1) where  1   2  and  1   2  are respectively the intersection and union of semantic classes C1 and C2." ></td>
	<td class="line x" title="126:246	This formula might be over-simple, because the similarity between two different items is not exploited." ></td>
	<td class="line x" title="127:246	So we propose the following measure,       1, 2 =      ( , )   2   1   1    2  (3.2) where |C| is the number of items in semantic class C, and sim(a,b) is the similarity between items a and b, which will be discussed shortly." ></td>
	<td class="line x" title="128:246	In Section 4, we compare the performance of the above two formulas by experiments." ></td>
	<td class="line x" title="129:246	Sort items: We assign an importance score to every item in a semantic class and sort them according to the importance scores." ></td>
	<td class="line x" title="130:246	Intuitively, an item should get a high rank if the average similarity between the item and the other items in the semantic class is high, and if it has high similarity to the query item q. Thus we calculate the importance of item a in a semantic class C as follows,     |  =   sim(a,C)+(1- )  sim(a,q) (3.3) where   is a parameter in [0,1], sim(a,q) is the similarity between a and the query item q, and sim(a,C) is the similarity between a and C, calculated as,       ,  =     ( , )       (3.4) Item similarity calculation: Formulas 3.2, 3.3, and 3.4 rely on the calculation of the similarity between two items." ></td>
	<td class="line x" title="131:246	One simple way of estimating item similarity is to count the number of RASCs containing both of them." ></td>
	<td class="line x" title="132:246	We extend such an idea by distinguishing the reliability of different patterns and punishing term similarity contributions from the same site." ></td>
	<td class="line x" title="133:246	The resultant similarity formula is,     ( , ) =  log(1 +   ( (  , ))    =1 )   =1  (3.5) where Ci,j is a RASC containing both a and b, P(Ci,j) is the pattern via which the RASC is extracted, and w(P) is the weight of pattern P. Assume all these RASCs belong to m sites with Ci,j extracted from a page in site i, and ki being the number of RASCs corresponding to site i. To determine the weight of every type of pattern, we randomly selected 50 RASCs for each pattern and labeled their quality." ></td>
	<td class="line x" title="134:246	The weight of each kind of pattern is then determined by the average quality of all labeled RASCs corresponding to it." ></td>
	<td class="line x" title="135:246	The efficiency of postprocessing is not a problem, because the time cost of postprocessing is much less than that of the topic modeling phase." ></td>
	<td class="line x" title="136:246	3.4 Discussion 3.4.1 Efficiency of processing popular items Our approach receives a query item q from users and returns the semantic classes containing the query." ></td>
	<td class="line x" title="137:246	The maximal query processing time should not be larger than several seconds, because users would not like to wait more time." ></td>
	<td class="line x" title="138:246	Although the average query processing time of our approach is much shorter than 1 second (see Table 4 in Section 4), it takes several minutes to process a popular item such as Washington, because it is contained in a lot of RASCs." ></td>
	<td class="line x" title="139:246	In order to reduce the maximal online processing time, our solution is offline processing popular items and storing the resultant semantic classes on disk." ></td>
	<td class="line x" title="140:246	The time cost of offline processing is feasible, because we spent about 15 hours on a 4core machine to complete the offline processing for all the items in our RASC collection." ></td>
	<td class="line x" title="141:246	3.4.2 Alternative approaches One may be able to easily think of other approaches to address our problem." ></td>
	<td class="line x" title="142:246	Here we discuss some alternative approaches which are treated as our baseline in experiments." ></td>
	<td class="line x" title="143:246	RASC clustering: Given a query item q, run a clustering algorithm over CR(q) and merge all RASCs in the same cluster as one semantic class." ></td>
	<td class="line x" title="144:246	Formula 3.1 or 3.2 can be used to compute the similarity between RASCs in performing clustering." ></td>
	<td class="line x" title="145:246	We try two clustering algorithms in experiments: K-Medoids and DBSCAN." ></td>
	<td class="line x" title="146:246	Please note kmeans cannot be utilized here because coordinates are not available for RASCs." ></td>
	<td class="line x" title="147:246	One drawback of RASC clustering is that it cannot deal with the case of one RASC containing the items from multiple semantic classes." ></td>
	<td class="line x" title="148:246	Item clustering: By Formula 3.5, we are able to construct an item graph GI to record the neighbors (in terms of similarity) of each item." ></td>
	<td class="line x" title="149:246	Given a query item q, we first retrieve its neighbors from GI, and then run a clustering algorithm over the neighbors." ></td>
	<td class="line x" title="150:246	As in the case of RASC clustering, we try two clustering algorithms in experiments: K-Medoids and DBSCAN." ></td>
	<td class="line x" title="151:246	The primary disadvantage of item clustering is that it cannot assign an item (except for the query item q) to 463 multiple semantic classes." ></td>
	<td class="line x" title="152:246	As a result, when we input gold as the query, the item silver can only be assigned to one semantic class, although the term can simultaneously represents a color and a chemical element." ></td>
	<td class="line x" title="153:246	4 Experiments 4.1 Experimental Setup Datasets: By using the Open Directory Project (ODP3) URLs as seeds, we crawled about 40 million English web pages in a breadth-first way." ></td>
	<td class="line x" title="154:246	RASCs are extracted via applying a list of sentence structure patterns and HTML tag patterns (see Table 1 for some examples)." ></td>
	<td class="line x" title="155:246	Our RASC collection CR contains about 2.7 million unique RASCs and 1 million distinct items." ></td>
	<td class="line x" title="156:246	Query set and labeling: We have volunteers to try Google Sets4, record their queries being used, and select overall 55 queries to form our query set." ></td>
	<td class="line x" title="157:246	For each query, the results of all approaches are mixed together and labeled by following two steps." ></td>
	<td class="line x" title="158:246	In the first step, the standard (or ideal) semantic classes (SSCs) for the query are manually determined." ></td>
	<td class="line x" title="159:246	For example, the ideal semantic classes for item Georgia may include Countries, and U.S. states." ></td>
	<td class="line x" title="160:246	In the second step, each item is assigned a label of Good, Fair, or Bad with respect to each SSC." ></td>
	<td class="line x" title="161:246	For example, silver is labeled Good with respect to colors and chemical elements." ></td>
	<td class="line x" title="162:246	We adopt metric MnDCG (Section 4.2) as our evaluation metric." ></td>
	<td class="line x" title="163:246	Approaches for comparison: We compare our approach with the alternative approaches discussed in Section 3.4.2." ></td>
	<td class="line x" title="164:246	LDA: Our approach with LDA as the topic model." ></td>
	<td class="line x" title="165:246	The implementation of LDA is based on Bleis code of variational EM for LDA5." ></td>
	<td class="line x" title="166:246	pLSI: Our approach with pLSI as the topic model." ></td>
	<td class="line x" title="167:246	The implementation of pLSI is based on Schein, et al.(2002)." ></td>
	<td class="line x" title="169:246	KMedoids-RASC: The RASC clustering approach illustrated in Section 3.4.2, with the K-Medoids clustering algorithm utilized." ></td>
	<td class="line x" title="170:246	DBSCAN-RASC: The RASC clustering approach with DBSCAN utilized." ></td>
	<td class="line x" title="171:246	KMedoids-Item: The item clustering approach with the K-Medoids utilized." ></td>
	<td class="line x" title="172:246	DBSCAN-Item: The item clustering approach with the DBSCAN clustering algorithm utilized." ></td>
	<td class="line x" title="173:246	3 http://www.dmoz.org 4 http://labs.google.com/sets 5 http://www.cs.princeton.edu/~blei/lda-c/ K-Medoids clustering needs to predefine the cluster number k. We fix the k value for all different query item q, as has been done for the topic model approach." ></td>
	<td class="line x" title="174:246	For fair comparison, the same postprocessing is made for all the approaches." ></td>
	<td class="line x" title="175:246	And the same preprocessing is made for all the approaches except for the item clustering ones (to which the preprocessing is not applicable)." ></td>
	<td class="line x" title="176:246	4.2 Evaluation Methodology Each produced semantic class is an ordered list of items." ></td>
	<td class="line x" title="177:246	A couple of metrics in the information retrieval (IR) community like Precision@10, MAP (mean average precision), and nDCG (normalized discounted cumulative gain) are available for evaluating a single ranked list of items per query (Croft et al., 2009)." ></td>
	<td class="line x" title="178:246	Among the metrics, nDCG (Jarvelin and Kekalainen, 2000) can handle our three-level judgments (Good, Fair, and Bad, refer to Section 4.1),      @ =      /log( + 1)   =1       /log( + 1) =1  (4.1) where G(i) is the gain value assigned to the ith item, and G*(i) is the gain value assigned to the ith item of an ideal (or perfect) ranking list." ></td>
	<td class="line x" title="179:246	Here we extend the IR metrics to the evaluation of multiple ordered lists per query." ></td>
	<td class="line x" title="180:246	We use nDCG as the basic metric and extend it to MnDCG." ></td>
	<td class="line x" title="181:246	Assume labelers have determined m SSCs (SSC1~SSCm, refer to Section 4.1) for query q and the weight (or importance) of SSCi is wi." ></td>
	<td class="line x" title="182:246	Assume n semantic classes are generated by an approach and n1 of them have corresponding SSCs (i.e., no appropriate SSC can be found for the remaining n-n1 semantic classes)." ></td>
	<td class="line x" title="183:246	We define the MnDCG score of an approach (with respect to query q) as,          =  1           (SSC ) i=1   mi=1  (4.2) where             = 0                                              = 0 1   max  [1,   ](       ,  )        0   (4.3) In the above formula, nDCG(Gi,j) is the nDCG score of semantic class Gi,j; and ki denotes the number of semantic classes assigned to SSCi." ></td>
	<td class="line x" title="184:246	For a list of queries, the MnDCG score of an algorithm is the average of all scores for the queries." ></td>
	<td class="line x" title="185:246	The metric is designed to properly deal with the following cases, 464 i)." ></td>
	<td class="line x" title="186:246	One semantic class is wrongly split into multiple ones: Punished by dividing    in Formula 4.3; ii)." ></td>
	<td class="line x" title="187:246	A semantic class is too noisy to be assigned to any SSC: Processed by the n1/n in Formula 4.2; iii)." ></td>
	<td class="line x" title="188:246	Fewer semantic classes (than the number of SSCs) are produced: Punished in Formula 4.3 by assigning a zero value." ></td>
	<td class="line x" title="189:246	iv)." ></td>
	<td class="line x" title="190:246	Wrongly merge multiple semantic classes into one: The nDCG score of the merged one will be small because it is computed with respect to only one single SSC." ></td>
	<td class="line x" title="191:246	The gain values of nDCG for the three relevance levels (Bad, Fair, and Good) are respectively -1, 1, and 2 in experiments." ></td>
	<td class="line x" title="192:246	4.3 Experimental  Results 4.3.1 Overall performance comparison Figure 3 shows the performance comparison between the approaches listed in Section 4.1, using metrics MnDCG@n (n=110) . Postprocessing is performed for all the approaches, where Formula 3.2 is adopted to compute the similarity between semantic classes." ></td>
	<td class="line x" title="193:246	The results show that that the topic modeling approaches produce higher-quality semantic classes than the other approaches." ></td>
	<td class="line x" title="194:246	It indicates that the topic mixture assumption of topic modeling can handle the multi-membership problem very well here." ></td>
	<td class="line x" title="195:246	Among the alternative approaches, RASC clustering behaves better than item clustering." ></td>
	<td class="line x" title="196:246	The reason might be that an item cannot belong to multiple clusters in the two item clustering approaches, while RASC clustering allows this." ></td>
	<td class="line x" title="197:246	For the RASC clustering approaches, although one item has the chance to belong to different semantic classes, one RASC can only belong to one semantic class." ></td>
	<td class="line x" title="198:246	Figure 3." ></td>
	<td class="line x" title="199:246	Quality comparison (MnDCG@n) among approaches (frequency threshold h = 4 in preprocessing; k = 5 in topic models) 4.3.2 Preprocessing experiments Table 4 shows the average query processing time and results quality of the LDA approach, by varying frequency threshold h. Similar results are observed for the pLSI approach." ></td>
	<td class="line x" title="200:246	In the table, h=1 means no preprocessing is performed." ></td>
	<td class="line x" title="201:246	The average query processing time is calculated over all items in our dataset." ></td>
	<td class="line x" title="202:246	As the threshold h increases, the processing time decreases as expected, because the input of topic modeling gets smaller." ></td>
	<td class="line x" title="203:246	The second column lists the results quality (measured by MnDCG@10)." ></td>
	<td class="line x" title="204:246	Interestingly, we get the best results quality when h=4 (i.e., the items with frequency less than 4 are discarded)." ></td>
	<td class="line x" title="205:246	The reason may be that most low-frequency items are noisy ones." ></td>
	<td class="line x" title="206:246	As a result, preprocessing can improve both results quality and processing efficiency; and h=4 seems a good choice in preprocessing for our dataset." ></td>
	<td class="line x" title="207:246	h Avg." ></td>
	<td class="line x" title="208:246	Query Proc." ></td>
	<td class="line x" title="209:246	Time (seconds) Quality (MnDCG@10) 1 0.414 0.281 2 0.375 0.294 3 0.320 0.322 4 0.268 0.331 5 0.232 0.328 6 0.210 0.315 7 0.197 0.315 8 0.184 0.313 9 0.173 0.288 Table 4." ></td>
	<td class="line x" title="210:246	Time complexity and quality comparison among LDA approaches of different thresholds  4.3.3 Postprocessing experiments  Figure 4." ></td>
	<td class="line x" title="211:246	Results quality comparison among topic modeling approaches with and without postprocessing (metric: MnDCG@10)  The effect of postprocessing is shown in Figure 4." ></td>
	<td class="line x" title="212:246	In the figure, NP means no postprocessing is performed." ></td>
	<td class="line x" title="213:246	Sim1 and Sim2 respectively mean Formula 3.1 and Formula 3.2 are used in postprocessing as the similarity measure between 0 0 . 0 5 0 . 1 0 . 1 5 0 . 2 0 . 2 5 0 . 3 0 . 3 5 0 . 4 0 . 4 5 1 2 3 4 5 6 7 8 9 10 p L SI L DA K M e d o id s R A SC DB SC A N R A SC K M e d o id s I t e m DB SC A N I t e m n 0 . 2 7 0 . 2 8 0 . 2 9 0 . 3 0 . 3 1 0 . 3 2 0 . 3 3 0 . 3 4 L DA p L SI NP Sim 1 Sim 2 465 semantic classes." ></td>
	<td class="line x" title="214:246	The same preprocessing (h=4) is performed in generating the data." ></td>
	<td class="line x" title="215:246	It can be seen that postprocessing improves results quality." ></td>
	<td class="line x" title="216:246	Sim2 achieves more performance improvement than Sim1, which demonstrates the effectiveness of the similarity measure in Formula 3.2." ></td>
	<td class="line x" title="217:246	4.3.4 Sample results Table 5 shows the semantic classes generated by our LDA approach for some sample queries in which the bad classes or bad members are highlighted (to save space, 10 items are listed here, and the query itself is omitted in the resultant semantic classes)." ></td>
	<td class="line x" title="218:246	Query Semantic Classes apple C1: ibm, microsoft, sony, dell, toshiba,  samsung, panasonic, canon, nec, sharp  C2: peach, strawberry, cherry, orange, banana, lemon, pineapple, raspberry, pear, grape  gold C1: silver, copper, platinum, zinc, lead, iron, nickel, tin, aluminum, manganese  C2: silver, red, black, white, blue, purple, orange, pink, brown, navy  C3: silver, platinum, earrings, diamonds, rings, bracelets, necklaces, pendants, jewelry, watches  C4: silver, home, money, business, metal, furniture, shoes, gypsum, hematite, fluorite  lincoln C1: ford, mazda, toyota, dodge, nissan, honda, bmw, chrysler, mitsubishi, audi  C2: bristol, manchester, birmingham, leeds, london, cardiff, nottingham, newcastle, sheffield, southampton  C3: jefferson, jackson, washington, madison, franklin, sacramento, new york city, monroe, Louisville, marion  computer science C1: chemistry, mathematics, physics, biology, psychology, education, history, music, business, economics  Table 5." ></td>
	<td class="line x" title="219:246	Semantic classes generated by our approach for some sample queries (topic model = LDA)  5 Related Work Several categories of work are related to ours." ></td>
	<td class="line x" title="220:246	The first category is about set expansion (i.e., retrieving one semantic class given one term or a couple of terms)." ></td>
	<td class="line oc" title="221:246	Syntactic context information is used (Hindle, 1990; Ruge, 1992; Lin, 1998) to compute term similarities, based on which similar words to a particular word can directly be returned." ></td>
	<td class="line x" title="222:246	Google sets is an online service which, given one to five items, predicts other items in the set." ></td>
	<td class="line x" title="223:246	Ghahramani and Heller (2005) introduce a Bayesian Sets algorithm for set expansion." ></td>
	<td class="line x" title="224:246	Set expansion is performed by feeding queries to web search engines in Wang and Cohen (2007) and Kozareva (2008)." ></td>
	<td class="line x" title="225:246	All of the above work only yields one semantic class for a given query." ></td>
	<td class="line x" title="226:246	Second, there are pattern-based approaches in the literature which only do limited integration of RASCs (Shinzato and Torisawa, 2004; Shinzato and Torisawa, 2005; Pasca, 2004), as discussed in the introduction section." ></td>
	<td class="line x" title="227:246	In Shi et al.(2008), an ad-hoc approach was proposed to discover the multiple semantic classes for one item." ></td>
	<td class="line x" title="229:246	The third category is distributional similarity approaches which provide multi-membership support (Harris, 1985; Lin  and Pantel, 2001; Pantel and Lin, 2002)." ></td>
	<td class="line x" title="230:246	Among them, the CBC algorithm (Pantel and Lin, 2002) addresses the multi-membership problem." ></td>
	<td class="line x" title="231:246	But it relies on term vectors and centroids which are not available in pattern-based approaches." ></td>
	<td class="line x" title="232:246	It is therefore not clear whether it can be borrowed to deal with multi-membership here." ></td>
	<td class="line x" title="233:246	Among the various applications of topic modeling, maybe the efforts of using topic model for Word Sense Disambiguation (WSD) are most relevant to our work." ></td>
	<td class="line x" title="234:246	In Cai et al (2007), LDA is utilized to capture the global context information as the topic features for better performing the WSD task." ></td>
	<td class="line x" title="235:246	In Boyd-Graber et al.(2007), Latent Dirichlet with WordNet (LDAWN) is developed for simultaneously disambiguating a corpus and learning the domains in which to consider each word." ></td>
	<td class="line x" title="237:246	They do not generate semantic classes." ></td>
	<td class="line x" title="238:246	6 Conclusions We presented an approach that employs topic modeling for semantic class construction." ></td>
	<td class="line x" title="239:246	Given an item q, we first retrieve all RASCs containing the item to form a collection CR(q)." ></td>
	<td class="line x" title="240:246	Then we perform some preprocessing to CR(q) and build a topic model for it." ></td>
	<td class="line x" title="241:246	Finally, the output semantic classes of topic modeling are post-processed to generate the final semantic classes." ></td>
	<td class="line x" title="242:246	For the CR(q) which contains a lot of RASCs, we perform offline processing according to the above process and store the results on disk, in order to reduce the online query processing time." ></td>
	<td class="line x" title="243:246	We also proposed an evaluation methodology for measuring the quality of semantic classes." ></td>
	<td class="line x" title="244:246	We show by experiments that our topic modeling approach outperforms the item clustering and RASC clustering approaches." ></td>
	<td class="line x" title="245:246	Acknowledgments We wish to acknowledge help from Xiaokang Liu for mining RASCs from web pages, Changliang Wang and Zhongkai Fu for data process." ></td>
	<td class="line x" title="246:246	466" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-2062
Syntax is from Mars while Semantics from Venus! Insights from Spectral Analysis of Distributional Similarity Networks
Biemann, Christian;Choudhury, Monojit;Mukherjee, Animesh;"></td>
	<td class="line x" title="1:81	Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 245248, Suntec, Singapore, 4 August 2009." ></td>
	<td class="line x" title="2:81	c 2009 ACL and AFNLP Syntax is from Mars while Semantics from Venus!" ></td>
	<td class="line x" title="3:81	Insights from Spectral Analysis of Distributional Similarity Networks Chris Biemann Microsoft/Powerset, San Francisco Chris.Biemann@microsoft.com Monojit Choudhury Microsoft Research Lab India monojitc@microsoft.com Animesh Mukherjee Indian Institute of Technology Kharagpur, India animeshm@cse.iitkgp.ac.in Abstract We study the global topology of the syntactic and semantic distributional similarity networks for English through the technique of spectral analysis." ></td>
	<td class="line x" title="4:81	We observe that while the syntactic network has a hierarchical structure with strong communities and their mixtures, the semantic network has several tightly knit communities along with a large core without any such welldefined community structure." ></td>
	<td class="line x" title="5:81	1 Introduction Syntax and semantics are two tightly coupled, yet very different properties of any natural language  as if one is from Mars and the other from Venus." ></td>
	<td class="line x" title="6:81	Indeed, this exploratory work shows that the distributional properties of syntax are quite different from those of semantics." ></td>
	<td class="line x" title="7:81	Distributional hypothesis states that the words that occur in the same contexts tend to have similar meanings (Harris, 1968)." ></td>
	<td class="line x" title="8:81	Using this hypothesis, one can define a vector space model for words where every word is a point in some n-dimensional space and the distance between them can be interpreted as the inverse of the semantic or syntactic similarity between their corresponding distributional patterns." ></td>
	<td class="line x" title="9:81	Usually, the co-occurrence patterns with respect to the function words are used to define the syntactic context, whereas that with respect to the content words define the semantic context." ></td>
	<td class="line x" title="10:81	An alternative, but equally popular, visualization of distributional similarity is through graphs or networks, where each word is represented as nodes and weighted edges indicate the extent of distributional similarity between them." ></td>
	<td class="line x" title="11:81	What are the commonalities and differences between the syntactic and semantic distributional patterns of the words of a language?" ></td>
	<td class="line x" title="12:81	This study is an initial attempt to answer this fundamental and intriguing question, whereby we construct the syntactic and semantic distributional similarity network (DSN) and analyze their spectrum to understand their global topology." ></td>
	<td class="line x" title="13:81	We observe that there are significant differences between the two networks: the syntactic network has well-defined hierarchical community structure implying a systematic organization of natural classes and their mixtures (e.g., words which are both nouns and verbs); on the other hand, the semantic network has several isolated clusters or the so called tightly knit communities and a core component that lacks a clear community structure." ></td>
	<td class="line x" title="14:81	Spectral analysis also reveals the basis of formation of the natural classes or communities within these networks." ></td>
	<td class="line x" title="15:81	These observations collectively point towards a well accepted fact that the semantic space of natural languages has extremely high dimension with no clearly observable subspaces, which makes theorizing and engineering harder compared to its syntactic counterpart." ></td>
	<td class="line x" title="16:81	Spectral analysis is the backbone of several techniques, such as multi-dimensional scaling, principle component analysis and latent semantic analysis, that are commonly used in NLP." ></td>
	<td class="line x" title="17:81	In recent times, there have been some work on spectral analysis of linguistic networks as well." ></td>
	<td class="line x" title="18:81	Belkin and Goldsmith (2002) applied spectral analysis to understand the struture of morpho-syntactic networks of English words." ></td>
	<td class="line x" title="19:81	The current work, on the other hand, is along the lines of Mukherjee et al.(2009), where the aim is to understand not only the principles of organization, but also the global topology of the network through the study of the spectrum." ></td>
	<td class="line x" title="21:81	The most important contribution here, however, lies in the comparison of the topology of the syntactic and semantic DSNs, which, to the best of our knowledge, has not been explored previously." ></td>
	<td class="line x" title="22:81	245 2 Network Construction The syntactic and semantic DSNs are constructed from a raw text corpus." ></td>
	<td class="line x" title="23:81	This work is restricted to the study of English DSNs only1." ></td>
	<td class="line x" title="24:81	Syntactic DSN: We define our syntactic network in a similar way as previous works in unsupervised parts-of-speech induction (cf.(Schutze, 1995; Biemann, 2006)): The most frequent 200 words in the corpus (July 2008 dump of English Wikipedia) are used as features in a word window of 2 around the target words." ></td>
	<td class="line x" title="26:81	Thus, each target word is described by an 800-dimensional feature vector, containing the number of times we observe one of the most frequent 200 words in the respective positions relative to the target word." ></td>
	<td class="line x" title="27:81	In our experiments, we collect data for the most frequent 1000 and 5000 target words, arguing that all syntactic classes should be represented in those." ></td>
	<td class="line x" title="28:81	A similarity measure between target words is defined by the cosine between the feature vectors." ></td>
	<td class="line x" title="29:81	The syntactic graph is formed by inserting the target words as nodes and connecting nodes with edge weights equal to their cosine similarity if this similarity exceeds a threshold t = 0.66." ></td>
	<td class="line oc" title="30:81	Semantic DSN: The construction of this network is inspired by (Lin, 1998)." ></td>
	<td class="line x" title="31:81	Specifically, we parsed a dump of English Wikipedia (July 2008) with the XLE parser (Riezler et al., 2002) and extracted the following dependency relations for nouns: Verb-Subject, Verb-Object, Nouncoordination, NN-compound, Adj-Mod." ></td>
	<td class="line x" title="32:81	These lexicalized relations act as features for the nouns." ></td>
	<td class="line x" title="33:81	Verbs are recorded together with their subcategorization frame, i.e. the same verb lemmas in different subcat frames would be treated as if they were different verbs." ></td>
	<td class="line x" title="34:81	We compute log-likelihood significance between features and target nouns (as in (Dunning, 1993)) and keep only the most significant 200 features per target word." ></td>
	<td class="line x" title="35:81	Each feature f gets a feature weight that is inversely proportional to the logarithm of the number of target words it applies on." ></td>
	<td class="line x" title="36:81	The similarity of two target nouns is then computed as the sum of the feature weights they share." ></td>
	<td class="line x" title="37:81	For our analysis, we restrict the graph to the most frequent 5000 target common nouns and keep only the 200 highest weighted edges per target noun." ></td>
	<td class="line x" title="38:81	Note that the degree of a node can 1As shown in (Nath et al., 2008), the basic structure of these networks are insensitive to minor variations in the parameters (e.g., thresholds and number of words) and the choice of distance metric." ></td>
	<td class="line x" title="39:81	Figure 1: The spectrum of the syntactic and semantic DSNs of 1000 nodes." ></td>
	<td class="line x" title="40:81	still be larger than 200 if this node is contained in many 200 highest weighted edges of other target nouns." ></td>
	<td class="line x" title="41:81	3 Spectrum of DSNs Spectral analysis refers to the systematic study of the eigenvalues and eigenvectors of a network." ></td>
	<td class="line x" title="42:81	Although here we study the spectrum of the adjacency matrix of the weighted networks, it is also quite common to study the spectrum of the Laplacian of the adjacency matrix (see for example, Belkin and Goldsmith (2002))." ></td>
	<td class="line x" title="43:81	Fig." ></td>
	<td class="line x" title="44:81	1 compares the spectrum of the syntactic and semantic DSNs with 1000 nodes, which has been computed as follows." ></td>
	<td class="line x" title="45:81	First, the 1000 eigenvalues of the adjacency matrix are sorted in descending order." ></td>
	<td class="line x" title="46:81	Then we compute the spectral coverage till the ith eigenvalue by adding the squares of the first i eigenvalues and normalizing it by the sum of the squares of all the eigenvalues a quantity also known as the Frobenius norm of the matrix." ></td>
	<td class="line x" title="47:81	We observe that for the semantic DSN the first 10 eigenvalues cover only 40% of the spectrum and the first 500 together make up 75% of the spectrum." ></td>
	<td class="line x" title="48:81	On the other hand, for the syntactic DSN, the first 10 eigenvalues cover 75% of the spectrum while the first 20 covers 80%." ></td>
	<td class="line x" title="49:81	In other words, the structure of the syntactic DSN is governed by a few (order of 10) significant principles, whereas that of the semantic DSN is controlled by a large number of equally insignificant factors." ></td>
	<td class="line x" title="50:81	The aforementioned observation has the following alternative, but equivalent interpretations: (a) the syntactic DSN can be clustered in lower dimensions (e.g., 10 or 20) because, most of the rows in the matrix can be approximately expressed as a linear combination of the top 10 to 20 246 Figure 2: Plot of corpus frequency based rank vs. eigenvector centrality of the words in the DSNs of 5000 nodes." ></td>
	<td class="line x" title="51:81	eigenvectors." ></td>
	<td class="line x" title="52:81	Furthermore, the graceful decay of the eigenvalues of the syntactic DSN implies the existence of a hierarchical community structure, which has been independently verified by Nath et al.(2008) through analysis of the degree distribution of such networks; and (b) a random walk conducted on the semantic DSN will have a high tendency to drift away very soon from the semantic class of the starting node, whereas in the syntactic DSN, the random walk is expected to stay within the same syntactic class for a long time." ></td>
	<td class="line x" title="54:81	Therefore, it is reasonable to advocate that characterization and processing of syntatic classes is far less confusing than that of the semantic classes  a fact that requires no emphasis." ></td>
	<td class="line x" title="55:81	4 Eigenvector Analysis The first eigenvalue tells us to what extent the rows of the adjacency matrix are correlated and therefore, the corresponding eigenvector is not a dimension pointing to any classificatory basis of the words." ></td>
	<td class="line x" title="56:81	However, as we shall see shortly, the other eigenvectors corresponding to the significantly high eigenvalues are important classificatory dimensions." ></td>
	<td class="line x" title="57:81	Fig 2 shows the plot of the first eigenvector component (aka eigenvector centrality) of a word versus its rank based on the corpus frequency." ></td>
	<td class="line x" title="58:81	We observe that the very high frequency (i.e., low rank) nodes in both the networks have low eigenvector centrality, whereas the medium frequency nodes display a wide range of centrality values." ></td>
	<td class="line x" title="59:81	However, the most striking difference between the networks is that while in the syntactic DSN the centrality values are approximately normally distributed for the medium frequency words, the least frequent words enjoy the highest centrality for the semantic DSN." ></td>
	<td class="line x" title="60:81	Furthermore, we observe that the most central nodes in the semantic DSN correspond to semantically unambiguous words of similar nature (e.g., deterioration, abandonment, fragmentation, turmoil)." ></td>
	<td class="line x" title="61:81	This indicates the existence of several tightly knit communities consisting of not so high frequency words which pull in a significant fraction of the overall centrality." ></td>
	<td class="line x" title="62:81	Since the high frequency words are usually polysemous, they on the other hand form a large, but noncliqueish structure at the core of the network with a few connections to the tightly knit communities." ></td>
	<td class="line x" title="63:81	This is known as the tightly knit community effect (TKC effect) that renders very low centrality values to the truly central nodes of the network (Lempel and Moran, 2000)." ></td>
	<td class="line x" title="64:81	The structure of the syntactic DSN, however, is not governed by the TKC effect to such an extreme extent." ></td>
	<td class="line x" title="65:81	Hence, one can expect to easily identify the natural classes of the syntactic DSN, but not its semantic counterpart." ></td>
	<td class="line x" title="66:81	In fact, this observation is further corroborated by the higher eigenvectors." ></td>
	<td class="line x" title="67:81	Fig." ></td>
	<td class="line x" title="68:81	3 shows the plot of the second eigenvector component versus the fourth one for the two DSNs consisting of 5000 words." ></td>
	<td class="line x" title="69:81	It is observed that for the syntactic network, the words get neatly clustered into two sets comprised of words with the positive and negative second eigenvector components." ></td>
	<td class="line x" title="70:81	The same plot for the semantic DSN shows that a large number of words have both the components close to zero and only a few words stand out on one side of the axes  those with positive second eigenvector component and those with negative fourth eigenvector component." ></td>
	<td class="line x" title="71:81	In essence, none of these eigenvectors can neatly classify the words into two sets  a trend which is observed for all the higher eigenvectors (we conducted experiments for up to the twentieth eigenvector)." ></td>
	<td class="line x" title="72:81	Study of the individual eignevectors further reveals that the nodes with either the extreme positive or the extreme negative components have strong linguistic correlates." ></td>
	<td class="line x" title="73:81	For instance, in the syntactic DSN, the two ends of the second eigen247 Figure 3: Plot of the second vs. fourth eigenvector components of the words in the DSNs." ></td>
	<td class="line x" title="74:81	vector correspond to nouns and adjectives; one of the ends of the fourth, fifth, sixth and the twelfth eigenvectors respectively correspond to location nouns, prepositions, first names and initials, and verbs." ></td>
	<td class="line x" title="75:81	In the semantic DSN, one of the ends of the second, third, fourth and tenth eigenvectors respectively correspond to professions, abstract terms, food items and body parts." ></td>
	<td class="line x" title="76:81	One would expect that the higher eigenvectors (say the 50th one) would show no clear classificatory basis for the syntactic DSN, while for the semantic DSN those could be still associated with prominent linguistic correlates." ></td>
	<td class="line x" title="77:81	5 Conclusion and Future Work Here, we presented some initial investigations into the nature of the syntactic and semantic DSNs through the method of spectral analysis, whereby we could observe that the global topology of the two networks are significantly different in terms of the organization of their natural classes." ></td>
	<td class="line x" title="78:81	While the syntactic DSN seems to exhibit a hierarchical structure with a few strong natural classes and their mixtures, the semantic DSN is composed of several tightly knit small communities along with a large core consisting of very many smaller illdefined and ambiguous sets of words." ></td>
	<td class="line x" title="79:81	To visualize, one could draw an analogy of the syntactic and semantic DSNs respectively to crystalline and amorphous solids." ></td>
	<td class="line x" title="80:81	This work can be furthered in several directions, such as, (a) testing the robustness of the findings across languages, different network construction policies, and corpora of different sizes and from various domains; (b) clustering of the words on the basis of eigenvector components and using them in NLP applications such as unsupervised POS tagging and WSD; and (c) spectral analysis of WordNet and other manually constructed ontologies." ></td>
	<td class="line x" title="81:81	Acknowledgement CB and AM are grateful to Microsoft Research India, respectively for hosting him while this research was conducted, and financial support." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W09-0201
One Distributional Memory, Many Semantic Spaces
Baroni, Marco;Lenci, Alessandro;"></td>
	<td class="line x" title="1:170	Proceedings of the EACL 2009 Workshop on GEMS: GEometical Models of Natural Language Semantics, pages 18, Athens, Greece, 31 March 2009." ></td>
	<td class="line x" title="2:170	c2009 Association for Computational Linguistics One distributional memory, many semantic spaces Marco Baroni University of Trento Trento, Italy marco.baroni@unitn.it Alessandro Lenci University of Pisa Pisa, Italy alessandro.lenci@ilc.cnr.it Abstract We propose an approach to corpus-based semantics, inspired by cognitive science, in which different semantic tasks are tackled using the same underlying repository of distributional information, collected once and for all from the source corpus." ></td>
	<td class="line x" title="3:170	Task-specific semantic spaces are then built on demand from the repository." ></td>
	<td class="line x" title="4:170	A straightforward implementation of our proposal achieves state-of-the-art performance on a number of unrelated tasks." ></td>
	<td class="line x" title="5:170	1 Introduction Corpus-derived distributional semantic spaces have proved valuable in tackling a variety of tasks, ranging from concept categorization to relation extraction to many others (Sahlgren, 2006; Turney, 2006; Pado and Lapata, 2007)." ></td>
	<td class="line x" title="6:170	The typical approach in the field has been a local one, in which each semantic task (or set of closely related tasks) is treated as a separate problem, that requires its own corpus-derived model and algorithms." ></td>
	<td class="line x" title="7:170	Its successes notwithstanding, the one task  one model approach has also some drawbacks." ></td>
	<td class="line x" title="8:170	From a cognitive angle, corpus-based models hold promise as simulations of how humans acquire and use conceptual and linguistic information from their environment (Landauer and Dumais, 1997)." ></td>
	<td class="line x" title="9:170	However, the common view in cognitive (neuro)science is that humans resort to a multipurpose semantic memory, i.e., a database of interconnected concepts and properties (Rogers and McClelland, 2004), adapting the information stored there to the task at hand." ></td>
	<td class="line x" title="10:170	From an engineering perspective, going back to the corpus to train a different model for each application is inefficient and it runs the risk of overfitting the model to a specific task, while losing sight of its adaptivity  a highly desirable feature for any intelligent system." ></td>
	<td class="line x" title="11:170	Think, by contrast, of WordNet, a single network of semantic information that has been adapted to all sorts of tasks, many of them certainly not envisaged by the resource creators." ></td>
	<td class="line x" title="12:170	In this paper, we explore a different approach to corpus-based semantics." ></td>
	<td class="line x" title="13:170	Our model consists of a distributional semantic memory  a graph of weighted links between concepts built once and for all from our source corpus." ></td>
	<td class="line x" title="14:170	Starting from the tuples that can be extracted from this graph, we derive multiple semantic spaces to solve a wide range of tasks that exemplify various strands of corpus-based semantic research: measuring semantic similarity between concepts, concept categorization, selectional preferences, analogy of relations between concept pairs, finding pairs that instantiate a target relation and spotting an alternation in verb argument structure." ></td>
	<td class="line x" title="15:170	Given a graph like the one in Figure 1 below, adaptation to all these tasks (and many others) can be reduced to two basic operations: 1) building semantic spaces, as cooccurrence matrices defined by choosing different units of the graph as row and column elements; 2) measuring similarity in the resulting matrix either between specific rows or between a row and an average of rows whose elements share a certain property." ></td>
	<td class="line x" title="16:170	After reviewing some of the most closely related work (Section 2), we introduce our approach (Section 3) and, in Section 4, we proceed to test it in various tasks, showing that its performance is always comparable to that of task-specific methods." ></td>
	<td class="line x" title="17:170	Section 5 draws the current conclusions and discusses future directions." ></td>
	<td class="line x" title="18:170	2 Related work Turney (2008) recently advocated the need for a uniform approach to corpus-based semantic tasks." ></td>
	<td class="line x" title="19:170	Turney recasts a number of semantic challenges in terms of relational or analogical similarity." ></td>
	<td class="line x" title="20:170	Thus, if an algorithm is able to tackle the latter, it can 1 also be used to address the former." ></td>
	<td class="line x" title="21:170	Turney tests his system in a variety of tasks, obtaining good results across the board." ></td>
	<td class="line x" title="22:170	His approach amounts to picking a task (analogy recognition) and reinterpreting other tasks as its particular instances." ></td>
	<td class="line x" title="23:170	Conversely, we assume that each task may keep its specificity, and unification is achieved by designing a sufficiently general distributional structure, from which semantic spaces can be generated on demand." ></td>
	<td class="line x" title="24:170	Currently, the only task we share with Turney is finding SAT analogies, where his method outperforms ours by a large margin (cf.Section 4.2.1)." ></td>
	<td class="line x" title="26:170	However, Turney uses a corpus that is 25 times larger than ours, and introduces negative training examples, whereas we dependencyparse our corpus  thus, performance is not directly comparable." ></td>
	<td class="line x" title="27:170	Besides the fact that our approach does not require labeled training data like Turneys one, it provides, we believe, a more intuitive measure of taxonomic similarity (taxonomic neighbours are concepts that share similar contexts, rather than concepts that co-occur with patterns indicating a taxonomic relation), and it is better suited to model productive semantic phenomena, such as the selectional preferences of verbs with respect to unseen arguments (eating topinambur vs. eating ideas)." ></td>
	<td class="line x" title="28:170	Such tasks will require an extension of the current framework of Turney (2008) beyond evidence from the direct cooccurrence of target word pairs." ></td>
	<td class="line x" title="29:170	While our unified framework is, as far as we know, novel, the specific ways in which we tackle the different tasks are standard." ></td>
	<td class="line oc" title="30:170	Concept similarity is often measured by vectors of co-occurrence with context words that are typed with dependency information (Lin, 1998; Curran and Moens, 2002)." ></td>
	<td class="line x" title="31:170	Our approach to selectional preference is nearly identical to the one of Pado et al.(2007)." ></td>
	<td class="line x" title="33:170	We solve SAT analogies with a simplified version of the method of Turney (2006)." ></td>
	<td class="line x" title="34:170	Detecting whether a pair expresses a target relation by looking at shared connector patterns with model pairs is a common strategy in relation extraction (Pantel and Pennacchiotti, 2008)." ></td>
	<td class="line x" title="35:170	Finally, our method to detect verb slot similarity is analogous to the slot overlap of Joanis et al.(2008) and others." ></td>
	<td class="line x" title="37:170	Since we aim at a unified approach, the lack of originality of our task-specific methods should be regarded as a positive fact: our general framework can naturally reproduce, locally, well-tried ad-hoc solutions." ></td>
	<td class="line x" title="38:170	3 Distributional semantic memory Many different, apparently unrelated, semantic tasks resort to the same underlying information, a distributional semantic memory consisting of weighted concept+link+concept tuples extracted from the corpus." ></td>
	<td class="line x" title="39:170	The concepts in the tuples are typically content words." ></td>
	<td class="line x" title="40:170	The link contains corpusderived information about how the two words are connected in context: it could be for example a dependency path or a shallow lexico-syntactic pattern." ></td>
	<td class="line x" title="41:170	Finally, the weight typically derives from cooccurrence counts for the elements in a tuple, rescaled via entropy, mutual information or similar measures." ></td>
	<td class="line x" title="42:170	The way in which the tuples are identified and weighted when populating the memory is, of course, of fundamental importance to the quality of the resulting models." ></td>
	<td class="line x" title="43:170	However, once the memory has been populated, it can be used to tackle many different tasks, without ever having to go back to the source corpus." ></td>
	<td class="line x" title="44:170	Our approach can be compared with the typical organization of databases, in which multiple alternative views can be obtained from the same underlying data structure, to answer different information needs." ></td>
	<td class="line x" title="45:170	The data structure is virtually independent from the way in which it is accessed." ></td>
	<td class="line x" title="46:170	Similarly, the structure of our repository only obeys to the distributional constraints extracted from the corpus, and it is independent from the ways it will be queried to address a specific semantic task." ></td>
	<td class="line x" title="47:170	Different tasks can simply be defined by how we split the tuples from the repository into row and column elements of a matrix whose cells are filled by the corresponding weights." ></td>
	<td class="line x" title="48:170	Each of these derived matrices represents a particular view of distributional memory: we will discuss some of these views, and the tasks they are appropriate for, in Section 4." ></td>
	<td class="line x" title="49:170	Concretely, we used here the web-derived, 2billion word ukWaC corpus,1 dependency-parsed with MINIPAR.2 Focusing for now on modeling noun-to-noun and noun-to-verb connections, we selected the 20,000 most frequent nouns and 5,000 most frequent verbs as target concepts (minus stop lists of very frequent items)." ></td>
	<td class="line x" title="50:170	We selected as target links the top 30 most frequent direct verbnoun dependency paths (e.g., kill+obj+victim), the top 30 preposition-mediated noun-to-noun or 1http://wacky.sslmit.unibo.it 2http://www.cs.ualberta.ca/lindek/ minipar.htm 2 die victim subj_in 1335.2 teacher subj_tr 109.4 soldier subj_in 4547.5 policeman subj_in 68.6 school in 2.5 kill  subj_tr 22.4 obj 915.4  obj 9.9 subj_tr 1306.9 obj 8948.3 subj_tr 38.2 obj 538.1 at 7020.1 with 28.9 in 11894.4 handbook with 3.2 use 10.1 gun with 105.9 use 41.0 in 2.8 at 10.3 in 2.5 with 30.5 use 7.4 Figure 1: A fragment of distributional memory verb-to-noun paths (e.g., soldier+with+gun) and the top 50 transitive-verb-mediated noun-to-noun paths (e.g., soldier+use+gun)." ></td>
	<td class="line x" title="51:170	We extracted all tuples in which a target link connected two target concepts." ></td>
	<td class="line x" title="52:170	We computed the weight (strength of association) for all the tuples extracted in this way using the local MI measure (Evert, 2005), that is theoretically justified, easy to compute for triples and robust against overestimation of rare events." ></td>
	<td class="line x" title="53:170	Tuples with local MI  0 were discarded." ></td>
	<td class="line x" title="54:170	For each preserved tuplec1+l+c2, we added a sameweight c1 + l1 + c2 tuple." ></td>
	<td class="line x" title="55:170	In graph-theoretical terms (treating concepts as nodes and labeling the weighted edges with links), this means that, for each edge directed from c1 to c2, there is an edge from c2 to c1 with the same weight and inverse label, and that such inverse edges constitute the full set of links directed from c2 to c1." ></td>
	<td class="line x" title="56:170	The resulting database (DM, for Distributional Memory) contains about 69 million tuples." ></td>
	<td class="line x" title="57:170	Figure 1 depicts a fragment of DM represented as a graph (assume, for what we just said, that for each edge from x to y there is a same-weight edge from y to x with inverse label: e.g., the obj link from kill to victim stands for the tuples kill+obj+victim and victim+obj1+kill, both with weight 915.4; subj in identifies the subjects of intransitive constructions, as in The victim died; subj tr refers to the subjects of transitive sentences, as in The policeman killed the victim)." ></td>
	<td class="line x" title="58:170	We also trained 3 closely comparable models that use the same source corpus, the same target concepts (in one case, also the same target links) and local MI as weighting method, with the same filtering threshold." ></td>
	<td class="line x" title="59:170	The myPlain model implements a classic flat co-occurrence approach (Sahlgren, 2006) in which we keep track of verbto-noun co-occurrence within a window that can include, maximally, one intervening noun, and noun-to-noun co-occurrence with no more than 2 intervening nouns." ></td>
	<td class="line x" title="60:170	The myHAL model uses the same co-occurrence window, but, like HAL (Lund and Burgess, 1996), treats left and right cooccurrences as distinct features." ></td>
	<td class="line x" title="61:170	Finally, myDV uses the same dependency-based target links of DM as filters." ></td>
	<td class="line x" title="62:170	Like in the DV model of Pado and Lapata (2007), only pairs connected by target links are preserved, but the links themselves are not part of the model." ></td>
	<td class="line x" title="63:170	Since none of these alternative models stores information about the links, they are only appropriate for the concept similarity tasks, where links are not necessary." ></td>
	<td class="line x" title="64:170	4 Semantic views and experiments We now look at three views of the DM graph: concept-by-link+concept (CxLC), concept+concept-by-link (CCxL), and concept+link-by-concept (CLxC)." ></td>
	<td class="line x" title="65:170	Each view will be tested on one or more semantic tasks and compared with alternative models." ></td>
	<td class="line x" title="66:170	There is a fourth possible view, links-by-concept+concept (LxCC), that is not explored here, but would lead to meaningful semantic tasks (finding links that express similar semantic relations)." ></td>
	<td class="line x" title="67:170	4.1 The CxLC semantic space Much work in computational linguistics and related fields relies on measuring similarity among words/concepts in terms of their patterns of cooccurrence with other words/concepts (Sahlgren, 2006)." ></td>
	<td class="line x" title="68:170	For this purpose, we arrange the information from the graph in a matrix where the concepts (nodes) of interest are rows, and the nodes they are connected to by outgoing edges are columns, typed with the corresponding edge label." ></td>
	<td class="line x" title="69:170	We refer to this view as the concept-by-link+concept 3 (CxLC) semantic space." ></td>
	<td class="line x" title="70:170	From the graph in Figure 1, we can for example construct the matrix in Table 1 (here and below, showing only some rows and columns of interest)." ></td>
	<td class="line x" title="71:170	By comparing the row vectors of such matrix using standard geometrical techniques (e.g., measuring the normalized cosine distance), we can find out about concepts that tend to share similar properties, i.e., are taxonomically similar (synonyms, antonyms, cohyponyms), e.g., soldiers and policemen, that both kill, are killed and use guns." ></td>
	<td class="line x" title="72:170	subj in1subj tr1 obj1 with use die kill kill gun gun teacher 109.4 0.0 9.9 0.0 0.0 victim 1335.2 22.4 915.4 0.0 0.0 soldier 4547.5 1306.9 8948.3 105.9 41.0 policeman 68.6 38.2 538.1 30.5 7.4 Table 1: A fragment of the CxLC space We use the CxLC space in three taxonomic similarity tasks: modeling semantic similarity judgments, noun categorization and verb selectional restrictions." ></td>
	<td class="line x" title="73:170	4.1.1 Human similarity ratings We use the dataset of Rubenstein and Goodenough (1965), consisting of 65 noun pairs rated by 51 subjects on a 0-4 similarity scale (e.g. carautomobile 3.9, cord-smile 0.0)." ></td>
	<td class="line x" title="74:170	The average rating for each pair is taken as an estimate of the perceived similarity between the two words." ></td>
	<td class="line x" title="75:170	Following Pado and Lapata (2007), we use Pearsons r to evaluate how the distances (cosines) in the CxLC space between the nouns in each pair correlate with the ratings." ></td>
	<td class="line x" title="76:170	Percentage correlations for DM, our other models and the best absolute result obtained by Pado and Lapata (DV+), as well as their best cosine-based performance (cosDV+), are reported in Table 2." ></td>
	<td class="line x" title="77:170	model r model r myDV 70 DV+ 62 DM 64 myHAL 61 myPlain 63 cosDV+ 47 Table 2: Correlation with similarity ratings DM is the second-best model, outperformed only by DV when the latter is trained on comparable data (myDV in Table 2)." ></td>
	<td class="line x" title="78:170	Notice that, here and below, we did not try any parameter tuning (e.g., using a similarity measure different than cosine, feature selection, etc.) to improve the performance of DM." ></td>
	<td class="line x" title="79:170	4.1.2 Noun categorization We use the concrete noun dataset of the ESSLLI 2008 Distributional Semantics shared task,3 including 44 concrete nouns to be clustered into cognitively justified categories of increasing generality: 6-way (birds, ground animals, fruits, greens, tools and vehicles), 3-way (animals, plants and artifacts) and 2-way (natural and artificial entities)." ></td>
	<td class="line x" title="80:170	Following the task guidelines, we clustered the target row vectors in the CxLX matrix with CLUTO,4 using its default settings, and evaluated the resulting clusters in terms of cluster-sizeweighted averages of purity and entropy (see the CLUTO documentation)." ></td>
	<td class="line x" title="81:170	An ideal solution would have 100% purity and 0% entropy." ></td>
	<td class="line x" title="82:170	Table 3 provides percentage results for our models as well as for the ESSLLI systems that reported all the relevant performance measures, indexed by first author." ></td>
	<td class="line x" title="83:170	Models are ranked by a global score given by summing the 3 purity values and subtracting the 3 entropies." ></td>
	<td class="line x" title="84:170	model 6-way 3-way 2-way global P E P E P E Katrenko 89 13 100 0 80 59 197 Peirsman+ 82 23 84 34 86 55 140 DM 77 24 79 38 59 97 56 myDV 80 28 75 51 61 95 42 myHAL 75 27 68 51 68 89 44 Peirsman 73 28 71 54 61 96 27 myPlain 70 31 68 60 59 97 9 Shaoul 41 77 52 84 55 93 -106 Table 3: Concrete noun categorization DM outperforms our models trained on comparable resources." ></td>
	<td class="line x" title="85:170	Katrenkos system queries Google for patterns that cue the category of a concept, and thus its performance should rather be seen as an upper bound for distributional models." ></td>
	<td class="line x" title="86:170	Peirsman and colleagues report results based on different parameter settings: DMs performance  not tuned to the task  is worse than their top model, but better than their worse." ></td>
	<td class="line x" title="87:170	4.1.3 Selectional restrictions In this task we test the ability of the CxLC space to predict verbal selectional restrictions." ></td>
	<td class="line x" title="88:170	We use the CxLC matrix to compare a concept to a prototype constructed by averaging a set of other concepts, that in this case represent typical fillers of 3http://wordspace.collocations.de/ doku.php/esslli:start 4http://glaros.dtc.umn.edu/gkhome/ cluto/cluto/overview 4 a verbal slot  for example, by averaging the vectors of the nouns that are, according to the underlying graph, objects of killing, we can build a vector for the typical killee, and model selectional restrictions by measuring the similarity of other concepts (including concepts that have not been seen as objects of killing in the corpus) to this prototype." ></td>
	<td class="line x" title="89:170	Note that the DM graph is used both to find the concepts to enter in the prototype (the set of nouns that are connected to a verb by the relevant edge) and to compute similarity." ></td>
	<td class="line x" title="90:170	Thus, the method is fully unsupervised." ></td>
	<td class="line x" title="91:170	We test on the two datasets of human judgments about the plausibility of nouns as arguments (either subjects or objects) of verbs used in Pado et al.(2007), one (McRae) consisting of 100 nounverb pairs rated by 36 subjects, the second (Pado) with 211 pairs rated by 20 subjects." ></td>
	<td class="line x" title="93:170	For each verb in these datasets, we built its prototypical subject/object argument vector by summing the normalized vectors of the 50 nouns with the highest weight on the appropriate dependency link to the verb (e.g., the top 50 nouns connected to kill by an obj link)." ></td>
	<td class="line x" title="94:170	The cosine distance of a noun to a prototype is taken as the model plausibility judgment about the noun occurring as the relevant verb argument." ></td>
	<td class="line x" title="95:170	Since we are interested in generalization, if the target noun is in the prototype set we subtract its vector from the prototype before calculating the cosine." ></td>
	<td class="line x" title="96:170	For our comparison models, there is no way to determine which nouns would form the prototype, and thus we train them using the same top noun lists we employ for DM." ></td>
	<td class="line x" title="97:170	Following Pado and colleagues, performance is measured by the Spearmancorrelation coefficient between the average human ratings and the model predictions." ></td>
	<td class="line x" title="98:170	Table 4 reports percentage coverage and correlations for our models as well as those in Pado et al.(2007) (ParCos is the best among their purely corpus-based systems)." ></td>
	<td class="line x" title="100:170	model McRae Pado coverage  coverage  Pado 56 41 97 51 DM 96 28 98 50 ParCos 91 21 98 48 myDV 96 21 98 39 myHAL 96 12 98 29 myPlain 96 12 98 27 Resnik 94 3 98 24 Table 4: Correlation with verb-argument plausibility judgments DM does very well on this task: its performance on the Pado dataset is comparable to that of the Pado system, that relies on FrameNet." ></td>
	<td class="line x" title="101:170	DM has nearly identical performance to the latter on the Pado dataset." ></td>
	<td class="line x" title="102:170	On the McRae data, DM has a lower correlation, but much higher coverage." ></td>
	<td class="line x" title="103:170	Since we are using a larger corpus than Pado et al.(2007), who train on the BNC, a fairer comparison might be the one with our alternative models, that are all outperformed by DM by a large margin." ></td>
	<td class="line x" title="105:170	4.2 The CCxL semantic space Another view of the DM graph is exemplified in Table 5, where concept pairs are represented in terms of the edge labels (links) connecting them." ></td>
	<td class="line x" title="106:170	Importantly, this matrix contains the same information that was used to build the CxLC space of Table 1, with a different arrangement of what goes in the rows and in the columns, but the same weights in the cells  compare, for example, the soldier+gun-by-with cell in Table 5 to the soldierby-with+gun cell in Table 1." ></td>
	<td class="line x" title="107:170	in at with use teacher school 11894.47020.1 28.9 0.0 teacher handbook 2.5 0.0 3.2 10.1 soldier gun 2.8 10.3 105.9 41.0 Table 5: A fragment of the CCxL space We use this space to measure relational similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools." ></td>
	<td class="line x" title="108:170	We also extend relational similarity to prototypes." ></td>
	<td class="line x" title="109:170	Given some example pairs instantiating a relation, we can harvest new pairs linked by the same relation by computing the average CCxL vector of the examples, and finding the nearest neighbours to this average." ></td>
	<td class="line x" title="110:170	In the case at hand, the link profile of pairs such as soldier+gun and teacher+handbook could be used to build an instrument relation prototype." ></td>
	<td class="line x" title="111:170	We test the CCxL semantic space on recognizing SAT analogies (relational similarity between pairs) and semantic relation classification (relational similarity to prototypes)." ></td>
	<td class="line x" title="112:170	4.2.1 Recognizing SAT analogies We used the set of 374 multiple-choice questions from the SAT college entrance exam." ></td>
	<td class="line x" title="113:170	Each question includes one target pair, usually called 5 the stem (ostrich-bird) , and 5 other pairs (lioncat, goose-flock, ewe-sheep, cub-bear, primatemonkey)." ></td>
	<td class="line x" title="114:170	The task is to choose the pair most analogous to the stem." ></td>
	<td class="line x" title="115:170	Each SAT pair can be represented by the corresponding row vector in the CCxL matrix, and we select the pair with the highest cosine to the stem." ></td>
	<td class="line x" title="116:170	In Table 6 we report our results, together with the state-of-the-art from the ACL wiki5 and the scores of Turney (2008) (PairClass) and from Amac Herdagdelens PairSpace system, that was trained on ukWaC." ></td>
	<td class="line x" title="117:170	The Attr cells summarize the performance of the 6 models on the wiki table that are based on attributional similarity only (Turney, 2006)." ></td>
	<td class="line x" title="118:170	For the other systems, see the references on the wiki." ></td>
	<td class="line x" title="119:170	Since our coverage is very low (44% of the stems), in order to make a meaningful comparison with the other models, we calculated a corrected score (DM)." ></td>
	<td class="line x" title="120:170	Having full access to the results of the ukWaC-trained, similarly performing PairSpace system, we calculated the adjusted score by assuming that the DM-toPairSpace error ratio (estimated on the items we cover) is constant on the whole dataset, and thus the DM hit count on the unseen items is approximated by multiplying the PairSpace hit count on the same items by the error ratio (DM+ is DMs accuracy on the covered test items only)." ></td>
	<td class="line x" title="121:170	model % correct model % correct LRA 56.1 KnowBest 43.0 PERT 53.3 DM 42.3 PairClass 52.1 LSA 42.0 VSM 47.1 AttrMax 35.0 DM+ 45.3 AttrAvg 31.0 PairSpace 44.9 AttrMin 27.3 k-means 44.0 Random 20.0 Table 6: Accuracy with SAT analogies DM does not excel in this task, but its corrected performance is well above chance and that of all the attributional models, and comparable to that of a WordNet-based system (KnowBest) and a system that uses manually crafted information about analogy domains (LSA)." ></td>
	<td class="line x" title="122:170	All systems with performance above DM+ (and k-means) use corpora that are orders of magnitude larger than ukWaC." ></td>
	<td class="line x" title="123:170	4.2.2 Classifying semantic relations We also tested the CCxL space on the 7 semantic relations between nominals adopted in Task 4 of SEMEVAL 2007 (Girju et 5http://www.aclweb.org/aclwiki/index." ></td>
	<td class="line x" title="124:170	php?title=SAT_Analogy_Questions al., 2007): Cause-Effect, Instrument-Agency, Product-Producer, Origin-Entity, Theme-Tool, Part-Whole, Content-Container." ></td>
	<td class="line x" title="125:170	For each relation, the dataset includes 140 training examples and about 80 test cases." ></td>
	<td class="line x" title="126:170	Each example consists of a small context retrieved from the Web, containing word pairs connected by a certain pattern (eg., * contains *)." ></td>
	<td class="line x" title="127:170	The retrieved contexts were manually classified by the SEMEVAL organizers as positive (e.g., wrist-arm) or negative (e.g., effectiveness-magnesium) instances of a certain relation (e.g., Part-Whole)." ></td>
	<td class="line x" title="128:170	About 50% training and test cases are positive instances." ></td>
	<td class="line x" title="129:170	For each relation, we built hit and miss prototype vectors, by averaging across the vectors of the positive and negative training pairs attested in our CCxL model (we use only the word pairs, not the surrounding contexts)." ></td>
	<td class="line x" title="130:170	A test pair is classified as a hit for a certain relation if it is closer to the hit prototype vector for that relation than to the corresponding miss prototype." ></td>
	<td class="line x" title="131:170	We used the SEMEVAL 2007 evaluation method, i.e., precision, recall, Fmeasure and accuracy, macroaveraged over all relations, as reported in Table 7." ></td>
	<td class="line x" title="132:170	The DM+ scores ignore the 32% pairs not in our CCxL space; the DM scores assume random performance on such pairs." ></td>
	<td class="line x" title="133:170	These scores give the range within which our performance will lie once we introduce techniques to deal with unseen pairs." ></td>
	<td class="line x" title="134:170	We also report results of the SEMEVAL systems that did not use the organizer-provided WordNet sense labels nor information about the query used to retrieve the examples, as well as performance of several trivial classifiers, also from the SEMEVAL task description." ></td>
	<td class="line x" title="135:170	model precision recall F accuracy UCD-FC 66.1 66.7 64.8 66.0 UCB 62.7 63.0 62.7 65.4 ILK 60.5 69.5 63.8 63.5 DM+ 60.3 62.6 61.1 63.3 UMELB-B 61.5 55.7 57.8 62.7 SemeEval avg 59.2 58.7 58.0 61.1 DM 56.7 58.2 57.1 59.0 UTH 56.1 57.1 55.9 58.8 majority 81.3 42.9 30.8 57.0 probmatch 48.5 48.5 48.5 51.7 UC3M 48.2 40.3 43.1 49.9 alltrue 48.5 100.0 64.8 48.5 Table 7: SEMEVAL relation classification The DM accuracy is higher than the three SEMEVAL baselines (majority, probmatch and alltrue), DM+ is above the average performance of 6 the comparable SEMEVAL models." ></td>
	<td class="line x" title="136:170	Differently from DM, the models that outperform it use features extracted from the training contexts and/or specific additional resources: an annotated compound database for UCD-FC, machine learning algorithms to train the relation classifiers (ILK, UCD-FC), Web counts (UCB), etc. The less than optimal performance by DM is thus counterbalanced by its higher parsimony and generality." ></td>
	<td class="line x" title="137:170	4.3 The CLxC semantic space A third view of the information in the DM graph is the concept+link-by-concept (CLxC) semantic space exemplified by the matrix in Table 8." ></td>
	<td class="line x" title="138:170	teacher victim soldier policeman kill subj tr 0.0 22.4 1306.9 38.2 kill obj 9.9 915.4 8948.3 538.1 die subj in 109.4 1335.2 4547.5 68.6 Table 8: A fragment of the CLxC space This view captures patterns of similarity between (surface approximations to) argument slots of predicative words." ></td>
	<td class="line x" title="139:170	We can thus use the CLxC space to extract generalizations about the inner structure of lexico-semantic representations of the sort formal semanticists have traditionally being interested in." ></td>
	<td class="line x" title="140:170	In the example, the patterns of co-occurrence suggest that objects of killing are rather similar to subjects of dying, hinting at the classic cause(subj,die(obj)) analysis of killing by Dowty (1977) and many others." ></td>
	<td class="line x" title="141:170	Again, no new information has been introduced  the matrix in Table 8 is yet another re-organization of the data in our graph (compare, for example, the die+subj inby-teacher cell of this matrix with the teacher-bysubj in+die cell in Table 1)." ></td>
	<td class="line x" title="142:170	4.3.1 The causative/inchoative alternation Syntactic alterations (Levin, 1993) represent a key aspect of the complex constraints that shape the syntax-semantics interface." ></td>
	<td class="line x" title="143:170	One of the most important cases of alternation is the causative/inchoative, in which the object argument (e.g., John broke the vase) can also be realized as an intransitive subject (e.g., The vase broke)." ></td>
	<td class="line x" title="144:170	Verbs differ with respect to the possible syntactic alternations they can participate in, and this variation is strongly dependent on their semantic properties (e.g. semantic roles, event type, etc.)." ></td>
	<td class="line x" title="145:170	For instance, while break can undergo the causative/inchoative alternation, mince cannot: cf.John minced the meat and *The meat minced." ></td>
	<td class="line x" title="147:170	We test our CLxC semantic space on the discrimination between transitive verbs undergoing the causative-inchoative alternations and non-alternating ones." ></td>
	<td class="line x" title="148:170	We took 232 causative/inchoative verbs and 170 nonalternating transitive verbs from Levin (1993)." ></td>
	<td class="line x" title="149:170	For each verb vi, we extracted from the CLxC matrix the row vectors corresponding to its transitive subject (vi + subj tr), intransitive subject (vi +subj in), and direct object (vi +obj) slots." ></td>
	<td class="line x" title="150:170	Given the definition of the causative/inchoative alternation, we predict that with alternating verbs vi + subj in should be similar to vi + obj (the things that are broken also break), while this should not hold for non-alternating verbs (mincees are very different from mincers)." ></td>
	<td class="line x" title="151:170	Our model is completely successful in detecting the distinction." ></td>
	<td class="line x" title="152:170	The cosine similarity between transitive subject and object slots is fairly low for both classes, as one would expect (medians of 0.16 for alternating verbs and 0.11 for non-alternating verbs)." ></td>
	<td class="line x" title="153:170	On the other hand, while for the nonalternating verbs the median cosine similarity between the intransitive subject and object slots is a similarly low 0.09, for the alternating verbs the median similarity between these slots jump up to 0.31." ></td>
	<td class="line x" title="154:170	Paired t-tests confirm that the per-verb difference between transitive subject vs. object cosines and intransitive subject vs. object cosines is highly statistically significant for the alternating verbs, but not for the non-alternating ones." ></td>
	<td class="line x" title="155:170	5 Conclusion We proposed an approach to semantic tasks where statistics are collected only once from the source corpus and stored as a set of weighted concept+link+concept tuples (naturally represented as a graph)." ></td>
	<td class="line x" title="156:170	Different semantic spaces are constructed on demand from this underlying distributional memory, to tackle different tasks without going back to the corpus." ></td>
	<td class="line x" title="157:170	We have shown that a straightforward implementation of this approach leads to excellent performance in various taxonomic similarity tasks, and to performance that, while not outstanding, is at least reasonable on relational similarity." ></td>
	<td class="line x" title="158:170	We also obtained good results in a task (detecting the causative/inchoative alternation) that goes beyond classic NLP applications and more in the direction of theoretical semantics." ></td>
	<td class="line x" title="159:170	The most pressing issue we plan to address is how to improve performance in the relational sim7 ilarity tasks." ></td>
	<td class="line x" title="160:170	Fortunately, some shortcomings of our current model are obvious and easy to fix." ></td>
	<td class="line x" title="161:170	The low coverage is in part due to the fact that our set of target concepts does not contain, by design, some words present in the task sets." ></td>
	<td class="line x" title="162:170	Moreover, while our framework does not allow ad-hoc optimization of corpus-collection methods for different tasks, the way in which the information in the memory graph is adapted to tasks should of course go beyond the nearly baseline approaches we adopted here." ></td>
	<td class="line x" title="163:170	In particular, we need to develop a backoff strategy for unseen pairs in the relational similarity tasks, that, following Turney (2006), could be based on constructing surrogate pairs of taxonomically similar words found in the CxLC space." ></td>
	<td class="line x" title="164:170	Other tasks should also be explored." ></td>
	<td class="line x" title="165:170	Here, we viewed our distributional memory in line with how cognitive scientists look at the semantic memory of healthy adults, i.e., as an essentially stable long term knowledge repository." ></td>
	<td class="line x" title="166:170	However, much interesting semantic action takes place when underlying knowledge is adapted to context." ></td>
	<td class="line x" title="167:170	We plan to explore how contextual effects can be modeled in our framework, focusing in particular on how composition affects word meaning (Erk and Pado, 2008)." ></td>
	<td class="line x" title="168:170	Similarity could be measured directly on the underlying graph, by relying on graph-based similarity algorithms  an elegant approach that would lead us to an even more unitary view of what distributional semantic memory is and what it does." ></td>
	<td class="line x" title="169:170	Alternatively, DM could be represented as a three-mode tensor in the framework of Turney (2007), enabling smoothing operations analogous to singular value decomposition." ></td>
	<td class="line x" title="170:170	Acknowledgments We thank Ken McRae and Peter Turney for providing data-sets, Amac Herdagdelen for access to his results, Katrin Erk for making us look at DM as a graph, and the reviewers for helpful comments." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W09-0203
Unsupervised Classification with Dependency Based Word Spaces
Rothenhäusler, Klaus;Schütze, Hinrich;"></td>
	<td class="line x" title="1:170	Proceedings of the EACL 2009 Workshop on GEMS: GEometical Models of Natural Language Semantics, pages 1724, Athens, Greece, 31 March 2009." ></td>
	<td class="line x" title="2:170	c2009 Association for Computational Linguistics Unsupervised Classification with Dependency Based Word Spaces Klaus Rothenhusler and Hinrich Schtze Institute for Natural Language Processing University of Stuttgart Stuttgart, Germany {Klaus.Rothenhaeusler, Hinrich.Schuetze}@ims.uni-stuttgart.de Abstract We present the results of clustering experiments with a number of different evaluation sets using dependency based word spaces." ></td>
	<td class="line x" title="3:170	Contrary to previous results we found a clear advantage using a parsed corpus over word spaces constructed with the help of simple patterns." ></td>
	<td class="line x" title="4:170	We achieve considerable gains in performance over these spaces ranging between 9 and 13% in absolute terms of cluster purity." ></td>
	<td class="line x" title="5:170	1 Introduction Word space models have become a mainstay in the automatic acquisition of lexical semantic knowledge." ></td>
	<td class="line x" title="6:170	The computation of semantic relatedness of two words in such models is based on their distributional similarity." ></td>
	<td class="line x" title="7:170	The most crucial way in which such models differ is the definition of distributional similarity: In a regular word space model the observed distribution concerns the immediate neighbours of a word within a predefined window to the left and right (Schtze, 1992; Sahlgren, 2006)." ></td>
	<td class="line x" title="8:170	Early on in the development as an alternative models were proposed that relied on the similarity of the distribution of syntactic relations (Hindle, 1990; Pad and Lapata, 2007)." ></td>
	<td class="line x" title="9:170	More recently the distribution of the occurrence within simple patterns defined in the form of regular expressions that are supposed to capture explicit semantic relations was explored as the basis of distributional similarity (Almuhareb and Poesio, 2004)." ></td>
	<td class="line pc" title="10:170	Whereas dependency based semantic spaces have been shown to surpass other word space models for a number of problems (Pad and Lapata, 2007; Lin, 1998), for the task of categorisation simple pattern based spaces have been shown to perform equally good if not better (Poesio and Almuhareb, 2005b; Almuhareb and Poesio, 2005b)." ></td>
	<td class="line x" title="11:170	We want to show that dependency based spaces also fare better in these tasks if the dependency relations used are selected reasonably." ></td>
	<td class="line x" title="12:170	At the same time we want to show that such a system can be built with freely available components and without the need to rely on the index of a proprietary search engine vendor." ></td>
	<td class="line x" title="13:170	We propose to use the web acquired data of the ukWaC (Ferraresi et al., 2008), which is huge but still manageable and comes in a pre-cleaned version with HTML markup removed." ></td>
	<td class="line x" title="14:170	It can easily be fed into a parser like MiniPar which allows for the subsequent extraction of dependency relations of different types and complexity." ></td>
	<td class="line oc" title="15:170	In particular we work with dependency paths that can reach beyond direct dependencies as opposed to Lin (1998) but in the line of Pado and Lapata (2007)." ></td>
	<td class="line x" title="16:170	In contrast to the latter, however, different paths that end in the same word are not generally mapped to the same dimension in our model." ></td>
	<td class="line x" title="17:170	A path in a dependency graph can pass through several nodes and encompass different relations." ></td>
	<td class="line x" title="18:170	We experimented with two sets of nouns previously used in the literature for word clustering." ></td>
	<td class="line x" title="19:170	The nouns in both sets are taken from a number of different WordNet categories." ></td>
	<td class="line x" title="20:170	Hence, the task consists in clustering together the words from the same category." ></td>
	<td class="line x" title="21:170	By keeping the clustering algorithm constant, differences in performance can be attributed to the differences of the word representations." ></td>
	<td class="line x" title="22:170	The next section provides a formal description of our word space model." ></td>
	<td class="line x" title="23:170	Section 3 reports on our clustering experiments with two sets of concepts used previously to evaluate the categorisation abilities of word spaces." ></td>
	<td class="line x" title="24:170	Section 4 discusses these re17 sults and draws some conclusions." ></td>
	<td class="line x" title="25:170	2 Word Space Construction We follow the formalisation and terminology developed in Pado and Lapata (2007) according to which a dependency based space is determined by the sets of its basis elements B and targets T that form a matrix M = B  T , a similarity function S that assigns a real-valued similarity measure to pairs of elements from T , the association measure A that captures the strength of the relation between a target and a basis element, the context selection function cont, the basis mapping function  and the path value function v. Our set of targets is always a subset of the lemmas output by MiniPar." ></td>
	<td class="line x" title="26:170	The remaining elements are defined in this section." ></td>
	<td class="line x" title="27:170	We use pi to denote a path in a dependency graph which is conceived of as an undirected graph for this purpose." ></td>
	<td class="line x" title="28:170	So, in general a dependency path has an upward and downward part where one can have length zero." ></td>
	<td class="line x" title="29:170	All the paths used to define the contexts for target words are anchored there, i.e. they start from the target." ></td>
	<td class="line x" title="30:170	In choosing the context definitions that determine what dependency paths are used in the construction of the word vectors, we oriented ourselves at the sets proposed in Pado and Lapata (2007)." ></td>
	<td class="line x" title="31:170	As Pado and Lapata (2007) achieved their best results with it we started from their medium sized set of context definitions, from which we extracted the appropriate ones for our experiments and added some that seemed to make sense for our purposes: As our evaluation sets consist entirely of nouns, we used only context definitions that start at a noun." ></td>
	<td class="line x" title="32:170	Thereby we can ensure that only nominal uses are recorded in a word vector if a target word can have different parts of speech." ></td>
	<td class="line x" title="33:170	The complete set of dependency relations our context selection function cont comprises is given in Figure 1 along with an example for each." ></td>
	<td class="line x" title="34:170	We only chose paths that end in an open word class assuming that they are more informative about the meaning of a target word." ></td>
	<td class="line x" title="35:170	Paths ending in a preposition for instance, as used by Pado and Lapata (2007), were not considered." ></td>
	<td class="line x" title="36:170	For the same reason we implemented a simple stop word filter that discards paths ending in a pronoun, which are assigned the tag N by MiniPar just like any other noun." ></td>
	<td class="line x" title="37:170	On the other hand we added the relation between a prepositional complement and the noun it modifies (appearing as relation IX in Figure 1) as a close approximation of the pattern used by (Almuhareb and Poesio, 2004) to identify attributes of a concept as detailed in the next section." ></td>
	<td class="line x" title="38:170	Path specifications X and XI are also additions we made that are thought to gather additional attribute values to the ones already covered by III." ></td>
	<td class="line oc" title="39:170	As a basis mapping function  we used a generalisation of the one used by Grefenstette (1994) and Lin (1998)." ></td>
	<td class="line o" title="40:170	They map a dependency between two words to a pair consisting of the relation label l and the end word of the dependency end(pi)." ></td>
	<td class="line n" title="41:170	As we use paths that span more than a single relation, this approach is not directly applicable to our setup." ></td>
	<td class="line x" title="42:170	Instead we use a mapping function that maps a path to the sequence of edge labels through which it passes combined with the end word: (pi) = (l(pi),end(pi)) where l() is a labelling function that returns the sequence of edge labels for a given path." ></td>
	<td class="line x" title="43:170	With this basis mapping function the nodes or words respectively through which a path passes are all neglected except for the node where the path ends." ></td>
	<td class="line x" title="44:170	So, for the noun human the sequence human and mouse genome as well as the sequence human and chimpanzee genome increase the count for the same basis element :N:conj:N:*:N:nn:N:genome." ></td>
	<td class="line x" title="45:170	Here we use a path notation of the general form: (: POS : rel : POS : {word,})n where POS is a part of speech, rel a relation and word a node label, i.e. a lemma, all as produced by MiniPar." ></td>
	<td class="line x" title="46:170	The length of a path is determined by n and the asterisk (*) indicates that a node label is ignored by the basis mapping function." ></td>
	<td class="line x" title="47:170	As an alternative we experimented with a lexical basis mapping function that maps a path to its end word: (pi) = end(pi) This reduces the number of dimensions considerably and yields semantic spaces that are similar to window based word spaces." ></td>
	<td class="line x" title="48:170	As this mapping function consistently delivered worse results, we dropped it from our evaluation." ></td>
	<td class="line x" title="49:170	Considering that (Pad and Lapata, 2007) only reported very small differences for different path valuation functions, we only used a constant valuation of paths: vconst(pi) = 1 18 (I) the subject of a verb All humans die." ></td>
	<td class="line x" title="50:170	PreDet N Vpre subj (II) an object of a verb Gods from another world created humans V N subj obj (III) modified by an adjective Young dogs are like young humans VBE Prep A N s pred pcomp-n mod (IV) linked to another noun via a genitive relation The humans eyes glimmered with comprehension Det N N V det subj mod gen (V) part of a nominal complex The human body presents a problem." ></td>
	<td class="line x" title="51:170	Det N N V subj det obj nn (VI) part of a conjunction Humans and animals are equally fair game." ></td>
	<td class="line x" title="52:170	N U N VBE s punc pred conj (VII) the subject of a predicate noun Humans are the only specie that has sex for pleasure." ></td>
	<td class="line x" title="53:170	N VBE N C s det, m od pred rel subj (VIII) the subject of a predicate adjective Humans are fallible." ></td>
	<td class="line x" title="54:170	N VBE A s pred subj (IX) the prepositional complement modifying a noun You must get into the mind of humans." ></td>
	<td class="line x" title="55:170	N Aux V Det N Prep N s aux det obj mod pcom p-n (X) the prepositional complement modifying a noun that is the subject of a predicate adjective The nature of humans is corrupt." ></td>
	<td class="line x" title="56:170	N Prep N VBE A s mod pcom p-n pred (XI) the prepositional complement modifying a noun that is the subject of a predicate noun Chief diseases of humans are infections." ></td>
	<td class="line x" title="57:170	N Prep N VBE N s mod pcom p-n pred (XII) relations I-IV and VI-XI above but now with the target as part of a complex noun phrase as shown for a conjunction relation (VI) in the example They interrogated him about the human body and reproduction." ></td>
	<td class="line x" title="58:170	Prep Det N N U N mod det pcomp-n puncnn conj Figure 1: Context definitions used in the construction of our word spaces." ></td>
	<td class="line x" title="59:170	All examples show contexts for the target human." ></td>
	<td class="line x" title="60:170	Greyed out parts are just for illustrative purposes and have no impact on the word vectors." ></td>
	<td class="line x" title="61:170	The examples are slightly simplified versions of sentences found in ukWaC.19 Thus, an occurrence of any path, irrespective of length or grammatical relations that are involved, increases the count of the respective basis element by one." ></td>
	<td class="line x" title="62:170	We implemented three different association functions, A, to transform the raw frequency counts and weight the influence of the different cooccurrences." ></td>
	<td class="line x" title="63:170	We worked with an implementation of the log likelihood ratio (g-Score) as proposed by Dunning (1993) and two variants of the t-score, one considering all values (t-score) and one where only positive values (t-score+) are kept following the results of Curran and Moens (2002)." ></td>
	<td class="line x" title="64:170	We also experimented with different frequency cutoffs removing dimensions that occur very frequently or very rarely." ></td>
	<td class="line x" title="65:170	3 Evaluation For all our experiments we used the ukWaC corpus1 to construct the word spaces, which was parsed using MiniPar." ></td>
	<td class="line x" title="66:170	The latter provides lemma information, which we used as possible target and context words." ></td>
	<td class="line x" title="67:170	The word vectors we built from this data were represented as pseudo documents in an inverted index." ></td>
	<td class="line x" title="68:170	To our knowledge the experiments described in this paper are the first to work with a completely parsed version of the ukWaC." ></td>
	<td class="line x" title="69:170	For the evaluation the word vectors for the test sets were clustered into a predefined number of clusters corresponding to the number of concept classes from which the words were drawn." ></td>
	<td class="line x" title="70:170	All experiments were conducted with the CLUTO toolkit (Karypis, 2003) using the repeated bisections clustering algorithm with global optimisation and the cosine as a distance measure to maintain comparability with related work, e.g. Baroni et al.(2008)." ></td>
	<td class="line x" title="72:170	As the main evaluation measure we used purity for the whole set as supplied by CLUTO." ></td>
	<td class="line x" title="73:170	For a clustering solution  of n clusters and a set of classes C, purity can be defined as: purity(,C) = 1n  k maxj |k cj| where k denotes the set of terms in a cluster and cj the set of terms in a class." ></td>
	<td class="line x" title="74:170	This aggregate measure of purity corresponds to the weighted sum of purities for the individual clusters, which is defined as the ratio of items in a cluster that belong to the majority class." ></td>
	<td class="line x" title="75:170	The results for the two test 1http://wacky.sslmit.unibo.it sets we used are described in the following two subsections." ></td>
	<td class="line x" title="76:170	3.1 Results for 214 nouns from Almuhareb and Poesio (2004) The first set we worked with was introduced by Almuhareb and Poesio (2004) and consists of 214 nouns from 13 different categories in WordNet." ></td>
	<td class="line x" title="77:170	In the original paper the best results were achieved with vector representations built from concept attributes and their values as identified by simple patterns." ></td>
	<td class="line x" title="78:170	For the identification of attribute values of a concept C the following pattern was used [a|an|the] * C [is|was] It will find instances such as an adult human is identifying adult as a value for an attribute (age) of [HUMAN] (we use small capitals enclosed in square brackets to denote a concept)." ></td>
	<td class="line x" title="79:170	Attributes themselves are searched with the pattern the * of the C [is|was] A match for the concept [HUMAN] would be the dignity of the human is, which yields dignity as an attribute." ></td>
	<td class="line x" title="80:170	These patterns were translated into queries and submitted to the Google2 search engine." ></td>
	<td class="line x" title="81:170	We compare our dependency based spaces with the results achieved with the pattern based approach in Table 1." ></td>
	<td class="line x" title="82:170	association measure g-score t-score t-score+ dependency based space 77.1% 85.5% 96.7% window based space 84.1% 82.7% 89.3% pattern based space 85.5% Table 1: Categorisation results for the 214 concepts and 13 classes proposed in Almuhareb and Poesio (2004), which is also the source of the result for the pattern based space." ></td>
	<td class="line x" title="83:170	They only used t-score+." ></td>
	<td class="line x" title="84:170	The numbers given are the best accuracies achieved under the different settings." ></td>
	<td class="line x" title="85:170	For the window based space we used the best performing in a free association task with a window size of six words to each side and all the 2http://www.google.com 20 context accuracy # dimensions (I) 82.2% 7359 (II) 92.5% 6680 (III) 88.3% 45322 (IV)  37231 (V) 82.2% 240157 (VI) 95.3% 93917 (VII) 86.9% 45527 (VIII) 77.1% 5245 (IX) 91.6% 87765 (X)  2186 (XI)  6967 (XII) 93.0% 188763 Table 2: Clustering results using only one kind of path specification." ></td>
	<td class="line x" title="86:170	For (IV), (X) and (XI) purity values are missing because vectors for some of the words could not be built." ></td>
	<td class="line x" title="87:170	words that appeared at least two times as dimensions ignoring stop words." ></td>
	<td class="line x" title="88:170	The effective dimensionality of the so built word vectors is 417 837." ></td>
	<td class="line x" title="89:170	The results for the dependency based spaces were built by selecting all paths without any frequency thresholds which resulted in a set of 767 119 dimensions." ></td>
	<td class="line x" title="90:170	As can be seen, both window and dependency based spaces exceed the pattern based space for certain association measures." ></td>
	<td class="line x" title="91:170	But the dependency space also has a clear advantage over the window based space." ></td>
	<td class="line x" title="92:170	In particular the t-score+ measure yields very good results." ></td>
	<td class="line x" title="93:170	In contrast the g-score offers the worst results with the t-score retaining negative values somewhere in between." ></td>
	<td class="line x" title="94:170	For our further experiments we hence used the t-score+ association measure." ></td>
	<td class="line x" title="95:170	3.1.1 Further Analysis We ran a number of experiments to quantify the impact the different kinds of paths have on the clustering result." ></td>
	<td class="line x" title="96:170	We first built spaces using only a single kind of path to find out how good each performs on its own." ></td>
	<td class="line x" title="97:170	The result can be found in Table 2." ></td>
	<td class="line x" title="98:170	For some of the words in the evaluation set no contexts could be found when only one of the two most complex context specifications (X), (XI) was used or when the context was reduced to the genitive relation (IV)." ></td>
	<td class="line x" title="99:170	Apart from that the results suggest that even a single type of relation on its own can prove highly effective." ></td>
	<td class="line x" title="100:170	Especially the conjunctive relation (VI) performs very well with a purity value of 95.3%." ></td>
	<td class="line x" title="101:170	removed context accuracy (I) 97.2% (II) 97.7% (III) 97.2% (IV) 97.2% (V) 98.1% (VI) 96.3% (VII) 97.2% (VIII) 97.2% (IX) 96.7% (X) 97.2% (XI) 97.2% (XII) 96.7% Table 3: Clustering results for spaces with one context specification removed." ></td>
	<td class="line x" title="102:170	To further clarify the role of the different kinds of contexts, we ran the experiment with word spaces where we removed each one of the twelve context specifications in turn." ></td>
	<td class="line x" title="103:170	The results as given in Table 3 are a bit astonishing at first sight: Only the removal of the conjunctive relation actually leads to a decrease in performance." ></td>
	<td class="line x" title="104:170	All the other contexts seem to be either redundant  with performance staying the same when they are removed  or even harmful  with performance increasing once they are removed." ></td>
	<td class="line x" title="105:170	Having observed this, we tried to remove further context specifications and surprisingly found that the best performance of 98.1% can be reached by only including the conjunction (VI) and the object (II) relations." ></td>
	<td class="line x" title="106:170	The dimensionality of these vectors is only a fraction of the original ones with 100 597." ></td>
	<td class="line x" title="107:170	The result for the best performing dependency based space listed in the table is almost perfect." ></td>
	<td class="line x" title="108:170	Having a closer look at the results reveals that in fact only four words are put into a wrong cluster." ></td>
	<td class="line x" title="109:170	These words are: lounge, pain, mouse, oyster." ></td>
	<td class="line x" title="110:170	The first is classified as [BUILDING] instead of [FURNITURE]." ></td>
	<td class="line x" title="111:170	In the case of lounge the misclassification seems to be attributable to the ambiguity of the word which can either denote a piece of furniture or a waiting room." ></td>
	<td class="line x" title="112:170	The latter is apparently the more prominent sense in the data." ></td>
	<td class="line x" title="113:170	In this usage the word often appears in conjunctions with room or hotel just like restaurant, inn or clubhouse." ></td>
	<td class="line x" title="114:170	Pain is misclassified as an [ILLNESS] instead of a [FEELING] which is at least a close miss. The misclassification of mouse as a [BODY PART] seems rather odd on the other hand." ></td>
	<td class="line x" title="115:170	The reason for 21 it becomes apparent when looking at the most descriptive and discriminating features of the [BODY PART] cluster: In both lists the highest in the ranking is the dimension :N:mod:A:left, i.e. left as an adjectival modifier of the word in question." ></td>
	<td class="line x" title="116:170	The prominence of this particular modification is of course due to the fact that a lot of body parts come in pairs and that the members of these pairs are commonly identified by assigning them to the left or right half of the body." ></td>
	<td class="line x" title="117:170	Certainly, the word mouse enters this cluster not through its sense of mouse1 as an animal but rather through its sense of mouse2 as a piece of computer equipment that has two buttons, which are also referred to as the left and right one." ></td>
	<td class="line x" title="118:170	Unfortunately, MiniPar frequently resolves left in a wrong way as a modifier of mouse instead of button." ></td>
	<td class="line x" title="119:170	Finally for oyster which is put into the [EDIBLE FRUIT] instead of the [ANIMAL] cluster it is conspicuous that oyster is the only sea animal in the evaluation set and consequently it rarely occurs in conjunctions with the other animals." ></td>
	<td class="line x" title="120:170	Conjunctions, however, seem to be the most important features for defining all the clusters." ></td>
	<td class="line x" title="121:170	Additionally oyster scores low on a lot of dimensions that are typical for a big number of the members of the animal cluster, e.g. :N:obj:V:kill." ></td>
	<td class="line x" title="122:170	3.2 Results for 402 words from Almuhareb and Poesio (2005a) In Poesio and Almuhareb (2005a) a larger evaluation set is introduced that comprises 402 nouns sampled from the hierarchies under the 21 unique beginners in WordNet." ></td>
	<td class="line x" title="123:170	The words were also chosen so that candidates from different frequency bands and different levels of ambiguity were represented." ></td>
	<td class="line x" title="124:170	Further results using this set are reported in Almuhareb and Poesio (2005b)." ></td>
	<td class="line x" title="125:170	The best result was obtained with the attribute pattern alone and filtering to include only nouns." ></td>
	<td class="line x" title="126:170	We tried to assemble word vectors with the same patterns based on the ukWaC corpus." ></td>
	<td class="line x" title="127:170	But even if we included both patterns, we were only able to construct vectors for 363 of the 402 words." ></td>
	<td class="line x" title="128:170	For 118 of them the number of occurrences, on which they were based, was less than ten." ></td>
	<td class="line x" title="129:170	This gives an impression of the size of the index that is necessary for such an approach." ></td>
	<td class="line x" title="130:170	To date such an immense amount of data is only available through proprietary search engine providers." ></td>
	<td class="line x" title="131:170	This makes a system dependant upon the availability of an API of such a vendor." ></td>
	<td class="line x" title="132:170	In fact the version of the Google API on which the original experiments relied has since been axed." ></td>
	<td class="line x" title="133:170	Our approach circumvents such problems." ></td>
	<td class="line x" title="134:170	We ran analogous experiments to the ones described in the previous section on this evaluation set, now producing 21 clusters." ></td>
	<td class="line x" title="135:170	The results given in Table 4 are for a dependency space without any frequency thresholds and the complete set of context specifications as defined above." ></td>
	<td class="line x" title="136:170	The settings for the window based space were also the same (6 words to each side)." ></td>
	<td class="line x" title="137:170	Again the results achieved with the t-score+ association were clearly superior to the others and were used in all the following experiments." ></td>
	<td class="line x" title="138:170	Unsurprisingly, for this more difficult task the performance is not as good as for the smaller set but nevertheless the superiority of the dependency based space is clearly visible with an absolute increase in cluster purity of 8.2% compared with the pattern based space." ></td>
	<td class="line x" title="139:170	association measure g-score t-score t-score+ dependency based space 67.9% 67.2% 79.1% window based space 65.7% 60.7% 67.9% pattern based space 70.9% Table 4: Categorisation results for the 402 concepts and 21 classes proposed in Almuhareb and Poesio (2005a) which is also the source of the result for the pattern based space." ></td>
	<td class="line x" title="140:170	The numbers given are the best accuracies achieved under the different settings." ></td>
	<td class="line x" title="141:170	3.2.1 Further Analysis Again we ran further experiments to determine the impact of the different kinds of relations." ></td>
	<td class="line x" title="142:170	The removal of any single context specification leads to a performance drop with this evaluation set." ></td>
	<td class="line x" title="143:170	The smallest decrease is observed when removing context specification XII." ></td>
	<td class="line x" title="144:170	However, as we had seen in the previous experiment with the smaller set that only two context specifications suffice to reach peak performance, we conducted another experiment where we started from the best performing space constructed from a single context specification (the conjunction relation, VI) and successively added the specification that led to the biggest performance gain." ></td>
	<td class="line x" title="145:170	The crucial results are 22 majority class concepts solid tetrahedron, salient, ring, ovoid, octahedron, knob, icosahedron, fluting, dome, dodecahedron, cylinder, cuboid, cube, crinkle, concavity, samba, coco, nonce, divan, ball, stitch, floater, trove, hoard, mouse time yesteryear, yesterday, tonight, tomorrow, today, quaternary, period, moment, hereafter, gestation, future, epoch, day, date, aeon, stretch, snap, throb, straddle, nap motivation wanderlust, urge, superego, obsession, morality, mania, life, impulse, ethics, dynamic, conscience, compulsion, plasticity, opinion, acceptance, sensitivity, desire, interest assets wager, taxation, quota, profit, payoff, mortgage, investment, income, gain, fund, credit, capital, allotment, allocation, possession, inducement, incentive, disincentive, deterrence, share, sequestrian, cheque, check, bond, tailor district village, town, sultanate, suburb, state, shire, seafront, riverside, prefecture, parish, metropolis, land, kingdom, county, country, city, canton, borough, borderland, anchorage, tribe, nation, house, fen, cordoba, faro legal document treaty, statute, rescript, obligation, licence, law, draft, decree, convention, constitution, bill, assignment, commencement, extension, incitement, caliphate, clemency, venture, dispensation physical property weight, visibility, temperature, radius, poundage, momentum, mass, length, diameter, deflection, taper, indentation, droop, corner, concavity social unit troop , team, platoon, office, legion, league, household, family, department, confederacy, company, committee, club, bureau, brigade, branch, agency atmospheric phenomenon wind, typhoon, tornado, thunderstorm, snowfall, shower, sandstorm, rainstorm, lightning, hurricane, fog, drizzle, cyclone, crosswind, cloudburst, cloud, blast, aurora, airstream, glow social occasion wedding, rededication, prom, pageantry, inaugural, graduation, funeral, fundraiser, fiesta, fete, feast, enthronement, dance, coronation, commemoration, ceremony, celebration, occasion, raffle, beano monetary unit zloty, yuan, shilling, rupee, rouble, pound, peso, penny, lira, guilder, franc, escudo, drachma, dollar, dirham, dinar, cent tree sycamore, sapling, rowan, pine, palm, oak, mangrove, jacaranda, hornbeam, conifer, cinchona, casuarina, acacia, riel chemical element zinc, titanium, silver, potassium, platinum, oxygen, nitrogen, neon, magnesium, lithium, iron, hydrogen, helium, germanium, copper, charcoal, carbon, calcium, cadmium, bismuth, aluminium, gold illness smallpox, plague, meningitis, malnutrition, leukemia, hepatitis, glaucoma, flu, eczema, diabetes, cirrhosis, cholera, cancer, asthma, arthritis, anthrax, acne, menopause feeling wonder, shame, sadness, pleasure, passion, love, joy, happiness, fear, anger, heaviness, coolness, torment, tenderness, suffering, stinging vehicle van, truck, ship, rocket, pickup, motorcycle, helicopter, cruiser, car, boat, bicycle, automobile, airplane, aircraft, jag creator producer, photographer, painter, originator, musician, manufacturer, maker, inventor, farmer, developer, designer, craftsman, constructor, builder, artist, architect, motivator pain toothache, soreness, sting, soreness, sciatica, neuralgia, migraine, lumbago, headache, earache, burn, bellyache, backache, ache, rheumatism, pain animal zebra, turtle, tiger, sheep, rat, puppy, monkey, lion, kitten, horse, elephant, dog, deer, cow, cat, camel, bull, bear game whist, volleyball, tennis, softball, soccer, rugby, lotto, keno, handball, golf, football, curling, chess, bowling, basketball, baccarat, twister edible fruit watermelon, strawberry, pineapple, pear, peach, orange, olive, melon, mango, lemon, kiwi, grape, cherry, berry, banana, apple, oyster, walnut, pistachio, mandarin, lime, fig, chestnut Figure 2: Optimal clustering for large evaluation set." ></td>
	<td class="line x" title="146:170	contexts used purity (VI) 73.4% (VI), (II) 76.6% (VI), (II), (III) 80.1% Table 5: Clustering the larger evaluation set with an increasing number of context specifications." ></td>
	<td class="line x" title="147:170	given in Table 5." ></td>
	<td class="line x" title="148:170	As can be seen the object relation is added first again." ></td>
	<td class="line x" title="149:170	This time though the inclusion of adjectival modification brings another performance increase which is even one per cent above the result for the space built from all possible relations." ></td>
	<td class="line x" title="150:170	The addition of any further contexts consistently degrades performance." ></td>
	<td class="line x" title="151:170	The clustering solution thus produced is given in Figure 2." ></td>
	<td class="line x" title="152:170	From the 1 872 698 dimension used in the original space only 341 214 are retained." ></td>
	<td class="line x" title="153:170	4 Discussion and Conclusion Our results are counterintuitive at first sight as it could be expected that a larger number of different contexts would increase performance." ></td>
	<td class="line x" title="154:170	Instead we see the best performance with only a very lim23 ited set of possible contexts." ></td>
	<td class="line x" title="155:170	We suspect that this behaviour is due to a large amount of correlation between the different kinds of contexts." ></td>
	<td class="line x" title="156:170	The addition of further contexts beyond a certain point therefore has no positive effect." ></td>
	<td class="line x" title="157:170	As an indication for this it might be noticed that the three context specifications that yield the best result for the 402 word set comprise relations with the three main open word classes." ></td>
	<td class="line x" title="158:170	It is to be expected that they contribute orthogonal information that covers central dimensions of meaning." ></td>
	<td class="line x" title="159:170	The slight decrease in performance that can be observed when further contexts are added is probably due to chance fluctuations and almost certainly not significant; with significance being hard to determine for any of the results." ></td>
	<td class="line x" title="160:170	However, it is obviously necessary to cover a basic variety of features." ></td>
	<td class="line x" title="161:170	Patterns which are used to explicitly track semantic relations on the textual surface seem to be too restrictive." ></td>
	<td class="line x" title="162:170	Information accessible from co-occurring verbs for example is completely lost." ></td>
	<td class="line x" title="163:170	In a regular window based word space such information is retained and its performance is competitive with a pattern based approach." ></td>
	<td class="line x" title="164:170	This method is obviously too liberal, though, if compared to the dependency spaces." ></td>
	<td class="line x" title="165:170	In general we were able to show that semantic spaces are obviously able to capture categorical knowledge about concepts best when they are built from a syntactically annotated source." ></td>
	<td class="line x" title="166:170	This is true even if the context specification used is not the most parsimonious." ></td>
	<td class="line x" title="167:170	The problem of determining the right set of contexts is therefore rather an optimisation issue than a question of using dependency based spaces or not." ></td>
	<td class="line x" title="168:170	It is a considerable one, though, as computations are much cheaper with vectors of reduced dimensionality, of course." ></td>
	<td class="line x" title="169:170	For the categorisation task the inclusion of more complex relations reaching over several dependencies does not seem to be helpful considering they can all be dropped without a decrease in performance." ></td>
	<td class="line x" title="170:170	As Pado and Lapata (2007) reached better results in their experiments with a broader set of context specifications we conclude that the selection of the kinds of context to include when constructing a word space depends largely on the task at hand." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W09-0805
Unsupervised Concept Discovery In Hebrew Using Simple Unsupervised Word Prefix Segmentation for Hebrew and Arabic
Dinur, Elad;Davidov, Dmitry;Rappoport, Ari;"></td>
	<td class="line x" title="1:267	Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 3644, Athens, Greece, 31 March, 2009." ></td>
	<td class="line x" title="2:267	c2009 Association for Computational Linguistics Unsupervised Concept Discovery In Hebrew Using Simple Unsupervised Word Prefix Segmentation for Hebrew and Arabic Elad Dinur1 Dmitry Davidov2 1Institute of Computer Science 2ICNC The Hebrew University of Jerusalem Ari Rappoport1 Abstract Fully unsupervised pattern-based methods for discovery of word categories have been proven to be useful in several languages." ></td>
	<td class="line x" title="3:267	The majority of these methods rely on the existence of function words as separate text units." ></td>
	<td class="line x" title="4:267	However, in morphology-rich languages, in particular Semitic languages such as Hebrew and Arabic, the equivalents of such function words are usually written as morphemes attached as prefixes to other words." ></td>
	<td class="line x" title="5:267	As a result, they are missed by word-based pattern discovery methods, causing many useful patterns to be undetected and a drastic deterioration in performance." ></td>
	<td class="line x" title="6:267	To enable high quality lexical category acquisition, we propose a simple unsupervised word segmentation algorithm that separates these morphemes." ></td>
	<td class="line x" title="7:267	We study the performance of the algorithm for Hebrew and Arabic, and show that it indeed improves a state-of-art unsupervised concept acquisition algorithm in Hebrew." ></td>
	<td class="line x" title="8:267	1 Introduction In many NLP tasks, we wish to extract information or perform processing on text using minimal knowledge on the input natural language." ></td>
	<td class="line x" title="9:267	Towards this goal, we sometimes find it useful to divide the set of words in natural language to function words and content words, a division that applies in the vast majority of languages." ></td>
	<td class="line x" title="10:267	Function words (or grammatical words, e.g., a, an, the, in, of, etc) are words that have little or highly ambiguous lexical meaning, and serve to express grammatical or semantic relationships with the other words in a sentence." ></td>
	<td class="line x" title="11:267	In some morphologically-rich languages, important function words are not written as spaceseparated units but as morphemes attached as prefixes to other words." ></td>
	<td class="line x" title="12:267	This fact can cause problems when statistically analyzing text in these languages, for two main reasons: (1) the vocabulary of the language grows, as our lexical knowledge comes solely from a corpus (words appear with and without the function morphemes); (2) information derived from the presence of these morphemes in the sentence is usually lost." ></td>
	<td class="line x" title="13:267	In this paper we address the important task of a fully unsupervised acquisition of Hebrew lexical categories (or concepts  words sharing a significant aspect of their meaning)." ></td>
	<td class="line x" title="14:267	We are not aware of any previous work on this task for Hebrew." ></td>
	<td class="line x" title="15:267	Due to the problem above, the performance of many acquisition algorithms deteriorates unacceptably." ></td>
	<td class="line x" title="16:267	This happens, for example, in the (Davidov and Rappoport, 2006) algorithm that utilizes automatically detected function words as the main building block for pattern construction." ></td>
	<td class="line x" title="17:267	In order to overcome this problem, one should separate such prefixes from the compound words (words consisting of function morphemes attached to content words) in the input corpus." ></td>
	<td class="line x" title="18:267	When we consider some particular word, there are frequently many options to split it to smaller strings." ></td>
	<td class="line x" title="19:267	Fortunately, the set of function words is small and closed, and the set of grammatical sequences of function prefixes is also small." ></td>
	<td class="line x" title="20:267	Hence we assume it does not cost us much to know in advance what are the possible sequences for a specific language." ></td>
	<td class="line x" title="21:267	Even when considering the small number of possible function words, the task of separating them is not simple, as some words may be ambiguous." ></td>
	<td class="line x" title="22:267	When reading a word that starts with a prefix known to be a function morpheme, the word may 36 be a compound word, or it may be a meaningful word by itself." ></td>
	<td class="line x" title="23:267	For example, the word hsws in Hebrew1 can be interpreted as hsws (hesitation), or h sws (the horse)." ></td>
	<td class="line x" title="24:267	The segmentation of the word is context dependent  the same string may be segmented differently in different contexts." ></td>
	<td class="line x" title="25:267	One way of doing such word prefix segmentation is to perform a complete morphological disambiguation of the sentence." ></td>
	<td class="line x" title="26:267	The disambiguation algorithm finds for each word its morphological attributes (POS tag, gender, etc.), and decides whether a word is a compound word or a word without prefixes." ></td>
	<td class="line x" title="27:267	A disambiguation algorithm generally relies on a language-specific morphological analyzer." ></td>
	<td class="line x" title="28:267	It may also require a large manually tagged corpus, construction of which for some particular language or domain requires substantial human labor." ></td>
	<td class="line x" title="29:267	We avoid the utilization of such costly and language-specific disambiguation algorithms and manually annotated data." ></td>
	<td class="line x" title="30:267	In this paper we present a novel method to separate function word prefixes, and evaluate it using manually labeled gold standards in Hebrew and Arabic." ></td>
	<td class="line x" title="31:267	We incorporate the method into a pattern-based Hebrew concept acquisition framework and show that it greatly improves state-of-art results for unsupervised lexical category acquisition." ></td>
	<td class="line x" title="32:267	This improvement allows the pattern-based unsupervised framework to use one-tenth of the Hebrew data in order to reach a similar level of results." ></td>
	<td class="line x" title="33:267	Section 2 discusses related work, and Section 3 reviews the word categories discovery algorithm." ></td>
	<td class="line x" title="34:267	Section 4 presents the word prefix segmentation algorithm." ></td>
	<td class="line x" title="35:267	Results are given in Section 5." ></td>
	<td class="line x" title="36:267	2 Related Work In this paper we develop an unsupervised framework for segmentation of the function words for languages where context is important for correct segmentation." ></td>
	<td class="line x" title="37:267	Our main target language is Hebrew, and we experimented with Arabic as well." ></td>
	<td class="line x" title="38:267	As far as we know, there is no work on unsupervised segmentation of words in Hebrew which does not utilize language-specific tools such as morphological analyzers." ></td>
	<td class="line x" title="39:267	Lee et al.(2003) addressed supervised word segmentation in Arabic and have some aspects similar to our approach." ></td>
	<td class="line x" title="41:267	As in their study, we 1Transcription is according to (Ornan, 2005), except for Shin which is denoted by $." ></td>
	<td class="line x" title="42:267	also have a pre-supplied list of possible prefix sequences and assume a trigram model in order to find the most probable morpheme sequence." ></td>
	<td class="line x" title="43:267	Both studies evaluate performance on a segmented text, and not just on words in the lexicon." ></td>
	<td class="line x" title="44:267	However, their algorithm, while achieving good performance (97% accuracy), relies on a training set  a manually segmented corpus of about 110,000 words, while our unsupervised framework does not require any annotation and is thus easier to implement and to apply to different domains and languages." ></td>
	<td class="line x" title="45:267	Snyder and Barzilay (2008) study the task of unsupervised morphological segmentation of multiple languages." ></td>
	<td class="line x" title="46:267	Their algorithm automatically induces a segmentation and morpheme alignment of short parallel phrases from a multilingual corpus." ></td>
	<td class="line x" title="47:267	Their corpus (The Hebrew Bible and translations) contains parallel phrases in English, Arabic, Hebrew and Aramaic." ></td>
	<td class="line x" title="48:267	They obtain 63.87 F-Score for Hebrew words segmentation (prefix and suffix), where recall and precision is calculated based on all possible segmentation points." ></td>
	<td class="line x" title="49:267	Another type of segmentation algorithms involves utilization of language-specific morphological analyzers for complete morphological disambiguation." ></td>
	<td class="line x" title="50:267	In Hebrew each word usually has more than one possible POS (along with other attributes, such as gender, number, etc.)." ></td>
	<td class="line x" title="51:267	Assuming we have a morphological analyzer (producing the set of possible analyses for a given word), we can try to discover the correct segmentation of each word." ></td>
	<td class="line x" title="52:267	Levinger et al.(1995) developed a method for disambiguation of the results provided by a morphological analyzer for Hebrew." ></td>
	<td class="line x" title="54:267	Adler and Elhadad (2006) proposed an unsupervised algorithm for word segmentation." ></td>
	<td class="line x" title="55:267	They estimate an initial language model (using (Levinger et al., 1995)) and improve this model with EM." ></td>
	<td class="line x" title="56:267	Direct comparison to their work is problematic, however, since we avoid utilization of a language-specific morphology/POS analyzer." ></td>
	<td class="line x" title="57:267	There are also studies of this type that utilize labeled data (Bar-Haim et al., 2005), where the language model is learned from the training data." ></td>
	<td class="line x" title="58:267	Extensive research has been done on word segmentation, where, unlike in our study, the segmentation is evaluated for every word, regardless of its context." ></td>
	<td class="line x" title="59:267	Creutz (2003) presents an algorithm for unsupervised segmentation under these assumptions." ></td>
	<td class="line x" title="60:267	He proposes a probabilistic model which 37 utilizes the distributions of morpheme length and frequency to estimate the quality of the induced morphemes." ></td>
	<td class="line x" title="61:267	Dasgupta and Ng (2007) improves over (Creutz, 2003) by suggesting a simpler approach." ></td>
	<td class="line x" title="62:267	They segment a prefix using the word frequency with and without a prefix." ></td>
	<td class="line x" title="63:267	Other recent studies that follow the context-independent setup include (Creutz and Lagus, 2005; Keshava and Pitler, 2005; Demberg, 2007)." ></td>
	<td class="line x" title="64:267	They test their methods on English, Finnish and Turkish." ></td>
	<td class="line x" title="65:267	All of these studies, however, assume contextindependency of segmentation, disregarding the ambiguity that may come from context." ></td>
	<td class="line x" title="66:267	This makes it problematic to apply the proposed methods to context-dependent morphology types as in Hebrew and Arabic." ></td>
	<td class="line x" title="67:267	The guiding goal in the present paper is the concept acquisition problem." ></td>
	<td class="line x" title="68:267	Concept acquisition of different kinds has been studied extensively." ></td>
	<td class="line x" title="69:267	The two main classification axes for this task are the type of human input and annotation, and the basic algorithmic approach used." ></td>
	<td class="line x" title="70:267	The two main algorithmic approaches are clustering of context feature vectors and pattern-based discovery." ></td>
	<td class="line x" title="71:267	The first approach is to map each word to a feature vector and cluster these vectors." ></td>
	<td class="line oc" title="72:267	Example of such algorithms are (Pereira et al., 1993) and (Lin, 1998) that use syntactic features in the vector definition." ></td>
	<td class="line x" title="73:267	Pantel and Lin (2002) improves on the latter by clustering by committee." ></td>
	<td class="line x" title="74:267	Recently, there is a growing interest in the second main algorithmic approach, usage of lexicosyntactic patterns." ></td>
	<td class="line x" title="75:267	Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004)." ></td>
	<td class="line x" title="76:267	Thus (Dorow et al., 2005) discover categories using two basic pre-specified patterns (x and y, x or y)." ></td>
	<td class="line x" title="77:267	Some recent studies have proposed frameworks that attempt to avoid any implicit or explicit prespecification of patterns." ></td>
	<td class="line x" title="78:267	Davidov and Rappoport (2006) proposed a method that detects function words by their high frequency, and utilizes these words for the discovery of symmetric patterns." ></td>
	<td class="line x" title="79:267	Their method is based on two assumptions: (1) some function words in the language symmetrically connect words belonging to the same category; (2) such function words can be detected as the most frequent words in language." ></td>
	<td class="line x" title="80:267	While these assumptions are reasonable for many languages, for some morphologically rich languages the second assumption may fail." ></td>
	<td class="line x" title="81:267	This is due to the fact that some languages like Hebrew and Arabic may express relationships not by isolated function words but by morphemes attached in writing to other words." ></td>
	<td class="line x" title="82:267	As an example, consider the English word and, which was shown to be very useful in concept acquisition (Dorow et al., 2005)." ></td>
	<td class="line x" title="83:267	In Hebrew this word is usually expressed as the morpheme w attached to the second word in a conjunction ( wsws   and horse)." ></td>
	<td class="line x" title="84:267	Patterns discovered by such automatic pattern discovery algorithms are based on isolated words, and hence fail to capture and-based relationships that are very useful for detection of words belonging to the same concept." ></td>
	<td class="line x" title="85:267	Davidov and Rappoport (2006) reports very good results for English and Russian." ></td>
	<td class="line x" title="86:267	However, no previous work applies a fully unsupervised concept acquisition for Hebrew." ></td>
	<td class="line x" title="87:267	In our study we combine their concept acquisition framework with a simple unsupervised word segmentation technique." ></td>
	<td class="line x" title="88:267	Our evaluation confirms the weakness of word-based frameworks for morphology-rich languages such as Hebrew, and shows that utilizing the proposed word segmentation can overcome this weakness while keeping the concept acquisition approach fully unsupervised." ></td>
	<td class="line x" title="89:267	3 Unsupervised Discovery of Word Categories In this study we use word segmentation to improve the (Davidov and Rappoport, 2006) method for discovery of word categories, sets of words sharing a significant aspect of their meaning." ></td>
	<td class="line x" title="90:267	An example for such a discovered category is the set of verbs {dive, snorkel, swim, float, surf, sail, drift, }." ></td>
	<td class="line x" title="91:267	Below we briefly describe this category acquisition algorithm." ></td>
	<td class="line x" title="92:267	The algorithm consists of three stages as follows." ></td>
	<td class="line x" title="93:267	First, it discovers a set of pattern candidates, which are defined by a combination of high frequency words (denoted by H) and slots for low frequency (content) words (denoted by C)." ></td>
	<td class="line x" title="94:267	An example for such a pattern candidate is x belongs to y, where x and y stand for content word slots." ></td>
	<td class="line x" title="95:267	The patterns are found according to a predefined set of possible meta-patterns." ></td>
	<td class="line x" title="96:267	The meta-patterns are language-independent2 and consist of up to 4 2They do not include any specific words, only a relative order of high/low frequency words, and hence can be used on 38 words in total, from which two are (non-adjacent) content words." ></td>
	<td class="line x" title="97:267	Four meta-patterns are used: CHC, CHCH, CHHC, HCHC." ></td>
	<td class="line x" title="98:267	Second, those patterns which give rise to symmetric lexical relationships are identified." ></td>
	<td class="line x" title="99:267	The meaning of phrases constructed from those patterns is (almost) invariant to the order of the content words contained in them." ></td>
	<td class="line x" title="100:267	An example for such a pattern is x and y." ></td>
	<td class="line x" title="101:267	In order to identify such useful patterns, for each pattern we build a graph following (Widdows and Dorow, 2002)." ></td>
	<td class="line x" title="102:267	The graph is constructed from a node for each content word, and a directed arc from the node x to y if the corresponding content words appear in the pattern such that x precedes y." ></td>
	<td class="line x" title="103:267	Then we calculate several symmetry measures on the graph structure and select the patterns with best values for these measures." ></td>
	<td class="line x" title="104:267	The third stage is the generation of categories." ></td>
	<td class="line x" title="105:267	We extract tightly connected sets of words from the unified graph which combines all graphs of selected patterns." ></td>
	<td class="line x" title="106:267	Such sets of words define the desired categories." ></td>
	<td class="line x" title="107:267	The patterns which include the x and y substring are among the most useful patterns for generation of categories (they were used in (Dorow et al., 2005) and discovered in all 5 languages tested in (Davidov and Rappoport, 2006))." ></td>
	<td class="line x" title="108:267	However, in Hebrew such patterns can not be found in the same way, since the function word and is the prefix w and not a standalone high frequency word." ></td>
	<td class="line x" title="109:267	Another popular set of patterns are ones including x or y." ></td>
	<td class="line x" title="110:267	Such patterns can be identified in Hebrew, as or in Hebrew is a separate word." ></td>
	<td class="line x" title="111:267	However, even in this case, the content word represented by x or y may appear with a prefix." ></td>
	<td class="line x" title="112:267	This damages the construction of the pattern graph, since two different nodes may be created instead of one  one for a regular content word, the other for the same word with a prefix." ></td>
	<td class="line x" title="113:267	Consequently, it is reasonable to assume that segmenting the corpus in advance should improve the results of discovery of word categories." ></td>
	<td class="line x" title="114:267	4 Word Segmentation Algorithm We assume we know the small and closed set of grammatical function word prefix sequences in the language3." ></td>
	<td class="line x" title="115:267	Our input is a sentence, and our obany languages with explicit word segmentation." ></td>
	<td class="line x" title="116:267	3Unlike development of labeled training data, handcrafting such a closed set is straightforward for many languages and does not requires any significant time/human labor jective is to return the correct segmentation of the sentence." ></td>
	<td class="line x" title="117:267	A sentence L is a sequence of words {w1,w2,,wn}." ></td>
	<td class="line x" title="118:267	A segmentation Si of L is a sequence of morphemes {m1,m2,,mk} and l(Si) is the number of morphemes in the sequence." ></td>
	<td class="line x" title="119:267	Note that l(Si) may be different for each segmentation." ></td>
	<td class="line x" title="120:267	The best segmentation S will be calculated by: P(Si) = p(m1)p(m2|m1) l(Si)productdisplay i=3 p(mi|mi1mi2) S = argmaxS i P(Si) Calculation of joint probabilities requires a trigram model of the language." ></td>
	<td class="line x" title="121:267	Below we describe the construction of the trigram model and then we detail the algorithm for efficient calculation of S. 4.1 Construction of trigram model Creating the trigram language model is done in two stages: (1) we segment a corpus automatically, and (2) we learn a trigram language model from the segmented corpus." ></td>
	<td class="line x" title="122:267	4.1.1 Initial corpus segmentation For initial corpus segmentation, we define a statistical measure for the segmentation of individual words." ></td>
	<td class="line x" title="123:267	Let wx be a word, such that w is the prefix of the word composed of a sequence of function word prefixes and x is a string of letters." ></td>
	<td class="line x" title="124:267	Let f(x) be the frequency of the word x in the corpus." ></td>
	<td class="line x" title="125:267	Denote by al the average length of the strings (with prefixes) in the language." ></td>
	<td class="line x" title="126:267	This can be easily estimated from the corpus  every string that appears in the corpus is counted once." ></td>
	<td class="line x" title="127:267	l(x) is the number of characters in the word x. We utilize two parameters G,H, where G < H (we used G = 2.5,H = 3.5) and define the following functions : factor(x) = braceleftBigg alGl(x) alH l(x) < al G 0 otherwise Rank(wx) = f(wx)f(wx) + f(x) + factor(x) Note that the expression f(wx)f(wx)+f(x) is a number in (0,1], inversely correlated with the frequency of the prefixed word." ></td>
	<td class="line x" title="128:267	Thus higher Rank(wx) values indicate that the word is less likely to be composed of the prefix w followed by the word x. 39 The expression alGl(x)alH is a number in (0,1], therefore factor(x)  [0,1]." ></td>
	<td class="line x" title="129:267	H is G 1 in order to keep the expression smaller than 1." ></td>
	<td class="line x" title="130:267	The term factor(x) is greater as x is shorter." ></td>
	<td class="line x" title="131:267	The factor is meant to express the fact that short words are less likely to have a prefix." ></td>
	<td class="line x" title="132:267	We have examined this in Hebrew  as there are no words of length 1, two letter words have no prefix." ></td>
	<td class="line x" title="133:267	We have analyzed 102 randomly chosen three letter words, and found that only 19 of them were prefixed words." ></td>
	<td class="line x" title="134:267	We have analyzed 100 randomly chosen four letter words, and found that 40 of them were prefixed words." ></td>
	<td class="line x" title="135:267	The result was about the same for five letter words." ></td>
	<td class="line x" title="136:267	In order to decide whether a word needs to be separated, we define a threshold T  [0,1]." ></td>
	<td class="line x" title="137:267	We allow word separation only when Rank(wx) is lower than T. When there are more than two possible sequences of function word prefixes (mhsws,m hsws, mh sws), we choose the segmentation with the lower rank." ></td>
	<td class="line x" title="138:267	4.1.2 Learning the trigram model The learning of the language model is based on counts of the corpus, assigning a special symbol, u/k (unknown) for all words that do not appear in the corpus." ></td>
	<td class="line x" title="139:267	As estimated by (Lee et al., 2003), we set the probability of u/k to be 1E  9." ></td>
	<td class="line x" title="140:267	The value of the symbol u/k was observed to be significant." ></td>
	<td class="line x" title="141:267	We found that the value proposed by (Lee et al., 2003) for Arabic gives good results also for Hebrew." ></td>
	<td class="line x" title="142:267	4.2 Dynamic programming approach for word segmentation The naive method to find S is to iterate over all possible segmentations of the sentence." ></td>
	<td class="line x" title="143:267	This method may fail to handle long sentences, as the number of segmentations grows exponentially with the length of the sentence." ></td>
	<td class="line x" title="144:267	To overcome this problem, we use dynamic programming." ></td>
	<td class="line x" title="145:267	Each morpheme has an index i to its place in a segmentation sequence." ></td>
	<td class="line x" title="146:267	Iteratively, for index i, for every morpheme which appears in some segmentation in index i, we calculate the best segmentation of the sequence m1 mi." ></td>
	<td class="line x" title="147:267	Two problems arise here: (1) we need to calculate which morphemes may appear in a given index; (2) we need to constrain the calculation, such that only valid segmentations would be considered." ></td>
	<td class="line x" title="148:267	To calculate which morphemes can appear in a given index we define the object Morpheme." ></td>
	<td class="line x" title="149:267	It contains the morpheme (string), the index of a word in the sentence the morpheme belongs to, reference to the preceding Morpheme in the same word, and indication whether it is the last morpheme in the word." ></td>
	<td class="line x" title="150:267	For each index of the sentence segmentation, we create a list of Morphemes (index-list)." ></td>
	<td class="line x" title="151:267	For each word wi, and for segmentation m1i,,mki , we create Morphemes M1i ,,Mki . We traverse sequentially the words in the sentence, and for each segmentation we add the sequence of Morphemes to all possible index-lists." ></td>
	<td class="line x" title="152:267	The indexlist for the first Morpheme M1i is the combination of successors of all the index-lists that contain a Morpheme Mki1." ></td>
	<td class="line x" title="153:267	The constraints are enforced easily  if a Morpheme Mji is the first in a word, the preceding Morpheme in the sequence must be the last Morpheme of the previous word." ></td>
	<td class="line x" title="154:267	Otherwise, the preceding Morpheme must be Mj1i , which is referenced by Mji . 4.3 Limitations While our model handles the majority of cases, it does not fully comply with a linguistic analysis of Hebrew, as there are a few minor exceptions." ></td>
	<td class="line x" title="155:267	We assumed that there is no ambiguity in the function word prefixes." ></td>
	<td class="line x" title="156:267	This is not entirely correct, as in Hebrew we have two different kinds of exceptions for this rule." ></td>
	<td class="line x" title="157:267	For example, the prefix k$ (when), can also be interpreted as the prefix k (as) followed by the prefix $ (that)." ></td>
	<td class="line x" title="158:267	As the second interpretation is rare, we always assumed it is the prefix k$." ></td>
	<td class="line x" title="159:267	This rule was applied wherever an ambiguity exists." ></td>
	<td class="line x" title="160:267	However, we did not treat this problem as it is very rare, and in the development set and test set it did not appear even once." ></td>
	<td class="line x" title="161:267	A harder problem is encountered when processing the word bbyt." ></td>
	<td class="line x" title="162:267	Two interpretations could be considered here: b byt (in a house), and b h byt (in the house)." ></td>
	<td class="line x" title="163:267	Whether this actually poses a problem or not depends on the application." ></td>
	<td class="line x" title="164:267	We assume that the correct segmentation here is b byt." ></td>
	<td class="line x" title="165:267	Without any additional linguistic knowledge (for example, diacritical vowel symbols should suffice in Hebrew), solving these problems requires some prior discriminative data." ></td>
	<td class="line x" title="166:267	5 Evaluation and Results We evaluate our algorithm in two stages." ></td>
	<td class="line x" title="167:267	First we test the quality of our unsupervised word segmentation framework on Hebrew and Arabic, comparing our segmentation results to a manually anno40 With factor(x) Without factor(x) T Prec." ></td>
	<td class="line x" title="168:267	Recall F-Measure Accuracy Prec." ></td>
	<td class="line x" title="169:267	Recall F-Measure Accuracy 0.70 0.844 0.798 0.820 0.875 0.811 0.851 0.830 0.881 0.73 0.841 0.828 0.834 0.883 0.808 0.866 0.836 0.884 0.76 0.837 0.846 0.841 0.886 0.806 0.882 0.842 0.887 0.79 0.834 0.870 0.851 0.893 0.803 0.897 0.847 0.890 0.82 0.826 0.881 0.852 0.892 0.795 0.904 0.846 0.888 0.85 0.820 0.893 0.854 0.892 0.787 0.911 0.844 0.886 0.88 0.811 0.904 0.855 0.891 0.778 0.917 0.841 0.882 Table 1: Ranks vs. Threshold T for Hebrew." ></td>
	<td class="line x" title="170:267	With factor(x) Without factor(x) T Prec." ></td>
	<td class="line x" title="171:267	Recall F-Measure Accuracy Prec." ></td>
	<td class="line x" title="172:267	Recall F-Measure Accuracy 0.91 0.940 0.771 0.846 0.892 0.903 0.803 0.850 0.891 0.93 0.930 0.797 0.858 0.898 0.903 0.840 0.870 0.904 0.95 0.931 0.810 0.866 0.904 0.902 0.856 0.878 0.909 0.97 0.927 0.823 0.872 0.906 0.896 0.869 0.882 0.911 0.99 0.925 0.848 0.872 0.915 0.878 0.896 0.886 0.913 1.00 0.923 0.852 0.886 0.915 0.841 0.896 0.867 0.895 Table 2: Ranks vs. Threshold T for Arabic." ></td>
	<td class="line x" title="173:267	Algorithm P R F A Rank seg." ></td>
	<td class="line x" title="174:267	0.834 0.870 0.851 0.893 Baseline 0.561 0.491 0.523 0.69 Morfessor 0.630 0.689 0.658 0.814 Table 3: Segmentation results comparison." ></td>
	<td class="line x" title="175:267	tated gold standard." ></td>
	<td class="line x" title="176:267	Then we incorporate word segmentation into a concept acquisition framework and compare the performance of this framework with and without word segmentation." ></td>
	<td class="line x" title="177:267	5.1 Corpora and annotation For our experiments in Hebrew we used a 19MB Hebrew corpus obtained from the Mila Knowledge Center for Processing Hebrew4." ></td>
	<td class="line x" title="178:267	The corpus consists of 143,689 different words, and a total of 1,512,737 word tokens." ></td>
	<td class="line x" title="179:267	A sample text of size about 24,000 words was taken from the corpus, manually segmented by human annotators and used as a gold standard in our segmentation evaluation." ></td>
	<td class="line x" title="180:267	In order to estimate the quality of our algorithm for Arabic, we used a 7MB Arabic news items corpus, and a similarly manually annotated test text of 4715 words." ></td>
	<td class="line x" title="181:267	The Arabic corpus is too small for meaningful category discovery, so we used it only in the segmentation evaluation." ></td>
	<td class="line x" title="182:267	5.2 Evaluation of segmentation framework In order to estimate the performance of word segmentation as a standalone algorithm we applied our algorithm on the Hebrew and Arabic corpora, 4http://mila.cs.technion.ac.il." ></td>
	<td class="line x" title="183:267	using different parameter settings." ></td>
	<td class="line x" title="184:267	We first calculated the word frequencies, then applied initial segmentation as described in Section 4." ></td>
	<td class="line x" title="185:267	Then we used SRILM (Stolcke, 2002) to learn the trigram model from the segmented corpus." ></td>
	<td class="line x" title="186:267	We utilized Good-Turing discounting with Katz backoff, and we gave words that were not in the training set the constant probability 1E  9." ></td>
	<td class="line x" title="187:267	Finally we utilized the obtained trigram model to select sentence segmentations." ></td>
	<td class="line x" title="188:267	To test the influence of the factor(x) component of the Rank value, we repeated our experiment with and without usage of this component." ></td>
	<td class="line x" title="189:267	We also ran our algorithm with a set of different threshold T values in order to study the influence of this parameter." ></td>
	<td class="line x" title="190:267	Tables 1 and 2 show the obtained results for Hebrew and Arabic respectively." ></td>
	<td class="line x" title="191:267	Precision is the ratio of correct prefixes to the total number of detected prefixes in the text." ></td>
	<td class="line x" title="192:267	Recall is the ratio of prefixes that were split correctly to the total number of prefixes." ></td>
	<td class="line x" title="193:267	Accuracy is the number of correctly segmented words divided by the total number of words." ></td>
	<td class="line x" title="194:267	As can be seen from the results, the best F-score with and without usage of the factor(x) component are about the same, but usage of this component gives higher precision for the same F-score." ></td>
	<td class="line x" title="195:267	From comparison of Arabic and Hebrew performance we can also see that segmentation decisions for the task in Arabic are likely to be easier, since the accuracy for T=1 is very high." ></td>
	<td class="line x" title="196:267	It means that, unlike in Hebrew (where the best results were obtained for T=0.79), a word which starts with a pre41 Method us k-means random avg shared meaning(%) 85 24.61 10 avg triplet score(1-4) 1.57 2.32 3.71 avg category score(1-10) 9.35 6.62 3.5 Table 4: Human evaluation results." ></td>
	<td class="line x" title="197:267	abuse, robbery, murder, assault, extortion good, cheap, beautiful, comfortable son, daughter, brother, parent when, how, where essential, important, central, urgent Table 5: A sample from the lexical categories discovered in Hebrew (translated to English)." ></td>
	<td class="line x" title="198:267	fix should generally be segmented." ></td>
	<td class="line x" title="199:267	We also compared our best results to the baseline and to previous work." ></td>
	<td class="line x" title="200:267	The baseline draws a segmentation uniformly for each word, from the possible segmentations of the word." ></td>
	<td class="line x" title="201:267	In an attempt to partially reproduce (Creutz and Lagus, 2005) on our data, we also compared our results to the results obtained from Morfessor CategoriesMAP, version 0.9.1 (Described in (Creutz and Lagus, 2005))." ></td>
	<td class="line x" title="202:267	The Morfessor Categories-MAP algorithm gets a list of words and their frequencies, and returns the segmentation for every word." ></td>
	<td class="line x" title="203:267	Since Morfessor may segment words with prefixes which do not exist in our predefined list of valid prefixes, we did not segment the words that had illegal prefixes as segmented by Morfessor." ></td>
	<td class="line x" title="204:267	Results for this comparison are shown in Table 3." ></td>
	<td class="line x" title="205:267	Our method significantly outperforms both the baseline and Morfessor-based segmentation." ></td>
	<td class="line x" title="206:267	We have also tried to improve the language model by a self training scheme on the same corpus but we observed only a slight improvement, giving 0.848 Precision and 0.872 Recall." ></td>
	<td class="line x" title="207:267	5.3 Discovery of word categories We divide the evaluation of the word categories discovery into two parts." ></td>
	<td class="line x" title="208:267	The first is evaluating the improvement in the quantity of found lexical categories." ></td>
	<td class="line x" title="209:267	The second is evaluating the quality of these categories." ></td>
	<td class="line x" title="210:267	We have applied the algorithm to a Hebrew corpus of size 130MB5, which is sufficient for a proof of concept." ></td>
	<td class="line x" title="211:267	We compared the output of the categories discovery on two different settings, with function word separation and without such separation." ></td>
	<td class="line x" title="212:267	In both settings we omit5Again obtained from the Mila Knowledge Center for Processing Hebrew." ></td>
	<td class="line x" title="213:267	N A J With Separation 148 4.1 1 No Separation 36 2.9 0 Table 6: Lexical categories discovery results comparison." ></td>
	<td class="line x" title="214:267	N: number of categories." ></td>
	<td class="line x" title="215:267	A: average category size." ></td>
	<td class="line x" title="216:267	J: junk words." ></td>
	<td class="line x" title="217:267	ted all punctuation symbols." ></td>
	<td class="line x" title="218:267	In both runs of the algorithm we used the same parameters." ></td>
	<td class="line x" title="219:267	Eight symmetric patterns were automatically chosen for each run." ></td>
	<td class="line x" title="220:267	Two of the patterns that were chosen by the algorithm in the unseparated case were also chosen in the separated case." ></td>
	<td class="line x" title="221:267	5.3.1 Manual estimation of category quality Evaluating category quality is challenging since no exhaustive lists or gold standards are widely accepted even in English, certainly so in resourcepoor languages such as Hebrew." ></td>
	<td class="line x" title="222:267	Hence we follow the human judgment evaluation scheme presented in (Davidov and Rappoport, 2006), for the categories obtained from the segmented corpus." ></td>
	<td class="line x" title="223:267	We compared three methods of word categories discovery." ></td>
	<td class="line x" title="224:267	The first is random sampling of words into categories." ></td>
	<td class="line x" title="225:267	The second is k-means, where each word is mapped to a vector, and similarity is calculated as described in (Pantel and Lin, 2002)." ></td>
	<td class="line x" title="226:267	We applied k-means to the set of vectors, with similarity as a distance function." ></td>
	<td class="line x" title="227:267	If a vector had low similarity with all means, we leave it unattached." ></td>
	<td class="line x" title="228:267	Therefore some clusters contained only one vector." ></td>
	<td class="line x" title="229:267	Running the algorithm 10 times, with different initial means each time, produced 60 clusters with three or more words." ></td>
	<td class="line x" title="230:267	An interesting phenomenon we observed is that this method produces very nice clusters of named entities." ></td>
	<td class="line x" title="231:267	The last method is the one in (Davidov and Rappoport, 2006)." ></td>
	<td class="line x" title="232:267	The experiment contained two parts." ></td>
	<td class="line x" title="233:267	In Part I, subjects were given 40 triplets of words and were asked to rank them using the following scale: (1) the words definitely share a significant part of their meaning; (2) the words have a shared meaning but only in some context; (3) the words have a shared meaning only under a very unusual context/situation; (4) the words do not share any meaning; (5) I am not familiar enough with some/all of the words." ></td>
	<td class="line x" title="234:267	The 40 triplets were obtained as follows." ></td>
	<td class="line x" title="235:267	20 of our categories were selected at random from the non-overlapping categories we have discovered, and three words were selected from each of these 42 at random." ></td>
	<td class="line x" title="236:267	10 triplets were selected in the same manner from the categories produced by k-means, and 10 triplets were selected at random from content words in the same document." ></td>
	<td class="line x" title="237:267	In Part II, subjects were given the full categories represented by the triplets that were graded as 1 or 2 in Part I (the full good categories in terms of sharing of meaning)." ></td>
	<td class="line x" title="238:267	Subjects were asked to grade the categories from 1 (worst) to 10 (best) according to how much the full category had met the expectations they had when seeing only the triplet." ></td>
	<td class="line x" title="239:267	Nine people participated in the evaluation." ></td>
	<td class="line x" title="240:267	A summary of the results is given in Table 4." ></td>
	<td class="line x" title="241:267	The categories obtained from the unsegmented corpus are too few and too small for a significant evaluation." ></td>
	<td class="line x" title="242:267	Therefore we applied the evaluation scheme only for the segmented corpus." ></td>
	<td class="line x" title="243:267	The results from the segmented corpus contain some interesting categories, with a 100% precision, like colors, Arab leaders, family members and cities." ></td>
	<td class="line x" title="244:267	An interesting category is {Arabic, English, Russian, French, German, Yiddish, Polish, Math}." ></td>
	<td class="line x" title="245:267	A sample of some other interesting categories can be seen in Table 5." ></td>
	<td class="line x" title="246:267	5.3.2 Segmentation effect on category discovery In Table 6, we find that there is a major improvement in the number of acquired categories, and an interesting improvement in the average category size." ></td>
	<td class="line x" title="247:267	One might expect that as a consequence of an incorrect segmentation of a word, junk words may appear in the discovered categories." ></td>
	<td class="line x" title="248:267	As can be seen, only one junk word was categorized." ></td>
	<td class="line x" title="249:267	Throughout this paper we have assumed that function word properties of languages such as Hebrew and Arabic decrease performance of wholeword pattern-based concept acquisition methods." ></td>
	<td class="line x" title="250:267	To check this assumption, we have applied the concept acquisition algorithm on several webbased corpora of several languages, while choosing corpora size to be exactly equal to the size of the Hebrew corpus (130Mb) and utilizing exactly the same parameters." ></td>
	<td class="line x" title="251:267	We did not perform quality evaluation6, but measured the number of concepts and concept size." ></td>
	<td class="line x" title="252:267	Indeed the number of categories was (190, 170, 159, 162, 150, 29) for Russian, English, Spanish, French, Turkish and Arabic respectively, clearly inferior for Arabic in comparison to these European and Slavic languages." ></td>
	<td class="line x" title="253:267	A similar 6Brief manual examination suggests no significant drops in concept quality." ></td>
	<td class="line x" title="254:267	tendency was observed for average concept size." ></td>
	<td class="line x" title="255:267	At the same time prefix separation does help to extract 148 concepts for Hebrew, making it nearly inline with other languages." ></td>
	<td class="line x" title="256:267	In contrast, our preliminary experiments on English and Russian suggest that the effect of applying similar morphological segmentation on these languages in insignificant." ></td>
	<td class="line x" title="257:267	In order to test whether more data can substitute segmentation even for Hebrew, we have obtained by means of crawling and web queries a larger (while potentially much more noisy) webbased 2GB Hebrew corpus which is based on forum and news contents." ></td>
	<td class="line x" title="258:267	Our goal was to estimate which unsegmented corpus size (if any) can bring similar performance (in terms of concept number, size and quality)." ></td>
	<td class="line x" title="259:267	We gradually increased corpus size and applied the concept acquisition algorithm on this corpus." ></td>
	<td class="line x" title="260:267	Finally, we have obtained similar, nearly matching, results to our 130MB corpus for a 1.2GB Hebrew subcorpus of the 2GB Hebrew corpus." ></td>
	<td class="line x" title="261:267	The results remain stable for 4 different 1.2GB subsets taken from the same 2GB corpus." ></td>
	<td class="line x" title="262:267	This suggests that while segmentation can be substituted with more data, it may take roughly x10 more data for Hebrew to obtain the same results without segmentation as with it." ></td>
	<td class="line x" title="263:267	6 Summary We presented a simple method for separating function word prefixes from words." ></td>
	<td class="line x" title="264:267	The method requires very little language-specific knowledge (the prefixes), and it can be applied to any morphologically rich language." ></td>
	<td class="line x" title="265:267	We showed that this segmentation dramatically improves lexical acquisition in Hebrew, where nearly 10 data is required to obtain the same number of concepts without segmentation." ></td>
	<td class="line x" title="266:267	While in this paper we evaluated our framework on the discovery of concepts, we have recently proposed fully unsupervised frameworks for the discovery of different relationship types (Davidov et al., 2007; Davidov and Rappoport, 2008a; Davidov and Rappoport, 2008b)." ></td>
	<td class="line x" title="267:267	Many of these methods are mostly based on function words, and may greatly benefit from the proposed segmentation framework." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W09-1108
Superior and Efficient Fully Unsupervised Pattern-based Concept Acquisition Using an Unsupervised Parser
Davidov, Dmitry;Reichart, Roi;Rappoport, Ari;"></td>
	<td class="line x" title="1:257	Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 4856, Boulder, Colorado, June 2009." ></td>
	<td class="line x" title="2:257	c 2009 Association for Computational Linguistics Superior and Efficient Fully Unsupervised Pattern-based Concept Acquisition Using an Unsupervised Parser Dmitry Davidov1 Roi Reichart1 Ari Rappoport2 1ICNC , 2Institute of Computer Science Hebrew University of Jerusalem {dmitry@alice.nc|roiri@cs|arir@cs}.huji.ac.il Abstract Sets of lexical items sharing a significant aspect of their meaning (concepts) are fundamental for linguistics and NLP." ></td>
	<td class="line x" title="3:257	Unsupervised concept acquisition algorithms have been shown to produce good results, and are preferable over manual preparation of concept resources, which is labor intensive, error prone and somewhat arbitrary." ></td>
	<td class="line x" title="4:257	Some existing concept mining methods utilize supervised language-specific modules such as POS taggers and computationally intensive parsers." ></td>
	<td class="line x" title="5:257	In this paper we present an efficient fully unsupervised concept acquisition algorithm that uses syntactic information obtained from a fully unsupervised parser." ></td>
	<td class="line x" title="6:257	Our algorithm incorporates the bracketings induced by the parser into the meta-patterns used by a symmetric patterns and graph-based concept discovery algorithm." ></td>
	<td class="line x" title="7:257	We evaluate our algorithm on very large corpora in English and Russian, using both human judgments and WordNetbased evaluation." ></td>
	<td class="line x" title="8:257	Using similar settings as the leading fully unsupervised previous work, we show a significant improvement in concept quality and in the extraction of multiword expressions." ></td>
	<td class="line x" title="9:257	Our method is the first to use fully unsupervised parsing for unsupervised concept discovery, and requires no languagespecific tools or pattern/word seeds." ></td>
	<td class="line x" title="10:257	1 Introduction Comprehensive lexical resources for many domains and languages are essential for most NLP applications." ></td>
	<td class="line x" title="11:257	One of the most utilized types of such resources is a repository of concepts: sets of lexical items sharing a significant aspect of their meanings (e.g., types of food, tool names, etc)." ></td>
	<td class="line x" title="12:257	While handcrafted concept databases (e.g., WordNet) are extensively used in NLP, manual compilation of such databases is labor intensive, error prone, and somewhat arbitrary." ></td>
	<td class="line x" title="13:257	Hence, for many languages and domains great efforts have been made for automated construction of such databases from available corpora." ></td>
	<td class="line x" title="14:257	While language-specific and domainspecific studies show significant success in development of concept discovery frameworks, the majority of domains and languages remain untreated." ></td>
	<td class="line x" title="15:257	Hence there is a need for a framework that performs well for many diverse settings and is as unsupervised and language-independent as possible." ></td>
	<td class="line x" title="16:257	Numerous methods have been proposed for seedbased concept extraction where a set of concept patterns (or rules), or a small set of seed words for each concept, is provided as input to the concept acquisition system." ></td>
	<td class="line x" title="17:257	However, even simple definitions for concepts are not always available." ></td>
	<td class="line x" title="18:257	To avoid requiring this type of input, a number of distributional and pattern-based methods have been proposed for fully unsupervised seed-less acquisition of concepts from text." ></td>
	<td class="line x" title="19:257	Pattern-based algorithms were shown to obtain high quality results while being highly efficient in comparison to distributional methods." ></td>
	<td class="line x" title="20:257	Such fully unsupervised methods do not incorporate any language-specific parsers or taggers, so can be successfully applied to diverse languages." ></td>
	<td class="line x" title="21:257	However, unsupervised pattern-based methods suffer from several weaknesses." ></td>
	<td class="line x" title="22:257	Thus they are frequently restricted to single-word terms and are unable to discover multiword expressions in efficient and precise manner." ></td>
	<td class="line x" title="23:257	They also usually ignore potentially useful part-of-speech and other syntactic information." ></td>
	<td class="line x" title="24:257	In order to address these weaknesses, several studies utilize language-specific parsing or 48 tagging systems in concept acquisition." ></td>
	<td class="line x" title="25:257	Unfortunately, while improving results, this heavily affects the languageand domainindependence of such frameworks, and severely impacts efficiency since even shallow parsing is computationally demanding." ></td>
	<td class="line x" title="26:257	In this paper we present a method to utilize the information induced by unsupervised parsers in an unsupervised pattern-based concept discovery framework." ></td>
	<td class="line x" title="27:257	With the recent development of fast fully unsupervised parsers, it is now possible to add parserbased information to lexical patterns while keeping the language-independence of the whole framework and still avoiding heavy computational costs." ></td>
	<td class="line x" title="28:257	Specifically, we incorporate the bracketings induced by the parser into the meta-patterns used by a symmetric patterns and graph-based unsupervised concept discovery algorithm." ></td>
	<td class="line x" title="29:257	We performed a thorough evaluation on two English corpora (the BNC and a 68GB web corpus) and on a 33GB Russian corpus." ></td>
	<td class="line x" title="30:257	Evaluations were done using both human judgments and WordNet, in similar settings as that of the leading unsupervised previous work." ></td>
	<td class="line x" title="31:257	Our results show that utilization of unsupervised parser both improves the assignment of single-word terms to concepts and allows highprecision discovery and assignment of of multiword expressions to concepts." ></td>
	<td class="line x" title="32:257	2 Previous Work Much work has been done on lexical acquisition of all sorts and the acquisition of concepts in particular." ></td>
	<td class="line x" title="33:257	Concept acquisition methods differ in the type of corpus annotation and other human input used, and in their basic algorithmic approach." ></td>
	<td class="line x" title="34:257	Some methods directly aim at concept acquisition, while the direct goal in some is the construction of hyponym (is-a) hierarchies." ></td>
	<td class="line x" title="35:257	A subtree in such a hierarchy can be viewed as defining a concept." ></td>
	<td class="line x" title="36:257	A major algorithmic approach is to represent word contexts as vectors in some space and use distributional measures and clustering in that space." ></td>
	<td class="line oc" title="37:257	Pereira (1993), Curran (2002) and Lin (1998) use syntactic features in the vector definition." ></td>
	<td class="line x" title="38:257	(Pantel and Lin, 2002) improves on the latter by clustering by committee." ></td>
	<td class="line x" title="39:257	Caraballo (1999) uses conjunction and appositive annotations in the vector representation." ></td>
	<td class="line x" title="40:257	Several studies avoid requiring any syntactic annotation." ></td>
	<td class="line x" title="41:257	Some methods are based on decomposition of a lexically-defined matrix (by SVD, PCA etc), e.g.(Schutze, 1998; Deerwester et al., 1990)." ></td>
	<td class="line x" title="43:257	While great effort has been made for improving the computational complexity of distributional methods (Gorman and Curran, 2006), they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale well for very large datasets." ></td>
	<td class="line x" title="44:257	The second main approach is to use lexicosyntactic patterns." ></td>
	<td class="line x" title="45:257	Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004)." ></td>
	<td class="line x" title="46:257	Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns, numerous pattern-based methods have been proposed for the discovery of concepts from seeds." ></td>
	<td class="line x" title="47:257	Other studies develop concept acquisition for on-demand tasks where concepts are defined by user-provided seeds." ></td>
	<td class="line x" title="48:257	Many of these studies utilize information obtained by language-specific parsing and named entity recognition tools (Dorow et al., 2005)." ></td>
	<td class="line x" title="49:257	Pantel et al.(2004) reduce the depth of linguistic data used, but their method requires POS tagging." ></td>
	<td class="line x" title="51:257	TextRunner (Banko et al., 2007) utilizes a set of pattern-based seed-less strategies in order to extract relational tuples from text." ></td>
	<td class="line x" title="52:257	However, this system contains many language-specific modules, including the utilization of a parser in one of the processing stages." ></td>
	<td class="line x" title="53:257	Thus the majority of the existing pattern-based concept acquisition systems rely on pattern/word seeds or supervised language-specific tools, some of which are very inefficient." ></td>
	<td class="line x" title="54:257	Davidov and Rappoport (2006) developed a framework which discovers concepts based on high frequency words and symmetry-based pattern graph properties." ></td>
	<td class="line x" title="55:257	This framework allows a fully unsupervised seed-less discovery of concepts without relying on language-specific tools." ></td>
	<td class="line x" title="56:257	However, it completely ignores potentially useful syntactic or morphological information." ></td>
	<td class="line x" title="57:257	For example, the pattern X and his Y is useful for acquiring the concept of family member types, as in his siblings and his parents." ></td>
	<td class="line x" title="58:257	Without syntactic information, it can capture noise, as in  in ireland) and his wife) (parentheses denote syntactic constituent boundaries)." ></td>
	<td class="line x" title="59:257	As another example, the useful symmetric pattern either X or Y can appear in both good examples (choose either Chihuahua 49 or Collie.) and bad ones (either Collie or Australian Bulldog)." ></td>
	<td class="line x" title="60:257	In the latter case, the algorithm both captures noise (Australlian is now considered as a candidate for the dog type concept), and misses the discovery of a valid multiword candidate (Australlian Bulldog)." ></td>
	<td class="line x" title="61:257	While symmetry-based filtering greatly reduces such noise, the basic problem remains." ></td>
	<td class="line x" title="62:257	As a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial." ></td>
	<td class="line x" title="63:257	Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews)." ></td>
	<td class="line x" title="64:257	Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English." ></td>
	<td class="line x" title="65:257	These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here." ></td>
	<td class="line x" title="66:257	These works learn an unlabeled syntactic structure, dependency or constituency." ></td>
	<td class="line x" title="67:257	In this work we use constituency trees as our syntactic representation." ></td>
	<td class="line x" title="68:257	Another important factor in concept acquisition is the source of textual data used." ></td>
	<td class="line x" title="69:257	To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al., 2007; Pasca and Van Durme, 2008; Davidov and Rappoport, 2009)." ></td>
	<td class="line x" title="70:257	While these methods have a definite practical advantage of dealing with the most recent and comprehensive data, web-based evaluation has some methodological drawbacks such as limited repeatability (Kilgarriff, 2007)." ></td>
	<td class="line x" title="71:257	In this study we apply our framework on offline corpora in settings similar to that of previous work, in order to be able to make proper comparisons." ></td>
	<td class="line x" title="72:257	3 Efficient Unsupervised Parsing Our method utilizes the information induced by unsupervised parsers." ></td>
	<td class="line x" title="73:257	Specifically, we make use of the bracketings induced by Seginers parser1 (Seginer, 2007)." ></td>
	<td class="line x" title="74:257	This parser has advantages in three major as1The parser is freely available at http://staff.science.uva.nl/yseginer/ccl pects relevant to this paper." ></td>
	<td class="line x" title="75:257	First, it achieves state of the art unsupervised parsing performance: its F-score2 is 75.9% for sentences of up to 10 words from the PennTreebank Wall Street Journal corpus (WSJ) (Marcus, 1993), and 59% for sentences of the same length from the German NEGRA (Brants, 1997) corpus." ></td>
	<td class="line x" title="76:257	These corpora consists of newspaper texts." ></td>
	<td class="line x" title="77:257	Second, to obtain good results, manually created POS tags are used as input in all the unsupervised parsers mentioned above except of Seginers, which uses raw sentences as input." ></td>
	<td class="line x" title="78:257	(Headden et al., 2008) have shown that the performance of algorithms that require POS tags substantially decreases when using POS tags induced by unsupervised POS taggers instead of manually created ones." ></td>
	<td class="line x" title="79:257	Seginers incremental parser is therefore the only fully unsupervised parser providing high quality parses." ></td>
	<td class="line x" title="80:257	Third, Seginers parser is extremely fast." ></td>
	<td class="line x" title="81:257	During its initial stage, the parser builds a lexicon." ></td>
	<td class="line x" title="82:257	Our Pentium 2.8GHB machines with 4GHB RAM can store in memory the lexicon created by up to 0.2M sentences." ></td>
	<td class="line x" title="83:257	We thus divided our corpora to batches of 0.2M sentences and parsed each of them separately." ></td>
	<td class="line x" title="84:257	Note that in this setup parsing quality might be even better than the quality reported in (Seginer, 2007), since in the setup reported in that paper the parser was applied to a few thousand sentences only." ></td>
	<td class="line x" title="85:257	On average, the parsing time of a single batch was 5 minutes (run time did not significantly differ across batches and corpora)." ></td>
	<td class="line x" title="86:257	Parser description." ></td>
	<td class="line x" title="87:257	The parser utilizes the novel common-cover link representation for syntactic structure." ></td>
	<td class="line x" title="88:257	This representation resembles dependency structure but unlike the latter, it can be translated into a constituency tree, which is the syntactic representation we use in this work." ></td>
	<td class="line x" title="89:257	The parsing algorithm creates the common-cover links structure of a sentence in an incremental manner." ></td>
	<td class="line x" title="90:257	This means that the parser reads the words of a sentence one after the other and, as each word is read, it is only allowed to add links that have one of their ends at that words (and update existing ones)." ></td>
	<td class="line x" title="91:257	Words which have not yet been read are not avail2F = 2RP R+P , where R and P are the recall and precision ofthe parsers bracketing compared to manually created bracketing of the same text." ></td>
	<td class="line x" title="92:257	This is the accepted measure for parsing performance (see (Klein, 2005))." ></td>
	<td class="line x" title="93:257	50 able to the parser at this stage." ></td>
	<td class="line x" title="94:257	This restriction is inspired by psycholinguistics research which suggests that humans process language incrementally." ></td>
	<td class="line x" title="95:257	This results in a significant restriction of the parsers search space, which is the reason it is so fast." ></td>
	<td class="line x" title="96:257	During its initial stage the parser builds a lexicon containing, for each word, statistics helping the decision of whether to link that word to other words." ></td>
	<td class="line x" title="97:257	The lexicon is updated as any new sentence is read." ></td>
	<td class="line x" title="98:257	Lexicon updating is also done in an incremental manner so this stage is also very fast." ></td>
	<td class="line x" title="99:257	4 Unsupervised Pattern Discovery In the first stage of our algorithm, we run the unsupervised parser on the corpus in order to produce a bracketing structure for each sentence." ></td>
	<td class="line x" title="100:257	In the second stage, described here, we use these bracketings in order to discover, in a fully unsupervised manner, patterns that could be useful for concept mining." ></td>
	<td class="line x" title="101:257	Our algorithm is based on the concept acquisition method of (Davidov and Rappoport, 2006)." ></td>
	<td class="line x" title="102:257	We discover patterns that connect terms belonging to the same concept in two main stages: discovery of pattern candidates, and identification of the symmetric patterns among the candidates." ></td>
	<td class="line x" title="103:257	Pattern candidates." ></td>
	<td class="line x" title="104:257	A major idea of (Davidov and Rappoport, 2006) is that a few dozen high frequency words (HFW) such as and and is connect other, less frequent content terms into relationships." ></td>
	<td class="line x" title="105:257	They define meta-patterns, which are short sequences of Hs and Cs, where H is a slot for a HFW and C is a slot for a content word (later to become a word belonging to a discovered concept)." ></td>
	<td class="line x" title="106:257	Their method was shown to produce good results." ></td>
	<td class="line x" title="107:257	However, the fact that it does not consider any syntactic information causes problems." ></td>
	<td class="line x" title="108:257	Specifically, it does not consider the constituent structure of the sentence." ></td>
	<td class="line x" title="109:257	Meta-patterns that cross constituent boundaries are likely to generate noise  two content words (Cs) in a meta-pattern that belong to different constituents are likely to belong to different concepts as well." ></td>
	<td class="line x" title="110:257	In addition, meta-patterns that do not occupy a full constituent are likely to cut multiword expressions (MWEs) into two parts, one part that gets treated as a valid C word and one part that is completely ignored." ></td>
	<td class="line x" title="111:257	The main idea in the present paper is to use the bracketings induced by unsupervised parsers in order to avoid the problems above." ></td>
	<td class="line x" title="112:257	We utilize bracketing boundaries in our meta-patterns in addition to HFW and C slots." ></td>
	<td class="line x" title="113:257	In other words, their original meta-patterns are totally lexical, while ours are lexico-syntactic meta-patterns." ></td>
	<td class="line x" title="114:257	We preserve the attractive properties of meta-patterns, because both HFWs and bracketings can be found or computed in a language independent manner and very efficiently." ></td>
	<td class="line x" title="115:257	Concretely, we define a HFW as a word appearing more than TH times per million words, and a C as a word or multiword expression containing up to 4 words, appearing less than TC times per million." ></td>
	<td class="line x" title="116:257	We require that our patterns include two slots for Cs, separated by at least a single HFW or bracket." ></td>
	<td class="line x" title="117:257	We allow separation by a single bracket because the lowest level in the induced bracketing structure usually corresponds to lexical items, while higher levels correspond to actual syntactic constituents." ></td>
	<td class="line x" title="118:257	In order to avoid truncation of multiword expressions, we also require the meta pattern to start and end by a HFW or bracket." ></td>
	<td class="line x" title="119:257	Thus our meta-patterns match the following regular expression: {H|B} C1 {H|B}+ C2 {H|B} where * means zero or more times, and + means one or more time and B can be (,) brackets produced by the parser (in these patterns we do not need to guarantee that brackets match properly)." ></td>
	<td class="line x" title="120:257	Examples of such patterns include ((C1)in C2)), (C1)(such(as(((C2), and (C1)and(C2)3." ></td>
	<td class="line x" title="121:257	We dismiss rare patterns that appear less than TP times per million words." ></td>
	<td class="line x" title="122:257	Symmetric patterns." ></td>
	<td class="line x" title="123:257	Many of the pattern candidates discovered in the previous stage are not usable." ></td>
	<td class="line x" title="124:257	In order to find a usable subset, we focus on the symmetric patterns." ></td>
	<td class="line x" title="125:257	We define a symmetric pattern as a pattern in which the same pair of terms (C words) is likely to appear in both left-to-right and right-toleft orders." ></td>
	<td class="line x" title="126:257	In order to identify symmetric patterns, for each pattern we define a pattern graph G(P), as proposed by (Widdows and Dorow, 2002)." ></td>
	<td class="line x" title="127:257	If term pair (C1,C2) appears in pattern P in some context, 3This paper does not use any punctuation since the parser is provided with sentences having all non-alphabetic characters removed." ></td>
	<td class="line x" title="128:257	We assume word separation." ></td>
	<td class="line x" title="129:257	C1,2 can be a word or a multiword expression." ></td>
	<td class="line x" title="130:257	51 we add nodes c1,c2 to the graph and a directed edge EP(c1,c2) between them." ></td>
	<td class="line x" title="131:257	In order to select symmetric patterns, we create such a pattern graph for every discovered pattern, and create a symmetric subgraph SymG(P) in which we take only bidirectional edges from G(P)." ></td>
	<td class="line x" title="132:257	Then we compute three measures for each pattern candidate as proposed by (Davidov and Rappoport, 2006): M1(P) := |{c1|c2EP(c1,c2)  c3EP(c3,c1)}||Nodes(G(P))| M2(P) := |Nodes(SymG(P))||Nodes(G(P))| M3(P) := |Edges(SymG(P))||Edges(G(P))| For each measure, we prepare a sorted list of all candidate patterns." ></td>
	<td class="line x" title="133:257	We remove patterns that are not in the top ZT (we use 100, see Section 6) in any of the three lists, and patterns that are in the bottom ZB in at least one of the lists." ></td>
	<td class="line x" title="134:257	5 Concept Discovery At the end of the previous stage we have a set of symmetric patterns." ></td>
	<td class="line x" title="135:257	We now use them in order to discover concepts." ></td>
	<td class="line x" title="136:257	The concept discovery algorithm is essentially the same as used by (Davidov and Rappoport, 2006) and has some similarity with the one used by (Widdows and Dorow, 2002)." ></td>
	<td class="line x" title="137:257	In this section we outline the algorithm." ></td>
	<td class="line x" title="138:257	The clique-set method." ></td>
	<td class="line x" title="139:257	The utilized approach to concept discovery is based on connectivity structures in the all-pattern term relationship graph G, resulting from merging all of the single-pattern graphs for symmetric patterns selected in the previous stage." ></td>
	<td class="line x" title="140:257	The main observation regarding G is that highly interconnected words are good candidates to form a concept." ></td>
	<td class="line x" title="141:257	We find all strong n-cliques (subgraphs containing n nodes that are all interconnected in both directions)." ></td>
	<td class="line x" title="142:257	A clique Q defines a concept that contains all of the nodes in Q plus all of the nodes that are (1) at least unidirectionally connected to all nodes in Q, and (2) bidirectionally connected to at least one node in Q. Using this definition, we create a concept for each such clique." ></td>
	<td class="line x" title="143:257	Note that a single term can be assigned to several concepts." ></td>
	<td class="line x" title="144:257	Thus a clique based on a connection of the word Sun to Microsoft can lead to a concept of computer companies, while the connection of Sun to Earth can lead to a concept of celestial bodies." ></td>
	<td class="line x" title="145:257	Reducing noise: merging and windowing." ></td>
	<td class="line x" title="146:257	Since any given term can participate in many cliques, the algorithm creates overlapping categories, some of which redundant." ></td>
	<td class="line x" title="147:257	In addition, due to the nature of language and the imperfection of the corpus some noise is obviously to be expected." ></td>
	<td class="line x" title="148:257	We enhance the quality of the obtained concepts by merging them and by windowing on the corpus." ></td>
	<td class="line x" title="149:257	We merge two concepts Q,R, iff there is more than a 50% overlap between them: (|QintersectiontextR| > |Q|/2)  (|QintersectiontextR| > |R|/2)." ></td>
	<td class="line x" title="150:257	In order to increase concept quality and remove concepts that are too context-specific, we use a simple corpus windowing technique." ></td>
	<td class="line x" title="151:257	Instead of running the algorithm of this section on the whole corpus, we divide the corpus into windows of equal size and perform the concept discovery algorithm of this section (without pattern discovery) on each window independently." ></td>
	<td class="line x" title="152:257	We now have a set of concepts for each window." ></td>
	<td class="line x" title="153:257	For the final set, we select only those concepts that appear in at least two of the windows." ></td>
	<td class="line x" title="154:257	This technique reduces noise at the potential cost of lowering coverage." ></td>
	<td class="line x" title="155:257	A decrease in the number of windows should produce more noisy results, while discovering more concepts and terms." ></td>
	<td class="line x" title="156:257	In the next section we show that while windowing is clearly required for a large corpus, incorporation of parser data increases the quality of the extracted corpus to the point where windowing can be significantly reduced." ></td>
	<td class="line x" title="157:257	6 Results In order to estimate the quality of concepts and to compare it to previous work, we have performed both automatic and human evaluation." ></td>
	<td class="line x" title="158:257	Our basic comparison was to (Davidov and Rappoport, 2006) (we have obtained their data and utilized their algorithm), where we can estimate if incorporation of parser data can solve some fundamental weaknesses of their framework." ></td>
	<td class="line x" title="159:257	In the following description, we call their algorithm P and our parser-based framework P+." ></td>
	<td class="line x" title="160:257	We have also performed an indirect comparison to (Widdows and Dorow, 2002)." ></td>
	<td class="line x" title="161:257	While there is a significant number of other related studies4 on concept acquisition (see Section 2), 4Most are supervised and/or use language-specific tools." ></td>
	<td class="line x" title="162:257	52 direct or even indirect comparison to these works is problematic due to difference in corpora, problem definitions and evaluation strategies." ></td>
	<td class="line x" title="163:257	Below we describe the corpora and parameters used in our evaluation and then show and discuss WordNet-based and Human evaluation settings and results." ></td>
	<td class="line x" title="164:257	Corpora." ></td>
	<td class="line x" title="165:257	We performed in-depth evaluation in two languages, English and Russian, using three corpora, two for English and one for Russian." ></td>
	<td class="line x" title="166:257	The first English corpus is the BNC, containing about 100M words." ></td>
	<td class="line x" title="167:257	The second English corpus, DMOZ(Gabrilovich and Markovitch, 2005), is a web corpus obtained by crawling URLs in the Open Directory Project (dmoz.org), resulting in 68GB containing about 8.2G words from 50M web pages." ></td>
	<td class="line x" title="168:257	The Russian corpus (Davidov and Rappoport, 2006) was assembled from web-based Russian repositories, to yield 33GB and 4G words." ></td>
	<td class="line x" title="169:257	All of these corpora were also used by (Davidov and Rappoport, 2006) and BNC was used in similar settings by (Widdows and Dorow, 2002)." ></td>
	<td class="line x" title="170:257	Algorithm parameters." ></td>
	<td class="line x" title="171:257	The thresholds TH,TC,TP,ZT,ZB, were determined mostly by practical memory size considerations: we computed thresholds that would give us the maximal number of terms, while enabling the pattern access table to reside in main memory." ></td>
	<td class="line x" title="172:257	The resulting numbers are 100,50,20,100,100." ></td>
	<td class="line x" title="173:257	Corpus window size was determined by starting from a small window size, extracting at random a single window, running the algorithm, and iterating this process with increased 2 window sizes until reaching a desired vocabulary concept participation percentage (before windowing) (i.e., x% of the different words in the corpus participate in terms assigned into concepts." ></td>
	<td class="line x" title="174:257	We used 5%.)." ></td>
	<td class="line x" title="175:257	We also ran the algorithm without windowing in order to check how well the provided parsing information can help reduce noise." ></td>
	<td class="line x" title="176:257	Among the patterns discovered are the ubiquitous ones containing and,or, e.g. ((X) or (a Y)), and additional ones such as from (X) to (Y)." ></td>
	<td class="line x" title="177:257	Influence of parsing data on number of discovered concepts." ></td>
	<td class="line x" title="178:257	Table 1 compares the concept acquisition framework with (P+) and without (P) utilization of parsing data." ></td>
	<td class="line x" title="179:257	We can see that the amount of different words V W C AS P P+ P P+ P P+ DMOZ 16 330 504 142 130 12.8 16.0 BNC 0.3 25 42 9.6 8.9 10.2 15.6 Russ." ></td>
	<td class="line x" title="180:257	10 235 406 115 96 11.6 15.1 Table 1: Results for concept discovery with (P+) and without (P) utilization of parsing data." ></td>
	<td class="line x" title="181:257	V is the total number (millions) of different words in the corpus." ></td>
	<td class="line x" title="182:257	W is the number (thousands) of words belonging to at least one of the terms for one of the concepts." ></td>
	<td class="line x" title="183:257	C is the number (thousands) of concepts (after merging and windowing)." ></td>
	<td class="line x" title="184:257	AS is the average(words) category size." ></td>
	<td class="line x" title="185:257	covered by discovered concepts raises nearly 1.5fold when we utilize patterns based on parsing data in comparison to pure HFW patterns used in previous work." ></td>
	<td class="line x" title="186:257	We can also see nearly the same increase in average concept size." ></td>
	<td class="line x" title="187:257	At the same time we observe about 15% reduction in the total number of discovered concepts." ></td>
	<td class="line x" title="188:257	There are two opposite factors in P+ which may influence the number of concepts, their size and coverage in comparison to P. On one hand, utilization of more restricted patterns that include parsing information leads to a reduced number of concept term instances being discovered." ></td>
	<td class="line x" title="189:257	Thus, the P+ pattern (X (or (a Y)) will recognize (TV (or (a movie)) instance and will miss (lunch) or (a snack)), while the P pattern X or a Y will capture both." ></td>
	<td class="line x" title="190:257	This leads to a decrease in the number of discovered concepts." ></td>
	<td class="line x" title="191:257	On the other hand, P+ patterns, unlike P ones, allow the extraction of multiword expressions5, and indeed more than third of the discovered terms using P+ were MWEs." ></td>
	<td class="line x" title="192:257	Utilization of MWEs not only allows to cover a greater amount of different words, but also increases the number of discovered concepts since new concepts can be found using cliques of newly discovered MWEs." ></td>
	<td class="line x" title="193:257	From the results, we can see that for a given concept size and word coverage, the ability to discover MWEs overcomes the disadvantage of ignoring potentially useful concepts." ></td>
	<td class="line x" title="194:257	Human judgment evaluation." ></td>
	<td class="line x" title="195:257	Our human judgement evaluation closely followed the protocol (Davidov and Rappoport, 2006)." ></td>
	<td class="line x" title="196:257	We used 4 subjects for evaluation of the English 5While P method can potentially be used to extract MWEs, preliminary experimentation shows that without significant modification, quality of MWEs obtained by P is very low in comparison to P+ 53 concepts and 4 subjects for Russian ones." ></td>
	<td class="line x" title="197:257	In order to assess subjects reliability, we also included random concepts (see below)." ></td>
	<td class="line x" title="198:257	The goal of the experiment was to examine the differences between the P+ and P concept acquisition frameworks." ></td>
	<td class="line x" title="199:257	Subjects were given 50 triplets of words and were asked to rank them using the following scale: (1) the words definitely share a significant part of their meaning; (2) the words have a shared meaning but only in some context; (3) the words have a shared meaning only under a very unusual context/situation; (4) the words do not share any meaning; (5) I am not familiar enough with some/all of the words." ></td>
	<td class="line x" title="200:257	The 50 triplets were obtained as follows." ></td>
	<td class="line x" title="201:257	We have randomly selected 40 concept pairs (C+,C): C+ in P+ and C in P using five following restrictions: (1) concepts should contain at least 10 words; (2) for a selected pair, C+ should share at least half of its single-word terms with C, and C should share at least half of its words with C+; (3) C+ should contain at least 3 MWEs; (4) C should contain at least 3 words not appearing in C+; (5) C+ should contain at least 3 single-word terms not appearing in C. These restrictions allow to select concept pairs such that C+ is similar to C while they still carry enough differences which can be examined." ></td>
	<td class="line x" title="202:257	We selected the triplets as following: for pairs (C+, C) ten triplets include terms appearing in both C+ and C (Both column in Table 2), ten triplets include singleword terms appearing in C+ but not C (P+ single column), ten triplets include single-word terms appearing in C but not C+ (P column), ten triplets include MWEs appearing in C+ (P+ mwe column) and ten triplets include random terms obtained from P+ concepts (Rand column)." ></td>
	<td class="line x" title="203:257	P+ P Both Rand mwe single % shared meaning DMOZ 85 88 68 81 6 BNC 85 90 61 88 0 Russ." ></td>
	<td class="line x" title="204:257	89 95 70 93 11 triplet score (1-4) DMOZ 1.7 1.4 2.5 1.7 3.8 BNC 1.6 1.3 2.1 1.5 4.0 Russ." ></td>
	<td class="line x" title="205:257	1.5 1.1 2.0 1.3 3.7 Table 2: Results of evaluation by human judgment of three data sets." ></td>
	<td class="line x" title="206:257	P+ single/mwe: single-word/MWE terms existing only in P+ concept; P: single-word terms existing only in P concept; Both: terms existing in both concepts; Rand: random terms." ></td>
	<td class="line x" title="207:257	See text for detailed explanations." ></td>
	<td class="line x" title="208:257	The first part of Table 2 gives the average percentage of triplets that were given scores of 1 or 2 (that is, significant shared meaning)." ></td>
	<td class="line x" title="209:257	The second part gives the average score of a triplet (1 is best)." ></td>
	<td class="line x" title="210:257	In these lines scores of 5 were not counted." ></td>
	<td class="line x" title="211:257	Interevaluator Kappa between scores are 0.68/0.75/0.76 for DMOZ, BNC and Russian respectively." ></td>
	<td class="line x" title="212:257	We can see that terms selected by P and skipped by P+ receive low scores, at the same time even singleword terms selected by P+ and skipped by P show very high scores." ></td>
	<td class="line x" title="213:257	This shows that using parser data, the proposed framework can successfully avoid selection of erroneous terms, while discovering highquality terms missed by P. We can also see that P+ performance on MWEs, while being slightly inferior to the one for single-word terms, still achieves results comparable to those of single-word terms." ></td>
	<td class="line x" title="214:257	Thus our algorithm can greatly improve the results not only by discovering of MWEs but also by improving the set of single word concept terms." ></td>
	<td class="line x" title="215:257	WordNet-based evaluation." ></td>
	<td class="line x" title="216:257	The major guideline in this part of the evaluation was to compare our results with previous work (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) without the possible bias of human evaluation." ></td>
	<td class="line x" title="217:257	We have followed their methodology as best as we could, using the same WordNet (WN) categories and the same corpora." ></td>
	<td class="line x" title="218:257	This also allows indirect comparison to several other studies, thus (Widdows and Dorow, 2002) reports results for an LSA-based clustering algorithm that are vastly inferior to the pattern-based ones." ></td>
	<td class="line x" title="219:257	The evaluation method is as follows." ></td>
	<td class="line x" title="220:257	We took the exact 10 WN subsets referred to as subjects in (Widdows and Dorow, 2002), and removed all multiword items." ></td>
	<td class="line x" title="221:257	We then selected at random 10 pairs of words from each subject." ></td>
	<td class="line x" title="222:257	For each pair, we found the largest of our discovered concepts containing it." ></td>
	<td class="line x" title="223:257	The various morphological forms or clear typos of the same word were treated as one in the evaluation." ></td>
	<td class="line x" title="224:257	We have improved the evaluation framework for Russian by using the Russian WordNet (Gelfenbeynand et al., 2003) instead of back-translations as done in (Davidov and Rappoport, 2006)." ></td>
	<td class="line x" title="225:257	Preliminary examination shows that this has no apparent effect on the results." ></td>
	<td class="line x" title="226:257	For each found concept C containing N words, we computed the following: (1) Precision: the num54 ber of words present in both C and WN divided by N; (2) Precision*: the number of correct words divided by N. Correct words are either words that appear in the WN subtree, or words whose entry in the American Heritage Dictionary or the Britannica directly defines them as belonging to the given class (e.g., murder is defined as a crime)." ></td>
	<td class="line x" title="227:257	This was done in order to overcome the relative poorness of WN; (3) Recall: the number of words present in both C and WN divided by the number of words in WN; (4) The percentage of correctly discovered words (according to Precision*) that are not in WN." ></td>
	<td class="line x" title="228:257	Table 3 compares the macro-average of these 10 categories to corresponding related work." ></td>
	<td class="line x" title="229:257	We do not Prec." ></td>
	<td class="line x" title="230:257	Prec.* Rec." ></td>
	<td class="line x" title="231:257	%New DMOZ P 79.8 86.5 22.7 2.5 P+ 79.5 91.3 28.6 3.7 BNC P 92.76 95.72 7.22 0.4 P+ 93.0 96.1 14.6 1.7 Widdows 82.0 Russian P 82.39 89.64 20.03 2.1 P+ 83.5 92.6 29.6 4.0 Table 3: WordNet evaluation in comparison to P (Davidov and Rappoport, 2006) and to Widdows(Widdows and Dorow, 2002)." ></td>
	<td class="line x" title="232:257	Columns show average precision, precision* (as defined in text), recall, and % of new words added to corresponding WN subtree." ></td>
	<td class="line x" title="233:257	observe apparent rise in precision when comparing P+ and P, but we can see significant improvement in both recall and precision* for all of three corpora." ></td>
	<td class="line x" title="234:257	In combination with human judgement results, this suggests that the P+ framework successfully discovers more correct terms not present in WN." ></td>
	<td class="line x" title="235:257	This causes precision to remain constant while precision* improves significantly." ></td>
	<td class="line x" title="236:257	Rise in recall also shows that the P+ framework can discover significantly more correct terms from the same data." ></td>
	<td class="line x" title="237:257	Windowing requirement." ></td>
	<td class="line x" title="238:257	As discussed in Section 5, windowing is required for successful noise reduction." ></td>
	<td class="line x" title="239:257	However, due to the increase in pattern quality with parser data, it is likely that less noise will be captured by the discovered patterns." ></td>
	<td class="line x" title="240:257	Hence, windowing could be relaxed allowing to obtain more data with sufficiently high precision." ></td>
	<td class="line x" title="241:257	In order to test this issue we applied our algorithms on the DMOZ corpus with 3 different windowing settings: (1) choosing window size as described above; (2) using 4 larger window; (3) avoiding windowing altogether." ></td>
	<td class="line x" title="242:257	Each time we randomly sampled a set of 100 concepts and tagged (by the authors) noisy ones." ></td>
	<td class="line x" title="243:257	A concept is considered to be noisy if it has at least 3 words unrelated to each other." ></td>
	<td class="line x" title="244:257	Table 4 shows results of this test." ></td>
	<td class="line x" title="245:257	Reg." ></td>
	<td class="line x" title="246:257	Window 4 Window No windowing P 4 18 33 P+ 4 5 21 Table 4: Percentage of noisy concepts as a function of windowing." ></td>
	<td class="line x" title="247:257	We can see that while windowing is still essential even with available parser data, using this data we can significantly reduce windowing requirements, allowing us to discover more concepts from the same data." ></td>
	<td class="line x" title="248:257	Timing requirements are modest, considering we parsed such large amounts of data." ></td>
	<td class="line x" title="249:257	BNC parsing took 45 minutes, and the total single-machine processing time for the 68Gb DMOZ corpus was 4 days6." ></td>
	<td class="line x" title="250:257	In comparison, a state-of-art supervised parser (Charniak and Johnson, 2005) would process the same amount of data in 1.3 years7." ></td>
	<td class="line x" title="251:257	7 Discussion We have presented a framework which utilizes an efficient fully unsupervised parser for unsupervised pattern-based discovery of concepts." ></td>
	<td class="line x" title="252:257	We showed that utilization of unsupervised parser in pattern acquisition not only allows successful extraction of MWEs but also improves the quality of obtained concepts, avoiding noise and adding new terms missed by the parse-less approach." ></td>
	<td class="line x" title="253:257	At the same time, the framework remains fully unsupervised, allowing its straightforward application to different languages as supported by our bilingual evaluation." ></td>
	<td class="line x" title="254:257	This research presents one more step towards the merging of fully unsupervised techniques for lexical acquisition, allowing to extract semantic data without strong assumptions on domain or language." ></td>
	<td class="line x" title="255:257	While we have aimed for concept acquisition, the proposed framework can be also useful for extraction of different types of lexical relationships, both among concepts and between concept terms." ></td>
	<td class="line x" title="256:257	6In fact, we used a PC cluster, and all 3 corpora were parsed in 15 hours." ></td>
	<td class="line x" title="257:257	7Considering the reported parsing rate of 10 sentences per second 55" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W09-1316
Incorporating Syntactic Dependency Information towards Improved Coding of Lengthy Medical Concepts in Clinical Reports
Bashyam, Vijayaraghavan;Taira, Ricky K;"></td>
	<td class="line x" title="1:153	Proceedings of the Workshop on BioNLP, pages 125132, Boulder, Colorado, June 2009." ></td>
	<td class="line x" title="2:153	c 2009 Association for Computational Linguistics ________________________________ *  formerly with the Medical Imaging Informatics Group, Dept. of Radiological Sciences, University of California Los Angeles, Los Angeles, CA 90024 Incorporating syntactic dependency information towards improved coding of lengthy medical concepts in clinical reports  Vijayaraghavan Bashyam, PhD* Monster Worldwide Inc. Mountain View, CA 94043 vbashyam@ucla.edu Ricky K Taira, PhD Medical Imaging Informatics Group University of California, Los Angeles Los Angeles, CA 90024 rtaira@mii.ucla.edu Abstract Medical concepts in clinical reports can be found with a high degree of variability of expression." ></td>
	<td class="line x" title="3:153	Normalizing medical concepts to standardized vocabularies is a common way of accounting for this variability." ></td>
	<td class="line x" title="4:153	One of the challenges in medical concept normalization is the difficulty in comparing two concepts which are orthographically different in representation but are identical in meaning." ></td>
	<td class="line x" title="5:153	In this work we describe a method to compare medical phrases by utilizing the information found in syntactic dependencies." ></td>
	<td class="line x" title="6:153	We collected a large corpus of radiology reports from our university medical center." ></td>
	<td class="line x" title="7:153	A shallow semantic parser was used to identify anatomical phrases." ></td>
	<td class="line x" title="8:153	We performed a series of transformations to convert the anatomical phrase into a normalized syntactic dependency representation." ></td>
	<td class="line x" title="9:153	The new representation provides an easy intuitive way of comparing the phrases for the purpose of concept normalization." ></td>
	<td class="line x" title="10:153	1 Introduction A vast amount of electronic information is generated in hospitals as a part of routine clinical care due to the adoption of the electronic medical record by health care centers in the United States (Berner et al., 2005; Jha et al., 2006)." ></td>
	<td class="line x" title="11:153	A significant portion of this information is in the form of unstructured free-text (Hall, 2000; Tange et al., 1998)." ></td>
	<td class="line x" title="12:153	A free text representation makes it difficult for applications to accurately extract medical information for generic purposes (Ananiadou et al., 2004)." ></td>
	<td class="line x" title="13:153	The problem of variability of expression in natural language expression has been well studied (Bates, 1986, 1989, 1998; Blair and Maron, 1985; Funk and Reid, 1983; Furnas et al., 1984; Gomez et al., 1990)." ></td>
	<td class="line x" title="14:153	In the medical domain in particular, users frequently express the same concept in different ways and different concepts in similar ways (Ananiadou and Nenadic, 2006)." ></td>
	<td class="line x" title="15:153	To illustrate, the terms heart attack and cardiac attack both refer to the same concept  myocardial infarction." ></td>
	<td class="line x" title="16:153	Conversely the term left lobe could refer to the left lobe of lung or the left lobe of liver depending on the context (occurrence in a chest radiology report versus a gastro-intestinal radiology report)." ></td>
	<td class="line x" title="17:153	Such variability suggests a need to normalize concepts encountered in medical reports to a standard vocabulary in order to ensure interoperability." ></td>
	<td class="line x" title="18:153	Several standardized vocabularies exist in the medical domain such as the Unified Medical Language System (Humphreys and Lindberg, 1993), Systematized Nomenclature of Medicine Clinical Terms (College of American Pathologists, July 2003), Medical Subject Headings (National Library of Medicine), and the International Classification of Diseases (World Health Organization)." ></td>
	<td class="line x" title="19:153	There have been several attempts in the past (Aronson, 2001; Bashyam and Taira, 2005; Bashyam et al., 2007; Cooper and Miller, 1998; Friedman et al., 2004; Nadkarni et al., 2001; Oliver and Altman, 1994; Ruch et al., 2003; Zou et al., 2003) to map medical concepts to their standardized concept found in these terminologies." ></td>
	<td class="line x" title="20:153	These approaches are based on mostly on lexical matching (Bashyam et al., 2007), string matching (Nadkarni et al., 2001), statistical indexing (Cooper and 125 Miller, 1998), natural language processing (Aronson, 2001; Friedman et al., 2004) information retrieval techniques (Bashyam and Taira, 2005; Oliver and Altman, 1994; Ruch et al., 2003; Zou et al., 2003) or a combination of these approaches (Cooper and Miller, 1998)." ></td>
	<td class="line x" title="21:153	These systems have managed to map a large percentage of medical terms to their respective standard terminologies in their reported experiments." ></td>
	<td class="line x" title="22:153	While these systems have managed to perform satisfactorily for the task of normalizing simple expressions, they all acknowledge the larger problem of normalizing lengthy expressions." ></td>
	<td class="line x" title="23:153	To illustrate, Nadkarni et al.(2001) mention the mapping of the phrase spleen rupture and normal stomach to the concept stomach rupture as a possible spurious mapping." ></td>
	<td class="line x" title="25:153	We hypothesize that using deep syntactic information can help in avoiding such spurious mapping." ></td>
	<td class="line x" title="26:153	We describe a system which uses information found in syntactic dependencies to help in the coding of lengthy phrases." ></td>
	<td class="line x" title="27:153	Preliminary results using this approach are reported as a proof-of-concept." ></td>
	<td class="line x" title="28:153	2 Background Syntactic dependency parsing has received much focus from the natural language processing community (Eisner, 1996; Kudo and Matsumoto, 2000; Nivre and Scholz, 2004; Yamada and Matsumoto, 2003)." ></td>
	<td class="line x" title="29:153	A syntactic dependency relation is an asymmetric relation between two words." ></td>
	<td class="line x" title="30:153	One word is called the head, and the other word is called the modifier or dependent." ></td>
	<td class="line x" title="31:153	A word in the sentence can play the role of the head in several dependency relations (i.e., it can have several modifiers) but each word can play the role of the modifier only once." ></td>
	<td class="line x" title="32:153	A special word, named the root, does not play the role of the modifier in any relation." ></td>
	<td class="line x" title="33:153	The set of dependency relations that can be defined on a sentence form a tree, called the dependency tree." ></td>
	<td class="line x" title="34:153	An example of dependencies in a typical sentence found in a radiology report is shown in Figure 1." ></td>
	<td class="line x" title="35:153	Systems based on syntactic dependencies have been used successfully in several information retrieval experiments with results outperforming traditional retrieval systems (Croft et al., 1991; Gao et al., 2004; Gonzalez et al., 2005; Smeaton, 1986)." ></td>
	<td class="line oc" title="36:153	In particular, this method has been used for word sense disambiguation (Lin, 1997) and thesaurus construction (Lin, 1998)." ></td>
	<td class="line x" title="37:153	Dependency trees have also been used for medical concept representation in the domains of radiology (Steimann, 1998) and pathology (Romacker et al., 1999)." ></td>
	<td class="line x" title="38:153	3 Methods 3.1 Anatomy Phrase Extraction For identifying anatomy phrases, we use a specialized phrase parser trained to identify anatomy phrases within clinical reports." ></td>
	<td class="line x" title="39:153	The input to the parser is a sentence tagged with a part-of-speech tag and a semantic tag." ></td>
	<td class="line x" title="40:153	The lexical analyzer module of our NLP system takes a single sentence as the input and produces an output of word tokens tagged with their syntactic and semantic classes." ></td>
	<td class="line x" title="41:153	The semantic tag is obtained by mapping tokens in a sentence to a taxonomy handcrafted for the domain of radiology reports custom built from radiology textbooks, radiology review manuals, radiology word compilations and published radiology glossaries apart from actual radiology reports (Taira et al., 2001)." ></td>
	<td class="line x" title="42:153	Features of our implementation    Figure 1." ></td>
	<td class="line x" title="43:153	Example of a syntactic dependency parse tree with emphasis towards semantics." ></td>
	<td class="line x" title="44:153	Each arc    shows a dependency relation between a head and a modifier." ></td>
	<td class="line x" title="45:153	126 include: 1) a large number (>450)  of semantic classes as compared to lexical sources currently available allowing improved discrimination for tasks such as syntactic parsing, semantic interpretation and frame building; 2) the system recognizes special symbols including dates, medical abbreviations, medical coding symbols, numeric measurements, image slice references, and proper names; and 3) the system performs some word sense disambiguation using surrounding syntactic and semantic word features." ></td>
	<td class="line x" title="46:153	Our phrase parsing module currently targets anatomy phrases (e.g., right upper lobe of lung), existential relationships (e.g., there is no evidence of), and spatial relationships (e.g., is located 1cm above)." ></td>
	<td class="line x" title="47:153	We utilize a supervised learning approach to estimate the feature weights to a maximum entropy model which classifies words as the start, inside, end, single, or outside of a phrase boundary." ></td>
	<td class="line x" title="48:153	A Viterbi dynamic programming algorithm  is used to maximize the tag sequence probability." ></td>
	<td class="line x" title="49:153	The anatomy phrase chunker has been tested on 4,500 sentences with recall and precision scores of 97.1% and 97.4% respectively." ></td>
	<td class="line x" title="50:153	3.2 Normalized Dependency Representation We perform a series of transformations to convert an anatomical phrase from a free-text representation to a normalized dependency vector space representation." ></td>
	<td class="line x" title="51:153	The following steps are taken in the representation conversion:  Syntactic Parsing  The anatomy phrase identified by the phrase parser preserves lexical information which is used to obtain a dependency parse tree using a full syntactic parser." ></td>
	<td class="line x" title="52:153	This parser is based on a novel field theory approach to dependency parsing." ></td>
	<td class="line x" title="53:153	The parser is strongly modeled for the radiology domain with performance accuracies of 84.9% and 89.9% for link precision and recall respectively for parsing whole sentences (Taira et al., 2007)." ></td>
	<td class="line x" title="54:153	In comparison, the state-of-the-art parsers have performance accuracies in the low nineties for link precision and recall in the domain of newspaper text, with performance unknown in the domain of clinical text." ></td>
	<td class="line x" title="55:153	Link Reduction   Our system classifies dependency links into two types  bilexical links and trilexical links." ></td>
	<td class="line x" title="56:153	A bilexical link is a strong dependency relation between two words (e.g. determinernoun) whereas a trilexical link usually has a mediator word in between the two words (e.g. findinginlocation)." ></td>
	<td class="line x" title="57:153	When possible, a trilexical link is converted to a bilexical link by the elimination of the mediator word and the link type is tagged by the mediator word." ></td>
	<td class="line x" title="58:153	The link type can play important roles in certain cases." ></td>
	<td class="line x" title="59:153	In cases where the mediator word is also important, the trilexical link is considered as a pair of bilexical links." ></td>
	<td class="line x" title="60:153	Token Level Normalization  Once the parse tree is obtained, the tokens are normalized to their base form." ></td>
	<td class="line x" title="61:153	The normalization is an approximate kind of lemmatization." ></td>
	<td class="line x" title="62:153	However we also perform word level synonym normalization." ></td>
	<td class="line x" title="63:153	For lemmatization, we use the Lexical Variant Generator tools developed by the National Library of Medicine for biomedical text (McCray et al., 1994)." ></td>
	<td class="line x" title="64:153	For synonyms, we use a handcrafted lexicon built for the domain of radiology." ></td>
	<td class="line x" title="65:153	This step helps in avoiding missing a mapping due to lexical differences due to pluralization, abbreviations and acronyms, case differences etc. This representation is referred to as the normalized dependency vector space representation 3.3 Mapping to a Terminology The normalized dependency parse tree is represented as in a vector space as a bag-of-links as analogous to the so-called bag-of-words representation in conventional information retrieval." ></td>
	<td class="line x" title="66:153	Two phrases can now be compared by using similarity measures such as cosine, dice, jaccard etc. within the dimension-space of dependency-links." ></td>
	<td class="line x" title="67:153	One phrase can be the anatomy phrase in a clinical report and the other phrase can be an entry in a standardized terminology." ></td>
	<td class="line x" title="68:153	127  Figure 2." ></td>
	<td class="line x" title="69:153	Example illustrating the transformation of a medical phrase from a free-text representation to a normalized syntactic dependency  vector space representation." ></td>
	<td class="line x" title="70:153	An exercise in normalization is described in Figure 2 to illustrate how this method works." ></td>
	<td class="line x" title="71:153	Consider the following phrase in a neuro-radiology report: ventral postero-medial thalamic nucleus." ></td>
	<td class="line x" title="72:153	The corresponding concept in the target terminology is the phrase postero-medial ventral nucleus of thalamus." ></td>
	<td class="line x" title="73:153	These phrases if compared by string matching will not result in direct matches." ></td>
	<td class="line x" title="74:153	Permuting words and trying to compare rearrangements is complicated." ></td>
	<td class="line x" title="75:153	In our approach, we first preprocess our terminology list and store it in a database." ></td>
	<td class="line x" title="76:153	The preprocessing step is described in the right column (Phrase 2) of Figure 2." ></td>
	<td class="line x" title="77:153	Starting with the phrase postero-medial ventral nucleus of thalamus, we first tokenize the individual words (lexical analysis) in the first step." ></td>
	<td class="line x" title="78:153	In the second step, we parse the phrase to arrive at the dependency tree." ></td>
	<td class="line x" title="79:153	In the third step, the trilexical link nucleusofthalamus is converted to a bilexical link by eliminating the word of and tagging it as the link type." ></td>
	<td class="line x" title="80:153	In the following step, each word is normalized to its base form." ></td>
	<td class="line x" title="81:153	In the fifth step, the phrase is represented as a bag-of-links and stored in a database." ></td>
	<td class="line x" title="82:153	Similarly all the other phrases in our terminology are stored." ></td>
	<td class="line x" title="83:153	When the query phrase ventral postero-medial thalamic nucleus is compared against the terminology it undergoes the same processes previously described (Figure 2, Phrase 1)." ></td>
	<td class="line x" title="84:153	The importance of word-normalization can be seen here." ></td>
	<td class="line x" title="85:153	In step 4, the word thalamic is normalized to thalamus." ></td>
	<td class="line x" title="86:153	The final output is the bag-of-links representation." ></td>
	<td class="line x" title="87:153	For con128 venience of comparison Figure 2 shows together, the query phrase and target phrase undergoing the various steps starting from a bag-of-words representation to a bag-of-links representation." ></td>
	<td class="line x" title="88:153	It is clear that both phrases look identical in the final representation." ></td>
	<td class="line x" title="89:153	While a string comparison would have missed equating the two in their original wordlevel representation, a comparison in the dependency vector space is likely to score them as a perfect match." ></td>
	<td class="line x" title="90:153	4 Experiment and Results We obtained a set of 2500 neuro-radiology reports from our university medical center." ></td>
	<td class="line x" title="91:153	Using the shallow semantic parser, we extracted a set of 2551 unique anatomical phrases." ></td>
	<td class="line x" title="92:153	Of the 2551 phrases, 819 phrases were single worded terms." ></td>
	<td class="line x" title="93:153	We discarded the single word terms." ></td>
	<td class="line x" title="94:153	Single worded phrases do not fall into the difficult-to-map category which this method is specifically aiming to address." ></td>
	<td class="line x" title="95:153	Moreover, a minimum of two words are required to define a syntactic dependency and thus the method is irrelevant for single worded terms." ></td>
	<td class="line x" title="96:153	Thus we used only the 1732 multi-worded terms in our experiment." ></td>
	<td class="line x" title="97:153	The average length of the multiworded terms was 2.48 words." ></td>
	<td class="line x" title="98:153	We chose the UMLS, a coordinated repository of vocabularies as a target for concept coding." ></td>
	<td class="line x" title="99:153	To reduce complexity, we removed non-English concepts and concepts outside the domain of     neuroradiology by filtering out unrelated concepts." ></td>
	<td class="line x" title="100:153	Our final terminology had a size of about 100,000 entries." ></td>
	<td class="line x" title="101:153	We preprocessed the entire terminology using the above mentioned steps and stored the dependency representation in a database." ></td>
	<td class="line x" title="102:153	Every anatomy phrase was queried against this database and cosine similarity was used to measure relevance." ></td>
	<td class="line x" title="103:153	No weighting system was employed although it is possible to weight links by their types." ></td>
	<td class="line x" title="104:153	A physician domain expert manually evaluated the results of the 1732 queries for performance." ></td>
	<td class="line x" title="105:153	Of the 1732 phrases, 1091  phrases (62.9% accuracy, 95% CI 0.946%) were successfully matched." ></td>
	<td class="line x" title="106:153	Since the target set is extremely large in size (as in any IR system), a recall analysis was not performed." ></td>
	<td class="line x" title="107:153	A baseline comparison with MMTx (in phrase mode) resulted in 1051 phrases (60.68% accuracy, 95% CI 0.49%) being mapped by MMTx." ></td>
	<td class="line x" title="108:153	Table 1 summarizes the results." ></td>
	<td class="line x" title="109:153	5 Discussion Analysis of the errors showed that the following error types resulted in the inability to match phrases perfectly:  Parsing without context:  A syntactic parser can parse a sentence and identify dependency relations in a sentence." ></td>
	<td class="line x" title="110:153	However, when a phrase is given as an input, it is not always easy to parse a phrase and generate a dependency representation." ></td>
	<td class="line x" title="111:153	There is context (remaining portions of the sentence) missing which is needed to unambiguously parse the phrase." ></td>
	<td class="line x" title="112:153	In the case of anatomical phrases, our system was able to parse it because the source sentences from which they were extracted were available." ></td>
	<td class="line x" title="113:153	However, in the case of the UMLS phrases, there is no such available information." ></td>
	<td class="line x" title="114:153	Therefore manual parsing of several UMLS phrases had to be performed." ></td>
	<td class="line x" title="115:153	One potential solution to this problem could be to identify MEDLINE sentences that contain these UMLS concepts and obtain a dependency parse tree using the context of the sentence." ></td>
	<td class="line x" title="116:153	Modular system architecture:  Since the system is modular, any errors in one of the modules (tokenization, word level normalization etc.) would result in the final dependency representation being imperfect." ></td>
	<td class="line x" title="117:153	The specific errors we noticed were:  Parsing Errors:  Our parser has a higher accuracy for parsing phrases than whole sentences." ></td>
	<td class="line x" title="118:153	However in this experiment, there were 37 instances where it failed in MMTx Matched Phrases Syn." ></td>
	<td class="line x" title="119:153	Dependency Matched Phrases 1051 1091 n=1732 60.68% 62.99% (0.49%) (0.49%)  Table 1." ></td>
	<td class="line x" title="120:153	Overview of Results 129 assigning the correct links." ></td>
	<td class="line x" title="121:153	This resulted in partial matches." ></td>
	<td class="line x" title="122:153	Word Normalization Errors:   There is a natural ambiguity introduced when words are normalized to their base forms." ></td>
	<td class="line x" title="123:153	Words with completely different senses can have the same root form (e.g. leftleaves and leftleft (spatial direction))." ></td>
	<td class="line x" title="124:153	Similarly, a word can have different normalized forms depending on the sense (e.g. leafleaves and leftleaves)." ></td>
	<td class="line x" title="125:153	A robust method for word-level normalization is desired that can also perform word-sense disambiguation." ></td>
	<td class="line x" title="126:153	Currently the NLMs word level normalization tool is being used which is not perfect and therefore errors introduced due to this module result in the entire phrase being transformed incorrectly or ambiguously." ></td>
	<td class="line x" title="127:153	The ideal word level normalization will result in the words cancer, cancerous, carcinoma all conflating to the same word which is beyond purely morphological analysis." ></td>
	<td class="line x" title="128:153	Link Reduction Errors:  Not all relations manifest as simple bilexical and trilexical links." ></td>
	<td class="line x" title="129:153	Some relations are tetralexical and although they can be reduced effectively to bilexical links, the methodology needs to be investigated." ></td>
	<td class="line x" title="130:153	To illustrate, consider the phrases mass consistent with cancer and cancerous mass parsed as   massconsistentwithcancer  cancerousmass.  The former is parsed as four words with three links." ></td>
	<td class="line x" title="131:153	To convert it into a bilexical link, the words consistent and with need to be: (1) clustered as a single token and (2) eliminated by transferring it to the link as a label." ></td>
	<td class="line x" title="132:153	This is a more complicated process and we still havent explored such abstractions." ></td>
	<td class="line x" title="133:153	A robust rule based link reduction system is desired to handle such cases." ></td>
	<td class="line x" title="134:153	Another limitation of this method is that the heuristic rules for link reduction may not be applicable outside the radiology domain." ></td>
	<td class="line x" title="135:153	Finally, syntactic dependency parsers are built using computationally complex algorithms." ></td>
	<td class="line x" title="136:153	Thus while using them can result in advanced language understanding, they may not be suitable for real-time applications." ></td>
	<td class="line x" title="137:153	There is always a tradeoff between accuracy and speed and it remains to be seen if robust low complexity parsers can be developed." ></td>
	<td class="line x" title="138:153	The inability to perform a recall analysis also make is difficult to judge the theoretical best performance." ></td>
	<td class="line x" title="139:153	That is, it is quite likely that there are many phrases in our dataset that do not have a corresponding UMLS concept." ></td>
	<td class="line x" title="140:153	Performing a recall analysis would help in determining this." ></td>
	<td class="line x" title="141:153	While we noticed several areas of improvement in our system, we were encouraged by the comparison of the overall results of our system to that of MMTx." ></td>
	<td class="line x" title="142:153	We did not do an error analysis of MMTx since several previous publications have documented the various kinds of errors in MMTx (Bashyam et al., 2007; Divita et al., 2004; Meng et al., 2005)." ></td>
	<td class="line x" title="143:153	Our idea is to provide a baseline comparison showing that our approach performs comparably if not better than MMTx which is the most commonly used1 tool for concept coding." ></td>
	<td class="line x" title="144:153	To our knowledge this the first time syntactic dependencies have been used for this task, Previous attempts have relied purely on shallow parsers." ></td>
	<td class="line x" title="145:153	6 Future Work Increasing the robustness of the individual modules is a primary requirement for further experiments to prevent the weakest link effect cascading to the final output." ></td>
	<td class="line x" title="146:153	Specifically we plan to work towards a robust word level normalization system." ></td>
	<td class="line x" title="147:153	Additionally, robust evaluation methods including comparisons with other techniques will be investigated." ></td>
	<td class="line x" title="148:153	7 Conclusion Syntactic dependency based methods for medical concept coding show promise." ></td>
	<td class="line x" title="149:153	While some of the described implementations are specific to domain (radiology) and phrase type (anatomy), it is expected that the principle is general enough to be applied in other domains as well." ></td>
	<td class="line x" title="150:153	1 For an overview of recent applications of MMTx, see (Bashyam et al., 2007) 130 Acknowledgements The authors would like to thank Lew Andrada, Gregory Leazer, Jonathan Furner and Christine Borgman for several useful suggestions." ></td>
	<td class="line x" title="151:153	This work was supported in part by the following grants: 1." ></td>
	<td class="line x" title="152:153	National Institute of Biomedical Imaging and Bioengineering P01-EB00216 2." ></td>
	<td class="line x" title="153:153	National Institute of Health R01EB002247" ></td>
</tr></table>
</div
</body></html>
