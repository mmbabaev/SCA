<html><body><head><link rel="stylesheet" type="text/css" href="style.css" /><script src="map.js"></script><script src="jquery-1.7.1.min.js"></script></head>
<div class="dstPaperData">
P90-1034 <div class="dstPaperTitle">Noun Classification From Predicate-Argument Structures</div><div class="dstPaperAuthors">Hindle, Donald;</div>
</div>
<table cellspacing="0" cellpadding="0"><tr>
	<td class="srcData" >Source Paper</td>
	<td class="pp legend" ><input type="checkbox" id="cbIPositive" checked="true"/><label for="cbIPositive">Informal +<label></td>
	<td class="nn legend" ><input type="checkbox" id="cbINegative" checked="true"/><label for="cbINegative">Informal -<label></td>
	<td class="oo legend" ><input type="checkbox" id="cbIObjective" checked="true"/><label for="cbIObjective">Informal Neutral<label></td>
	<td class="ppc legend" ><input type="checkbox" id="cbEPositive" checked="true"/><label for="cbEPositive">Formal +</label></td>
	<td class="nnc legend" ><input type="checkbox" id="cbENegative" checked="true"/><label for="cbENegative">Formal -</label></td>
	<td class="ooc legend" ><input type="checkbox" id="cbEObjective" checked="true"/><label for="cbEObjective">Formal Neutral</label></td>
	<td class="lb"><input type="checkbox" id="cbSentenceBoundary"/><label for="cbSentenceBoundary">Sentence Boundary</label></td>
</tr></table>
<div class="dstPaper">
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="E91-1038
The Semantics Of Collocational Patterns For Reporting Verbs
Bergler, Sabine;"></td>
	<td class="line x" title="1:121	The Semantics of Collocational Patterns for Reporting Verbs Sabine Bergler Computer Science Department Brandeis University Waltham, MA 02254 e-mail: sabine@chaos.cs.brandeis.edu Abstract One of the hardest problems for knowledge extraction from machine readable textual sources is distinguishing entities and events that are part of the main story from those that are part of the narrative structure, hnportantly, however, reported sl)eech in newspaper articles explicitly links these two levels." ></td>
	<td class="line x" title="2:121	In this paper, we illustrate what the lexical semantics of reporting verbs must incorporate in order to contribute to the reconstruction of story and context." ></td>
	<td class="line x" title="3:121	The lexical structures proposed are derived from the analysis of semantic collocations over large text corpora." ></td>
	<td class="line x" title="4:121	I Motivation We can distinguish two levels in newspaper articles: the pure information, here called primary informalion, and the meta-informati0n, which embeds the primary information within a perspective, a belief context, or a modality, which we call circumstan.tim information." ></td>
	<td class="line x" title="5:121	The distinction is not limited to, but is best illustrated by, reported speech sentences." ></td>
	<td class="line x" title="6:121	Here the matrix clause or reporting clause corresponds to the circumstantial:information, while the complement (whether realized as a full clause or as a noun phrase) corresponds t'o primary information." ></td>
	<td class="line x" title="7:121	For tasks such as knowledge extraction it is the primary information that is of interest." ></td>
	<td class="line x" title="8:121	For example in the text of Figure 1 the matrix clauses (italicized) give the circumstantial information of the who, when and how of the reporting event, while what is reported (the primary information) is givel~ in tile complements." ></td>
	<td class="line x" title="9:121	The particular reporting verb also adds important information about the manner of the original utterance, the preciseness of tile quote, the temporal relaI, iolJship between,uatrix clause and e(mq~h:me,l,, aml more." ></td>
	<td class="line x" title="10:121	In addition, the source of tile original information provides information about the reliability or credibility of the primary information." ></td>
	<td class="line x" title="11:121	Because the individual reporting verbs differ slightly but importantly in this respect, it is the lexicai semantics that must account for such knowledge." ></td>
	<td class="line x" title="12:121	US Advising Third Parties on Hostages (R1) The Bush administration continued to insist ~esterday that (CI) it is not involved in negotiations over the Western hostages in Lebanon, (R2) but acknowledged that (C2) US olliciais have provided advice to and have been kept informed by 'people at all levels' who are holding such talks." ></td>
	<td class="line x" title="13:121	(C3) 'There's a lot happening, and I don't want to be discouraging,' (R3) Marlin Fitzwalet, the president's spokesman, told reporters." ></td>
	<td class="line x" title="14:121	(R4) But Fitzwater stressed that (C4) he was not trying to fuel speculation about any impending release, (R5) and said (C5) there was 'no reason to believe' the situation had changed." ></td>
	<td class="line x" title="15:121	(All Nevertheless, it appears that it has Figure 1: Boston Globe, March 6, 1990 We describe here a characterization of influences which the reporting clause has on the interpretation of the reported clause without fully analyzing the reported clause." ></td>
	<td class="line x" title="16:121	This approach necessarily leaves many questions open, because the two clauses are so intimately linked that no one can be analyzed fully in isolation." ></td>
	<td class="line x" title="17:121	Our goal is, however, to show a minimal requirement on the lexical semantics of tile words involved, thereby enabling us to attempt a solution to the larger problems in text analysis." ></td>
	<td class="line x" title="18:121	The lexicai semantic framework we assume ill this paper is that of the Generative Lexicon introduced hy Pustejovsky \[Pustejovsky89\]." ></td>
	<td class="line x" title="19:121	This framework allows o. 216 us to represent explicitly even those semantic celloKeywords cations which have traditionally been assumed to be insist presupl)ositions and not part of the lexicon itself." ></td>
	<td class="line x" title="20:121	insist on II Semantic Collocations Reporting verbs carry a varying amount of information regarding time, manner, factivity, reliability etc. of the original utterance." ></td>
	<td class="line x" title="21:121	The most unmarked reporting verb is say." ></td>
	<td class="line x" title="22:121	The only presupposition for say is that there was an original utterance, the assumption being that this utterance is represented as closely as possible." ></td>
	<td class="line x" title="23:121	In this sense say is even less marked than re." ></td>
	<td class="line x" title="24:121	porl, which in addition specifies an a(Iressee (usually implicit from the context)." ></td>
	<td class="line x" title="25:121	The other members in the semantic fieM are set apart through their semantic collocations." ></td>
	<td class="line x" title="26:121	Let us consider in depth the case of insist." ></td>
	<td class="line x" title="27:121	One usage cart be found in the first part of the first sentence in Figure 1, repeated here as (1)." ></td>
	<td class="line x" title="28:121	1 The Bush administration continued to insist yesterday that it is not involved in negotiations over the Weslern hostages in Lebanon." ></td>
	<td class="line x" title="29:121	The lexical definition of insist in the Longman Dictionary of Contemporary English (LDOGE) \[Procter78\] is insist 1 to declare firmly (when opposed) and in the Merriam Webster Pocket Dictionary (MWDP) \[WooJrr4\]: insist to take a resolute stand: PER, SIST." ></td>
	<td class="line x" title="30:121	The opposition, mentioned explicitly in LDOCE but only hinted at in MWDP, is an important part of the meaning of insisl." ></td>
	<td class="line x" title="31:121	In a careful analysis of a 250,000 word text base of TIME magazine articles from 1963 (TIMEcorpus) \[Berglerg0a\] we confirmed that in every sentence containing insist some kind of opposition could be recovered and was supported by some other means (such as emphasis through word order etc.)." ></td>
	<td class="line x" title="32:121	Tire most common form of expressing the opposition was through negation, as in (1) above." ></td>
	<td class="line x" title="33:121	In an automatic analysis of the 7 million word corpus containing Wall Street Journal documents (WSJC) \[Berglerg0b\], we found the distribution of patterns of opposition reported in Figure 2." ></td>
	<td class="line x" title="34:121	This analysis shows that of 586 occurrences of insist throughout tim VVSJC, 10O were instances of the idiom insisted on which does not subcategorize for a clausal complement." ></td>
	<td class="line x" title="35:121	Ignoring I.hese occurrences for now, of the remaining 477 occurrences, 428 cooccur Oct 586 109 insist & but 117 insist & negation 186 insist & subjunctive 159 insist & but & net." ></td>
	<td class="line x" title="36:121	14 insist & but & on 12 insist & but & subj." ></td>
	<td class="line x" title="37:121	Comments occurrences throughout the corpus these have been cleaned by hand and are actually occurrences of the idiom insist on rather than accidental co-occurrences." ></td>
	<td class="line x" title="38:121	occurrences of both insist and but in the same sentence includes not and n'l includes would, could, should, and be Figure 2: Negative markers with insist in WSJC with such explicit markers of opposition as but (selecting for two clauses that stand in an opposition), not and n't, and subjunctive markers (indicating an opposition to factivity)." ></td>
	<td class="line x" title="39:121	While this is a rough analysis ;rod contains some 'noise', it supports the findings of our carefid study on the TIMEcorpus, namely the following: 2 A propositional opposition is implicit in the lexical semantics of insist." ></td>
	<td class="line x" title="40:121	This is where our proposal goes beyond traditional colloeational information, as for example recently argued for by Smadja and McKeown \[Smadja&McKeown90\]." ></td>
	<td class="line x" title="41:121	They argue for a flexible lexicon design that can accomodate both single word eutries and collocational patterns of different strength and rigidity." ></td>
	<td class="line x" title="42:121	But the collocations considered in their proposal are all based on word cooccurrences, not taking advantage of the even richer layer of semantic collocations made use of in this proposal." ></td>
	<td class="line p" title="43:121	Semantic collocations are harder to extract than cooccurrence patterns--the state of the art does not enable us to find semantic collocations automatically t. This paper however argues that if we take advantage of lexicai paradigmatic behavior underlying the lexicon, we can at least achieve semi-automatic extraction of semantic collocations (see also Calzolari and Bindi (1990) I But note the important work by Hindle \[HindlegO\] on extracting semantically similar nouns based on their substitutability in certain verb contexts." ></td>
	<td class="line o" title="44:121	We see his work as very similar in spirit." ></td>
	<td class="line x" title="45:121	2!7 and Pustejovsky and Anick (1990) for a description of tools for such a semi-automatic acquisition of semantic information from a large corpus)." ></td>
	<td class="line x" title="46:121	Using qualia structure as a means for structuring different semantic fields for a word \[Pustejovsky89\], we can summarize the discussion of tile lexical semantics of insist with a preliminary definition, making explicit tile underlying opposition to the,xssumed context (here denoted by ) and the fact that insist is a reporting verb." ></td>
	<td class="line x" title="47:121	3 (Preliminary Lexical l)elinition) insist(A,B) \[Form: Reporting Verb\] \[7'elic: utter(A,B) & :1: opposed(B#)\] \[Agentive: human(A)\] III Logical Metonymy in the previous section we argued that certain semantic collocations are part of the lexical semantics of a word." ></td>
	<td class="line x" title="48:121	In this section we will show that reporting verbs as a class allow logical metonymy \[Pustejovsky91\] \[l'ustejovsky&Anick88\]." ></td>
	<td class="line x" title="49:121	An example caLL be found in (1), where the metonymy is found in tile subject, NP." ></td>
	<td class="line x" title="50:121	The Bush administration is a compositional object of type administration, which is defined somewhat like (4)." ></td>
	<td class="line x" title="51:121	4 (Lexical l)elinition) administration \[Form: + plural part of: institution\] \[Telic: execute(x, orders(y)), where y is a high official in the specific institution\] \[Constitutive: + human executives, officials,\] \[Aoentive: appoint(y, x)\] In its formal role at least, i an administration does not fldfill the requirements for making an utterance-only in its constitutive role is there the attribute \[4_ human\], allowing for the metonymic use." ></td>
	<td class="line x" title="52:121	Although metonymy is a general device -in that it can appear in almost any context and make use of associations never considered before 2 -a closer 2As the well-known examl)h'." ></td>
	<td class="line x" title="53:121	The ham sandwich ordered another coke." ></td>
	<td class="line x" title="54:121	illustrates." ></td>
	<td class="line x" title="55:121	look at the data reveals, however, that metonymy as used in newspaper articles is much more restricted and systematic, corresponding very closely to logical metonymy \[Pustejovsky89\]." ></td>
	<td class="line x" title="56:121	Not all reporting verbs use the same kind of metonymy, however." ></td>
	<td class="line x" title="57:121	Different reporting verbs select for different semantic features in their source NPs." ></td>
	<td class="line x" title="58:121	More precisely, they seem to distinguish between a single person, a group of persons, and an institution." ></td>
	<td class="line x" title="59:121	We confirmed this preference on the TIMEcorpus, extracting automatically all tile sentences containing one of seven reporting verbs and analyzing these data by hand." ></td>
	<td class="line x" title="60:121	While the number of occurrences of each reportitLg verb was much too small to deduce tile verb's lexical sema,Ltics, they nevertheless exhibited interesting tendencies." ></td>
	<td class="line x" title="61:121	Figure 3 shows the distribution of the degree of animacy." ></td>
	<td class="line x" title="62:121	The numbers indicate percent of total occurrence of the verb, i.e. in 100 sentences that contain insist as a reporting verb, 57 have a single person as their source." ></td>
	<td class="line x" title="63:121	\]person I group I instil." ></td>
	<td class="line x" title="64:121	\[ other admit 64% 19% 14% 2% announce  51% 10% 31% 8% claim 35% 21% 38% 6% denied 55% 17% 17% 11% insist 57% 24% 16% 3% said 83% 6% 4% 8% told 69% 7% 8% 16% Figure 3: Degree of Animacy in Reporting Verbs The significance of the results in Figure 3 is that semantically related words have very similar distributions and that this distribution differs from the distribution of less related words." ></td>
	<td class="line x" title="65:121	Admit, denied and insist then fall ill one category that we call call here informally \[-inst\], said and told fan in \[+person\], and claim  and announce fall into a not yet clearly marked category \[other\]." ></td>
	<td class="line x" title="66:121	We are currently implementing statistical methods to perform similar analyses on WSJC." ></td>
	<td class="line x" title="67:121	We hope that the impreciseness of an automated analysis using statistical methods will be counterbalanced by very clear results." ></td>
	<td class="line x" title="68:121	The TIMEcorpus also exhibited a preference for one particular metonymy, which is of special interest for reporting verbs, namely where the name of a country, of a country's citizens, of a capital, or even of the building in which the government resides stands for the government itself." ></td>
	<td class="line x" title="69:121	Examples are Great Britain/ The British/London/ Buckingham Palace announced  Figure 4 shows the preference of the re218I)orting verbs for tiffs metonymy in subject position." ></td>
	<td class="line x" title="70:121	Again the numbers are too small to say anything about each lexical entry, but the difference in preference is strong enough to suggest it is not only due to the specific style of the magazine, but that some metonymies form strong collocations that should be reflected in the lexicon." ></td>
	<td class="line x" title="71:121	Such results ill addition provide interesting data for preference driven semantic analysis such as Wilks' \[Wilks75\]." ></td>
	<td class="line x" title="72:121	Figure for the verbs." ></td>
	<td class="line x" title="73:121	Verb admit allnounce claim denied insist said told percent of all occurrences 5% \]8% 25% 33% 9% 3% 0% 4: Country, countrymen, or capital standing government in subject l)osition of 7 reporting IV A Source NP Grammar The analysis of the subject NPs of all occurrences of tile 7 verbs listed ill Figure 3 displayed great regularity in tile TIMEcorpus." ></td>
	<td class="line x" title="74:121	Not only was the logical metonymy discussed in the previous section pervasive, but moreover a fairly rigid semanticgrammar for the source NPs emerged." ></td>
	<td class="line x" title="75:121	Two rules of this semantic grammar are listed in Figure 5." ></td>
	<td class="line x" title="76:121	source \[quant\] \[mod\] descriptor \[',' name ','\] J \[descriptor j((a J the) rood)\] \[mod\] name J \[inst's I name's\] descriptor \[name\] J name ',' \[a j the\] \[relation prep\] descriptor J name ',' \[a \] the\] name's (descriptor J relation) \] name ',' free relative clause descriptor, role I \[inst\] position I \[position (for I of)\] \[quant\] inst Figure 5: Two rules in a semantic grammar for source NPs The grammar exemplified in Figure 5 is partial -it only captures the regularities found in the TIMEcorpus." ></td>
	<td class="line x" title="77:121	Source NPs, like all NPs, can be adorned with modifiers, temporal adjuncts, appositions, and relative clauses of any shape." ></td>
	<td class="line x" title="78:121	Tile important observation is that these cases are very rare in thc corpus data and must be dealt with by general (i.e. syntactic) principles." ></td>
	<td class="line x" title="79:121	The value of a specialized semantic grammar for source NPs is that it provides a powerful interface between lexical semantics, syntax, and compositional semantics." ></td>
	<td class="line x" title="80:121	Our source NP grammar compiles differeat kinds of knowledge." ></td>
	<td class="line x" title="81:121	It spells out explicitly that logical metonymy is to be expected in the context of reportiog verbs." ></td>
	<td class="line x" title="82:121	Moreover, it restricts possible metonymies: the ham sandwich is not a typical source with reporting verbs." ></td>
	<td class="line x" title="83:121	The source gralnmar also gives a likely ordering of pertinent information as roughly COUNTRYILOCATION ALLEGIANCE INSTITUTION POSITION NAME." ></td>
	<td class="line x" title="84:121	This information defines esscntially the schema for the rei)resentation of the source in the knowledge exI.raction domain." ></td>
	<td class="line x" title="85:121	We are currently applying this grammar to the data i,a WSJC in order to see whether it is specific to the TIMEcorpus." ></td>
	<td class="line x" title="86:121	Preliminary results were encouraging: The adjustments needed so far consisted only of small enhancements such as adding locative PPs at the end of a descriptor." ></td>
	<td class="line x" title="87:121	V LCPs Lexical Conceptual Paradigms The data that lead to our source NP gratmnar was essentially collocational materiah We extracted tile sul)ject NPs for a set of verbs, analyzed the iexicalization of tile source and generalized the findings a. In this section we will justify why we think that tile results can properly be generalized and what impact this has on tile representation in the lexicon." ></td>
	<td class="line x" title="88:121	It has been noted that dictionary definitions form a -usually slmllow -hierarchy \[Amsler80\]." ></td>
	<td class="line x" title="89:121	Unfortunately explicitness is often traded in for conciseness in dictionaries, and conceptual hierarchies cannot be automatically extracted from dictionaries alone." ></td>
	<td class="line x" title="90:121	Yet for a computational lexicon, explicit dependencies in the form of lexicai inheritance are crucial \[Briscoe&al.90\] \[Pustejovsky&Boguraev91\]." ></td>
	<td class="line x" title="91:121	Following Anick and Pustejovsky (1990), we argue that lexical items having related, paradigmatic syntactic behavior enter into the same iezical conceptual paradigm." ></td>
	<td class="line x" title="92:121	Tiffs states that items within an LCP will have a set ofsyntactic realization patterns for how the 3A detailed report on the analysis can be found in \[BergleJX30a\] 219 word and its conceptual space (e.g. presuppositions) are realized in a text." ></td>
	<td class="line x" title="93:121	For example, reporting verbs form such a paradigm." ></td>
	<td class="line x" title="94:121	In fact the definition of an individual word often stresses the difl'erence between it and the closest synonym rather than giving a constructive (decompositioual) definition (see LDOCE)." ></td>
	<td class="line x" title="95:121	4 Given these assumptions, we will revise our definition of insist in (3)." ></td>
	<td class="line x" title="96:121	We introduce an I,CP (i.e. soma,Jtic type), REPOffFING VERB, which spells out the core semantics of reporting verbs." ></td>
	<td class="line x" title="97:121	It also makes explicit reference to the source NI ) grammar dist'ussed in Section IV as the default grammar for the subject NP (in active voicc)." ></td>
	<td class="line x" title="98:121	This general template allows us to define the individval lexical entry concisely in a form close to norn,al dictionary d,;li,fifions: deviations and enhancements,as well as restrictions of the general pattern are expressed for the i,,dividnal entry, making a COml)arison betweelt two entries focus on the differences in eqtailments." ></td>
	<td class="line x" title="99:121	5 (Definition of Semantic Type) REPORTING VERB \[Form: :IA,B,C,D: utter(A,B) & hear(C,B) & utter(C, utter(A,B)) & hear(D,utter(C, utter(A,B)))\] \[Constitutive: SU BJ ECT: type:SourceN P, COMPLEMENT \] \[Agent|re: AGENT(C), COAGENT(A)/ 6 (i,exical Definition) insist(A,B) \[Form: ItEI)ORTING VEI(B\] \[Tclic: 3: opposed(B,~b)\] \[Constitutive: MANNER: vehement\] \[Agent|re: \[-inst\]\] A related word, deny, might be defined as 7." ></td>
	<td class="line x" title="100:121	7 (Lexical Definition) deny(A,B) \[Form: REPORTING VERB\] \[T~tic: 3q,: negate(n,q,)\] \[Agentive: l-instil (6) and (7) differ in the quality of their opposition to the assumed proposition in the context, tb: insist only specifies an opposition, whereas deny actually negates that proposition." ></td>
	<td class="line x" title="101:121	The entries also reflect ~' ll'he notion of LCPs is of course related to the idea of aemanlic fields \[Trier31\]." ></td>
	<td class="line x" title="102:121	their common preference not to participate in the metonymy that allows insiitulions to appear in subjcct position." ></td>
	<td class="line x" title="103:121	Note t, hat opposed and negate are not assumed to be primitives but decompositions; these predicates are themselves decomposed further in the lexicon." ></td>
	<td class="line x" title="104:121	Insist (and other reporting verbs) 'inherit' much structural inforrnation from their semantic type, i.e, the LCP REPOR'I3NG VERB." ></td>
	<td class="line x" title="105:121	It is the semantic type that actual.ly provides the constructive definition, whereas the individual entries only dclinC refinements on the type." ></td>
	<td class="line x" title="106:121	This follows standard inheritance mechanisms for inheritance hierarchies \[Pustciovsky&Boguraev91\] \[Evans&Gazdar90\]." ></td>
	<td class="line x" title="107:121	Among other things the I,CI ) itEPOltTING VEiLB specilles our specialized semantic grammar for one of its constituents, namely the subject NP in nonpassive usage." ></td>
	<td class="line x" title="108:121	This not only enhances tile tools available to a parser in providing semantic constraints useful for constituent delimiting, but also provides an elegant:way to explicitly state which logical metonymies are common with a given class of words 5." ></td>
	<td class="line x" title="109:121	VI Summary Reported speech is an important phenomenon that cannot be ignored when analyzing newspaper articles." ></td>
	<td class="line x" title="110:121	We argue that the lexicai semantics of reportiug vcrbs plays all important part in extracting information from large on-iiine tcxt bases." ></td>
	<td class="line x" title="111:121	Based oil extensive studies of two corpora, the 250,000 word TlMEcorpus and the 7 million word Wall Street Journal Corpus we identified that semantic coilocalious must be represented ill the lexicon, expanding thus on current trends to indude syntactic collocations in a word based lexicon \[Smadj~d~M cKeown90\]." ></td>
	<td class="line x" title="112:121	We further discovered that logical metonymy is pervasive in subject position of reporting verbs, but that reporting verbs differ with respect to their preference for different kinds of logical metonymy." ></td>
	<td class="line x" title="113:121	A careful analysis of seven reporting verbs in the TIMEcorpus suggested that there are three features that divide the reporting verbs into classes according to the preference for metonymy in subject position, namely whether the subject NP refers to the source as a single person, a group of people, or an institution." ></td>
	<td class="line x" title="114:121	The analysis of the source NPs of seven reporting verbs further allowed us to formulate a specialized seSGrimshaw \[Grimshaw79\] argues that verbs also select for their complements on a semantic basis." ></td>
	<td class="line x" title="115:121	\[;'or the sake of coneiscncss tim whole issue of the form of the complement and its semantic connection has to be omitted here." ></td>
	<td class="line x" title="116:121	220 mantic grammar for source NPs, which constitutes an important interface between lexical semantics, syntax, and compositional semantics used by an application program." ></td>
	<td class="line x" title="117:121	We are currently testing the completeness of this grammar on a different corpus and are planning to implement a noun phrase parser." ></td>
	<td class="line x" title="118:121	We have imbedded the findings in the framework of Pustejovsky's Generative Lexicon and qualia theory \[Pustejovsky89\] \[Pustejovsky91\]." ></td>
	<td class="line x" title="119:121	This rich knowi' edge representation scheme allows us to represent explicitly the underlying structure of the lexicon, ineluding the clustering of entries into semant.ic types (i.e. I,CPs) with inheritance and the representation of information which wa.s previously considered presuppositional and not part of the lexicai entry itself." ></td>
	<td class="line x" title="120:121	In this process we observed that the analysis of semantic collocations can serve as a measure of semantic closeness of words." ></td>
	<td class="line x" title="121:121	Acknowledgements: I would like to thank I.ily advisor, James Pustejovsky, for inspiring discussions and irlany critical readings." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P91-1017
Two Languages Are More Informative Than One
Dagan, Ido;Itai, Alon;Schwall, Ulrike;"></td>
	<td class="line x" title="1:208	Two Languages Are More Informative Than One * Ido Dagan Computer Science Department Technion, Haifa, Israel and IBM Scientific Center Haifa, Israel dagan@cs.technion.ac.il Alon Itai Computer Science Department Technion, Haifa, Israel itai~cs.technion.ac.il Ulrike Schwall IBM Scientific Center Institute for Knowledge Based Systems Heidelberg, Germany schwall@dhdibml Abstract This paper presents a new approach for resolving lexical ambiguities in one language using statistical data on lexical relations in another language." ></td>
	<td class="line x" title="2:208	This approach exploits the differences between mappings of words to senses in different languages." ></td>
	<td class="line x" title="3:208	We concentrate on the problem of target word selection in machine translation, for which the approach is directly applicable, and employ a statistical model for the selection mechanism." ></td>
	<td class="line x" title="4:208	The model was evaluated using two sets of Hebrew and German examples and was found to be very useful for disambiguation." ></td>
	<td class="line x" title="5:208	1 Introduction The resolution of hxical ambiguities in non-restricted text is one of the most difficult tasks of natural language processing." ></td>
	<td class="line x" title="6:208	A related task in machine translation is target word selection the task of deciding which target language word is the most appropriate equivalent of a source language word in context." ></td>
	<td class="line x" title="7:208	In addition to the alternatives introduced from the different word senses of the source language word, the target language may specify additional alternatives that differ mainly in their usages." ></td>
	<td class="line x" title="8:208	Traditionally various linguistic levels were used to deal with this problem: syntactic, semantic and pragmatic." ></td>
	<td class="line x" title="9:208	Computationally the syntactic methods are the easiest, but are of no avail in the frequent situation when the different senses of the word show *This research was partially supported by grant number 120-741 of the Iarael Council for Research and Development the same syntactic behavior, having the same part of speech and even the same subcategorization frame." ></td>
	<td class="line x" title="10:208	Substantial application of semantic or pragmatic knowledge about the word and its context for broad domains requires compiling huge amounts of knowledge, whose usefulness for practical applications has not yet been proven (Lenat et al. , 1990; Nirenburg et al. , 1988; Chodorow et al. , 1985)." ></td>
	<td class="line x" title="11:208	Moreover, such methods fail to reflect word usages." ></td>
	<td class="line x" title="12:208	It is known for many years that the use of a word in the language provides information about its meaning (Wittgenstein, 1953)." ></td>
	<td class="line x" title="13:208	Also, statistical approaches which were popular few decades ago have recently reawakened and were found useful for computational linguistics." ></td>
	<td class="line x" title="14:208	Consequently, a possible (though partial) alternative to using manually constructed knowledge can be found in the use of statistical data on the occurrence of lexical relations in large corpora." ></td>
	<td class="line oc" title="15:208	The use of such relations (mainly relations between verbs or nouns and their arguments and modifiers) for various purposes has received growing attention in recent research (Church and Hanks, 1990; Zernik and Jacobs, 1990; Hindle, 1990)." ></td>
	<td class="line oc" title="16:208	More specifically, two recent works have suggested to use statistical data on lexical relations for resolving ambiguity cases of PP-attachment (Hindle and Rooth, 1990) and pronoun references (Dagan and Itai, 1990a; Dagan and Itai, 1990b)." ></td>
	<td class="line x" title="17:208	Clearly, statistical methods can be useful also for target word selection." ></td>
	<td class="line x" title="18:208	Consider, for example, the Hebrew sentence extracted from the foreign news section of the daily Haaretz, September 1990 (transcripted to Latin letters)." ></td>
	<td class="line x" title="19:208	130 (1) Nose ze maria' mi-shtei ha-mdinot mi-lahtom 'al hoze shalom." ></td>
	<td class="line x" title="20:208	This sentence would translate into English as: (2) That issue prevented the two countries from signing a peace treaty." ></td>
	<td class="line x" title="21:208	The verb 'lab_tom' has four word senses: 'sign', 'seal', 'finish' and 'close'." ></td>
	<td class="line x" title="22:208	Whereas the noun 'hose' means both 'contract' and 'treaty'." ></td>
	<td class="line x" title="23:208	Here the difference is not in the meaning, but in usage." ></td>
	<td class="line x" title="24:208	One possible solution is to consult a Hebrew corpus tagged with word senses, from which we would probably learn that the sense 'sign' of 'lahtom' appears more frequently with 'hoze' as its object than all the other senses." ></td>
	<td class="line x" title="25:208	Thus we should prefer that sense." ></td>
	<td class="line x" title="26:208	However, the size of corpora required to identify lexical relations in a broad domain is huge (tens of millions of words) and therefore it is usually not feasible to have such corpora manually tagged with word senses." ></td>
	<td class="line x" title="27:208	The problem of choosing between 'treaty' and 'contract' cannot be solved using only information on Hebrew, because Hebrew does not distinguish between them." ></td>
	<td class="line x" title="28:208	The solution suggested in this paper is to identify the lexical relationships in corpora of the target language, instead of the source language." ></td>
	<td class="line x" title="29:208	Consulting English corpora of 150 million words, yields the following statistics on single word frequencies: 'sign' appeared 28674 times, 'seal' 2771 times, 'finish' appeared 15595 times, 'close' 38291 times, 'treaty' 7331 times and 'contract' 30757 times." ></td>
	<td class="line x" title="30:208	Using a naive approach of choosing the most frequent word yields (3) *That issue prevented the two countries from closing a peace contract." ></td>
	<td class="line x" title="31:208	This may be improved upon if we use lexical relations." ></td>
	<td class="line x" title="32:208	We consider word combinations and count how often they appeared in the same syntactic relation as in the ambiguous sentence." ></td>
	<td class="line x" title="33:208	For the above example, among the successfully parsed sentences of the corpus, the noun compound 'peace treaty' appeared 49 times, whereas the compound 'peace contract' did not appear at all; 'to sign a treaty' appeared 79 times while none of the other three alternatives appeared more than twice." ></td>
	<td class="line x" title="34:208	Thus we first prefer 'treaty' to 'contract' because of the noun compound 'peace treaty' and then proceed to prefer 'sign' since it appears most frequently having the object 'treaty' (the order of selection is explained in section 3)." ></td>
	<td class="line x" title="35:208	Thus in this case our method yielded the correct translation." ></td>
	<td class="line x" title="36:208	Using this method, we take the point of view that some ambiguity problems are easier to solve at the level of the target language instead of the source language." ></td>
	<td class="line x" title="37:208	The source language sentences are considered as a noisy source for target language sentences, and our task is to devise a target language model that prefers the most reasonable translation." ></td>
	<td class="line x" title="38:208	Machine translation (MT) is thus viewed in part as a recognition problem, and the statistical model we use specifically for target word selection may be compared with other language models in recognition tasks (e.g. Katz (1985) for speech recognition)." ></td>
	<td class="line x" title="39:208	In contrast to this view, previous approaches in MT typically resolved examples like (1) by stating various constraints in terms of the source language (Nirenburg, 1987)." ></td>
	<td class="line x" title="40:208	As explained before, such constraints cannot be acquired automatically and therefore are usually limited in their coverage." ></td>
	<td class="line x" title="41:208	The experiment conducted to test the statistical model clearly shows that the statistics on lexical relations are very useful for disambiguation." ></td>
	<td class="line x" title="42:208	Most notable is the result for the set of examples for Hebrew to English translation, which was picked randomly from foreign news sections in Israeli press." ></td>
	<td class="line x" title="43:208	For this set, the statistical model was applicable for 70% of the ambiguous words, and its selection was then correct for 92% of the cases." ></td>
	<td class="line x" title="44:208	These results for target word selection in machine translation suggest to use a similar mechanism even if we are interested only in word sense disambiguation within a single language!" ></td>
	<td class="line x" title="45:208	In order to select the right sense of a word, in a broad coverage application, it is useful to identify lexical relations between word senses." ></td>
	<td class="line x" title="46:208	However, within corpora of a single language it is possible to identify automatically only relations at the word level, which are of course not useful for selecting word senses in that language." ></td>
	<td class="line x" title="47:208	This is where other languages can supply the solution, exploiting the fact that the mapping between words and word senses varies significantly among different languages." ></td>
	<td class="line x" title="48:208	For instance, the English words 'sign' and 'seal' correspond to a very large extent to two distinct senses of the Hebrew word 'lab_tom' (from example (1))." ></td>
	<td class="line x" title="49:208	These senses should be distinguished by most applications of Hebrew understanding programs." ></td>
	<td class="line x" title="50:208	To make this distinction, it is possible to do the same process that is performed for target word selection, by producing all the English alternatives for the lexical relations involving 'lahtom'." ></td>
	<td class="line x" title="51:208	Then the Hebrew sense which corresponds to the most plausible English lexical relations is preferred." ></td>
	<td class="line x" title="52:208	This process requires a bilingual lexicon which maps each Hebrew sense separately into its possible translations, similar 131 to a Hebrew-Hebrew-English lexicon (like the Oxford English-English-Hebrew dictionary (Hornby et al. , 1980))." ></td>
	<td class="line x" title="53:208	In some cases, different senses of a Hebrew word map to the same word also in English." ></td>
	<td class="line x" title="54:208	In these cases, the lexical relations of each sense cannot be identified in an English corpus, and a third language is required to distinguish among these senses." ></td>
	<td class="line x" title="55:208	As a long term vision, one can imagine a multilingual corpora based system, which exploits the differences between languages to automatically acquire knowledge about word senses." ></td>
	<td class="line x" title="56:208	As explained above, this knowledge would be crucial for lexical disambiguation, and will also help to refine other types of knowledge acquired from large corpora 1." ></td>
	<td class="line x" title="57:208	2 The Linguistic Model The ambiguity of a word is determined by the number of distinct, non-equivalent representations into which the word can be mapped (Van Eynde et al. , 1982)." ></td>
	<td class="line x" title="58:208	In the case of machine translation the ambiguity of a source word is thus given by the number of target representations for that word in the bilingual lexicon of the translation system." ></td>
	<td class="line x" title="59:208	Given a specific syntactic context the ambiguity can be reduced to the number of alternatives which may appear in that context." ></td>
	<td class="line x" title="60:208	For instance, if a certain translation of a verb corresponds to an intransitive occurrence of that verb, then this possibility is eliminated when the verb occurs with a direct object." ></td>
	<td class="line x" title="61:208	In this work we are interested only in those ambiguities that are left after applying all the deterministic syntactic constraints." ></td>
	<td class="line x" title="62:208	For example, consider the following Hebrew sentence, taken from the daily Haaretz, September 1990: (4) Diplomatim svurim ki hitztarrfuto shell Hon Sun magdila et ha.sikkuyim l-hassagat hitqaddmut ba-sihot." ></td>
	<td class="line x" title="63:208	Here, the ambiguous words in translation to English are 'magdila', 'hitqaddmut' and 'sih_ot'." ></td>
	<td class="line x" title="64:208	To facilitate the reading, we give the translation of the sentence to English, and in each case of an ambiguous selection all the alternatives are listed within curly brackets, the first alternative being the correct one." ></td>
	<td class="line x" title="65:208	1For inatanoe, Hindie (1990) indicates the need to distlnguhsh among aeaases of polysemic words for his statistical c\]~Hic~tlon method." ></td>
	<td class="line x" title="66:208	132 (5) Diplomats believe that the joining of Hon Sun { increases I enlarges I magnifies } the chances for achieving { progress \[ advance I advancement } in the { talks I conversations I calls }." ></td>
	<td class="line x" title="67:208	We use the term a lezical relation to denote the cooccurrence relation of two (or possibly more) specific words in a sentence, having a certain syntactic relationship between them." ></td>
	<td class="line x" title="68:208	Typical relations are between verbs and their subjects, objects, complements, adverbs and modifying prepositional phrases." ></td>
	<td class="line x" title="69:208	Similarly, nouns are related also with their objects, with their modifying nouns in compounds and with their modifying adjectives and prepositional phrases." ></td>
	<td class="line x" title="70:208	The relational representation of a sentence is simply the list of all lexical relations that occur in the sentence." ></td>
	<td class="line x" title="71:208	For our purpose, the relational representation contains only those relations that involve at least one ambiguous word." ></td>
	<td class="line x" title="72:208	The relational representation for example (4) is given in (6) (for readability we represent the Hebrew word by its English equivalent, prefixed by 'H' to denote the fact that it is a Hebrew word): (6) a." ></td>
	<td class="line x" title="73:208	(subj-verb: H-joining H-increase) b." ></td>
	<td class="line x" title="74:208	(verb-obj: H-increase H-chance) c." ></td>
	<td class="line x" title="75:208	(verb-obj: H-achieve H-progress) d." ></td>
	<td class="line x" title="76:208	(noun-pp: H-progress H-in H-talks) The relational representation of a source sentence is reflected also in its translation to a target sentence." ></td>
	<td class="line x" title="77:208	In some cases the relational representation of the target sentence is completely equivalent to that of the source sentence, and can be achieved just by substituting the source words with target words." ></td>
	<td class="line x" title="78:208	In other cases, the mapping between source and target relations is more complicated, as is the case for the following German example: (7) Der Tisch gefaellt mir." ></td>
	<td class="line x" title="79:208	-I like the table." ></td>
	<td class="line x" title="80:208	Here, the original subject of the source sentence becomes the object in the target sentence." ></td>
	<td class="line x" title="81:208	This kind of mapping usually influences the translation process and is therefore encoded in components of the translation program, either explicitly or implicitly, especially in transfer based systems." ></td>
	<td class="line x" title="82:208	Our model assumes that such a mapping of source language relations to target language relations is possible, an assumption that is valid for many practical cases." ></td>
	<td class="line x" title="83:208	When applying the mapping of relations on one lexicai relation of the source sentence we get several alternatives for a target relation." ></td>
	<td class="line x" title="84:208	For instance, applying the mapping to example (6-c) we get three alternatives for the relation in the target sentence: (8) (verb-obj: achieve progress) (verb-obj: achieve advance) (verb-obj: achieve advancement) For example (6-d) we get 9 alternatives, since both 'H-progress' and 'H-talks' have three alternative translations." ></td>
	<td class="line x" title="85:208	In order to decide which alternative is the most probable, we count the frequencies of all the alternative target relations in very large corpora." ></td>
	<td class="line x" title="86:208	For example (8) we got the counts 20, 5 and 1 respectively." ></td>
	<td class="line x" title="87:208	Similarly, the target relation 'to increase chance' was counted 20 times, while the other alternatives were not observed at all." ></td>
	<td class="line x" title="88:208	These counts are given as input to the statistical model described in the next section, which performs the actual target word selection." ></td>
	<td class="line x" title="89:208	3 The Statistical Model Our selection algorithm is based on the following statistical model." ></td>
	<td class="line x" title="90:208	Consider first a single relation." ></td>
	<td class="line x" title="91:208	The linguistic model provides us with several alternatives as in example (8)." ></td>
	<td class="line x" title="92:208	We assume that each alternative has a theoretical probability Pi to be appropriate for this case." ></td>
	<td class="line x" title="93:208	We wish to select the alternative for which Pi is maximal, provided that it is significantly larger than the others." ></td>
	<td class="line x" title="94:208	We have decided to measure this significance by the odds ratio of the two most probable alternatives P = Pl/P2." ></td>
	<td class="line x" title="95:208	However, we do not know the theoretical probabilities, therefore we get a bound for p using the frequencies of the alternatives in the corpus." ></td>
	<td class="line x" title="96:208	Let/3 i be the probabilities as observed in the corpus (101 = ni/n, where ni is the number of times that alternative i appeared in the corpus and n is the total number of times that all the alternatives for the relation appeared in the corpus)." ></td>
	<td class="line x" title="97:208	For mathematical convenience we bound In p instead of p. Assuming that samples of the alternative relations are distributed normally, we get the following bound with confidence 1 a: where Z is the eonfidenee coefficient." ></td>
	<td class="line x" title="98:208	We approximate the variance by the delta method (e.g. Johnson and Wichern (1982)): =,n _ 1 p~(1 p~) -) 1 p~(1 p~) + 2 P*P~ p~ n p~ n npxI~ 1 1 1 1 1 1 = + ~, + =~+~." ></td>
	<td class="line x" title="99:208	npa nI~ n~x n~ nl n2 Therefore we get that with probability at least 1--or, In _> In Zl-a + We denote the right hand side (the bound) by B~,(nl, n2)." ></td>
	<td class="line x" title="100:208	In sentences with several relations, we consider the best two alternatives for each relation, and take the relation for which B,, is largest." ></td>
	<td class="line x" title="101:208	If this Ba is less than a specified threshold then we do not choose between the alternatives." ></td>
	<td class="line x" title="102:208	Otherwise, we choose the most frequent alternative to this relation and select the target words appearing in this alternative." ></td>
	<td class="line x" title="103:208	We then eliminate all the other alternative translations for the selected words, and accordingly eliminate all the alternatives for the remaining relations which involve these translations." ></td>
	<td class="line x" title="104:208	In addition we update the observed probabilities for the remaining relations, and consequently the remaining Ba's." ></td>
	<td class="line x" title="105:208	This procedure is repeated until all target words have been determined or the maximal Ba is below the threshold." ></td>
	<td class="line x" title="106:208	The actual parameters we have used so far were c~ = 0.05 and the bound for Bawas -0.5." ></td>
	<td class="line x" title="107:208	To illustrate the selection algorithm, we give the details for example (6)." ></td>
	<td class="line x" title="108:208	The highest bound for the odds ratio (Ba = 1.36) was received for the relation 'increase-chance', thus selecting the translation 'increase' for 'H-increase'." ></td>
	<td class="line x" title="109:208	The second was Ba = 0.96, 133 for 'achieve-progress'." ></td>
	<td class="line x" title="110:208	This selected the translations 'achieve' and 'progress', while eliminating the other senses of 'H-progress' in the remaining relations." ></td>
	<td class="line x" title="111:208	Then, for the relation 'progress-in-talks' we got Ba = 0.3, thus selecting the appropriate translation for 'H-talks'." ></td>
	<td class="line x" title="112:208	4 The Experiment An experiment was conducted to test the performance of the statistical model in translation from Hebrew and German to English." ></td>
	<td class="line x" title="113:208	Two sets of paragraphs were extracted randomly from current Hebrew and German press." ></td>
	<td class="line x" title="114:208	The Hebrew set contained 10 paragraphs taken from foreign news sections, while the German set contained 12 paragraphs of text not restricted to a specific topic." ></td>
	<td class="line x" title="115:208	Within these paragraphs we have (manually) identified the target word selection ambiguities, using a bilingual dictionary." ></td>
	<td class="line x" title="116:208	Some of the alternative translations in the dictionary were omitted if it was judged that they will not be considered by an actual component of a machine translation program." ></td>
	<td class="line x" title="117:208	These cases included very rare or archaic translations (that would not be contained in an MT lexicon) and alternatives that could be eliminated using syntactic knowledge (as explained in section 2) 2 . For each of the remaining alternatives, it was judged if it can serve as an acceptable translation in the given context." ></td>
	<td class="line x" title="118:208	This a priori judgment was used later to decide whether the selection of the automatic procedure is correct." ></td>
	<td class="line x" title="119:208	As a result of this process, the Hebrew set contained 105 ambiguous words (which had at least one unacceptable translation) and the German set 54 ambiguous words." ></td>
	<td class="line x" title="120:208	Now it was necessary to identify the lexical relations within each of the sentences." ></td>
	<td class="line x" title="121:208	As explained before, this should be done using a source language parser, and then mapping the source relations to the target relations." ></td>
	<td class="line x" title="122:208	At this stage of the research, we still do not have the necessary resources to perform the entire process automatically s, therefore we have approximated it by translating the sentences into English and extracting the lexical relations using the English Slot Grammar (ESG) parser (mc2Due to some technicalities, we have also restricted the experiment to cases in which all the relevant translations of a word consists exactly one English word, which is the most frequent situaticm." ></td>
	<td class="line x" title="123:208	awe are currently integrating this process within GSG (German Slot Gr~nmm') and LMT-GE (the Germs~a to English MT prototype)." ></td>
	<td class="line x" title="124:208	Cord, 1989) 4." ></td>
	<td class="line x" title="125:208	Using this parser we have classified the lexical relations to rather general classes of syntactic relations, based on the slot structure of ESG." ></td>
	<td class="line x" title="126:208	The important syntactic relations used were between a verb and its arguments and modifiers (counting as one class all objects, indirect objects, complements and nouns in modifying prepositional phrases) and between a noun and its arguments and modifiers (counting as one class all noun objects, modifying nouns in compounds and nouns in modifying prepositional phrases)." ></td>
	<td class="line x" title="127:208	The success of using this general level of syntactic relations indicates that even a rough mapping of source to target language relations would be useful for the statistical model." ></td>
	<td class="line x" title="128:208	The statistics for the alternative English relations in each sentence were extracted from three corpora: The Washington Post articles (about 40 million words), Associated Press news wire (24 million) and the Hansard corpus of the proceedings of the Canadian Parliament (85 million words)." ></td>
	<td class="line x" title="129:208	The statistics were extracted only from sentences of up to 25 words (to facilitate parsing) which contained altogether about 55 million words." ></td>
	<td class="line x" title="130:208	The lexical relations in the corpora were extracted by ESG, in the same way they were extracted for the English version of the example sentences (see Dagan and Itai (1990a) for a discussion on using an automatic parser for extracting lexical relations from a corpus, and for the technique of acquiring the statistics)." ></td>
	<td class="line x" title="131:208	The parser failed to produce any parse for about 35% of the sentences, which further reduced the actual size of the corpora which was used." ></td>
	<td class="line x" title="132:208	5 Evaluation Two measurements, applicability and precision, are used to evaluate the performance of the statistical model." ></td>
	<td class="line x" title="133:208	The applicability denotes the proportion of cases for which the model performed a selection, i.e. those cases for which the bound Bapassed the threshold." ></td>
	<td class="line x" title="134:208	The precision denotes the proportion of cases for which the model performed a correct selection out of all the applicable cases." ></td>
	<td class="line x" title="135:208	We compare the precision of the model to that of the 'word frequencies' procedure, which always selects the most frequent target word." ></td>
	<td class="line x" title="136:208	This naive 'straw-man' is less sophisticated than other methods suggested in the literature but it is useful as a common benchmark (e.g. Sadler (1989)) since it can 4The parsing process was controlled manually to make sure that we do not get wrong relational representation of the exo amp\]es due to parsing errors." ></td>
	<td class="line x" title="137:208	134 be easily implemented." ></td>
	<td class="line x" title="138:208	The success rate of the 'word frequencies' procedure can serve as a measure for the degree of lexical ambiguity in a given set of examples, and thus different methods can be partly compared by their degree of success relative to this procedure." ></td>
	<td class="line x" title="139:208	Out of the 105 ambiguous Hebrew words, for 32 the bound Badid not pass the threshold (applicability of 70%)." ></td>
	<td class="line x" title="140:208	The remaining 73 examples were distributed according to the following table: \[ Hebrew-Engiish \]\] Word Frequencies correct I incorrect I Relations Statistics \[ correct Thus the precision of the statistical model was 92% (67/73) 5 while relying just on word frequencies yields 64% (47/73)." ></td>
	<td class="line x" title="141:208	Out of the 54 ambiguous German words, for 22 the bound Badid not pass the threshold (applicability of 59%)." ></td>
	<td class="line x" title="142:208	The remaining 32 examples were distributed according to the following table: Oerm English II Word equeoci I,, correct \] incorrect Relations Statistics \[ correct 8 inrre ' \[\[ I 0 I Thus the precision of the statistical model was 75% (24/32), while relying just on word frequencies yields 53% (18/32)." ></td>
	<td class="line x" title="143:208	We attribute the lower success rate for the German examples to the fact that they were not restricted to topics that are well represented in the corpus." ></td>
	<td class="line x" title="144:208	Statistical analysis for the larger set of Hebrew examples shows that with 95% confidence our method succeeds in at least 86% of the applicable examples (using the parameters of the distribution of proportions)." ></td>
	<td class="line x" title="145:208	With the same confidence, our method improves the word frequency method by at least 18% (using confidence interval for the difference of proportions in multinomial distribution, where the four cells of the multinomial correspond to the four entries in the result table)." ></td>
	<td class="line x" title="146:208	In the examples that were treated correctly by our 5An a posteriorl observation showed that in three of the six errors the selection of the model was actually acceptable, and the a priori judgment of the hnman translator was too severe." ></td>
	<td class="line x" title="147:208	For example, in one of these cases the statistics selected the expression 'to begin talks' while the human translator regarded this expression as incorrect and selected 'to start talks'." ></td>
	<td class="line x" title="148:208	If we consider these cases as correct then there are only three selection errors, getting a 96% precision." ></td>
	<td class="line x" title="149:208	method, such as the examples in the previous sections, the statistics succeeded to capture two major types of disambiguating data." ></td>
	<td class="line x" title="150:208	In preferring 'signtreaty' upon 'seal-treaty', the statistics reflect the relevant semantic constraint." ></td>
	<td class="line x" title="151:208	In preferring 'peacetreaty' upon 'peace-contract', the statistics reflect the hxical usage of 'treaty' in English which differs from the usage of 'h_oze' in Hebrew." ></td>
	<td class="line x" title="152:208	6 Failures and Possible Improvements A detailed analysis of the failures of the method is most important, as it both suggests possible improvements for the model and indicates its limitations." ></td>
	<td class="line x" title="153:208	As described above, these failures include either the cases for which the method was not applicable (no selection) or the cases in which it made an incorrect selection." ></td>
	<td class="line x" title="154:208	The following paragraphs list the various reasons for both types." ></td>
	<td class="line x" title="155:208	6.1 Inapplicability Insufficient data." ></td>
	<td class="line x" title="156:208	This was the reason for nearly all the cases of inapplicability." ></td>
	<td class="line x" title="157:208	For instance, none of the alternative relations 'an investigator of corruption' (the correct one) or 'researcher of corruption' (the incorrect one) was observed in the parsed corpus." ></td>
	<td class="line x" title="158:208	In this case it is possible to perform the correct selection if we used only statistics about the cooccurrences of 'corruption' with either 'investigator' or 'researcher', without looking for any syntactic relation (as in Church and Hanks (1990))." ></td>
	<td class="line x" title="159:208	The use of this statistic is a subject for further research, but our initial data suggests that it can substantially increase the applicability of the statistical method with just a little decrease in its precision." ></td>
	<td class="line x" title="160:208	Another way to deal with the lack of statistical data for the specific words in question is to use statistics about similar words." ></td>
	<td class="line x" title="161:208	This is the basis for Sadler's Analogical Semantics (1989) which has not yet proved effective." ></td>
	<td class="line pc" title="162:208	His results may be improved if more sophisticated techniques and larger corpora are used to establish similarity between words (such as in (Hindle, 1990))." ></td>
	<td class="line x" title="163:208	Conflicting data." ></td>
	<td class="line x" title="164:208	In very few cases two alternatives were supported equally by the statistical data, thus preventing a selection." ></td>
	<td class="line x" title="165:208	In such cases, both alternatives are valid at the independent level of the lexical relation, but may be inappropriate for the specific context." ></td>
	<td class="line x" title="166:208	For instance, the two alternatives of 'to take 135 a job' or 'to take a position' appeared in one of the examples, but since the general context concerned with the position of a prime minister only the latter was appropriate." ></td>
	<td class="line x" title="167:208	In order to resolve such examples it may be useful to consider also cooccurrences of the ambiguous word with other words in the broader context." ></td>
	<td class="line x" title="168:208	For instance, the word 'minister' seems to cooccur in the same context more frequently with 'position' than with 'job'." ></td>
	<td class="line x" title="169:208	In another example both alternatives were appropriate also for the specific context." ></td>
	<td class="line x" title="170:208	This happened with the German verb 'werfen', which may be translated (among other options) as 'throw', 'cast' or 'score'." ></td>
	<td class="line x" title="171:208	In our example 'werfen' appeared in the context of 'to throw/cast light' and these two correct alternatives had equal frequencies in the corpus ('score' was successfully eliminated)." ></td>
	<td class="line x" title="172:208	In such situations any selection between the alternatives will be appropriate and therefore any algorithm that handles conflicting data will work properly." ></td>
	<td class="line x" title="173:208	6.2 Incorrect Selection Using the inappropriate relation." ></td>
	<td class="line x" title="174:208	One of the examples contained the Hebrew word 'matzav', which two of its possible translations are 'state' and 'position'." ></td>
	<td class="line x" title="175:208	The phrase which contained this word was: 'to put an end to the {state I position} of war  '." ></td>
	<td class="line x" title="176:208	The ambiguous word is involved in two syntactic relations, being a complement of 'put' and also modified by 'war'." ></td>
	<td class="line x" title="177:208	The corresponding frequencies were: (9) verb-comp: put-position 320 verb-comp: put-state 18 noun-nob j: state-war 13 noun-nob j: position-war 2 The bound of the odds ration (Ba) for the first relation was higher than for the second, and therefore this relation determined the translation as 'position'." ></td>
	<td class="line x" title="178:208	However, the correct translation should be 'state', as determined by the second relation." ></td>
	<td class="line x" title="179:208	This example suggests that while ordering the involved relations (or using any other weighting mechanism) it may be necessary to give different weights to the different types of syntactic relations." ></td>
	<td class="line x" title="180:208	For instance, it seems reasonable that the object of a noun should receive greater weight in selecting the noun's sense than the verb for which this noun serves as a complement." ></td>
	<td class="line x" title="181:208	Confusing senses." ></td>
	<td class="line x" title="182:208	In another example, the Hebrew word 'qatann', which two of its meanings are 'small' and 'young', modified the word 'sikkuy', which means 'prospect' or 'chance'." ></td>
	<td class="line x" title="183:208	In this context, the correct sense is necessarily 'small'." ></td>
	<td class="line x" title="184:208	However, the relation that was observed in the corpus was 'young prospect', relating to the human sense of 'prospect' which appeared in sport articles (a promising young person)." ></td>
	<td class="line x" title="185:208	This borrowed sense of 'prospect' is necessarily inappropriate, since in Hebrew it is represented by the equivalent of 'hope' ('tiqva'), and not by 'sikkuy'." ></td>
	<td class="line x" title="186:208	The reason for this problem is that after producing the possible target alternatives, our model ignores the source language input as it uses only a monolingual target corpus." ></td>
	<td class="line x" title="187:208	This can be solved if we use an aligned bilingual corpus, as suggested by Sadler (1989) and Brown et al.(1990)." ></td>
	<td class="line x" title="189:208	In such a corpus the occurrences of the relation 'young prospect' will be aligned to the corresponding occurrences of the Hebrew word 'tiqva', and will not be used when the Hebrew word 'sikkuy' is involved." ></td>
	<td class="line x" title="190:208	Yet, it should be brought in mind that an aligned corpus is the result of manual translation, which can be viewed as a manual tagging of the words with their equivalent senses in the other language." ></td>
	<td class="line x" title="191:208	This resource is much more expensive and less available than the untagged monolingual corpus, while it seems to be necessary only for relatively rare situations." ></td>
	<td class="line x" title="192:208	Lack of deep understanding." ></td>
	<td class="line x" title="193:208	By their nature, statistical methods rely on large quantities of shallow information." ></td>
	<td class="line x" title="194:208	Thus, they are doomed to fail when disambiguation can rely only on deep understanding of the text and no other surface cues are available." ></td>
	<td class="line x" title="195:208	This happened in one of the Hebrew examples, where the two alternatives were either 'emigration law' or 'immigration law' (the Hebrew word 'hagira' is used for both subsenses)." ></td>
	<td class="line x" title="196:208	While the context indicated that the first alternative is correct, the statistics preferred the second alternative." ></td>
	<td class="line x" title="197:208	It seems that such cases are quiet rare, but only further evaluation will show the extent to which deep understanding is really needed." ></td>
	<td class="line x" title="198:208	7 Conclusions The method presented takes advantage of two linguistic phenomena: the different usage of words and word senses among different languages and the importance of lexical cooccurrences within syntactic relations." ></td>
	<td class="line x" title="199:208	The experiment shows that these phenomena are indeed useful for practical disambiguation." ></td>
	<td class="line x" title="200:208	We suggest that the high precision received in the experiment relies on two characteristics of the am136 biguity phenomena, namely the sparseness and redundancy of the disambiguating data." ></td>
	<td class="line x" title="201:208	By sparseness we mean that within the large space of alternative interpretations produced by ambiguous utterances, only a small portion is commonly used." ></td>
	<td class="line x" title="202:208	Therefore the chance of an inappropriate interpretation to be observed in the corpus (in other contexts) is low." ></td>
	<td class="line x" title="203:208	Redundancy relates to the fact that different informants (such as different lexical relations or deep understanding) tend to support rather than contradict one another, and therefore the chance of picking a 'wrong' informant is low." ></td>
	<td class="line x" title="204:208	The examination of the failures suggests that future research may improve both the applicability and precision of the model." ></td>
	<td class="line x" title="205:208	Our next goal is to handle inapplicable cases by using cooccurrence data regardless of syntactic relations and similarities between words." ></td>
	<td class="line x" title="206:208	We expect that increasing the applicability will lead to some decrease in precision, similar to the tradeoff between recall and precision in information retrieval." ></td>
	<td class="line x" title="207:208	Pursuing this tradeoff will improve the performance of the method and reveal its limitations." ></td>
	<td class="line x" title="208:208	8 Acknowledgments We would like to thank Mori Rimon, Peter Brown, Ayala Cohen, Ulrike Rackow, Herb Leass and Hans Karlgren for their help and comments." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P91-1027
Automatic Acquisition Of Subcategorization Frames From Untagged Text
Brent, Michael R.;"></td>
	<td class="line x" title="1:189	AUTOMATIC ACQUISITION OF SUBCATEGORIZATION FRAMES FROM UNTAGGED TEXT Michael R. Brent MIT AI Lab 545 Technology Square Cambridge, Massachusetts 02139 michael@ai.mit.edu ABSTRACT This paper describes an implemented program that takes a raw, untagged text corpus as its only input (no open-class dictionary) and generates a partial list of verbs occurring in the text and the subcategorization frames (SFs) in which they occur." ></td>
	<td class="line x" title="2:189	Verbs are detected by a novel technique based on the Case Filter of Rouvret and Vergnaud (1980)." ></td>
	<td class="line x" title="3:189	The completeness of the output list increases monotonically with the total number of occurrences of each verb in the corpus." ></td>
	<td class="line x" title="4:189	False positive rates are one to three percent of observations." ></td>
	<td class="line x" title="5:189	Five SFs are currently detected and more are planned." ></td>
	<td class="line x" title="6:189	Ultimately, I expect to provide a large SF dictionary to the NLP community and to train dictionaries for specific corpora." ></td>
	<td class="line x" title="7:189	1 INTRODUCTION This paper describes an implemented program that takes an untagged text corpus and generates a partial list of verbs occurring in it and the subcategorization frames (SFs) in which they occur." ></td>
	<td class="line x" title="8:189	So far, it detects the five SFs shown in Table 1." ></td>
	<td class="line x" title="9:189	SF Good Example Bad Example Description direct object direct object & clause direct object & infinitive clause infinitive greet them tell him he's a fool want him to attend know I'll attend hope to attend *arrive them *hope him he's a fool *hope him to attend *want I'll attend *greet to attend Table 1: The five subcategorization frames (SFs) detected so far The SF acquisition program has been tested on a corpus of 2.6 million words of the Wall Street Journal (kindly provided by the Penn Tree Bank project)." ></td>
	<td class="line x" title="10:189	On this corpus, it makes 5101 observations about 2258 orthographically distinct verbs." ></td>
	<td class="line x" title="11:189	False positive rates vary from one to three percent of observations, depending on the SF." ></td>
	<td class="line x" title="12:189	1.1 WHY IT MATTERS Accurate parsing requires knowing the subcategorization frames of verbs, as shown by (1)." ></td>
	<td class="line oc" title="13:189	(1) a. I expected \[nv the man who smoked NP\] to eat ice-cream h. I doubted \[NP the man who liked to eat ice-cream NP\] Current high-coverage parsers tend to use either custom, hand-generated lists of subcategorization frames (e.g. , Hindle, 1983), or published, handgenerated lists like the Ozford Advanced Learner's Dictionary of Contemporary English, Hornby and Covey (1973) (e.g. , DeMarcken, 1990)." ></td>
	<td class="line x" title="14:189	In either case, such lists are expensive to build and to maintain in the face of evolving usage." ></td>
	<td class="line x" title="15:189	In addition, they tend not to include rare usages or specialized vocabularies like financial or military jargon." ></td>
	<td class="line x" title="16:189	Further, they are often incomplete in arbitrary ways." ></td>
	<td class="line x" title="17:189	For example, Webster's Ninth New Collegiate Dictionary lists the sense of strike meaning 'go occur to', as in 'it struck him that ', but it does not list that same sense of hit." ></td>
	<td class="line x" title="18:189	(My program discovered both)." ></td>
	<td class="line x" title="19:189	1.2 WHY IT'S HARD The initial priorities in this research were:." ></td>
	<td class="line x" title="20:189	Generality (e.g. , minimal assumptions about the text) . Accuracy in identifying SF occurrences  Simplicity of design and speed Efficient use of the available text was not a high priority, since it was felt that plenty of text was available even for an inefficient learner, assuming sufficient speed to make use of it." ></td>
	<td class="line x" title="21:189	These priorities 209 had a substantial influence on the approach taken." ></td>
	<td class="line x" title="22:189	They are evaluated in retrospect in Section 4." ></td>
	<td class="line x" title="23:189	The first step in finding a subcategorization frame is finding a verb." ></td>
	<td class="line x" title="24:189	Because of widespread and productive noun/verb ambiguity, dictionaries are not much use -they do not reliably exclude the possibility oflexical ambiguity." ></td>
	<td class="line x" title="25:189	Even if they did, a program that could only learn SFs for unambiguous verbs would be of limited value." ></td>
	<td class="line x" title="26:189	Statistical disambiguators make dictionaries more useful, but they have a fairly high error rate, and degrade in the presence of many unfamiliar words." ></td>
	<td class="line x" title="27:189	Further, it is often difficult to understand where the error is coming from or how to correct it." ></td>
	<td class="line x" title="28:189	So finding verbs poses a serious challenge for the design of an accurate, general-purpose algorithm for detecting SFs." ></td>
	<td class="line x" title="29:189	In fact, finding main verbs is more difficult than it might seem." ></td>
	<td class="line x" title="30:189	One problem is distinguishing participles from adjectives and nouns, as shown below." ></td>
	<td class="line x" title="31:189	(2) a. John has \[~p rented furniture\] (comp.: John has often rented apartments) b. John was smashed (drunk) last night (comp.: John was kissed last night) c. John's favorite activity is watching TV (comp.: John's favorite child is watching TV) In each case the main verb is have or be in a context where most parsers (and statistical disambiguators) would mistake it for an auxiliary and mistake the following word for a participial main verb." ></td>
	<td class="line x" title="32:189	A second challenge to accuracy is determining which verb to associate a given complement with." ></td>
	<td class="line x" title="33:189	Paradoxically, example (1) shows that in general it isn't possible to do this without already knowing the SF." ></td>
	<td class="line x" title="34:189	One obvious strategy would be to wait for sentences where there is only one candidate verb; unfortunately, it is very difficult to know for certain how many verbs occur in a sentence." ></td>
	<td class="line x" title="35:189	Finding some of the verbs in a text reliably is hard enough; finding all of them reliably is well beyond the scope of this work." ></td>
	<td class="line x" title="36:189	Finally, any system applied to real input, no matter how carefully designed, will occasionally make errors in finding the verb and determining its subcategorizatiou frame." ></td>
	<td class="line x" title="37:189	The more times a given verb appears in the corpus, the more likely it is that one of those occurrences will cause an erroneous judgment." ></td>
	<td class="line x" title="38:189	For that reason any learning system that gets only positive examples and makes a permanent judgment on a single example will always degrade as the number of occurrences increases." ></td>
	<td class="line x" title="39:189	In fact, making a judgment based on any fixed number of examples with any finite error rate will always lead to degradation with corpussize." ></td>
	<td class="line x" title="40:189	A better approach is to require a fixed percentage of the total occurrences of any given verb to appear with a given SF before concluding that random error is not responsible for these observations." ></td>
	<td class="line x" title="41:189	Unfortunately, determining the cutoff percentage requires human intervention and sampling error makes classification unstable for verbs with few occurrences in the input." ></td>
	<td class="line x" title="42:189	The sampling error can be dealt with (Brent, 1991) but predetermined cutoff percentages stir require eye-bailing the data." ></td>
	<td class="line x" title="43:189	Thus robust, unsupervised judgments in the face of error pose the third challenge to developing an accurate learning system." ></td>
	<td class="line x" title="44:189	1.3 HOW IT'S DONE The architecture of the system, and that of this paper, directly reflects the three challenges described above." ></td>
	<td class="line x" title="45:189	The system consists of three modules: 1." ></td>
	<td class="line x" title="46:189	Verb detection: Finds some occurrences of verbs using the Case Filter (Rouvret and Vergnaud, 1980), a proposed rule of grammar. 2." ></td>
	<td class="line x" title="47:189	SF detection: Finds some occurrences of five subcategorization frames using a simple, finite-state grammar for a fragment of English." ></td>
	<td class="line x" title="48:189	3." ></td>
	<td class="line x" title="49:189	SF decision: Determines whether a verb is genuinely associated with a given SF, or whether instead its apparent occurrences in that SF are due to error." ></td>
	<td class="line x" title="50:189	This is done using statistical models of the frequency distributions." ></td>
	<td class="line x" title="51:189	The following two sections describe and evaluate the verb detection module and the SF detection module, respectively; the decision module, which is still being refined, will be described in a subsequent paper." ></td>
	<td class="line x" title="52:189	The final two sections provide a brief comparison to related work and draw conclusions." ></td>
	<td class="line x" title="53:189	2 VERB DETECTION The technique I developed for finding verbs is based on the Case Filter of Rouvret and Verguaud (1980)." ></td>
	<td class="line x" title="54:189	The Case Filter is a proposed rule of grammar which, as it applies to English, says that every noun-phrase must appear either immediately to the left of a tensed verb, immediately to the right of a preposition, or immediately to the right of a main verb." ></td>
	<td class="line x" title="55:189	Adverbs and adverbial phrases (including days and dates) are ignored for the purposes of case adjacency." ></td>
	<td class="line x" title="56:189	A noun-phrase that satisfies the Case Filter is said to 'get case' or 'have case', while one that violates it is said to 'lack case'." ></td>
	<td class="line x" title="57:189	The program judges an open-class word to be a main verb if it is adjacent to a pronoun or proper name that would otherwise lack case." ></td>
	<td class="line x" title="58:189	Such a pronoun or proper name is either the subject or 210 the direct object of the verb." ></td>
	<td class="line x" title="59:189	Other noun phrases are not used because it is too difficult to determine their right boundaries accurately." ></td>
	<td class="line x" title="60:189	The two criteria for evaluating the performance of the main-verb detection technique are efficiency and accuracy." ></td>
	<td class="line x" title="61:189	Both were measured using a 2.6 million word corpus for which the Penn Treebank project provides hand-verified tags." ></td>
	<td class="line x" title="62:189	Efficiency of verb detection was assessed by running the SF detection module in the normal mode, where verbs were detected using the Case Filter technique, and then running it again with the Penn Tags substituted for the verb detection module." ></td>
	<td class="line x" title="63:189	The results are shown in Table 2." ></td>
	<td class="line x" title="64:189	Note SF direct object direct object &: clause direct object & infinitive clause infinitive Occurrences Found 3,591 94 310 739 367 Control 8,606 381 3,597 14,144 11,880 Efficiency 40% 25% 8% 5% 3% Table 2: Efficiency of verb detection for each of the five SFs, as tested on 2.6 million words of the Wall Street Journal and controlled by the Penn Treehank's hand-verified tagging the substantial variation among the SFs: for the SFs 'direct object' and 'direct object & clause' efficiency is roughly 40% and 25%, respectively; for 'direct object & infinitive' it drops to about 8%; and for the intransitive SFs it is under 5%." ></td>
	<td class="line x" title="65:189	The reason that the transitive SFs fare better is that the direct object gets case from the preceding verb and hence reveals its presence -intransitive verbs are harder to find." ></td>
	<td class="line x" title="66:189	Likewise, clauses fare better than infinitives because their subjects get case from the main verb and hence reveal it, whereas infinitives lack overt subjects." ></td>
	<td class="line x" title="67:189	Another obvious factor is that, for every SF listed above except 'direct object' two verbs need to be found -the matrix verb and the complement verb -if either one is not detected then no observation is recorded." ></td>
	<td class="line x" title="68:189	Accuracy was measured by looking at the Penn tag for every word that the system judged to be a verb." ></td>
	<td class="line x" title="69:189	Of approximately 5000 verb tokens found by the Case Filter technique, there were 28 disagreements with the hand-verified tags." ></td>
	<td class="line x" title="70:189	My program was right in 8 of these cases and wrong in 20, for a 0.24% error-rate beyond the rate using hand-verified tags." ></td>
	<td class="line x" title="71:189	Typical disagreements in which my system was right involved verbs that are ambiguous with much more frequent nouns, like mold in 'The Soviet Communist Party has the power to shape corporate development and mold it into a body dependent upon it '." ></td>
	<td class="line x" title="72:189	There were several systematic constructions in which the Penn tags were right and my system was wrong, including constructions like 'We consumers are' and pseudo-clefts like '~vhat you then do is you make them think  (These examples are actual text from the Penn corpus)." ></td>
	<td class="line x" title="73:189	The extraordinary accuracy of verb detection -within a tiny fraction of the rate achieved by trained human taggers -and it's relatively low efficiency are consistent with the priorities laid out in Section 1.2." ></td>
	<td class="line x" title="74:189	2.1 SF DETECTION The obvious approach to finding SFs like 'V NP to V' and 'V to V' is to look for occurrences of just those patterns in the training corpus; but the obvious approach fails to address the attachment problem illustrated by example (1) above." ></td>
	<td class="line x" title="75:189	The solution is based on the following insights:  Some examples are clear and unambiguous." ></td>
	<td class="line x" title="76:189	 Observations made in clear cases generalize to all cases." ></td>
	<td class="line x" title="77:189	 It is possible to distinguish the clear cases from the ambiguous ones with reasonable accuracy." ></td>
	<td class="line x" title="78:189	 With enough examples, it pays to wait for the clear cases." ></td>
	<td class="line x" title="79:189	Rather than take the obvious approach of looking for 'V NP to V', my approach is to wait for clear cases like 'V PRONOUN to V'." ></td>
	<td class="line x" title="80:189	The advantages can be seen by contrasting (3) with (1)." ></td>
	<td class="line x" title="81:189	(3) a. OK I expected him to eat ice-cream b. * I doubted him to eat ice-cream More generally, the system recognizes linguistic structure using a small finite-state grammar that describes only that fragment of English that is most useful for recognizing SFs." ></td>
	<td class="line x" title="82:189	The grammar relies exclusively on closed-class lexical items such as pronouns, prepositions, determiners, and auxiliary verbs." ></td>
	<td class="line x" title="83:189	The grammar for detecting SFs needs to distinguish three types of complements: direct objects, infinitives, and clauses." ></td>
	<td class="line x" title="84:189	The grammars for each of these are presented in Figure 1." ></td>
	<td class="line x" title="85:189	Any open-class word judged to he a verb (see Section 2) and followed immediately by matches for <DO>, <clause>, <infinitives, <DO><clanse>, or <DO><inf> is assigned the corresponding SF." ></td>
	<td class="line x" title="86:189	Any word ending in 'ly' or 211 <clause> := that?" ></td>
	<td class="line x" title="87:189	(<subj-pron> I <subj-obj-pron> <tensed-verb> <subj-pron> := I J he \[ she \[ I \[ they <subj-obj-pron> := you, it, yours, hers, ours, theirs <DO> := <obj-pron> <obj-pron> := me \[ him \[ us \[ them <infinitive> := to <previously-noted-uninflected-verb> I his I <proper-name>) Figure 1: A non-recursive (finite-state) grammar for detecting certain verbal complements." ></td>
	<td class="line x" title="88:189	indicates an optional element." ></td>
	<td class="line x" title="89:189	Any verb followed immediately expressions matching <DO>, <clause>, <infinitive>, <DO> <clause>, or <DO> <infinitive> is assigned the corresponding SF." ></td>
	<td class="line x" title="90:189	belonging to a list of 25 irregular adverbs is ignored for purposes of adjacency." ></td>
	<td class="line x" title="91:189	The notation 'T' follows optional expressions." ></td>
	<td class="line x" title="92:189	The category previously-noted-uninflected-verb is special in that it is not fixed in advance -open-class nonadverbs are added to it when they occur following an unambiguous modal." ></td>
	<td class="line x" title="93:189	I This is the only case in which the program makes use of earlier decisions -literally bootstrapping." ></td>
	<td class="line x" title="94:189	Note, however, that ambiguity is possible between mass nouns and uninflected verbs, as in to fish." ></td>
	<td class="line x" title="95:189	Like the verb detection algorithm, the SF detection algorithm is evaluated in terms of efficiency and accuracy." ></td>
	<td class="line x" title="96:189	The most useful estimate of efficiency is simply the density of observations in the corpus, shown in the first column of Table 3." ></td>
	<td class="line x" title="97:189	The SF direct object direct object & clause direct object & infinitive clause infinitive occurrences found 3,591 94 310 739 367 % error 1.5% 2.0% 1.5% 0.5% 3.0% Table 3: SF detector error rates as tested on 2.6 million words of the Wall Street Journal accuracy of SF detection is shown in the second 1If there were room to store an unlimited number of uninflected verbs for later reference then the grammar formalism would not be finite-state." ></td>
	<td class="line x" title="98:189	In fact, a fixed amount of storage, sufficient to store all the verbs in the language, is allocated." ></td>
	<td class="line x" title="99:189	This question is purely academic, however -a hash-table gives constant-time average performance." ></td>
	<td class="line x" title="100:189	column of Table 3." ></td>
	<td class="line x" title="101:189	2 The most common source of error was purpose adjuncts, as in 'John quit to pursue a career in finance,' which comes from omitting the in order from 'John quit in order to pursue a career in finance'." ></td>
	<td class="line x" title="102:189	These purpose adjuncts were mistaken for infinitival complements." ></td>
	<td class="line x" title="103:189	The other errors were more sporadic in nature, many coming from unusual extrapositions or other relatively rare phenomena." ></td>
	<td class="line x" title="104:189	Once again, the high accuracy and low efficiency are consistent with the priorities of Section 1.2." ></td>
	<td class="line x" title="105:189	The throughput rate is currently about ten-thousand words per second on a Sparcstation 2, which is also consistent with the initial priorities." ></td>
	<td class="line x" title="106:189	Furthermore, at ten-thousand words per second the current density of observations is not problematic." ></td>
	<td class="line x" title="107:189	3 RELATED WORK Interest in extracting lexical and especially collocational information from text has risen dramatically in the last two years, as sufficiently large corpora and sufficiently cheap computation have become available." ></td>
	<td class="line oc" title="108:189	Three recent papers in this area are Church and Hanks (1990), Hindle (1990), and Smadja and McKeown (1990)." ></td>
	<td class="line o" title="109:189	The latter two are concerned exclusively with collocation relations between open-class words and not with grammatical properties." ></td>
	<td class="line x" title="110:189	Church is also interested primarily in open-class collocations, but he does discuss verbs that tend to be followed by infinitives within his mutual information framework." ></td>
	<td class="line x" title="111:189	Mutual information, as applied by Church, is a measure of the tendency of two items to appear near one-another -their observed frequency in nearby positions is divided by the expectation of that frequency if their positions were random and independent." ></td>
	<td class="line x" title="112:189	To measure the tendency of a verb to be followed within a few words by an infinitive, Church uses his statistical disambiguator 2Error rates computed by hand verification of 200 examples for each SF using the tagged mode." ></td>
	<td class="line x" title="113:189	These are estimated independently of the error rates for verb detection." ></td>
	<td class="line x" title="114:189	212 (Church, 1988) to distinguish between to as an infinitive marker and to as a preposition." ></td>
	<td class="line x" title="115:189	Then he measures the mutual information between occurrences of the verb and occurrences of infinitives following within a certain number of words." ></td>
	<td class="line x" title="116:189	Unlike our system, Church's approach does not aim to decide whether or not a verb occurs with an infinitival complement -example (1) showed that being followed by an infinitive is not the same as taking an infinitival complement." ></td>
	<td class="line x" title="117:189	It might be interesting to try building a verb categorization scheme based on Church's mutual information measure, but to the best of our knowledge no such work has been reported." ></td>
	<td class="line x" title="118:189	4 CONCLUSIONS The ultimate goal of this work is to provide the NLP community with a substantially complete, automatically updated dictionary of subcategorization frames." ></td>
	<td class="line x" title="119:189	The methods described above solve several important problems that had stood in the way of that goal." ></td>
	<td class="line x" title="120:189	Moreover, the results obtained with those methods are quite encouraging." ></td>
	<td class="line x" title="121:189	Nonetheless, two obvious barriers still stand on the path to a fully automated SF dictionary: a decision algorithm that can handle random error, and techniques for detecting many more types of SFs." ></td>
	<td class="line x" title="122:189	Algorithms are currently being developed to resolve raw SF observations into genuine lexical properties and random error." ></td>
	<td class="line x" title="123:189	The idea is to automatically generate statistical models of the sources of error." ></td>
	<td class="line x" title="124:189	For example, purpose adjuncts like 'John quit to pursue a career in finance' are quite rare, accounting for only two percent of the apparent infinitival complements." ></td>
	<td class="line x" title="125:189	Furthermore, they are distributed across a much larger set of matrix verbs than the true infinitival complements, so any given verb should occur with a purpose adjunct extremely rarely." ></td>
	<td class="line x" title="126:189	In a histogram sorting verbs by their apparent frequency of occurrence with infinitival complements, those that in fact have appeared with purpose adjuncts and not true subcategorized infinitives will be clustered at the low frequencies." ></td>
	<td class="line x" title="127:189	The distributions of such clusters can be modeled automatically and the models used for identifying false positives." ></td>
	<td class="line x" title="128:189	The second requirement for automatically generating a full-scale dictionary is the ability to detect many more types of SFs." ></td>
	<td class="line x" title="129:189	SFs involving certain prepositional phrases are particularly chal: lenging." ></td>
	<td class="line x" title="130:189	For example, while purpose adjuncts (mistaken for infinitival complements) are relatively rare, instrumental adjuncts as in 'John hit the nail with a hammer' are more common." ></td>
	<td class="line x" title="131:189	The problem, of course, is how to distinguish them from genuine, subcategorized PPs headed by with, as in 'John sprayed the lawn with distilled water'." ></td>
	<td class="line x" title="132:189	The hope is that a frequency analysis like the one planned for purpose adjuncts will work here as well, but how successful it will be, and if successful how large a sample size it will require, remain to be seen." ></td>
	<td class="line x" title="133:189	The question of sample size leads back to an evaluation of the initial priorities, which favored simplicity, speed, and accuracy, over efficient use of the corpus." ></td>
	<td class="line x" title="134:189	There are various ways in which the high-priority criteria can be traded off against efficiency." ></td>
	<td class="line x" title="135:189	For example, consider (2c): one might expect that the overwhelming majority of occurrences of 'is V-ing' are genuine progressives, while a tiny minority are cases copula." ></td>
	<td class="line x" title="136:189	One might also expect that the occasional copula constructions are not concentrated around any one present participle but rather distributed randomly among a large population." ></td>
	<td class="line x" title="137:189	If those expectations are true then a frequency-modeling mechanism like the one being developed for adjuncts ought to prevent the mistaken copula from doing any harm." ></td>
	<td class="line x" title="138:189	In that case it might be worthwhile to admit 'is V-ing', where V is known to be a (possibly ambiguous) verb root, as a verb, independent of the Case Filter mechanism." ></td>
	<td class="line x" title="139:189	ACKNOWLEDGMENTS Thanks to Don Hindle, Lila Gleitman, and Jane Grimshaw for useful and encouraging conversations." ></td>
	<td class="line x" title="140:189	Thanks also to Mark Liberman, Mitch Marcus and the Penn Treebank project at the University of Pennsylvania for supplying tagged text." ></td>
	<td class="line x" title="141:189	This work was supported in part by National Science Foundation grant DCR-85552543 under a Presidential Young Investigator Award to Professor Robert C. Berwick." ></td>
	<td class="line x" title="142:189	References \[Brent, 1991\] M. Brent." ></td>
	<td class="line x" title="143:189	Semantic Classification of Verbs from their Syntactic Contexts: An Implemented Classifier for Stativity." ></td>
	<td class="line x" title="144:189	In Proceedings of the 5th European A CL Conference." ></td>
	<td class="line x" title="145:189	Association for Computational Linguistics, 1991." ></td>
	<td class="line x" title="146:189	\[Church and Hanks, 1990\] K. Church and P. Hanks." ></td>
	<td class="line x" title="147:189	Word association norms, mutual information, and lexicography." ></td>
	<td class="line x" title="148:189	Comp." ></td>
	<td class="line x" title="149:189	Ling., 16, 1990." ></td>
	<td class="line x" title="151:189	\[Church, 1988\] K. Church." ></td>
	<td class="line x" title="152:189	A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text." ></td>
	<td class="line x" title="153:189	In Proceedings of the 2nd ACL Conference on Applied NLP." ></td>
	<td class="line x" title="154:189	ACL, 1988." ></td>
	<td class="line x" title="155:189	\[DeMarcken, 1990\] C. DeMarcken." ></td>
	<td class="line x" title="156:189	Parsing the LOB Corpus." ></td>
	<td class="line x" title="157:189	In Proceedings of the A CL. Assocation for Comp." ></td>
	<td class="line x" title="158:189	Ling., 1990." ></td>
	<td class="line x" title="159:189	\[Gleitman, 1990\] L. Gleitman." ></td>
	<td class="line x" title="160:189	The structural sources of verb meanings." ></td>
	<td class="line x" title="161:189	Language Acquisition, 1(1):3-56, 1990." ></td>
	<td class="line x" title="162:189	\[Hindle, 1983\] D. Hindle." ></td>
	<td class="line x" title="163:189	User Manual for Fidditch, a Deterministic Parser." ></td>
	<td class="line x" title="164:189	Technical Report 7590-142, Naval Research Laboratory, 1983." ></td>
	<td class="line xc" title="165:189	\[Hindle, 1990\] D. Hindle." ></td>
	<td class="line x" title="166:189	Noun cl~sification from predicate argument structures." ></td>
	<td class="line x" title="167:189	In Proceedings of the 28th Annual Meeting of the ACL, pages 268-275." ></td>
	<td class="line x" title="168:189	ACL, 1990." ></td>
	<td class="line x" title="169:189	\[Hornby and Covey, 1973\] A. Hornby and A. Covey." ></td>
	<td class="line x" title="170:189	Ozford Advanced Learner's Dictionary of Contemporary English." ></td>
	<td class="line x" title="171:189	Oxford University Press, Oxford, 1973." ></td>
	<td class="line x" title="172:189	\[Levin, 1989\] B. Levin." ></td>
	<td class="line x" title="173:189	English Verbal Diathesis." ></td>
	<td class="line x" title="174:189	Lexicon Project orking Papers no. 32, MIT Center for Cognitive Science, MIT, Cambridge, MA., 1989." ></td>
	<td class="line x" title="176:189	\[Pinker, 1989\] S. Pinker." ></td>
	<td class="line x" title="177:189	Learnability and Cognition: The Acquisition of Argument Structure." ></td>
	<td class="line x" title="178:189	MIT Press, Cambridge, MA, 1989." ></td>
	<td class="line x" title="179:189	\[Rouvret and Vergnaud, 1980\] A. Rouvret and JR Vergnaud." ></td>
	<td class="line x" title="180:189	Specifying Reference to the Subject." ></td>
	<td class="line x" title="181:189	Linguistic Inquiry, 11(1), 1980." ></td>
	<td class="line x" title="182:189	\[Smadja and McKeown, 1990\] F. Smadja and K. McKeown." ></td>
	<td class="line x" title="183:189	Automatically extracting and representing collocations for language generation." ></td>
	<td class="line x" title="184:189	In 28th Anneal Meeting of the Association for Comp." ></td>
	<td class="line x" title="185:189	Ling., pages 252-259." ></td>
	<td class="line x" title="186:189	ACL, 1990." ></td>
	<td class="line x" title="187:189	\[Zwicky, 1970\] A. Zwicky." ></td>
	<td class="line x" title="188:189	In a Manner of Speaking." ></td>
	<td class="line x" title="189:189	Linguistic Inquiry, 2:223-233, 1970 ." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="A92-1013
Computational Lexicons: The Neat Examples And The Odd Exemplars
Basili, Roberto;Pazienza, Maria Teresa;Velardi, Paola;"></td>
	<td class="line x" title="1:225	Computational Lexicons: the Neat Examples and the Odd Exemplars Roberto Basili, Maria Teresa Pazienza Dip." ></td>
	<td class="line x" title="2:225	di Ingegneria Elettronica, Universita' 'Tor Vergata', Roma, Italy Paola Velardi Ist." ></td>
	<td class="line x" title="3:225	di Informatica, Universita' di Ancona, Ancona, Italy Abstract When implementing computational lexicons it is important to keep in mind the texts that a NLP system must deal with." ></td>
	<td class="line x" title="4:225	Words relate to each other in many different, often queer, ways: this information is rarely found in dictionaries, and it is quite hard to be invented a priori, despite the imagination that linguists exhibit at inventing esoteric examples." ></td>
	<td class="line x" title="5:225	In this paper we present the results of an experiment in learning from corpora the frequent selectional restrictions holding between content words." ></td>
	<td class="line x" title="6:225	The method is based on the analysis of word associations augmented with syntactic markers and semantic tags." ></td>
	<td class="line x" title="7:225	Word pairs are extracted by a morphosyntactic analyzer and clustered according to their semantic tags." ></td>
	<td class="line x" title="8:225	A statistical measure is applied to the data to evaluate the significance of a detected relation." ></td>
	<td class="line x" title="9:225	Clustered association data render the study of word associations more interesting with several respects: data are more reliable even for smaller corpora, more easy to interpret, and have many practical applications in NLP." ></td>
	<td class="line x" title="10:225	1." ></td>
	<td class="line x" title="11:225	Introduction One of the fundamental property of computational lexicons is an account of the relations between verbs and its arguments." ></td>
	<td class="line x" title="12:225	Arguments are identified by their position in a predicate-argument structure, or by conceptual relations names (e.g. agent, purpose, location, etc)." ></td>
	<td class="line x" title="13:225	Arguments are annotated with selectional restrictions, that impose type constraints on the set of content words that may fill a relation." ></td>
	<td class="line x" title="14:225	Selectional restrictions often do not provide all the semantic information that is necessary in NLP systems, however they are at the basis of the majority of computational approaches to syntactic and semantic disambiguation." ></td>
	<td class="line x" title="15:225	It has been noticed that representing only the semantics of verbs may be inadequate (Velardi et al. 1988; Boguraev 1991; Macpherson 1991)." ></td>
	<td class="line x" title="16:225	The notion of spreading the semantic load supports the idea that every content word should be represented in the lexicon as the union of all the situations in which it could potentially participate." ></td>
	<td class="line x" title="17:225	Unfortunately, hand writing selectional restrictions is not an easy matter, because it is time consuming and it is hard to keep consistency among the data when the lexicon has several hundred or thousand words." ></td>
	<td class="line x" title="18:225	However the major difficulty is that words relate to each other in many different, often domain dependent ways." ></td>
	<td class="line x" title="19:225	The nowadays vast literature on computational lexicons is filled with neat examples of the eat(animate,food) flavour, but in practice in many language domains selectional constraints between words are quite odd." ></td>
	<td class="line x" title="20:225	It is not just a matter of violating the semantic expectations, such as in 'kill the process' or 'my car drinks gasoline', neither it is that kind of fancifulness that linguists exhibit at finding queer sentences." ></td>
	<td class="line x" title="21:225	Rather, there exist statistically relevant linguistic relations that are hard to imagine a-priori, almost never found in dictionaries, and even harder to assign to the appropriate slot in the whatever conceptual structure adopted for lexical representation." ></td>
	<td class="line x" title="22:225	Several examples of such relations are shown throughout this paper." ></td>
	<td class="line x" title="23:225	Ideally, knowledge on word relations should be acquired directly from massive amounts of texts~ rather than from hand-crafted rules." ></td>
	<td class="line x" title="24:225	This idea is a!" ></td>
	<td class="line x" title="25:225	the basis of many recent studies on word associations." ></td>
	<td class="line x" title="26:225	The results of these studies have important applications in lexicography, to detect lexicosyntactic regularities (Church and Hanks, 19901 (Calzolari and Bindi,1990), such as, for example~ support verbs (e.g. 'make-decision') prepositional verbs (e.g. 'rely-upon') idioms, semantic relations (e.g. 'part_of') and fixed expressions (e.g. 'kick the bucket')." ></td>
	<td class="line oc" title="27:225	In (Hindle,1990; Zernik, 1989; Webster el Marcus, 1989) cooccurrence analyses augmented with syntactic parsing is used for the purpose of word classification." ></td>
	<td class="line o" title="28:225	All these studies are based on th~ (strong) assumption that syntactic similarity in wor(~ patterns implies semantic similarity." ></td>
	<td class="line x" title="29:225	In (Guthrie el al. , 1991), sets of consistently contiguous word~, ('neighbourhood') are extracted from machinereadable dictionaries, to help semantic disambiguation in information retrieval." ></td>
	<td class="line x" title="30:225	In (Smadj~ and McKeown, 1990) statistically collectec associations provide pragmatic cues for lexical choic( in sentence generation." ></td>
	<td class="line x" title="31:225	For example, we can learr that 'make decision' is a better choice than, say 96 'have decision' or 'take decision'." ></td>
	<td class="line x" title="32:225	(Hindle and Rooths, 1991) proposes that a syntactic disambiguation criterion can be gathered by comparing the probability of occurrence of nounpreposition and verb-preposition pairs in V NP PP structures." ></td>
	<td class="line x" title="33:225	In general word associations are collected by extracting word pairs in a +-5 window." ></td>
	<td class="line x" title="34:225	In (Calzolari and Bindi, 1990), (Church and Hanks, 1990) the significance of an association (x,y) is measured by the mutual information I(x,y), i.e. the probability of observing x and y together, compared with the probability of observing x and y independently." ></td>
	<td class="line x" title="35:225	In (Smadja, 1989), (Zernik and Jacobs, 1990), the associations are filtered by selecting the word pairs (x,y) whose frequency of occurrence is above f+ks, where f is the average appearance, s is the standard deviation, and k is an empirically determined factor." ></td>
	<td class="line oc" title="36:225	(Hindle, 1990; Hindle and Rooths,1991) and (Smadja, 1991) use syntactic markers to increase the significance of the data." ></td>
	<td class="line x" title="37:225	(Guthrie et al. , 1991\] uses the subject classification given in machine-readable dictionaries (e.g. economics, engineering, etc)." ></td>
	<td class="line x" title="38:225	to reinforce cooccurence links." ></td>
	<td class="line n" title="39:225	Despite the use of these methods to add evidence to the data, the major problem with word-pairs collections is that reliable results are obtained only for a small subset of high-frequency words on very large corpora, otherwise the association ratio becomes unstable." ></td>
	<td class="line n" title="40:225	For example, Church run his experiment on a corpus with over 20-30 millions words, and Hindle reports 6 millions words as not being an adequate corpus." ></td>
	<td class="line x" title="41:225	In many practical NLP/IR applications corpora are not so large, and typically span from 500,000 to a few million words." ></td>
	<td class="line x" title="42:225	The analysis of associations could be done on wider domains, but a part for very general words, it is much more desirable to collect data from the application corpus." ></td>
	<td class="line x" title="43:225	Information collected from other sources could add noise rather than strengthening the data, because in most applications jargon, technical words, and domain-dependent associations are the norm." ></td>
	<td class="line x" title="44:225	In (Smadja, 1989b) it is shown a table of operational pairs like adjective-noun and verb-object, from which clearly emerges the very different nature of the two source domains (Unix Usenet and Jerusalem Post)." ></td>
	<td class="line x" title="45:225	For example, the noun-noun pairs with 'tree' include associations such as 'parse, grammar, decision' and 'olive, Christmas'." ></td>
	<td class="line x" title="46:225	If the NLP/IR application is about the computer world, associations such as 'olive tree' or 'Christmas tree' are (at best) useless." ></td>
	<td class="line x" title="47:225	A second problem with statistically collected word pairs is that an analysis based simply on surface distribution may produce data at a level of granularity too fine." ></td>
	<td class="line x" title="48:225	For example, a purely distributional analysis for word classification, such as those cited above, might place two verbs into distinct classes because one is used primarily with an object olive and the other with the object grape." ></td>
	<td class="line x" title="49:225	This may not be appropriate given the application." ></td>
	<td class="line x" title="50:225	Abstraction via semantic classes (e.g. VEGETABLE), would ensure that the ontology found is appropriate for the domain." ></td>
	<td class="line n" title="51:225	The model of prepositional attachment preference proposed by Hindle is also too weak if applied only to verb-preposition and nounpreposition pairs." ></td>
	<td class="line x" title="52:225	A preposition may or may not be related to a verb, even if it frequently cooccurs with it, depending upon the underlying semantic relation." ></td>
	<td class="line x" title="53:225	It is the semantic category of the noun following a preposition that determines the nature of the semantic link (e.g. for+ HUMAN ENTITY = beneficiary, for+ACTION = purpose), and ultimately influences the choice of the proper attachment." ></td>
	<td class="line x" title="54:225	Semantic abstraction also renders the data more readable." ></td>
	<td class="line x" title="55:225	Millions of simple word cooccurrences let the experimenter sink in an ocean of data, without providing much insight of the conceptual nature of the detected associations." ></td>
	<td class="line x" title="56:225	In this paper, we present a study on word associations augmented with syntactic markers and semantic tagging." ></td>
	<td class="line x" title="57:225	We call these data clustered associations." ></td>
	<td class="line x" title="58:225	Clustered association data are syntactic pairs or triples (e.g. N_V(\]ohn,go) V prep_N(go, to,Boston), N_prepN(Boston,by,bus) 1) in which one or both content words are replaced by their semantic tag (e.g. V_prep_N(PHYSICAL ACT-toPLACE),N_prep_N(PLACE-by-MACHINE) etc.)." ></td>
	<td class="line x" title="59:225	Semantic tags are very high-level in order to reduce the cost of hand-tagging." ></td>
	<td class="line x" title="60:225	Clustered association data have several advantages: First, statistically meaningful data can be gathered from (relatively) small corpora; Second, data are presented in a compact form and are much more readable; Third, clustered association data are useful for many interesting NLP applications, such as conceptual clustering, syntactic and semantic disambiguation, and semi-automatic learning of the relevant selectional restrictions in a given language domain." ></td>
	<td class="line x" title="61:225	In this paper we discuss the results of an experiment in learning selectional restrictions, to provide support for the design of computational lexicons." ></td>
	<td class="line x" title="62:225	Other results are presented in (Basili et al. , 1991; Fabrizi et al. , forthcomingl." ></td>
	<td class="line x" title="63:225	1 We did not want to schock the reader with queer examples since the introduction." ></td>
	<td class="line x" title="64:225	97 The method is applied to a corpus of economic enterprise descriptions, registered at the Chambers of Commerce in Italy." ></td>
	<td class="line x" title="65:225	The database of these descriptions (in total over 1,000,000 descriptions, each spanning from 1 to 100-200 words) is managed in Italy by the Company CERVED." ></td>
	<td class="line x" title="66:225	Sentences describe one or several commercial enterprises carried out by a given Company." ></td>
	<td class="line x" title="67:225	Examples of these descriptions are provided throughout the text." ></td>
	<td class="line x" title="68:225	In our experiment, we used only 25,000 descriptions, including about 500,000 words." ></td>
	<td class="line x" title="69:225	A second experiment on a legal corpus is under preparation and will be ready shortly." ></td>
	<td class="line x" title="70:225	2 Acquiring syntactic associations Clustered association data are collected by first extracting from the corpus all the syntactically related word pairs." ></td>
	<td class="line oc" title="71:225	Combining statistical and parsing methods has been done by (Hindle, 1990; Hindle and Rooths,1991) and (Smadja and McKewon, 1990; Smadja,1991)." ></td>
	<td class="line x" title="72:225	The novel aspect of our study is that we collect not only operational pairs, but triples, such as N_prep N, V_prep_N etc. In fact, the preposition convey important information on the nature of the semantic link between syntactically related content words." ></td>
	<td class="line x" title="73:225	By looking at the preposition, it is possible to restrict the set of semantic relations underlying a syntactic relation (e.g. for=purpose,beneficiary)." ></td>
	<td class="line x" title="74:225	To extract syntactic associations two methods have been adopted in the literature." ></td>
	<td class="line x" title="75:225	Smadja attempts to apply syntactic information to a set of automatically collected collocations (statistics-first)." ></td>
	<td class="line o" title="76:225	Hindle performs syntactic parsing before collocational analysis (syntax-first)." ></td>
	<td class="line x" title="77:225	In our study, we decided to adopt the syntax-first approach, because: as remarked above, it is important to extract not only syntactic pairs, but also triples; statistically collected associations miss some syntactic relation between distant words in coordinate constructions (usually the window in which word pairs are extracted is +-5) and couple many words that are not syntactically related." ></td>
	<td class="line x" title="78:225	Even though (Smadja,1991) reports good performances of his system, it must be noticed that the precision and efficiency figures of the parser apply to a set of data that have been already (statistically) processed." ></td>
	<td class="line x" title="79:225	Thus the actual precision and efficiency in extracting syntactically related words from the source corpus may be lower than expected." ></td>
	<td class="line x" title="80:225	As in other similar works, the syntactic analyzer used in this study does not rely on a complete Italian grammar." ></td>
	<td class="line x" title="81:225	The parser only detects the surface syntactic relations between words." ></td>
	<td class="line x" title="82:225	A full description of the analyzer is outside the scope of this paper (see (Marziali, 1991) for details)." ></td>
	<td class="line x" title="83:225	In short, the parser consists of a segmentation algorithm to cut texts into phrases (NP, PP, VP etc), and a phrase parser that is able to detect the following 15 links: N_V, V_N, N_ADJ, N N, N_prep_N, V_prep_N, N_prep_V, V_prep_V, N_cong_N, ADJ_cong_ADJ, V_ADV, ADV_cong_ADV, V_cong V, N_prep_ADJ, V_prep_ADJ." ></td>
	<td class="line x" title="84:225	The segmentation algorithm is very simple." ></td>
	<td class="line x" title="85:225	If the domain sublanguage is good Italian, sentence cutting is based on the presence of verbs, punctuation, adverbs such as when, if, because, etc: For more jergal domains, such as the economic enterprise corpus, text cutting is based on heuristics such as the detection of a word classified as 'activity' (Fasolo et a1.,1990)." ></td>
	<td class="line x" title="87:225	In fact, this domain is characterized by absence of punctuation, ill formed sentences, long nested coordinate constructions." ></td>
	<td class="line x" title="88:225	The phrase parser is based on DCG (Pereira and Warren,1980), the most complex part of which is the treatment of coordination." ></td>
	<td class="line x" title="89:225	The grammar consists of about 20 rules." ></td>
	<td class="line x" title="90:225	Rather than a parse tree, the output is a 'fiat' set of syntactic relations between content words." ></td>
	<td class="line o" title="91:225	For example, parsing the sentence: fabbrica di scarpe per uomo e per bambino (*manufacture of shoes for man and child) produces the following relations: N_prep N(fabbrica,di,scarpe) N prep_N(fabbrica,per,uomo) N_prep_N(fabbrica,per,bambino) N_prep_N(scarpe,per,uomo) N_prep_N(scarpe,per,bambino) N_cong_N(uomo,e,bambino) Unlike Church and Hindle, we are not interested in collecting binary or ternary relations between words within a sentence, but rather in detecting recurring binary syntactic associations in the corpus." ></td>
	<td class="line x" title="92:225	For this purpose it is unnecessary to retrieve even partial parse trees." ></td>
	<td class="line x" title="93:225	The complexity of the grammar is O(n2), that makes it computationally attractive for parsing large corpora." ></td>
	<td class="line x" title="94:225	In (Marziali,1991) the efficiency and precision of this grammar with respect to the full se!" ></td>
	<td class="line x" title="95:225	of surface syntactic links detectable by a complete DCG grammar are evaluated to be 85% and 90%." ></td>
	<td class="line x" title="96:225	The reference output adopted to perform the evaluation is a syntactic graph (Seo and Simmons,1989)'." ></td>
	<td class="line x" title="97:225	Syntactic graphs include in a unique graph the set of all possible parse trees." ></td>
	<td class="line x" title="98:225	The evaluation was hand-made 98 over a set of 100 sentences belonging to three domains: the economic corpus, the legal corpus, and a novel." ></td>
	<td class="line x" title="99:225	The performances are better for the legal corpus and the novel, due to the ungrammaticality of the economic corpus." ></td>
	<td class="line x" title="100:225	The relatively high efficiency rate, as compared with the figures reported in (Brent, 1991), are due to the fact that Italian morphology is far more complex than English." ></td>
	<td class="line x" title="101:225	Once a good morphologic analyzer is available (the one used in our work is very well tested, and has first described in (Russo,1987)), problems such as verb detection, raised in (Brent, 1991), are negligible." ></td>
	<td class="line x" title="102:225	In addition, the text-cutting algorithm has positive effects on the precision." ></td>
	<td class="line x" title="103:225	Despite this, we verified that about a 35% of the syntactic associations extracted from the economic corpus are semantically unrelated, due to syntactic ambiguity." ></td>
	<td class="line x" title="104:225	As shown in the following sections, semantic clustering in part solves this problem, because semantically unrelated word pairs do not accumulate statistical relevance, except for very rare and unfortunate cases." ></td>
	<td class="line x" title="105:225	In any case, we need more experiments to verify the effect of a more severe sentence cutting algorithm on the precision at detecting semantically related pairs." ></td>
	<td class="line x" title="106:225	This issue is particularly relevant for ungrammatical texts, as in the economic corpus." ></td>
	<td class="line x" title="107:225	3." ></td>
	<td class="line x" title="108:225	Assigning semantic tags The set of syntactic associations extracted by the DCG parser are first clustered according to the cooccurring words and the type of syntactic link." ></td>
	<td class="line x" title="109:225	A further clustering is performed based on the semantic tag associated to the cooccurring words." ></td>
	<td class="line x" title="110:225	Clustering association data through semantic tagging has two important advantages: First, it improves significantly the reliability of association data, even for small corpora; Second, and more importantly, semantic tags make it explicit the semantic nature of word relations." ></td>
	<td class="line x" title="111:225	Manually adding semantic tags to words may appear very expensive, but in fact it is not, if very broad, domain-dependent classes are selected." ></td>
	<td class="line x" title="112:225	In our application, the following 13 categories were adopted: PHYSICAL_ACT (packaging, travel, build, etc)." ></td>
	<td class="line x" title="113:225	MENTAL_ACT(sell, organize, handle, teach, etc)." ></td>
	<td class="line x" title="114:225	HUMAN_ENTITY (shareholder, company, person, farmer, tailor, etc)." ></td>
	<td class="line x" title="115:225	ANIMAL (cow, sheep, etc)." ></td>
	<td class="line x" title="116:225	VEGETABLE (carrots, grape, rubber, coffee, etc)." ></td>
	<td class="line x" title="117:225	MATERIAL (wood, iron, water, cement, etc)." ></td>
	<td class="line x" title="118:225	BUILDING (mill, shop, house, grocery, etc)." ></td>
	<td class="line x" title="119:225	BYPRODUCT (jam, milk, wine, drink, hide, etc)." ></td>
	<td class="line x" title="120:225	ARTIFACT (item, brickwork, toy, table, wears, etc)." ></td>
	<td class="line x" title="121:225	MACHINE (engine, tractor, grindstone,computer, etc)." ></td>
	<td class="line x" title="122:225	PLACE (ground, field, territory, Italy, sea, etc)." ></td>
	<td class="line x" title="123:225	QUALITY (green, chemical, coaxial, flexible, etc)." ></td>
	<td class="line x" title="124:225	MANNER (chemically, by-hand, retail, etc)." ></td>
	<td class="line x" title="125:225	These categories classify well enough the words which are found in the selected sub-corpus as a testbed for our research." ></td>
	<td class="line x" title="126:225	Some words received two tags: for example, there are sentences in which a BUILDING metonymically refers to the commercial ACT held in that building (e.g. 'trade mills for the production'); some word is both a BY_PRODUCT (e.g. 'wood carving') or a MATERIAL (e.g. 'handicrafts in wood')." ></td>
	<td class="line x" title="127:225	Because the domain is very specific, double-tagging i s never due to polisemy." ></td>
	<td class="line x" title="128:225	Once the definition of a semantic class is clearly stated, and with the help of a simple user interface, hand tagging a word is a matter of seconds." ></td>
	<td class="line x" title="129:225	We adopted the policy that, whenever assigning a tag is not obvious, or none of the available tags seems adequate, the word is simply skipped." ></td>
	<td class="line x" title="130:225	Unclassified words are less than 10% in our corpus." ></td>
	<td class="line x" title="131:225	Overall, we classified over 5000 words (lemmata)." ></td>
	<td class="line x" title="132:225	The activity of classification was absolutely negligible in comparison with all the other activities in this research, both on the ground of time and required skill." ></td>
	<td class="line x" title="133:225	Domain-dependent tags render the classification task more simple and ensure that the clustered association data are appropriate given the application." ></td>
	<td class="line x" title="134:225	An obvious drawback is that it is necessary to re-classify many words if the application domain changes significantly." ></td>
	<td class="line x" title="135:225	For example, we are currently preparing a new experiment on a legal corpus." ></td>
	<td class="line x" title="136:225	The domain is semantically more rich, hence we needed 15 classes." ></td>
	<td class="line x" title="137:225	A first estimate revealed that about 30-40% of the words need to be re-classified using more appropriate semantic tags." ></td>
	<td class="line x" title="138:225	4 Acquisition of selectional restrictions Clustered association data are at the basis of our method to detect the important selectional restrictions that hold in a given sublanguage." ></td>
	<td class="line x" title="139:225	The statistical significance of the detected relations is measured by the probability of cooccurrence of two classes C 1 and C 2 in the pattern C 1 synt-rel C2, where synt-rel is one of the syntactic relations detectable by the parser summarized in Section 2." ></td>
	<td class="line x" title="140:225	99 Rather than evaluating the probability Pr(C 1 syntrel C2), we computed the conditioned probability P(C1,C2/synt-rel) estimated by: f(Cl,synt rel,C 2 ) (1) f(synt_rel) The reason for using (1) rather than other measures proposed in the literature, is that what matters here is to detect all the statistically relevant phenomena, not necessarily all the meaningful associations." ></td>
	<td class="line x" title="141:225	Such measures as the mutual information and the t-score (Church et al. , 1991) give emphasis to the infrequent phenomena, because the statistical significance of the coupling between C 1 and C 2 is related to the probability of occurrence of C 1 and C 2 independently from each other." ></td>
	<td class="line x" title="142:225	This would be useful at detecting rare but meaningful relations if one could rely on the correctness of the data." ></td>
	<td class="line x" title="143:225	Unfortunately, due to syntactic ambiguity and errors in parsing, many syntactic associations are not semantically related, i.e. there exists no plausible selectional relations between the to cooccurring words." ></td>
	<td class="line x" title="144:225	Using the mutual information, such relations could accumulate statistical evidence." ></td>
	<td class="line x" title="145:225	The (1) is more conservative, but ensures more reliable results." ></td>
	<td class="line x" title="146:225	In any case, we run several experiments with different statistical measures, without being entirely happy with any of these." ></td>
	<td class="line x" title="147:225	Finding more appropriate statistical methods is one of the future objectives of our work." ></td>
	<td class="line x" title="148:225	Clustered association data are used to build tables, one for each syntactic structure, whose element (x,y) represents the statistical significance in the corpus of a concept pair C 1 C 2." ></td>
	<td class="line x" title="149:225	All the relevant couplings among classes are identified by a human operator who inspects the tables, and labels concept pairs by the appropriate conceptual relation." ></td>
	<td class="line x" title="150:225	Finding an appropriate set of conceptual relations is not an easy task." ></td>
	<td class="line x" title="151:225	In labeling concept pairs, we relied on our preceding work on semantic representation with Conceptual Graph \[Pazienza and Velardi, 1987\]." ></td>
	<td class="line x" title="152:225	Four of these tables are presented in the Appendix." ></td>
	<td class="line x" title="153:225	The data have been collected from a corpus of about 500,000 words." ></td>
	<td class="line x" title="154:225	The morphosyntactic analyzer takes about 6-10 hours on a Spark station." ></td>
	<td class="line x" title="155:225	Clustering the data takes about as much." ></td>
	<td class="line x" title="156:225	At first, we extracted only the V_N, N_prep N and V_prep_N associations, for a total of 52,155 different syntactic associations." ></td>
	<td class="line x" title="157:225	The average is 5 occurrences for each association." ></td>
	<td class="line x" title="158:225	At first glance, the data seem quite odd even to an Italian reader, but it turns out that the tables show exactly what the corpus includes." ></td>
	<td class="line x" title="159:225	Let us briefly go through the 4 tables." ></td>
	<td class="line x" title="160:225	Table 1 summarizes the relations Cl-per-C 2 (per=for)." ></td>
	<td class="line x" title="161:225	Some of the significant associations are: ARTIFACT PHYSICAL_ACT (e.g.: articoli per Io sport (*items for sport), attrezzi per giardinaggio (*tools for gardening)) ARTIFACT BUILDING (e.g. biancheria per la casa (*linens for the house), mobili per negozi (*furnitures for shops)) MACHINE-BUILDING (e.g. macchinari per laboratori (*equipments for laboratories), macine per mulini (*grindstones for mills)) All the above relations subsume the usage (or figurative_destination) relation." ></td>
	<td class="line x" title="162:225	Notice that the 'advertised' beneficiary relation is not very significant in the corpus." ></td>
	<td class="line x" title="163:225	The only statistically relevant beneficiary relations are ARTIFACT-for-HUMAN_ENTITY ( ( e.g. calzature per uomo (*shoes for man), biancheria per signora (*linens for lady)) and HUMAN_ENTITY_for_HUMANENTITY (e.g. parrucchire per signora (*hairdresser for lady)." ></td>
	<td class="line x" title="164:225	It appears that in the considered domain, verbs, except for some, poorly relate with the preposition for (this is the first surprise!)." ></td>
	<td class="line x" title="165:225	Table 2 shows the Cl-in-C 2 relations." ></td>
	<td class="line x" title="166:225	Two relations represent the large majority: ARTIFACT-inBYPRODUCT (e.g. calzature in pelle (*shoes in leather), guarnizioni in gomma (packings in rubber)) ARTIFACT-in-MATERIAL (e.g. oggetti in legnc (*handicrafts in wood) ringhiere in ferro (*banisters in iron)) both subsume a matter relation (this is one of the few 'expected' associations we found)." ></td>
	<td class="line x" title="167:225	Less frequent but interesting are the followin~ relations: MENTAL_ACT-in-MENTAL_ACT (e.g. concedere ir~ appalto (*to grant in bid) acquistare in leasing (*to buy in leasing)) ARTIFACT-in-ARTIFACT (e.g. prodotti in scatok (*products in can)) While the second is a 'reassuring' location relatior (subsumed also by the in-PLACE associations in th( last column), we are less sure about the semanti( interpretation of the first relation." ></td>
	<td class="line x" title="168:225	Tentatively, w( choosed the manner relation." ></td>
	<td class="line x" title="169:225	The same type o: relation is also found in the CI-a-C 2 (a=to,on) tabh (Table 3): MENTAL_ACT-a-MENTAL_ACT (e.g acquistare a credito (*to buy to (=on) credit) abilitare all'ottenimento (*qualifying to th4 attainment), assistenza all'insegnamento (assistenc, to the teaching)) 100 The first example (on credit) clearly subsumes the same relation as for in leasing; the following two seem of a different nature." ></td>
	<td class="line x" title="170:225	We used figurativedestination to label these relations." ></td>
	<td class="line x" title="171:225	This may or may not be the best interpretation: however, what matters here is not so much the human interpretation of the data, but rather the ability of the system at detecting the relevant semantic associations, whatever their name could be." ></td>
	<td class="line x" title="172:225	Once again in this table, notice that the common relations, like recipient (to-HUMAN_ENTITY) and destination (to-PLACE) are less frequent than expected." ></td>
	<td class="line x" title="173:225	Table 4 shows the Cl-da-C 2 relations (da=from,for, to)." ></td>
	<td class="line x" title="174:225	The most frequent relations are: MATERIAL-da-PHYSICAL_ACT (e.g materiali da imballaggio (*material from (=for) packing) legna da ardere (*wood from (=to) burn)) ARTIFACT-da-ARTIFACT (e.g cera da pavimenti (*wax for floors), lenzuola da letto (*sheets for bed)) ARTIFACT-da-PLACE (e.g giocattoli da mare (*toys for sea) abiti da montagna (*wears for mountain) MENTAL_ACT-da-BUILDING (e.g acquistare da fabbrica (*to buy from firms), comprare da oleifici (*to buy from oil-mills)) The first three relations, very frequent in the corpus, all subsume the usage relation." ></td>
	<td class="line x" title="175:225	It is interesting to notice that in Italian 'da+PLACE' commonly subsumes a source relation, just as in English (from+PLACE)." ></td>
	<td class="line x" title="176:225	The table however shows that this is not the case, at least when 'from-PLACE' cooccurs with classes such as ARTIFACT and MATERIAL." ></td>
	<td class="line x" title="177:225	The classical source sense is found in the fourth example." ></td>
	<td class="line x" title="178:225	BUILDINGs here metonymically refer to the human organization that manages an activity in the building." ></td>
	<td class="line x" title="179:225	Currently we are unable to analyze the preposition di (*of), because in the corpus it is used for the large majority to subsume the direct-object syntactic relation (e.g. vendita di frutta *sale of fruit)." ></td>
	<td class="line x" title="180:225	It turns out that the distribution of Cl-di-C 2 is too even to allow an analysis of the data." ></td>
	<td class="line x" title="181:225	Perhaps a less crude parsing strategy could help at ruling out these associations." ></td>
	<td class="line x" title="182:225	A new domain is now under examination (a legal corpus on taxation norms)." ></td>
	<td class="line x" title="183:225	A first analysis of the data shows that even for this corpus, despite it is much less jergal, several unconventional relations hold between content words." ></td>
	<td class="line x" title="184:225	5." ></td>
	<td class="line x" title="185:225	Final Remarks We spent some time at illustrating the tables to make the reader more confident with the data, and to show with several practical examples the thesis of this paper, i.e. that selectional restrictions are more fanciful than what usually appears from the literature on computational lexicons (and from dictionaries as well)." ></td>
	<td class="line x" title="186:225	The reader should not think that we selected for our application the oddest domain we could find: similar (as for fancifulness) data are being extracted from a legal corpus which is currently under examination." ></td>
	<td class="line x" title="187:225	The (semi-)automatic acquisition of selectional restrictions is only one ot the things that can be learned using clustered association data." ></td>
	<td class="line x" title="188:225	In a forthcoming paper (Basili et al. , forthcoming) the same data, clustered only by the right-hand word, are at the basis of a very reliable algorithm for syntactic disambiguation." ></td>
	<td class="line x" title="189:225	We are also experimenting concept formation algorithms for verb and noun classification (Fabrizi et al. , forthcoming)." ></td>
	<td class="line x" title="190:225	In summary, clustered associations in our view greatly improve the reliability and applicability of studies on word associations." ></td>
	<td class="line x" title="191:225	More work is necessary, because of semantic tagging, but there is an evident payoff." ></td>
	<td class="line x" title="192:225	In any case, semantic tagging is not at all the most painful manual activity in association studies." ></td>
	<td class="line x" title="193:225	Acknowledgements." ></td>
	<td class="line x" title="194:225	We thank CERVEDomani for making us available the corpus of enterprise descriptions." ></td>
	<td class="line x" title="195:225	This work has been in part supported by the European Community (PRO-ART and NOMOS ESPRIT 1991 n. 5330)." ></td>
	<td class="line x" title="196:225	Appendix: Examples of acquired conceptual associations per I) 2) 3) 4) 5) 6) 7) 8) 9) i0) ii) i) att mat 2) att ment 3) manufatto 4)entita_umana 5) vegetale 6) costruzione 7) derivato 8) materiale 9) animali i0) macchinario ll) luoghi 0.121 0.075 0.041 0.054 0.094 0.068 0.016 0.024 0.003 0.001 0.061 0.030 0.013 0.004 0.027 0.008 0.000 0.001 0.032 0.036 0.004 0.004 0.000 0.000 0 031 0.022 0.000 0.039 0.002 0.002 0 023 0.018 0.000 0.023 O.OO1 0.000 0 045 0.026 0.001 0.057 0.005 0.005 0 002 0.024 0.000 0.014 0.000 0.001 0 002 0.000 0.000 0 012 0.010 0.013 0.000 0.000 0 006 0.001 0.000 0.004 0.001 0.001 0 011 0.001 0.000 0.015 0.002 0.002 0.000 O.OlO 0.002 O.OO1 0.033 0.001 0.001 0.001 0.000 0.001 0.010 0.005 0.000 0.011 0.001 0.001 0.001 0.001 0.002 0.003 0.004 0.004 0 003 0 004 0 001 0 000 0 001 0 001 0 001 0 000 0 001 0 000 Table 1:Cl-per-C2 102 in 1) 2) 3) 4) 5) 6) 7) 8) 9) 10) 11) I) att_mat 0.019 0.048 0.023 2) att ment 0.033 0.088 0.038 0.050 0.001 0 3) manufatto 0.014 0.006 0.066 0.001 0.007 0 4)entita umana 0.004 0.009 0.000 5) vegetale 0.010 6) costruzione 0.008 0.013 0.017 7) derivato 0.001 0.001 0.006 8) materiale 0.002 0.008 9) animali I0) macchinario 0.001 ii) luoghi 0.001 0.003 0.001 0.013 0.002 0 013 0 041 0.085 0.002 0 0.001 0 0.000 0 0.001 0 0 007 0 007 0 001 0 009 0 004 0 000 0 001 0 016 0 048 092 0 121 004 0 009 006 0 000 009 0 035 005 0 005 002 0 005 0.003 0.001 0.002 Table 2:Cl-in-C2 0.000 0.053 0.004 0.074 0.001 0.009 0.010 0.001 0.020 0.004 0.008 0.001 0.000 0.000 i) 2) 3) 4) 5) 6) 7) 8) 9) I0) II) i) 2) 3) manufatto 0 005 0 4)entita_umana 0 001 0 5) vegetale 0 001 0 6) costruzione 0 007 0 7) derivato 0 000 0 8) materiale 0 002 0 9) animali 0 i0) macchinario 0.004 0 ii) luoghi 0.001 0 attmat att_ment 013 0.019 0.000 009 0\[001 0.002 001 0.002 009 0.002 0.002 001 0.000 0.001 011 000 005 0.002 005 0.007 0.020 0.084 0.032 0.020 0.018 0.002 0.006 0.001 0.025 0.036 0.037 0 351 0.077 0.055 0.008 0.019 0.016 0.005 0.001 0.024 0.049 0.004 0.001 0.002 0.000 0.005 0.005 0.002 0.000 0.002 0.001 0.008 0.001 0.001 0.002 0.001 0.007 0.004 0.004 0.001 0.001 0.004 0.003 0.000 0.001 0.002 0.002 0.003 0.002 0.001 0.017 Table 3:CI-a-C2 da i) 2) 3) 4) 5) 6) 7) 8) 9) i0) ii) I) 2) att_ment 0 3) manufatto 0 ~)entita_umana 0 5) vegetale 0 6) costruzione 0 7) derivato 0 8) materiale 0 9) animali 0 i0) macchinario 0 ii) luoghi 0 art mat 0 046 0.023 0.036 0.033 0.001 0.023 0.010 0.008 022 0.012 0.047 0.052 0.001 0.037 0.001 0.001 023 0.009 0.251 0.009 0.002 0.036 0.007 0.002 003 0.004 0.010 0.004 0.001 0.005 0.002 002 0.001 0.001 0.002 008 0.007 0.036 0.003 0.003 0.023 0.004 0.001 012 0.001 0.010 0.001 0.001 0.001 0.005 012 0.001 0.010 0.001 0.001 0.001 0.005 003 0.001 0.003 0.003 0.008 004 0.001 0.007 0.002 0.001 0.001 003 0.001 0.002 Table 4:Cl-da-C2 0.005 0 021 0.004 0 032 0.007 0 059 0 00~ 0 016 0 025 0 009 0 009 0 006 0.007 0 001 0 001 Legenda: 1) att_mat = PHYSICALACT 2) att_ment = MENTALACT 3) manufatto = ARTIFACT 4) entita umana = HUMAN_ENTITY 5) vegetale = VEGETABLE 6) costruzione = BUILDING 7) derivato = BYPRODUCT 8) materiale = MATTER 9) animali = ANIMALS 10) macchinario = MACHINE 11) luoghi = PLACES References Basili, M. T. Pazienza, P. Velardi, Using word association for syntactic disambiguation, 2nd." ></td>
	<td class="line x" title="197:225	Congress of the Italian Association for Artificial Intelligence, Palermo, 1991 B. Boguraev, Building a Lexicon: the Contribution of Computers, IBM Report, T.J. Watson Research Center, 1991 M. Brent, Automatic Aquisition of Subcategorization frames from Untagged Texts, in (ACL, 1991) N. Calzolari, R. Bindi, Acquisition of Lexical Information from Corpus, in (COLING 1990) K. W. Church, P. Hanks, Word Association Norms, Mutual Information, and Lexicography, Computational Linguistics, vol." ></td>
	<td class="line x" title="198:225	16, n. 1, March 1990." ></td>
	<td class="line x" title="199:225	K. Church, W. Gale, P. Hanks, D. Hindle, Using Statistics in Lexical Analysis, in (Zernik, 1991)." ></td>
	<td class="line x" title="200:225	S. Fabrizi, M.T.Pazienza, P. Velardi, A corpusdriven clustering algorithm for the acquisition of word ontologies, forthcoming." ></td>
	<td class="line x" title="201:225	M.Fasolo, L.Garbuio, N.Guarino, Comprensione di descrizioni di attivita' economicoproduttive espresse in linguaggio naturale, Proc." ></td>
	<td class="line x" title="202:225	of GULP Conference, Padova 1990." ></td>
	<td class="line x" title="203:225	Jo Guthrie, L. Guthrie, Y. Wilks, H. Aidinejad, Subject-dependent Co-occurrence and Word Sense Disambiguation, in (ACL, 1991)." ></td>
	<td class="line oc" title="204:225	D. Hindle, Noun classification from predicate argument structures, in (ACL,1990)." ></td>
	<td class="line x" title="205:225	D. Hindle, M. Rooths, Structural Ambiguity and Lexical Relations, in (ACL, 1991)." ></td>
	<td class="line x" title="206:225	'Lexical Semantics and Knowledge Representation' Proc." ></td>
	<td class="line x" title="207:225	of a workshop sponsored by the Special Interest Group on the Lexicon of the ACL, Ed." ></td>
	<td class="line x" title="208:225	J. Pustejovsky, June 1991 M. Macpherson, Redefining the Level of the Word, in (Lexical, 1991)." ></td>
	<td class="line x" title="209:225	A. Marziali, 'Laurea' dissertation, University of Roma II, Dept. of Electrical Engineering, in preparation M.T. Pazienza, P. Velardi, A structured Representation of Word Senses for Semantic Analysis, Third Conference of the European Chapter of ACL, Copenhagen, April 1-3, 1987." ></td>
	<td class="line x" title="210:225	F. Pereira, D. Warren, Definite Clause Grammars for Language Analysis A Survey of the Formalism and a Comparison with Augmented Transition Networks, in Artificial Intelligence, n. 13, 1980." ></td>
	<td class="line x" title="211:225	M. Russo, A generative grammar approach for the morphologic and morphosyntactic analysis of the Italian language, 3rd." ></td>
	<td class="line x" title="212:225	Conf." ></td>
	<td class="line x" title="213:225	of the European Chapter of the ACL, Copenhaghen, April 1-3 1987 J. Seo, R.F. Simmons, Syntactic Graphs a Representation for the Union of All Ambigous Parse Trees, Computational Linguistics, Vol." ></td>
	<td class="line x" title="214:225	15, n.1, March, 1989." ></td>
	<td class="line x" title="215:225	F. A. Smadja, Lexical Co-occurrence The Missing Link, Literary and Linguistic Computing, vol." ></td>
	<td class="line x" title="216:225	4, n.3, 1989." ></td>
	<td class="line x" title="217:225	F. Smadja, Macrocoding the Lexicon with Cooccurrence Knowledge, First Lexical Acquisition Workshop, August 1989, Detroit, and in (Zernik,1991)." ></td>
	<td class="line x" title="218:225	F. Smadja, K. McKewon, Automatically extracting and representing collocations for language generation, in (ACL,1990)." ></td>
	<td class="line x" title="219:225	F. Smadja, From N-Grams to Collocations an evaluation of XTRACT, in (ACL,1991)." ></td>
	<td class="line x" title="220:225	P. Velardi, M.T. Pazienza, M. De Giovanetti 'Conceptual Graphs for the Analysis and Generation of Sentences ', in IBM Journal oi R&D, special issue on language processing, March 1988 M. Webster M. Marcus, Automatic Acquisition ot lexical semantics of verbs from sentence frames, Proc." ></td>
	<td class="line x" title="221:225	of ACL89, Vancouver 1989 U. Zernik, Lexical acquisition Learning from Corpus by capitalizing on Lexical categories Proc." ></td>
	<td class="line x" title="222:225	of IJCAI 1989, Detroit 1989 U. Zernik, P. Jacobs, Tagging for Learning Collecting Thematic Relations from Corpus Proc." ></td>
	<td class="line x" title="223:225	of COLING 90, Helsinki, August 1990." ></td>
	<td class="line x" title="224:225	U. Zernik ed." ></td>
	<td class="line x" title="225:225	'Lexical Acquisition Using On-line Resources to Build a Lexicon', Lawrence Erlbaum Ass.,1991" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C92-2082
Automatic Acquisition Of Hyponyms From Large Text Corpora
Hearst, Marti A.;"></td>
	<td class="line x" title="1:201	Automatic Acquisition of Hyponyms ~om Large Text Corpora Marti A. Hearst Computer Science Division, 571 Evans Hall University of California, Berkeley Berkeley, CA 94720 and Xerox Palo Alto Research Center marti~cs, berkeley, edu Abstract We describe a method for the automatic acquisition of the hyponymy lexical relation from unrestricted text." ></td>
	<td class="line x" title="2:201	Two goals motivate the approach: (i) avoidance of the need for pre-encoded knowledge and (ii) applicability across a wide range of text." ></td>
	<td class="line x" title="3:201	We identify a set of lexico-syntactic patterns that are easily recognizable, that occur iYequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest." ></td>
	<td class="line x" title="4:201	We describe a method for discovering these patterns and suggest that other lexical relations will also be acquirable in this way." ></td>
	<td class="line x" title="5:201	A subset of the acquisition algorithm is implemented and the results are used to attgment and critique the structure of a large hand-built thesaurus." ></td>
	<td class="line x" title="6:201	Extensions and applications to areas such as information retrieval are suggested." ></td>
	<td class="line x" title="7:201	1 Introduction Currently there is much interest in the automatic acquisition of lexiea\[ syntax and semantics, with the goal of building up large lexicons for natural lain guage processing." ></td>
	<td class="line x" title="8:201	Projects that center around extracting lexical information from Machine Readable Dictionaries (MRDs) have shown much success but are inherently limited, since the set of entries within a dictionary is fixed." ></td>
	<td class="line x" title="9:201	In order to find terms and expressions that are not defined in MRDs we must turn to other textual resources." ></td>
	<td class="line x" title="10:201	For this purpose, we view a text corpus not only as a source of information, but also as a source of information about the language it is written in." ></td>
	<td class="line x" title="11:201	When interpreting unrestricted, domain-independent text, it is difficult to determine in advance what kind of infbrmation will be encountered and how it will be expressed." ></td>
	<td class="line x" title="12:201	Instead of interpreting everything in the text in great detail, we can searcil for specific lexical relations that are expressed in well-known ways." ></td>
	<td class="line x" title="13:201	Surprisingly useful information can be found with only a very simple understanding of a text." ></td>
	<td class="line x" title="14:201	Consider the following sentence: 1." ></td>
	<td class="line x" title="15:201	(SI) The bow lute, such as the Bambara ndang, is plucked and has an individual curved neck :for each string." ></td>
	<td class="line x" title="16:201	Most fluent readers of English who }lave never before encountered the term 'q3amhara ndang' will nevertheless from this sentence infer that a 'Bambara udang' is a kind of 'bow Iute'." ></td>
	<td class="line x" title="17:201	This is true even if tile reader has only a fuzzy conception of what a how lute is. Note that the attthor of the sentence is not deliberately defining the term, as would a dictionary or a children's book containing a didactic sentence like A Bambara ndang is a kind of bow lute." ></td>
	<td class="line x" title="18:201	However, the semantics of the lexico-syntactic construction indicated by the pattern: (la) NPo h as {NP1, NP2  (and Ior)} NP,, are such that they imply (lb) for all NP,, 1 < i< n, hyponym(NPi, NPo) Thus from sentence (SI) we conclude hyponym ( 'Barn bare n dang', 'how lu re')." ></td>
	<td class="line x" title="19:201	We use the term hyponym similarly to the sense used in (Miller et el." ></td>
	<td class="line x" title="20:201	1990): a concept represented by a lexicaI item L0 is said to be a hyponym of the concept represented by a lexical item LI if native speakers of English accept sentences constructed from the frame An Lo is a (kind of) L1." ></td>
	<td class="line x" title="21:201	Here Lt is the hypernym of Lo and the relationship is reflexive and transitive, but not symmetric." ></td>
	<td class="line x" title="22:201	This example shows a way to discover a hyponymic lexical relationship between two or more noun phrases in a naturally-occurring text." ></td>
	<td class="line x" title="23:201	This approach is simllar in spirit to the pattern-based interpretation techniques being used in MRD processing." ></td>
	<td class="line x" title="24:201	For example, t All examples in this paper are real text, taken from Grolter's Amerwan Acaderntc Encyclopedia(Groher tg00) AcrF.s DE COLING-92, NANTI~S, 23-28 Aol}r 1992 5 3 9 PROC." ></td>
	<td class="line x" title="25:201	OV COLING-92, NhNTIIS, AUG. 23-28, 1992 (Alshawi 1987), in interpreting LDOCE definitions, uses a hierarchy of patterns which consist mainly of part-of-speech indicators and wildcard characters." ></td>
	<td class="line x" title="26:201	(Markowitz e~ al. 1986), (Jensen & Binot 1987), and (Nakamura & Nagao 1988) also use pattern recognition to extract semantic relations such as taxonomy from various dictionaries." ></td>
	<td class="line x" title="27:201	(Ahlswede & Evens I988) compares an approach based on parsing Webster's 7th definitions with one based on pattern recognition, and finds that for finding simple semantic relations, pattern recognition \[s far more accurate and efficient than parsing." ></td>
	<td class="line x" title="28:201	The general feeling is that the structure and function of MRDs makes their interpretation amenable to pattern-recognition techniques." ></td>
	<td class="line x" title="29:201	Thus one could say by interpreting sentence (S1) according to (In-b) we are applying pattern-based relation recognition to general texts." ></td>
	<td class="line x" title="30:201	Since one of the goals of building a lexical hierarchy automatically is to aid in the construction of a natural language processing program, this approach to acquisition is preferable to one that needs a complex parser ~nd knowledge base." ></td>
	<td class="line x" title="31:201	The tradeoff is that the the reformation acquired is coarse-grained." ></td>
	<td class="line x" title="32:201	There are many ways that the structure of a language can indicate the meanings of lexical items, but the difficulty lies in finding constructions that frequently and reliably indicate the relation of interest." ></td>
	<td class="line x" title="33:201	It might seem tbat because free text is so varied in form and content (as compared with the somewhat regular structure of the dictionary) that it may not be possible to find such constructions." ></td>
	<td class="line x" title="34:201	However, we have identified a set of lexico-syntactic patterns, including the one shown in (In) above, that indicate the hyponymy relation and that satisfy the following desiderata: (i) They occur frequently and in many text genres." ></td>
	<td class="line x" title="35:201	(ii) They (almost) always indicate the relation of interest." ></td>
	<td class="line x" title="36:201	(iii) They can be recognized with little or no preencoded knowledge." ></td>
	<td class="line x" title="37:201	Item (i) indicates that the pattern will result in the discovery of many instances of the relation, item (ii) that the information extracted will not be erroneous, and item (iii) that making use of the pattern does not require the tools that it is intended to help build." ></td>
	<td class="line x" title="38:201	Finding instances of the hyponymy relation is useful for several purposes: Lexicon Augmentation." ></td>
	<td class="line x" title="39:201	Hyponymy relations can be used to augment and verify existing lexicons, including ones built from MRDs." ></td>
	<td class="line x" title="40:201	Section 3 of this paper describes an example, comparing results extracted from a text corpus with information stored in the noun hierarchy of WordNet ((Miller et al. 1990)), a hand-built lexical thesaurus." ></td>
	<td class="line x" title="41:201	Noun Phrase Semantics." ></td>
	<td class="line x" title="42:201	Another purpose to which these relations can be applied is the identification of the general meaning of an unfamiliar noun phrases." ></td>
	<td class="line x" title="43:201	For example, discovering the predicate hyponym( 'broken bone', 'injury') indicates that tbe term 'broken bone' can be understood at some level as an 'injury' without having to determine the correct senses of the component words and how they combine." ></td>
	<td class="line x" title="44:201	Note also that a term like 'broken bone' is not likely to appear in a dictionary or lexicon, although it is a common locution." ></td>
	<td class="line x" title="45:201	Semantic Relatedness Information." ></td>
	<td class="line oc" title="46:201	There bas recently been work in the detection of semantically related nouns via, for example, shared argument structures (Hindle 1990), and shared dictionary definition context (Wilks e al. 1990)." ></td>
	<td class="line o" title="47:201	These approaches attempt to infer relationships among \[exical terms by looking at very large text samples and determining which ones are related in a statistically significant way." ></td>
	<td class="line x" title="48:201	The technique introduced in this paper can be seen as having a similar goal but an entirely different approach, since only one sample need be found in order to determine a salient relationship (and that sample may be infrequently occurring or nonexistent)." ></td>
	<td class="line x" title="49:201	Thinking of the relations discovered as closely related semantically instead of as hyponymic is most felicitous when the noun phrases involved are modified and atypical." ></td>
	<td class="line x" title="50:201	Consider, for example, the predicate hyponym( 'detonating explosive', 'blasting agent') This relation may not be a canonical ISA relation but the fact that it was found in a text implies that the terms' meanings are close." ></td>
	<td class="line x" title="51:201	Connecting terms whose expressions are quite disparate but whose meanings are similar should be useful for improved synonym expansion in information retrieval and for finding chains of semantically related phrases, as used in the approach to recognition of topic boundaries of (Morris Hirst 1991)." ></td>
	<td class="line x" title="52:201	We observe that terms that occur in a list are often related semantically, whether they occur in a hyponymy relation or not." ></td>
	<td class="line x" title="53:201	In the next section we outline a way to discover these lexico-syntactic patterns as well as illustrate those we have found." ></td>
	<td class="line x" title="54:201	Section 3 shows the results of searching texts for a restricted version of one of the patterns and compares the results against a hand-built thesaurus." ></td>
	<td class="line x" title="55:201	Section 4 is a discussion of the merits of this work and describes future directions." ></td>
	<td class="line x" title="56:201	2 Lexico-Syntactic Patterns for Hyponymy Since only a subset of the possible instances of the hyponymy relation will appear in a particular form, we need to make use of as many patterns as possible." ></td>
	<td class="line x" title="57:201	Below is a list of lexico-syntactie patterns that indicate the hyponymy relation, followed by illustrative sentence fragments and the predicates that can ACTI~S DE COLING-92, NANTES, 23-28 AOt~r 1992 5 4 0 PROC." ></td>
	<td class="line x" title="58:201	OF COLING-92, NANTES, AUG. 23-28, 1992 be derived from them (detail about the environment surrounding tile patterns is omitted for simplicity): (2)  h NP us {NP,}* {(or \[ and)} NP  works by such authors as Herrick, Goldsmith, and Shakespeare." ></td>
	<td class="line x" title="59:201	hyf)onym I'~author', 'Ilerrick'), llyponym( 'author', '(;oldsmith '), hyponynl( 'author', 'Shakespeare') (3) NP {, NP} * {,} o,' other NP Bruises, wounds, broken bones or other injuries . . ." ></td>
	<td class="line x" title="60:201	~ hyponym( 'bruise'." ></td>
	<td class="line x" title="61:201	'injury'), hyponym ( 'wo und', 'mj ury' ), hyponym( 'broken bone', 'injury') (4) NP {, NP}* {,} and other NP  temples, treasuries,altd other important civic buildings." ></td>
	<td class="line x" title="62:201	:~hyponym('tenlple', 'civic' building'), hyponym( 'treasury ', 'civic building') (5) m, {,} .~clsa,,~y {NP 5* {o,." ></td>
	<td class="line x" title="63:201	' a} NP All common-law countries, including Canada and England  -~, hyponym( 'Canada', 'collllnou--law coon try'), flyponym ( 'Eng\]and', 'common-law co lm try') (6) NP {,} especially {NP,}* {or\] and} NP  most: European countries, especially France, England, and Spain." ></td>
	<td class="line x" title="64:201	~ hyponym( 'France', 'European country'), hyponym( 'England', 'European country'), hypouym( 'Spain', 'European country') When a relation hyponym(NPo, NI'I) is discovered, aside from some temmatizing and removal of unwanted modifiers, tile uonn phrase is left as all atomic unit, not broken clown and analyzed." ></td>
	<td class="line x" title="65:201	Ira more detailed interpretation is desired, the results can be passed on to a more intelligent or specialized language analysis component." ></td>
	<td class="line x" title="66:201	And, as mentioned above, this kind of discovery procedure can be a partial solution for a problenr like noun phrase interpretation because at least part of the meaning of the phrase is indicated by tile hyponymy relation." ></td>
	<td class="line x" title="67:201	and we usually want them to be singular." ></td>
	<td class="line x" title="68:201	Adjectival quantiflers such as 'other' and 'some' are usually undesirable and can be eliminated in most cases without making the statement of tile hypouym relation erroneous." ></td>
	<td class="line x" title="69:201	('omparatives SUCh as 'inlportaat' and 'smaller' are usually best removed, since their meaning \[s relative and dependent on tile context in which they appear." ></td>
	<td class="line x" title="70:201	Ilow much modification is desirable depends on the application to which the lexical relations will be put." ></td>
	<td class="line x" title="71:201	For budding up a basic, general-domain thesaurus, single-word uouns and very cOnllnon colnpouuds are most appropriate." ></td>
	<td class="line x" title="72:201	For a inore specialized domain, umre modified terms have their place." ></td>
	<td class="line x" title="73:201	Per example, noun phrases in ~he me(licai lontain otteu have several layers of modification which should be preserved in a taxonomy of medical terms." ></td>
	<td class="line x" title="74:201	Other difficulties and concerns are discussed ill Section a. 2.2 Discovery of New Patterns How can these patterns be found?" ></td>
	<td class="line x" title="75:201	Initially we discovered patterns (1)(3) 5y observation, looldug through text and noticing die patterns and tile relationships they indicate, lu order to find new patterns automatically, we sketch the following procedure: 1." ></td>
	<td class="line x" title="76:201	l)ecide on a lexical relation, R, that is of interest, e.g., 'gro up/member'(iu our formulation this is a subset of the hypouylny relation)." ></td>
	<td class="line x" title="77:201	2." ></td>
	<td class="line x" title="78:201	Gather a list of terms for which this relation is known to hold, e.g., 'England-country'." ></td>
	<td class="line x" title="79:201	This list can be found autonmtically using the method described here, bootstrapping from patterns found by hand, or by bootstrapping from an existing lexicon or knowledge base." ></td>
	<td class="line x" title="80:201	3." ></td>
	<td class="line x" title="81:201	Find places in tile corpus where these expressions occur syntactically near one another and record the environment." ></td>
	<td class="line x" title="82:201	4." ></td>
	<td class="line x" title="83:201	t,'ind the commonaflties among these environi~leuts and hypothesize that corn.men ones yield patterns that indicate the relation of interest." ></td>
	<td class="line x" title="84:201	5." ></td>
	<td class="line x" title="85:201	Once a new pattern has been positively identified, use it to gather more instances of the target relation and go to Step 2." ></td>
	<td class="line x" title="86:201	2.1 Some Considerations In example (4) above, the full noun phrase corresponding to the hypernym is 'other important civic buildings'." ></td>
	<td class="line x" title="87:201	This illustrates a difficulty that arises from using free text as the data source, as opposed to a dictionary often the form that a noun phrase occurs in is not what we would like to record." ></td>
	<td class="line x" title="88:201	For example, nouns frequently occur in their plural form We tried this procedure by hand using just one pair of terms at a time." ></td>
	<td class="line x" title="89:201	In the first case we tried the 'Fngland-country' example, and with just this pair we tound uew patterns (4) and (5), as well as (1) (3) which were already known." ></td>
	<td class="line x" title="90:201	Next we tried 'tankvehicle' and discovered a very productive pattern, pattern (6)." ></td>
	<td class="line x" title="91:201	(Note that for this pattern, even though it has an emphatic element, this does not affect the fact that the relation indicated is hypouymic)." ></td>
	<td class="line x" title="92:201	AcrEs DE COLING-92, N^mEs, 23-28 hotrr 1992 5 4 1 l)Roc, ov COLING-92, NAbrrEs, AUG. 23-28, 1992 We have tried applying this technique to meronymy (i.e. , the part/whole relation), but without great success." ></td>
	<td class="line x" title="93:201	The patterns fotu~.d for this relation do not tend to uniquely identify it, but can be used to express other relations as well." ></td>
	<td class="line x" title="94:201	It may be the case that in English the hyponymy relation is especially amenable to this kind of analysis, perhaps due to its 'naming' nature." ></td>
	<td class="line x" title="95:201	However, we have bad some success at identification of more specific relations, such as patterns that indicate certain types of proper nouns." ></td>
	<td class="line x" title="96:201	We have not implemented an automatic version of this algorithm, primarily because Step 4 is underdetermined." ></td>
	<td class="line x" title="97:201	2.3 Related Work This section discusses work in acquisition of lexical information from text corpora, although as mentioned earlier, significant work has been done in acquiring lexical information from MRDs." ></td>
	<td class="line x" title="98:201	(Coates-Stephens 1991) acquires semantic descriptions of proper nouns in a system called FUNES." ></td>
	<td class="line x" title="99:201	FUNES attempts to fill in frame roles, (e.g. , name, age~ origin, position, and works-for, for a person frame) by processing newswire text." ></td>
	<td class="line x" title="100:201	This system is similar to the work described here in that it recognizes some features of the context in which the proper noun occurs in order to identify some relevant semantic attributes." ></td>
	<td class="line x" title="101:201	For instance." ></td>
	<td class="line x" title="102:201	Coates-Stephens mentions that 'known as' can explicitly introduce meanings for terms, as can appositives." ></td>
	<td class="line x" title="103:201	We also have considered these markers, hut the tbrmer often does not cleanly indicate 'another name for' and the latter is difficult to recognize accurately." ></td>
	<td class="line x" title="104:201	FUNES differs quite strongly from our approach in that, because it is able to fill in many kinds of frame roles, it requires a parser that produces a detailed structure, and it requires a domain-dependent knowlege base/lexicon." ></td>
	<td class="line x" title="105:201	(Velardi & Pazienza 1989) makes use of hand-coded selection restriction and conceptual relation rules in order to assign case roles to lexical items, and (Jacobs & Zernik 1988) uses extensive domain knowledge to fill in missing category information for unknown words." ></td>
	<td class="line x" title="106:201	Work on acquisition of syntactic information from text corpora includes Brent's (Brent 1991) verb subcategorization frame recognition technique and Smadja's (Smadja & McKeown 1990) collocation acquisition algorithm." ></td>
	<td class="line x" title="107:201	(Calzolari & Bindi 1990) use corpus-based statistical association ratios to determine lexical information such as prepositional complementation relations, modification relations, and significant compounds." ></td>
	<td class="line x" title="108:201	Our methodology is similar to Brent's in its effort to distinguish clear pieces of evidence from ambiguous ones." ></td>
	<td class="line x" title="109:201	The assumption is that that given a large enough corpus, the algorithm can afford wait until it encounters clear examples." ></td>
	<td class="line x" title="110:201	Brent's algorithm relies on a clever trick: in the configuration of interest (in this case, verb valence descriptions), where noun phrases are the source of ambiguity, it uses only sentences which have pronouns in the crucial position, since pronouns do not allow this ambiguity." ></td>
	<td class="line x" title="111:201	This approach is qnite effective, but the disadvantage is that it isn't clear that it is applicable to any other tasks." ></td>
	<td class="line x" title="112:201	The approach presented in this paper, using the algorithm sketched in the previous subsection, is potentially extensible." ></td>
	<td class="line x" title="113:201	3 Incorporating Results into WordNet To validate this acquisition method, we compared the results of a restricted version of the algorithm with information found in WordNet." ></td>
	<td class="line x" title="114:201	2 WordNet (Miller et al. 1990) is a hand-built online thesaurus whose organization is modeled after the results of psycbolinguistic research." ></td>
	<td class="line x" title="115:201	To use tile authors' words, Wordnet ' is an attempt to organize lexical information in terms of word meanings, rather than word forms." ></td>
	<td class="line x" title="116:201	In that respect, WordNet resembles a thesaurus more than a dictionary ' To this end, word forms with synonymous meanings are grouped into sets, called synsets." ></td>
	<td class="line x" title="117:201	This allows a distinction to be made between senses of homographs." ></td>
	<td class="line x" title="118:201	For example, the noun 'board' appears in the synsets {board, plank} and {board, committee}, and this grouping serves for the most part as the word's definition." ></td>
	<td class="line x" title="119:201	In version 1.1, WordNet contains about 34,000 noun word forms, including some compounds and proper nouns, organized into about 26,000 synsets." ></td>
	<td class="line x" title="120:201	Noun synsets are organized hierarchically according to the hyponymy relation with implied inheritance and are further distinguished by values of features such as meronymy." ></td>
	<td class="line x" title="121:201	WordNet's coverage and structure are impressive and provide a good basis for an automatic acquisition algorithm to build on." ></td>
	<td class="line x" title="122:201	When comparing a result hyponym(No,Nt) to the contents of WordNet's noun hierarchy, three kinds of outcomes are possible: Verify." ></td>
	<td class="line x" title="123:201	If both No and Nt are in WordNet, and if the relation byponym(No,N1) is in the hierarchy (possibly througi~ transitive closure) then the thesaurus is verified." ></td>
	<td class="line x" title="124:201	Critique." ></td>
	<td class="line x" title="125:201	If both No and N1 are in WordNet, and if the relation hyponym(No, N1) is not in the hierarchy (even through transitive closure) then the thesaurus is critiqued, i.e., a new set of hyponym connections is suggested." ></td>
	<td class="line x" title="126:201	Augment." ></td>
	<td class="line x" title="127:201	If one or both of No and NI are not present then these noun phrases and their relation are suggested as entries." ></td>
	<td class="line x" title="128:201	As an example of critiquing, consider the following 2The author thanks Miller, et al,, for the distribution of WordNet." ></td>
	<td class="line x" title="129:201	AcrEs DE COL1NG-92, NANTES, 23-28 AoU'r 1992 5 4 2 PRec." ></td>
	<td class="line x" title="130:201	OF COLING-92, NANTES, AUG. 23-28, 1992 sentence and derived relation: (S2) Other input-output devces, such as printers, color plotzers,  ~ hyponym('~rinter','~npnt-mltput device') The text indicates that a printer is a kind of inputoutput device." ></td>
	<td class="line x" title="131:201	Figure 1 indicates tile portion of tile hyponymy relation in WordNet's noun hierarchy that has to do with printers and devices." ></td>
	<td class="line x" title="132:201	Note ;although the terms device and printer are present, they are not linked in such as way as to allow the easy insertion UO device under the more general dewce and over the more specific printer." ></td>
	<td class="line x" title="133:201	Although it is not obvious what to suggest to fix this portion of the hierarchy from this one relation ~done, it is clear that its discovery highlights a trouble spot ill tile sstructure.,__/_'-._._, Figure t: A Fragment of the WordNet Noun Hierarchy." ></td>
	<td class="line x" title="135:201	Syasets are enclosed in braces; most synsets have more connections than those shown." ></td>
	<td class="line x" title="136:201	aereal~: ricu* ~heat* countries: Cuba Vietnam France* hydrocarbon: ethylene ~ubstances: bromine* hydrogen* protozoa: parameclum liqueurs: anisette* absinthe* rocks: graltlte* substances: phosphorus* nitrogen* species: stuatornis oilbirds bivalves: scallop* fungi: smuts* rusts* fabrics: acrylics* nylon* silk* antibiotlcS: amplcillin erythromycln* institutions: temples king seabirds: penguins albatross* flatworms: tapeworms pla~aria amphibians: frogs* ~aterfowl: ducks legumes: lentils* beans* nuts org~lisms: horsetails ferns mosses rivers: Sevier Ca\[rson Humboldt fruit: olives* grapes* hydrocarbons: benzene gasolne ideologies: liberalism conservatism industries: steel iron shoes min.rals: pyrite* galena phenomena: lightning* infection; menlngltis dyes: quercitron Figure 2: Relations found in Grolier's." ></td>
	<td class="line x" title="137:201	The format is hypernym: hyponyrn list." ></td>
	<td class="line x" title="138:201	Entries with * indicate relations found in WordNet." ></td>
	<td class="line x" title="139:201	Most of the terms in WordNet's noun hierarchy are unmodified nouns or nouns with a single modifier." ></td>
	<td class="line x" title="140:201	For this reason, ill this experiment we only extracted relations consisting of mmmdified nouns in both the hypernym and hypouym roles (although determiners are allowed and a very small set of quantifier adjectives: 'some', 'many', 'certain', and 'other')." ></td>
	<td class="line x" title="141:201	Making this restriction is also usethl because of the difficulties with determining which modifiers are significant, as touched on above, and because it seems easier to make a judgement call about the correctness of the classification of unmodified nouns for evaluation purposes." ></td>
	<td class="line x" title="142:201	Since we are trying to acquire lexical information our parsing mechanism should not be one that requires extensive lexicat information." ></td>
	<td class="line x" title="143:201	In order to detect the lexico-syntactic patterns, we use a unification-based constituent analyzer (taken from (Batali 1991)), which builds on the output of a part-or=speech tagger (Cutting el al. 1991)." ></td>
	<td class="line x" title="144:201	(All code described in this report is written m Common Lisp and run on Sun SparcStations)." ></td>
	<td class="line x" title="145:201	We wrote grammar rules for the constituent analyzer to recognize the pattern in (la)." ></td>
	<td class="line x" title="146:201	As mentioned above, in this experiment we are detecting only unmodified nouns." ></td>
	<td class="line x" title="147:201	Therefore, when a noun is found in the hypernym position, that is, before the lexemes 'such as', we check for the noun's inclusion in a relative clause, or as part of a larger noun phrase that includes an appositive or a parenthetical." ></td>
	<td class="line x" title="148:201	Using tile constituent analyzer, it is not necessary to parse the entire selltence; instead we look at just enough local context around the iexical items in the pattern to ensure that tile nouns in tile pattern are isolated." ></td>
	<td class="line x" title="149:201	After the hypernym is detected the hyponyms are identified." ></td>
	<td class="line x" title="150:201	Often they occur ill a llst and each element ill the list holds a hyponym relation with the hypernym." ></td>
	<td class="line x" title="151:201	The main difficulty here lies m determining the extent of the last term in the list." ></td>
	<td class="line x" title="152:201	3.1 Results and Evaluation Figure 2 illustrates some of the results of a run of the acquisition algorithm on Grolier's American Academic Encyelopedia(Grolier 1990), where a restricted version of pattern (la) is the target (space constraints do not allow a full listing of the results)." ></td>
	<td class="line x" title="153:201	After the relations are found they are looked up in WordNet." ></td>
	<td class="line x" title="154:201	We placed the WordNet noun hierarchy into a b-tree data structure for efficient retrieval and update and used a breadth-first-search to search through the transitive closure." ></td>
	<td class="line x" title="155:201	Ont of 8.6M words of encyclopedia text, there are AcrEs DE COL1NG-92, NANt .'F.S, 23-28 ho,,~'r 1992 5 4 3 Paoc." ></td>
	<td class="line x" title="156:201	ov COLING-92, NANTES, AUO." ></td>
	<td class="line x" title="157:201	23-28, 1992 7067 sentences that contain tile lexemes 'such as' contiguously." ></td>
	<td class="line x" title="158:201	Out of these, 152 relations fit tile restrictions of the experiment, namely that both the hyponyms and the hypernyms are unmodified (with the exceptions mentioned above)." ></td>
	<td class="line x" title="159:201	When the restrictions were eased slightly, so that NPs consisting of two nouns or a present/past participle plus a noun were allowed, 330 relations were found." ></td>
	<td class="line x" title="160:201	Wheu the latter experiment was run o21 about 20M words of New York Times text, 3178 sentences contained 'such as' contiguously, and 46 relations were found using the strict no-modifiers criterion." ></td>
	<td class="line x" title="161:201	Wilen the set of t52 Grolier's relations was looked up in WordNet, 180 out of the 226 mlique words involved in the relations actually existed in the hierarchy, and 61 out of the 106 feasible relations (i.e. , relations in which both terms were already registered in WordNet) were found." ></td>
	<td class="line x" title="162:201	The quality of the relations found seems high overall, although there are difficulties." ></td>
	<td class="line x" title="163:201	As to be expected, metonymy occurs, as seen in hyponym('king', 'institution')." ></td>
	<td class="line x" title="164:201	A more common problem is underspecification." ></td>
	<td class="line x" title="165:201	For example, one relation is hyponym( 'steatornis', 'species'), which is problematic because what kind of species needs to be known and most likely this reformation was mentioned in the previous sentence." ></td>
	<td class="line x" title="166:201	Similarly, relations were found between 'device' and 'plot', 'metaphor', and 'character', underspecifying the fact that literary devices of some sort are under discussion." ></td>
	<td class="line x" title="167:201	Sometimes the relationship expressed is slightly askance of the norm." ></td>
	<td class="line x" title="168:201	For example, the algorithm finds hyponym( 'Washington', 'nationalist')and hyponym( 'aircraft', 'target') which are somewhat context and point-of-view dependent." ></td>
	<td class="line x" title="169:201	This is not necessarily a problem; as mentioned above, finding alternative ways of stating similar notions is one of our goals." ></td>
	<td class="line x" title="170:201	However, it is important to try to distinguish the more canonical and context-independent relations for entry in a thesaurus." ></td>
	<td class="line x" title="171:201	There are a few relations whose hypernyms are very high-level terms, e.g., 'substance' aud 'form'." ></td>
	<td class="line x" title="172:201	These are not incorrect; they just may not be as useful as more specific relations." ></td>
	<td class="line x" title="173:201	Overall, the results are encouraging." ></td>
	<td class="line x" title="174:201	Although the number of relations found is small compared to the size of the text used, this situation can he greatly improved in several ways." ></td>
	<td class="line x" title="175:201	Less stringent restrictions will increase the numbers, as the slight loosening shown in the Grolier's experiment indicates." ></td>
	<td class="line x" title="176:201	A more savvy grammar for the constituent analyzer should also increase the results." ></td>
	<td class="line x" title="177:201	3.2 Automatic Updating The question arises as to how to automatically insert relations between terms into the hierarchy." ></td>
	<td class="line x" title="178:201	This involves two main difficulties." ></td>
	<td class="line x" title="179:201	First, if both lexical expressions are present in the noun hierarchy but one or both }lave more than one sense, the algorithm must decide which senses to link together." ></td>
	<td class="line x" title="180:201	We have preliminary ideas as to how to work around this problem." ></td>
	<td class="line x" title="181:201	Say the hyponym in question has only one sense, but the hypernym has several." ></td>
	<td class="line x" title="182:201	Then the task is simplified to determining which sense of the hypernym to link the hypouym to." ></td>
	<td class="line x" title="183:201	We can then make use of a lexical disambiguation algorithm, e.g., (Hearst 1991), to determine which sense of the hypernym is being used iu the sample sentence." ></td>
	<td class="line x" title="184:201	Furthermore, since we've assumed the hyponym has only one main sense we could do tile following: Look through a corpus for occurrences of the hyponym and see if its environment tends to be similar to one of the senses of its hypernym." ></td>
	<td class="line x" title="185:201	For example, if the hypernym is 'bank' and the hyponym is 'First National', every time, within a sample of text, the term 'First National' occurs, replace it with 'bank', and then run the disambiguation algorithm as usual." ></td>
	<td class="line x" title="186:201	If this term can be positively classified as having one sense of bank over the others, then this would provide strong evidence as to which sense of the hypernym to link the hypouym to." ></td>
	<td class="line x" title="187:201	This idea is purely speculative; we have not yet tested it." ></td>
	<td class="line x" title="188:201	The second main problem with inserting new relations arises when one or both terms do not occur in the hierarchy at all." ></td>
	<td class="line x" title="189:201	In this case, we have to determine which, if any, existing synset the term belongs in and then do the sense determination mentioned above." ></td>
	<td class="line x" title="190:201	4 Conclusions We have described a low-cost approach for automatic acquisition of semantic lexical relations from uurestricted text." ></td>
	<td class="line x" title="191:201	This method is meant to provide an incremental step toward the larger goals of natural language processing." ></td>
	<td class="line x" title="192:201	Our approach is complementary to statistically based approaches that find semantic relations between terms, iu that ours requires a single specially expressed instance of a relation while the others require a statistically significant number of generally expressed relations." ></td>
	<td class="line x" title="193:201	We've shown that our approach is also useful as a critiquing component for existing knowledge bases and lexicons." ></td>
	<td class="line x" title="194:201	We plan to test the pattern discovery algorithm on more relations and on languages other than English (depending on the corpora available)." ></td>
	<td class="line x" title="195:201	We would also like to do some analysis of the noun phrases that are acquired, and to explore the effects of various kinds of modifiers on the appropriateness of the noun phrase." ></td>
	<td class="line x" title="196:201	We plan to do this in the context of analyzing environmental impact reports." ></td>
	<td class="line x" title="197:201	Acknowledgements." ></td>
	<td class="line x" title="198:201	This work was supported in part by an internship at tile Xerox Palo Alto Research Center and in part by the University of California and Digital Equipment Corporation under Digital's flagAcrEs DE COLING-92, NANTES, 23-28 ^o~-r 1992 5 4 4 PRoc." ></td>
	<td class="line x" title="199:201	OF COLING-92." ></td>
	<td class="line x" title="200:201	NANTES, Auo." ></td>
	<td class="line x" title="201:201	23-28, 1992 ship research project Sequoia 2000: Large Capacity Object Servers to Support Global Change Research." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P92-1028
Corpus-Based Acquisition Of Relative Pronoun Disambiguation Heuristics
Cardie, Claire;"></td>
	<td class="line x" title="1:330	CORPUS-BASED ACQUISITION OF RELATIVE PRONOUN DISAMBIGUATION HEURISTICS Claire Cardie Department of Computer Science University of Massachusetts Amherst, MA 01003 E-mail: cardie@cs.umass.edu ABSTRACT This paper presents a corpus-based approach for deriving heuristics to locate the antecedents of relative pronouns." ></td>
	<td class="line x" title="2:330	The technique dupficates the performance of hand-coded rules and requires human intervention only during the training phase." ></td>
	<td class="line x" title="3:330	Because the training instances are built on parser output rather than word cooccurrences, the technique requires a small number of training examples and can be used on small to medium-sized corpora." ></td>
	<td class="line x" title="4:330	Our initial results suggest that the approach may provide a general method for the automated acquisition of a variety of disambiguation heuristics for natural language systems, especially for problems that require the assimilation of syntactic and semantic knowledge." ></td>
	<td class="line x" title="5:330	1 INTRODUCTION State-of-the-art natural language processing (NLP) systems typically rely on heuristics to resolve many classes of ambiguities, e.g., prepositional phrase attachment, part of speech disambiguation, word sense disambiguation, conjunction, pronoun resolution, and concept activation." ></td>
	<td class="line x" title="6:330	However, the manual encoding of these heuristics, either as part of a formal grammar or as a set of disarnbiguation rules, is difficult because successful heuristics demand the assimilation of complex syntactic and semantic knowledge." ></td>
	<td class="line x" title="7:330	Consider, for example, the problem of prepositional phrase attachment." ></td>
	<td class="line x" title="8:330	A number of purely structural solutions have been proposed including the theories of Minimal Attachment (Frazier, 1978) and Right Association (Kimball, 1973)." ></td>
	<td class="line x" title="9:330	While these models may suggest the existence of strong syntactic preferences in effect during sentence understanding, other studies provide clear evidence that purely syntactic heuristics for prepositional phrase attachment will not work (see (Whittemore, Ferrara, & Brunner, 1990), (Taraban, & McClelland, 1988))." ></td>
	<td class="line x" title="10:330	However, computational linguists have found the manual encoding of disarnbiguation rules -especially those that merge syntactic and semantic constraints -to be difficult, time-consuming, and prone to error." ></td>
	<td class="line x" title="11:330	In addition, hand-coded heuristics are often incomplete and perform poorly in new domains comprised of specialized vocabularies or a different genre of text." ></td>
	<td class="line x" title="12:330	In this paper, we focus on a single ambiguity in sentence processing: locating the antecedents of relative pronouns." ></td>
	<td class="line x" title="13:330	We present an implemented corpus-based approach for the automatic acquisition of disambiguation heuristics for that task." ></td>
	<td class="line x" title="14:330	The technique uses an existing hierarchical clustering system to determine the antecedent of a relative pronoun given a description of the clause that precedes it and requires only minimal syntactic parsing capabilities and a very general semantic feature set for describing nouns." ></td>
	<td class="line x" title="15:330	Unlike other corpus-based techniques, only a small number of training examples is needed, making the approach practical even for small to medium-sized online corpora." ></td>
	<td class="line x" title="16:330	For the task of relative pronoun disambignation, the automated approach duplicates the performance of hand-coded rules and makes it possible to compile heuristics tuned to a new corpus with little human intervention." ></td>
	<td class="line x" title="17:330	Moreover, we believe that the technique may provide a general approach for the automated acquisition of disambiguation heuristics for additional problems in natural language processing." ></td>
	<td class="line x" title="18:330	In the next section, we briefly describe the task of relative pronoun disambiguation." ></td>
	<td class="line x" title="19:330	Sections 3 and 4 give the details of the acquisition algorithm and evaluate its performance." ></td>
	<td class="line x" title="20:330	Problems with the approach and extensions required for use with large corpora of unrestricted text are discussed in Section 5." ></td>
	<td class="line x" title="21:330	2 DISAMBIGUATING RELATIVE PRONOUNS Accurate disambiguation of relative pronouns is important for any natural language processing system that hopes to process real world texts." ></td>
	<td class="line x" title="22:330	It is especially a concern for corpora where the sentences tend to be long and information-packed." ></td>
	<td class="line x" title="23:330	Unfortunately, to understand a sentence containing a relative pronoun, an NLP system must solve two difficult problems: the system has to locate the antecedent of the relative pronoun and then determine the antecedent's implicit position in the embedded clause." ></td>
	<td class="line x" title="24:330	Although finding the gap in the embedded clause is an equally difficult 216 problem, the work we describe here focuses on locating the relative pronoun antecedent.1 This task may at first seem relatively simple: the antecedent of a relative pronoun is just the most recent constituent that is a human." ></td>
	<td class="line x" title="25:330	This is the case for sentences S1-$7 in Figure 1, for example." ></td>
	<td class="line x" title="26:330	However, this strategy assumes that the NLP system produces a perfect syntactic and semantic parse of the clause preceding the relative pronoun, including prepositional phrase attachment (e.g. , $3, $4, and $7) and interpretation of conjunctions (e.g. , $4, $5, and $6) and appositives (e.g. , $6)." ></td>
	<td class="line x" title="27:330	In $5, for example, the antecedent is the entire conjunction of phrases (i.e. , 'Jim, Terry, and Shawn'), not just the most recent human (i.e. , 'Shawn')." ></td>
	<td class="line x" title="28:330	In $6, either s1." ></td>
	<td class="line x" title="29:330	Tony saw the boy who won the award." ></td>
	<td class="line x" title="30:330	$2." ></td>
	<td class="line x" title="31:330	The boy who gave me the book had red hair." ></td>
	<td class="line x" title="32:330	$3." ></td>
	<td class="line x" title="33:330	Tony ate dinner with the men from Detroit who sold computers." ></td>
	<td class="line x" title="34:330	$4." ></td>
	<td class="line x" title="35:330	I spoke to the woman with the black shirt and green hat over in the far comer of the room whc wanted a second interview." ></td>
	<td class="line x" title="36:330	SS." ></td>
	<td class="line x" title="37:330	I'd like to thank Jim." ></td>
	<td class="line x" title="38:330	Terry, and Shawn, who provided the desserts." ></td>
	<td class="line x" title="39:330	$6." ></td>
	<td class="line x" title="40:330	I'd like to thank our sponsors, GE andNSF, who provide financial support." ></td>
	<td class="line x" title="41:330	ST. The woman from Philadelphia who played soccer was my sister." ></td>
	<td class="line x" title="42:330	$8." ></td>
	<td class="line x" title="43:330	The awards for the children who pass the test are in the drawer." ></td>
	<td class="line x" title="44:330	$9." ></td>
	<td class="line x" title="45:330	We wondered who stole the watch." ></td>
	<td class="line x" title="46:330	S10." ></td>
	<td class="line x" title="47:330	We talked with the woman and the man who danced." ></td>
	<td class="line x" title="48:330	Figure 1." ></td>
	<td class="line x" title="49:330	Examples of Relative Pronoun Antecedents 'our sponsors' or its appositive 'GE and NSF' is a semantically valid antecedent." ></td>
	<td class="line x" title="50:330	Because pp-attachment and interpretation of conjunctions and appositives remain difficult for current systems, it is often unreasonable to expect reliable parser output for clauses containing those constructs." ></td>
	<td class="line x" title="51:330	Moreover, the parser must access both syntactic and semantic knowledge in finding the antecedent of a relative pronoun." ></td>
	<td class="line x" title="52:330	The syntactic structure of the clause preceding 'who' in $7 and $8, for example, is identical (NP-PP) but the antecedent in each case is different." ></td>
	<td class="line x" title="53:330	In $7, the antecedent is the subject, 'the woman;' in $9, it is the prepositional phrase 1For a solution to the gap-finding problem that is consistent with the simplified parsing strategy presented below, see (Cardie & Lehnert, 1991)." ></td>
	<td class="line x" title="54:330	modifier, 'the children'." ></td>
	<td class="line x" title="55:330	Even if we assume a perfect parse, there can be additional complications." ></td>
	<td class="line x" title="56:330	In some cases the antecedent is not the most recent constituent, but is a modifier of that constituent (e.g. , $8)." ></td>
	<td class="line x" title="57:330	Sometimes there is no apparent antecedent at all (e.g. , $9)." ></td>
	<td class="line x" title="58:330	Other times the antecedent is truly ambiguous without seeing more of the surrounding context (e.g. , S10)." ></td>
	<td class="line x" title="59:330	As a direct result of these difficulties, NLP system builders have found the manual coding of rules that find relative pronoun antecedents to be very hard." ></td>
	<td class="line x" title="60:330	In addition, the resulting heuristics are prone to errors of omission and may not generalize to new contexts." ></td>
	<td class="line x" title="61:330	For example, the UMass/MUC-3 system 2 began with 19 rules for finding the antecedents of relative pronouns." ></td>
	<td class="line x" title="62:330	These rules included both structural and semantic knowledge and were based on approximately 50 instances of relative pronouns." ></td>
	<td class="line x" title="63:330	As counterexamples were identified, new rules were added (approximately 10) and existing rules changed." ></td>
	<td class="line x" title="64:330	Over time, however, we became increasingly reluctant to modify the rule set because the global effects of local rule changes were difficult to measure." ></td>
	<td class="line x" title="65:330	Moreover, the original rules were based on sentences that UMass/MUC-3 had found to contain important information." ></td>
	<td class="line x" title="66:330	As a result, the rules tended to work well for relative pronoun disambiguation in sentences of this class (93% correct for one test set of 50 texts), but did not generalize to sentences outside of the class (78% correct on the same test set of 50 texts)." ></td>
	<td class="line x" title="67:330	2.1 CURRENT APPROACHES Although descriptions of NLP systems do not usually include the algorithms used to find relative pronoun antecedents, current high-coverage parsers seem to employ one of 3 approaches for relative pronoun disambiguation." ></td>
	<td class="line x" title="68:330	Systems that use a formal syntactic grammar often directly encode information for relative pronoun disambiguation in the grammar." ></td>
	<td class="line x" title="69:330	Alternatively, a syntactic filter is applied to the parse tree and any noun phrases for which coreference with the relative pronoun is syntactically legal (or, in some cases, illegal) are passed to a semantic component which determines the antecedent using inference or preference rules (see (Correa, 1988), (Hobbs, 1986), (Ingria, & Stallard, 1989), (Lappin, & McCord, 1990))." ></td>
	<td class="line x" title="70:330	The third approach employs handcoded disambiguation heuristics that rely mainly on 2UMass/MUC-3 is a version of the CIRCUS parser (Lehnert, 1990) developed for the MUC-3 performance evaluation." ></td>
	<td class="line x" title="71:330	See (Lehnert et." ></td>
	<td class="line x" title="72:330	al., 1991) for a description of UMass/MUC-3." ></td>
	<td class="line x" title="73:330	MUC-3 is the Third Message Understanding System Evaluation and Message Understanding Conference (Sundheim, 1991)." ></td>
	<td class="line x" title="74:330	217 semantic knowledge but also include syntactic constraints (e.g. , UMass/MUC-3)." ></td>
	<td class="line x" title="75:330	However, there are problems with all 3 approaches in that 1) the grammar must be designed to find relative pronoun antecedents for all possible syntactic contexts; 2) the grammar and/or inference rules require tuning for new corpora; and 3) in most cases, the approach unreasonably assumes a completely correct parse of the clause preceding the relative pronoun." ></td>
	<td class="line x" title="76:330	In the remainder of the paper, we present an automated approach for deriving relative pronoun disambigu_a6on rules." ></td>
	<td class="line x" title="77:330	This approach avoids the problems associated with the manual encoding of heuristics and grammars and automatically tailors the disambiguation decisions to the syntactic and semantic profile of the corpus." ></td>
	<td class="line x" title="78:330	Moreover, the technique requires only a very simple parser because input to the clustering system that creates the disambiguation heuristics presumes neither pp-attachment nor interpretation of conjunctions and appositives." ></td>
	<td class="line x" title="79:330	3 AN AUTOMATED APPROACH Our method for deriving relative pronoun disambiguation heuristics consists of the following steps: 1." ></td>
	<td class="line x" title="80:330	Select from a subset of the corpus all sentences containing a particular relative pronoun." ></td>
	<td class="line x" title="81:330	(For the remainder of the paper, we will focus on the relative pronoun 'who')." ></td>
	<td class="line x" title="82:330	2." ></td>
	<td class="line x" title="83:330	For each instance of the relative pronoun in the selected sentences, a. parse the portion of the sentence that precedes it into low-level syntactic constituents b. use the results of the parse to create a training instance that represents the disambiguation decision for this occurrence of the relative pronoun." ></td>
	<td class="line x" title="84:330	3." ></td>
	<td class="line x" title="85:330	Provide the training instances as input to an existing conceptual clustering system." ></td>
	<td class="line x" title="86:330	During the training phase outlined above, the clustering system creates a hierarchy of relative pronoun disambiguation decisions that replace the hand-coded heuristics." ></td>
	<td class="line x" title="87:330	Then, for each new occurrence of the wh-word encountered after training, we retrieve the most similar disambiguation decision from the hierarchy using a representation of the clause preceding the wh-word as the probe." ></td>
	<td class="line x" title="88:330	Finally, the antecedent of the retrieved decision guides the selection of the antecedent for the new occurrence of the relative pronoun." ></td>
	<td class="line x" title="89:330	Each step of the training and testing phases will be explained further in the sections that follow." ></td>
	<td class="line x" title="90:330	3.1 SELECTING SENTENCES FROM THE CORPUS For the relative pronoun disambiguation task, we used the MUC-3 corpus of 1500 articles that range from a single paragraph to over one page in length." ></td>
	<td class="line x" title="91:330	In theory, each article describes one or more terrorist incidents in Latin America." ></td>
	<td class="line x" title="92:330	In practice, however, about half of the texts are actually irrelevant to the MUC task." ></td>
	<td class="line x" title="93:330	The MUC-3 articles consist of a variety of text types including newspaper articles, TV news reports, radio broadcasts, rebel communiques, speeches, and interviews." ></td>
	<td class="line x" title="94:330	The corpus is relatively small it contains approximately 450,000 words and 18,750 sentences." ></td>
	<td class="line oc" title="95:330	In comparison, most corpus-based algorithms employ substantially larger corpora (e.g. , 1 million words (de Marcken, 1990), 2.5 million words (Brent, 1991), 6 million words (Hindle, 1990), 13 million words (Hindle, & Rooth, 1991))." ></td>
	<td class="line x" title="96:330	Relative pronoun processing is especially important for the MUC-3 corpus because approximately 25% of the sentences contain at least one relative pronoun." ></td>
	<td class="line x" title="97:330	3 In fact, the relative pronoun 'who' occurs in approximately 1 out of every 10 sentences." ></td>
	<td class="line x" title="98:330	In the experiment described below, we use 100 texts containing 176 instances of the relative pronoun 'who' for training." ></td>
	<td class="line x" title="99:330	To extract sentences containing a specific relative pronoun, we simply search the selected articles for instances of the relative pronoun and use a preprocessor to locate sentence boundaries." ></td>
	<td class="line x" title="100:330	3.2 PARSING REQUIREMENTS Next, UMass/MUC-3 parses each of the selected sentences." ></td>
	<td class="line x" title="101:330	Whenever the relative pronoun 'who' is recognized, the syntactic analyzer returns a list of the low-level constituents of the preceding clause prior to any attachment decisions (see Figure 2)." ></td>
	<td class="line x" title="102:330	UMass/MUC-3 has a simple, deterministic, stackoriented syntactic analyzer based on the McEli parser (Schank, & Riesbeck, 1981)." ></td>
	<td class="line x" title="103:330	It employs lexicallyindexed local syntactic knowledge to segment incoming text into noun phrases, prepositional phrases, and verb phrases, ignoring all unexpected constructs and unknown words." ></td>
	<td class="line x" title="104:330	4 Each constituent 3There are 4707 occurrences of wh-words (i.e. , who, whom, which, whose, where, when, why) in the approximately 18,750 sentences that comprise the MUC-3 corpus." ></td>
	<td class="line x" title="105:330	4Although UMass/MUC-3 can recognize other syntactic classes, only noun phrases, prepositional phrases, and verb phrases become part of the training instance." ></td>
	<td class="line x" title="106:330	218 Sources in downtown Lima report that the police last night detained Juan Bautista and Rogoberto Matute, who ~ U Mass/MUC-3 syntactic analyzer the police : \[subject, human\] detained : \[verb\] Juan Bautista : \[np, proper-name\] Rogoberto Matute : \[np, proper-name\] Figure 2." ></td>
	<td class="line x" title="107:330	Syntactic Analyzer Output returned by the parser (except the verb) is tagged with the semantic classification that best describes the phrase's head noun." ></td>
	<td class="line x" title="108:330	For the MUC-3 corpus, we use a set of 7 semantic features to categorize each noun in the lexicon: human, proper-name, location, entity, physical-target, organization, and weapon." ></td>
	<td class="line x" title="109:330	In addition, clause boundaries are detected using a method described in (Cardie, & Lehnert, 1991)." ></td>
	<td class="line x" title="110:330	It should be noted that all difficult parsing decisions are delayed for subsequent processing components." ></td>
	<td class="line x" title="111:330	For the task of relative pronoun disambiguation, this means that the conceptual clustering system, not the parser, is responsible for recognizing all phrases that comprise a conjunction of antecedents and for specifying at least one of the semantically valid antecedents in the case of appositives." ></td>
	<td class="line x" title="112:330	In addition, pp-attachment is more easily postponed until after the relative pronoun antecedent has been located." ></td>
	<td class="line x" title="113:330	Consider the sentence 'I ate with the men from the restaurant in the club'." ></td>
	<td class="line x" title="114:330	Depending on the context, 'in the club' modifies either 'ate' or 'the restaurant'." ></td>
	<td class="line x" title="115:330	If we know that 'the men' is the antecedent of a relative pronoun, however (e.g. , 'I ate with the men from the restaurant in the club, who offered me the job'), it is probably the case that 'in the club' modifies 'the men'." ></td>
	<td class="line x" title="116:330	Finally, because the MUC-3 domain is sufficiently narrow in scope, lexical disambiguation problems are infrequent." ></td>
	<td class="line x" title="117:330	Given this rather simplistic view of syntax, we have found that a small set of syntactic predictions covers the wide variety of constructs in the MUC-3 corpus." ></td>
	<td class="line x" title="118:330	3.3 CREATING THE TRAINING INSTANCES Output from the syntactic analyzer is used to generate a training instance for each occurrence of the relative pronoun in the selected sentences." ></td>
	<td class="line x" title="119:330	A training instance represents a single disambiguation decision and includes one attribute-value pair for every lowlevel syntactic constituent in the preceding clause." ></td>
	<td class="line x" title="120:330	The attributes of a training instance describe the syntactic class of the constituent as well as its position with respect to the relative pronoun." ></td>
	<td class="line x" title="121:330	The value associated with an attribute is the semantic feature of the phrase's head noun." ></td>
	<td class="line x" title="122:330	(For verb phrases, we currently note only their presence or absence using the values t and nil, respectively)." ></td>
	<td class="line x" title="123:330	Consider the training instances in Figure 3." ></td>
	<td class="line x" title="124:330	In S 1, for example, 'of the 76th district court' is represented with the attribute ppl because it is a prepositional phrase and is in the first position to the left of 'who'." ></td>
	<td class="line x" title="125:330	Its value is 'physical-target' because 'court' is classified as a physical-target in the lexicon." ></td>
	<td class="line x" title="126:330	The subject and verb constituents (e.g. , 'her DAS bodyguard' in $3 and 'detained' in $2) retain their traditional s and v labels, however -no positional information is included for those attributes." ></td>
	<td class="line x" title="127:330	S1: \[The judge\] \[of the 76th court\] \[,\] who  I I Training instance: \[ (s human) (pp l physical-rargeO (v nil) (antecedent ((s) ) ) \] f12: \[The police\] \[detained\] Uuan Bautista\] \[and\] \[Rogoberto Matute\] \[,\] who  Training instanoa: \[ (s human) (v 0 (np2 proper-name) (npl proper-name) (antecedent ((rip2 npl))) \] S8: \[Her DAS bodyguard\] \[,\] \[Dagoberto Rodriquez\] \[,\] who I I Training instance: \[( s human) (npl proper-name) (v nil) (antecedent ((npl )(s npl )(s)))\] Figure 3." ></td>
	<td class="line x" title="128:330	Training Instances 219 In addition to the constituent attribute-value pairs, a training instance contains an attribute-value pair that represents the correct antecedent." ></td>
	<td class="line x" title="129:330	As shown in Figure 3, the value of the antecedent attribute is a list of the syntactic constituents that contain the antecedent (or (none) if the relative pronoun has no anteceden0." ></td>
	<td class="line x" title="130:330	In S 1, for example, the antecedent of 'who' is 'the judge'." ></td>
	<td class="line x" title="131:330	Because this phrase is located in the subject position, the value of the antecedent attribute is (s)." ></td>
	<td class="line x" title="132:330	Sometimes, however, the antecedent is actually a conjunction of phrases." ></td>
	<td class="line x" title="133:330	In these cases, we represent the antecedent as a list of the constituents associated with each element of the conjunction." ></td>
	<td class="line x" title="134:330	Look, for example, at the antecedent in $2." ></td>
	<td class="line x" title="135:330	Because 'who' refers to the conjunction 'Juan Bautista and Rogoberto Matute,' and because those phrases occur as rip1 and rip2, the value of the antecedent attribute is (np2 npl)." ></td>
	<td class="line x" title="136:330	$3 shows yet another variation of the antecedent attribute-value pair." ></td>
	<td class="line x" title="137:330	In this example, an appositive creates three equivalent antecedents: 1) 'Dagoberto Rodriguez' (rip1), 2) 'her DAS bodyguard' m (s), and 3) 'her DAS bodyguard, Dagoberto Rodriguez' -(s npl)." ></td>
	<td class="line x" title="138:330	UMass/MUC-3 automatically generates the training instances as a side effect of parsing." ></td>
	<td class="line x" title="139:330	Only the desired antecedent is specified by a human supervisor via a menu-driven interface that displays the antecedent options." ></td>
	<td class="line x" title="140:330	3.4 BUILDING THE HIERARCHY OF DISAMBIGUATION HEURISTICS As the training instances become available they are input to an existing conceptual clustering system called COBWEB (Fisher, 1987)." ></td>
	<td class="line x" title="141:330	5 COBWEB employs an evaluation metric called category utility (Gluck, & Corter, 1985) to incrementally discover a classification hierarchy that covers the training instances." ></td>
	<td class="line x" title="142:330	6 It is this hierarchy that replaces the handcoded disambiguation heuristics." ></td>
	<td class="line x" title="143:330	While the details of COBWEB are not necessary, it is important to know that nodes in the hierarchy represent concepts that increase in generality as they approach the root of the tree." ></td>
	<td class="line x" title="144:330	Given a new instance to classify, COBWEB 5 For these experiments, we used a version of COBWEB developed by Robert Williams at the University of Massachusetts at Amherst." ></td>
	<td class="line x" title="145:330	6Conceptual clustering systems typically discover appropriate classes as well as the the concepts for each class when given a set of examples that have not been preclassified by a teacher." ></td>
	<td class="line x" title="146:330	Our unorthodox use of COBWEB to perform supervised learning is prompted by plans to use the resulting hierarchy for tasks other than relative pronoun disambiguation." ></td>
	<td class="line x" title="147:330	220 retrieves the most specific concept that adequately describes the instance." ></td>
	<td class="line x" title="148:330	3.5 USING THE DISAMBIGUATION HEURISTICS HIERARCHY After training, the resulting hierarchy of relative pronoun disambiguation decisions supplies the antecedent of the wh-word in new contexts." ></td>
	<td class="line x" title="149:330	Given a novel sentence containing 'who,' UMass/MUC-3 generates a set of attribute-value pairs that represent the clause preceding the wh-word." ></td>
	<td class="line x" title="150:330	This probe is just a training instance without the antecedent attributevalue pair." ></td>
	<td class="line x" title="151:330	Given the probe, COBWEB retrieves from the hierarchy the individual instance or abstract class that is most similar and the antecedent of the retrieved example guides selection of the antecedent for the novel case." ></td>
	<td class="line x" title="152:330	We currently use the following selection heuristics to 1) choose an antex~ent for the novel sentence that is consistent with the context of the probe; or to 2) modify the retrieved antecedent so that it is applicable in the current context: 1." ></td>
	<td class="line x" title="153:330	Choose the first option whose constituents are all present in the probe." ></td>
	<td class="line x" title="154:330	2." ></td>
	<td class="line x" title="155:330	Otherwise, choose the first option that contains at least one constituent present in the probe and ignore those constituents in the retrieved antex~ent that are missing from the probe." ></td>
	<td class="line x" title="156:330	3." ></td>
	<td class="line x" title="157:330	Otherwise, replace the np constituents in the retrieved antecedent that are missing from the probe with pp constituents (and vice versa), and try 1 and 2 again." ></td>
	<td class="line x" title="158:330	In S 1 of Figure 4, for example, the first selection heuristic applies." ></td>
	<td class="line x" title="159:330	The retrieved instance specifies the np2 constituent as the location of the antecedent and the probe has rip2 as one of its constituents." ></td>
	<td class="line x" title="160:330	Therefore, UMass/MUC-3 infers that the antecedent of 'who' for the current sentence is 'the hardliners,' i.e., the contents of the np2 syntactic constituent." ></td>
	<td class="line x" title="161:330	In $2, however, the retrieved concept specifies an antecedent from five constituents, only two of which are actually present in the probe." ></td>
	<td class="line x" title="162:330	Therefore, we ignore the missing constituents pp5, rip4, and pp3, and look to just np2 and rip1 for the antecedent." ></td>
	<td class="line x" title="163:330	For $3, selection heuristics 1 and 2 fail because the probe contains no pp2 constituent." ></td>
	<td class="line x" title="164:330	However, if we replace pp2 with np2 in the retrieved antecedent, then heuristic 1 applies and 'a specialist' is chosen as the antecedent." ></td>
	<td class="line x" title="165:330	Sl: \[It\] \[encourages\] \[the military men\] \[,\] \[and\] \[the hardliners\] \[in ARENA\] who I I I \[(s enaty) (vO (np3 human) (np2 human) (ppl org)\] Antecedent of Retrieved Instance: ((np2)) Antecedent of Probe:." ></td>
	<td class="line x" title="166:330	(np2) = 'the hardliners' S2: \[There\] \[are\] \[also\] \[criminals\] \[like\] \[Vice President Merino\] \[,\] \[a man\] who \[(s entity) (v t) (rip3 human) (rip2 proper-name) (rip1 human)\] Antecedent of Retrieved Instance: ((pp5 np4 pp3 np2 np1)) Antecedent of Probe:." ></td>
	<td class="line x" title="167:330	(np2 np1) = Wice President Merino, a man' $3: \[It\] \[coincided\] \[with the arrival\] \[of Smith\] \[,\] \[a specialist\] \[from the UN\] \[,\] who ~ (pp4Jntity) \[ \[ (plplentity)\] \[(s entity) (v 0 (pp3 proper-name) (rip2 human) Antecedent of Retrieved Instance: ((pp2)) Antecedent of Probe: (np2) = 'a specialist' Figure 4." ></td>
	<td class="line x" title="168:330	Using the Disambiguation Heuristics Hierarchy 4 RESULTS As described above, we used 100 texts (approximately 7% of the corpus) containing 176 instances of the relative pronoun 'who' for training." ></td>
	<td class="line x" title="169:330	Six of those instances were discarded when the UMass/MUC-3 syntactic analyzer failed to include the desired antecedent as part of its constituent representation, making it impossible for the human supervisor to specify the location of the antecedent." ></td>
	<td class="line x" title="170:330	7 After training, we tested the resulting disambiguation hierarchy on 71 novel instances extracted from an additional 50 texts in the corpus." ></td>
	<td class="line x" title="171:330	Using the selection heuristics described above, the correct antecedent was found for 92% of the test instances." ></td>
	<td class="line x" title="172:330	Of the 6 errors, 3 involved probes with antecedent combinations never seen in any of the training cases." ></td>
	<td class="line x" title="173:330	This usually indicates that the semantic and syntactic structure of the novel clause differs significantly from those in the disambiguation hierarchy." ></td>
	<td class="line x" title="174:330	This was, in fact, the case for 2 out of 3 of the errors." ></td>
	<td class="line x" title="175:330	The third error involved a complex conjunction and appositive combination." ></td>
	<td class="line x" title="176:330	In this case, the retrieved antecedent specified 3 out of 4 of the required constituents." ></td>
	<td class="line x" title="177:330	If we discount the errors involving unknown antecedents, our algorithm correctly classifies 94% of the novel instances (3 errors)." ></td>
	<td class="line x" title="178:330	In comparison, the original UMass/MUC-3 system that relied on handcoded heuristics for relative pronoun disambiguation finds the correct antecedent 87% of the time (9 errors)." ></td>
	<td class="line x" title="179:330	However, a simple heuristic that chooses the most recent phrase as the antecedent succeeds 86% of the time." ></td>
	<td class="line x" title="180:330	(For the training sets, this heuristic works only 75% of the time)." ></td>
	<td class="line x" title="181:330	In cases where the antecedent was not the most recent phrase, UMass/MUC-3 errs 67% of the time." ></td>
	<td class="line x" title="182:330	Our automated algorithm errs 47% of the time." ></td>
	<td class="line x" title="183:330	It is interesting that of the 3 errors that did not specify previously unseen an~exlents, one was caused by parsing blunders." ></td>
	<td class="line x" title="184:330	The remaining 2 errors involved relative pronoun antecedents that are difficult even for people to specify: 1) ' 9 rebels died at the hands of members of the civilian militia, who resisted the attacks' and 2) ' the government expelled a group of foreign drug traffickers who had established themselves in northern Chile'." ></td>
	<td class="line x" title="185:330	Our algorithm chose 'the civilian militia' and 'foreign drug traffickers' as the antecedents of 'who' instead of the preferred antecedents 'members of the civilian militia' and 'group of foreign drug traffickers." ></td>
	<td class="line x" title="186:330	'8 5 CONCLUSIONS We have described an automated approach for the acquisition of relative pronoun disambiguation heuristics that duplicates the performance of handceded rules." ></td>
	<td class="line x" title="187:330	Unfortunately, extending the technique for use with unrestricted texts may be difficult." ></td>
	<td class="line x" title="188:330	The UMass/MUC-3 parser would clearly need additional mechanisms to handle the ensuing part of speech and 7Other parsing errors occurred throughout the training set, but only those instances where the antecedent was not recognized as a constituent (and the wh-word had an anteceden0 were discarded." ></td>
	<td class="line oc" title="189:330	8Interestingly, in work on the automated classification of nouns, (Hindle, 1990) also noted problems with 'empty' words that depend on their complements for meaning." ></td>
	<td class="line x" title="190:330	221 word sense disambiguation problems." ></td>
	<td class="line x" title="191:330	However, recent research in these areas indicates that automated approaches for these tasks may be feasible (see, for example, (Brown, Della Pietra, Della Pietra, & Mercer, 1991) and (l-Iindle, 1983))." ></td>
	<td class="line x" title="192:330	In addition, although our simple semantic feature set seems adequate for the current relative pronoun disambiguntion task, it is doubtful that a single semantic feature set can be used across all domains and for all disambignation tasks." ></td>
	<td class="line x" title="193:330	9 In related work on pronoun disambig~_~_afion, Dagan and Itai (1991) successfully use statistical cooccurrence patterns to choose among the syntactically valid pronoun referents posed by the parser." ></td>
	<td class="line x" title="194:330	Their approach is similar in that the statistical database depends on parser output." ></td>
	<td class="line x" title="195:330	However, it differs in a variety of ways." ></td>
	<td class="line x" title="196:330	First, human intervention is required not to specify the correct pronoun antecedent, but to check that the complete parse tree supplied by the parser for each training example is correct and to rule out potential examples that are inappropriate for their approach." ></td>
	<td class="line x" title="197:330	More importantly, their method requires very large COrlxra of data." ></td>
	<td class="line x" title="198:330	Our technique, on the other hand, requires few training examples because each training instance is not word-based, but created from higher-level parser output." ></td>
	<td class="line x" title="199:330	10 Therefore, unlike other corpus-based techniques, our approach is practical for use with small to medium-sized corpora in relatively narrow domains." ></td>
	<td class="line x" title="200:330	((Dagan & Itai, 1991) mention the use of semantic feature-based cooccurrences as one way to make use of a smaller corpus)." ></td>
	<td class="line x" title="201:330	In addition, because human intervention is required only to specify the antecedent during the training phase, creating disambiguation heuristics for a new domain requires little effort." ></td>
	<td class="line x" title="202:330	Any NLP system that uses semantic features for describing nouns and has minimal syntactic parsing capabilities can generate the required training instances." ></td>
	<td class="line x" title="203:330	The parser need only recognize noun phrases, verbs, and prepositional phrases because the disambiguation heuristics, not the parser, are responsible for recognizing the conjunctions and appositives that comprise a relative pronoun antecedent." ></td>
	<td class="line x" title="204:330	Moreover, the success of the approach for structurally complex antecedents suggests that the technique may provide a general approach for the 9 In recent work on the disambiguation of structurally, but not semantically, restricted phrases, however, a set of 16 predefined semantic categories sufficed (Ravin, 1990)." ></td>
	<td class="line x" title="205:330	10Although further work is needed to determine the optimal number of training examples, it is probably the case that many fewer than 170 instances were required even for the experiments described here." ></td>
	<td class="line x" title="206:330	222 automated acquisition of disambiguation rules for other problems in natural language processing." ></td>
	<td class="line x" title="207:330	6 ACKNOWLEDGMENTS This research was supported by the Office of Naval Research, under a University Research Initiative Grant, Contract No." ></td>
	<td class="line x" title="208:330	N00014-86-K-0764 and NSF Presidential Young Investigators Award NSFIST8351863 (awarded to Wendy Lehnert) and the Advanced Research Projects Agency of the Department of Defense monitored by the Air Force Office of Scientific Research under Contract No." ></td>
	<td class="line x" title="209:330	F49620-88-C-0058." ></td>
	<td class="line x" title="210:330	REFERENCES Brent, M." ></td>
	<td class="line x" title="211:330	(1991)." ></td>
	<td class="line x" title="212:330	Automatic acquisition of subcategorization frames from untagged text." ></td>
	<td class="line x" title="213:330	Proceedings, 29th Annual Meeting of the Association for Computational Linguists." ></td>
	<td class="line x" title="214:330	University of California, Berkeley." ></td>
	<td class="line x" title="215:330	Association for Computational Linguists." ></td>
	<td class="line x" title="216:330	Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., & Mercer, R. L." ></td>
	<td class="line x" title="217:330	(1991)." ></td>
	<td class="line x" title="218:330	Word-sense disambiguation using statistical methods." ></td>
	<td class="line x" title="219:330	Proceedings, 29th Annual Meeting of the Association for Computational Linguists." ></td>
	<td class="line x" title="220:330	University of California, Berkeley." ></td>
	<td class="line x" title="221:330	Association for Computational Linguists." ></td>
	<td class="line x" title="222:330	Cardie, C. , & Lehnert, W." ></td>
	<td class="line x" title="223:330	(1991)." ></td>
	<td class="line x" title="224:330	A Cognitively Plausible Approach to Understanding Complex Syntax." ></td>
	<td class="line x" title="225:330	Proceedings, Eighth National Conference on Artificial Intelligence." ></td>
	<td class="line x" title="226:330	Anaheim, CA." ></td>
	<td class="line x" title="227:330	AAAI Press \] The MIT Press." ></td>
	<td class="line x" title="228:330	Correa, N." ></td>
	<td class="line x" title="229:330	(1988)." ></td>
	<td class="line x" title="230:330	A Binding Rule for Government-Binding Parsing." ></td>
	<td class="line x" title="231:330	Proceedings, COLING '88." ></td>
	<td class="line x" title="232:330	Budapest." ></td>
	<td class="line x" title="233:330	Dagan, I. and Itai, A." ></td>
	<td class="line x" title="234:330	(1991)." ></td>
	<td class="line x" title="235:330	A Statistical Filter for Resolving Pronoun References." ></td>
	<td class="line x" title="236:330	In Y.A. Feldman and A.Bruckstein (Eds.), Artificial Intelligence and Computer Vision (pp." ></td>
	<td class="line x" title="237:330	125-135)." ></td>
	<td class="line x" title="238:330	North-Holland: Elsevier." ></td>
	<td class="line x" title="239:330	de Marcken, C. G." ></td>
	<td class="line x" title="240:330	(1990)." ></td>
	<td class="line x" title="241:330	Parsing the LOB corpus." ></td>
	<td class="line x" title="242:330	Proceedings, 28th Annual Meeting of the Association for Computational Linguists." ></td>
	<td class="line x" title="243:330	University of Pittsburgh." ></td>
	<td class="line x" title="244:330	Association for Computational Linguists." ></td>
	<td class="line x" title="245:330	Fisher, D. H." ></td>
	<td class="line x" title="246:330	(1987)." ></td>
	<td class="line x" title="247:330	Knowledge Acquisition Via Incremental Conceptual Clustering." ></td>
	<td class="line x" title="248:330	Machine Learning, 2, 139-172." ></td>
	<td class="line x" title="249:330	Frazier, L." ></td>
	<td class="line x" title="250:330	(1978)." ></td>
	<td class="line x" title="251:330	On comprehending sentences: Syntactic parsing strategies." ></td>
	<td class="line x" title="252:330	Ph.D. Thesis." ></td>
	<td class="line x" title="253:330	University of Connecticut." ></td>
	<td class="line x" title="254:330	Gluck, M. A., & Corter, J. E." ></td>
	<td class="line x" title="255:330	(1985)." ></td>
	<td class="line x" title="256:330	Information, uncertainty, and the utility of categories." ></td>
	<td class="line x" title="257:330	Proceedings, Seventh Annual Conference of the Cognitive Science Society." ></td>
	<td class="line x" title="258:330	Lawrence Erlbaum Associates." ></td>
	<td class="line x" title="259:330	Hindle, D." ></td>
	<td class="line x" title="260:330	(1983)." ></td>
	<td class="line x" title="261:330	User manual for Fidditch (7590-142)." ></td>
	<td class="line x" title="262:330	Naval Research Laboratory." ></td>
	<td class="line x" title="263:330	Hindle, D." ></td>
	<td class="line x" title="264:330	(1990)." ></td>
	<td class="line x" title="265:330	Noun classification from predicate-argument structures." ></td>
	<td class="line x" title="266:330	Proceedings, 28th Annual Meeting of the Association for Computational Linguists." ></td>
	<td class="line x" title="267:330	University of Pittsburgh." ></td>
	<td class="line x" title="268:330	Association for Computational Linguists." ></td>
	<td class="line x" title="269:330	Hindle, D. , & Rooth, M." ></td>
	<td class="line x" title="270:330	(1991)." ></td>
	<td class="line x" title="271:330	Structural ambiguity and lexical relations." ></td>
	<td class="line x" title="272:330	Proceedings, 29th Annual Meeting of the Association for Computational Linguists." ></td>
	<td class="line x" title="273:330	University of California, Berkeley." ></td>
	<td class="line x" title="274:330	Association for Computational Linguists." ></td>
	<td class="line x" title="275:330	Hobbs, J." ></td>
	<td class="line x" title="276:330	(1986)." ></td>
	<td class="line x" title="277:330	Resolving Pronoun References." ></td>
	<td class="line x" title="278:330	In B. J. Grosz, K. Sparck Jones, & B. L. Webber (Eds.), Readings in Natural Language Processing (pp." ></td>
	<td class="line x" title="279:330	339-352)." ></td>
	<td class="line x" title="280:330	Los Altos, CA: Morgan Kaufmann Publishers, Inc. Ingria, R. , & Stallard, D." ></td>
	<td class="line x" title="281:330	(1989)." ></td>
	<td class="line x" title="282:330	A computational mechanism for pronominal reference." ></td>
	<td class="line x" title="283:330	Proceedings, 27th Annual Meeting of the Association for Computational Linguistics." ></td>
	<td class="line x" title="284:330	Vancouver." ></td>
	<td class="line x" title="285:330	Kimball, J." ></td>
	<td class="line x" title="286:330	(1973)." ></td>
	<td class="line x" title="287:330	Seven principles of surface structure parsing in natural language." ></td>
	<td class="line x" title="288:330	Cognition, 2, 15-47." ></td>
	<td class="line x" title="289:330	Lappin, S. , & McCord, M." ></td>
	<td class="line x" title="290:330	(1990)." ></td>
	<td class="line x" title="291:330	A syntactic filter on pronominal anaphora for slot grammar." ></td>
	<td class="line x" title="292:330	Proceedings, 28th Annual Meeting of the Association for Computational Linguistics." ></td>
	<td class="line x" title="293:330	University of Pittsburgh." ></td>
	<td class="line x" title="294:330	Association for Computational Linguistics." ></td>
	<td class="line x" title="295:330	Lehnert, W." ></td>
	<td class="line x" title="296:330	(1990)." ></td>
	<td class="line x" title="297:330	Symbolic/Subsymbolic Sentence Analysis: Exploiting the Best of Two Worlds." ></td>
	<td class="line x" title="298:330	In J. Bamden, & J. Pollack (Eds.), Advances in Connectionist and Neural Computation Theory." ></td>
	<td class="line x" title="299:330	Norwood, NJ: Ablex Publishers." ></td>
	<td class="line x" title="300:330	Lehnert, W. , Cardie, C. , Fisher, D. , Riloff, E. , & Williams, R." ></td>
	<td class="line x" title="301:330	(1991).University of Massachusetts: Description of the CIRCUS System as Used for MUC-3." ></td>
	<td class="line x" title="302:330	Proceedings, Third Message Understanding Conference (MUC-3)." ></td>
	<td class="line x" title="303:330	San Diego, CA." ></td>
	<td class="line x" title="304:330	Morgan Kaufmann Publishers." ></td>
	<td class="line x" title="305:330	Ravin, Y." ></td>
	<td class="line x" title="306:330	(1990)." ></td>
	<td class="line x" title="307:330	Disambignating and interpreting verb definitions." ></td>
	<td class="line x" title="308:330	Proceedings, 28th Annual Meeting of the Association for Computational Linguists." ></td>
	<td class="line x" title="309:330	University of Pittsburgh." ></td>
	<td class="line x" title="310:330	Association for Computational Linguists." ></td>
	<td class="line x" title="311:330	Schank, R. , & Riesbeck, C." ></td>
	<td class="line x" title="312:330	(1981)." ></td>
	<td class="line x" title="313:330	Inside Computer Understanding: Five Programs Plus Miniatures." ></td>
	<td class="line x" title="314:330	Hillsdale, NJ: Lawrence Erlbaum." ></td>
	<td class="line x" title="315:330	Sundheim, B. M." ></td>
	<td class="line x" title="316:330	(May,1991)." ></td>
	<td class="line x" title="317:330	Overview of the Third Message Understanding Evaluation and Conference." ></td>
	<td class="line x" title="318:330	Proceedings,Third Message Understanding Conference (MUC-3)." ></td>
	<td class="line x" title="319:330	San Diego, CA." ></td>
	<td class="line x" title="320:330	Morgan Kanfmann Publishers." ></td>
	<td class="line x" title="321:330	Taraban, R. , & McClelland, J. L." ></td>
	<td class="line x" title="322:330	(1988)." ></td>
	<td class="line x" title="323:330	Constituent attachment and thematic role assignment in sentence processing: influences of content-based expectations." ></td>
	<td class="line x" title="324:330	Journal of Memory and Language, 27, 597-632." ></td>
	<td class="line x" title="325:330	Whittemore, G. , Ferrara, K. , & Brunner, H." ></td>
	<td class="line x" title="326:330	(1990)." ></td>
	<td class="line x" title="327:330	Empirical study of predictive powers of simple attachment schemes for post-modifier prepositional phrases." ></td>
	<td class="line x" title="328:330	Proceedings, 28th Annual Meeting of the Association for Computational Linguistics." ></td>
	<td class="line x" title="329:330	University of Pittsburgh." ></td>
	<td class="line x" title="330:330	Association for Computational Linguistics ." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="H93-1049
Hypothesizing Word Association From Untagged Text
Matsukawa, Tomoyoshi;"></td>
	<td class="line x" title="1:159	HYPOTHESIZING UNTAGGED TEXT WORD ASSOCIATION FROM Tomoyoshi Matsukawa BBN Systems and Technologies 70 Fawcett St. Cambridge, MA 02138 ABSTRACT This paper reports a new method for suggesting word associations, based on a greedy algorithm that employs Chisquare statistics on joint frequencies of pairs of word groups compared against chance co-occurrence." ></td>
	<td class="line x" title="2:159	The benefits of this new approach are: 1) we can consider even low frequency words and word pairs, and 2) word groups and word associations can be automatically generated." ></td>
	<td class="line x" title="3:159	The method provided 87% accuracy in hypothesizing word associations for unobserved combinations of words in Japanese text." ></td>
	<td class="line x" title="4:159	1." ></td>
	<td class="line x" title="5:159	INTRODUCTION Using mutual information for measuring word association has become popular since \[Church and Hanks, 1990\] defined word association ratio as mutual information between two words." ></td>
	<td class="line x" title="6:159	Word association ratios are a promising tool for lexicography, but there seem to be at least two limitations to the method: 1) much data with low frequency words or word pairs cannot be used and 2) generalization of word usage still depends totally on lexicographers." ></td>
	<td class="line x" title="7:159	In this paper, we propose an alternative (or extended) method for suggesting word associations using Chi-square statistics, which can be viewed as an approximation to mutual information." ></td>
	<td class="line x" title="8:159	Rather than considering significance of joint frequencies of word pairs as \[Church and Hanks, 1990\] did, our algorithm uses joint frequencies of pairs of word groups instead." ></td>
	<td class="line x" title="9:159	The algorithm employs a hillclimbing search for a pair of word groups that occur significantly frequently." ></td>
	<td class="line x" title="10:159	The benefits of this new approach are: 1) that we can consider even low frequency words and word pairs, and 2) that word groups or word associations can be automatically generated,.namely automatic hypothesis of word associations, which can later be reviewed by a lexicographer." ></td>
	<td class="line x" title="11:159	3) word associations can be used in parsing and understanding natural language, as well as in natural language generation \[Smadja and McKeown, 1990\]." ></td>
	<td class="line x" title="12:159	Our method proved to be 87% accurate in hypothesizing word associations for unobserved combinations of words in Japanese text, where accuracy was tested by human verification of a random sample of hypothesized word pairs." ></td>
	<td class="line x" title="13:159	We extracted 14,407 observations of word co-occurrences, involving 3,195 nouns and 4,365 verb/argument pairs." ></td>
	<td class="line x" title="14:159	Out of this we hypothesized 7,050 word associations." ></td>
	<td class="line x" title="15:159	The corpus size was 280,000 words." ></td>
	<td class="line x" title="16:159	We would like to apply the same approach to English." ></td>
	<td class="line x" title="17:159	2." ></td>
	<td class="line x" title="18:159	RELATED WORK Some previous work (e.g. , \[Weischedel, et al. , 1990\]) found verb-argument associations from bracketed text, such as that in TREEBANK; however, this paper, and related work has hypothesized word associations from untagged text." ></td>
	<td class="line oc" title="19:159	\[Hindle 1990\] confirmed that word association ratios can be used for measuring similarity between nouns." ></td>
	<td class="line x" title="20:159	For example, 'ship', 'plane', 'bus', etc. , were automatically ranked as similar to 'boat'." ></td>
	<td class="line x" title="21:159	\[Resnik 1992\] reported a word association ratio for identifying noun classes from a preexisting hierarchy as selectional constraints on the object of a verb." ></td>
	<td class="line x" title="22:159	\[Brown et.al. 1992\] proves that, under the assumption of a bi-gram class model, the perplexity of a corpus is minimized when the average mutual information between word classes is maximized." ></td>
	<td class="line x" title="23:159	Based on that fact, they cluster words via a greedy search algorithm which finds a local maximum in average mutual information." ></td>
	<td class="line o" title="24:159	Our algorithm considers joint frequencies of pairs of word groups (as \[Brown et." ></td>
	<td class="line oc" title="25:159	al. 1992\] does) in contrast to joint frequencies of word pairs as in \[Church and Hanks, 1990\] and \[Hindle 1990\]." ></td>
	<td class="line x" title="26:159	Here a word group means any subset of the whole set of words." ></td>
	<td class="line x" title="27:159	For example, 'ship,' 'plane,' 'boat' and 'car' may be a word group." ></td>
	<td class="line x" title="28:159	The algorithm will find pairs of such word groups." ></td>
	<td class="line x" title="29:159	Another similarity to \[Brown et." ></td>
	<td class="line x" title="30:159	al. 1992\]'s clustering algorithm is the use of greedy search for a pair of word groups that occur significantly frequently, using an evaluation function based on mutual information between classes." ></td>
	<td class="line x" title="31:159	On the other hand, unlike \[Brown et." ></td>
	<td class="line x" title="32:159	al. 1992\], we assume some automatic syntactic analysis of the corpus, namely part-of-speech analysis and at least finite-state approximations to syntactic dependencies." ></td>
	<td class="line x" title="33:159	Moreover, the clustering is done depth first, not breadth first as \[Brown et." ></td>
	<td class="line x" title="34:159	248 al. 1992\], i.e., clusters are hypothesized one by one, not in parallel." ></td>
	<td class="line x" title="35:159	3." ></td>
	<td class="line x" title="36:159	OVERVIEW OF THE METHOD The method consists of three phases: 1) Automatic part of speech tagging of text." ></td>
	<td class="line x" title="37:159	First, texts are labeled by our probabilistic part of speech tagger (POST) which has been extended for Japanese morphological processing \[Matsukawa et." ></td>
	<td class="line x" title="38:159	al. 1993\]." ></td>
	<td class="line x" title="39:159	This is fully automatic; human review is not necessary under the assumption that the tagger has previously been trained on appropriate text \[Meteer et." ></td>
	<td class="line x" title="40:159	al. 1991\] 1 2) Finite state pattern matching." ></td>
	<td class="line x" title="41:159	Second, a finite-state pattern matcher with patterns representing possible grammatical relations, such as verb/argument pairs, nominal compounds, etc. is run over the sample text to suggest word pairs which will be considered candidates for word associations." ></td>
	<td class="line x" title="42:159	As a result, we get a word cooccurrence matrix." ></td>
	<td class="line x" title="43:159	Again, no human review of the pattern matching is assumed." ></td>
	<td class="line x" title="44:159	3) Filtering/Generalization of word associations via Chi-square." ></td>
	<td class="line x" title="45:159	Third, given the word co-occurrence matrix, the program starts from an initial pair of word groups (or a submatrix in the matrix), incrementally adding into the submatrix a word which locally gives the highest Chisquare score to the submatrix." ></td>
	<td class="line x" title="46:159	Finally, words are removed which give a higher Chisquare score by their removal." ></td>
	<td class="line x" title="47:159	By adding and removing words until reaching an appropriate significance level, we get a submatrix as a hypothesis of word associations between the cluster of words represented as rows in the submatrix and the cluster of words represented as columns in the submatrix." ></td>
	<td class="line x" title="48:159	4 WORD SEGMENTATION AND PART OF SPEECH LABELING 1 In our experience thus far in three domains and in both Japanese and English, while retraining POST on domainspecific data would reduce the error rate, the effect on overall performance of the system in data extraction from text has been small enough to make retraining unnecessary." ></td>
	<td class="line x" title="49:159	The effect of domain-specific lexical entries (e.g. , DRAM is a noun in microelectronics) often mitigates the need to retrain." ></td>
	<td class="line x" title="50:159	Since in Japanese word separators such as spaces are not present, words must be segmented before we assign part of speech to words." ></td>
	<td class="line x" title="51:159	To do this, we use JUMAN from Kyoto University to segment Japanese text into words, AMED, an example-based segmentation corrector, and a Hidden Markov Model (POST) \[Matsukawa, et." ></td>
	<td class="line x" title="52:159	al. 1993\]." ></td>
	<td class="line x" title="53:159	For example, POST processes an input text such as the following: and produces tagged text such as: 2 --~j/CONJ, /TT ~/CN ~/CN ~,~/rM ~_:~)~:~.,/PN O/NCM ~ ~/SN ::\[~,~/CN '~/CM L./ADV." ></td>
	<td class="line x" title="55:159	/IT ~/CN IJCN ~/NCM ~'~#2/ADJ ~jCN Q)/NCM .Jzff/./CN ~\[Iii~/CN I/~'T/CN ~/NCM ~_ ~/FN '~/PT, \[FT ~ 2\[s;/PN ~TPT ~/NCM ~/CM ~\]~t-~ ~/VB ~,~$/VSUF  /KT 5." ></td>
	<td class="line x" title="56:159	FINITE STATE PATTERN MATCHING We use the following finite state patterns for extracting possible Japanese verb/argument word co-occurrences from automatically segmented and tagged Japanese text." ></td>
	<td class="line x" title="57:159	Completely different patterns would be used for English." ></td>
	<td class="line x" title="58:159	PN PT ''' SN SN where CN = common noun PN = proper name SN = Sa-inflection noun (nominal verb) CM = case marker (-nom/-acc argument) PT = particle (other arguments) VB = verb Here, the first part (CN, PN or SN) represents a noun." ></td>
	<td class="line x" title="59:159	Since in Japanese the head noun of a noun phrase is always at the right end of the phrase, this part should always match a head noun." ></td>
	<td class="line x" title="60:159	The second part (CM or PT) represents a postposition which identifies an argument of a verb." ></td>
	<td class="line x" title="61:159	The final pattern element (VB or SN) represents a verb." ></td>
	<td class="line x" title="62:159	Sainflection nouns (SN) are nominalized verbs which form a verb phrase with the morpheme 'suru'." ></td>
	<td class="line x" title="63:159	2 CONJ = conjunction; Tr = Japanese comma; CN = common noun; TM = Topic marker; PN proper noun; etc. 249 Distance 0 1 2 4 Matched Text g~|/CN \]j-t~/CN ~:'~_/CN k/PT ~J~/'SN xJ-&/VB ~ ~/FN '~TPT  7 9 MX/PN 0)/NCM ~_~/CN ~/PT ~a~/CN ~i~}~t~/SN ~/CM L~NB  ~I\]Z~/ADJ ~:~t/CN ~/'PT '~'/~--b/CN \]J/CM ~i~l~/SN L~NB  ~-/CN -~/CN ~/CN ~/PT ~/CN ~/NNSU~--F/CN ~/NCM ~j #/ON ~ig~/SN ~/NCM Figure 1: Examples of Pattern Matches with Skipping over Words." ></td>
	<td class="line x" title="64:159	Since argument structure in Japanese is marked by postpositions, i.e., case markers (i.e. , 'o,' 'ga') and partic?,es (e.g. , 'ni,' 'kara,' . . .), word combinations matched with the patterns will represent associations between a noun filling a particular argument type (e.g. , 'o') and a verb." ></td>
	<td class="line x" title="65:159	Note that topic markers (TM; i.e., 'wa') and toritate markers (TTM; e.g.'mo', 'sae', ) are not included in the pattern since these do not uniquely identify the case of the argument." ></td>
	<td class="line x" title="66:159	Just as in English, the arguments of a verb in Japanese may be quite distant from the verb; adverbial phrases and scrambling are two cases that may separate a verb from its argument(s)." ></td>
	<td class="line x" title="67:159	We approximate this in a finite state machine by allowing words to be skipped." ></td>
	<td class="line x" title="68:159	In our experiment, up to four words could be skipped." ></td>
	<td class="line x" title="69:159	As shown in Figure 1, matching an argument structure varies from distance 0 to 4." ></td>
	<td class="line x" title="70:159	By limiting the algorithm to a maximum of four word gaps, and by not considering the ambiguous cases of topic markers and taritate markers, we have chosen to limit the cases considered in favor of high accuracy in automatically hypothesizing word associations." ></td>
	<td class="line x" title="71:159	\[Brent, 1991\] similarly limited what his algorithm could learn in favor of high accuracy." ></td>
	<td class="line x" title="72:159	6." ></td>
	<td class="line x" title="73:159	FILTERING AND GENERALIZATION VIA CHI-SQUARE Word combinations found via the finite state patterns include a noun, postposition, and a verb." ></td>
	<td class="line x" title="74:159	A two dimensional matrix (a word co-occurrence matrix) is formed, where the columns are nouns, and the rows are pairs of a verb plus postposifion." ></td>
	<td class="line x" title="75:159	The cells of the matrix are the frequency of the noun (column element) cooccurring in the given case with that verb (row element)." ></td>
	<td class="line x" title="76:159	Starting from a submatrix, the algorithm successively adds to the submatfix the word with the largest Chi-square score among all words outside the submatrix." ></td>
	<td class="line x" title="77:159	Words are added until a local maximum is reached." ></td>
	<td class="line x" title="78:159	Finally, the appropriateness of the submatrix as a hypothesis of word associations is checked with heuristic criteria based on the sizes of the row and the column of the submatrix." ></td>
	<td class="line x" title="79:159	Currently, we use the following criteria for appropriateness of a submatrix: LET 1 : size of row of submatfix m : size of column of submatrix C1, C2, C3 : parameters IF 1 > C1, and m > C1, and 1 > C2 or m/l < C3, and m > C2 or l/m < C3 THEN the submatrix is appropriate." ></td>
	<td class="line x" title="80:159	For any submatrix found, the co-occurrence observations for the clustered words are removed from the word cooccurrence matrix and treated as a single column of clustered nouns and a single row of clustered verb plus case pairs." ></td>
	<td class="line x" title="81:159	Currently, we use the following values for the parameters: C1=2, C2=10, and C3=10." ></td>
	<td class="line x" title="82:159	Table 1." ></td>
	<td class="line x" title="83:159	shows an example of clustering starting from the initial submatrix shown in Figure 2." ></td>
	<td class="line x" title="84:159	The words in Figure 2 were manually selected as words meaning 'organization'." ></td>
	<td class="line x" title="85:159	In Table 1, the first (leftmost) column indicates the word which was added to the submatfix at each step." ></td>
	<td class="line x" title="86:159	The second column gives an English gloss of the word." ></td>
	<td class="line x" title="87:159	The third column reports fix,Y), the frequency of the co-occurrences between the word and the words that co-occur with it." ></td>
	<td class="line x" title="88:159	For example, the first line of the table shows that the word '~/~L' (establish/-acc) co-occurred with the 'organization' words 26 times." ></td>
	<td class="line x" title="89:159	The rightmost column specifies I(X,Y), the scaled mutual information between the rows and columns of the submatrix." ></td>
	<td class="line x" title="90:159	As the clustering proceeds, I(X,Y) gets larger." ></td>
	<td class="line x" title="91:159	~_~(company), ;~k:~l\](head quarter), mS(organization), ~(coorporation), iitij:~.J:(both companies), ~(school), ~:~t\](the company), zj~:~i(child company), ~l~(bank), ~/~(department store), ~t~t~\]~(agency), ~n0(coop.), ~j:~IXbusiness company), ~.~(city bank), ~)~(stand), ~-~ ~\[~l~(trust bank), 3~/~(branch), ~-~ ~(credit association), :~k)~(head store), ~--~--(university), :~-:~(each company), --~\] ~-~ (department store), JAR(agriculture cooperative), --~ --(maker), :~:)~(book store), if' L,' I~')-~j(TV station), 7~ :Y' ~ ~ ~ M(agency), X --)'~(superrnarket), ~\[~tXjoint-stock corporation), ~(doctoFs office), )~(all stores) Figure 2: The initial word group (submatrix) for the clustering shown in Table 1." ></td>
	<td class="line x" title="92:159	250 Word added ~/~ ~/~ ~/~ ~/~ ~/~I~< ~ ~/~ ~/~ ~/~ ~/~ ~/~A ~/~ fi/~ ~z/ ~ z~ ~z/~ ~/~ ~/~ ~/~ ~z/~ ~/~\]~ ~A Z~Z ATT Gloss establish/-acc tie-up/with tie-up/-nom unite/with cooperate/-nom possess/-nom unite/-nom advance/-nom in succession proceed/-nom purchase/-acc entrust/-acc produce/-nom develop/-nom invest/-nom expand/with develop/-nom publish/-nom agree/-nom demand/from invest/in sell/-nom purchase/-nom open/-acc introduce/from create/-nom utilize/at limit/to treat/-nom connect/-nom do/-nom exclude/-acc oppose/to sign/-copula sell/to participate/in corporation major Japan Nisho-Iwai three parties Drug Company Sony dealer Institution Honda Mitsubishi AT&T Air Line respectively Honda Freq 26 25 18 11 7 8 7 6 5 4 5 6 6 7 6 3 3 4 3 3 5 7 3 4 3 3 3 3 3 3 5 3 3 3 4 4 9 5 5 4 3 4 5 5 5 4 3 3 4 3 3 I 0.11 0.19 0.25 0.29 0.32 0.35 0.38 0.40 0.43 0.44 0.46 0.47 0.49 0.51 0.52 0.54 0.55 0.56 0.58 0.59 0.60 0.61 0.63 0.64 0.65 0.66 0.67 0.68 0.69 0.69 0.70 0.71 0.71 0.72 0.72 0.72 0.74 0.75 0.77 0.78 0.79 0.80 0.81 0.81 0.82 0.83 0.83 0.84 0.84 0.85 0.85 ~t~ Bank 7 0.85 ~j~:~ Air Line 6 0.85 ~-~.~ Trust Company 4 0.85 ~I~ Steel Company 4 0.85 Table 1: Example of Clustering 7." ></td>
	<td class="line x" title="93:159	EVALUATION Using 280,000 words of Japanese source text from the TIPSTER joint ventures domain, we tried several variations of the initial submatrices (word groups) from which the search in step three of the method starts: a) complete bipartite subgraphs, b) pre-classified noun groups and c) significantly frequent word pairs." ></td>
	<td class="line x" title="94:159	Based on the results of the experiments, we concluded that alternative (b) gives both the most accurate word associations and the highest coverage of word associations." ></td>
	<td class="line x" title="95:159	This technique is practical because classification of nouns is generally much simpler than that of verbs." ></td>
	<td class="line x" title="96:159	We don't propose any automatic algorithm to accomplish noun classification, but instead note that we were able to manually classify nouns in less than ten categories at about 500 words/hour." ></td>
	<td class="line x" title="97:159	That productivity was achieved using our new tool for manual word classification, which is partially inspired by EDR's way of classifying their semantic lexical data \[Matsukawa and Yokota, 1991 \]." ></td>
	<td class="line x" title="98:159	Based on a corpus of 280,000 words in the TIPSTER joint ventures domain, the most frequently occurring Japanese nouns, proper nouns, and verbs were automatically identified." ></td>
	<td class="line x" title="99:159	Then, a student classified the frequently occurring nouns into one of the twelve categories in (1) below, and each frequently occurring proper noun into one of the four categories in (2) below, using a menu-based tool, we were able to categorize 3,195 lexical entries in 12 person-hours." ></td>
	<td class="line x" title="100:159	3 These categories were then used as input to the word co-occurrence algorithm." ></td>
	<td class="line x" title="101:159	1." ></td>
	<td class="line x" title="102:159	Common noun categories 1 a. Organization CORPORATION GOVERNMENT UNDETERMINED-CORPORATION OTHER-ORGANIZATION 1 b. Location CITY COUNTRY PROVINCE 3 We divided the process of classifying common nouns into two phases; classification into the four categories la, lb, lc and ld, and further classification into the twelve categories." ></td>
	<td class="line x" title="103:159	As a result, each word was checked twice." ></td>
	<td class="line x" title="104:159	We found that using two phases generally improves both overall productivity and consistency." ></td>
	<td class="line x" title="105:159	251 OTHER-LOCATION 1 c. Person ENTITY-OFFICER TrlLE OTHER-PERSON 1 d. Other 2." ></td>
	<td class="line x" title="106:159	Proper noun categories ORGANIZATION LOCATION PERSON OTHER Using the 280,000 word joint venture corpus, we collected 14,407 word co-occurrences, involving 3,195 nouns and 4,365 verb/argument pairs, by the finite state pattern given in Section 5." ></td>
	<td class="line x" title="107:159	16 submatrices were clustered, grouping 810 observed word co-occurrences and 6,240 unobserved (or hypothesized) word co-occurrences." ></td>
	<td class="line x" title="108:159	We evaluated the accuracy of the system by manual review of a random sample of 500 hypothesized word co-occurrences." ></td>
	<td class="line x" title="109:159	Of these, 435, or 87% were judged reasonable." ></td>
	<td class="line x" title="110:159	This ratio is fine compared with a random sample of 500 arbitrary word cooccurrences between the 3,195 nouns and the 4,365 verb/argument pairs, of which only 153 (44%) were judged reasonable." ></td>
	<td class="line x" title="111:159	Table 2 below shows some examples judged reasonable; questionable examples are marked by '?'; unreasonable hypotheses are marked with an asterisk." ></td>
	<td class="line x" title="112:159	With a small corpus (280,000 words) such as ours, considering small frequency co-occurrences is critical." ></td>
	<td class="line x" title="113:159	Looking at Table 3 below, if we had to ignore cooccurrences with frequency less than five (as \[Church and Hanks 1990\] did), there would be very little data." ></td>
	<td class="line x" title="114:159	With our method, as long as the frequency of co-occurrence of the word being considered with the set is greater than two, the statistic is stable." ></td>
	<td class="line x" title="115:159	Frequency Number of Word Pairs 0 6240 1 631 2 113 3 36 4 18 5 4 6 2 7 3 9 1 10 1 16 1 Table 3: Pair Frequencies 8." ></td>
	<td class="line x" title="116:159	CONCLUSION Our method achieved fully automatic hypothesis of word associations, starting from untagged text and generalizing to unobserved word associations." ></td>
	<td class="line x" title="117:159	As a result of human review 87% of the hypotheses were judged to be reasonable." ></td>
	<td class="line x" title="118:159	Because the technique considers low frequency cases, most of the data was used in making generalizations." ></td>
	<td class="line x" title="119:159	It remains to be determined how well this method will work for English, but with appropriate finite state patterns, similar results may be achieved." ></td>
	<td class="line x" title="120:159	(owner) (take office/as) A T T ~' 6/~X (AT&T) (introduceA~rom) ~$\[\] ~:/~ (melropolitan) (build/at) (personnel) (dispatch/-acc) (Commitee) (unite/with) (library) (sell/-nom) (Company) (organize/-acc) ~r~ ~/~ (agency) (publish/-nom) (post office) (tie-up/with) ~t ~:/~ (State) (developAo) (Cannon) (enter/-acc) ~ ~:/~ (doctor's office) (limit/to) (nations) (haveAn) ~ ~/~ (Nomura) (prroduce/-nom) ~ ~/~ (station employee) (take office/-nom) D R A M ~/~ (DRAM) (unite/-nom) (Switzerland) (see/-nom) ~ ~:/~ (director) (announce/to) Table 2: Examples of reasonable hypothesized cooccurrences ACKNOWLEDGMENTS The author wishes to thank Madeleine Bates, Ralph Weischedel and Sean Boisen for significant contributions to this paper." ></td>
	<td class="line x" title="121:159	252 1." ></td>
	<td class="line x" title="122:159	2. 3." ></td>
	<td class="line x" title="123:159	4. 5." ></td>
	<td class="line x" title="124:159	6. 7." ></td>
	<td class="line x" title="125:159	8. 9." ></td>
	<td class="line x" title="126:159	10." ></td>
	<td class="line x" title="127:159	REFERENCES Brent, M.R., (1991) 'Automatic Acquisition of Subcategorization Frames from Untagged Text,' Proceedings of the 29th annual Meeting of the ACL, pp." ></td>
	<td class="line x" title="128:159	209-214." ></td>
	<td class="line x" title="129:159	Brown, P.F., et." ></td>
	<td class="line x" title="130:159	al., (1992) 'Class-based N-gram Models of Natural Language,' Computational Linguistics Vol." ></td>
	<td class="line x" title="131:159	18 (4), pp." ></td>
	<td class="line x" title="132:159	467-479." ></td>
	<td class="line x" title="133:159	Church, K. and Hanks, P. , (1990) 'Word Association Norms, Mutual Information, and Lexicography,' Computational Linguistics Vol." ></td>
	<td class="line x" title="134:159	16 (1), pp.22-29." ></td>
	<td class="line oc" title="135:159	Hindle, D. , (1990) 'Noun Classification from Predicate-Argument Structures,' Proceedings of the 28th Annual Meeting of the ACL, pp." ></td>
	<td class="line x" title="136:159	268-275." ></td>
	<td class="line x" title="137:159	Hoel P. G., (1971): Introduction to Mathematical Statistics, Chapter 9." ></td>
	<td class="line x" title="138:159	2. Resnik, P. , (1992) 'A Class-based Approach to Lexical Discovery,' Proceedings of the 30th Annual Meeting of the ACL, pp." ></td>
	<td class="line x" title="139:159	327-329." ></td>
	<td class="line x" title="140:159	Smadja F.A. and McKeown, K.R., (1990) 'Automatically Extracting and Representing Collocations for Language Generation,' Proceedings of the 28th Annual Meeting of the ACL, pp." ></td>
	<td class="line x" title="141:159	252-259." ></td>
	<td class="line x" title="142:159	Matsukawa T. , Miller S. and Weischedel R." ></td>
	<td class="line x" title="143:159	(1993) 'Example-based Correction of Word Segmentation and Part of Speech Labelling,' Proceedings of DARPA Human Language Technologies Workshop." ></td>
	<td class="line x" title="144:159	Matsukawa, T. and Yokota, E." ></td>
	<td class="line x" title="145:159	(1991) 'Development of the Concept Dictionary Implementation of Lexical Knowledge,' Proc." ></td>
	<td class="line x" title="146:159	of pre-conference workshop sponsored by the special Interest Group on the Lexicon (SIGLEX) of the Association for Computational Linguistics, 1991." ></td>
	<td class="line x" title="147:159	Weischedel, R. et al.(1991) 'Partial Parsing: A Report on Work in Progress,' Proceedings of the Workshop on Speech and Natural Language, pp." ></td>
	<td class="line x" title="149:159	204210." ></td>
	<td class="line x" title="150:159	APPENDIX: JUSTIFICATION OF CHI SQUARE Chi-square score is given by the following formula : I(X, Y)= ~ I(X, Y) p(X, Y) E p(X, Y' Io = / gp-~-p~) (0) where .,~ Y= columns and rows of a word co-occurrence matrix X, Y = subsets of X~ Y, respectively (i.e. word classes at the columns and the rows) This can be justified as follows." ></td>
	<td class="line x" title="151:159	According to \[Hoel 1971\], the likelihood ratio LAMBDA for a test of the hypothesis: p(i) = po(i) (i = 1, 2  k), where p(i) is the probability of case i and po(i) is a hypothesized probability of it, when observations are independent of each other, is given as: k, n(i) -2 log LAMBDA 2 ~ n(i) (1) = log~ i=l where n(i) is the number of observations of case i, and e(i) is its expectation, i.e., e(i) = n p(i), where n is the total number of observations." ></td>
	<td class="line x" title="152:159	The distribution is chi-square when n is large." ></td>
	<td class="line x" title="153:159	If we assume two word classes, ci and cj, occur independently, then the expected value of the probability of their cooccurrence will be, e(ci, cj)= n p(ci) p(cj) (2) where p(ci) and p(cj) are estimations of the probability of occurrence of ci and cj." ></td>
	<td class="line x" title="154:159	The maximum likelihood estimate of p(ci) and p(cj) is f(ci)/n and f(cj)/n, where f(cj) and f(cj) are the number of observations of words classified in ci and cj." ></td>
	<td class="line x" title="155:159	The maximum likelihood estimate of p(ci, cj), the probability of the co-occurrences of words in ci and cj, is f(ci, cj)/n, where f(ci, cj) is the number of observations of the co-occurrences." ></td>
	<td class="line x" title="156:159	Then the number of the co-occurrences n(ci, cj) (which is the same as f(ci, cj) ) can be represented as, n(ci, cj)= n p(ci, cj) (3) Therefore, given k classes, cl, c2  ck, substituting (2) and (3) into (1)." ></td>
	<td class="line x" title="157:159	k i p(ci, c j) 2 ~ ~ np(ci, cj)log i=0j=0 p(~i) }~(-~j ) (4) If n is large, this will have a chi-square distribution; therefore, we can estimate how unlikely our assumption of independence among word classes is. Since formula (4) gives a scaled average mutual information among the word classes, searching for a partition of words that provides maximum average mutual information among word classes is equivalent to seeking classes where independence among word classes is minimally likely." ></td>
	<td class="line x" title="158:159	The algorithm reported in this paper searches for pairs of word classes which provide a local maximum I(X, Y), a term in the summation of formula (0)." ></td>
	<td class="line x" title="159:159	253" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="J93-2002
From Grammar To Lexicon: Unsupervised Learning Of Lexical Syntax
Brent, Michael R.;"></td>
	<td class="line x" title="1:359	From Grammar to Lexicon: Unsupervised Learning of Lexical Syntax Michael R. Brent* Johns Hopkins University Imagine a language that is completely unfamiliar; the only means of studying it are an ordinary grammar book and a very large corpus of text." ></td>
	<td class="line x" title="2:359	No dictionary is available." ></td>
	<td class="line x" title="3:359	How can easily recognized, surface grammatical facts be used to extract from a corpus as much syntactic information as possible about individual words?" ></td>
	<td class="line x" title="4:359	This paper describes an approach based on two principles." ></td>
	<td class="line x" title="5:359	First, rely on local morpho-syntactic cues to structure rather than trying to parse entire sentences." ></td>
	<td class="line x" title="6:359	Second, treat these cues as probabilistic rather than absolute indicators of syntactic structure." ></td>
	<td class="line x" title="7:359	Apply inferential statistics to the data collected using the cues, rather than drawing a categorical conclusion from a single occurrence of a cue." ></td>
	<td class="line x" title="8:359	The effectiveness of this approach for inferring the syntactic frames of verbs is supported by experiments on an English corpus using a program called Lerner." ></td>
	<td class="line x" title="9:359	Lerner starts out with no knowledge of content words--it bootstraps from determiners, auxiliaries, modals, prepositions, pronouns, complementizers, coordinating conjunctions, and punctuation." ></td>
	<td class="line x" title="10:359	1." ></td>
	<td class="line x" title="11:359	Introduction This paper presents a study in the automatic acquisition of lexical syntax from naturally occurring English text." ></td>
	<td class="line x" title="12:359	It focuses on discovering the kinds of syntactic phrases that can be used to represent the semantic arguments of particular verbs." ></td>
	<td class="line x" title="13:359	For example, want can take an infinitive argument and hope a tensed clause argument, but not vice versa: (1) a. b. c. d. John wants Mary to be happy." ></td>
	<td class="line x" title="14:359	John hopes that Mary is happy." ></td>
	<td class="line x" title="15:359	*John wants that Mary is happy." ></td>
	<td class="line x" title="16:359	*John hopes Mary to be happy." ></td>
	<td class="line x" title="17:359	This study focuses on the ability of verbs to take arguments represented by infinitives, tensed clauses, and noun phrases serving as both direct and indirect objects." ></td>
	<td class="line x" title="18:359	These lexical properties are similar to those that Chomsky (1965) termed subcategorization frames, but to avoid confusion the properties under study here will be referred to as syntactic frames or simply frames." ></td>
	<td class="line x" title="19:359	The general framework for the problems addressed in this paper can be thought of as follows." ></td>
	<td class="line x" title="20:359	Imagine a language that is completely unfamiliar; the only means of studying it are an ordinary grammar book and a very large corpus of text (or transcribed speech)." ></td>
	<td class="line x" title="21:359	No dictionary is available." ></td>
	<td class="line x" title="22:359	How can easily recognized, surface grammatical * Department of Cognitive Science, Johns Hopkins University, Baltimore MD 21218; michael@mail.cog.jhu.edu (~) 1993 Association for Computational Linguistics Computational Linguistics Volume 19, Number 2 facts be used to extract from a corpus as much syntactic information as possible about individual words?" ></td>
	<td class="line x" title="23:359	The scenario outlined above is adopted in this paper as a framework for basic research in computational language acquisition." ></td>
	<td class="line x" title="24:359	However, it is also an abstraction of the situation faced by engineers building natural language processing (NLP) systems for more familiar languages." ></td>
	<td class="line x" title="25:359	The lexicon is a central component of NLP systems and it is widely agreed that current lexical resources are inadequate." ></td>
	<td class="line x" title="26:359	Language engineers have access to some but not all of the grammar, and some but not all of the lexicon." ></td>
	<td class="line x" title="27:359	The most easily formalized and most reliable grammatical facts tend to be those involving auxiliaries, rnodals, and determiners, the agreement and case properties of pronouns, and so on." ></td>
	<td class="line x" title="28:359	These vary little from speaker to speaker, topic to topic, register to register." ></td>
	<td class="line x" title="29:359	Unfortunately, this information is not sufficient to parse sentences completely, a fact that is underscored by the current state of the parsing art." ></td>
	<td class="line x" title="30:359	If sentences cannot be parsed completely and reliably then the syntactic frames used in them cannot be determined reliably." ></td>
	<td class="line x" title="31:359	How, then, can reliable, easily formalized grammatical information be used to extract syntactic facts about words from a corpus?" ></td>
	<td class="line x" title="32:359	This paper suggests the following approach: Do not try to parse sentences completely." ></td>
	<td class="line x" title="33:359	Instead, rely on local morpho-syntactic cues such as the following facts about English: (1) The word following a determiner is unlikely to be functioning as a verb; (2) The sequence that the typically indicates the beginning of a clause." ></td>
	<td class="line x" title="34:359	Do not try to draw categorical conclusions about a word on the basis of one or a fixed number of examples." ></td>
	<td class="line x" title="35:359	Instead, attempt to determine the distribution of exceptions to the expected correspondence between cues and syntactic frames." ></td>
	<td class="line x" title="36:359	Use a statistical model to determine whether the cooccurrence of a verb with cues for a frame is too regular to be explained by randomly distributed exceptions." ></td>
	<td class="line x" title="37:359	The effectiveness of this approach for inferring the syntactic frames of verbs is supported by experiments using an implementation called Lerner." ></td>
	<td class="line x" title="38:359	In the spirit of the problem stated above, Lerner starts out with no knowledge of content words--it bootstraps from determiners, auxiliaries, modals, prepositions, pronouns, complementizers, coordinating conjunctions, and punctuation." ></td>
	<td class="line x" title="39:359	Lerner has two independent components corresponding to the two strategies listed above." ></td>
	<td class="line x" title="40:359	The first component identities sentences where a particular verb is likely to be exhibiting a particular syntactic frame." ></td>
	<td class="line x" title="41:359	It does this using local cues, such as the that the cue." ></td>
	<td class="line x" title="42:359	This component keeps track of the number of times each verb appears with cues for each syntactic frame as well as the total number of times each verb occurs." ></td>
	<td class="line x" title="43:359	This process can be described as collecting observations and its output as an observations table." ></td>
	<td class="line x" title="44:359	A segment of an actual observations table is shown in Table 4." ></td>
	<td class="line x" title="45:359	The observations table serves as input to the statistical modeler, which ultimately decides whether the accumulated evidence that a particular verb manifests a particular syntactic frame in the input is reliable enough to warrant a conclusion." ></td>
	<td class="line x" title="46:359	To the best of my knowledge, this is the first attempt to design a system that autonomously learns syntactic frames from naturally occurring text." ></td>
	<td class="line x" title="47:359	The goal of learning syntactic frames and the learning framework described above lead to three major differences between the approach reported here and most recent work in learning grammar from text." ></td>
	<td class="line x" title="48:359	First, this approach leverages a little a priori grammatical knowledge using statistical inference." ></td>
	<td class="line oc" title="49:359	Most work on corpora of naturally occurring language 244 Michael R. Brent From Grammar to Lexicon either uses no a priori grammatical knowledge (Brill and Marcus 1992; Ellison 1991; Finch and Chater 1992; Pereira and Schabes 1992), or else it relies on a large and complex grammar (Hindle 1990, 1991)." ></td>
	<td class="line x" title="50:359	One exception is Magerman and Marcus (1991), in which a small grammar is used to aid learning." ></td>
	<td class="line x" title="51:359	1 A second difference is that the work reported here uses inferential rather than descriptive statistics." ></td>
	<td class="line x" title="52:359	In other words, it uses statistical methods to infer facts about the language as it exists in the minds of those who produced the corpus." ></td>
	<td class="line nc" title="53:359	Many other projects have used statistics in a way that summarizes facts about the text but does not draw any explicit conclusions from them (Finch and Chater 1992; Hindle 1990)." ></td>
	<td class="line x" title="54:359	On the other hand, Hindle (1991) does use inferential statistics, and Brill (1992) recognizes the value of inference, although he does not use inferential statistics per se." ></td>
	<td class="line x" title="55:359	Finally, many other projects in machine learning of natural language use input that is annotated in some way, either with part-of-speech tags (Brill 1992; Brill and Marcus 1992; Magerman and Marcus 1990) or with syntactic brackets (Pereira and Schabes 1992)." ></td>
	<td class="line x" title="56:359	The remainder of the paper is organized as follows." ></td>
	<td class="line x" title="57:359	Section 2 describes the morphosyntactic cues Lerner uses to collect observations." ></td>
	<td class="line x" title="58:359	Section 3 presents the main contribution of this paper--the statistical model and experiments supporting its effectiveness." ></td>
	<td class="line x" title="59:359	Finally, Section 4 draws conclusions and lays out a research program in machine learning of natural language." ></td>
	<td class="line x" title="60:359	2." ></td>
	<td class="line x" title="61:359	Collecting Observations This section describes the local morpho-syntactic cues that Lerner uses to identify likely examples of particular syntactic frames." ></td>
	<td class="line x" title="62:359	These cues must address two problems: finding verbs in the input and identifying phrases that represent arguments to the verb." ></td>
	<td class="line x" title="63:359	The next two subsections present cues for these tasks." ></td>
	<td class="line x" title="64:359	The cues presented here are not intended to be the last word on local cues to structure in English; they are merely intended to illustrate the feasibility of such cues and demonstrate how the statistical model accommodates their probabilistic correspondence to the true syntactic structure of sentences." ></td>
	<td class="line x" title="65:359	Variants of these cues are presented in Brent (1991a, 1991b)." ></td>
	<td class="line x" title="66:359	The final subsection summarizes the procedure for collecting observations and discusses a sample of the observations table collected from the Brown corpus." ></td>
	<td class="line x" title="67:359	2.1 Finding Verbs Lerner identifies verbs in two stages, each carried out on a separate pass through the corpus." ></td>
	<td class="line x" title="68:359	First, strings that sometimes occur as verbs are identified." ></td>
	<td class="line x" title="69:359	Second, occurrences of those strings in context are judged as likely or unlikely to be verbal occurrences." ></td>
	<td class="line x" title="70:359	The second stage is necessary because of lexical ambiguity." ></td>
	<td class="line x" title="71:359	The first stage uses the fact that all English verbs can occur both with and without the suffix -ing." ></td>
	<td class="line x" title="72:359	Words are taken as potential verbs if and only if they display this alternation in the corpus." ></td>
	<td class="line x" title="73:359	2 There are a few words that meet this criterion but do not occur as verbs, including income~incoming (,incame/incomed), ear~earring, her~herring, and middle~middling." ></td>
	<td class="line x" title="74:359	However, the second stage of verb detection, combined with the statistical criteria, prevent these pairs from introducing errors." ></td>
	<td class="line x" title="75:359	1 Brill and Marcus (1992) use a single grammatical rule in the test phase to supplement the rules their system learns, but no grammatical knowledge is used in the learning phase." ></td>
	<td class="line x" title="76:359	2 Morphological analyzers typically use a root lexicon to resolve the ambiguities in morphological adjustment rules (Karttunen 1983)." ></td>
	<td class="line x" title="77:359	The system described here uses rules similar to those of Karttunen and Wittenburg (1983), but it resolves the ambiguities using only the contents of the corpus." ></td>
	<td class="line x" title="78:359	This technique will be described in a subsequent paper." ></td>
	<td class="line x" title="79:359	245 Computational Linguistics Volume 19, Number 2 Lerner assumes that a potential verb is functioning as a verb unless the context suggests otherwise." ></td>
	<td class="line x" title="80:359	In particular, an occurrence of a potential verb is taken as a nonverbal occurrence only if it follows a determiner or a preposition other than to." ></td>
	<td class="line x" title="81:359	For example, was talking would be taken as a verb, but a talk would not." ></td>
	<td class="line x" title="82:359	This precaution reduces the likelihood that a singular count noun will be mistaken for a verb, since singular count nouns are frequently preceded by a determiner." ></td>
	<td class="line x" title="83:359	Finally, the only morphological forms that are used for learning syntactic frames are the stem form and the -ing form." ></td>
	<td class="line x" title="84:359	There are several reasons for this." ></td>
	<td class="line x" title="85:359	First, forms ending in -s are potentially ambiguous between third person singular present verbs and plural nouns." ></td>
	<td class="line x" title="86:359	Since plural nouns are not necessarily preceded by determiners (I like to take walks), they could pose a significant ambiguity problem." ></td>
	<td class="line x" title="87:359	Second, past participles do not generally take direct objects: knows me and knew me are OK, but not  is known me. Further, the past tense and past participle forms of some verbs are identical, while those of others are distinct." ></td>
	<td class="line x" title="88:359	As a result, using the -ed forms would have complicated the statistical model substantially." ></td>
	<td class="line x" title="89:359	Since the availability of raw text is not generally a limiting factor, it makes sense to wait for the simpler cases." ></td>
	<td class="line x" title="90:359	2.2 Identifying Argument Phrases When a putative occurrence of a verb is found, the next step is to identify the syntactic types of nearby phrases and determine whether or not they are likely to be arguments of the verb." ></td>
	<td class="line x" title="91:359	First, assume that a phrase P and a verb V have been identified in some sentence." ></td>
	<td class="line x" title="92:359	Lerner's strategy for determining whether P is an argument to V has two components:." ></td>
	<td class="line x" title="93:359	2." ></td>
	<td class="line x" title="94:359	If P is a noun phrase (NP), take it as an argument only if there is evidence that it is not the subject of another clause." ></td>
	<td class="line x" title="95:359	Regardless of P's category, take it as an argument only if it occurs to the right of V and there are no potential attachment points for P between V and P. For example, suppose that the sequence that the were identified as the left boundary of a clause in the sentence I want to tell him that the idea won'tfly." ></td>
	<td class="line x" title="96:359	Because pronouns like him almost never take relative clauses, and because pronouns are known at the outset, Lerner concludes that the clause beginning with that the is probably an argument of the verb tell." ></td>
	<td class="line x" title="97:359	3 It is always possible that it could be an argument of the previous verb want, but Lerner treats that as unlikely." ></td>
	<td class="line x" title="98:359	On the other hand, if the sentence were I want to tell the boss that the idea won'tfly, then Lerner cannot determine whether the clause beginning with that the is an argument to tell or is instead related to boss, as in I want to fire the boss that the workers don't trust." ></td>
	<td class="line x" title="99:359	Now consider specific cues for identifying argument phrases." ></td>
	<td class="line x" title="100:359	The phrase types for which data are reported here are noun phrases, infinitive verb phrases (VPs), and tensed clauses." ></td>
	<td class="line x" title="101:359	These phrase types yield three syntactic frames with a single argument and three with two arguments, as shown in Table 1." ></td>
	<td class="line x" title="102:359	The cues used for identifying these frames are shown in Tables 2 and 3." ></td>
	<td class="line x" title="103:359	Table 2 defines lexical categories that are referred to in Table 3." ></td>
	<td class="line x" title="104:359	The category V in Table 3 starts out empty and is filled as verbs are detected on the first pass." ></td>
	<td class="line x" title="105:359	'cap' stands for any capitalized word and 'cap+' for any sequence of capitalized words." ></td>
	<td class="line x" title="106:359	These cues are applied by matching them against the string of words immediately to the right of each verb." ></td>
	<td class="line x" title="107:359	For example, a verb V is 3 Thanks to Don Hindle for this observation (personal communication)." ></td>
	<td class="line x" title="108:359	246 Michael R. Brent From Grammar to Lexicon Table 1 The six syntactic frames studied in this paper." ></td>
	<td class="line x" title="109:359	SF Description Good Example Bad Example NP only greet them *arrive them tensed clause hope he'll attend *want he'll attend infinitive hope to attend *greet to attend NP & clause tell him he's a fool *yell him he's a fool NP & infinitive want him to attend *hope him to attend NP & NP tell him the story *shout him the story Table 2 Lexical categories used in the definitions of the cues." ></td>
	<td class="line x" title="110:359	SUBJ: I I he I she I we \[ they OBJ: me \[ him \[ us \[ them SUBJ OBJ: you \[ it \[ yours \[ hers \[ ours \[ theirs DET: a \[ an \[ the \[ her \[ hiS \[ its \[ my \[ our \[ their \[ your \[ this \[ that \[ whose +TNS: has \[ have\[ had \[ am \[ is \[ are \[ was \[ were \[ do \[ does \[ did \[ can \[ could \[ may \[ might \[ must \[ would CC: when \[ before \[ after \[ as \[ while \[ if PUNC: \[ ? \[ ! \[, \[ ; \[ : will \[ Table 3 Cues for syntactic frames." ></td>
	<td class="line x" title="111:359	The category V is initially empty and is filled out during the first pass." ></td>
	<td class="line x" title="112:359	'cap' stands for any capitalized word and 'cap+' stands for any sequence of capitalized words." ></td>
	<td class="line x" title="113:359	Frame Symbol Cues NP only NP (0BJ \[ SUBJ_0BJ I cap) (PUNC i CC) Tensed Clause cl (that (DET \] SUBJ \] SUBJ_0BJ \[ cap+)) SUBJ I (SUBJ_0BJ +TNS) Infinitive VP inf to V NP & clause NPcl (0BJ i SUBJ_0BJ \] cap+) cl NP & infinitive NPinf (0BJ \[ SUBJ_0BJ \[ cap+) inf NP & NP (dat)." ></td>
	<td class="line x" title="114:359	NPNP (0nJ I SUBJ_OBJ I cap+) NP 247 Computational Linguistics Volume 19, Number 2 Table 4 A sample of the data collected from the untagged Brown Corpus using the cues of Table 3." ></td>
	<td class="line x" title="115:359	V NP NPNP NPcl NPinf cl inf V NP NPNP NPcl NPinf cl inf recall 42 3 4 recur 5 recede 5 redeem 3 receive 106 4 redirect 2 reckon 10 rediscover 2 recognize 71 6 6 reduce 85 2 recommend 32 2 1 reek 2 reconcile 5 reel 2 record 97 2 2 refer 43 1 recount 5 refine 4 recover 14 4 1 reflect 41 1 recreate 2 refresh 4 recruit 11 refuel 3 refuse 22 1 recorded as having occurred with a direct object and no other argument phrase if V is followed by a pronoun of ambiguous case and then a coordinating conjunction, as in I'll see you when you return from Mexico." ></td>
	<td class="line x" title="116:359	The coordinating conjunction makes it unlikely that the pronoun is the subject of another clause, as in I see you like champagne." ></td>
	<td class="line x" title="117:359	It also makes it unlikely that the verb has an additional NP argument, as in I'II tell you my secret recipe." ></td>
	<td class="line x" title="118:359	2.3 Summary and Sample Data To summarize, the procedure for collecting observations from a corpus is as follows: 1." ></td>
	<td class="line x" title="119:359	Go through the corpus once finding pairs of words such that one is the result of adding the suffix -ing to the other, applying appropriate morphological adjustment rules." ></td>
	<td class="line x" title="120:359	List members of such pairs as verbs." ></td>
	<td class="line x" title="121:359	2." ></td>
	<td class="line x" title="122:359	Go through the corpus again." ></td>
	<td class="line x" title="123:359	At each word w that is on the list of verbs, (a) If w is not preceded by a preposition or a determiner, increment the number of times that w appears as a verb." ></td>
	<td class="line x" title="124:359	(b) If any of the cues listed in Table 3 match the words immediately following w, increment the number of times that w appears to occur in the corresponding frame." ></td>
	<td class="line x" title="125:359	3." ></td>
	<td class="line x" title="126:359	Combine the data for the stem form and the -ing form." ></td>
	<td class="line x" title="127:359	Table 4 shows an alphabetically contiguous portion of the observations table that results from applying this procedure to the Brown Corpus (untagged)." ></td>
	<td class="line x" title="128:359	Each row represents data collected from one pair of words, including both the -ing form and the stem form." ></td>
	<td class="line x" title="129:359	The first column, titled V, represents the total number of times the word occurs in positions where it could be functioning as a verb." ></td>
	<td class="line x" title="130:359	Each subsequent column represents a single frame." ></td>
	<td class="line x" title="131:359	The number appearing in each row and column represents the number of times that the row's verb cooccurred with cues for the column's frame." ></td>
	<td class="line x" title="132:359	Zeros are omitted." ></td>
	<td class="line x" title="133:359	Thus recall and recalling occurred a combined total of 42 times, excluding those occurrences that followed determiners or prepositions." ></td>
	<td class="line x" title="134:359	Three of those occurrences were followed by a cue for a single NP argument and four were followed by cues for a tensed clause argument." ></td>
	<td class="line x" title="135:359	248 Michael R. Brent From Grammar to Lexicon Table 5 Judgments based on the observations in Table 4, made by the method of Section 3." ></td>
	<td class="line x" title="136:359	recall NP, cl recognize NP, cl recover NP refuse inf The cues are fairly rare, so verbs in Table 4 that occur fewer than 15 times tend not to occur with these cues at all." ></td>
	<td class="line x" title="137:359	Further, these cues occur fairly often in structures other than those they are designed to detect." ></td>
	<td class="line x" title="138:359	For example, record, recover, and refer all occurred with cues for an infinitive, although none of them in fact takes an infinitive argument." ></td>
	<td class="line x" title="139:359	The sentences responsible for these erroneous observations are: (2) (a) (b) (c) (d) But I shall campaign on the Meyner record to meet the needs of the years ahead." ></td>
	<td class="line x" title="140:359	Sposato needed a front, some labor stiff with a clean record to act as business agent of the Redhook local." ></td>
	<td class="line x" title="141:359	Then last season the Birds tumbled as low as 11-18 on May 19 before recovering to make a race of it and total 86 victories." ></td>
	<td class="line x" title="142:359	But I suspect that the old Roman was referring to change made under military occupation--the sort of change which Tacitus was talking about when  In (2a,b) record occurs as a noun." ></td>
	<td class="line x" title="143:359	In (2c) recover is a verb but the infinitive VP, to make a race of it  does not appear to be an argument." ></td>
	<td class="line x" title="144:359	In any case, it does not bear the same relation to the verb as the infinitive arguments of verbs like try, want, hope, ask, and refuse." ></td>
	<td class="line x" title="145:359	In (2d) refer is a verb but to change is a PP rather than an infinitive." ></td>
	<td class="line x" title="146:359	The remainder of this paper describes and evaluates a method for making judgments about the ability of verbs to appear in particular syntactic frames on the basis of noisy data like that of Table 4." ></td>
	<td class="line x" title="147:359	Given the data in Table 4, that method yields the judgments in Table 5." ></td>
	<td class="line x" title="148:359	3. Statistical Modeling As noted above, the correspondence between syntactic structure and the cues that Lerner uses is not perfect." ></td>
	<td class="line x" title="149:359	Mismatches between cue and structure are problematic because naturally occurring language provides no negative evidence." ></td>
	<td class="line x" title="150:359	If a V verb is followed by a cue for some syntactic frame S, that provides evidence that V does occur in frame S, but there is no analogous source of evidence that V does not occur in frame S. The occurrence of mismatches between cue and structure can be thought of as a random process where each occurrence of a verb V has some non-zero probability of being followed by a cue for a frame S, even if V cannot in fact occur in S. If this model is accurate, the more times V occurs, the more likely it is to occur at least once with a cue for S. The intransitive verb arrive, for example, will eventually occur with a cue for an NP argument, if enough text is considered." ></td>
	<td class="line x" title="151:359	A learner that considers a single occurrence of verb followed by a cue to be conclusive evidence will eventually come to the false conclusion that arrive is transitive." ></td>
	<td class="line x" title="152:359	In other words, the information 249 Computational Linguistics Volume 19, Number 2 provided by the cues will eventually be washed out by the noise." ></td>
	<td class="line x" title="153:359	This problem is inherent in learning from naturally occurring language, since infallible parsing is not possible." ></td>
	<td class="line x" title="154:359	The only way to prevent it is to consider the frequency with which each verb occurs with cues for each frame." ></td>
	<td class="line x" title="155:359	In other words, to consider each occurrence of V without a cue for S as a small bit of evidence against V being able to occur in frame S. This section describes a statistical technique for weighing such evidence." ></td>
	<td class="line x" title="156:359	Given a syntactic frame S, the statistical model treats each verb V as analogous to a biased coin and each occurrence of V as analogous to a flip of that coin." ></td>
	<td class="line x" title="157:359	An occurrence that is followed by a cue for S corresponds to one outcome of the coin flip, say heads; an occurrence without a cue for S corresponds to tails." ></td>
	<td class="line x" title="158:359	4 If the cues were perfect predictors of syntactic structure then a verb V that does not in fact occur in frame S would never appear with cues for S--the coin would never come up heads." ></td>
	<td class="line x" title="159:359	Since the cues are not perfect, such verbs do occur with cues for S. The problem is to determine when a verb occurs with cues for S often enough that all those occurrences are unlikely to be errors." ></td>
	<td class="line x" title="160:359	In the following discussion, a verb that in fact occurs in frame S in the input is described as a +S verb; one that does not is described as a -S verb." ></td>
	<td class="line x" title="161:359	The statistical model is based on the following approximation: for fixed S, all -S verbs have equal probability of being followed by a cue for S. Let ~r-s stand for that probability." ></td>
	<td class="line x" title="162:359	~r-s may vary from frame to frame, but not from verb to verb." ></td>
	<td class="line x" title="163:359	Thus, errors might be more common for tensed clauses than for NPs, but the working hypothesis is that all intransitives, such as saunter and arrive, are about equally likely to be followed by a cue for an NP argument." ></td>
	<td class="line x" title="164:359	If the error probability ~r-s were known, then we could use the standard hypothesis testing method for binomial frequency data." ></td>
	<td class="line x" title="165:359	For example, suppose 7r-s = .05--on average, one in twenty occurrences of a -S verb is followed by a cue for S. If some verb V occurs 200 times in the corpus, and 20 of those occurrences are followed by cues for S, that ought to suggest that V is unlikely to have probability .05 of being followed by a cue for S, and hence V is unlikely to be -S." ></td>
	<td class="line x" title="166:359	Specifically, the chance of flipping 20 or more heads out of 200 tosses of a coin with a five percent chance of coming up heads each time is less than three in 1000." ></td>
	<td class="line x" title="167:359	On the other hand, it is not all that unusual to flip 2 or more heads out of 20 on such a coin--it happens about one time in four." ></td>
	<td class="line x" title="168:359	If a verb occurs 20 times in the corpus and 2 of those occurrences are followed by cues for S, it is quite possible that V is -S and that the 2 occurrences with cues for S are explained by the five percent error rate on -S verbs." ></td>
	<td class="line x" title="169:359	The next section reviews the hypothesis-testing method and gives the formulas for computing the probabilities of various outcomes of coin tosses, given the coin's bias." ></td>
	<td class="line x" title="170:359	It also provides empirical evidence that, for some values of 7r_s, hypothesis-testing does a good job of distinguishing +S verbs from -S verbs that occur with cues for S because of mismatches between cue and structure." ></td>
	<td class="line x" title="171:359	The following section proposes a method for estimating ~r-s and provides empirical evidence that its estimates are nearly optimal." ></td>
	<td class="line x" title="172:359	3.1 Hypothesis Testing The statistical component of Lerner is designed to prevent the information provided by the cues from being washed out by the noise." ></td>
	<td class="line x" title="173:359	The basic approach is hypothesis testing on binomial frequency data (Kalbfleisch 1985)." ></td>
	<td class="line x" title="174:359	Specifically, a verb V is shown to 4 Given a verb V, the outcomes of the coins for different S's are treated as approximately independent, even though they cannot be perfectly independent." ></td>
	<td class="line x" title="175:359	Their dependence could be modeled using a multinomial rather than a binomial model, but the experimental data suggest that this is unnecessary." ></td>
	<td class="line x" title="176:359	250 Michael R. Brent From Grammar to Lexicon be +S by assuming that it is -S and then showing that if this were true, the observed pattern of cooccurrence of V with cues for S would be extremely unlikely." ></td>
	<td class="line x" title="177:359	3.1.1 Binomial Frequency Data." ></td>
	<td class="line x" title="178:359	In order to use the hypothesis testing method we need to estimate the probability ~r-s that an occurrence of a verb V will be followed by a cue for S if V is -S." ></td>
	<td class="line x" title="179:359	In this section it is assumed that 7r_s is known." ></td>
	<td class="line x" title="180:359	The next section suggests a means of estimating Tr_s." ></td>
	<td class="line x" title="181:359	In both sections it is also assumed that for each +S verb, V, the probability that V will be followed by a cue for S is greater than 7r_s." ></td>
	<td class="line x" title="182:359	Other than that, no assumptions are made about the probability that a +S verb will be followed by a cue for S. For example, two verbs with transitive senses, such as cut and walk, may have quite different frequencies of cooccurrence with cues for NP." ></td>
	<td class="line x" title="183:359	It does not matter what these frequencies are as long as they are greater than lr_Np." ></td>
	<td class="line x" title="184:359	If a coin has probability p of flipping heads, and if it is flipped n times, the probability of its coming up heads exactly m times is given by the binomial distribution: n~ P(m,n,p) m!(n m)!" ></td>
	<td class="line x" title="185:359	pm(1 p)n-m (1) The probability of coming up heads m or more times is given by the obvious sum: n P(m+, n, p) = ~ P(i, n, p) (2) i=m Analogously, P(m+, n, ~r-s) gives the probability that m or more occurrences of a -S verb V will be followed by a cue for S out of n occurrences total." ></td>
	<td class="line x" title="186:359	If m out of n occurrences of V are followed by cues for S, and if P(m+, n, ~r-s) is quite small, then it is unlikely that V is -S." ></td>
	<td class="line x" title="187:359	Traditionally, a threshold less than or equal to .05 is set such that a hypothesis is rejected if, assuming the hypothesis were true, the probability of outcomes as extreme as the observed outcome would be below the threshold." ></td>
	<td class="line x" title="188:359	The confidence attached to this conclusion increases as the threshold decreases." ></td>
	<td class="line x" title="189:359	3.1.2 Experiment." ></td>
	<td class="line x" title="190:359	The experiment presented in this section is aimed at determining how well the method presented above can distinguish +S verbs from -S verbs." ></td>
	<td class="line x" title="191:359	Let p-s be an estimate of 7r_s." ></td>
	<td class="line x" title="192:359	It is conceivable that P(m+,n,p-s) might not be a good predictor of whether or not a verb is +S, regardless of the estimate p-s." ></td>
	<td class="line x" title="193:359	For example, if the correspondence between the cues and the structures they are designed to detect were quite weak, then many -S verbs might have lower P(m+,n,p-s) than many +S verbs." ></td>
	<td class="line x" title="194:359	This experiment measures the accuracy of binomial hypothesis testing on the data collected by Lerner's cues as a function of p-s." ></td>
	<td class="line x" title="195:359	In addition to showing that P(m+, n, P-s) is good for distinguishing +S and -S verbs, these data provide a baseline against which to compare methods for estimating the error rate 7r_s." ></td>
	<td class="line x" title="196:359	Method The cues described in Section 2 were applied to the Brown Corpus (untagged version)." ></td>
	<td class="line x" title="197:359	Equation 2 was applied to the resulting data with a cutoff of P(m+,n,p_s) < .02 and p-s varying between 2 -5 (1 error in every 32 occurrences) and 2 -13 (1 error in every 8192 occurrences)." ></td>
	<td class="line x" title="198:359	The resulting judgments were compared to the blind judgments of a single judge." ></td>
	<td class="line x" title="199:359	One hundred ninety-three distinct verbs were chosen at random from the tagged version of the Brown Corpus for comparison." ></td>
	<td class="line x" title="200:359	Common verbs are more likely to be included in the test sample than rare verbs, but 251 Computational Linguistics Volume 19, Number 2 Table 6 Comparison of automatic classification to hand judgments for tensed-clause complement as a function of estimated error rate p (Brown Corpus)." ></td>
	<td class="line x" title="201:359	PRE = (TP / TP + FP); REC = (TP / TP + FN)." ></td>
	<td class="line x" title="202:359	log2 p-ct p-c1 TP FP TN FN MC %MC PRE REC 5 .0312 13 0 30 20 20 32 1.00 .39 6 .0156 19 0 30 14 14 22 1.00 .58 7 .0078 22 1 29 11 12 19 .96 .67 8 .0039 25 1 29 8 9 14 .96 .76 9 .0020 27 3 27 6 9 14 .90 .82 10 .0010 29 5 25 4 9 14 .85 .88 11 .0005 31 8 22 2 10 16 .79 .94 12 .0002 31 13 17 2 15 24 .70 .94 13 .0001 33 19 11 0 19 30 .63 1.00 no verb is included more than once." ></td>
	<td class="line x" title="203:359	Each verb was scored for a given frame only if it cooccurs with a cue for that frame at least once." ></td>
	<td class="line x" title="204:359	Thus, although 193 verbs were randomly selected from the corpus for scoring, only the 63 that cooccur with a cue for tensed clause at least once were scored for the tensed-clause frame." ></td>
	<td class="line x" title="205:359	This procedure makes it possible to evaluate the hypothesis-testing method on data collected by the cues, rather than evaluating the cues per se." ></td>
	<td class="line x" title="206:359	It also makes the judgment task much easier--it is not necessary to determine whether a verb can appear in a frame in principle, only whether it does so in particular sentences." ></td>
	<td class="line x" title="207:359	There were, however, five cases where the judgments were unclear." ></td>
	<td class="line x" title="208:359	These five were not scored." ></td>
	<td class="line x" title="209:359	See Appendix C for details." ></td>
	<td class="line x" title="210:359	Results The results of these comparisons are summarized in Table 6 (tensed clause) and Table 7 (infinitive)." ></td>
	<td class="line x" title="211:359	Each row shows the performance of the hypothesis-testing procedure for a different estimate P-s of the error-rate 7r_s." ></td>
	<td class="line x" title="212:359	The first column shows the negative logarithm of P-s, which is varied from 5 (1 error in 32 occurrences) to 13 (1 error in 8192 occurrences)." ></td>
	<td class="line x" title="213:359	The second column shows P-s in decimal notation." ></td>
	<td class="line x" title="214:359	The next four columns show the number of true positives (TP)--verbs judged +S both by machine and by hand; false positives (FP)--verbs judged +S by machine, -S by hand; true negatives (TN)--verbs judged -S both by machine and by hand; and false negatives (FN)--verbs judged -S by machine, +S by hand." ></td>
	<td class="line x" title="215:359	The numbers represent distinct verbs, not occurrences." ></td>
	<td class="line x" title="216:359	The seventh column shows the number of verbs that were misclassified (MC)--the sum of false positives and false negatives." ></td>
	<td class="line x" title="217:359	The eighth column shows the percentage of verbs that were misclassified (%MC)." ></td>
	<td class="line x" title="218:359	The next-to-last column shows the precision (PRE)--the true positives divided by all verbs that Lerner judged to be +S. The final column shows the recall (REC)--the true positives divided by all verbs that were judged +S by hand." ></td>
	<td class="line x" title="219:359	Discussion For verbs taking just a tensed clause argument, Table 6 shows that, given the right estimate P-s of lr_s, it is possible to classify these 63 verbs with only 1 false positive and 8 false negatives." ></td>
	<td class="line x" title="220:359	If the error rate were ignored or approximated as zero then the false positives would go up to 19." ></td>
	<td class="line x" title="221:359	On the other hand, if the error rate were taken to be as high as 1 in 25 then the false negatives would go up to 20." ></td>
	<td class="line x" title="222:359	In this case, the sum of both error types is minimized with 2 -8 < P-c1 _< 2 -1." ></td>
	<td class="line x" title="223:359	Table 7 shows similar results for verbs taking just an infinitive argument, where misclassifications are minimized with p-inf = 2-7." ></td>
	<td class="line x" title="224:359	252 Michael R. Brent From Grammar to Lexicon Table 7 Comparison of automatic classification to hand judgments for infinitive complement, as a function of estimated error rate p (Brown Corpus)." ></td>
	<td class="line x" title="225:359	log 2 p-i,/ p-i,f TP FP TN FN MC %MC PRE REC 5 .0312 14 0 33 13 13 22 1.00 .52 6 .0156 16 0 33 11 11 18 1.00 .59 7 .0078 19 1 32 8 9 15 .95 .70 8 .0039 22 6 27 5 11 18 .79 .81 9 .0020 22 8 25 5 13 22 .73 .81 10 .0010 24 12 21 3 15 25 .67 .89 11 .0005 24 14 19 3 17 28 .63 .89 12 .0002 26 19 14 1 20 33 .58 .96 13 .0001 27 26 7 0 26 43 .51 1.00 3.2 Estimating the Error Rate As before, assume that an occurrence of a -S verb is followed by a cue for S with probability 7r_s." ></td>
	<td class="line x" title="226:359	Also as before, assume that for each +S verb V, the probability that an occurrence of V is followed by a cue for S is greater than 7r_s." ></td>
	<td class="line x" title="227:359	It is useful to think of the verbs in the corpus as analogous to a large bag of coins with various biases, or probabilities of coming up heads." ></td>
	<td class="line x" title="228:359	The only assumption about the distribution of biases is that there is some definite but unknown minimum bias 7r_s." ></td>
	<td class="line x" title="229:359	5 Determining whether or not a verb appears in frame S is analogous to determining, for some randomly selected coin, whether its bias is greater than ~r-s." ></td>
	<td class="line x" title="230:359	The only available evidence comes from selecting a number of coins at random and flipping them." ></td>
	<td class="line x" title="231:359	The previous section showed how this can be done given an estimate of ~r-s." ></td>
	<td class="line x" title="232:359	Suppose a series of coins is drawn at random from the bag." ></td>
	<td class="line x" title="233:359	Each coin is flipped N times." ></td>
	<td class="line x" title="234:359	It is then assigned to a histogram bin representing the number of times it came up heads." ></td>
	<td class="line x" title="235:359	At the end of this sampling procedure bin i contains the number of coins that came up heads exactly i times out of N. Such a histogram is shown in Figure 1, where N = 40." ></td>
	<td class="line x" title="236:359	If N is large enough and enough coins are flipped N times, one would expect the following: 1." ></td>
	<td class="line x" title="237:359	The coins whose probability of turning up heads is ~r-s (the minimum) should cluster at the low-heads end of the histogram." ></td>
	<td class="line x" title="238:359	That is, there should be some 0 __G j0 _< N such that most of the coins that turn up j0 heads or fewer have probability 7r_s, and, conversely, most coins with probability ~r-s turn up j0 heads or fewer." ></td>
	<td class="line x" title="239:359	2." ></td>
	<td class="line x" title="240:359	Suppose j0 were known." ></td>
	<td class="line x" title="241:359	Then the portion of the histogram below j0 should have a roughly binomial shape." ></td>
	<td class="line x" title="242:359	In Figure 1, for example, the first eight bins have roughly the shape one would expect if j0 were 8." ></td>
	<td class="line x" title="243:359	In contrast, the first 16 bins do not have the shape one would expect if j0 5 If the number of coins is taken to be infinite, then the biases must be not only greater than ~r-s but bounded above ~r-s." ></td>
	<td class="line x" title="244:359	253 Computational Linguistics Volume 19, Number 2 Number of Coins 0 0 8 16 24 32 40 Number of Heads Hipped Figure 1 A histogram illustrating a binomially shaped distribution in the first eight bins." ></td>
	<td class="line x" title="245:359	were 16---their height drops to zero for two stretches before rising significantly above zero again." ></td>
	<td class="line x" title="246:359	Specifically, the height of the i th histogram bin should be roughly proportional to P(i, N, P-s), with N the fixed sample size and P-s an estimate of 7r_s." ></td>
	<td class="line x" title="247:359	Suppose again that j0 were known." ></td>
	<td class="line x" title="248:359	Then the average rate at which the coins in bins j0 or lower flip heads is a good estimate of ~r-s." ></td>
	<td class="line x" title="249:359	The estimation procedure tries out each bin as a possible estimate of j0." ></td>
	<td class="line x" title="250:359	Each estimate of j0 leads to an estimate of ~r-s and hence to an expected shape for the first j0 histogram bins." ></td>
	<td class="line x" title="251:359	Each estimate j of j0 is evaluated by comparing the predicted distribution in the first j bins to the observed distribution--the better the fit, the better the estimate." ></td>
	<td class="line x" title="252:359	Moving from coins to verbs, the procedure works as follows." ></td>
	<td class="line x" title="253:359	For some fixed N, consider the first N occurrences of each verb that occurs at least N times in the input." ></td>
	<td class="line x" title="254:359	(A uniform sample size N is needed only for estimating 7r-s." ></td>
	<td class="line x" title="255:359	Given an estimate of 7r-s, verbs with any number of occurrences can be classified)." ></td>
	<td class="line x" title="256:359	Let S be some syntactic frame and let H\[i\] be the number of distinct verbs that were followed by cues for S exactly i times out of N--i.e. , the height of the ith histogram bin." ></td>
	<td class="line x" title="257:359	Assume that there is some 1 ~ j0 _< N such that most -S verbs are followed by cues for S j0 times or fewer, and conversely most verbs that are followed by cues for S j0 times or fewer are -S verbs." ></td>
	<td class="line x" title="258:359	For each possible estimate j of j0 there is a corresponding estimate of 7r_s; namely, the average rate at which verbs in the first j bins are followed by cues for S. Choosing the most plausible estimate of 7r_s thus comes down to choosing the most plausible estimate of j0, the boundary between the -S verbs and the rest of the histogram." ></td>
	<td class="line x" title="259:359	To evaluate the plausibility of each possible estimate j of j0, measure the fit between the predicted distribution of -S verbs, assuming j is the boundary of the -S cluster, and the observed distribution of the -S verbs, also assuming j is the boundary of the -S cluster." ></td>
	<td class="line x" title="260:359	Given j, let p-s stand for the average rate at which verbs in bins j or lower are followed by cues for S. The predicted distribution for -S verbs is proportional to P(i,N,p-s) for 0 < i < N. The observed distribution of -S verbs, assuming j is the boundary of the -S cluster, is H\[i\] for 0 < i < j and 0 for j < i < N. Measure the fit between the predicted and observed distributions by normalizing both to have unit area and taking the sum over 0 < i < N of the squares of the differences between the two distributions at each bin i. 254 Michael R. Brent From Grammar to Lexicon Table 8 Comparison of automatic classification using the Brown Corpus to hand judgments." ></td>
	<td class="line x" title="261:359	The estimate p-s is made with N = 100." ></td>
	<td class="line x" title="262:359	The probability threshold is .02." ></td>
	<td class="line x" title="263:359	S j p-s TP FP TN FN MC %MC PRE REC cl 2 0.0037 25 1 28 8 9 15 .96 .76 inf 2 0.0048 22 1 32 5 6 10 .96 .81 NPcl 1 0.0002 3 2 2 0 2 29 .60 1.00 NPinf 1 0.0005 5 0 3 2 2 20 1.00 .71 NPNP 3 0.0004 3 0 3 3 3 33 1.00 .50 NP 4 0.0132 52 1 5 59 60 51 .98 .47 total 110 5 73 74 79 30 .96 .60 In pseudo-code, the procedure is as follows: ESTIMATE-P(H \[\], N) area := H\[0\], rain-sum-of-squares := oo, best-estimate := I; Try each value of j from 1 to N as an estimate of jo for j from I tO N p-s :=0 area := area + H~\] for i from 0 to j Normalize the -S bins to area 1." ></td>
	<td class="line x" title="264:359	H\[i\] H'\[i\] := area Estimate ~r-s by the average cooccurrence rate for the first j bins--those presumed to hold S verbs P-s := p-s + (-~, H'\[i\]) Check the fit, assuming j is the :kS boundary sum-of-squares := 0 for i from 0 to N Compute the predicted distribution/or bin i N!" ></td>
	<td class="line x" title="265:359	~i /1 P := ~H-s~ -P-s) N-i Verbs in the first bins j and below are presumed S if i<_j then normalized-observed := H'\[i\] else normalized-observed := 0 sum-of-squares := sum-of-squares + (normalized-observed -p)2 Choose the p-s yielding the best~it if sum-of-squares < min-sum-of-squares then rain-sum-of-squares := sum-of-squares best-estimate := P-s return best-estimate 3.2.1 Experiment." ></td>
	<td class="line x" title="266:359	This section evaluates the proposed estimation technique empirically in terms of the errors it yields when the cues of Section 2 are applied to the Brown Corpus." ></td>
	<td class="line x" title="267:359	The sample selection and scoring procedures are the same as in the previous section." ></td>
	<td class="line x" title="268:359	When ~r-s is estimated using sample size N -100, Table 8 shows 255 Computational Linguistics Volume 19, Number 2 the results for each of the six frames." ></td>
	<td class="line x" title="269:359	Varying N between 50 and 150 results in no significant change in the estimated error rates." ></td>
	<td class="line x" title="270:359	One way to judge the value of the estimation and hypothesis-testing methods is to examine the false positives." ></td>
	<td class="line x" title="271:359	Three of the five false positives result from errors in verb detection that are not distributed uniformly across verbs." ></td>
	<td class="line x" title="272:359	In particular, shock, board, and near are used more often as nonverbs than as verbs." ></td>
	<td class="line x" title="273:359	This creates many opportunities for nonverbal occurrences of these words to be mistaken for verbal occurrences." ></td>
	<td class="line x" title="274:359	Other verbs, like know, are unambiguous and thus are not subject to this type of error." ></td>
	<td class="line x" title="275:359	As a result, these errors violate the model's assumption that errors are distributed uniformly across verbs and highlight the limitations of the model." ></td>
	<td class="line x" title="276:359	The remaining false positives were touch and belong, both mistaken as taking an NP followed by a tensed clause." ></td>
	<td class="line x" title="277:359	The touch error was caused by the capitalization of the first word of a line of poetry: I knew not what did to a friend belong Till I stood up, true friend, by thy true side; Till was mistaken for a proper name." ></td>
	<td class="line x" title="278:359	The belong error was caused by mistaking a matrix clause for an argument in: With the blue flesh of night touching him he stood under a gentle hill caressing the flageolet with his lips, making it whisper." ></td>
	<td class="line x" title="279:359	It seems likely that such input would be much rarer in more mundane sources of text, such as newspapers of record, than in the diverse Brown Corpus." ></td>
	<td class="line x" title="280:359	The results for infinitives and clauses can also be judged by comparison to the optimal classifications rates from Tables 6 and 7." ></td>
	<td class="line x" title="281:359	In both cases the classification appears to be right in the optimal range." ></td>
	<td class="line x" title="282:359	In fact, the estimated error rate for infinitives produces a better classification than any of those shown in Table 7." ></td>
	<td class="line x" title="283:359	(It falls at a value between those shown)." ></td>
	<td class="line x" title="284:359	The classification of clauses and infinitives remains in the optimal range when the probability threshold is varied from .01 to .05." ></td>
	<td class="line x" title="285:359	Overall the tradeoff between improved precision and reduced recall seems quite good, as compared to doing no noise reduction (P-s = 0)." ></td>
	<td class="line x" title="286:359	The only possible exception is the NP frame, where noise reduction causes 59 false negatives in exchange for preventing only 5 false positives." ></td>
	<td class="line x" title="287:359	This is partly explained by the different prior probabilities of the different frames." ></td>
	<td class="line x" title="288:359	Most verbs can take a direct object argument, whereas most verbs cannot take a direct object argument followed by a tensed clause argument." ></td>
	<td class="line x" title="289:359	There is no way to know this in advance." ></td>
	<td class="line x" title="290:359	There may be other factors as well." ></td>
	<td class="line x" title="291:359	If the error rate for the NP cues is substantially lower than 1 out of 100, then it cannot be estimated accurately with sample size N = 100." ></td>
	<td class="line x" title="292:359	On the other hand, if the sample size N is increased substantially there may not be enough verbs that occur N times or more in the corpus." ></td>
	<td class="line x" title="293:359	So a larger corpus might improve the recall rate for NP." ></td>
	<td class="line x" title="294:359	4." ></td>
	<td class="line x" title="295:359	General Discussion This paper explores the possibility of using simple grammatical regularities to learn lexical syntax." ></td>
	<td class="line x" title="296:359	The data presented in Tables 6, 7, and 8 provide evidence that it is possible to learn significant aspects of English lexical syntax in this way." ></td>
	<td class="line x" title="297:359	Specifically, these data suggest that neither a large parser nor a large lexicon is needed to recover enough syntactic structure for learning lexical syntax." ></td>
	<td class="line x" title="298:359	Rather, it seems that significant 256 Michael R. Brent From Grammar to Lexicon lexical syntactic information can be recovered using a few approximate cues along with statistical inference based on a simple model of the cues' error distributions." ></td>
	<td class="line x" title="299:359	4.1 Other Syntactic Frames The lexical entry of a verb can specify other syntactic frames in addition to the six studied here." ></td>
	<td class="line x" title="300:359	In particular, many verbs take prepositional phrases (PPs) headed by a particular preposition or class of prepositions." ></td>
	<td class="line x" title="301:359	For example, put requires a location as a second argument, and locations are often represented by PPs headed by locative prepositions." ></td>
	<td class="line x" title="302:359	Extending Lerner to detect PPs is trivial." ></td>
	<td class="line x" title="303:359	Since the set of prepositions in the language is essentially fixed, all prepositions can be included in the initial lexicon." ></td>
	<td class="line x" title="304:359	Detecting a PP requires nothing more than detecting a preposition." ></td>
	<td class="line x" title="305:359	6 The statistical model can, of course, be applied without modification." ></td>
	<td class="line x" title="306:359	The problem, however, is determining which PPs are arguments and which are adjuncts." ></td>
	<td class="line x" title="307:359	There are clearly cases where a prepositional phrase can occur in a clause not by virtue of the lexical entry of the verb but rather by virtue of nonlexical facts of English syntax." ></td>
	<td class="line x" title="308:359	For instance, almost any verb can occur with a temporal PP headed by on, as in John arrived on Monday." ></td>
	<td class="line x" title="309:359	Such PPs are called adjuncts." ></td>
	<td class="line x" title="310:359	On the other hand, the sense of on in John sprayed water on the ceiling is quite different." ></td>
	<td class="line x" title="311:359	This sense, it can be argued, is available only because the lexical entry of spray specifies a location argument that can be realized as a PP." ></td>
	<td class="line x" title="312:359	If anything significant is to be learned about individual words, the nonspecific cooccurrences of verbs with PPs (adjuncts) must be separated from the specific ones (arguments)." ></td>
	<td class="line x" title="313:359	It is not clear how a machine learning system could do this, although frequency might provide some clue." ></td>
	<td class="line x" title="314:359	Worse, however, there are many cases in which even trained linguists lack clear intuitions." ></td>
	<td class="line x" title="315:359	Despite a number of attempts to formulate necessary and sufficient conditions for the argument/adjunct distinction (e.g. , Jackendoff 1977), there are many cases for which the various criteria do not agree or the judgments are unclear (Adams and Macfarland 1991)." ></td>
	<td class="line x" title="316:359	Thus, the Penn Treebank does not make the argument/adjunct distinction because their judges do not agree often enough." ></td>
	<td class="line x" title="317:359	Until a useful definition that trained humans can agree on is developed, it would seem fruitless to attempt machine learning experiments in this domain." ></td>
	<td class="line x" title="318:359	4.2 Limitations of the Statistical Model Although the results of this study are generally encouraging, they also point to some limitations of the statistical model presented here." ></td>
	<td class="line x" title="319:359	First, it does not take into account variation in the percentage of verbs that can appear in each frame." ></td>
	<td class="line x" title="320:359	For example, most verbs can take an NP argument, while very few can take an NP followed by a tensed clause." ></td>
	<td class="line x" title="321:359	This results in too few verbs being classified as +NP and too many being classified as +NPcl, as shown in Table 8." ></td>
	<td class="line x" title="322:359	Second, it does not take into account the fact that for some words with verbal senses most of their occurrences are verbal, whereas for others most of their occurrences are nonverbal." ></td>
	<td class="line x" title="323:359	For example, operate occurs exclusively as a verb while board occurs much more often as a noun than as a verb." ></td>
	<td class="line x" title="324:359	Since the cues are based on the assumption that the word in question is a verb, board presents many more opportunities for error than operate." ></td>
	<td class="line x" title="325:359	This violates the assumption that the probability of error for a given frame is approximately uniform across verbs." ></td>
	<td class="line x" title="326:359	6 The preposition/particle distinction is set aside here in order to focus on the more problematic argument/adjunct distinction." ></td>
	<td class="line x" title="327:359	257 Computational Linguistics Volume 19, Number 2 Table 9 Distribution of occurrences among morphological forms in the Brown Corpus." ></td>
	<td class="line x" title="328:359	The ambiguous words board and project show a pattern of distribution distinct from that of the unambiguous verbs operate and follow." ></td>
	<td class="line x" title="329:359	project 52 board 111 operate 48 follow 76 projects 54 boards 31 operates 15 follows 72 projected 10 boarded 3 operated 26 followed 150 projecting 5 boarding 1 operating 55 following 97 These limitations do not constitute a major impediment to applications of the current results." ></td>
	<td class="line x" title="330:359	For example, an applied system can be provided with the rough estimates that 80-95 percent of verbs take a direct object, while 1-2 percent take a direct object followed by a tensed clause." ></td>
	<td class="line x" title="331:359	Such estimates can be expected to reduce misclassification significantly." ></td>
	<td class="line x" title="332:359	Further, an existing dictionary could be used to 'train' a statistical model on familiar verbs." ></td>
	<td class="line x" title="333:359	A trained system would probably be more accurate in classifying new verbs." ></td>
	<td class="line x" title="334:359	Finally, the lexical ambiguity problem could probably be reduced substantially in the applied context by using a statistical tagging program (Brill 1992; Church 1988)." ></td>
	<td class="line x" title="335:359	For addressing basic questions in machine learning of natural language the solutions outlined above are not attractive." ></td>
	<td class="line x" title="336:359	All of those solutions provide the learner with additional specific knowledge of English, whereas the goal for the machine learning effort should be to replace specific knowledge with general knowledge about the types of regularities to be found in natural language." ></td>
	<td class="line x" title="337:359	There is one approach to the lexical ambiguity problem that does not require giving the learner additional specific knowledge." ></td>
	<td class="line x" title="338:359	The problem is as follows: words that occur frequently as, say, nouns are likely to have a different error rate from unambiguous verbs." ></td>
	<td class="line x" title="339:359	If it were known which words occur primarily as verbs and which occur primarily as nouns then separate error rate estimates could be made for each." ></td>
	<td class="line x" title="340:359	This would reduce the rate of false positive errors even without any further information about which particular occurrences are nominal and which are verbal." ></td>
	<td class="line x" title="341:359	One way to distinguish primarily nominal words from primarily verbal words is by the relative frequencies of their various inflected forms." ></td>
	<td class="line x" title="342:359	For example, Table 9 shows the contrast in the distribution of inflected forms between project and board on the one hand and operate and follow on the other." ></td>
	<td class="line x" title="343:359	Project and board are two words whose frequent occurrence as nouns has caused Lerner to make false positive errors." ></td>
	<td class="line x" title="344:359	In both cases, the stem and -s forms are much more common than the -ed and -ing forms." ></td>
	<td class="line x" title="345:359	Compare this to the distribution for the unambiguous verbs operate and follow." ></td>
	<td class="line x" title="346:359	In these cases the diversity of frequencies is much lower and does not display the characteristic pattern of a word that occurs primarily as a noun--ing and -ed forms that are much rarer than the -s and stem forms." ></td>
	<td class="line x" title="347:359	Similar characteristic patterns exist for words that occur primarily as adjectives." ></td>
	<td class="line x" title="348:359	Recognizing such ambiguity patterns automatically would allow a separate error rate to be estimated for the highly ambiguous words." ></td>
	<td class="line x" title="349:359	4.3 Future Work From the perspective of computational language acquisition, a natural direction in which to extend this work is to develop algorithms for learning some of the specific knowledge that was programmed into the system described above." ></td>
	<td class="line x" title="350:359	Consider the mor258 Michael R. Brent From Grammar to Lexicon phological adjustment rules according to which, for example, the final 'e' of bite is deleted when the suffix -ing is added, yielding biting rather than,'biteing'." ></td>
	<td class="line x" title="351:359	Lerner needs to know such rules in order to determine whether or not a given word occurs both with and without the suffix -ing." ></td>
	<td class="line x" title="352:359	Experiments are under way on an unsupervised procedure that learns such rules from English text, given only the list of English verbal suffixes." ></td>
	<td class="line x" title="353:359	This work is being extended further in the direction of discovering the morphemic suffixes themselves and discovering the ways in which these suffixes alternate in paradigms." ></td>
	<td class="line x" title="354:359	The short-term goal is to develop algorithms that can learn the rules of inflection in English starting from only a corpus and a general notion of the nature of morphological regularities." ></td>
	<td class="line x" title="355:359	Ultimately, this line of inquiry may lead to algorithms that can learn much of the grammar of a language starting with only a corpus and a general theory of the kinds of formal regularities to be found in natural languages." ></td>
	<td class="line x" title="356:359	Some elements of syntax may not be learnable in this way (Lightfoot 1991), but the lexicon, morphology, and phonology together make up a substantial portion of the grammar of a language." ></td>
	<td class="line x" title="357:359	If it does not prove possible to learn these aspects of grammar starting from a general ontology of linguistic regularities and using distributional analysis then that, too, is an interesting result." ></td>
	<td class="line x" title="358:359	It would suggest that the task requires a more substantive initial theory of possible grammars, or some semantic information about input sentences, or both." ></td>
	<td class="line x" title="359:359	In any case this line of inquiry promises to shed light on the nature of language, learning, and language learning." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="J93-2005
Lexical Semantic Techniques For Corpus Analysis
Pustejovsky, James D.;Anick, Peter G.;Bergler, Sabine;"></td>
	<td class="line x" title="1:423	Lexical Semantic Techniques for Corpus Analysis James Pustejovsky* Brandeis University Peter Anick~ Digital Equipment Corporation Sabine Bergler t Concordia University In this paper we outline a research program for computational linguistics, making extensive use of text corpora." ></td>
	<td class="line x" title="2:423	We demonstrate how a semantic framework for lexical knowledge can suggest richer relationships among words in text beyond that of simple co-occurrence." ></td>
	<td class="line x" title="3:423	The work suggests how linguistic phenomena such as metonymy and polysemy might be exploitable for semantic tagging of lexical items." ></td>
	<td class="line x" title="4:423	Unlike with purely statistical collocational analyses, the framework of a semantic theory allows the automatic construction of predictions about deeper semantic relationships among words appearing in collocational systems." ></td>
	<td class="line x" title="5:423	We illustrate the approach for the acquisition oflexical information for several classes of nominals, and how such techniques can fine-tune the lexical structures acquired from an initial seeding of a machine-readable dictionary." ></td>
	<td class="line x" title="6:423	In addition to conventional lexical semantic relations, we show how information concerning lexical presuppositions and preference relations can also be acquired from corpora, when analyzed with the appropriate semantic tools." ></td>
	<td class="line x" title="7:423	Finally, we discuss the potential that corpus studies have for enriching the data set for theoretical linguistic research, as well as helping to confirm or disconfirm linguistic hypotheses." ></td>
	<td class="line x" title="8:423	1." ></td>
	<td class="line x" title="9:423	Introduction The proliferation of on-line textual information poses an interesting challenge to linguistic researchers for several reasons." ></td>
	<td class="line x" title="10:423	First, it provides the linguist with sentence and word usage information that has been difficult to collect and consequently largely ignored by linguists." ></td>
	<td class="line x" title="11:423	Second, it has intensified the search for efficient automated indexing and retrieval techniques." ></td>
	<td class="line x" title="12:423	FulMext indexing, in which all the content words in a document are used as keywords, is one of the most promising of recent automated approaches, yet its mediocre precision and recall characteristics indicate that there is much room for improvement (Croft 1989)." ></td>
	<td class="line x" title="13:423	The use of domain knowledge can enhance the effectiveness of a full-text system by providing related terms that can be used to broaden, narrow, or refocus a query at retrieval time (Debili, Fluhr, and Radasua 1988; Anick et al. 1989." ></td>
	<td class="line x" title="14:423	Likewise, domain knowledge may be applied at indexing time to do word sense disambiguation (Krovetz and Croft 1989) or content analysis (Jacobs 1991)." ></td>
	<td class="line x" title="15:423	Unfortunately, for many domains, such knowledge, even in the form of a thesaurus, is either not available or is incomplete with respect to the vocabulary of the texts indexed." ></td>
	<td class="line x" title="16:423	* Computer Science Department, Brandeis University, Waltham MA 02254." ></td>
	<td class="line x" title="17:423	t Computer Science Department, Concordia University, Montreal, Quebec H3G 1M8, Canada." ></td>
	<td class="line x" title="18:423	Digital Equipment Corporation, 111 Locke Drive LM02-1/D12, Marlboro MA 01752." ></td>
	<td class="line x" title="19:423	(~) 1993 Association for Computational Linguistics Computational Linguistics Volume 19, Number 2 In this paper we examine how linguistic phenomena such as metonymy and polysemy might be exploited for the semantic tagging of lexical items." ></td>
	<td class="line x" title="20:423	Unlike purely statistical collocational analyses, employing a semantic theory allows for the automatic construction of deeper semantic relationships among words appearing in collocational systems." ></td>
	<td class="line x" title="21:423	We illustrate the approach for the acquisition of lexical information for several classes of nominals, and how such techniques can fine-tune the lexical structures acquired from an initial seeding of a machine-readable dictionary." ></td>
	<td class="line x" title="22:423	In addition to conventional lexical semantic relations, we show how information concerning lexical presuppositions and preference relations (Wilks 1978) can also be acquired from corpora, when analyzed with the appropriate semantic tools." ></td>
	<td class="line x" title="23:423	Finally, we discuss the potential that corpus studies have for enriching the data set for theoretical linguistic research, as well as helping to confirm or disconfirm linguistic hypotheses." ></td>
	<td class="line x" title="24:423	The aim of our research is to discover what kinds of knowledge can be reliably acquired through the use of these methods, exploiting, as they do, general linguistic knowledge rather than domain knowledge." ></td>
	<td class="line x" title="25:423	In this respect, our program is similar to Zernik's (1989) work on extracting verb semantics from corpora using lexical categories." ></td>
	<td class="line x" title="26:423	Our research, however, differs in two respects: first, we employ a more expressive lexical semantics; second, our focus is on all major categories in the language, and not just verbs." ></td>
	<td class="line x" title="27:423	This is important since for full-text information retrieval, information about nominals is paramount, as most queries tend to be expressed as conjunctions of nouns." ></td>
	<td class="line x" title="28:423	From a theoretical perspective, we believe that the contribution of the lexical semantics of nominals to the overall structure of the lexicon has been somewhat neglected, relative to that of verbs." ></td>
	<td class="line x" title="29:423	While Zernik (1989) presents ambiguity and metonymy as a potential obstacle to effective corpus analysis, we believe that the existence of motivated metonymic structures actually provides valuable clues for semantic analysis of nouns in a corpus." ></td>
	<td class="line x" title="30:423	We will assume, for this paper, the general framework of a generative lexicon as outlined in Pustejovsky (1991)." ></td>
	<td class="line x" title="31:423	In particular, we make use of the principles of type coercion and qualia structure." ></td>
	<td class="line x" title="32:423	This model of semantic knowledge associated with words is based on a system of generative devices that is able to recursively define new word senses for lexical items in the language." ></td>
	<td class="line x" title="33:423	These devices and the associated dictionary make up a generative lexicon, where semantic information is distributed throughout the lexicon to all categories." ></td>
	<td class="line x" title="34:423	The general framework assumes four basic levels of semantic description: argument structure, qualia structure, lexical inheritance structure, and event structure." ></td>
	<td class="line x" title="35:423	Connecting these different levels is a set of generative devices that provide for the compositional interpretation of words in context." ></td>
	<td class="line x" title="36:423	The most important of these devices is a semantic transformation called type coercion--analogous to coercion in programming languages--which captures the semantic relatedness between syntactically distinct expressions." ></td>
	<td class="line x" title="37:423	As an operation on types within a A-calculus, type coercion can be seen as transforming a monomorphic language into one with polymorphic types (cf.Cardelli and Wegner 1985)." ></td>
	<td class="line x" title="39:423	Argument, event, and qualia types must conform to the well-formedness conditions defined by the type system defined by the lexical inheritance structure when undergoing operations of semantic composition." ></td>
	<td class="line x" title="40:423	~ 1 The details of type coercion need not concern us here." ></td>
	<td class="line x" title="41:423	Briefly, however, whenever there exists a grammatical environment where more than one syntactic type satisfies the semantic type selected by the governing element, the governing element can be analyzed as coercing a range of surface types into a single semantic type." ></td>
	<td class="line x" title="42:423	An example of subject type coercion is a causative verb, semantically selecting an event as subject (as in (i)), but syntactically permitting a nonevent denoting NP (as in (ii)): i. The flood killed the grass." ></td>
	<td class="line x" title="43:423	ii." ></td>
	<td class="line x" title="44:423	The herbicide killed the grass." ></td>
	<td class="line x" title="45:423	332 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis One component of this approach, the qualia structure, specifies the different aspects of a word's meaning through the use of subtyping." ></td>
	<td class="line x" title="46:423	These include the subtypes CONSTITUTIVE, FORMAL, TELIC, and AGENTIVE." ></td>
	<td class="line x" title="47:423	To illustrate how these are used, the qualia structure for book is given below." ></td>
	<td class="line x" title="48:423	2  book(x,y)." ></td>
	<td class="line x" title="49:423	\] GONST = information(yl \] FORMAL = physobj(x) \[ TELIC = read(T,w,y) \[ AGENTIVE = write(T,z,y) J This structured representation allows one to use the same lexical entry in different contexts, where the word refers to different qualia of the noun's denotation." ></td>
	<td class="line x" title="50:423	For example, the sentences in (1)-(3) below refer to different aspects (or qualia) of the general meaning of book." ></td>
	<td class="line x" title="51:423	3 Example 1 This book weighs four ounces." ></td>
	<td class="line x" title="52:423	Example 2 John finished a book." ></td>
	<td class="line x" title="53:423	Example 3 This is an interesting book." ></td>
	<td class="line x" title="54:423	Example 1 makes reference to the formal role, while 3 refers to the constitutive role." ></td>
	<td class="line x" title="55:423	Example 2, however, can refer to either the telic or the agentive aspects given above." ></td>
	<td class="line x" title="56:423	The utility of such knowledge for information retrieval is readily apparent." ></td>
	<td class="line x" title="57:423	This theory claims that noun meanings should make reference to related concepts and the relations into which they enter." ></td>
	<td class="line x" title="58:423	The qualia structure, thus, can be viewed as a kind of generic template for structuring this knowledge." ></td>
	<td class="line x" title="59:423	Such information about how nouns relate to other lexical items and their concepts might prove to be much more useful in full-text information retrieval than what has come from standard statistical techniques." ></td>
	<td class="line x" title="60:423	To illustrate how such semantic structuring might be useful, consider the general class of artifact nouns." ></td>
	<td class="line x" title="61:423	A generative view of the lexicon predicts that by classifying an element into a particular category, we can generate many aspects of its semantic structure, and hence, its syntactic behavior." ></td>
	<td class="line x" title="62:423	For example, the representation above for book refers to several word senses, all of which are logically related by the semantic template for an artifactual object." ></td>
	<td class="line x" title="63:423	That is, it contains information, it has a material extension, it serves some function, and it is created by some particular act or event." ></td>
	<td class="line x" title="64:423	2 Briefly, the qualia can be defined as follows:  CONSTITUTIVE: the relation between an object and its constituent parts;  FORMAL: that which distinguishes it within a larger domain;  TELIC: its purpose and function;  AGENTIVE: factors involved in its origin or 'bringing it about'." ></td>
	<td class="line x" title="65:423	In the qualia structures given below, we adopt the convention that \[c~, r\] denotes conjunction of formulas within the feature structure, while \[a; r\] will denote disjunction." ></td>
	<td class="line x" title="66:423	3 A related approach for expressing the different semantic relations of nominals in distinguished contexts is given in Bierwisch (1983)." ></td>
	<td class="line x" title="67:423	333 Computational Linguistics Volume 19, Number 2 Such an analysis allows us to minimally structure objects according to these four qualia." ></td>
	<td class="line x" title="68:423	As an example of how objects cluster according to these dimensions, we will briefly consider three object types: (1) containers (of information), e.g., book, tape, record; (2) instruments, e.g., gun, hammer, paintbrush; and (3) figure-ground objects, e.g., door, room, fireplace." ></td>
	<td class="line x" title="69:423	Because of how their qualia structures differ, these classes appear in vastly different grammatical contexts." ></td>
	<td class="line x" title="70:423	As with containers in general, information containers permit metonymic extensions between the container and the material contained within it." ></td>
	<td class="line x" title="71:423	Collocations such as those in Examples 4 through 7 indicate that this metonymy is grammaticalized through specific and systematic head-PP constructions." ></td>
	<td class="line x" title="72:423	Example 4 read a book Example 5 read a story in a book Example 6 read a tape Example 7 read the information on the tape Instruments, on the other hand, display classic agent-instrument causative alternations, such as those in Examples 8 through 11 (cf.Fillmore 1968; Lakoff 1968, 1970)." ></td>
	<td class="line x" title="74:423	Example 8  smash the vase with the hammer Example 9 The hammer smashed the vase." ></td>
	<td class="line x" title="75:423	Example 10  kill him with a gun Example 11 The gun killed him." ></td>
	<td class="line x" title="76:423	Finally, figure-ground nominals (Pustejovsky and Anick 1988) permit perspective shifts such as those in Examples 12 through 15." ></td>
	<td class="line x" title="77:423	These are nouns that refer to physical objects as well as the specific enclosure or aperture associated with it." ></td>
	<td class="line x" title="78:423	Example 12 John painted the door." ></td>
	<td class="line x" title="79:423	Example 13 John walked through the door." ></td>
	<td class="line x" title="80:423	334 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis Example 14 John is scrubbing the fireplace." ></td>
	<td class="line x" title="81:423	Example 15 The smoke filled the fireplace." ></td>
	<td class="line x" title="82:423	That is, paint and scrub are actions on physical objects while walk through and fill are processes in spaces." ></td>
	<td class="line x" title="83:423	These collocational patterns, we argue, are systematically predictable from the lexical semantics of the noun, and we term such sets of collocated structures lexical conceptual paradigms (LCPs)." ></td>
	<td class="line x" title="84:423	4 To make this point clearer, let us consider a specific example of an LCP from the computer science domain, namely for the noun tape." ></td>
	<td class="line x" title="85:423	Because of the particular metonymy observed for a noun like tape, we will classify it as belonging to the container/containee LCP." ></td>
	<td class="line x" title="86:423	This general class is represented as follows, where P and 0 are predicate variables: 5 container(x,y) \] CONST = P(y) FORMAL = Q(x) TELIC = hold(S,x,y) The LCP is a generic qualia structure that captures not only the semantic relationship between arguments types of a relation, but also, through corpus-tuning, the collocation relations that realize these roles." ></td>
	<td class="line x" title="87:423	The telic function of a container, for example, is the relation hold, but this underspecifies which spatial prepositions would adequately satisfy this semantic relation (e.g. in, on, inside, etc.)." ></td>
	<td class="line x" title="88:423	In this view, a noun such as tape would have the following qualia structure: tape(x,y) CONST = information(y) FORMAL = physobj(x),2-dimen(x) TELIC = contain(S,x,y) AGENTIVE = write(T,z,y) This states that a tape is an 'information container' that is also a two-dimensional physical object, where the information is written onto the object." ></td>
	<td class="line x" title="89:423	6 With such nouns, a logical metonymy exists (as the result of type coercion), when the logical argument of a semantic type, which is selected by a function of some sort, denotes the semantic type itself." ></td>
	<td class="line x" title="90:423	Thus, in this example, the type selected for by a verb such as read refers to the 'information' argument for tape, while a verb such as carry would select for the 'physical object' argument." ></td>
	<td class="line x" title="91:423	They are, however, logically related, since the noun itself denotes a relation." ></td>
	<td class="line x" title="92:423	The representation above simply states that any semantics for tape must logically make reference to the object itself (formal), what it can contain (const), what purpose 4 This relates to Mel'~uk's lexical functions and the syntactic structures they associate with an element." ></td>
	<td class="line x" title="93:423	See Mel'~uk (1988) and references therein." ></td>
	<td class="line x" title="94:423	Cruse (1986, 1992) and Nunberg (1978) discuss the foregrounding and backgrounding of information with respect to similar examples." ></td>
	<td class="line x" title="95:423	5 Within the qualia structure for a term, FORMAL and CONST roles typically refer to the object domain while TELI and ACENTIVE refer to events." ></td>
	<td class="line x" title="96:423	Hence, the first parameter in the latter two roles refers to an event sort, i.e., a state (s), process (p), or transition (T)." ></td>
	<td class="line x" title="97:423	6 The appropriate selection of a surface spatial preposition will follow from its formal type specification as a 2-dimen object." ></td>
	<td class="line x" title="98:423	Cf." ></td>
	<td class="line x" title="99:423	Pustejovsky (in press) for details." ></td>
	<td class="line x" title="100:423	335 Computational Linguistics Volume 19, Number 2 it serves (telic), and how it arises (agentive)." ></td>
	<td class="line x" title="101:423	This provides us with a semantic representation that can capture the multiple perspectives a single lexical item may assume in different contexts." ></td>
	<td class="line x" title="102:423	Yet, the qualia for a lexical item such as tape are not isolated values for that one word, but are integrated into a global knowledge base indicating how these senses relate to other lexical items and their senses." ></td>
	<td class="line x" title="103:423	This is the contribution of inheritance and the hierarchical structuring of knowledge (cf.Evans and Gazdar 1990; Copestake and Briscoe 1992; Russell et al. 1992)." ></td>
	<td class="line x" title="105:423	In Pustejovsky (1991) it is suggested that there are two types of relational structures for lexical knowledge; a fixed inheritance similar to that of an is-a hierarchy (cf.Touretzky 1986); and a dynamic structure that operates generatively from the qualia structure of a lexical item to create a relational structure for ad hoc categories." ></td>
	<td class="line x" title="107:423	7 Reviewing briefly, the basic idea is that semantics allows for the dynamic creation of arbitrary concepts through the application of certain transformations to lexical meanings." ></td>
	<td class="line x" title="108:423	Thus for every predicate, Q, we can generate its opposition, =Q. Similarly, these two predicates can be related temporally to generate the transition events defining this opposition." ></td>
	<td class="line x" title="109:423	These operations include but may not be limited to: -~, negation; _<, temporal precedence; >, temporal succession; =, temporal equivalence; and act, an operator adding agency to an argument." ></td>
	<td class="line x" title="110:423	We will call the concept space generated by these operations the Projective Conclusion Space of a specific quale for a lexical item." ></td>
	<td class="line x" title="111:423	To return to the example of tape above, the predicates read and copy are related to the telic value by just such an operation, while predicates such as mount and dismount--i.e, unmount--are related to the formal role." ></td>
	<td class="line x" title="112:423	Following the previous discussion, with mounted as the predicate Q, successive applications of the negation and temporal precedence operators derives the transition verbs mount and dismount." ></td>
	<td class="line x" title="113:423	8 We return to a discussion of this in Section 3, and to how this space relates to statistically significant collocations in text." ></td>
	<td class="line x" title="114:423	It is our view that the approach outlined above for representing lexical knowledge can be put to use in the service of information retrieval tasks." ></td>
	<td class="line x" title="115:423	In this respect, our proposal can be compared to attempts at object classification in information science." ></td>
	<td class="line x" title="116:423	One approach, known as faceted classification (Vickery 1975) proceeds roughly as follows: collect all terms lying within a field; then group the terms into facets by assigning them to categories." ></td>
	<td class="line x" title="117:423	Typical examples of this are state, property, reaction, and device." ></td>
	<td class="line x" title="118:423	However, each subject area is likely to have its own sets of categories, which makes it difficult to re-use a set of facet classifications." ></td>
	<td class="line x" title="119:423	9 Even if the relational information provided by the qualia structure and inheritance would improve performance in information retrieval tasks, one problem still remains, namely that it would be very time-consuming to hand-code such structures for all nouns in a domain." ></td>
	<td class="line x" title="120:423	Since it is our belief that such representations are generic structures across all domains, it is our long-term goal to develop methods for automatically extracting these relations and values from on-line corpora." ></td>
	<td class="line x" title="121:423	In the sections that follow, we describe several experiments indicating that the qualia structures do, in fact, correlate with well-behaved collocational patterns, thereby allowing us to perform structure-matching operations over corpora to find these relations." ></td>
	<td class="line x" title="122:423	7 This is similar to thesauruslike structures, within the IR community, cf.for example Sparck Jones (1981)." ></td>
	<td class="line x" title="124:423	8 Details of the derivation are as follows." ></td>
	<td class="line x" title="125:423	Let Q be mounted, then ~Q gives ~mounted, and K applied to these two states gives Q < -~Q, which is lexicalized as dismount." ></td>
	<td class="line x" title="126:423	A similar derivation exists for mount." ></td>
	<td class="line x" title="127:423	Cf." ></td>
	<td class="line x" title="128:423	Pustejovsky (1991) for details." ></td>
	<td class="line x" title="129:423	9 This is reflected in the sublanguage work of Grishman, Hirschman, and Nhan (1986), whose automated discovery procedures are aimed at clustering nouns into categories like diagnosis and symptom." ></td>
	<td class="line x" title="130:423	336 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis 2." ></td>
	<td class="line x" title="131:423	Seeding Lexical Structures from MRDs In this section we discuss briefly how a lexical semantic theory can help in extracting information from machine-readable dictionaries (MRDs)." ></td>
	<td class="line x" title="132:423	We describe research on conversion of a machine-tractable dictionary (Wilks et al. 1993) into a usable lexical knowledge base (Boguraev 1991)." ></td>
	<td class="line x" title="133:423	Although the results here are preliminary, it is important to mention the process of converting an MRD into a lexical knowledge base, so that the process of corpus-tuning is put into the proper perspective." ></td>
	<td class="line x" title="134:423	The initial seeding of lexical structures is being done independently both from the Oxford Advanced Learners Dictionary (OALD) and from lexical entries in the Longman Dictionary of Contemporary English (Procter, Ilson, and Ayto 1978)." ></td>
	<td class="line x" title="135:423	These are then automatically adapted to the format of generative lexical structures." ></td>
	<td class="line x" title="136:423	It is these lexical structures that are then statistically tuned against the corpus, following the methods outlined in Anick and Pustejovsky (1990) and Pustejovsky (1992)." ></td>
	<td class="line x" title="137:423	Previous work by Amsler (1980), Calzolari (1984), Chodorow, Byrd, and Heidorn (1985), Byrd et al.(1987), Markowitz, Ahlswede, and Evens (1986), and Nakamura and Nagao (1988) showed that taxonomic information and certain semantic relations can be extracted from MRDs using fairly simple techniques." ></td>
	<td class="line x" title="139:423	Later work by Veronis and Ide (1991), Klavans, Chodorow, and Wacholder (1990), and Wilks et aL (1992) provides us with a number of techniques for transfering information from MRDs to a representation language such as that described in the previous section." ></td>
	<td class="line x" title="140:423	Our goal is to automate, to the extent possible, the initial construction of these structures." ></td>
	<td class="line x" title="141:423	Extensive research has been done on the kind of information needed by natural language programs and on the representation of that information (Wang, Vandendorpe, and Evens 1985; Ahlswede and Evens 1988)." ></td>
	<td class="line x" title="142:423	Following Boguraev et al.(1989) and Wilks et al. of 1989), we believe that much of what is needed for NLP lexicons can be found either explicitly or implicitly in a dictionary, and empirical evidence suggests that this information gives rise to a sufficiently rich lexical representation for use in extracting information from texts." ></td>
	<td class="line x" title="144:423	Techniques for identifying explicit information in machine-readable dictionaries have been developed by many researchers (Boguraev et al. 1989; Slator 1988; Slator and Wilks 1987; Guthrie et al. 1990) and are well understood." ></td>
	<td class="line x" title="145:423	Many properties of a word sense or the semantic relationships between word senses are available in MRDs, but this information can only be identified computationally through some analysis of the definition text of an entry (Atkins 1991)." ></td>
	<td class="line x" title="146:423	Some research has already been done in this area." ></td>
	<td class="line x" title="147:423	Alshawi (1987), Boguraev et al.(1989), Vossen, Meijs, and den Broeder (1989), and the work described in Wilks et al.(1992) have made explicit some kinds of implicit information found in MRDs." ></td>
	<td class="line x" title="150:423	Here we propose to refine and merge some of the previous techniques to make explicit the implicit information specified by a theory of generative lexicons." ></td>
	<td class="line x" title="151:423	Given what we described above for the lexical structures for nominals, we can identify these semantic relations in the OALD and LDOCE by pattern matching on the parse trees of definitions." ></td>
	<td class="line x" title="152:423	To illustrate what specific information can be derived by automatic seeding from machine-readable dictionaries, consider the following examples)  For example, the LDOCE definition for book is: 'a collection of sheets of paper fastened together as a thing to be read, or to be written in' 10 The following lexical entries, termed gls's, are taken from the lexical databases derived from the OALD using tools developed by Peter Dilworth, and from LDOCE using a combination of tools developed by Louise Guthrie, Gees Stein, and Pete Dilworth." ></td>
	<td class="line x" title="153:423	337 Computational Linguistics Volume 19, Number 2 while the OALD provides a somewhat different definition: 'number of sheet of papers, either printed or blank, fastened together in a cover'." ></td>
	<td class="line x" title="154:423	Note that both definitions are close to, but not identical to the information structure suggested in the previous section, using a qualia structure for nominals." ></td>
	<td class="line x" title="155:423	LDOCE suggests write in rather than write as the value for the telic role, while the OALD suggests nothing for this role." ></td>
	<td class="line x" title="156:423	Furthermore, although the physical contents of a book as 'a collection of sheets of paper' is mentioned, nowhere is information made reference to in the definition." ></td>
	<td class="line x" title="157:423	When the dictionary fails to provide the value for a semantic role, the information must be either hand-entered or the lexical structure must be tuned against a large corpus, in the hope of extracting such features automatically." ></td>
	<td class="line x" title="158:423	We turn to this issue in the next two sections." ></td>
	<td class="line x" title="159:423	Although the two dictionaries differ in substantial respects, it is remarkable how systematic the definition structures are for extracting semantic information, if there is a clear idea how this information should be structured." ></td>
	<td class="line x" title="160:423	For example, from the following OALD definition for cigarette, cigarette n roll of shredded tobacco enclosed in thin paper for smoking." ></td>
	<td class="line x" title="161:423	the initial lexical structure below is generated." ></td>
	<td class="line x" title="162:423	gls (cigarette, syn( \[type (n), code(C)\] ), qualia ( \[formal( \[roll\] ), telic ( \[smoking\] ), const ( \[tobacco,paper\] ), agent ( \[enclosed\] )\] ), cospec ( \[\] ) ) . Parsing the LDOCE entry for the same noun results in a different lexical structure: cigarette n finely cut shredded tobacco rolled in a narrow tube of thin paper for smoking." ></td>
	<td class="line x" title="163:423	gls (cigarette, syn( \[type (n), code(C), ldoce id(cigarette 0_1)\]), qualia( \[formal( \[tube\] ), telic( \[smoking\] ), const ( \[tobacco,paper\] ), agent ( \[rolled\] )\] ), cospec ( \[\] ) ) . One obvious problem with the above representation is that there is no information indicating how the word being defined binds to the relations in the qualia." ></td>
	<td class="line x" title="164:423	Currently, 338 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis subsequent routines providing for argument binding analyze the relational structure for particular aspects of noun meaning, giving us a lexical structure fairly close to what we need for representation and retrieval purposes, although the result is in no way ideal or uniform over all nominal forms." ></td>
	<td class="line x" title="165:423	(cf.Cowie, Guthrie, and Pustejovsky \[1992\] for details of this operation on LDOCE.): 11 cigarette(x) CONST = tobacco(y),shredded(y),paper(z) FOaMAL = roll(x) TELIC = smoke(T,w,x) AGENTIVE = artifact(x) In a related set of experiments performed while constructing a large lexical database for data extraction purposes, we seeded a lexicon with 6000 verbs from LDOCE." ></td>
	<td class="line x" title="167:423	This process and the corpus tuning for both argument typing and subcategorization acquisition are described in Cowie, Guthrie, and Pustejovsky (1992) and Pustejovsky et al.(1992)." ></td>
	<td class="line x" title="169:423	In summary, based on a theory of lexical semantics, we have discussed how an MRD can be useful as a corpus for automatically seeding lexical structures." ></td>
	<td class="line x" title="170:423	Rather than addressing the specific problems inherent in converting MRDs into useful lexicons, we have emphasized how it provides us, in a sense, with a generic vocabulary from which to begin lexical acquisition over corpora." ></td>
	<td class="line x" title="171:423	In the next section, we will address the problem of taking these initial, and often very incomplete lexical structures, and enriching them with information acquired from corpus analysis." ></td>
	<td class="line x" title="172:423	As mentioned in the previous section, the power of a generative lexicon is that it takes much of the burden of semantic interpretation off of the verbal system by supplying a much richer semantics for nouns and adjectives." ></td>
	<td class="line x" title="173:423	This makes the lexical structures ideal as an initial representation for knowledge acquisition and subsequent information retrieval tasks." ></td>
	<td class="line x" title="174:423	3." ></td>
	<td class="line x" title="175:423	Knowledge Acquisition from Corpora A machine-readable dictionary provides the raw material from which to construct computationally useful representations of the generic vocabulary contained within it." ></td>
	<td class="line x" title="176:423	The lexical structures discussed in the previous section are one example of how such information can be exploited." ></td>
	<td class="line x" title="177:423	Many sublanguages, however, are poorly represented in on-line dictionaries, if represented at all." ></td>
	<td class="line x" title="178:423	Vocabularies geared to specialized domains will be necessary for many applications, such as text categorization and information retrieval." ></td>
	<td class="line x" title="179:423	The second area of our research program that we discuss is aimed at developing techniques for building sublanguage lexicons via syntactic and statistical corpus analysis coupled with analytic techniques based on the tenets of generative lexicon theory." ></td>
	<td class="line x" title="180:423	To understand fully the experiments described in the next two sections, we will refer to several semantic notions introduced in previous sections." ></td>
	<td class="line x" title="181:423	These include type coercion, where a lexical item requires a specific type specification for its argument, and 11 As one reviewer correctly pointed out, more than simple argument binding is involved here." ></td>
	<td class="line x" title="182:423	For example, the model must know that paper can enclose shredded tobacco, but not the reverse." ></td>
	<td class="line x" title="183:423	Such information, typically part of commonsense knowledge, is well outside the domain of lexical semantics, as envisioned here." ></td>
	<td class="line x" title="184:423	One approach to this problem, consistent with our methodology, is to examine the corpus and the collocations that result from training on specific qualia relations." ></td>
	<td class="line x" title="185:423	Further work will hopefully clarify the nature of this problem, and whether it is best treated lexically or not." ></td>
	<td class="line x" title="186:423	339 Computational Linguistics Volume 19, Number 2 the argument is able to change type accordingly--this explains the behavior of logical metonymy and the syntactic variation seen in complements to verbs and nominals; and cospecification, a semantic tagging of what collocational patterns the lexical item may enter into." ></td>
	<td class="line x" title="187:423	Metonymy, in this view, can be seen as a case of the 'licensed violation' of selectional restrictions." ></td>
	<td class="line x" title="188:423	For example, while the verb announce selects for a human subject, sentences like The Dow Corporation announced third quarter losses are not only an acceptable paraphrase of the selectionally correct form Mr. Dow Jr. announced third quarter losses for Dow Corp, but they are the preferred form in the corpora being examined." ></td>
	<td class="line x" title="189:423	This is an example of subject type coercion, where the semantics for Dow Corp as a company must specify that there is a human typically associated with such official pronouncements (see Section 5)." ></td>
	<td class="line x" title="190:423	12 For one set of experiments, we used a corpus of approximately 3,000 articles written by Digital Equipment Corporation's Customer Support Specialists for an on-line computer troubleshooting library." ></td>
	<td class="line x" title="191:423	The articles, each oneto two-page long descriptions of a problem and its solution, comprise about I million words." ></td>
	<td class="line x" title="192:423	Our analysis proceeds in two phases." ></td>
	<td class="line x" title="193:423	In the first phase, we pre-process the corpus to build a database of phrasal relationships." ></td>
	<td class="line x" title="194:423	This consists briefly of the following steps: 1." ></td>
	<td class="line x" title="195:423	Perform unknown word resolution to the corpus." ></td>
	<td class="line x" title="196:423	The corpus is searched for strings that are not members of a 25,000 word generic on-line English lexicon." ></td>
	<td class="line x" title="197:423	Morphological analysis is then applied to these unknown strings to identify candidate citation forms and their likely morphological paradigms." ></td>
	<td class="line x" title="198:423	Unless morphological evidence indicates otherwise, we enter unknown words into the lexicon as regular nouns; if there is evidence of some other morphological paradigm, such as verbal or adjectival suffixes, the word is entered into the lexicon accordingly." ></td>
	<td class="line x" title="199:423	2." ></td>
	<td class="line x" title="200:423	Corpus tagging." ></td>
	<td class="line x" title="201:423	Once the lexicon is updated to include the new single word forms in the domain, the corpus is tagged with part-of-speech indicators." ></td>
	<td class="line x" title="202:423	Any words that are ambiguous with respect to category are disambiguated according to a set of several dozen ordered disambiguation heuristics, which choose a category based on the categories of the words immediately preceding and following the ambiguous term." ></td>
	<td class="line x" title="203:423	3." ></td>
	<td class="line x" title="204:423	Partial parsing." ></td>
	<td class="line x" title="205:423	The tagged corpus is then segmented into a fiat sequence of phrasal groupings, using closed class words such as prepositions and determiners, as well as certain part-of-speech transitions, to indicate likely phrase boundaries." ></td>
	<td class="line x" title="206:423	No attempt is made to construct a full parse tree or resolve prepositional phrase attachment, conjunction scoping, etc. A concordance is constructed, identifying, for each word appearing in the corpus, the set of sentences, phrases, and phrase locations in which the word appears." ></td>
	<td class="line x" title="207:423	12 Within the current framework, a distinction is made between logical metonymy, where the metonymic extension or relation is transparent from the lexical semantics of the coerced phrase, and conventional metonymy, where the relation may not be directly calculated from information provided grammatically." ></td>
	<td class="line x" title="208:423	For example, in the sentence 'The Boston office called today,' it is not clear from logical metonymy what relation Boston bears to office other than location; i.e., it is not obvious that it is a branch office." ></td>
	<td class="line x" title="209:423	This is well beyond lexical semantics (cf.Lakoff 1987 and Martin 1990)." ></td>
	<td class="line x" title="211:423	340 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis The database of partially parsed sentences provides the raw material for a number of sublanguage analyses." ></td>
	<td class="line x" title="212:423	This begins the second phase of analysis: 1." ></td>
	<td class="line x" title="213:423	Noun compound recognition and bracketing." ></td>
	<td class="line x" title="214:423	In technical sublanguages, noun compounds are often employed to expand the working vocabulary without the invention of new word forms." ></td>
	<td class="line x" title="215:423	It is therefore useful in applications such as lexicon-assisted full-text information retrieval (Anick 1992) to include such noun compounds as lexical items for both querying and thesaurus browsing." ></td>
	<td class="line x" title="216:423	We construct bracketed noun compounds from our database of partial parses in a two-step process." ></td>
	<td class="line x" title="217:423	The first simply searches the corpus for (recurring) contiguous sequences of nouns." ></td>
	<td class="line x" title="218:423	Then, to bracket each compound that includes more than two nouns, we test whether possible subcomponents of the phrase exist on their own (as complete noun compounds) elsewhere in the corpus." ></td>
	<td class="line x" title="219:423	Sample bracketed compounds derived from the computer troubleshooting database include \[ \[system management\] utility\], \[TK50 \[tape drive\]\], \[\[database management\] system\]." ></td>
	<td class="line x" title="220:423	2." ></td>
	<td class="line x" title="221:423	Generation of taxonomic relationships on the basis of collocational information." ></td>
	<td class="line x" title="222:423	Technical sublanguages often express subclass relationships in noun compounds of the form <instance-name> <class-name>, as in 'Unix operating system' and 'C language'." ></td>
	<td class="line x" title="223:423	Unfortunately, noun compounds are also employed to express numerous other relationships, as in 'Unix kernel' and 'C debugger'." ></td>
	<td class="line oc" title="224:423	We have found, however, that collocational evidence can be employed to suggest which noun compounds reflect taxonomic relationships, using a strategy similar to that employed by Hindle (1990) for detecting synonyms." ></td>
	<td class="line x" title="225:423	Given a term T, we extract from the phrase database those nouns Ni that appear as the head of any phrase in which T is the immediately preceding term." ></td>
	<td class="line x" title="226:423	These nouns represent candidate classes of which T may be a member." ></td>
	<td class="line oc" title="227:423	We then generate the set of verbs that take T as direct object and calculate the mutual information value for each verb/T collocation (cf.Hindle 1990)." ></td>
	<td class="line x" title="229:423	We do the same for each noun Ni." ></td>
	<td class="line x" title="230:423	Under the assumption that instance and class nouns are likely to co-occur with the same verbs, we compute a similarity score between T and each noun Ni, by summing the product of the mutual information values for those verbs occurring with both nouns." ></td>
	<td class="line x" title="231:423	(Verbs with negative mutual information values are left out of the calculation)." ></td>
	<td class="line x" title="232:423	The noun with the highest similarity score is often the class of which T is an instance, as illustrated by the sample results in Figure 1." ></td>
	<td class="line x" title="233:423	For each word displayed in Figure 1, its 'class' is the head noun with the highest similarity score." ></td>
	<td class="line x" title="234:423	Other head nouns occurring with the word as modifier are listed as well." ></td>
	<td class="line x" title="235:423	As with all the automated procedures described here, this algorithm yields useful, but imperfect results." ></td>
	<td class="line x" title="236:423	The class chosen for 'VMS,' for example, is incorrect, and may reflect the fact that in a DEC troubleshooting database, authors see no need to further specify VMS as 'VMS operating system'." ></td>
	<td class="line x" title="237:423	A more interesting observation is that, among the collocations associated with the terms, there are often several that might qualify as classes of which the term is an instance, e.g., DECWindows could also be classified as 'software'; TK50 might also qualify as 'tape'." ></td>
	<td class="line x" title="238:423	From a generative lexicon perspective, these alternative classifications reflect multiple inheritance through the noun's 341 Computational Linguistics Volume 19, Number 2 word class score other collocations HSC controller 27.69 BACKUP operation 34.18 RL02 disk 15.93 TK50 cartridge 39.17 ACCVIO error 14.35 VAX product 23.28 VMS support 7.98 upgrade procedure 12.27 DCL level 9.14 CHECKSUM value 4.45 EDT editor 11.58 TPU command 3.62 RTL error 1.58 DECWindows environment 75.46 device, disk, path, message disk, tape, process, saveset media, kit, pack tape, kit, density, format problem configuration, node, editor, hardware product, upgrade, installation phase, option, support, prerequisite command, procedure, access, error character, operation, error session, conversion, search, problem editor, session, function, debugger routine, library image, application, intrinsics, software Figure 1 Classification of nouns from a computer troubleshooting corpus." ></td>
	<td class="line x" title="239:423	qualia." ></td>
	<td class="line x" title="240:423	That is, 'cartridge' is further specifying the formal role of tape for TK50." ></td>
	<td class="line x" title="241:423	DECWindows is functionally an 'environment,' its telic role, while 'software' characterizes its formal quale." ></td>
	<td class="line x" title="242:423	3." ></td>
	<td class="line x" title="243:423	Extraction of information relating to noun's qualia." ></td>
	<td class="line x" title="244:423	Under certain circumstances, it may be possible to elicit information about a noun's qualia from automated procedures on a corpus." ></td>
	<td class="line x" title="245:423	In this line of research, we haved employed the notion of 'lexical conceptual paradigm' described above." ></td>
	<td class="line x" title="246:423	An LCP relates a set of syntactic behaviors to the lexical semantic structures of the participating lexical items." ></td>
	<td class="line x" title="247:423	For example, the set of expressions involving the word 'tape' in the context of its use as a secondary storage device suggests that it fits the container artifact schema of the qualia structure, with 'information' and 'file' as its containees: (a) read information from tape (b) write file to tape (c) read information on tape (d) read tape (e) write tape As mentioned in Section 1, containers tend to appear as objects of the prepositions to, from, in, and on as well as in direct object position, in which case they are typically serving metonymically for the containee." ></td>
	<td class="line x" title="248:423	Thus, the container LCP relates the set of generalized syntactic patterns V i Nj {to, froin~ on} X k vi Nj riNk to the underlying lexical semantic structure given below." ></td>
	<td class="line x" title="249:423	container(x,y) \] CONST = P(y) FORMAL ~Q(x) TELIC = hold(S,x,y) 342 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis verb MI count unload 5.43 5 position 3.92 5 mount 3.77 29 initialize 3.18 10 dismount 2.88 5 read 1.40 7 load 1.18 4 restore 0.80 3 write -0.24 2 copy -2.55 1 Figure 2 Verbs associated with direct object tape as direct object." ></td>
	<td class="line x" title="250:423	This LCP includes a nominal alternation between the container and containee in the object position of verbs." ></td>
	<td class="line x" title="251:423	For tape, this alternation is manifested for verbs that predicate the telic role of data storage but not the formal role of physical object, which refers to the object as a whole regardless of its contents: TELIC : data-storage (a) read (tape/data from tape) (b) write (tape/data on tape) (c) copy (tape/data from tape) FORMAL= physical object (a) mount (tape) (b) dismount (tape) We have explored the use of heuristics to distinguish those predicates that relate to the Telic quale of the noun." ></td>
	<td class="line x" title="252:423	Consider the word tape, which occurs as the direct object in 107 sentences in our corpus." ></td>
	<td class="line x" title="253:423	It appears with a total of 34 different verbs." ></td>
	<td class="line x" title="254:423	By applying the mutual information metric (MI) to the verb-object pairs, we can sort the verbs accordingly, giving us the table of verbs most highly associated with tape, shown in Figure 2." ></td>
	<td class="line x" title="255:423	While the mutual information statistic does a good job of identifying verbs that semantically relate to the word tape, it provides no information about how the verbs relate to the noun's qualia structure." ></td>
	<td class="line x" title="256:423	That is, verbs such as unload, position, and mount are selecting for the formal quale of tape, a physical object that can be physically manipulated with respect to a tape drive." ></td>
	<td class="line x" title="257:423	Read, write, and copy, on the other hand, relate to the telic role, the function of a tape as a medium for storing information." ></td>
	<td class="line x" title="258:423	Our hypothesis was that the nominal alternation can help to distinguish the two sets of verbs." ></td>
	<td class="line x" title="259:423	We reasoned that, if the alternation is based on the container/containee metonymy, then it will be those verbs that apply to the telic role of the direct object that participate in the alternation." ></td>
	<td class="line x" title="260:423	We tested this hypothesis as follows." ></td>
	<td class="line x" title="261:423	We generated a candidate set of containees for tape by identifying all the nouns that appeared in the corpus to the left of the adjunct on tape." ></td>
	<td class="line x" title="262:423	343 Computational Linguistics Volume 19, Number 2 $1 & 81 NS2 Sl-& Verbs with tape as object Verbs with a containee of tape as object {restore, create, write, read, copy, replace} {mount, initialize, unload, position, dismount, load, allocate } 81 82 81 Sl n& -& Verbs with disk as object Verbs with a containee of disk as object {compress, restore, disable, rebuild, modify, recover, search, copy} {mount, initialize, boot, dismount, serve, } Sl 82 Sin& $1 -~2 Verbs with directory as object Verbs with containee of directory as object {create, recreate, delete, store, rename, check} {own, miss, search, review} Figure 3 Intersection and set difference for three container nouns." ></td>
	<td class="line x" title="263:423	Then we took the set of verbs that had one of these containee nouns as a direct object and compared this set to the set of verbs that had the container noun tape as a direct object in the corpus." ></td>
	<td class="line x" title="264:423	According to our hypothesis, verbs applying to the telic role should appear in the intersection of these two sets (as a result of the alternation), while those applying to the formal role will appear in the set difference {verbs with containers as direct object}--{verbs with containees as direct object}." ></td>
	<td class="line x" title="265:423	The difference operation should serve to remove any verbs that co-occur with containee objects." ></td>
	<td class="line x" title="266:423	Figure 3 shows the results of intersection and set difference for three container nouns tape, disk, and directory." ></td>
	<td class="line x" title="267:423	The results indicate that the container LCP is able to differentiate nouns with respect to their telic and formal qualia, for the nouns tape and disk but not for directory." ></td>
	<td class="line x" title="268:423	The poor discrimination in the latter case can be attributed to the fact that a directory is a recursive container." ></td>
	<td class="line x" title="269:423	A directory contains files, and a directory is itself a file." ></td>
	<td class="line x" title="270:423	Therefore, verbs that apply to the formal role of directory are likely to apply to the formal role of objects contained in directories (such as other directories)." ></td>
	<td class="line x" title="271:423	This can be seen as a shortcoming of the container LCP for the task at hand, but may be a useful way of diagnosing when containers contain objects functionally similar to themselves." ></td>
	<td class="line x" title="272:423	The result of this corpus acquisition procedure is a kind of minimal faceted analysis for the noun tape, as illustrated below, showing only the qualia that are relevant to the discussion} 3 tape(x,y) 1 CONST = information(y);file(y) FORMAL = mount(z,x);dismount(z,x) TELIC = read(w,y);write(w,y);copy(w,y);contain(w,y) 13 Because the technique was sensitive to grammatical position of the object NP, the argument can be bound to the appropriate variable in the relation expressed in the qualia." ></td>
	<td class="line x" title="273:423	It should be pointed out that these qualia values do not carry event place variables, since such discrimination was beyond the scope of this experiment." ></td>
	<td class="line x" title="274:423	344 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis What is interesting about the qualia values is how close they are to the concepts in the projective conclusion space of tape, as mentioned in Section 1." ></td>
	<td class="line x" title="275:423	To illustrate this procedure on another semantic category, consider the term mouse in its computer artifact sense." ></td>
	<td class="line x" title="276:423	In our corpus, it appears in the object position of the verb use in a 'use NP to' construction, as well as the object of the preposition with following a transitive verb and its object: 1." ></td>
	<td class="line x" title="277:423	use the mouse to set breakpoints 2." ></td>
	<td class="line x" title="278:423	use the mouse anywhere 3." ></td>
	<td class="line x" title="279:423	move a window with the mouse 4." ></td>
	<td class="line x" title="280:423	click on it with the mouse These constructions are symptomatic of its role as an instrument; and the VP complement of to as well as the VP dominating the with-PP identify the telic predicates for the noun." ></td>
	<td class="line x" title="281:423	Other verbs, for which mouse appears as a direct object are currently defaulted into the formal role, resulting in an entry for mouse as follows: mouse(x) \] CONST = button(y) FORMAL = physobj(x) TELIG = set(x,breakpoint);move(x,window);click-on(x,z) The above experiments have met with limited success, enough to warrant continuing our application of lexical semantic theory to knowledge acquisition from corpora, but not enough to remove the human from the loop." ></td>
	<td class="line x" title="282:423	As they currently exist, the algorithms described here can be used as tools to help the knowledge engineer extract useful information from on-line textual sources, and in some applications (e.g. , a 'related terms' thesaurus for full text information retrieval) may provide a useful way to heuristically organize sublanguage terminology when human resources are unavailable." ></td>
	<td class="line x" title="283:423	4." ></td>
	<td class="line x" title="284:423	Semantic Type Induction from Syntactic Forms The purpose of the research described in this section is to experiment with the automatic acquisition of semantic tags for words in a sublanguage, tags well beyond that available from the seeding of MRDs." ></td>
	<td class="line x" title="285:423	The identification of semantic tags is the result of type coercion on known syntactic forms, to induce a semantic feature, such as \[+event\] or \[+object\]." ></td>
	<td class="line x" title="286:423	4.1 Coercive Environments in Corpora A pervasive example of type coercion is seen in the complements of aspectual verbs such as begin and finish, and verbs such as enjoy." ></td>
	<td class="line x" title="287:423	That is, in sentences such as 'John began the book,' the normal complement expected is an action or event of some sort, most often expressed by a gerundive or infinitival phrase: 'John began reading the book,' 'John began to read the book'." ></td>
	<td class="line x" title="288:423	In Pustejovsky (1991) it was argued that in such cases, the verb need not have multiple subcategorizations, but only one deep semantic type, in this case, an event." ></td>
	<td class="line x" title="289:423	Thus, the verb coerces its complement (e.g. 'the book') into an event related to that object." ></td>
	<td class="line x" title="290:423	Such information can be represented by means of a representational schema called qualia structure, which, among other things, specifies the relations associated with objects." ></td>
	<td class="line x" title="291:423	345 Computational Linguistics Volume 19, Number 2 Figure 4 Counts for objects of begin/V. count verb object 205 begin career 176 begin day 159 begin work 140 begin talk 120 begin campaign 113 begin investigation 106 begin process 92 begin program 85 begin operation 85 begin negotiation 66 begin strike 64 begin production 59 begin meeting 59 begin term 50 begin visit 45 begin test 39 begin construction 31 begin debate 29 begin trial In related work being carried out with Mats Rooth of the University of Stuttgart, we are exploring what the range of coercion types is, and what environments they may appear in, as discovered in corpora." ></td>
	<td class="line x" title="292:423	Some of our initial data suggest that the hypothesis of deep semantic selection may in fact be correct, as well as indicating what the nature of the coercion rules may be." ></td>
	<td class="line oc" title="293:423	Using techniques described in Church and Hindle (1990), Church and Hanks (1990), and Hindle and Rooth (1991), Figure 4 shows some examples of the most frequent V-O pairs from the AP corpus." ></td>
	<td class="line x" title="294:423	Corpus studies confirm similar results for 'weakly intensional contexts' such as the complement of coercive verbs such as veto." ></td>
	<td class="line x" title="295:423	These are interesting because regardless of the noun type appearing as complement, it is embedded within a semantic interpretation of 'the proposal to,' thereby clothing the complement within an intensional context." ></td>
	<td class="line x" title="296:423	The examples in Figure 5 with the verb veto indicate two things: first, that such coercions are regular and pervasive in corpora; second, that almost anything can be vetoed, but that the most frequently occurring objects are closest to the type selected by the verb." ></td>
	<td class="line x" title="297:423	What these data show is that the highest count complement types match the type required by the verb; namely, that one vetoes a bill or proposal to do something, not the thing itself." ></td>
	<td class="line x" title="298:423	These nouns can therefore be used with some predictive certainty for inducing the semantic type in coercive environments such as 'veto the expedition'." ></td>
	<td class="line x" title="299:423	This work is still preliminary, however, and requires further examination (Pustejovsky and Rooth \[unpublished\])." ></td>
	<td class="line x" title="300:423	4.2 Induction of Semantic Relations from Syntactic Forms In this section, we present another experiment indicating the feasibility of inducing semantic tags for lexical items from Corpora." ></td>
	<td class="line x" title="301:423	14 Imagine being able to take the V-O pairs 14 This section presents an abridged version of material reported on in Pustejovsky (1992)." ></td>
	<td class="line x" title="302:423	346 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis Figure 5 Counts for objects of veto/V. count verb object 303 veto bill 84 veto legislation 58 veto measure 35 veto resolution 21 veto law 14 veto item 12 veto decision 9 veto proposal 9 veto plan 7 veto package 6 veto increase 5 veto sanction 5 veto penalty 4 veto notice 4 veto idea 4 veto appropriation 4 veto mission 4 veto attempt 3 veto search 3 veto cut 3 veto deal 1 veto expedition such as those given in Section 4.1, and then applying semantic tags to the verbs that are appropriate to the role they play for that object (i.e. , induction of the qualia roles for that noun)." ></td>
	<td class="line x" title="303:423	This is similar to the experiment reported on in Section 3." ></td>
	<td class="line x" title="304:423	Here we apply a similar technique to a much larger corpus, in order to induce the agentive role for nouns; that is, the semantic predicate associated with bringing about the object." ></td>
	<td class="line x" title="305:423	In this example we look at the behavior of noun phrases and the prepositional phrases that follow them." ></td>
	<td class="line x" title="306:423	In particular, we look at the co-occurrence of nominals with between, with, and to." ></td>
	<td class="line x" title="307:423	Table 1 shows results of the conflating noun plus preposition patterns." ></td>
	<td class="line x" title="308:423	The percentage shown indicates the ratio of the particular collocation to the key word." ></td>
	<td class="line x" title="309:423	Mutual information (MI) statistics for the two words in collocation are also shown." ></td>
	<td class="line x" title="310:423	What these results indicate is that induction of semantic type from conflating syntactic patterns is possible." ></td>
	<td class="line x" title="311:423	Based on the semantic types for these prepositions, the syntactic evidence suggests that there is an equivalence class where each preposition makes reference to a symmetric relation between the arguments in the following two patterns:  Z with y = ARzAx3y\[Rz(x,y) A Rz(y, x)\]  Z between x and y=,XRz3x, y\[Rz(x, y)/x Rz(y, x)\] We then take these results and, for those nouns where the association ratios for N with and N between are similar, we pair them with the set of verbs governing these 'NP PP' combinations in corpus, effectively partitioning the original V-O set into \[+agentive\] predicates and \[-agentive\] predicates." ></td>
	<td class="line x" title="312:423	These are semantic n-grams rather than direct interpretations of the prepositions." ></td>
	<td class="line x" title="313:423	347 Computational Linguistics Volume 19, Number 2 Table 1 Mutual information for noun + preposition patterns." ></td>
	<td class="line x" title="314:423	Word Word Word Word Word Word Word + to + with + between Word + to + with + between (%)/MI (%)/MI (%)/MI (%)/MI (%)/MI (%)/MI agreement .117 .159 .028 expansion .013 .007 0 1.512 3.423 3.954 -.666 .381 n/a announcement .010 .003 0 impasse 0 .064 .096 -.918 -.409 n/a n/a 2.520 5.192 barrier .215 0 .030 interactions 0 0 .250 2.117 n/a 4.046 n/a n/a 6.141 competition .019 .028 .021 market .013 .006 .000 -.269 1.701 3.666 -.637 .240 -.500 confrontation .029 .283 .074 range .005 .002 .020 .141 4.000 4.932 -1.533 -.618 3.663 contest .052 .052 .039 relations .009 .217 .103 .715 2.323 4.301 -1.017 3.736 5.254 contract .066 .060 .002 settlement .013 .091 .012 .947 2.463 1.701 -.626 2.868 3.142 deal .028 .193 .004 talks .029 .218 .030 .086 3.616 2.015 .138 3.740 4.043 dialogue 0 .326 .152 venture .032 .105 .035 n/a 4.140 5.644 .226 3.008 4.185 difference .017 .009 .348 war .010 .041 .015 -.410 .638 6.474 -.937 2.079 3.372 What these expressions in effect indicate is the range of semantic environments they will appear in." ></td>
	<td class="line x" title="315:423	That is, in sentences like those in Example 16, the force of the relational nouns agreement and talks is that they are unsaturated for the predicate bringing about this relation." ></td>
	<td class="line x" title="316:423	In 17, on the other hand, the NPs headed by agreement and talks are saturated in this respect." ></td>
	<td class="line x" title="317:423	Example 16 a. John made an agreement with Mary." ></td>
	<td class="line x" title="318:423	b. Apple opened talks with IBM." ></td>
	<td class="line x" title="319:423	Example 17 a. This is an agreement between John and Mary." ></td>
	<td class="line x" title="320:423	b. Those were the first talks between Apple and IBM." ></td>
	<td class="line x" title="321:423	If our hypothesis is correct, we expect that verbs governing nominals collocated with a with-phrase will be mostly those predicates referring to the agentive quale of the nominal." ></td>
	<td class="line x" title="322:423	This is because the with-phrase is unsaturated as a predicate, and acts to 348 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis count verb object Figure 6 Verb-object pairs with prep = with." ></td>
	<td class="line x" title="323:423	19 form venture 3 announce venture 3 enter venture 2 discuss venture 1 be venture 1 abandon venture 1 begin venture 1 complete venture 1 negotiate venture 1 start venture 1 expect venture identify the agent of the verb as its argument (cf.Nilsen (1973))." ></td>
	<td class="line x" title="325:423	This is confirmed by our data, shown in Figure 6." ></td>
	<td class="line x" title="326:423	Conversely, verbs governing nominals collocating with a between-phrase will not refer to the agentive since the phrase is saturated already." ></td>
	<td class="line x" title="327:423	Indeed, the only verb occurring in this position with any frequency is the copula be, namely with the following counts: 12 be/V venture/0." ></td>
	<td class="line x" title="328:423	Thus, weak semantic types can be induced on the basis of syntactic behavior." ></td>
	<td class="line x" title="329:423	There is a growing literature on corpus-based acquisition and tuning (Smadja 1991a; Zernik and Jacobs 1991; Brent 1991; as well as Grishman and Sterling 1992)." ></td>
	<td class="line x" title="330:423	We share with these researchers a general dependence on well-behaved collocational patterns and distributional structures." ></td>
	<td class="line x" title="331:423	Probably the main distinguishing feature of our approach is its reliance on a fairly well studied semantic framework to aid and guide the semantic induction process itself, whether it involves selectional restrictions or semantic types." ></td>
	<td class="line x" title="332:423	5." ></td>
	<td class="line x" title="333:423	Lexical Presuppositions and Preferences In the previous section we presented algorithms for extracting collocational information from corpora, in order to supplement and fine-tune the lexical structures seeded by a machine-readable dictionary." ></td>
	<td class="line x" title="334:423	In this section we demonstrate that, in addition to conventional lexical semantic relations, it is also possible to acquire information concerning lexical presuppositions and preferences from corpora, when analyzed with the appropriate semantic tools." ></td>
	<td class="line x" title="335:423	In particular, we will discuss a phenomenon we call discourse polarity, and how corpus-based experiments provide clues toward the representation of this phenomenon, as well as information on preference relations." ></td>
	<td class="line x" title="336:423	As we have seen, providing a representational system for lexical semantic relations is a nontrivial task." ></td>
	<td class="line x" title="337:423	Representing presuppositional information, however, is even more daunting." ></td>
	<td class="line x" title="338:423	Nevertheless, there are some systematic semantic generalizations associated with such subtle lexical inferences." ></td>
	<td class="line x" title="339:423	To illustrate this, consider the following examples taken from the Wall Street Journal Corpus, involving the verb insist." ></td>
	<td class="line x" title="340:423	Example 18 But Mr. Fourtou insisted that the restructuring plans hadn't played a role in his decision." ></td>
	<td class="line x" title="341:423	349 Computational Linguistics Volume 19, Number 2 Example 19 But so far, the majority is insisting that a daily paper in the home is an essential educational resource that Mr. Oshry must have, like it or not." ></td>
	<td class="line x" title="342:423	Example 20 But Mr. Nishi insists there is a common theme to his scattered projects: to improve and spread personal computers." ></td>
	<td class="line x" title="343:423	Example 21 'Mister, Djemaa is a crazy place for you,' insists the first of many young men, clutching a visitor's sleeve." ></td>
	<td class="line x" title="344:423	Example 22 But the BNL sources yesterday insisted that the head office was aware of only a small portion of the credits to Iraq made by Atlanta." ></td>
	<td class="line x" title="345:423	Example 23 Mr. Smale, who ordinarily insists on a test market before a national roll-out, told the team to go ahead--although he said he was skeptical that Pringle's could survive, Mr. Tucker says." ></td>
	<td class="line x" title="346:423	Example 24 The Cantonese insist that their fish be 'fresh,' though one whiff of Hong Kong harbor and the visitor may yearn for something shipped from distant seas." ></td>
	<td class="line x" title="347:423	Example 25 Money isn't the issue, Mr. Bush insists." ></td>
	<td class="line x" title="348:423	From analyzing these and similar data, a pattern emerges concerning the use of verbs like insist in discourse; namely, the co-occurrence with discourse markers denoting negative affect, such as although and but, as well as literal negatives, e.g., no and not." ></td>
	<td class="line x" title="349:423	This is reminiscent of the behavior of negative polarity items such as any more and at all." ></td>
	<td class="line x" title="350:423	Such lexical items occur only in the context of negatives within a certain structural configuration." ></td>
	<td class="line x" title="351:423	15 In a similar way, verbs such as insist seem to require an overt or implicit negation within the immediate discourse context, rather than within the clause." ></td>
	<td class="line x" title="352:423	For this reason, we will call such verbs discourse polarity items." ></td>
	<td class="line x" title="353:423	For our purposes, the significance of such data is twofold: first, experiments on corpora can test and confirm linguistic intuitions concerning a subtle semantic judgment; second, if such knowledge is in fact so systematic, then it must be at least partially represented in the lexical semantics of the verb." ></td>
	<td class="line x" title="354:423	To test whether the intuitions supported by the above data could be confirmed in corpora, Bergler (1991) derived the statistical co-occurrence of insist with discourse polarity markers in the 7 million-word corpus of Wall Street Journal articles." ></td>
	<td class="line x" title="355:423	She derived the statistics reported in Figure 7." ></td>
	<td class="line x" title="356:423	Let us assume, on the basis of this preliminary data 16 presented in Bergler (1992) that these verbs in fact do behave as discourse polarity items." ></td>
	<td class="line x" title="357:423	The question then 15 There is a rich literature on this topic." ></td>
	<td class="line x" title="358:423	For discussion see Ladusaw (1980) and Linebarger (1980)." ></td>
	<td class="line x" title="359:423	16 Overlap between the categories occurs in less than 35 cases." ></td>
	<td class="line x" title="360:423	350 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis Keywords insist insist on insist & but insist & negation Count 586 109 insist & subjunctive Figure 7 117 186 159 Comments occurrences throughout the corpus these have been cleaned by hand and are actually occurrences of the idiom insist on rather than accidental co-occurrences." ></td>
	<td class="line x" title="361:423	occurrences of both insist and but in the same sentence includes not and n't includes would, could, should, and be Negative markers with insist in WSJC." ></td>
	<td class="line x" title="362:423	immediately arises as to how we represent this type of knowledge." ></td>
	<td class="line x" title="363:423	Using the language of the qualia structure discussed above, we can make explicit reference to the polarity behavior, in the following informal but intuitive representation for the verb insist." ></td>
	<td class="line x" title="364:423	17 insist(x:ind,y:prop) \] FORMAL = REPORTING-VERB--LCP TELIC = say(x,true(y)) & presupposed(~b) & y = ~b This entry states that in the REPORTING-VERB sense of the word, insist is a relation between an individual and a statement that is the negation of a proposition, ~b, presupposed in the context of the utterance." ></td>
	<td class="line x" title="365:423	As argued in Pustejovsky (1991) and Miller and Fellbaum (1991), such simple oppositional predicates form a central part of our lexicalization of concepts." ></td>
	<td class="line x" title="366:423	Semantically motivated collocations such as these extracted from large corpora can provide presuppositional information for words that would otherwise be missing from the lexical semantics of an entry." ></td>
	<td class="line p" title="367:423	While full automatic extraction of semantic collocations is not yet feasible, some recent research in related areas is promising." ></td>
	<td class="line pc" title="368:423	Hindle (1990) reports interesting results of this kind based on literal collocations, where he parses the corpus (Hindle 1983) into predicate-argument structures and applies a mutual information measure (Fano 1961; Magerman and Marcus 1990) to weigh the association between the predicate and each of its arguments." ></td>
	<td class="line o" title="369:423	For example, as a list of the most frequent objects for the verb drink in his corpus, Hindle found beer, tea, Pepsi, and champagne." ></td>
	<td class="line o" title="370:423	Based on the distributional hypothesis that the degree of shared contexts is a similarity measure for words, he develops a similarity metric for nouns based on their substitutability in certain verb contexts." ></td>
	<td class="line o" title="371:423	Hindle thus finds sets of semantically similar nouns based on syntactic co-occurrence data." ></td>
	<td class="line p" title="372:423	The sets he extracts are promising; for example, the ten most similar nouns to treaty in his corpus are agreement, plan, constitution, contract, proposal, accord, amendment, rule, law, and legislation." ></td>
	<td class="line o" title="373:423	This work is very close in spirit to our own investigation here; the emphasis on syntactic co-occurrence enables Hindle to extract his similarity lists automatically; they 17 For illustration, we use an abbreviated version of the lexical entries under discussion, highlighting only certain qualia for the verbs." ></td>
	<td class="line x" title="374:423	For the most recent representation of verbal semantics in this framework, see Pustejovsky (1993)." ></td>
	<td class="line x" title="375:423	351 Computational Linguistics Volume 19, Number 2 are therefore easy to compile for different corpora, different sublanguages, etc. Here we are attempting to use these techniques together with a model of lexical meaning, to capture deeper lexical semantic collocations; e.g., the generalization that the list of objects occurring for the word drink contains only liquids." ></td>
	<td class="line x" title="376:423	In the final part of this section, we turn to how the analysis of corpora can provide lexical semantic preferences for verb selection." ></td>
	<td class="line x" title="377:423	As discussed above, there is a growing body of research on deriving collocations from corpora (cf.Church and Hanks 1990; Klavans, Chodorow, and Wacholder 1990; Wilks et al. 1993; Smadja 1991a, 1991b; Calzolari and Bindi 1990)." ></td>
	<td class="line x" title="379:423	Here we employ the tools of semantic analysis from Section 1 to examine the behavior of metonymy with reporting verbs." ></td>
	<td class="line x" title="380:423	We will show, on the basis of corpus analysis, how verbs display marked differences in the ability to license metonymic operations over their arguments." ></td>
	<td class="line x" title="381:423	Such information, we argue, is part of the preference semantics for a sublanguage, as automatically derived from corpus." ></td>
	<td class="line x" title="382:423	Metonymy can be seen as a case of 'licensed violation' of selectional restrictions." ></td>
	<td class="line x" title="383:423	For example, while the verb announce selects for a human subject, sentences like The Phantasie Corporation announced third quarter losses are not only an acceptable paraphrase of the selectionally correct form Mr. Phantasie Jr. announced third quarter losses for Phantasie Corp, but they are the preferred form in the Wall Street Journal)." ></td>
	<td class="line x" title="384:423	This is an example of subject type coercion, as discussed in Section 1." ></td>
	<td class="line x" title="385:423	For example, the qualia structure for a noun such as corporation might be represented as below: corporation(x) CONST = group(y),spokesperson(w),executive(z) FORMAL = organization(x) TELIC = execute(z, decisions) AGENTIVE = incorporate(y,x) The metonymic extension in this example is straightforward: a spokesman, executive, or otherwise legitimate representative 'speaking for' a company or institution can be metonymically replaced by that company or institution." ></td>
	<td class="line x" title="386:423	TM We find that this type of metonymic extension for the subject is natural and indeed very frequent with reporting verbs Bergler (1991), such as announce, report, release, and claim, while it is in general not possible with other verbs selecting human subjects, e.g., the verbs of contemplation (such as contemplate, consider, and think)." ></td>
	<td class="line x" title="387:423	However, there are subtle differences in the occurrence of such metonymies for the different members of the same semantic verb class that arise from corpus analysis." ></td>
	<td class="line x" title="388:423	A reporting verb is an utterance verb that is used to relate the words of a source." ></td>
	<td class="line x" title="389:423	In a careful study of seven reporting verbs on a 250,000-word corpus of Time magazine articles from 1963, we found that the preference for different metonymic extensions varies considerably within this field (Bergler 1991)." ></td>
	<td class="line x" title="390:423	Figure 8 shows the findings for the words insist, deny, admit, claim, announce, said, and told for two metonymic extensions, namely where a group stands for an individual (Analysts said ) and where a company or other institution stands for the individual (IBM announced  ).19 The difference in patterns of metonymic behavior is quite striking: semantically similar verbs seem to pattern similarly over all three categories; admit, insist, and deny show a closer resemblance to each other than to any of the others, while said and 18 Note, however, that the metonymic extension is not quite as simple as extending from any employee to the whole company or institution, but that a form of legitimation has to be involved)." ></td>
	<td class="line x" title="391:423	For more detail see Bergler (1992)." ></td>
	<td class="line x" title="392:423	19 The data for Figure 8 have been screened to ensure that only occurrences that constitute reporting contexts were used." ></td>
	<td class="line x" title="393:423	352 James Pustejovsky et al. Lexical Semantic Techniques for Corpus Analysis admit deny insist announce claim said told person 64% 59% 57% 51% 35% 69% 19% 11% 24% 10% 21% 14% 19% 16% 31% 38% other 2% 11% 3% 8% 6% 8% 16% Figure 8 Preference for different metonymies in subject position." ></td>
	<td class="line x" title="394:423	--t person WSJ 49% TIME 83% group 15% 6% institution other 34% 2% 4% 8% Figure 9 Preference for metonymies for said in a 160,000-word fragment of the Wall Street Journal corpus." ></td>
	<td class="line x" title="395:423	told form a category by themselves." ></td>
	<td class="line x" title="396:423	There may be a purely semantic explanation why said and told seem not to prefer the metonymic use in subject position; e.g., perhaps these verbs relate more closely to the act of uttering, or perhaps they are too informal, stylistically." ></td>
	<td class="line x" title="397:423	Evidence from other corpora, however, suggests that such information is accurately characterized as lexical preference." ></td>
	<td class="line x" title="398:423	An initial experiment on a subset of the Wall Street Journal Corpus, for example, shows that said has a quite different metonymic distribution there, reported in Figure 9." ></td>
	<td class="line x" title="399:423	In this corpus we discovered that subject selection for an individual person appeared in only 50% of the sentences, while a company/institution appeared in 34% of the cases." ></td>
	<td class="line x" title="400:423	This difference could either be attributed to a difference in style between Time magazine and the Wall Street Journal or perhaps to a difference in general usage between 1963 and 1989." ></td>
	<td class="line x" title="401:423	The statistics presented here can of course not determine the reason for the difference, but rather help establish the lexical semantic preferences that exist in a certain corpus and sublanguage." ></td>
	<td class="line x" title="402:423	An important question related to the extraction of preference information is what the corpus should be." ></td>
	<td class="line x" title="403:423	Recent effort has been spent constructing balanced corpora, containing text from different styles and sources, such as novels, newspaper texts, scientific journal articles, etc. The assumption is of course that given a representative mix of samples of language use, we can extract the general properties and usage of words." ></td>
	<td class="line x" title="404:423	But if we gain access to sophisticated automatic corpus analysis tools such as those 353 Computational Linguistics Volume 19, Number 2 discussed above, and indeed if we have specialized algorithms for sublanguage extraction, then homogeneous corpora might provide better data." ></td>
	<td class="line x" title="405:423	The few examples of lexical preference mentioned in this section might not tell us anything conclusive for the definitive usage of a word such as said, if there even exists such a notion." ></td>
	<td class="line x" title="406:423	Nevertheless the statistics provide an important tool for text analysis within the corpus from which they are derived." ></td>
	<td class="line x" title="407:423	Because we can systematically capture the violation of selectional restrictions (as semantically predicted), there is no need for a text analysis system to perform extensive commonsense inferencing." ></td>
	<td class="line x" title="408:423	Thus, such presupposition and preference statistics are vital to efficient processing of real text." ></td>
	<td class="line x" title="409:423	6." ></td>
	<td class="line x" title="410:423	Summary and Discussion In this paper we have presented a particularly directed program of research for how text corpora can contribute to linguistics and computational linguistics." ></td>
	<td class="line x" title="411:423	We first presented a representation language for lexical knowledge, the generative lexicon, and demonstrated how it facilitates the structuring of lexical relations among words, looking in particular at the problems of metonymy and polysemy." ></td>
	<td class="line x" title="412:423	Such a framework for lexical knowledge suggests that there are richer relationships among words in text beyond that of simple co-occurrence that can be extracted automatically." ></td>
	<td class="line x" title="413:423	The work suggests how linguistic phenomena such as metonymy and polysemy might be exploited for knowledge acquisition for lexical items." ></td>
	<td class="line x" title="414:423	Unlike purely statistical collocational analyses, the framework of a semantic theory allows the automatic construction of predictions about deeper semantic relationships among words appearing in collocational systems." ></td>
	<td class="line x" title="415:423	We illustrated the approach for the acquisition of lexical information for several classes of nominals, and how such techniques can fine-tune the lexical structures acquired from an initial seeding of a machine-readable dictionary." ></td>
	<td class="line x" title="416:423	In addition to conventional lexical semantic relations, we then showed how information concerning lexical presuppositions and preference relations can also be acquired from corpora, when analyzed with the appropriate semantic tools." ></td>
	<td class="line x" title="417:423	In conclusion, we feel that the application of computational resources to the analysis of text corpora has and will continue to have a profound effect on the direction of linguistic and computational linguistic research." ></td>
	<td class="line x" title="418:423	Unlike previous attempts at corpus research, the current focus is supported and guided by theoretical tools, and not merely statistical techniques." ></td>
	<td class="line x" title="419:423	We should furthermore welcome the ability to expand the data set used for the confirmation of linguistic hypotheses." ></td>
	<td class="line x" title="420:423	At the same time, we must remember that statistical results themselves reveal nothing, and require careful and systematic interpretation by the investigator to become linguistic data." ></td>
	<td class="line x" title="421:423	Acknowledgments This research was supported by DARPA contract MDA904-91-C-9328." ></td>
	<td class="line x" title="422:423	We would like to thank Scott Waterman for his assistance in preparing the statistics." ></td>
	<td class="line x" title="423:423	We would also like to thank Mats Rooth, Scott Waterman, and four anonymous reviewers for useful comments and discussion." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P93-1022
Contextual Word Similarity And Estimation From Sparse Data
Dagan, Ido;Marcus, Shaul;Markovitch, Shaul;"></td>
	<td class="line x" title="1:178	CONTEXTUAL WORD SIMILARITY AND ESTIMATION FROM SPARSE DATA Ido Dagan AT T Bell Laboratories 600 Mountain Avenue Murray Hill, NJ 07974 dagan@res earch, art." ></td>
	<td class="line x" title="2:178	tom Shaul Marcus Computer Science Department Technion Haifa 32000, Israel shaul@cs, t echnion, ac." ></td>
	<td class="line x" title="3:178	il $haul Markovitch Computer Science Department Technion Haifa 32000, Israel shaulm@cs, t echnion, ac." ></td>
	<td class="line x" title="4:178	il Abstract In recent years there is much interest in word cooccurrence relations, such as n-grams, verbobject combinations, or cooccurrence within a limited context." ></td>
	<td class="line x" title="5:178	This paper discusses how to estimate the probability of cooccurrences that do not occur in the training data." ></td>
	<td class="line x" title="6:178	We present a method that makes local analogies between each specific unobserved cooccurrence and other cooccurrences that contain similar words, as determined by an appropriate word similarity metric." ></td>
	<td class="line x" title="7:178	Our evaluation suggests that this method performs better than existing smoothing methods, and may provide an alternative to class based models." ></td>
	<td class="line x" title="8:178	1 Introduction Statistical data on word cooccurrence relations play a major role in many corpus based approaches for natural language processing." ></td>
	<td class="line x" title="9:178	Different types of cooccurrence relations are in use, such as cooccurrence within a consecutive sequence of words (n-grams), within syntactic relations (verb-object, adjective-noun, etc)." ></td>
	<td class="line x" title="10:178	or the cooccurrence of two words within a limited distance in the context." ></td>
	<td class="line oc" title="11:178	Statistical data about these various cooccurrence relations is employed for a variety of applications, such as speech recognition (Jelinek, 1990), language generation (Smadja and McKeown, 1990), lexicography (Church and Hanks, 1990), machine translation (Brown et al. , ; Sadler, 1989), information retrieval (Maarek and Smadja, 1989) and various disambiguation tasks (Dagan et al. , 1991; Hindle and Rooth, 1991; Grishman et al. , 1986; Dagan and Itai, 1990)." ></td>
	<td class="line x" title="12:178	A major problem for the above applications is how to estimate the probability of cooccurrences that were not observed in the training corpus." ></td>
	<td class="line x" title="13:178	Due to data sparseness in unrestricted language, the aggregate probability of such cooccurrences is large and can easily get to 25% or more, even for a very large training corpus (Church and Mercer, 1992)." ></td>
	<td class="line x" title="14:178	Since applications often have to compare alternative hypothesized cooccurrences, it is important to distinguish between those unobserved cooccurrences that are likely to occur in a new piece of text and those that are not." ></td>
	<td class="line x" title="15:178	These distinctions ought to be made using the data that do occur in the corpus." ></td>
	<td class="line x" title="16:178	Thus, beyond its own practical importance, the sparse data problem provides an informative touchstone for theories on generalization and analogy in linguistic data." ></td>
	<td class="line x" title="17:178	The literature suggests two major approaches for solving the sparse data problem: smoothing and class based methods." ></td>
	<td class="line x" title="18:178	Smoothing methods estimate the probability of unobserved cooccurrences using frequency information (Good, 1953; Katz, 1987; Jelinek and Mercer, 1985; Church and Gale, 1991)." ></td>
	<td class="line x" title="19:178	Church and Gale (Church and Gale, 1991) show, that for unobserved bigrams, the estimates of several smoothing methods closely agree with the probability that is expected using the frequencies of the two words and assuming that their occurrence is independent ((Church and Gale, 1991), figure 5)." ></td>
	<td class="line x" title="20:178	Furthermore, using held out data they show that this is the probability that should be estimated by a smoothing method that takes into account the frequencies of the individual words." ></td>
	<td class="line x" title="21:178	Relying on this result, we will use frequency based es~imalion (using word frequencies) as representative for smoothing estimates of unobserved cooccurrences, for comparison purposes." ></td>
	<td class="line x" title="22:178	As will be shown later, the problem with smoothing estimates is that they ignore the expected degree of association between the specific words of the cooccurrence." ></td>
	<td class="line x" title="23:178	For example, we would not like to estimate the same probability for two cooccurrences like 'eat bread' and 'eat cars', despite the fact that both 'bread' and 'cars' may have the same frequency." ></td>
	<td class="line x" title="24:178	Class based models (Brown et al. , ; Pereira et al. , 1993; Hirschman, 1986; Resnik, 1992) distinguish between unobserved cooccurrences using classes of 'similar' words." ></td>
	<td class="line x" title="25:178	The probability of a specific cooccurrence is determined using generalized parameters about the probability of class cooccur\] 64 rence." ></td>
	<td class="line x" title="26:178	This approach, which follows long traditions in semantic classification, is very appealing, as it attempts to capture 'typical' properties of classes of words." ></td>
	<td class="line x" title="27:178	However, it is not clear at all that unrestricted language is indeed structured the way it is assumed by class based models." ></td>
	<td class="line x" title="28:178	In particular, it is not clear that word cooccurrence patterns can be structured and generalized to class cooccurrence parameters without losing too much information." ></td>
	<td class="line x" title="29:178	This paper suggests an alternative approach which assumes that class based generalizations should be avoided, and therefore eliminates the intermediate level of word classes." ></td>
	<td class="line x" title="30:178	Like some of the class based models, we use a similarity metric to measure the similarity between cooccurrence patterns of words." ></td>
	<td class="line x" title="31:178	But then, rather than using this metric to construct a set of word classes, we use it to identify the most specific analogies that can he drawn for each specific estimation." ></td>
	<td class="line x" title="32:178	Thus, to estimate the probability of an unobserved cooccurfence of words, we use data about other cooccurfences that were observed in the corpus, and contain words that are similar to the given ones." ></td>
	<td class="line x" title="33:178	For example, to estimate the probability of the unobserved cooccurrence 'negative results', we use cooccurrences such as 'positive results' and 'negative numbers', that do occur in our corpus." ></td>
	<td class="line x" title="34:178	The analogies we make are based on the assumption that similar word cooccurrences have similar values of mutual information." ></td>
	<td class="line x" title="35:178	Accordingly, our similarity metric was developed to capture similarities between vectors of mutual information values." ></td>
	<td class="line x" title="36:178	In addition, we use an efficient search heuristic to identify the most similar words for a given word, thus making the method computationally affordable." ></td>
	<td class="line x" title="37:178	Figure 1 illustrates a portion of the similarity network induced by the similarity metric (only some of the edges, with relatively high values, are shown)." ></td>
	<td class="line x" title="38:178	This network may be found useful for other purposes, independently of the estimation method." ></td>
	<td class="line x" title="39:178	The estimation method was implemented using the relation of cooccurrence of two words within a limited distance in a sentence." ></td>
	<td class="line x" title="40:178	The proposed method, however, is general and is applicable for anY type of lexical cooccurrence." ></td>
	<td class="line x" title="41:178	The method was evaluated in two experiments." ></td>
	<td class="line x" title="42:178	In the first one we achieved a complete scenario of the use of the estimation method, by implementing a variant of the d\[Sambiguation method in (Dagan et al. , 1991), for sense selection in machine translation." ></td>
	<td class="line x" title="43:178	The estimation method was then successfully used to increase the coverage of the disambiguation method by 15%, with an increase of the overall precision compared to a naive, frequency based, method." ></td>
	<td class="line x" title="44:178	In the second experiment we evaluated the estimation method on a data recovery task." ></td>
	<td class="line x" title="45:178	The task simulates a typical scenario in disambiguation, and also relates to theoretical questions about redundancy and idiosyncrasy in cooccurrence data." ></td>
	<td class="line x" title="46:178	In this evaluation, which involved 300 examples, the performance of the estimation method was by 27% better than frequency based estimation." ></td>
	<td class="line x" title="47:178	2 Definitions We use the term cooccurrence pair, written as (x, y), to denote a cooccurrence of two words in a sentence within a distance of no more than d words." ></td>
	<td class="line x" title="48:178	When computing the distance d, we ignore function words such as prepositions and determiners." ></td>
	<td class="line x" title="49:178	In the experiments reported here d = 3." ></td>
	<td class="line x" title="50:178	A cooccurrence pair can be viewed as a generalization of a bigram, where a bigram is a cooccurrence pair with d = 1 (without ignoring function words)." ></td>
	<td class="line x" title="51:178	As with bigrams, a cooccurrence pair is directional, i.e." ></td>
	<td class="line x" title="52:178	(x,y)  (y,x)." ></td>
	<td class="line x" title="53:178	This captures some information about the asymmetry in the linear order of linguistic relations, such as the fact that verbs tend to precede their objects and follow their subjects." ></td>
	<td class="line x" title="54:178	The mutual information of a cooccurrence pair, which measures the degree of association between the two words (Church and Hanks, 1990), is defined as (Fano, 1961): P(xly) I(x,y) -log 2 P(x,y) _ log 2 (1) P(x)P(y) P(x) = log 2 P(y\[x) P(Y) where P(x) and P(y) are the probabilities of the events x and y (occurrences of words, in our case) and P(x, y) is the probability of the joint event (a cooccurrence pair)." ></td>
	<td class="line x" title="55:178	We estimate mutual information values using the Maximum Likelihood Estimator (MLE): P(x,y) _log~." ></td>
	<td class="line x" title="56:178	N f(x,y) \] I(x, y) = log~ P~x)P--(y) ( -d f(x)f(y) ' (2) where f denotes the frequency of an eyent and N is the length of the corpus." ></td>
	<td class="line x" title="57:178	While better estimates for small probabilities are available (Good, 1953; Church and Gale, 1991), MLE is the simplest to implement and was adequate for the purpose of this study." ></td>
	<td class="line x" title="58:178	Due to the unreliability of measuring negative mutual information values in corpora that are not extremely large, we have considered in this work any negative value to be 0." ></td>
	<td class="line x" title="59:178	We also set/~(x, y) to 0 if f(x, y) = 0." ></td>
	<td class="line x" title="60:178	Thus, we assume in both cases that the association between the two words is as expected by chance." ></td>
	<td class="line x" title="61:178	165 paper articles 14I /\00 1 conference." ></td>
	<td class="line x" title="62:178	0.132." ></td>
	<td class="line x" title="63:178	papers ~ /~,, U. I6 ~, l',, '-,, worksh:p. ,,._ ~0.106 ~ ~ \0.126 0." ></td>
	<td class="line x" title="64:178	4 \  symposmm ~ j book ' ' documentation 0.137 Figure 1: A portion of the similarity network." ></td>
	<td class="line x" title="65:178	3 Estimation for an Unobserved Cooccurrence Assume that we have at our disposal a method for determining similarity between cooccurrence patterns of two words (as described in the next section)." ></td>
	<td class="line x" title="66:178	We say that two cooccurrence pairs, (wl, w2) and (w~, w~), are similar if w~ is similar to wl and w~ is similar to w2." ></td>
	<td class="line x" title="67:178	A special (and stronger) case of similarity is when the two pairs differ only in one of their words (e.g.(wl,w~) and (wl,w2))." ></td>
	<td class="line x" title="69:178	This special case is less susceptible to noise than unrestricted similarity, as we replace only one of the words in the pair." ></td>
	<td class="line x" title="70:178	In our experiments, which involved rather noisy data, we have used only this restricted type of similarity." ></td>
	<td class="line x" title="71:178	The mathematical formulations, though, are presented in terms of the general case." ></td>
	<td class="line x" title="72:178	The question that arises now is what analogies can be drawn between two similar cooccurrence pairs, (wl,w2) and tw' wt~ Their probak 1' 21' bilities cannot be expected to be similar, since the probabilities of the words in each pair can be different." ></td>
	<td class="line x" title="73:178	However, since we assume that wl and w~ have similar cooccurrence patterns, and so do w~ and w~, it is reasonable to assume that the mutual information of the two pairs will be similar (recall that mutual information measures the degree of association between the words of the pair)." ></td>
	<td class="line x" title="74:178	Consider for example the pair (chapter, describes), which does not occur in our corpus 1 . This pair was found to be similar to the pairs (intro1 We used a corpus of about 9 million words of texts in the computer domain, taken from articles posted to the USENET news system." ></td>
	<td class="line x" title="75:178	duction, describes), (book, describes)and (section, describes), that do occur in the corpus." ></td>
	<td class="line x" title="76:178	Since these pairs occur in the corpus, we estimate their mutual information values using equation 2, as shown in Table 1." ></td>
	<td class="line x" title="77:178	We then take the average of these mutual information values as the similarity based estimate for I(chapter, describes), denoted as f(chapter, describes) 2." ></td>
	<td class="line x" title="78:178	This represents the assumption that the word 'describes' is associated with the word 'chapter' to a similar extent as it is associated with the words 'introduction', 'book' and 'section'." ></td>
	<td class="line x" title="79:178	Table 2 demonstrates how the analogy is carried out also for a pair of unassociated words, such as (chapter, knows)." ></td>
	<td class="line x" title="80:178	In our current implementation, we compute i(wl, w2) using up to 6 most similar words to each of wl and w~, and averaging the mutual information values of similar pairs that occur in the corpus (6 is a parameter, tuned for our corpus." ></td>
	<td class="line x" title="81:178	In some cases the similarity method identifies less than 6 similar words)." ></td>
	<td class="line x" title="82:178	Having an estimate for the mutual information of a pair, we can estimate its expected frequency in a corpus of the given size using a variation of equation 2: w2) = d f(wl)f(w2)2I(tl't2) (3) /(wl, In our example, f(chapter) = 395, N = 8,871,126 and d = 3, getting a similarity based estimate of f(chapter, describes)= 3.15." ></td>
	<td class="line x" title="83:178	This value is much 2We use I for similarity based estimates, and reserve i for the traditional maximum fikefihood estimate." ></td>
	<td class="line x" title="84:178	The similarity based estimate will be used for cooccurrence pairs that do not occur in the corpus." ></td>
	<td class="line x" title="85:178	166 i(w, (introduction, describes) 6.85 (book, describes) 6.27 (section, describes) 6.12 f(wl,w2) f(wl) f(w2) 5 464 277 13 1800 277 6 923 277 Average: 6.41 Table 1: The similarity based estimate as an average on similar pairs: \[(chapter, describes) = 6.41 (wl, w2) \[(wl, w=) (introduction, knows) 0 (book, knows) 0 (section, knows) 0 Average: 0 f(wl,w2) f(wl) f(w2) 0 464 928 0 1800 928 0 923 928 Table 2: The similarity based estimate for a pair of unassociated words: I(chapter, knows) = 0 higher than the frequency based estimate (0.037), reflecting the plausibility of the specific combination of words 3." ></td>
	<td class="line x" title="86:178	On the other hand, the similarity based estimate for \](chapter, knows) is 0.124, which is identical to the frequency based estimate, reflecting the fact that there is no expected association between the two words (notice that the frequency based estimate is higher for the second pair, due to the higher frequency of 'knows')." ></td>
	<td class="line x" title="87:178	4 TheSimilarity Metric Assume that we need to determine the degree of similarity between two words, wl and w2." ></td>
	<td class="line x" title="88:178	Recall that if we decide that the two words are similar, then we may infer that they have similar mutual information with some other word, w. This inference would be reasonable if we find that on average wl and w2 indeed have similar mutual information values with other words in the lexicon." ></td>
	<td class="line x" title="89:178	The similarity metric therefore measures the degree of similarity between these mutual information values." ></td>
	<td class="line x" title="90:178	We first define the similarity between the mutual information values of Wl and w2 relative to a single other word, w. Since cooccurrence pairs are directional, we get two measures, defined by the position of w in the pair." ></td>
	<td class="line x" title="91:178	The left context similarity of wl and w2 relative to w, termed simL(Wl, w2, w), is defined as the ratio between the two mutual information values, having the larger value in the denominator: simL(wl, w2, w) = min(I(w, wl), I(w, w2)) (4) max(I(w, wl), I(w, w2)) 3The frequency based estimate for the expected frequency of a cooccurrence pair, assuming independent occurrence of the two words and using their individual frequencies, is -~f(wz)f(w2)." ></td>
	<td class="line x" title="92:178	As mentioned earlier, we use this estimate as representative for smoothing estimates of unobserved cooccurrences." ></td>
	<td class="line x" title="93:178	This way we get a uniform scale between 0 and 1, in which higher values reflect higher similarity." ></td>
	<td class="line x" title="94:178	If both mutual information values are 0, then sirnL(wl,w2, w) is defined to be 0." ></td>
	<td class="line x" title="95:178	The right context similarity, simn(wl, w2, w), is defined equivalently, for I(Wl, w) and I(w2, w) 4." ></td>
	<td class="line x" title="96:178	Using definition 4 for each word w in the lexicon, we get 2  l similarity values for Wl and w2, where I is the size of the lexicon." ></td>
	<td class="line x" title="97:178	The general similarity between Wl and w2, termed sim(wl, w2), is defined as a weighted average of these 2  l values." ></td>
	<td class="line x" title="98:178	It is necessary to use some weighting mechanism, since small values of mutual information tend to be less significant and more vulnerable to noisy data." ></td>
	<td class="line x" title="99:178	We found that the maximal value involved in computing the similarity relative to a specific word provides a useful weight for this word in computing the average." ></td>
	<td class="line x" title="100:178	Thus, the weight for a specific left context similarity value, WL(Wl, W2, W), is defined as: Wt(wl, w) = max(I(w, wl), :(w, (5) (notice that this is the same as the denominator in definition 4)." ></td>
	<td class="line x" title="101:178	This definition provides intuitively appropriate weights, since we would like to give more weight to context words that have a large mutual information value with at least one of Wl and w2." ></td>
	<td class="line x" title="102:178	The mutual information value with the other word may then be large, providing a strong 'vote' for similarity, or may be small, providing a strong 'vote' against similarity." ></td>
	<td class="line x" title="103:178	The weight for a specific right context similarity value is defined equivalently." ></td>
	<td class="line x" title="104:178	Using these weights, we get the weighted average in Figure 2 as the general definition of 4In the case of cooccurrence pairs, a word may be involved in two types of relations, being the left or right argument of the pair." ></td>
	<td class="line x" title="105:178	The definitions can be easily adopted to cases in which there are more types of relations, such as provided by syntactic parsing." ></td>
	<td class="line x" title="106:178	167 sim(wl, w2) = ~toetexicon sirnL(wl, w2, w) . WL(Wl, W2, W) -tsimR(wl, w2, w) . WR(wl, w~, w) _ WL(Wl, w2, w) + WR(wl, w2, w) Y'~,o e,,,,,i~or, min(I(w, wl), I(w, w2) ) + min(I(wl, w), I(w~, w)) ~wetexicon max(I(w, Wl), I(w, w2) ) + max(I(wx, w), I(w2, w) ) (6) Figure 2: The definition of the similarity metric." ></td>
	<td class="line x" title="107:178	Exhaustive Search Approximation similar words sim similar words sim aspects 1.000 topics 0.100 areas 0.088 expert 0.079 issues 0.076 approaches 0.072 aspects 1.000 topics 0.100 areas 0.088 expert 0.079 issues 0.076 concerning 0.069 Table 3: The most tic and exhaustive results." ></td>
	<td class="line x" title="108:178	similar words of aspects: heurissearch produce nearly the same similarity s. The values produced by our metric have an intuitive interpretation, as denoting a 'typical' ratio between the mutual information values of each of the two words with another third word." ></td>
	<td class="line x" title="109:178	The metric is reflexive (sirn(w,w) -1), symmetric (sim(wz, w2) = sirn(w2, wz)), but is not transitive (the values of sire(w1, w2) and sire(w2, w3) do not imply anything on the value of sire(w1, w3))." ></td>
	<td class="line x" title="110:178	The left column of Table 3 lists the six most similar words to the word 'aspects' according to this metric, based on our corpus." ></td>
	<td class="line x" title="111:178	More examples of similarity were shown in Figure 1." ></td>
	<td class="line x" title="112:178	4.1 An efficient search heuristic The estimation method of section 3 requires that we identify the most similar words of a given word w. Doing this by computing the similarity between w and each word in the lexicon is computationally very expensive (O(12), where I is the size of the lexicon, and O(l J) to do this in advance for all the words in the lexicon)." ></td>
	<td class="line x" title="113:178	To account for this problem we developed a simple heuristic that searches for words that are potentially similar to w, using thresholds on mutual information values and frequencies of cooccurrence pairs." ></td>
	<td class="line oc" title="114:178	The search is based on the property that when computing sim(wl, w2), words that have high mutual information values 5The nominator in our metric resembles the similarity metric in (Hindle, 1990)." ></td>
	<td class="line x" title="115:178	We found, however, that the difference between the two metrics is important, because the denominator serves as a normalization factor." ></td>
	<td class="line x" title="116:178	with both wl and w2 make the largest contributions to the value of the similarity measure." ></td>
	<td class="line x" title="117:178	Also, high and reliable mutual information values are typically associated with relatively high frequencies of the involved cooccurrence pairs." ></td>
	<td class="line x" title="118:178	We therefore search first for all the 'strong neighbors' of w, which are defined as words whose cooccurrence with w has high mutual information and high frequency, and then search for all their 'strong neighbors'." ></td>
	<td class="line x" title="119:178	The words found this way ('the strong neighbors of the strong neighbors of w') are considered as candidates for being similar words of w, and the similarity value with w is then computed only for these words." ></td>
	<td class="line x" title="120:178	We thus get an approximation for the set of words that are most similar to w. For the example given in Table 3, the exhaustive method required 17 minutes of CPU time on a Sun 4 workstation, while the approximation required only 7 seconds." ></td>
	<td class="line x" title="121:178	This was done using a data base of 1,377,653 cooccurrence pairs that were extracted from the corpus, along with their counts." ></td>
	<td class="line x" title="122:178	5 Evaluations 5.1 Word sense disambiguation in machine translation The purpose of the first evaluation was to test whether the similarity based estimation method can enhance the performance of a disambiguation technique." ></td>
	<td class="line x" title="123:178	Typically in a disambiguation task, different cooccurrences correspond to alternative interpretations of the ambiguous construct." ></td>
	<td class="line x" title="124:178	It is therefore necessary that the probability estimates for the alternative cooccurrences will reflect the relative order between their true probabilities." ></td>
	<td class="line x" title="125:178	However, a consistent bias in the estimate is usually not harmful, as it still preserves the correct relative order between the alternatives." ></td>
	<td class="line x" title="126:178	To carry out the evaluation, we implemented a variant of the disambiguation method of (Dagan et al. , 1991), for sense disambiguation in machine translation." ></td>
	<td class="line x" title="127:178	We term this method as THIS, for Target Word Selection." ></td>
	<td class="line x" title="128:178	Consider for example the Hebrew phrase 'laxtom xoze shalom', which translates as 'to sign a peace treaty'." ></td>
	<td class="line x" title="129:178	The word 'laxtom', however, is ambiguous, and can be translated to either 'sign' or 'seal'." ></td>
	<td class="line x" title="130:178	To resolve the ambiguity, the 168 Precision Applicability TWS 85.5 64.3 Augmented TWS 83.6 79.6 Word Frequency 66.9 100 Table 4: Results of TWS, Augmented TWS and Word Frequency methods TWS method first generates the alternative lexical cooccurrence patterns in the targel language, that correspond to alternative selections of target words." ></td>
	<td class="line x" title="131:178	Then, it prefers those target words that generate more frequent patterns." ></td>
	<td class="line x" title="132:178	In our example, the word 'sign' is preferred upon the word 'seal', since the pattern 'to sign a treaty' is much more frequent than the pattern 'to seal a treaty'." ></td>
	<td class="line x" title="133:178	Similarly, the word 'xoze' is translated to 'treaty' rather than 'contract', due to the high frequency of the pattern 'peace treaty '6." ></td>
	<td class="line x" title="134:178	In our implementation, cooccurrence pairs were used instead of lexical cooccurfence within syntactic relations (as in the original work), to save the need of parsing the corpus." ></td>
	<td class="line x" title="135:178	We randomly selected from a software manual a set of 269 examples of ambiguous Hebrew words in translating Hebrew sentences to English." ></td>
	<td class="line x" title="136:178	The expected success rate of random selection for these examples was 23%." ></td>
	<td class="line x" title="137:178	The similarity based estimation method was used to estimate the expected frequency of unobserved cooccurrence pairs, in cases where none of the alternative pairs occurred in the corpus (each pair corresponds to an alternative target word)." ></td>
	<td class="line x" title="138:178	Using this method, which we term Augmented TWS, 41 additional cases were disambiguated, relative to the original method." ></td>
	<td class="line x" title="139:178	We thus achieved an increase of about 15% in the applicability (coverage) of the TWS method, with a small decrease in the overall precision." ></td>
	<td class="line x" title="140:178	The performance of the Augmented TWS method on these 41 examples was about 15% higher than that of a naive, Word Frequency method, which always selects the most frequent translation." ></td>
	<td class="line x" title="141:178	It should be noted that the Word Frequency method is equivalent to using the frequency based estimate, in which higher word frequencies entail a higher estimate for the corresponding cooccurrence." ></td>
	<td class="line x" title="142:178	The results of the experiment are summarized in Table 4." ></td>
	<td class="line x" title="143:178	5.2 A data recovery task In the second evaluation, the estimation method had to distinguish between members of two sets of 8It should be emphasized that the TWS method uses only a monolingual target corpus, and not a bilingual corpus as in other methods ((Brown et al. , 1991; Gale et al. , 1992))." ></td>
	<td class="line x" title="144:178	The alternative cooccurrence patterns in the target language, which correspond to the alternative translations of the ambiguous source words, are constructed using a bilingual lexicon." ></td>
	<td class="line x" title="145:178	cooccurrence pairs, one of them containing pairs with relatively high probability and the other pairs with low probability." ></td>
	<td class="line x" title="146:178	To a large extent, this task simulates a typical scenario in disambiguation, as demonstrated in the first evaluation." ></td>
	<td class="line x" title="147:178	Ideally, this evaluation should be carried out using a large set of held out data, which would provide good estimates for the true probabilities of the pairs in the test sets." ></td>
	<td class="line x" title="148:178	The estimation method should then use a much smaller training corpus, in which none of the example pairs occur, and then should try to recover the probabilities that are known to us from the held out data." ></td>
	<td class="line x" title="149:178	However, such a setting requires that the held out corpus would be several times larger than the training corpus, while the latter should be large enough for robust application of the estimation method." ></td>
	<td class="line x" title="150:178	This was not feasible with the size of our corpus, and the rather noisy data we had." ></td>
	<td class="line x" title="151:178	To avoid this problem, we obtained the set of pairs with high probability from the training corpus, selecting pairs that occur at least 5 times." ></td>
	<td class="line x" title="152:178	We then deleted these pairs from the data base that is used by the estimation method, forcing the method to recover their probabilities using the other pairs of the corpus." ></td>
	<td class="line x" title="153:178	The second set, of pairs with low probability, was obtained by constructing pairs that do not occur in the corpus." ></td>
	<td class="line x" title="154:178	The two sets, each of them containing 150 pairs, were constructed randomly and were restricted to words with individual frequencies between 500 and 2500." ></td>
	<td class="line x" title="155:178	We term these two sets as the occurring and non-occurring sets." ></td>
	<td class="line x" title="156:178	The task of distinguishing between members of the two sets, without access to the deleted frequency information, is by no means trivial." ></td>
	<td class="line x" title="157:178	Trying to use the individual word frequencies will result in performance close to that of using random selection." ></td>
	<td class="line x" title="158:178	This is because the individual frequencies of all participating words are within the same range of values." ></td>
	<td class="line x" title="159:178	To address the task, we used the following procedure: The frequency of each cooccurrence pair was estimated using the similarity-based estimation method." ></td>
	<td class="line x" title="160:178	If the estimated frequency was above 2.5 (which was set arbitrarily as the average of 5 and 0), the pair was recovered as a member of the occurring set." ></td>
	<td class="line x" title="161:178	Otherwise, it was recovered as a member of the non-occurring set." ></td>
	<td class="line x" title="162:178	Out of the 150 pairs of the occurring set, our method correctly identified 119 (79%)." ></td>
	<td class="line x" title="163:178	For th e non-occurring set, it correctly identified 126 pairs (84%)." ></td>
	<td class="line x" title="164:178	Thus, the method achieved an 0retail accuracy of 81.6%." ></td>
	<td class="line x" title="165:178	Optimal tuning of the threshold, to a value of 2, improves the overall accuracy to 85%, where about 90% of the members of the occurring set and 80% of those in the non-occurring 169 set are identified correctly." ></td>
	<td class="line x" title="166:178	This is contrasted with the optimal discrimination that could be achieved by frequency based estimation, which is 58%." ></td>
	<td class="line x" title="167:178	Figures 3 and 4 illustrate the results of the experiment." ></td>
	<td class="line x" title="168:178	Figure 3 shows the distributions of the expected frequency of the pairs in the two sets, using similarity based and frequency based estimation." ></td>
	<td class="line x" title="169:178	It clearly indicates that the similarity based method gives high estimates mainly to members of the occurring set and low estimates mainly to members of the non-occurring set." ></td>
	<td class="line x" title="170:178	Frequency based estimation, on the other hand, makes a much poorer distinction between the two sets." ></td>
	<td class="line x" title="171:178	Figure 4 plots the two types of estimation for pairs in the occurring set as a function of their true frequency in the corpus." ></td>
	<td class="line x" title="172:178	It can be seen that while the frequency based estimates are always low (by construction) the similarity based estimates are in most cases closer to the true value." ></td>
	<td class="line x" title="173:178	6 Conclusions In both evaluations, similarity based estimation performs better than frequency based estimation." ></td>
	<td class="line x" title="174:178	This indicates that when trying to estimate cooccurrence probabilities, it is useful to consider the cooccurrence patterns of the specific words and not just their frequencies, as smoothing methods do." ></td>
	<td class="line x" title="175:178	Comparing with class based models, our approach suggests the advantage of making the most specific analogies for each word, instead of making analogies with all members of a class, via general class parameters." ></td>
	<td class="line x" title="176:178	This raises the question whether generalizations over word classes, which follow long traditions in semantic classification, indeed provide the best means for inferencing about properties of words." ></td>
	<td class="line x" title="177:178	Acknowledgements We are grateful to Alon Itai for his help in initiating this research." ></td>
	<td class="line x" title="178:178	We would like to thank Ken Church and David Lewis for their helpful comments on earlier drafts of this paper." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P93-1024
Distributional Clustering Of English Words
Pereira, Fernando C. N.;Tishby, Naftali;Lee, Lillian;"></td>
	<td class="line x" title="1:150	DISTRIBUTIONAL CLUSTERING OF ENGLISH WORDS Fernando Pereira AT&T Bell Laboratories 600 Mountain Ave. Murray Hill, NJ 07974, USA pereira@research, att." ></td>
	<td class="line x" title="2:150	com Naftali Tishby Dept. of Computer Science Hebrew University Jerusalem 91904, Israel tishby@cs, hu\]i. ac." ></td>
	<td class="line x" title="3:150	il Lillian Lee Dept. of Computer Science Cornell University Ithaca, NY 14850, USA llee~cs, cornell, edu Abstract We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts." ></td>
	<td class="line x" title="4:150	Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering." ></td>
	<td class="line x" title="5:150	Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership." ></td>
	<td class="line x" title="6:150	In many cases, the clusters can be thought of as encoding coarse sense distinctions." ></td>
	<td class="line x" title="7:150	Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical 'soft' clustering of the data." ></td>
	<td class="line x" title="8:150	Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data." ></td>
	<td class="line x" title="9:150	INTRODUCTION Methods for automatically classifying words according to their contexts of use have both scientific and practical interest." ></td>
	<td class="line x" title="10:150	The scientific questions arise in connection to distributional views of linguistic (particularly lexical) structure and also in relation to the question of lexical acquisition both from psychological and computational learning perspectives." ></td>
	<td class="line x" title="11:150	From the practical point of view, word classification addresses questions of data sparseness and generalization in statistical language models, particularly models for deciding among alternative analyses proposed by a grammar. It is well known that a simple tabulation of frequencies of certain words participating in certain configurations, for example of frequencies of pairs of a transitive main verb and the head noun of its direct object, cannot be reliably used for comparing the likelihoods of different alternative configurations." ></td>
	<td class="line x" title="12:150	The problemis that for large enough corpora the number of possible joint events is much larger than the number of event occurrences in the corpus, so many events are seen rarely or never, making their frequency counts unreliable estimates of their probabilities." ></td>
	<td class="line oc" title="13:150	Hindle (1990) proposed dealing with the sparseness problem by estimating the likelihood of unseen events from that of 'similar' events that have been seen." ></td>
	<td class="line x" title="14:150	For instance, one may estimate the likelihood of a particular direct object for a verb from the likelihoods of that direct object for similar verbs." ></td>
	<td class="line x" title="15:150	This requires a reasonable definition of verb similarity and a similarity estimation method." ></td>
	<td class="line o" title="16:150	In Hindle's proposal, words are similar if we have strong statistical evidence that they tend to participate in the same events." ></td>
	<td class="line n" title="17:150	His notion of similarity seems to agree with our intuitions in many cases, but it is not clear how it can be used directly to construct word classes and corresponding models of association." ></td>
	<td class="line x" title="18:150	Our research addresses some of the same questions and uses similar raw data, but we investigate how to factor word association tendencies into associations of words to certain hidden senses classes and associations between the classes themselves." ></td>
	<td class="line x" title="19:150	While it may be worth basing such a model on preexisting sense classes (Resnik, 1992), in the work described here we look at how to derive the classes directly from distributional data." ></td>
	<td class="line x" title="20:150	More specifically, we model senses as probabilistic concepts or clusters c with corresponding cluster membership probabilities p(clw ) for each word w. Most other class-based modeling techniques for natural language rely instead on 'hard' Boolean classes (Brown et al. , 1990)." ></td>
	<td class="line x" title="21:150	Class construction is then combinatorially very demanding and depends on frequency counts for joint events involving particular words, a potentially unreliable source of information as noted above." ></td>
	<td class="line x" title="22:150	Our approach avoids both problems." ></td>
	<td class="line x" title="23:150	Problem Setting In what follows, we will consider two major word classes, 12 and Af, for the verbs and nouns in our experiments, and a single relation between them, in our experiments the relation between a transitive main verb and the head noun of its direct object." ></td>
	<td class="line x" title="24:150	Our raw knowledge about the relation consists of the frequencies f~n of occurrence of particular pairs (v,n) in the required configuration in a training corpus." ></td>
	<td class="line x" title="25:150	Some form of text analysis is required to collect such a collection of pairs." ></td>
	<td class="line x" title="26:150	The corpus used in our first experiment was derived from newswire text automatically parsed by 183 Hindle's parser Fidditch (Hindle, 1993)." ></td>
	<td class="line x" title="27:150	More recently, we have constructed similar tables with the help of a statistical part-of-speech tagger (Church, 1988) and of tools for regular expression pattern matching on tagged corpora (Yarowsky, 1992)." ></td>
	<td class="line x" title="28:150	We have not yet compared the accuracy and coverage of the two methods, or what systematic biases they might introduce, although we took care to filter out certain systematic errors, for instance the misparsing of the subject of a complement clause as the direct object of a main verb for report verbs like 'say'." ></td>
	<td class="line x" title="29:150	We will consider here only the problem of classifying nouns according to their distribution as direct objects of verbs; the converse problem is formally similar." ></td>
	<td class="line x" title="30:150	More generally, the theoretical basis for our method supports the use of clustering to build models for any n-ary relation in terms of associations between elements in each coordinate and appropriate hidden units (cluster centroids) and associations between thosehidden units." ></td>
	<td class="line x" title="31:150	For the noun classification problem, the empirical distribution of a noun n is then given by the conditional distribution p,~(v) = f~./ ~v f'~' The problem we study is how to use the Pn to classify the n EAf." ></td>
	<td class="line x" title="32:150	Our classification method will construct a set C of clusters and cluster membership probabilities p(c\]n)." ></td>
	<td class="line x" title="33:150	Each cluster c is associated to a cluster centroid Pc, which is a distribution over l; obtained by averaging appropriately the pn." ></td>
	<td class="line x" title="34:150	Distributional Similarity To cluster nouns n according to their conditional verb distributions Pn, we need a measure of similarity between distributions." ></td>
	<td class="line x" title="35:150	We use for this purpose the relative entropy or Kullback-Leibler (KL) distance between two distributions O(p I\[ q) = ZP(x) log p(x) : q(x) This is a natural choice for a variety of reasons, which we will just sketch here) First of all, D(p I\[ q) is zero just when p = q, and it increases as the probability decreases that p is the relative frequency distribution of a random sample drawn according to q. More formally, the probability mass given by q to the set of all samples of length n with relative frequency distribution p is bounded by exp-nn(p I\] q) (Cover and Thomas, 1991)." ></td>
	<td class="line x" title="36:150	Therefore, if we are trying to distinguish among hypotheses qi when p is the relative frequency distribution of observations, D(p II ql) gives the relative weight of evidence in favor of qi." ></td>
	<td class="line x" title="37:150	Furthermore, a similar relation holds between D(p IIP') for two empirical distributions p and p' and the probability that p and p~ are drawn from the same distribution q. We can thus use the relative entropy between the context distributions for two words to measure how likely they are to be instances of the same cluster centroid." ></td>
	<td class="line x" title="38:150	aA more formal discussion will appear in our paper Distributional Clustering, in preparation." ></td>
	<td class="line x" title="39:150	From an information theoretic perspective D(p \]1 q) measures how inefficient on average it would be to use a code based on q to encode a variable distributed according to p. With respect to our problem, D(pn H Pc) thus gives us the information loss in using cluster centroid Pc instead of the actual distribution pn for word n when modeling the distributional properties of n. Finally, relative entropy is a natural measure of similarity between distributions for clustering because its minimization leads to cluster centroids that are a simple weighted average of member distributions." ></td>
	<td class="line x" title="40:150	One technical difficulty is that D(p \[1 p') is not defined when p'(x) = 0 but p(x) > 0." ></td>
	<td class="line x" title="41:150	We could sidestep this problem (as we did initially) by smoothing zero frequencies appropriately (Church and Gale, 1991)." ></td>
	<td class="line x" title="42:150	However, this is not very satisfactory because one of the goals of our work is precisely to avoid the problems of data sparseness by grouping words into classes." ></td>
	<td class="line x" title="43:150	It turns out that the problem is avoided by our clustering technique, since it does not need to compute the KL distance between individual word distributions, but only between a word distribution and average distributions, the current cluster centroids, which are guaranteed to be nonzero whenever the word distributions are." ></td>
	<td class="line x" title="44:150	This is a useful advantage of our method compared with agglomerative clustering techniques that need to compare individual objects being considered for grouping." ></td>
	<td class="line x" title="45:150	THEORETICAL BASIS In general, we are interested in how to organize a set of linguistic objects such as words according to the contexts in which they occur, for instance grammatical constructions or n-grams." ></td>
	<td class="line x" title="46:150	We will show elsewhere that the theoretical analysis outlined here applies to that more general problem, but for now we will only address the more specific problem in which the objects are nouns and the contexts are verbs that take the nouns as direct objects." ></td>
	<td class="line x" title="47:150	Our problem can be seen as that of learning a joint distribution of pairs from a large sample of pairs." ></td>
	<td class="line x" title="48:150	The pair coordinates come from two large sets./kf and 12, with no preexisting internal structure, and the training data is a sequence S of N independently drawn pairs Si = (ni, vi) 1 < i < N . From a learning perspective, this problem falls somewhere in between unsupervised and supervised learning." ></td>
	<td class="line x" title="49:150	As in unsupervised learning, the goal is to learn the underlying distribution of the data." ></td>
	<td class="line x" title="50:150	But in contrast to most unsupervised learning settings, the objects involved have no internal structure or attributes allowing them to be compared with each other." ></td>
	<td class="line x" title="51:150	Instead, the only information about the objects is the statistics of their joint appearance." ></td>
	<td class="line x" title="52:150	These statistics can thus be seen as a weak form of object labelling analogous to supervision." ></td>
	<td class="line x" title="53:150	184 Distributional Clustering While clusters based on distributional similarity are interesting on their own, they can also be profitably seen as a means of summarizing a joint distribution." ></td>
	<td class="line x" title="54:150	In particular, we would like to find a set of clusters C such that each conditional distribution pn(v) can be approximately decomposed as p,(v) = ~p(cln)pc(v), cEC where p(c\[n) is the membership probability of n in c and pc(v) = p(vlc ) is v's conditional probability given by the centroid distribution for cluster c. The above decomposition can be written in a more symmetric form as ~(n,v) = ~_,p(c,n)p(vlc ) cEC = ~-~p(c)P(nlc)P(Vlc) (1) cEC assuming that p(n) and /5(n) coincide." ></td>
	<td class="line x" title="55:150	We will take (1) as our basic clustering model." ></td>
	<td class="line x" title="56:150	To determine this decomposition we need to solve the two connected problems of finding suitable forms for the cluster membership p(c\[n) and the centroid distributions p(vlc), and of maximizing the goodness of fit between the model distribution 15(n, v) and the observed data." ></td>
	<td class="line x" title="57:150	Goodness of fit is determined by the model's likelihood of the observations." ></td>
	<td class="line x" title="58:150	The maximum likelihood (ML) estimation principle is thus the natural tool to determine the centroid distributions pc(v)." ></td>
	<td class="line x" title="59:150	As for the membership probabilities, they must be determined solely by the relevant measure of object-to-cluster similarity, which in the present work is the relative entropy between object and cluster centroid distributions." ></td>
	<td class="line x" title="60:150	Since no other information is available, the membership is determined by maximizing the configuration entropy for a fixed average distortion." ></td>
	<td class="line x" title="61:150	With the maximum entropy (ME) membership distribution, ML estimation is equivalent to the minimization of the average distortion of the data." ></td>
	<td class="line x" title="62:150	The combined entropy maximization entropy and distortion minimization is carried out by a two-stage iterative process similar to the EM method (Dempster et al. , 1977)." ></td>
	<td class="line x" title="63:150	The first stage of an iteration is a maximum likelihood, or minimum distortion, estimation of the cluster centroids given fixed membership probabilities." ></td>
	<td class="line x" title="64:150	In the second stage of each iteration, the entropy of the membership distribution is maximized for a fixed average distortion." ></td>
	<td class="line x" title="65:150	This joint optimization searches for a saddle point in the distortion-entropy parameters, which is equivalent to minimizing a linear combination of the two known as free energy in statistical mechanics." ></td>
	<td class="line x" title="66:150	This analogy with statistical mechanics is not coincidental, and provides a better understanding of the clustering procedure." ></td>
	<td class="line x" title="67:150	Maximum Likelihood Cluster Centroids For the maximum likelihood argument, we start by estimating the likelihood of the sequence S of N independent observations of pairs (ni,vi)." ></td>
	<td class="line x" title="68:150	Using (1), the sequence's model log likelihood is N l(S) = log p(c)p(n, le)p(vilc)." ></td>
	<td class="line x" title="69:150	i=l cEC Fixing the number of clusters (model size) Icl, we want to maximize l(S) with respect to the distributions P(nlc ) and p(vlc)." ></td>
	<td class="line x" title="70:150	The variation of l(S) with respect to these distributions is N /v(v, Ic)@(n ~fl(S) =~ 1 ~~p(c)| + / (2) i=1 P(ni, vi) c~c \P(nilc)6p(vi Ic)\] with p(nlc ) and p(vlc ) kept normalized." ></td>
	<td class="line x" title="71:150	Using Bayes's formula, we have 1 v( lni, ~(ni, vi) -p(c)p(ni\[c)p(vi\[c) (3) for any c. 2 Substituting (3) into (2), we obtain N (,logp(n, lc)) ~l(S) = ZZp(clni,vi) + (4) logp(vi Ic) i=1 cEC since ~flogp -@/p. This expression is particularly useful when the cluster distributions p(n\[c) and p(vlc ) have an exponential form, precisely what will be provided by the ME step described below." ></td>
	<td class="line x" title="72:150	At this point we need to specify the clustering model in more detail." ></td>
	<td class="line x" title="73:150	In the derivation so far we have treated, p(n c) and p(v c) symmetrically, corresponding to clusters not of verbs or nouns but of verb-noun associations." ></td>
	<td class="line x" title="74:150	In principle such a symmetric model may be more accurate, but in this paper we will concentrate on asymmetric models in which cluster memberships are associated to just one of the components of the joint distribution and the cluster centroids are specified only by the other component." ></td>
	<td class="line x" title="75:150	In particular, the model we use in our experiments has noun clusters with cluster memberships determined by p(nlc) and centroid distributions determined by p(vlc )." ></td>
	<td class="line x" title="76:150	The asymmetric model simplifies the estimation significantly by dealing with a single component, but it has the disadvantage that the joint distribution, p(n, v) has two different and not necessarily consistent expressions in terms of asymmetric models for the two coordinates." ></td>
	<td class="line x" title="77:150	2As usual in clustering models (Duda and Hart, 1973), we assume that the model distribution and the empirical distribution are interchangeable at the solution of the parameter estimation equations, since the model is assumed to be able to represent correctly the data at that solution point." ></td>
	<td class="line x" title="78:150	In practice, the data may not come exactly from the chosen model class, but the model obtained by solving the estimation equations may still be the closest one to the data." ></td>
	<td class="line x" title="79:150	185 Maximum Entropy Cluster Membership While variations of p(nlc ) and p(vlc ) iri equation (4) are not independent, we can treat them separately." ></td>
	<td class="line x" title="80:150	First, for fixed average distortion between the cluster centroid distributions p(vlc ) and the data p(vln), we find the cluster membership probabilities, which are the Bayes inverses of the p(nlc), that maximize the entropy of the cluster distributions." ></td>
	<td class="line x" title="81:150	With the membership distributions thus obtained, we then look for the p(vlc ) that maximize the log likelihood l(S)." ></td>
	<td class="line x" title="82:150	It turns out that this will also be the values ofp(vlc) that minimize the average distortion between the asymmetric cluster model and the data." ></td>
	<td class="line x" title="83:150	Given any similarity measure din, c) between nouns and cluster centroids, the average cluster distortion is (0) = ~_, ~,p(cln)d(n,c ) (5) nEAr tEd If we maximize the cluster membership entropy H = ~ Zp(cln)logp(nlc) (6) nEX cEd subject to normalization ofp(nlc) and fixed (5), we obtain the following standard exponential forms (Jaynes, 1983) for the class and membership distributions 1 p(nlc) = Z- exp -rid(n, c) (7) 1 p(cJn) = ~ exp -rid(n, c) (8) where the normalization sums (partition functions) are Z~ = ~,~ exp-fld(n,c) and Zn = ~exp-rid(n,c)." ></td>
	<td class="line x" title="84:150	Notice that d(n,c) does not need to be symmetric for this derivation, as the two distributions are simply related by Bayes's rule." ></td>
	<td class="line x" title="85:150	Returning to the log-likelihood variation (4), we can now use (7) for p(n\[c) and the assumption for the asymmetric model that the cluster membership stays fixed as we adjust the centroids, to obtain N 61(S) = ~ ~ p(elni)6rid(n,, c) + ~ log Z~ (9) i=1 eEC where the variation of p(v\[c) is now included in the variation of d(n, e)." ></td>
	<td class="line x" title="86:150	For a large enough sample, we may replace the sum over observations in (9) by the average over N 61(s) = p(n) -'p(ln)6rid(n, ) + 6 logZ nEN cEC which, applying Bayes's rule, becomes 1 61(S) = ~ ~(~ ~ p(nlc)6rid(n, c) + 6 log Z." ></td>
	<td class="line x" title="87:150	eEC hEN At the log-likelihood maximum, this variation must vanish." ></td>
	<td class="line x" title="88:150	We will see below that the use of relative entropy for similarity measure makes 6 log Zc vanish at the maximum as well, so the log likelihood can be maximized by minimizing the average distortion with respect to the class centroids while class membership is kept fixed 1 p(njc)6d(n,e)= o, cEC nEX or, sufficiently, if each of the inner sums vanish ~ p(nlcl6d(n,c)= 0 (10) tee nEAr Minimizing the Average KL Distortion We first show that the minimization of the relative entropy yields the natural expression for cluster centroids P(vle ) = ~ p(nlc)p(vln ) (11) nEW To minimize the average distortion (10), we observe that the variation of the KL distance between noun and centroid distributions with respect to the centroid distribution p(v\[c), with each centroid distribution normalized by the Lagrange multiplier Ac, is given by ( ~evP(V\[n)lgp(v\[c) ) ~d(n,c) = ~ + A(E,~ev p(vlc) 1) = ~-~( p(vln)+AO,p(vlc ) v(vl ) Substituting this expression into (10), we obtain,,~ v p(vlc) Since the ~p(vlc ) are now independent, we obtain immediately the desired centroid expression (11), which is the desired weighted average of noun distributions." ></td>
	<td class="line x" title="89:150	We can now see that the variation (5 log Z~ vanishes for centroid distributions given by (11), since it follows from (10) that 6 log = exp-rid(,, c)6d(n, e) Ze -ri -0 n The Free Energy Function The combined minimum distortion and maximum entropy optimization is equivalent to the minimization of a single function, the free energy 1 log Zn F = -~ = <D>-'Hlri, where (D) is the average distortion (5) and H is the cluster membership entropy (6)." ></td>
	<td class="line x" title="90:150	186 The free energy determines both the distortion and the membership entropy through OZF (D) O~ OF H OT ' where T =/~-1 is the temperature." ></td>
	<td class="line x" title="91:150	The most important property of the free energy is that its minimum determines the balance between the 'disordering' maximum entropy and 'ordering' distortion minimization in which the system is most likely to be found." ></td>
	<td class="line x" title="92:150	In fact the probability to find the system at a given configuration is exponential in F Pocexp-flF, so a system is most likely to be found in its minimal free energy configuration." ></td>
	<td class="line x" title="93:150	Hierarchical Clustering The analogy with statistical mechanics suggests a deterministic annealing procedure for clustering Rose et al. , 1990), in which the number of clusters s determined through a sequence of phase transitions by continuously increasing the parameter/?" ></td>
	<td class="line x" title="94:150	following an annealing schedule." ></td>
	<td class="line x" title="95:150	The higher is fl, the more local is the influence of each noun on the definition of centroids." ></td>
	<td class="line x" title="96:150	Distributional similarity plays here the role of distortion." ></td>
	<td class="line x" title="97:150	When the scale parameter fl is close to zero, the similarity is almost irrelevant." ></td>
	<td class="line x" title="98:150	All words contribute about equally to each centroid, and so the lowest average distortion solution involves just one cluster whose centroid is the average of all word distributions." ></td>
	<td class="line x" title="99:150	As fl is slowly increased, a critical point is eventually reached for which the lowest F solution involves two distinct centroids." ></td>
	<td class="line x" title="100:150	We say then that the original cluster has split into the two new clusters." ></td>
	<td class="line x" title="101:150	In general, if we take any cluster c and a twin c' of c such that the centroid Pc' is a small random perturbation of Pc, below the critical fl at which c splits the membership and centroid reestimation procedure given by equations (8) and (11) will make pc and Pc, converge, that is, c and c' are really the same cluster." ></td>
	<td class="line x" title="102:150	But with fl above the critical value for c, the two centroids will diverge, giving rise to two daughters of c. Our clustering procedure is thus as follows." ></td>
	<td class="line x" title="103:150	We start with very low /3 and a single cluster whose centroid is the average of all noun distributions." ></td>
	<td class="line x" title="104:150	For any given fl, we have a current set of leaf clusters corresponding to the current free energy (local) minimum." ></td>
	<td class="line x" title="105:150	To refine such a solution, we search for the lowest fl which is the critical value for some current leaf cluster splits." ></td>
	<td class="line x" title="106:150	Ideally, there is just one split at that critical value, but for practical performance and numerical accuracy reasons we may have several splits at the new critical point." ></td>
	<td class="line x" title="107:150	The splitting procedure can then be repeated to achieve the desired number of clusters or model cross-entropy." ></td>
	<td class="line x" title="108:150	3 gun missile weapon rocket root 1 missile 0.835 officer rocket 0.850 aide bullet 0.917 chief 0.940 manager 4 0.758 shot 0.858 0.786 bullet 0.925 0.862 rocket 0.930 0.875 missile 1.037 2 0.484 0.612 0.649 0.651 Figure 1: Direct object clusters for fire CLUSTERING EXAMPLES All our experiments involve the asymmetric model described in the previous section." ></td>
	<td class="line x" title="109:150	As explained there, our clustering procedure yields for each value of ~ a set CZ of clusters minimizing the free energy F, and the asymmetric model for fl estimates the conditional verb distribution for a noun n by cECB where p(cln ) also depends on ft. As a first experiment, we used our method to classify the 64 nouns appearing most frequently as heads of direct objects of the verb 'fire' in one year (1988) of Associated Press newswire." ></td>
	<td class="line x" title="110:150	In this corpus, the chosen nouns appear as direct object heads of a total of 2147 distinct verbs, so each noun is represented by a density over the 2147 verbs." ></td>
	<td class="line x" title="111:150	Figure 1 shows the four words most similar to each cluster centroid, and the corresponding wordcentroid KL distances, for the four clusters resulting from the first two cluster splits." ></td>
	<td class="line x" title="112:150	It can be seen that first split separates the objects corresponding to the weaponry sense of 'fire' (cluster 1) from the ones corresponding to the personnel action (cluster 2)." ></td>
	<td class="line x" title="113:150	The second split then further refines the weaponry sense into a projectile sense (cluster 3) and a gun sense (cluster 4)." ></td>
	<td class="line x" title="114:150	That split is somewhat less sharp, possibly because not enough distinguishing contexts occur in the corpus." ></td>
	<td class="line x" title="115:150	Figure 2 shows the four closest nouns to the centroid of each of a set of hierarchical clusters derived from verb-object pairs involving the 1000 most frequent nouns in the June 1991 electronic version of Grolier's Encyclopedia (10 mil187 grant distinction form representation state 1.320 t residence ally 1.458 state residence 1.473 conductor /,movement 1.534 teacher '-number 0.999 number material 1.361 material variety 1.401 mass mass 1.422'~ variety ~number diversity structure concentration J control 1.2011 recognition 1.317 nomination 1.363 ~i~i~im 1.366 1.392 ent 1.329 _ 1.554 voyage 1.338 -~1.571 ~migration 1.428 1.577 progress 1.441 ~ conductor 0.699 j Istate \]1.279 I vice-president 0.756~eople I 1.417\] editor 0.814 Imodem 1.418 director 0.825 \[farmer 1.425 1.082 j complex 1.161 ~aavy 1.096 I 1.102 network 1.175_._._~ommunity 1.099 I 1.213 community 1.276 \]aetwork 1.244 1.233 group 1.327~ Icomplex 1.259 '~omplex \[1.097 I Imaterial \[ 0.976 ~network I 1'2111 1.026 ~alt \] 1.217\[ lake 11.3601 1.093 ------'-'-~mg 1.2441 ~region 11.4351 1.252 ~aumber 1.250\[ ~ssay \[0.695 I l'278~number 1.047 Icomedy 10.8001 comedy 1.060------'~oem \[ 0'8291 essay 1.142 f-reatise \[ 0.850\] piece 1.198'~urnber 11.120 I ~ariety 1.217 I ~aterial 1.275 I Fluster 1.3111 ~tructure \[ 1.3711 ~elationship 1.460 I 1.429 change 1.561 j~P ect 1.492\[ 1.537 failure 1.562'-''\]system 1.497 I 1.577 variation 1.592~ iaollution 1.187\] 1.582, structure 1.592 ~'~ailure 1.290 I \ \[re_crease 1.328 I Imtection 1.432\] speed 1.177 ~number 11.4611 level 1.315 _. ,__Jconcentration 1.478 I velocity 1.371 ~trength 1.488 I size 1.440~ ~atio 1.488 I ~)lspeed 11.130 I ~enith 11.2141 epth 1.2441 ecognition 0.874\] tcclaim 1.026 I enown 1.079 nomination 1.104 form 1.110 I ~xplanation 1.255 I :are 1.2911 :ontrol 1.295 I voyage 0.8611 Lrip 0.972\] progress 1.016 I improvement 1.114 I )rogram 1.459 I,peration 1.478 I :tudy 1.480 I nvestigation 1.4811 ;onductor 0.457\] rice-president 0.474 I lirector 0.489 I :hairman 0.5001 Figure 2: Noun Clusters for Grolier's Encyclopedia 188  ~3 ~o -~  train,*-----, test p k s-D new --tt ~  t t t 0 0 100 200 300 400 number of dusters Figure 3: Asymmetric Model Evaluation, AP88 Verb-Direct Object Pairs 0.8 '\." ></td>
	<td class="line x" title="116:150	m~ exceptional 3 0.6 -o 0.4 0.2 s L, ., i 0 0 100 200 300 number of clusters 400 Figure 4: Pairwise Verb Comparisons, AP88 VerbDirect Object Pairs lion words)." ></td>
	<td class="line x" title="117:150	MODEL EVALUATION The preceding qualitative discussion provides some indication of what aspects of distributional relationships may be discovered by clustering." ></td>
	<td class="line x" title="118:150	However, we also need to evaluate clustering more rigorously as a basis for models of distributional relationships." ></td>
	<td class="line x" title="119:150	So, far, we have looked at two kinds of measurements of model quality: (i) relative entropy between held-out data and the asymmetric model, and (ii) performance on the task of deciding which of two verbs is more likely to take a given noun as direct object when the data relating one of the verbs to the noun has been withheld from the training data." ></td>
	<td class="line x" title="120:150	The evaluation described below was performed on the largest data set we have worked with so far, extracted from 44 million words of 1988 Associated Press newswire with the pattern matching techniques mentioned earlier." ></td>
	<td class="line x" title="121:150	This collection process yielded 1112041 verb-object pairs." ></td>
	<td class="line x" title="122:150	We selected then the subset involving the 1000 most frequent nouns in the corpus for clustering, and randomly divided it into a training set of 756721 pairs and a test set of 81240 pairs." ></td>
	<td class="line x" title="123:150	Relative Entropy Figure 3 plots the unweighted average relative entropy, in bits, of several test sets to asymmetric clustered models of different sizes, given by 1 ~,,eAr, D(t,,ll/~-), where Aft is the set of direct objects in the test set and t,~ is the relative frequency distribution of verbs taking n as direct object in the test set." ></td>
	<td class="line x" title="124:150	3 For each critical value of f?, we show the relative entropy with respect to awe use unweighted averages because we are interested her on how well the noun distributions are approximated by the cluster model." ></td>
	<td class="line x" title="125:150	If we were interested on the total information loss of using the asymmetric model to encode a test corpus, we would instead use the asymmetric model based on gp of the training set (set train), of randomly selected held-out test set (set test), and of held-out data for a further 1000 nouns that were not clustered (set new)." ></td>
	<td class="line x" title="126:150	Unsurprisingly, the training set relative entropy decreases monotonically." ></td>
	<td class="line x" title="127:150	The test set relative entropy decreases to a minimum at 206 clusters, and then starts increasing, suggesting that larger models are overtrained." ></td>
	<td class="line x" title="128:150	The new noun test set is intended to test whether clusters based on the 1000 most frequent nouns are useful classifiers for the selectional properties of nouns in general." ></td>
	<td class="line x" title="129:150	Since the nouns in the test set pairs do not occur in the training set, we do not have their cluster membership probabilities that are needed in the asymmetric model." ></td>
	<td class="line x" title="130:150	Instead, for each noun n in the test set, we classify it with respect to the clusters by setting p(cln) = exp -DD(p,~ I lc)/Z, where p,~ is the empirical conditional verb distribution for n given by the test set." ></td>
	<td class="line x" title="131:150	These cluster membership estimates were then used in the asymmetric model and the test set relative entropy calculated as before." ></td>
	<td class="line x" title="132:150	As the figure shows, the cluster model provides over one bit of information about the selectional properties of the new nouns, but the overtraining effect is even sharper than for the held-out data involving the 1000 clustered nouns." ></td>
	<td class="line x" title="133:150	Decision Task We also evaluated asymmetric cluster models on a verb decision task closer to possible applications to disambiguation in language analysis." ></td>
	<td class="line x" title="134:150	The task consists judging which of two verbs v and v' is more likely to take a given noun n as object, when all occurrences of (v, n) in the training set were deliberately deleted." ></td>
	<td class="line x" title="135:150	Thus this test evaluates how well the models reconstruct missing data in the the weighted average ~,~e~t fnD(t,~ll~,,) where f,, is the relative frequency of n in the test set." ></td>
	<td class="line x" title="136:150	189 verb distribution for n from the cluster centroids close to n. The data for this test was built from the training data for the previous one in the following way, based on a suggestion by Dagan et al.(1993)." ></td>
	<td class="line x" title="138:150	104 noun-verb pairs with a fairly frequent verb (between 500 and 5000 occurrences) were randomly picked, and all occurrences of each pair in the training set were deleted." ></td>
	<td class="line x" title="139:150	The resulting training set was used to build a sequence of cluster models as before." ></td>
	<td class="line x" title="140:150	Each model was used to decide which of two verbs v and v ~ are more likely to appear with a noun n where the (v, n) data was deleted from the training set, and the decisions were compared with the corresponding ones derived from the original event frequencies in the initial data set." ></td>
	<td class="line x" title="141:150	The error rate for each model is simply the proportion of disagreements for the selected (v, n, v t) triples." ></td>
	<td class="line x" title="142:150	Figure 4 shows the error rates for each model for all the selected (v, n, v ~) (al 0 and for just those exceptional triples in which the conditional ratio p(n, v)/p(n, v ~) is on the opposite side of 1 from the marginal ratio p(v)/p(v~)." ></td>
	<td class="line x" title="143:150	In other words, the exceptional cases are those in which predictions based just on the marginal frequencies, which the initial one-cluster model represents, would be consistently wrong." ></td>
	<td class="line x" title="144:150	Here too we see some overtraining for the largest models considered, although not for the exceptional verbs." ></td>
	<td class="line x" title="145:150	CONCLUSIONS We have demonstrated that a general divisive clustering procedure for probability distributions can be used to group words according to their participation in particular grammatical relations with other words." ></td>
	<td class="line x" title="146:150	The resulting clusters are intuitively informative, and can be used to construct classbased word coocurrence models with substantial predictive power." ></td>
	<td class="line x" title="147:150	While the clusters derived by the proposed method seem in many cases semantically significant, this intuition needs to be grounded in a more rigorous assessment." ></td>
	<td class="line x" title="148:150	In addition to predictive power evaluations of the kind we have already carried out, it might be worth comparing automatically-derived clusters with human judge: ments in a suitable experimental setting." ></td>
	<td class="line x" title="149:150	Moving further in the direction of class-based language models, we plan to consider additional distributional relations (for instance, adjectivenoun) and apply the results of clustering to the grouping of lexical associations in lexicalized grammar frameworks such as stochastic lexicalized tree-adjoining grammars (Schabes, 1992)." ></td>
	<td class="line x" title="150:150	ACKNOWLEDGMENTS We would like to thank Don Hindle for making available the 1988 Associated Press verb-object data set, the Fidditch parser and a verb-object structure filter, Mats Rooth for selecting the objects of 'fire' data set and many discussions, David Yarowsky for help with his stemming and concordancing tools, andIdo Dagan for suggesting ways of testing cluster models." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W93-0107
Hierarchical Clustering Of Verbs
Basili, Roberto;Pazienza, Maria Teresa;Velardi, Paola;"></td>
	<td class="line x" title="1:179	HIERARCHICAL CLUSTERING OF VERBS Roberto Basili (*) Maria Teresa Pazienza (*) Paola Velardi (**) (*) Universita' di Roma T~x Vergata, Italy (**) Universita' di Ancona, Italy Abstract." ></td>
	<td class="line x" title="2:179	In this paper we present an unsupervised learning algorithm for incremental concept formation, based on an augmented version of COBWEB." ></td>
	<td class="line x" title="3:179	The algorithm is applied to the task of acquiring a verb taxonomy through the systematic observation of verb usages in corpora." ></td>
	<td class="line x" title="4:179	Using a Machine Learning methodology for a Natural language problem required adjustments on both sides." ></td>
	<td class="line x" title="5:179	In fact, concept formation algorithms assume the input information as being stable, unambiguous and complete." ></td>
	<td class="line x" title="6:179	At the opposite, linguistic data are ambiguous, incomplete, and possibly erroneous." ></td>
	<td class="line x" title="7:179	A NL processor is used to extract semiautomatically from corpora the thematic roles of verbs and derive a feature-vector representation of verb instances." ></td>
	<td class="line x" title="8:179	In order to account for multiple instances of the same verb, the measure of category utility, defined in COBWEB, has been augmented with the notion of memory inertia." ></td>
	<td class="line x" title="9:179	Memory inertia models the influence that previously classified instances of a given verb have on the classification of subsequent instances of the same verb." ></td>
	<td class="line x" title="10:179	Finally, a method is defined to identify the basic-level classes of an acquired hierarchy, i.e. those bringing the most predictive information about their members." ></td>
	<td class="line x" title="11:179	1." ></td>
	<td class="line x" title="12:179	Introduction The design of word-sense taxonornies is acknowledged as one of the most difficult (and frustrating) tasks in NLP systems." ></td>
	<td class="line x" title="13:179	The decision to assign a word to a category is far from being straightforward (Nirenburg and Raskin (1987)) and often the lexicon builders do not use consistent classification pfincipia." ></td>
	<td class="line x" title="14:179	Automatic approaches to the acquisition of word taxonomies have generally made use of machine readable dictionaries (MRD), for the typical definitory nature of MRD texts." ></td>
	<td class="line x" title="15:179	For example, in Byrd et al. , (1987) and other similar studies the category of a word is acquired from the first few words of a dictionary definition." ></td>
	<td class="line x" title="16:179	Besides the well known problems of inconsistency and circularity of definitions, an inherent difficulty with this approach is that verbs can hardly be defined in terms of genus and differentiae." ></td>
	<td class="line x" title="17:179	Verb semantics resides in the nature of the event they describe, that is better expressed by the roles played by its arguments in a sentence." ></td>
	<td class="line x" title="18:179	Psycholinguistie studies on verb semantics outline the relevance of thematic roles, especially in eategorisation activities Keil, (1989), Jackendoff (1983) and indicate the argument structure of verbs as playing a central role in language acquisition Pinker (1989)." ></td>
	<td class="line x" title="19:179	In NLP, representing verb semantics with their thematic roles is a consolidated practice, even though theoretical researches (Pustejovski (1991)) propose more rich and formal representation frameworks." ></td>
	<td class="line oc" title="20:179	More recent papers Hindle (1990), Pereira and Tishby (1992) proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts." ></td>
	<td class="line o" title="21:179	Both papers use as a source of information large corpora, but differ in the type of statistical approach used to determine word similarity." ></td>
	<td class="line n" title="22:179	These studies, though valuable, leave several open problems: 70 1) A metric of conceptual closeness based on mere syntactic similarity is questionable, particularly if applied to verbs." ></td>
	<td class="line x" title="23:179	In fact, the argument structure of verbs is variegated and poorly overlapping." ></td>
	<td class="line x" title="24:179	Furthermore, subject and object relations do not fully characterize many verbs." ></td>
	<td class="line x" title="25:179	2) Many events accumulate statistical evidence only in very large corpora, even though in Pereira and Tishby (1992) the adopted notion of distributional similarity in part avoids this problem." ></td>
	<td class="line x" title="26:179	3) The description of a word is an 'agglomerate' of its occurrences in the corpus, and it is not possible to discriminate different senses." ></td>
	<td class="line x" title="27:179	4) None of the aforementioned studies provide a method to describe and evaluate the derived categories." ></td>
	<td class="line x" title="28:179	As a result, the acquired classifications seem of little use for a large-scale NLP system, and even for a linguist that is in charge of deriving the taxonomy." ></td>
	<td class="line x" title="29:179	Our research is an attempt to overcome in part the aforementioned limitations." ></td>
	<td class="line x" title="30:179	We present a corpus-driven unsupervised learning algorithm based on a modified version of COBWEB Fisher (1987), Gennari et al.(1989)." ></td>
	<td class="line x" title="32:179	The algorithm learns verb classifications through the systematic observation of verb usages in sentences." ></td>
	<td class="line x" title="33:179	The algorithm has been tested on two domains with very different linguistic styles, a commercial and a legal corpus of about 500,000 words each." ></td>
	<td class="line x" title="34:179	In section 2 we highlight the advantages that concept formation algorithms, like COBWEB, have over 'agglomerate' statistical approaches." ></td>
	<td class="line x" title="35:179	However, using a Machine Learning methodology for a Natural Language Processing problem required adjustments on both sides." ></td>
	<td class="line x" title="36:179	Raw texts representing instances of verb usages have been processed to fit the feature-vector like representation needed for concept formation algorithms." ></td>
	<td class="line x" title="37:179	The NL processor used for this task is briefly summarized in section2.1." ></td>
	<td class="line x" title="38:179	Similarly, it was necessary to adapt COBWEB to the linguistic nature of the classification activity, since, for example, the algorithm does not discriminate different instances of the same entity, i.e. polysernic verbs, nor identical instances of different entities, i.e. verbs with the same pattern of use." ></td>
	<td class="line x" title="39:179	These modifications are discussed in sections 2.1 trough 2.3." ></td>
	<td class="line x" title="40:179	Finally, in section 3 we present a method to identify the basic-level categories of a classification, i.e. those that are repository of most of the lexical information about their members." ></td>
	<td class="line x" title="41:179	Class descriptions and basic-level categories, as derived by our clustering algorithm, are in our view greatly helpful at addressing the intuition of a linguist towards the relevant taxonomic relations in a Oven language domain." ></td>
	<td class="line x" title="42:179	2." ></td>
	<td class="line x" title="43:179	CIAULAI: An algorithm to acquire word clusters Incremental example-based learning algorithms, like COBWEB Fisher (1987), seem more adequate than other Machine Learning and Statistical methods to the task of acquiring word taxonomies from corpora." ></td>
	<td class="line x" title="44:179	COBWEB has several desirable features: a) Incrementality, since whenever new data are available, the system updates its classification; b) A formal description of the acquired clusters; c) The notion of category utility, used to select among competing classifications." ></td>
	<td class="line x" title="45:179	b) and e) are particularly relevant to our linguistic problem, as remarked in the Introduction." ></td>
	<td class="line x" title="46:179	On the other side, applying COBWEB to verb classification is not straightforward." ></td>
	<td class="line x" title="47:179	First, there is a knowledge representation problem, that is common to most Machine Learning algorithms: Input instances must be pre-coded (manually) using a featureI Ciaula stands for Concept formation Algorithm Used for Language Acquisition, and has been inspired by the tale 'Ciaula scopre la luna' by Luigi Pirandello (1922)." ></td>
	<td class="line x" title="48:179	71 vector like representation." ></td>
	<td class="line x" title="49:179	This limited the use of such algorithms in many real world problems." ></td>
	<td class="line x" title="50:179	In the specific case we are analyzing, a manual codification of verb instances is not realistic on a large scale." ></td>
	<td class="line x" title="51:179	Second, the algorithm does not distinguish multiple usages of the same verb, nor different verbs that are found with the same pattern of use, since different instances with the same feature vector are taken as identical." ></td>
	<td class="line x" title="52:179	The motivation is that concept formation algorithms as COBWEB assume the input information as being stable, unambiguous, and complete." ></td>
	<td class="line x" title="53:179	At the opposite, our data do not exhibit a stable behaviour, they are ambiguous, incomplete, and possibly misleading, since errors in codification of verb instances may well be possible." ></td>
	<td class="line x" title="54:179	In the following sections we will discuss the methods by which we attempted to overcome these obstacles." ></td>
	<td class="line x" title="55:179	2.1 Representing verb instances This section describes the formal representation of verb instances and verb clusters in CIAULA." ></td>
	<td class="line x" title="56:179	Verb usages input to the clustering algorithm are represented by their thematic roles, acquired semi-automatically from corpora by a process that has been described in Basili, (1992a), (1992b), (in press)." ></td>
	<td class="line x" title="57:179	In short, sentences including verbs are processed as follows: First, a (general-purpose) morphologic and a partial syntactic analyzer Basili, (1992b) extracts from the sentences in the corpus all the elementary syntactic relations (esl) in which a word participates." ></td>
	<td class="line x" title="58:179	Syntactic relations are word pairs and triples augmented with a syntactic information, e.g. for the verb to carry: N_V( company,carry) V_N(carry,food) V_N(carry,goods) V_prep_N(carry, with;truck), etc. Each syntactic relation is stored with its frequency of occurrence in the corpus." ></td>
	<td class="line x" title="59:179	Ambiguous relations are weighted by a 1/k factor, where k is the number of competing esl in a sentence." ></td>
	<td class="line x" title="60:179	Second, the verb arguments are tagged by hand using 10-12 'naive' conceptual types (semantic tags), such as: ACT, PLACE, HUMAN_ENTITY, GOOD, etc. Conceptual types are not the same for every domain, even though the commercial and legal domains have many common types." ></td>
	<td class="line x" title="61:179	Syntactic relations between words are validated in terms of semantic relations between word classes using a set of semiautomatically acquired selectional rules Basili, (1992a)." ></td>
	<td class="line x" title="62:179	For example, V_prep_N(carry,with,truck) is accepted as an istance of the high-level selectional rule \[ACT\]-->(INSTRUMENT)>\[MACHINE\]." ></td>
	<td class="line x" title="63:179	The relation: \[carry\]>(INSTRUMENT)->\[truck\] is acquired as part of the argument structure of the verb to carry." ></td>
	<td class="line x" title="64:179	In other published papers we demonstrated that the use of semantic tags greatly increase the statistical stabifity of the data, and add predictive power to the acquired information on word usages, at the price of a limited manual work (the semantic tagging)." ></td>
	<td class="line x" title="65:179	For the purpose of this paper, the interesting aspect is that single instances of verb usages (local 2 meanings) are validated on the basis of a global analysis of the corpus." ></td>
	<td class="line x" title="66:179	This considerably reduces (though does not eliminate) the presence of erroneous instances." ></td>
	<td class="line x" title="67:179	The detected thematic roles of a verb v in a sentence are represented by the featurevector: (1) v / (Rit:Catjt) it~ I, jt~ J t=l,2 n where Rit are the thematic roles (AGENT, INSTRUMENT etc)." ></td>
	<td class="line x" title="68:179	3 and Catjt are the conceptual types of the words to which v is related semantically." ></td>
	<td class="line x" title="69:179	For example, the 2 i.e. meanings that are completely described within a single sentence of the corpus 3 The roles used are an extension of Sowa's conceptual relations \[Sowa 1984\]." ></td>
	<td class="line x" title="70:179	Details on the set of conceptual relations used and a corpus-based method to select a domain-approprime set, are provided in other papers." ></td>
	<td class="line x" title="71:179	72 following sentence in the commercial domain: ' ia ditta produce beni di consumo con macchinari elettromeccanici' ' the company produces goods with electroraechanical machines' originates the instance: produce/(AGENT:HUMAN~ENTITY, OBJECT:GOODS, INSTRUMENT:MACHINE) Configurations in which words of the same conceptual type play the same roles are strong suggestion of semantic similarity between the related events." ></td>
	<td class="line x" title="72:179	The categorisation process must capture this similarity among local meanings of verbs." ></td>
	<td class="line x" title="73:179	The representation of verb clusters follows the scheme adopted in COBWEB." ></td>
	<td class="line x" title="74:179	Each target class is represented by the probability that its members (i.e. verbs) are seen with a set of typical roles." ></td>
	<td class="line x" title="75:179	Given the set {Ri}i~I of thematic roles and the set {Catj }je j of conceptual types, a target class ~ for our clustering system is given by the following (2) cE = < cog,, \[x\]ij, Vc E, S~ > or equivalently by (2)' < c, \[x\]ij, V, S > A class is represented in COBWEB by the matrix \[x\]ij, showing the distribution of probability among relations (Ri) and conceptual types (Cat j)." ></td>
	<td class="line x" title="76:179	The additional parameters V~,and cog, are introduced to account for multiple instances of the same verb in a class, c~ is the cardinality (i.e. the number of different instance members of cE), and V~ is the set of pairs <v, v#> such that it exists at least one instance v / (Ri:Caztj) classified in ~, and v# is the number of such instances." ></td>
	<td class="line x" title="77:179	Finally, S~,iS the set of CEsubtypes." ></td>
	<td class="line x" title="78:179	The definitions of the empty class (3.1) and of the top node of the taxonomy (3.2) follows from (2) (3.1) <0,\[xlij,{O},lO}> with xij=0 for each i,j (3.2) <Ntot, \[x\]ij, V, S > where Ntot is the number of available instances in the corpus, V is the set of verbs with their absolute occurrences." ></td>
	<td class="line x" title="79:179	An excerpt of a class acquired from the legal domain is showed in Fig." ></td>
	<td class="line x" title="80:179	1." ></td>
	<td class="line x" title="81:179	The semantic types used in this domain are listed in the figure." ></td>
	<td class="line x" title="82:179	Special type of classes are those in which only a verb has been classified, that we will call singleton classes." ></td>
	<td class="line x" title="83:179	A singleton class is a class cE=<c,\[x\]ij,V,S> for which card(V)= 1." ></td>
	<td class="line x" title="84:179	It will be denoted by { v } where v is the only member of (whatever its occurrences) ~." ></td>
	<td class="line x" title="85:179	For a singleton class it is clearly true that S={0}." ></td>
	<td class="line x" title="86:179	Note that a singleton class is different from an instance because any number of instances of the verb v can be classified in {v }." ></td>
	<td class="line x" title="87:179	2.2 Measuring the utility of a classification As remarked in the introduction, a useful property of concept formation algorithms, with respect to agglomerate statistical approaches, is the use of formal methods that guide the classification choices." ></td>
	<td class="line x" title="88:179	Quantitative approaches to model human choices in categorisation have been adopted in psychological models of conceptual development." ></td>
	<td class="line x" title="89:179	In her seminal work, Rosch (1976) introduced a metrics of preference, the category cue validity, expressed by the sum of expectations of observing some feature in the class members." ></td>
	<td class="line x" title="90:179	This value is maximum for the so-called basic level categories." ></td>
	<td class="line x" title="91:179	A later development, used in COBWEB, introduces the notion of category utility, derived from the application of the Bayes law to the expression of the predictive power of a given classification." ></td>
	<td class="line x" title="92:179	Given a classification 73 into K classes, the category utility is given by: (4)." ></td>
	<td class="line x" title="93:179	K 2 E prob(C z)~.prob(attr ffval}C k'l JJ In COBWEB, a hill climbing algorithm is defined to maximize the category utility of a resulting classification." ></td>
	<td class="line x" title="94:179	The following expression is used to discriminate among conflicting clusters: K 2 2 prob(C ~.prob(attr pval~C~ -~,prob(attr pvalj) (5) k-I j$,I K The clusters that maximize the above quantity provide the system with the capability of deriving the best predictive taxonomy with respect to the set of i attributes and j values." ></td>
	<td class="line x" title="95:179	This evaluation maximizes infra-class similarity and intraclass dissimilarity." ></td>
	<td class="line x" title="96:179	Class: 123 I Cardina I ity : A AGEN: 0.00 AFF: 0.00 FI_S: 0.00 MANN: 0.00 FI_D: 0.00 FI_L: 0.00 REF: 0.00 REC: 0'.00 CAUSE: 0.00 LOC: 0.00 Father class: 7 18 (5) Level: 2 D 0.00 0 0.00 0 0.00 0 1.00 0 0.00 0 0.00 0 0.00 0 0.00 0 0.00 0 0.00 0 Tau: 1.00 RE G HE AE S 00 0.00 1.00 0.00 0.00 00 0.00 0.00 0.00 0.00 00 0.00 0.00 0.00 0.00 00 0.00 0.00 0.00 0.00 00 0.00 0.00 0.00 0.00 00 0.00 0.00 0.00 0.00 00 0.00 0.00 0.00 0.00 00 0.00 0.00 0.00 0.00 00 0.00 0.00 0.00 0.00 00 0.00 0.00 0.00 0.00 Omega : 0.28 RE TE P AM Q M 0 00 0.00 0.00 0.00 0.00 0.00 0 00 0.00 0.00 0.00 0.00 0.00 0 00 0.00 0.00 0.00 0.00 0.00 0 00 0.00 0.00 0.00 0.00 0.00 0 00 0.00 0.00 0.00 0.00 0.00 0 00 0.00 0.00 0.00 0.00 0.00 0 00 0.00 0.00 0.00 0.00 0.00 0 00 0.00 0.00 0.00 0.00 0.00 0 00 0.00 0.00 0.00 0.00 0.00 0 00 0.00 0.00 0.00 0.00 0.00 Heads: approvare (occ 8) %to approve stabllire (occ 7) %to establish, to decide prevedere (occ i) %to foresee disporre (occ i) %to dispose dichiarare (occ I) %to declare LE, QEd~/2/k (semantic types for the legal domain): A=ACT, D=DOCUMENT, RE=REAL ESTATE, G=GOODS, HE=HUMANENTITY, AE=ABSTRACT_ENTITY, S=STATE, AM=AMOUNT, TE=TEMPORAL_ENTITY, P=PLACES, Q=QUALITY, M=MANNER Fig 1." ></td>
	<td class="line x" title="97:179	Example of cluster produced by the system The notion of category utility adopted in COBWEB, however, does not fully cope with our linguistic problem." ></td>
	<td class="line x" title="98:179	As remarked in the previous section, multiple instances of the same entity are not considered in COBWEB." ></td>
	<td class="line x" title="99:179	In order to account for multiple instances of a verb, we introduced the notion of mnemonic inertia." ></td>
	<td class="line x" title="100:179	The mnemonic inertia models an inertial trend attracting a new instance of an already classified verb in the class where it was previously classified." ></td>
	<td class="line x" title="101:179	Given the incoming instance v / (Ri:Ca, tj) and a current classification in the set of classes ~, for each k the mnemonic inertia is modelled by: (6) gk(v) = #v/Ck where #v is the number of instances of the verb v already classified in 5~: and Ck is the cardinality of c~:." ></td>
	<td class="line x" title="102:179	(6) expresses a fuzzy membership of v to the class 5~k. The more instances of v are classified into 5fk, the more future observations of v will be attracted by ~." ></td>
	<td class="line x" title="103:179	A suitable combination of the mnemonic 74 inertia and the category utility provides our system with generalization capabilities along with the 'conservative' policy of leaving different verb instances separate." ></td>
	<td class="line x" title="104:179	The desired effect within the data is that slightly different usages of a verb are classified in the same cluster, while remarkable differences result in different classifications." ></td>
	<td class="line x" title="105:179	The global measure of category utility, used by the CIAULA algorithm during classification, can now be defined." ></td>
	<td class="line x" title="106:179	Let v / (Ri:Catj) be the incoming instance, 56k be the set of classes, and let cu(v,k) be the category utility as defined in (5), the measure It, given by (7) It = vcu(v,k) + (1-v)Itk(v) v~ \[0,1\] expresses the global utility of the classification obtained by assigning the instance v to the class ~k." ></td>
	<td class="line x" title="107:179	(7) is a distance metrics among instances and classes." ></td>
	<td class="line x" title="108:179	2.3 The incremental clustering algorithm." ></td>
	<td class="line x" title="109:179	The algorithm for the incremental clustering of verb instances follows the approach used in COBWEB." ></td>
	<td class="line x" title="110:179	Given a new incoming instance I and a current valid classification {5~k}ke K, the system evaluates the utility of the new classification obtained by inserting I in each class." ></td>
	<td class="line x" title="111:179	The maximum utility value corresponds to the best predictive configuration of classes." ></td>
	<td class="line x" title="112:179	A further attempt is made to change the current configuration (introducing a new class, merging the two best candidate for the classification or splitting the best classes in the set of its son) to improve the predictivity." ></td>
	<td class="line x" title="113:179	The main difference with respect to COBWEB, due to the linguistic nature of the problem at hand, concern the procedure to evaluate the utility of a temporary classification and the MERGE operator, as it applies to singleton classes." ></td>
	<td class="line x" title="114:179	The description of the algorithm is given in Appendix 1." ></td>
	<td class="line x" title="115:179	Auxiliary procedures are omitted for brevity." ></td>
	<td class="line x" title="116:179	According to (7), the procedure G_UTILITY(x, I, ~, ~, v) evaluates the utility of the classification as a combination of the category utility and the inertial factor introduced in (6)." ></td>
	<td class="line x" title="117:179	Current values experimented for v are 0.90-0.75." ></td>
	<td class="line x" title="118:179	Figure 2 shows the difference between the standard MERGE operation, identical to that used in COBWEB, and the elementary MERGE between two singleton classes, as defined in CIAULA." ></td>
	<td class="line x" title="119:179	Fig." ></td>
	<td class="line x" title="120:179	2: Merge (a) vs. Elementary Merge (b) 3." ></td>
	<td class="line x" title="121:179	Experimental Results." ></td>
	<td class="line x" title="122:179	The algorithm has been experimented on two corpora of about 500,000 words each, a legal and a commercial domain, that exhibit very different linguistic styles and verb usages." ></td>
	<td class="line x" title="123:179	Only verbs for which at least 65 instances in each corpus have been considered, in order to further reduce parsing errors." ></td>
	<td class="line x" title="124:179	Notice however that the use of semantic tags in corpus parsing reduces considerably the noise, with respect to other corpus-based approaches." ></td>
	<td class="line x" title="125:179	75 In the first experiment, CIAULA classifies 3325 examples of 371 verbs, from the legal corpus." ></td>
	<td class="line x" title="126:179	In the second, it receives 1296 examples of 41 verbs from the commercial corpus." ></td>
	<td class="line x" title="127:179	Upon a careful analysis of the clusters obtained from each domain, the resulting classifications were judged quite expressive, and semantically biased from the target linguistic domains, a part from some noise due to wrong semantic interpretation of elementary syntactic structures Basili et al. , (1992a)." ></td>
	<td class="line x" title="128:179	However, the granularity of the description of the final taxonomy is too fine, to be usefully imported in the type hierarchy of a NLP system." ></td>
	<td class="line x" title="129:179	Furthermore, the order of presentation of the different examples strongly influences the final result 4." ></td>
	<td class="line x" title="130:179	In order to derive reliable results we must find some invariant with respect to the presentation order." ></td>
	<td class="line x" title="131:179	An additional requirement is to define some objective measure of the quality of the acquired classification, other than the personal judgement of the authors." ></td>
	<td class="line x" title="132:179	In this section we define a measure of the class informative power, able to capture the most relevant levels of the hierarchy." ></td>
	<td class="line x" title="133:179	The idea is to extract from the hierarchy the basic level classes, or classes that are repository of the most relevant lexical information about their members." ></td>
	<td class="line x" title="134:179	We define basic level classes of the classification those bringing most predictive and stable information with respect to the presentation order." ></td>
	<td class="line x" title="135:179	The notion of basic level classes has been introduced in Rosch (1978)." ></td>
	<td class="line x" title="136:179	She experimentally demonstrated that some conceptual categories are more meaningful than others as for the quantity of information they bring about their members." ></td>
	<td class="line x" title="137:179	Membership to such classes implies a grater number of attributes to be inherited by instances of the domain." ></td>
	<td class="line x" title="138:179	These classes appear at the intermediate levels of a taxonomy: for example within the vague notion of animal, classes such dog or cat 4 This is an inherent problem with concept formation algorithms seem to concentrate the major part of information about their members, with respect for example to the class of mammals Lakoff (1987)." ></td>
	<td class="line x" title="139:179	But what is a basic-level class for verbs?" ></td>
	<td class="line x" title="140:179	A formal definition for these more representative classes, able to guide the intuition of the linguist in the categorisation activity has been attempted, and will be discussed in the next section." ></td>
	<td class="line x" title="141:179	3.1." ></td>
	<td class="line x" title="142:179	Basic level categories of verbs." ></td>
	<td class="line x" title="143:179	The information conveyed by the derived clusters, c~=<c,\[x\]ij,V,S>, is in the distributions of the matrices \[x\]ij, and in the set V. Two examples may be helpful at distinguishing classes that are more selective, from other more vague clusters." ></td>
	<td class="line x" title="144:179	Let C~l be a singleton class, with WI=<I,\[xl\],VI,{O}>." ></td>
	<td class="line x" title="145:179	This clearly implies that \[xl\] is binary." ></td>
	<td class="line x" title="146:179	This class is highly typical, as it is strongly characterized by its only instance, but it has no generalization power." ></td>
	<td class="line x" title="147:179	Given, for example, a class qbl=<10,\[x2\],V2,S> for which the cardinality of a V2 is 10, and let \[x2\] be such that for each couple <ij> for which x2ij~0, it follows x2i'=I/10j . This class is scarcely typical but has a strong generalization power, as it clusters verbs that show no overlaps between the thematic roles they are represented by." ></td>
	<td class="line x" title="148:179	We can say that typicality is signaled by high values of roles-types probabilities (i.e. xij=prob((Ri:Catj) I c g) ), while the generalization power to of a class W=<c,\[x\]ij,V,S>, is related to the following quantity: (8) co = card(V)/c To quantify the typicality of a class cg=<c,\[x\]ij,V,S>, the following definitions are useful." ></td>
	<td class="line x" title="149:179	Given a threshold ae \[0,1\], the typicality of Cgis given by: 76 (9) xW = ~<i,j>e TW xij / card(T~ where T~,is the typicality set of ~, i.e. I<i,j> I xij >a}." ></td>
	<td class="line x" title="150:179	DEF (Basic-level verb category)." ></td>
	<td class="line x" title="151:179	Given two thresholds T, 8 e \[ 0,1 \], c~=<e,\[x\]ij,V,S> is a basic-level category for the related taxonomy iff: (10.1) co < T (generalization power) (10.2) 'cog > 8 (typicality) Like all the classes derived by the algorithm of section 2.3, each basic-level category ~=<c,\[x\]ij,V,S> determines two fuzzy membership values of the verb v included in V. The local membership of v to ~, I.t l~(v), is defined by: (11) gtlW(V)= #v/max# I <w, #w>~ V} The global membership of v to ~, \].t2~(v), is : (12) l.t2~(v) = #v / nv, where nv is the number of different instances of v in the learning set." ></td>
	<td class="line x" title="152:179	(11) depends on the contribution of v to the distribution of probabilities \[x\]i',j i.e. it measures the adherence of v to the prototype." ></td>
	<td class="line x" title="153:179	(12) determines how typical is the classification of v in ~, with respect to all the observations of v in the corpus." ></td>
	<td class="line x" title="154:179	Low values of the global membership are useful at identifying instances of v that are likely to be originated by parsing errors." ></td>
	<td class="line x" title="155:179	Given a classification,.qbf extended sets of linguistic instances, the definition (10) identifies all the basic-level classes." ></td>
	<td class="line x" title="156:179	Repeated experiment over the two corpora demonstrated that these classes are substantially invariant with respect to the presentation order of the instances." ></td>
	<td class="line x" title="157:179	The values y=0.6 and 8=0.75 have been empirically selected as producing the most stable results in both corpora." ></td>
	<td class="line x" title="158:179	4 Discussion The Appendix 2 shows all the basic level categories derived from a small learning set, named DPR633, that belongs to the legal corpus." ></td>
	<td class="line x" title="159:179	CIAULA receives in input 293 examples of 30 verbs." ></td>
	<td class="line x" title="160:179	The reason for showing DPR633 rather than an excerpt of the results derived from the full corpus is that there was no objective way to select among the over 300 basic level classes." ></td>
	<td class="line x" title="161:179	In Appendix 2, the relatively low values of gtl and I,t 2 are due to the exiguity of the example set, rather than to errors in parsing, as remarked in the previous section." ></td>
	<td class="line x" title="162:179	Of corse, the basic-level classes extracted from the larger corpora exhibit a more striking similarity among their members, indicated by highest values of global and local membership." ></td>
	<td class="line x" title="163:179	An example of cluster extracted from the whole legal corpus was shown in Figure 1." ></td>
	<td class="line x" title="164:179	The example shown in Appendix 2 is however 'good enough' to highlight some interesting property of our clustering method." ></td>
	<td class="line x" title="165:179	Each cluster has a semantic description, and the degree of local and global membership of verbs give an objective measure of the similarity among cluster members." ></td>
	<td class="line x" title="166:179	It is interesting to observe that the algorithm classifies in distinct clusters different verb usages." ></td>
	<td class="line x" title="167:179	For example, the cluster 4 and the cluster 6 classify two different usages of the verb indicare, e.g. indicare un'ammontare (to indicate an amount) and indicare un motive (to specify a motivation), where 'ammontare' is a type of AMOUNT(AM) and ' motive' is a type of ABSTRACT_ENTITY (AE)." ></td>
	<td class="line x" title="168:179	The two clusters 13 and 14 capture the physical and abstract use of eseguire, e.g. eseguire un'opera (to build a building(=REAL_ESTATE) yrs." ></td>
	<td class="line x" title="169:179	eseguire un pagamento (to make a payment(= AMOUNT,A CT) )." ></td>
	<td class="line x" title="170:179	77 The clusters 3 and 6 classify two uses of the verb tenere, i.e. tenere un registro (to keep a record(=DOCUMENT) yrs." ></td>
	<td class="line x" title="171:179	tenere un discorso (to hold a speech(=ABSTRACT_ENTITY))." ></td>
	<td class="line x" title="172:179	Many other (often domain-dependent) examples are reflected in the derived classification." ></td>
	<td class="line x" title="173:179	To sum up, we believe that CIAULA has several advantages over other clustering algonthrns presented in literature." ></td>
	<td class="line x" title="174:179	(1) The derived clusters have a semantic description, i.e. the predicted thematic roles of its members." ></td>
	<td class="line x" title="175:179	(2) The clustering algorithm incrementally assigns instances to classes, evaluating its choices on the basis of a formal cfitefium, the global utility." ></td>
	<td class="line x" title="176:179	(3) The defined measures of typicality and generalization power make it possible to select the basic-level classes of a hierarchy, i.e. those that are repository of most lexical information about their members." ></td>
	<td class="line x" title="177:179	These classes demonstrated substantially stable with respect to the order of presentation ofption, i.e. the predicted thematic roles of its members." ></td>
	<td class="line x" title="178:179	(4) It is possible to discriminate different usages of verbs, since verb instances are considered individually." ></td>
	<td class="line x" title="179:179	The hierarchy, as obtained by CIAULA, is not usable tout court by a NLP system, however class descriptions and basic-level categories appear to be greatly useful at addressing the intuition of the linguist." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W93-0113
Evaluation Techniques For Automatic Semantic Extraction: Comparing Syntactic And Window Based Approaches
Grefenstette, Gregory;"></td>
	<td class="line x" title="1:200	Evaluation Techniques for Automatic Semantic Extraction: Comparing Syntactic and Window Based Approaches Gregory Grefenstette Department of Computer Science University of Pittsburgh Pittsburgh, PA 15260 grefen@cs.pitt, edn Abstract As large on-line corpora become more prevalent, a number of attempts have been made to automatically extract thesaurus-like relations directly from text using knowledge poor methods." ></td>
	<td class="line x" title="2:200	In the absence of any specific application, comparing the results of these attempts is difficult." ></td>
	<td class="line x" title="3:200	Here we propose an evaluation method using gold standards, i.e., pre-existing hand-compiled resources, as a means of comparing extraction techniques." ></td>
	<td class="line x" title="4:200	Using this evaluation method, we compare two semantic extraction techniques which produce similar word lists, one using syntactic context of words, and the other using windows of heuristically tagged words." ></td>
	<td class="line x" title="5:200	The two techniques are very similar except that in one case selective natural language processing, a partial syntactic analysis, is performed." ></td>
	<td class="line x" title="6:200	On a 4 megabyte corpus, syntactic contexts produce significantly better results against the gold standards for the most characteristk: words in the corpus, while windows produce better results for rare words." ></td>
	<td class="line x" title="7:200	1 Introduction As more text becomes available electronically, it is tempting to imagine the development of automatic filters able to screen these tremendous flows of text extracting usefill bits of information." ></td>
	<td class="line x" title="8:200	In order to properly filter, it is useful to know when two words are similar in a corpus." ></td>
	<td class="line x" title="9:200	Knowing this would allcviate part of the term variability problem of natural language discussed in Furnas et al.(1987)." ></td>
	<td class="line x" title="11:200	Individuals will choose a variety of words to name the same object or operation, with little overlap between people's choices." ></td>
	<td class="line x" title="12:200	This variability in naming was cited as the principal reason for large numbers of missed citations in a large-scale evaluation of an information retrieval system \[Blair and Maron, 1985\]." ></td>
	<td class="line x" title="13:200	A proper filter must be able to access information in the text using any word of a set of similar words." ></td>
	<td class="line oc" title="14:200	A number of knowledge-rich \[Jacobs and Rau, 1990, Calzolari and Bindi, 1990, Mauldin, 1991\] and knowledge-poor \[Brown et al. , 1992, Hindle, 1990, Ruge, 1991, Grefenstette, 1992\] methods have been proposed for recognizing when words are similar." ></td>
	<td class="line o" title="15:200	The knowledge-rich approaches require either a conceptual dependency representation, or semantic tagging of the words, while the knowledge-poor approaches require no previously encoded semantic information, and depend on frequency of co-occurrence of word contexts to determine similarity." ></td>
	<td class="line x" title="16:200	Evaluations of results produced by the above systems are often been limited to visual verification by a human subject or left to the human reader." ></td>
	<td class="line x" title="17:200	In this paper, we propose gold standard evaluation techniques, allowing us to objectively evaluate and to compare two knowledge-poor approaches for extracting word similarity relations from large text corpora." ></td>
	<td class="line x" title="18:200	In order to evaluate the relations extracted, we measure the overlap of the results of each technique against existing hand-created 143 repositories of semantic information such as thesauri and dictionaries." ></td>
	<td class="line x" title="19:200	We describe below }low such resources can be used as evaluation tools, and apply them to two knowledge-poor approaches." ></td>
	<td class="line x" title="20:200	One of the tested semantic extraction approaches uses selective natural language processing, in this case the lexical-syntactic relations that can be extracted for each word in a corpus by robust parsers \[Hindle, 1983, Grefenstette, 1993\]." ></td>
	<td class="line x" title="21:200	The other approach uses a variation on a classic windowing technique around each word such as was used in \[Phillips, 1985\]." ></td>
	<td class="line x" title="22:200	Both techniques are applied to the same 4 megabyte corpus." ></td>
	<td class="line x" title="23:200	We evaluate the results of both techniques using our gold standard evaluations over thesauri and dictionaries and compare the results obtained by the syntactic based method to those obtained by the windowing method." ></td>
	<td class="line x" title="24:200	The syntax-based method provides a better overlap with the manually defined thesaurus classes for the 600 most frequently appearing words in the corpus, while for rare words the windowing method performs slightly better for rare words." ></td>
	<td class="line x" title="25:200	2 Gold Standards Evaluation 2.1 Thesauri Roger's Thesaurus is readily available via anonymous ftp 1." ></td>
	<td class="line x" title="26:200	In it are collected more than 30,000 unique words arranged in a shallow hierarchy under 1000 topic numbers such as Existence (Topic Number 1), Inexistence (2), Substantiality (3), Unsubstantiality (4),  , Rite (998), Canonicals (999), and Temple (1000)." ></td>
	<td class="line x" title="27:200	Although this is far from the total number of semantic axes of which one could think, it does provide a wide swath of commonly accepted associations of English language words." ></td>
	<td class="line x" title="28:200	We would expect that any system claiming to extract semantics from text should find some of the relations contained in this resource." ></td>
	<td class="line x" title="29:200	By transforming the online source of such a thesaurus, we use it as a gold standard by which to measure the results of different similarity extraction techniques." ></td>
	<td class="line x" title="30:200	This measurement is done by checking whether the 'similar words' discovered by each technique are placed under the same heading in this thesaurus." ></td>
	<td class="line x" title="31:200	In order to create this evaluation tool, we extracted a list consisting of all single-word entries from our thesauri with their topic number or numbers." ></td>
	<td class="line x" title="32:200	A portion of the extracted Roger list in Figure 1 shows that abatement appears under two topics: Nonincrease (36) and Discount (813)." ></td>
	<td class="line x" title="33:200	Abbe and abbess both belong under the same topic heading 996 (Clergy)." ></td>
	<td class="line x" title="34:200	The extracted Roger's list has 60,071 words (an average of 60 words for each of the 1000 topics)." ></td>
	<td class="line x" title="35:200	Of these 32,000 are unique (an average of two occurrence for each word)." ></td>
	<td class="line x" title="36:200	If we assume for simplicity that each word appears under exactly 2 of the 1000 topics, and that the words are uniformly distributed, the chance that two words wl and w2 occur under the same topic is Pnoaa = 2, (2/1000), since wl is under 2 topic headings and since the chance that w2 is under any specific topic heading is 2/1000." ></td>
	<td class="line x" title="37:200	The probability of finding two randomly chosen words together under the same heading, then, is 0.4%." ></td>
	<td class="line x" title="38:200	Our measurement of a similarity extraction technique using this gold standard is performed as follows." ></td>
	<td class="line x" title="39:200	1 For example, in March 1993 it was available via anonymous ftp at the Internet site world.std.com in the directory/obi/obi2/Gutenberg/etext91, as well at over 30 other sites." ></td>
	<td class="line x" title="40:200	144 Roget ' s entry Topic,, abaCement 36 abatement 813 abatis 717 abatjour 260 abattis 717 abattoir 361 abba 166 abbacy 995 abbatial 995 abbatical 995 abbatis 717 ~bbe 996 abbess 996 Macquarie entry subheading,o disesteem 036406 disesteem 063701 diseur 022701 disfavour 003901 disfavour 056601 disfavour 063701 disfeature 018212 disfeaturement 018201 disfigure 006804 disfigure 018212 disfigure 020103 disfigured 006803 disfigured 020102 .." ></td>
	<td class="line x" title="41:200	Figure 1: Samples from One Word Entries in Both Thesauri Given a corpus, use the similarity extraction method to derive similarity judgements between the words appearing in the corpus." ></td>
	<td class="line x" title="42:200	For each word, take the word appearing as most similar." ></td>
	<td class="line x" title="43:200	Examine the human compiled thesaurus to see if that pair of words appears under the same topic number." ></td>
	<td class="line x" title="44:200	If it does, count this as a hit." ></td>
	<td class="line x" title="45:200	This procedure was followed on the 4 megabyte corpus described below to test two semantic extraction techniques, one using syntactically derived contexts to judge similarity and one using window-based contexts." ></td>
	<td class="line x" title="46:200	The results of these evaluations are also given below." ></td>
	<td class="line x" title="47:200	2.2 Dictionary We also use an online dictionary as a gold standard following a slightly different procedure." ></td>
	<td class="line x" title="48:200	Many researchers have drawn on online dictionaries in attempts to do semantic discovery \[Sparck Jones, 1986, Vossen et aL, 1989, Wilks et ai., 1989\], whereas we use it here only as a tool for evaluating extraction techniques from unstructured text." ></td>
	<td class="line x" title="50:200	We have an online version of Webster's 7th available, and we use it in evaluating discovered similarity pairs." ></td>
	<td class="line x" title="51:200	This evaluation is based on the assumption that similar words will share some overlap in their dictionary definitions." ></td>
	<td class="line x" title="52:200	In order to determine overlap, each the entire literal definition is broken into a list of individual words." ></td>
	<td class="line x" title="53:200	This list of tokens contains all the words in the dictionary entry, including dictionary-related markings and abbreviations." ></td>
	<td class="line x" title="54:200	In order to clean this list of non-information-bearing words, we automatically removed any word or token 1." ></td>
	<td class="line x" title="55:200	of fewer than 4 characters, 2." ></td>
	<td class="line x" title="56:200	among the most common 50 words of 4 or more letters in the Brown corpus, 3." ></td>
	<td class="line x" title="57:200	among the most common 50 words of 4 or more letters appearing in the definitions of Webster's 7th, 145 ad-min-is-tra-tlon n. 1." ></td>
	<td class="line x" title="58:200	the act or process of administering 2." ></td>
	<td class="line x" title="59:200	performance of executive duties :: c<MANAGEMENT> 3." ></td>
	<td class="line x" title="60:200	the execution of public affairs as distinguished from policy making 4." ></td>
	<td class="line x" title="61:200	a) a body of persons who administer b) i<cap> :: a group constituting the political executive in a presidential government c) a governmental agency or board 5." ></td>
	<td class="line x" title="62:200	the term of office of an administrative officer, or body." ></td>
	<td class="line x" title="63:200	administer, administering, administrative, affairs, agency, board, constituting, distinguished, duties, execution, executive, government, governmental, making, management, office, officer, performance, persons, policy, political, presidential, public, term Figure 2: Webster definition of 'administration,' and resulting definition list after filtering through stoplist." ></td>
	<td class="line x" title="64:200	4." ></td>
	<td class="line x" title="65:200	listed as a preposition, quantifier, or determiner in our lexicon, 5." ></td>
	<td class="line x" title="66:200	of 4 or more letters from a common information retrieval stoplist, 6." ></td>
	<td class="line x" title="67:200	among the dictionary-related set: slang, attrib, kind, word, brit, heSS, lion, ment." ></td>
	<td class="line x" title="68:200	These conditions generated a list of 434 stopwords of 4 or more characters which are retracted from any dictionary definition, The remaining words are sorted into a list." ></td>
	<td class="line x" title="69:200	For example, the list produced for the definition of the word administration is given in Figure 2." ></td>
	<td class="line x" title="70:200	For simplicity no morphological analysis or any other modifications were performed on the tokens in these lists." ></td>
	<td class="line x" title="71:200	To compare two words using these lists, the intersection of each word's filtered definition list is performed." ></td>
	<td class="line x" title="72:200	For example, the intersection between the lists derived from the dictionary entries of diamond and ruby is (precious, stone); between right and freedom it is (acting, condition, political, power, privilege, right)." ></td>
	<td class="line x" title="73:200	In order to use these dictionaryderived lists as an evaluation tool, we perform the following experiment on a corpus." ></td>
	<td class="line x" title="74:200	Given a corpus, take the similarity pairs derived by the semantic extraction technique in order of decreasing frequency of the first term." ></td>
	<td class="line x" title="75:200	Perform the intersection of their respective two dictionary definitions as described above." ></td>
	<td class="line x" title="76:200	If this intersection contains two or more elements, count this as a hit." ></td>
	<td class="line x" title="77:200	This evahlation method was also performed on the results of both semantic extraction techniques applied to the corpus described in the next section." ></td>
	<td class="line x" title="78:200	3 Corpus The corpus used for the evaluating the two techniques was extracted from Grolier's Encyclopedia for other experiments in semantic extraction." ></td>
	<td class="line x" title="79:200	In order to generate a relatively coherent corpus, the corpus was created by extracting only those those sentences which contained the word Harvard or one of the thirty hyponyms found under the word institution in WordNet 2 \[Miller et al. , 1990\], viz." ></td>
	<td class="line x" title="80:200	institution, establishment, charity, religion,  , settlement This produced a corpus of 3.9 megabytes of text." ></td>
	<td class="line x" title="81:200	2 WordNet was not used itself as a gold standard since its hierarchy is very deep and its inherent notion of semantic classes is not as clearly defined as in Roger." ></td>
	<td class="line x" title="82:200	146 4 Semantic Extraction Techniques We will use these gold standard evaluation techniques to compare two techniques for extracting similarity lists from raw text." ></td>
	<td class="line x" title="83:200	The first technique \[Grefenstette, 1992\] extracts the syntactic context of each word throughout the corpus." ></td>
	<td class="line x" title="84:200	The corpus is divided into lexical units via a regular grammar, each lexical unit is assigned a list of context-free syntactic categories, and a normalized form." ></td>
	<td class="line x" title="85:200	Then a time linear stochastic grammar similar to the one described in \[de Marcken, 1990\] selects a most probable category for each word." ></td>
	<td class="line x" title="86:200	A syntactic analyzer described in \[Grefenstette, 1993\] chunks nouns and verb phrases and create relations within chunks and between chunks." ></td>
	<td class="line x" title="87:200	A noun's context becomes all the other adjectives, nouns, and verbs that enter into syntactic relations with it." ></td>
	<td class="line x" title="88:200	As a second technique, more similar to classical knowledge-poor techniques \[Phillips, 1985\] for judging word similarity, we do not perform syntactic disambiguation and analysis, but simply consider some window of words around a given word as forming the context of that word." ></td>
	<td class="line x" title="89:200	We suppose that we have a lexicon, which we do, that gives all the possible parts of speech for a word." ></td>
	<td class="line x" title="90:200	Each word in the corpus is looked up in this lexicon as in the first technique, in order to normalize the word and know its possible parts of speech \[Evans et al. , 1991\]." ></td>
	<td class="line x" title="91:200	A noun's context will be all the words that can be nouns, adjectives, or verbs within a certain window around the noun." ></td>
	<td class="line x" title="92:200	The window that was used was all nouns, adjectives, or verbs on either side of the noun within ten and within the same sentence." ></td>
	<td class="line x" title="93:200	In both cases we will compare nouns to each other, using their contexts." ></td>
	<td class="line x" title="94:200	In the first case, the disambiguator determines whether a given ambiguous word is a noun or not." ></td>
	<td class="line x" title="95:200	In the second case, we will simply decide that if a word can be at once a noun or verb, or a noun or adjective, that it is a noun." ></td>
	<td class="line x" title="96:200	This distinction between the two techniques of using a cursory syntactic analysis or not allows us to evaluate what is gained by the addition of this processing step." ></td>
	<td class="line x" title="97:200	Figure 3 below shows the types of contexts extracted by the selective syntactic technique and by the windowing technique for a sentence from the corpus." ></td>
	<td class="line x" title="98:200	Once context is extracted for each noun, the contexts are compared for similarity using a weighted Jaccard measure \[Grefenstette, 1993\]." ></td>
	<td class="line x" title="99:200	In order to reduce run time for the similarity comparison, only those nouns appearing more than 10 times in tile corpus were retained." ></td>
	<td class="line x" title="100:200	2661 unique nouns appear 10 times or more." ></td>
	<td class="line x" title="101:200	For the windowing technique 33,283 unique attributes with which to judge the words are extracted." ></td>
	<td class="line x" title="102:200	The similarity judging run takes 4 full days on a DEC 5000, compared to 3 and 1/2 hours for the similarity calculation using data from the syntactic technique, due to greatly increased number of attributes for each word." ></td>
	<td class="line x" title="103:200	For each noun, we retain the noun rated as most similar by the Jaccard similarity measure." ></td>
	<td class="line x" title="104:200	Figure 4 shows some examples of words found most similar by both techniques." ></td>
	<td class="line x" title="105:200	5 Results The first table, in Figure 5, compares the hits produced by the two techniques over Rogel's and over another online thesaurus, Macquarie's, that we had available in the Laboratory for Computational Linguistics at Carnegie Mellon University." ></td>
	<td class="line x" title="106:200	This table compares the results obtained from the windowing technique described in preceding paragraphs to those 147 With the arrival of Europeans in 1788, many Aboriginal societies, caught vithin the coils of expanding white settlement, were gradually destroyed . Contexts o/nouns extracted after syntactic analysis arrival european society catch-SUBJ settlement expand-DOBJ Some contex~ arrival aboriginal arrival coil arrival settlement european aboriginal european coil european settlement society european society coil society settlement society aboriginal society destroy-DOBJ coil catch-IOBJ settlement white extracted with 10 full-word window arrival society arrival expand arrival destroy european society european expand european destroy society aboriginal society expand society destroy arrival catch arrival uhite european arrival european catch european ehite society arrival society catch society white Figure 3: Comparison of Extracted Contexts using Syntactic and Non-Syntactic Techniques Corpus word formation work foundation government education religious university group establishment power creation state program law year center art form century member part Technique used Syntax creation school institution constitution training religion institution institution creation authority establishment law institution constitution century development architecture group year group center system religious system state public century institution member government government state government education public government city science life religious group government Figure 4: Sample of words found to be most similar, by the syntactic based technique, and by the window technique, to some frequently occurring words in the corpus 148 1-20 21-40 41-60 61-80 81-100 101-200 201-300 301-400 401-500 501-600 601-700 701-800 801-900 901-1000 1001-2000 2001-3000 25% 10% 25% 15% 15% 14% 21% 13% 15% 13% 8% 11% 17% 8% 10.2% 7.9% 50% 30% 30% 30% 40% 31% 29% 17% 16% 11% 11% 9% 6% 10% 4.9% 2.4% 15% 20% 30% 20% 15% 19% 20% 12% 12% 10% 11% 9% 13% 9% 11.8% 7.9% ROGET hits SYNTAX WINDOW 40% 55% 45% 40% 35% 55% 30% 45% 35% 35% 34% 34% 30% 29% 18% 25% 13% 24% 15% 19% 14% 20% 9% 17% 7%; 25% 9% 29% 5.3% 19.2% 2.1% 15.2% 50% 60% 70% 05% 55% 55% 34% 29% 26% 16% 14% 17% 12% 12% 6.9% 5.2% Figure 5: Windowing vs Syntactic Percentage of Hits for words from most frequent to least .c '3 & 2 results over corpus using Window vs Syntactic Contexts R.OGET MACQUARIE WEBSTER RANK WINDOW SYNTAX WINDOW SYNTAX 1-20 21-40 41-60 61-80 81-100 100 200 300 400 500 600 700 800 900 1000 >2000 Figure 6: Comparison of hit percentage in Roger's using simple 10-word windowing technique(clear) vs syntactic technique(black)." ></td>
	<td class="line x" title="107:200	The y-axis gives the percentage of hits for each group of frequency-ranked terms." ></td>
	<td class="line x" title="108:200	149 WEBSTER hits :\] '3 &  1-20 21-40 41-60 61-80 81-100 100 200 300 400 500 600 700 800 900 1000 >2000 Figure 7: Comparison of hits in Macquarie's using simple 10-word windowing technique(clear) vs syntactic technique(black)." ></td>
	<td class="line x" title="109:200	The y-axis gives the percentage of hits for each group of frequency-ranked terms." ></td>
	<td class="line x" title="110:200	'3 MACQUARIE hits %20 21-40 41'60 61-80 81-100 100 200 300 400 500 600 700 800 9(X) 1000 >2000 Figure 8: Comparison of hit percentage in Webster's using simple 10-word windowing technique (hashed bars) vs syntactic technique (solid bars)." ></td>
	<td class="line x" title="111:200	The y-axis gives the percentage of hits for each group of frequency-ranked terms." ></td>
	<td class="line x" title="112:200	150 Roger First 600 WINDOW HITS MISS SYNTACTIC HITS MISS 48 60 91 401 Macquarie SYNTACTIC First 600 HITS MISS I WINDOW HITS MISS 42 54 103 401 X 2=6.4 X 2= 15.3 p < .025 p < .005 Roger Last 600 WINDOW HITS MISS SYNTACTIC HITS MISS 2 28 14 556 Macquarie Last 600 WINDOW HITS MISS SYNTACTIC HITS MISS 4 40 14 542 X 2=4.6 X 2= 12.5 p < .05 p < .0005 Figure 9: X 2 results comparing Syntactic and windowing hits in man-made thesauri obtained from the syntactic technique, retaining only words for which similarity judgements were made by both techniques." ></td>
	<td class="line x" title="113:200	It can be seen in Figure 5 that simple technique of moving a window over a large corpus, counting co-occurrences of words, and eliminating empty words, provides a good hit ratio for frequently appearing words, since about 1 out of 5 of the 100 most frequent words are found similar to words appearing in the same heading in a hand-built thesaurus." ></td>
	<td class="line x" title="114:200	It can also be seen that the performance of the partial syntactic analysis based technique is better for the 600 most frequently appearing nouns, which may be considered as the characteristic vocabulary of the corpus." ></td>
	<td class="line x" title="115:200	The difference in performance between the two techniques is statistically significant (p i 0.05)." ></td>
	<td class="line x" title="116:200	The results of a X 2 test are given in Figure 9." ></td>
	<td class="line x" title="117:200	Figures 6 and 7 show the same results as histograms." ></td>
	<td class="line x" title="118:200	In these histograms it becomes more evident that the window co-occurrence techniques give more hits for less frequently occurring words, after the 600th most frequent word." ></td>
	<td class="line x" title="119:200	One reason for this can be seen by examining the 900th most frequent word, employment." ></td>
	<td class="line x" title="120:200	Since the windowing technique extracts up to 20 non-stopwords from either side, there are still 537 context words attached to this word, while the syntactically-based technique, which examines finer-grained contexts, only provides 32 attributes." ></td>
	<td class="line x" title="121:200	Figure 8 shows the results of applying the less focused dictionary gold standard experiment to the similarities obtained from the corpus by each technique." ></td>
	<td class="line x" title="122:200	For this experiment, both techniques provide about the same overlap for frequent words, and the same significantly stronger showing for the rare words for the windowing technique." ></td>
	<td class="line x" title="123:200	151 6 Conclusion In this paper wc presented a general method for comparing tile results of two similarity extraction techniques via gold standards." ></td>
	<td class="line x" title="124:200	'Fhis method can be used when no applicationspecific evaluation technique exists and provides a relative measurement of techniques against human-generated standard semantic resources." ></td>
	<td class="line x" title="125:200	We showed how these gold standards could be processed to produce a tool for measuring overlap between their contents and the results of a semantic extraction method." ></td>
	<td class="line x" title="126:200	We applied these gold standard evaluations to two different semantic extraction techniques passed over the same 4 megabyte corpus." ></td>
	<td class="line x" title="127:200	The syntactic-based technique produced greater overlap with the gold standards derived from thesauri for the characteristic vocabulary of the corpus, while the windowbased technique provided relatively better results for rare words." ></td>
	<td class="line x" title="128:200	This dichotomous result suggests that no one statistical technique is adapted to all ranges of frequencies of words from a corpus." ></td>
	<td class="line x" title="129:200	Everyday experience suggests that frequently occurring events can be more finely analyzed than rarer ones." ></td>
	<td class="line x" title="130:200	In the domain of corpus linguistics, the same reasoning can be applied." ></td>
	<td class="line x" title="131:200	For frequent words, finer grained context such as that provided by even rough syntactic analysis, is rich enough to judge similarity." ></td>
	<td class="line x" title="132:200	For less frequent words, reaping more though less exact information such as that given by windows of N words provides more information about each word." ></td>
	<td class="line x" title="133:200	For rare words, the context may have to be extended beyond a window, to the paragraph, or section, or entire document level, as Crouch (1990) did for rarely appearing words." ></td>
	<td class="line x" title="134:200	Acknowledgements." ></td>
	<td class="line x" title="135:200	This research was performed under the auspices of the Laboratory for Computational Linguistics (Carnegie Mellon University) directed by Professor David A. Evans." ></td>
	<td class="line x" title="136:200	References \[Blair and Maron, 1985\] D.C. Blair and M.E. Maron." ></td>
	<td class="line x" title="137:200	An evaluation of retrieval effectiveness." ></td>
	<td class="line x" title="138:200	Communications of the ACM, 28:289-299, 1985." ></td>
	<td class="line x" title="139:200	\[Brown et al. , 1992\] Peter F. Brown, Vincent J. Della Pietra, Petere V. deSouza, Jenifer C. Lai, and Robert L. Mercer." ></td>
	<td class="line x" title="140:200	Class-based n-gram models of natural language." ></td>
	<td class="line x" title="141:200	Computational Linguistics, 18(4):467-479, 1992." ></td>
	<td class="line x" title="142:200	\[Calzolari and Bindi, 1990\] Nicoletta Calzolari and Remo Bindi." ></td>
	<td class="line x" title="143:200	Acquisition of lexical information from a large textual italian corpus." ></td>
	<td class="line x" title="144:200	In Proceedings of the Thirteenth International Conference on Computational Linguistics, Helsinki, 1990." ></td>
	<td class="line x" title="145:200	\[Crouch, 1990\] C. J. Crouch." ></td>
	<td class="line x" title="146:200	An approach to the automatic construction of global thesauri." ></td>
	<td class="line x" title="147:200	Information Processing and Management, 26(5):629-640, 1990." ></td>
	<td class="line x" title="148:200	\[de Marcken, 1990\] Carl G. de Marcken." ></td>
	<td class="line x" title="149:200	Parsing the LOB corpus." ></td>
	<td class="line x" title="150:200	In 28th Annual Meeting of the Association for Computational Linguistics, pages 243-251, Pittsburgh, PA, June 6-9 1990." ></td>
	<td class="line x" title="151:200	ACL." ></td>
	<td class="line x" title="152:200	\[Evans et al. , 1991\] David A. Evans, Steve K. Handerson, Robert G. Lefferts, and Ira A. Monarch." ></td>
	<td class="line x" title="153:200	A summary of the CLARIT project." ></td>
	<td class="line x" title="154:200	Technical Report CMU-LCL-91-2, Laboratory for Computational Linguistics, Carnegie-Mellon University, November 1991." ></td>
	<td class="line x" title="155:200	\[Furnas et aL, 1987\] George W. Fumas, Tomas K. Landauer, L.M. Gomez, and Susan T. Dumais." ></td>
	<td class="line x" title="156:200	The vocabulary problem in human-system communication." ></td>
	<td class="line x" title="157:200	Communications of the ACM, 30(11):964-971, November 1987." ></td>
	<td class="line x" title="158:200	\[Grefenstette, 1992\] G. Grefenstette." ></td>
	<td class="line x" title="159:200	Sextant: Exploring unexplored contexts for semantic extraction from syntactic analysis." ></td>
	<td class="line x" title="160:200	In 30th Annual Meeting of the Association for Computational Linguistics, Newark, Delaware, 28 June 2 July 1992." ></td>
	<td class="line x" title="161:200	ACL'92." ></td>
	<td class="line x" title="162:200	\[Grefenstette, 1993\] Gregory Grefenstette." ></td>
	<td class="line x" title="163:200	Extracting semantics from raw text, implementation details." ></td>
	<td class="line x" title="164:200	Heuristics: the Journal of Knowledge Engineering, 1993." ></td>
	<td class="line x" title="165:200	To Appear in the Special Issue on Knowledge Extraction from Text, Available as TR CS92-05, from the University of Pittsburgh, CS Dept. \[Hindle, 1983\] Donald Hindle." ></td>
	<td class="line x" title="166:200	User manual for Fidditeh." ></td>
	<td class="line x" title="167:200	Technical Report 7590-142, Navall Research Laboratory, 1983." ></td>
	<td class="line oc" title="168:200	\[Hindle, 1990\] D. Hindle." ></td>
	<td class="line o" title="169:200	Noun classification from predicate-argument structures." ></td>
	<td class="line x" title="170:200	In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, pages 268-275, Pittsburgh, 1990." ></td>
	<td class="line x" title="171:200	ACL." ></td>
	<td class="line x" title="172:200	\[Jacobs and Rau, 1990\] Paul Jacobs and Lisa Rau." ></td>
	<td class="line x" title="173:200	SCISOR.: Extracting information from on-line news." ></td>
	<td class="line x" title="174:200	Communications of the ACM, 33(11):88-97, 1990." ></td>
	<td class="line x" title="175:200	\[Mauldin, 1991\] M. L. Mauldin." ></td>
	<td class="line x" title="176:200	Conceptual Information Retrieval: A case study in adaptive parsing." ></td>
	<td class="line x" title="177:200	Kluwer, Norwell, MA, 1991." ></td>
	<td class="line x" title="178:200	\[Miller et al. , 1990\] George A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. J. Miller." ></td>
	<td class="line x" title="179:200	Introduction to WordNet: An on-line lexical database." ></td>
	<td class="line x" title="180:200	Journal of Lexicography, 3(4):235-244, 1990." ></td>
	<td class="line x" title="181:200	\[Phillips, 1985\] Martin Phillips." ></td>
	<td class="line x" title="182:200	Aspects of Text Structure: An investigation of the lexical organization of text." ></td>
	<td class="line x" title="183:200	Elsevier, Amsterdam, 1985." ></td>
	<td class="line x" title="184:200	\[Ruge, 1991\] Gerda Ruge." ></td>
	<td class="line x" title="185:200	Experiments on linguistically based term associations." ></td>
	<td class="line x" title="186:200	In RIAO'91, pages 528-545, Barcelona, April 2-5 1991." ></td>
	<td class="line x" title="187:200	CID, Paris." ></td>
	<td class="line x" title="188:200	\[Sparck Jones, 1986\] Karen Sparck Jones." ></td>
	<td class="line x" title="189:200	Synonymy and Semantic Classification." ></td>
	<td class="line x" title="190:200	Edinburgh University Press, Edinburgh, 1986." ></td>
	<td class="line x" title="191:200	PhD thesis delivered by University of Cambridge in 1964." ></td>
	<td class="line x" title="192:200	\[Vossen et ai., 1989\] P. Vossen, W. Meijs, and M. den Broeder." ></td>
	<td class="line x" title="194:200	Meaning and structure in dictionary definitions." ></td>
	<td class="line x" title="195:200	In Bran Boguraev and Ted Briscoe, editors, Computational Lexicography for Natural Language Processing, pages 171-190." ></td>
	<td class="line x" title="196:200	Longman Group UK Limited, London, 1989." ></td>
	<td class="line x" title="197:200	\[Wilks et al. , 1989\] Yorick Wilks, D. Fass, C. Guo, J. McDonald, T. Plate, and B. Slator." ></td>
	<td class="line x" title="198:200	A tractable machine dictionary as a resource for computational semantics." ></td>
	<td class="line x" title="199:200	In Bran Boguraev and Ted Briscoe, editors, Computational Lexicography for Natural Language Processing, pages 193-228." ></td>
	<td class="line x" title="200:200	Longman Group UK Limited, London, 1989 ." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="A94-1011
Exploiting Sophisticated Representations For Document Retrieval
Finch, Steven;"></td>
	<td class="line x" title="1:156	Exploiting Sophisticated Representations for Document Retrieval Steven Finch Language Technology Group, HCRC University of Edinburgh S. Finch~ed." ></td>
	<td class="line x" title="2:156	ac." ></td>
	<td class="line x" title="3:156	uk Abstract The use of NLP techniques for document classification has not produced significant improvements in performance within the standard term weighting statistical assignment paradigm (Fagan 1987; Lewis, 1992bc; Buckley, 1993)." ></td>
	<td class="line x" title="4:156	This perplexing fact needs both an explanation and a solution if the power of recently developed NLP techniques are to be successfully applied in IR." ></td>
	<td class="line x" title="5:156	A novel method for adding linguistic annotation to corpora is presented which involves using a statistical POS tagger in conjunction with unsupervised structure finding methods to derive notions of 'noun group', 'verb group', and so on which is inherently extensible to more sophisticated annotation, and does not require a pre-tagged corpus to fit." ></td>
	<td class="line x" title="6:156	One of the distinguishing features of a more linguistically sophisticated representation of documents over a word set based representation of them is that linguistically sophisticated units are more frequently individually good predictors of document descriptors (keywords) than single words are." ></td>
	<td class="line x" title="7:156	This leads us to consider the assignment of descriptors from individual phrases rather than from the weighted sum of a word set representation." ></td>
	<td class="line x" title="8:156	We investigate how sets of individually high-precision rules can result in a low precision when used together, and develop some theory about these probably-correct rules." ></td>
	<td class="line x" title="9:156	We then proceed to repeat results which show that standard statistical models are not particularly suitable for exploiting linguistically sophisticated representations, and show that a statistically fitted rule-based model provides significantly improved performance for sophisticated representations." ></td>
	<td class="line x" title="10:156	It therefore shows that statistical systems can exploit sophisticated representations of documents, and lends some suppor t to the use of more linguistically 65 sophisticated representations for document classification." ></td>
	<td class="line x" title="11:156	This paper reports on work done for the LRE project SmTA, which is creating a PC based tool to be used in the technical abstracting industry." ></td>
	<td class="line x" title="12:156	1 Models and Representations First, I discuss the general paradigm for document classification, along with the conventions for notation used throughout this document." ></td>
	<td class="line x" title="13:156	We have a set of documents {zi}, and set of descriptors, {di}." ></td>
	<td class="line x" title="14:156	Each document is represented in one or more ways in some domain, usually as a set." ></td>
	<td class="line x" title="15:156	The elements of this set will be called diagnostic units or predicates, {wi} or {i)." ></td>
	<td class="line x" title="16:156	These diagnostic units might be the words comprising the document, or more linguistically sophisticated annotations of parts of the document." ></td>
	<td class="line x" title="17:156	They may, in general, be predicates over documents." ></td>
	<td class="line x" title="18:156	The representation of the document by diagnostic units will be called the DU-representation of the document, and for a document z, will be denoted T~(x)." ></td>
	<td class="line x" title="19:156	From the DU representation of the documents, one or more descriptors are assigned to each of them by some automatic system." ></td>
	<td class="line x" title="20:156	This paradigm of description is applicable to much of the work on text classification (and other fields in information retrieval)." ></td>
	<td class="line x" title="21:156	This paper assesses the utility of using linguistically sophisticated diagnostic units together with a slightly non-standard statistical assignment model in order to assign descriptors to a document." ></td>
	<td class="line x" title="22:156	2 The Corpus This paper reports work undertaken for the LRE project SISTA (Semi-automatic Indexing System for Technical Abstracts)." ></td>
	<td class="line x" title="23:156	This section briefly describes one of the corpora used by this project." ></td>
	<td class="line x" title="24:156	The RAPRA corpus comprises some 212,000 technical abstracts pertaining to research and commercial exploitation in the rubber and plastics industry." ></td>
	<td class="line x" title="25:156	To each abstract, an average of 15 descriptors selected from a thesaurus of some 10,000 descriptors is assigned to each article." ></td>
	<td class="line x" title="26:156	The frequency of assignment of descriptors varies roughly in the same way as the frequency of word use varies (the frequencies of descriptor tokens (very) approximately satisfies the Zipf-Mandelbrot law)." ></td>
	<td class="line x" title="27:156	Descriptors are assigned by expert indexers from the entire article and expert domain knowledge, not just from the abstract, so it is unlikely that any automatic system which analyses only the abstracts can assign all the descriptors which are manually assigned to the abstract." ></td>
	<td class="line x" title="28:156	We show a fairly typical example below." ></td>
	<td class="line x" title="29:156	It is clear that many of these descriptors must have been assigned from the main text of the article, and not from the abstract alone." ></td>
	<td class="line x" title="30:156	Moreover, this is common practice in the technical abstract indexing industry, so it seems unlikely that the situation will be better for other corpora." ></td>
	<td class="line x" title="31:156	Nevertheless, we can hope to follow a strategy of assigning descriptors when there is enough information to do so." ></td>
	<td class="line x" title="32:156	Macromolecular Deformation Model to Estimate Viscoelastic Flow Effects in Polymer Melts The elastic deformation of polymer macromolecules in a shear field is used as the basis for quantitative predictions of viscoelastic flow effects in a polymer melt." ></td>
	<td class="line x" title="33:156	NonNewtonian viscosity, capillary end correction factor, maximum die swell, and die swell profile of a polymer melt arc predicted by the model." ></td>
	<td class="line x" title="34:156	All these effects can be reduced to generic master curves, which are independent of polymer type." ></td>
	<td class="line x" title="35:156	Macromolecular deformation also influences the brittle failure strength of a processed polymer glass." ></td>
	<td class="line x" title="36:156	The model gives simple and accurate estimates of practically important processing effects, and uses fitting parameters with the clear physical identity of viscoelastic constants, which follow well established trends with respect to changes in polymcr composition or processing conditions." ></td>
	<td class="line x" title="37:156	12 refs." ></td>
	<td class="line x" title="38:156	Original assignment: BRITTLE FAILURE; COMPANY; DATA; DIE SWELL; ELASTIC DEFORMATION; EQUATION; GRAPH; MACROMOLECULE; MELT FLOW; MODEL; NONNEWTONIAN; PLASTIC; POLYMERIC GLASS; PROCESSING; RHEOLOGICAL PROPERTIES; RHEOLOGY; TECHNICAL; THEORY; THERMOPLASTIC; VISCOELASTIC PROPERTIES; VISCOELASTICITY; VISCOSITY 3 Models Two classes of models for assessing descriptor appropriateness were used." ></td>
	<td class="line x" title="39:156	One class comprises variants of Salton's term-weighting models, and one is more allied to fuzzy or default logic in so much as it assigns descriptors due to the presence of certain diagnostic units." ></td>
	<td class="line x" title="40:156	What is interesting for us is that term weighting models do not seem able to easily exploit the additional information provided by a more sophisticated representation of a document, while an alternative statistical single term model can." ></td>
	<td class="line x" title="41:156	3.1 Term weighting models The standard term weighting model is defined by chosing a set of parameters {c~ij } (one for each worddescriptor pair) and {fli} (one for each desc,'iptor) so that a likelihood or appropriateness function, /2, can be defined by C(alw) = (1) wEW This has been widely used, and is provably equivalent to a large class of probabilistic models (e.g. Van Risjbergen, 1979) which make various assumptions about the independence between descriptors and diagnostic units (Fuhr & Buckley, 1993)." ></td>
	<td class="line x" title="42:156	Various strategies for estimating the parameters for this model have been proposed (e.g. Salton & Yang, 1973, Buckley 1993, Fuhr & Buekley, 1993)." ></td>
	<td class="line x" title="43:156	Some of these concentrate on the need for re-estimating weights according to relevance feedback information, while some make use of various functions of term frequency, document frequency, maximum withindocument frequency, and various other measurements of corpora." ></td>
	<td class="line x" title="44:156	Nevertheless, the problem of estimating the huge number of parameters needed for such a model is statistically problematic, and as Buckley (1993) points out, the choice of weights has a large influence on the effectiveness of any model for classification or for retrieval." ></td>
	<td class="line x" title="45:156	There are so many variations on the theme of term weighting models that it is impossible to try them all in one experiment, so this paper uses a variation of a model used by Lewis (1992e) in which he re-.ports the results of some experiments using phrases In a term weighting model (which has a probabilistic interpretation)." ></td>
	<td class="line x" title="46:156	Several term weighting models have been tried, but they all evaluate within 5 points of each other on both precision and recall (when suitably tweaked)." ></td>
	<td class="line x" title="47:156	The model eventually chosen for the tests reported here was a smoothed logistic model which gave the best results of all the probabilistically inspired term weighting models considered." ></td>
	<td class="line x" title="48:156	3.2 Single term model In contrast to making assumptions of independence about the relationship between diagnostic units and words, the next model utilises only those diagnostic units which strongly predict descriptors (i.e. have frequently been associated with descriptors) without making assumptions about the independence of diagnostic units given descriptors." ></td>
	<td class="line x" title="49:156	We shall investigate this class of models using probability theory." ></td>
	<td class="line x" title="50:156	The main problem with using probability theory for problems in document classification is that while it might be relatively easy to estimate probabilities such as P(dlw ) for some diagnostic unit w and some descriptor d, it is not possible 66 to infer much about P(dIw~), where  is some additional information (e.g. the other DUs which represent the document), since these probabilities have not been estimated, and would take a far larger corpus to reliably estimate in any case." ></td>
	<td class="line x" title="51:156	The situation gets exponentially worse as the information we have about the document increases." ></td>
	<td class="line x" title="52:156	The exception to this rule is when P(dlw ) is close to 1, in which case it is very unlikely that additional information changes its value much." ></td>
	<td class="line x" title="53:156	This fact is further investigated now." ></td>
	<td class="line x" title="54:156	The strategy explored here is to concentrate on finding 'sure-fire' indicators of descriptors, in a somewhat similar manner to how Carnegie's TCS works, by exploiting the fact that with a preclassified training corpus we can identify sure-fire indicators empirically and 'trawl' in a large set of informative diagnostic units for those which identify descriptors with high precision." ></td>
	<td class="line x" title="55:156	The basis of the model is the following: We consider a likelihood function, Z: defined by: Z(dlw) = gd~ N~ That is, the number of articles in the training corpus that d was observed to occur with w divided by the number of articles in which w occurred in the training corpus." ></td>
	<td class="line x" title="56:156	This is an empirical estimate of the conditional probability, P(d\[w)." ></td>
	<td class="line x" title="57:156	We shall assume (for simplicity's sake) that we have a large enough corpus do reliably estimate these probabilities." ></td>
	<td class="line x" title="58:156	The strategy for descriptor assignment we are investigating is to assign a descriptor d if and only if one of a set of predicates over representations of documents is true." ></td>
	<td class="line x" title="59:156	We define the rule (x) ~ d to be Probably Correct do degree  if and only if P(dl ) > 1-." ></td>
	<td class="line x" title="60:156	We wish to keep the precision resulting from using this strategy high while increasing the number of rules to improve recall." ></td>
	<td class="line x" title="61:156	The predicates  we shall consider for this paper will be very simple (they will typically be true iff w E T~(x) for some diagnostic unit w), but in principle, they could be arbitrarily complex (as they are in Carnegie's TCS)." ></td>
	<td class="line x" title="62:156	The primary question of concern is whether the ensemble of rules {i --~ d} retains precision or not." ></td>
	<td class="line x" title="63:156	Unfortunately, the answer to this question is that this is not necessarily the case unless we put some constraints on the predicates." ></td>
	<td class="line x" title="64:156	Proposition 1 Let  be a set of predicates with the property that for some fixed descriptor d,  E  ---+ P(d\] ) > 1 ." ></td>
	<td class="line x" title="65:156	That is each of the rules i --+ d is probably correct to degree c. The expected precision of the rule (V i) --* d is _ ne where n is the cardinality, \](I)\]." ></td>
	<td class="line x" title="66:156	at least 1 Proof: \[Straight-forward and omitted\] This proposition asserts that one cannot be guaranteed to be able to keep adding diagnostic units to improve recall without hurting precision, unless the 67 quality of those diagnostic units is also improved (i.e. c is decreased in proportion to the number of DUs which are considered)." ></td>
	<td class="line x" title="67:156	This is unfortunate, but nevertheless the question of how much adding diagnostic units to help recall will hurt precision is an entirely empirical matter dependent on the true nature of P; this proposition is a worst case, and gives us reason to be careful." ></td>
	<td class="line x" title="68:156	Performance will be expected to be poorest if there are many rules which correspond to the same true positives, but different sets of false positives." ></td>
	<td class="line x" title="69:156	If the predicates are disjoint, for example, then the precision of a disjunction is at least as great as the precision of applying any single rule." ></td>
	<td class="line x" title="70:156	So if we design our predicates so that they are disjoint, then we retain precision while increasing recall." ></td>
	<td class="line x" title="71:156	In practice, this is infeasible, but it is feasible to look more carefully at frequently co-occurring predicates, since these will be most likely to reduce precision." ></td>
	<td class="line x" title="72:156	1 The main moral we can draw from the above two propositions is that we must be careful about the case where diagnostic units are highly correlated." ></td>
	<td class="line x" title="73:156	One situation which is relatively frequent as the sophistication of representation increases is that some diagnostic units always co-occur with others." ></td>
	<td class="line x" title="74:156	For example, if the document were represented by sequences of words, then the sequence 'olefin polymerisation' always occurs whenever the sequence 'high temperature olefin polymerisation' occurs." ></td>
	<td class="line x" title="75:156	In this case, it might be thought to pay to look only at the most specific diagnostic units since we have if wl --* w2, then P(Z\]wlw2C) = P(XIwlC) for any distribution P whatsoever (here, C represents any other contextual information we have, for example the other diagnostic units representing the document)." ></td>
	<td class="line x" title="76:156	However, if wl is significantly less frequent than w2 estimation errors of P(d\[wl) will be larger for P(dlw2) for any descriptor d, so there may not be a significant advantage." ></td>
	<td class="line x" title="77:156	However, it does give us a 1 One classic example is the case of the 'New Hampshire Yankee Power Plant'." ></td>
	<td class="line x" title="78:156	In a collection of New York Times articles studied by Jacobs & Rau (1990), the word 'Yankee' was found to predict NUCLEAR POWER because of the frequent occurrence of articles about this plant." ></td>
	<td class="line x" title="79:156	However, 'Yankee' on its own without the other words in this phrase is a good predictor of articles about the New York Yankees, a baseball team." ></td>
	<td class="line x" title="80:156	If highly mutually informative words 'are combined into conjunctive predicates (e.g. 'Yankee' E x & 'Plant' E x), and a document is represented by its most specific predicates only, then when 'Yankee' appears alone, it will be a good predictor of the descriptor SPORT." ></td>
	<td class="line x" title="81:156	This example can also show that the bound described above is tight." ></td>
	<td class="line x" title="82:156	Imagine (suspending belief) that each of the five words in the phrase have the same number of occurrences, i, in the document collection without NUCLEAR POWER where they never occur together palrwise, and always occur all together in j true positives of the descriptor." ></td>
	<td class="line x" title="83:156	Then the precision of assigning NUCLEAR POWER if any one of them appears in a document is j+51-'-2--, and since e in this case is i+--~, the bound follows (for the case n = 5) with a little algebra." ></td>
	<td class="line x" title="84:156	theoretical reason to believe that representing a document by its set of most specific predicates is worth investigating, and this shall be investigated below." ></td>
	<td class="line x" title="85:156	If one considers a calculus similar to the one described here, but allows ~ to limit to 0, then a weak default logic ensues which has been studied by Adams (1975), and further investigated by Pearl (1988)." ></td>
	<td class="line x" title="86:156	4 Adding linguistic description The simplest way of representing a document is as a set or multi set of words." ></td>
	<td class="line x" title="87:156	Many people (eg." ></td>
	<td class="line x" title="88:156	Lewis 1992bc; Jacobs & Rau 1990) have suggested that a more linguistically sophisticated representation of a document might be more effective for the purposes of statistical keyword assignment." ></td>
	<td class="line x" title="89:156	Unfortunately, attempts to do this have not been found to reliably improve performance as measured by recall and precision for the task of document classification." ></td>
	<td class="line x" title="90:156	I shall present evidence that a more sophisticated representation makes better predictions from the Single Term model defined above than it does from standard term weighting models." ></td>
	<td class="line x" title="91:156	4.1 Linguistic description The simplest form of linguistic description of the content of a machine-readable document is in the form of a sequence (or a set) of words." ></td>
	<td class="line x" title="92:156	More sophisticated linguistic information comes in several forms, all of which may need to be represented if performance in an automatic categorisation experiment is to be improved." ></td>
	<td class="line oc" title="93:156	Typical examples of linguistically sophisticated annotation include tagging words with their syntactic category (although this has not been found to be effective for 1R), lemma of the word (e.g. 'corpus' for 'corpora'), phrasal information (e.g. identifying noun groups and phrases (Lewis 1992c, Church 1988)), and subject-predicate identification (e.g. Hindle 1990)." ></td>
	<td class="line x" title="94:156	For the RAPRA corpus, we currently identify noun groups and adjective groups." ></td>
	<td class="line x" title="95:156	This is achieved in a manner similar to Church's (1988) PARTS algorithm used by Lewis (1992bc), in the sense that its main properties are robustness and corpus sensitivity." ></td>
	<td class="line x" title="96:156	All that is important for this paper is that the technique identifies various groupings of words (for example, noun-groups, adjective groups, and so on) with a high level of accuracy." ></td>
	<td class="line x" title="97:156	Major parts of the technique are described in detail in Finch, 1993." ></td>
	<td class="line x" title="98:156	As an example, this is some of the linguistic markup which represents the title of the sample document shown earlier." ></td>
	<td class="line x" title="99:156	 macromolecular deformation (NG); macromolecular deformation model (NG); deformation (NG); deformation model (NG); model (NG); viscoelastic flow (NG); viscoelastic flow effects (NGS); flow (NG); flow effects (NGS); effects (NGS); polymer (NG); polymer melts (NGS); melts (NGS) It is clear that the markup is far from sophisticated, and is very much a small variation on a simple sequence-based representation." ></td>
	<td class="line x" title="100:156	Nevertheless, it is fairly accurate in so much as well over 90% of what are claimed to be noun groups can be interpreted as such." ></td>
	<td class="line x" title="101:156	One very useful by-product of using a linguistically based representation is that Il~ can help in linguistic tasks such as terminological collection." ></td>
	<td class="line x" title="102:156	I shall present some examples of diagnostic units which are highly associated with descriptors later." ></td>
	<td class="line x" title="103:156	5 Predicting from sophisticated representations In what follows, we shall compare the relative performance of a term weighting model with the single term model as we vary the sophistication of representation." ></td>
	<td class="line x" title="104:156	Proportional assignmen~ (Lewis 1992b) is used to assign the descriptors from statistical measurements of their appropriateness." ></td>
	<td class="line x" title="105:156	This method ensures that roughly the same number of assignments of particular descriptors are made as are actually made in the test corpus." ></td>
	<td class="line x" title="106:156	The strategy is simply to assign descriptor d to the N documents which score highest for this descriptor, where N is chosen in proportion to the occurrence of d in the training corpus." ></td>
	<td class="line x" title="107:156	For term weighting models, the score is simply the combined weight of the document; for the single term model, the score is sup~eT(~ ) P(dlw)." ></td>
	<td class="line x" title="108:156	The Rule Based assignment strategy applies only to the single term model and the rule w --~ d is included just in case P(dlw )> 1-." ></td>
	<td class="line x" title="109:156	Figure 1 shows a few of the rules." ></td>
	<td class="line x" title="110:156	All of these entries share the property that P(d\]w) > 0.8." ></td>
	<td class="line x" title="111:156	They were selected at random from the 85,500 associations which were found." ></td>
	<td class="line x" title="112:156	5.1 Representations and models Five paradigms of representation of documents will be compared, and two term appropriateness models will be compared." ></td>
	<td class="line x" title="113:156	This gives us ten combinations." ></td>
	<td class="line x" title="114:156	The first representation paradigm is a baseline one: represent documents as the set of the words contained in them." ></td>
	<td class="line x" title="115:156	The second paradigm is to represent documents according to word sequences, and the third is to apply a noun-group and adjectivegroup recogniser." ></td>
	<td class="line x" title="116:156	The fourth and fifth representation modes consider representing documents by only their most specific diagnostic units." ></td>
	<td class="line x" title="117:156	For example, if the sequence 'thermoplastic elastomer compounds' 68 polymer materials Research/NG; EEC legislation/NGS; venture partners/NGS; Bergen op/NP sheet lines/NGS railroad/NG injection moulding fa~:ility/NG PHENOLPHTHALEIN/NP unsaturated polyester composites/NGS thermoplastic elastomer compounds/NGS properties features/NGS fiber Glass/NG comparative performance/NG automotive hose/NGS Bitruder/NP worldwide tyre/NG Victrex polyethersulphone/NP PS melts/NGS viscoelastic characteristics/NGS plastics waste/NG lattice relaxation/NG fatigue crack propagation/NG unidirectional composites/NGS Flory Huggins interaction/NG DATA '-* LEGISLATION --* JOINT VENTURE --* PLASTIC ---* COMPANY --* COMPANY --* PLASTIC --* DATA --~ THERMOSET ---* RUBBER ---* PLASTIC --* GLASS FIBRE REINFORCED PLASTIC --* DATA --, RUBBER --, EXTRUDER COMPANIES -'~ COMPANIES ---+ PLASTIC ---* VISCOELASTIC PROPERTIES RECYCLING NUCLEAR MAGNETIC RESONANCE '--+ MECHANICAL PROPERTIES REINFORCED PLASTIC TECHNICAL Figure 1: This figure shows some probably correct rules for the RAPRA corpus." ></td>
	<td class="line x" title="118:156	In all, there are over 85,000 such rules." ></td>
	<td class="line x" title="119:156	appeared in the abstract, then ordinarily this would include the sequence 'elastomer compounds', which would be included in the representation." ></td>
	<td class="line x" title="120:156	The results of section 3.2 might encourage us to believe that representing a document by only its most specific diagnostic units will improve performance (or, at least, precision)." ></td>
	<td class="line x" title="121:156	Consequently, a sequence of words is defined to be most specific if (a) it is a diagnostic unit and (b) it is not properly contained in a token of any other diagnostic unit present in the document." ></td>
	<td class="line x" title="122:156	2 The noun-groups are found by performing a simple parse of the documents as described above, and identifying likely noun groups of length 3 or less." ></td>
	<td class="line x" title="123:156	The contingency table of diagnostic units verses manually assigned descriptors on a training corpus of 200,000 documents was collected, and this was used as the basis for two term appropriateness models." ></td>
	<td class="line x" title="124:156	Probabilities were estimated by adding a constant (usually 0.02 was found fairly optimal) to each cell, and directly estimating from these slightly adjusted counts." ></td>
	<td class="line x" title="125:156	The 50,000 most frequent diagnostic unit types were chosen, and terms which appeared in more than 10% of documents were discarded." ></td>
	<td class="line x" title="126:156	2If 'elastomer compounds' appeared separately in the document from 'thermoplastic elastomer compounds', then both of these sequences would be represented in the experiments reported here." ></td>
	<td class="line x" title="127:156	6 Results The results of the experiments on the RAPRA corpus are presented below." ></td>
	<td class="line x" title="128:156	3 Despite the peculiarities of the corpus, the message is clear." ></td>
	<td class="line x" title="129:156	The result that the standard model fares no better on word sequence sets than on word sets is repeated, and it is clear that the Single Term model fares much better than the Logit model on this data set." ></td>
	<td class="line x" title="130:156	However, what is most interesting is that the Single Term models fares significantly better on the more sophisticated sequence based representations of the document than on the simpler word based representation." ></td>
	<td class="line x" title="131:156	There is, however, no significant advantage identified by parsing the corpus into noun-groups over simply considering all word sequences." ></td>
	<td class="line x" title="132:156	The recall scores for the rule-based tagging strategy show that the improved performance of the sequence based representations can be explained by 3All recall and precision scores are microaveraged (Lewis 1992c); they are the expected probability of assigning or recalling correctly per tagging decision." ></td>
	<td class="line x" title="133:156	The training set was a set of 200,000 abstracts, and the separate test set had 10,000 abstracts." ></td>
	<td class="line x" title="134:156	The experiments looked at only the 520 most common descriptors." ></td>
	<td class="line x" title="135:156	In the table, TW means that a term-weighting model was used, while ST means that the single term model was used." ></td>
	<td class="line x" title="136:156	'Word' means the representation was a wordset, 'Seq', the set of all sequences, and 'NG' the set of groups derived from the grammar." ></td>
	<td class="line x" title="137:156	For the sequence representations, either all the possible sequences or groups were used (denoted by 'all'), or just the most specific ones were used (denoted by 'spec')." ></td>
	<td class="line x" title="138:156	69 the presence of many more 'good' descriptor indicators." ></td>
	<td class="line x" title="139:156	Assignment Prop." ></td>
	<td class="line x" title="140:156	Prop." ></td>
	<td class="line x" title="141:156	Prop." ></td>
	<td class="line x" title="142:156	Prop." ></td>
	<td class="line x" title="143:156	Prop." ></td>
	<td class="line x" title="144:156	Prop." ></td>
	<td class="line x" title="145:156	Prop." ></td>
	<td class="line x" title="146:156	Prop." ></td>
	<td class="line x" title="147:156	Prop." ></td>
	<td class="line x" title="148:156	Rule  = .2 Rule  = .2 Rule  = .2 Rule  = .2 Rule  = .2 Model TW TW TW TW TW ST ST ST ST ST ST ST ST ST Repn Prec Rec Word 33% 32% Seq all 32% 34% Seq spec 33% 34% NG all 31% 36% NG spec 32% 32% Word 54% 48% Seq all 57% 55% Seq spec 55% 55% NG 56% 60% Word 83% 7% Seq all 77% 42% Seq spec 80% 40% NG all 82% 42% NG spec 84% 37% 7 Conclusion The significant theoretical result is that as the sophistication of the representation of abstracts is increased, the performance of the single term model improves, while the performance of the term weighting models does not improve significantly." ></td>
	<td class="line x" title="149:156	This has been a fairly universal experience among researchers working within the term weighting classification paradigm." ></td>
	<td class="line x" title="150:156	Although there is a very marginally significant improvement from using linguistically sophisticated representations over simple sequence representations if all of the sequences are represented, this largely (though not entirely) disappears when only most specific sequences are considered, so it might be a result of the effects discussed in section 3.2." ></td>
	<td class="line x" title="151:156	The rule based assignment strategy exploits the Single Term model's estimates, and also performs much better on word sequence representations than on word set representations." ></td>
	<td class="line x" title="152:156	This assignment strategy is promising because it can exploit more sophisticated representations well, has a sound theory behind it, and will assign descriptors only where it has enough information to do so." ></td>
	<td class="line x" title="153:156	Some of the descriptors in the RAPRA corpus, for example, are only ever assigned from the entire article from which the abstract is taken, so no assignment strategy will ever do well on these." ></td>
	<td class="line x" title="154:156	On the other hand this model also shows promise that IR techniques might be applied to help infer linguistic resources such as term banks from large classified corpora." ></td>
	<td class="line x" title="155:156	The next stage is to add more sophisticated linguistic annotation to corpora, and to trawl for rules in boolean combinations of descriptors, thus addressing the results of section 3.2." ></td>
	<td class="line x" title="156:156	In this way this work can be considered similar in spirit to that undertaken by Apte et al (1994), but differs in the forms of representation which are being considered for documents." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C94-1074
A 'Not-So-Shallow' Parser For Collocational Analysis
Basili, Roberto;Pazienza, Maria Teresa;Velardi, Paola;"></td>
	<td class="line x" title="1:270	A 'not-so-shallow' parser for collocational analysis Basili R.(*), M.T. Pazienza (*), P. Velardi () (*) Dipartimento Ingegneria Elettronica, Universit,~ di Roma,Tor Vergata \[rbas, pazienza}@tovvxl, ccd.utow:m, it: () Istituto di Informatica, Universitk di Ancona vela@anvax2, cinec~." ></td>
	<td class="line x" title="2:270	J_t Abstract." ></td>
	<td class="line x" title="3:270	Collocational analysis is the basis of many studies on lexical acquisition." ></td>
	<td class="line x" title="4:270	Collocations are extracted from corpora using more or less shallow processing techniques, that span from purely statistical methods to partial parsers." ></td>
	<td class="line x" title="5:270	Our point is that, despite one of tile objectives of collocational analysis is to acquire high-coverage lexical data at low human cost, this is often not the case." ></td>
	<td class="line x" title="6:270	Human work is in fact required for the initial training of most statistically based methods." ></td>
	<td class="line x" title="7:270	A more serious problem is that shallow processing techniques produce a noise that is not acceptable for a fully automated system." ></td>
	<td class="line x" title="8:270	We propose in this paper a not-so-shallow parsing strategy that reliably detects binary and ternary relations among words." ></td>
	<td class="line x" title="9:270	We show that adding more syntactic knowledge to the." ></td>
	<td class="line x" title="10:270	recipe significantly improves the recall and precision of tile detected collocations, regardless of any subsequent statistical computation, while still nleeting the cornputational requi,'ements of corpus parsers." ></td>
	<td class="line x" title="11:270	1." ></td>
	<td class="line x" title="12:270	Week methods for the analysis of collocations In the past few years there has been a flourishing of interest in the study of word collocations." ></td>
	<td class="line x" title="13:270	A common method to extract collocations is using windowing techniques for the extraction of word associations." ></td>
	<td class="line x" title="14:270	In (Zernik 1990; Calzolari and Bindi 1990; Smadja 1989; Church and Hanks 1990) associations are detected in a 5 window." ></td>
	<td class="line x" title="15:270	A wider window ( tO0 words) is used in (Gale et al. 1992)." ></td>
	<td class="line x" title="16:270	Windowing techniques are also used in (Jelinek et al, 1990), where it is proposed a trigram model to automatically derive, and refine, context-free rules of the grammar (Fujisaki et al, 1991)." ></td>
	<td class="line x" title="17:270	Windowing techniques weekly model tile locality of language as well as other lexical information." ></td>
	<td class="line x" title="18:270	The reliability of the acquired information depends upon tile window size." ></td>
	<td class="line x" title="19:270	A small window fails to detect many important word relations, while enlarging tile window affects the tractability of tile statistical model (especially for markovian n-gram models)." ></td>
	<td class="line x" title="20:270	Finally, window-based collocations provide limited information when dealing with a variety of lexical phenomena." ></td>
	<td class="line x" title="21:270	For example, the simple observation of word cooccurrences is not a suitable marker of lexical subcategorization." ></td>
	<td class="line x" title="22:270	Another popular al;proach is usinl,r a partial parser, augmented with statistical parameters." ></td>
	<td class="line x" title="23:270	Tile reciprocal contribution of syntax and statistics has been outlined in (Zemik 119911) to have an important role for automatic lexicaI acquisition." ></td>
	<td class="line x" title="24:270	The syntactic relations are usually derived by preq)rocessing the target corpus with a part-of-speech tagger or with a simplified parser." ></td>
	<td class="line x" title="25:270	Syntactic markers are applied to elementary links among words or to more structurecl contexts." ></td>
	<td class="line x" title="26:270	The pa,'tial character of the different parsers described in literature makes it possible to process large corpora at a 'reasonable' computational effort." ></td>
	<td class="line x" title="27:270	Most syntax-based statistical approaches use deterministic parsing, derived from Marcus' work on PARSIF'AI." ></td>
	<td class="line x" title="28:270	parser (Marcus, 1980)." ></td>
	<td class="line x" title="29:270	I'ARS1FAL is a deterministic parser with lookahead cat)abilities, that enables partial analyses." ></td>
	<td class="line x" title="30:270	One of the PARSIFAL emanations, the Fidditch parser by I lindle, is used in (Flindle 1990) to detect subject-w~rb-object (SVO) triples." ></td>
	<td class="line x" title="31:270	SVO triples are allowed to be incomplete, i.e. the subject or the object can be missing." ></td>
	<td class="line x" title="32:270	Noisy data (i.e. words that are neither syntactically nor semantically,elated) are reduced by the use of statistical measures, sucl-t as the Itllltllal information (Church et al, 1991), as defined in information tlmory." ></td>
	<td class="line x" title="33:270	The Fidditch parser requires a lexicon including informatkm about base word fornls atld syntactic constraints (e.g,." ></td>
	<td class="line x" title="34:270	tile complement structure of verbs)." ></td>
	<td class="line x" title="35:270	Non-trivial preliminary work is tllus necessary in tuning the lexicon for the different domains and sublanguages." ></td>
	<td class="line x" title="36:270	A second problem with the Fidditch parser is poor performances: tilt_' recall and precision at detecting word collocations are declared to be as low as 50%, I-iowever it is unclear if this value applies only to SVO triples, and how it has been derived." ></td>
	<td class="line x" title="37:270	The recall is low because tile Fidditch parser, as other partial parsers (Sekine et al, 1992; Resnik and Hearst, i993), only detect links between adjacent or near-adjacent words." ></td>
	<td class="line x" title="38:270	Thougll a 50'/,, precision and recall might be 447 reasonable for human assisted tasks, like in lexicography, supervised translation, etc. , it is not 'fair enough' if collocational analysis must serve a fully automated system." ></td>
	<td class="line x" title="39:270	In fact, corpus linguistics became a popular research field because of the claim that shallow techniques could overcome the lexical coverage bottleneck of traditional NLP techniques." ></td>
	<td class="line nc" title="40:270	Among the applications of collocational analysis for lexical acquisition are: the derivation of syntactic disambiguation cues (Basili et al. 1991, 1993a; Hindle and Rooths 1991,1993; Sekine 1992) (Bogges et al. 1992), sense preference (Yarowski 1992), acquisition of selectional restrictions (Basili et al. 1992b, 1993b; Utsuro et al. 1993), lexical preference in generation (Smadjia 1991), word clustering (Pereira 1993; Hindle 1990; Basili et al. 1993c), etc. In the majority of these papers, even though the (precedent or subsequent) statistical processing reduces the number of accidental associations, very large corpora (10,000,000 words) are necessary to obtain reliable data on a 'large enough' number of words." ></td>
	<td class="line n" title="41:270	In addition, most papers produce a performance evaluation of their methods but do not provide a measure of the coverage, i.e. the percentage of cases for which their method actually provides a (right or wrong) solution." ></td>
	<td class="line x" title="42:270	It is quite common that results are discussed only for 10-20 cases." ></td>
	<td class="line x" title="43:270	In our previous papers, we used semantic tagging to further reduce the noise and gain evidence of recurrent phenomena even with small corpora." ></td>
	<td class="line x" title="44:270	However, no accurate or shallow method can resume valid information that has been lost in previous steps (i.e. in extracting collocations)." ></td>
	<td class="line x" title="45:270	We believe that a higher precision and recall of the input collocational data is desirable to ensure a good coverage to the whatever lexical learning algorithm." ></td>
	<td class="line x" title="46:270	In this paper we describe a not-so-shallow, multi-step, parsing strategy that allows it to detect long distance syntactic relations while keeping the temporal complexity compatible with the computational requirements of largescale parsers." ></td>
	<td class="line x" title="47:270	We demonstrate that a bit more syntax can be added to the recipe, with a significant improvement over existing partial parsers." ></td>
	<td class="line x" title="48:270	We do not discuss of any subsequent processing (statistically or/and knowledge based) that may be applied to further improve the quality of collocational data, since this is outside the scope of this presentation." ></td>
	<td class="line x" title="49:270	The interested reader may refer to our previous works on the matter." ></td>
	<td class="line x" title="50:270	2." ></td>
	<td class="line x" title="51:270	A 'not-so-shallow' parsing technique Our syntactic analyzer (hereafter SSA) extracts partial syntactic structures from corpora." ></td>
	<td class="line x" title="52:270	The analyzer, based on discontinuous grammar (Dahl,1989), is able to detect binary and ternary syntactic relations among words, that we call elementary slmtactic lil~k,~ (esl), The framework of discontinuous grammars has several advantages: it allows a simple notation, and exhibits portability among different logic programming styles." ></td>
	<td class="line x" title="53:270	The presence of skip rules makes it possible to detect long distance dependencies between co-occurring words." ></td>
	<td class="line x" title="54:270	This is particularly important in many texts, for the presence of long coordinate constructions, nested clauses, lists, parenthesised clauses." ></td>
	<td class="line x" title="55:270	The partial parsing strategy described hereafter requires in input few more than a morphologic lexicon (section 2.1)." ></td>
	<td class="line x" title="56:270	Post morphologic processing, as described in section 2.2, is not strictly required, though obviously it increases the reliability of the detected word relations." ></td>
	<td class="line x" title="57:270	The lexicon used is purely morphologic, unlike for the Fidditch parser, neither it requires training, like in n-gram based models." ></td>
	<td class="line x" title="58:270	This means that the shallow analyzer is portable by minimum changes over different domains." ></td>
	<td class="line x" title="59:270	This is not the case with the deterministic partial parsing used in similar works." ></td>
	<td class="line x" title="60:270	Furthermore the grammar rules are easy to tune to different linguistic subdomains." ></td>
	<td class="line x" title="61:270	The analyzer enables the detection of different types of syntactic links among words: noun-verb, verbnoun, noun-preposition-noun, etc. This information is richer than just SVO triples, in that phrase structures are partitioned in more granular units." ></td>
	<td class="line x" title="62:270	The parsing method has been implemented for different corpora, which exhibit very different linguistic styles: a corpus of commercial activities (CD), in telegraphic style, a legal domain (LD) on taxation norms and lows, and remote sensing (RSD) abstracts." ></td>
	<td class="line x" title="63:270	The latter is in English, while the former two are in Italian." ></td>
	<td class="line x" title="64:270	The English application is rather less developed (a smaller morphologic lexicon, no postmorphology, etc.), however it is useful here to demonstrate that the approach is language independent." ></td>
	<td class="line x" title="65:270	In this paper we use many examples from the RSD." ></td>
	<td class="line x" title="66:270	2.1 Morphology The morphologic analyzer (Marziali, 1992) derives from the work on a generative approach to the Italian morphology (Russo, 1987), first used in DANTE, a NLP system for analysis of short narrative texts in the financial domain (Antonacci et al. 1989)." ></td>
	<td class="line x" title="67:270	Tile analyzer includes over 7000 elementary lemmata (stems without affixes, e.g. flex is the elementary lemma for de448 flex, in-flex, re-fiex) anti has been experimented since now on economic, financial, commercial and legal domains." ></td>
	<td class="line x" title="68:270	Elementary lemmata cover much more than 70(}0 words, since many words have an affix." ></td>
	<td class="line x" title="69:270	An entry in the lexicon is as follows: lexicon(len~na, stem, ending_class, syntactic feature) where l emma iS the elementary lemma (e.g. ancora for ancor-aggio (anchor-age)), stem is the lemma without ending (ancor), ending_class iS one over about 60 types of inflections." ></td>
	<td class="line x" title="70:270	For example, ancora belongs to the class ec cosa, since it inflects like the word cosa (thinq,)." ></td>
	<td class="line x" title="71:270	The Italian morphologic lexicon and grammars are fully general." ></td>
	<td class="line x" title="72:270	This means that the analyzer has a tendency to overgenerate." ></td>
	<td class="line x" title="73:270	For example, the word agente (agent, in the sense of dealer), is interpreted as a i~.oun and as the present participle of the verb agire (to act), though this type of inflected form is never found in both Italian domains." ></td>
	<td class="line x" title="74:270	This problem is less evident in English, that is less inflected." ></td>
	<td class="line x" title="75:270	Overgeneration is a common problem with grammar based approaches to morphology, as opposed to part of speech (pos) taggers." ></td>
	<td class="line x" title="76:270	On the other side, pos taggers need manual work for corpus training every since a new domain is to be analyzed." ></td>
	<td class="line x" title="77:270	To quantitatively evaluate the phenomenon of overgeneration, we conskfered a test set of 25 sentences in the LD, including about 800 words." ></td>
	<td class="line x" title="78:270	Of these 800, there were 546 different nouns, adjectives anti verbs (i.e. potentially ambiguous words)." ></td>
	<td class="line x" title="79:270	The analyzer provided 631 interpretations of the 546 words." ></td>
	<td class="line x" title="80:270	There were 76 ambiguous words." ></td>
	<td class="line x" title="81:270	The overall estimated ambiguity is 76/546:0,139, while the overgeneration ratio is better evaluated by: O = \[631 (546-76)\]/76=161/76:2,11 2.2." ></td>
	<td class="line x" title="82:270	Post morphological processing The purpose of this module is to analyse compound expressions and numbers, such as compound verbs, dates, numeric expressions, and super!atives." ></td>
	<td class="line x" title="83:270	Ad-hoc context free grammar have been defined." ></td>
	<td class="line x" title="84:270	Post morphological processing includes also simple (but generally valid) heuristic rules to reduce certain types of ambiguity." ></td>
	<td class="line x" title="85:270	'Ihere are two group of such rules: (i) Rules to disambiguate ambiguous nounadjective (N/Agg) interpretations (e.g. acid) (ii) Rules to disambiguate ambiguous verb-noun (V/N) interpretations (e.g. study) One example of heuristics for N/Agg is: If N/Agg is neither preceded nor followed by a noun, or N/Agg, before a verb is reached, Then it is a noun." ></td>
	<td class="line x" title="86:270	Ex: and sulphuric ~ was detected Though examples are in English, post morphology has not been developed for the English language at the time we are w,'iting." ></td>
	<td class="line x" title="87:270	After post-morphologic analysis, the 546 nouns, verbs anti adjectives produced only 562 interpretations." ></td>
	<td class="line x" title="88:270	The new overgeneration ratio is then O':(562-(546-76))/76=92/76=1,2 The estimated efficacy of the postrnorphology, is 161/92=1,75, about 50%.'eduction of the initial ambiguity." ></td>
	<td class="line x" title="89:270	2.3." ></td>
	<td class="line x" title="90:270	The parser The SSA syntactic analysis is a rewriting procedure of a single sentence into a set of ~!_1 ~meme~!-y_~y~ i\]jg_jin!~ (esl)." ></td>
	<td class="line x" title="91:270	The SSA is based on a discontinuous grammar, described more formally in (Basili et al. 1992a)." ></td>
	<td class="line x" title="92:270	In tiffs section we provide a qualitative clescription of the rules by which esl's are generated." ></td>
	<td class="line x" title="93:270	Examples of esl's generated by the parser are: N_V (the subject-verb relation), V N (the direct object_verb relation), N P N (noun preposition noun), V P N (verb preposition noun), N_Adj (adjective noun), N N (conq)ound) etc. Overall, we identify over 20 different esl's." ></td>
	<td class="line x" title="94:270	There is a discontinuous grammar rule for each esl." ></td>
	<td class="line x" title="95:270	A description of a rule used to derive N P N links is in Figure 1." ></td>
	<td class="line x" title="96:270	This description applies by straightforward modifications to any other esl type (though some esl rules include a concordance test)." ></td>
	<td class="line x" title="97:270	As remfirked at the beginning of this section, skip rules are the key to extract long distance syntactic relations and to approximate the behaviour of a full parser." ></td>
	<td class="line x" title="98:270	The first predicate LOOK RIGItT of Figure 1 skips over the string X until it finds a preposition (prep(w2))." ></td>
	<td class="line x" title="99:270	The second LOOK_RIG\[ IT skips over Y until it finds a noun (noun(w3))." ></td>
	<td class="line x" title="100:270	Given an initial string NL_segment, BACKTRACK force the system to analyse all the possible solutions of the predicate LOOKRIGHT (i.e. one-step rigth skips) to derive all the N P N groups, headed by the first norm (i.e. wl)." ></td>
	<td class="line x" title="101:270	For example, given the string: low concentrations of acetone and ethyl alchool in acqueous solutions the following N_PN are generated: concentration of acetone, concentration of alchool, concentration in solution, acetone in 449 solution, alchooI in solution, all of which are syntactically correct." ></td>
	<td class="line x" title="102:270	SSA rule( NL segment, N_P_N) BEGIN P, EPIZd~T IFNL_segment is EMPTY 'IIIEN F2KrI'; ELSE BEGIN NL segment=(wl Rest)." ></td>
	<td class="line x" title="103:270	IF (noun(wl) ) THFM BEGIN LOOK_RIGIIT(X, w2, Rest, New_Rest); %Rest=(X w2 NewRest) IF (TEST_ON(X) AND prep(w2) ) 'IIIEN BEG I N LOOK RIGIIT( Y, w2, New_Rest, _); %New_Rest--(Y w3 _) IF ( TEST ON(Y) AND noun(w3) ) 'llIEN ASSERT(esl(N_P_N, wl, w2, w3)); BACKTRACK; END; BACKTRACK; END POPwl FROM Nb_segment; END END." ></td>
	<td class="line x" title="104:270	Figure 1: A description of an N P N rule An uncontrolled application of skip rules would however produce unacceptable noise." ></td>
	<td class="line x" title="105:270	The TEST_ON0 are ad hoc heuristic rules that avoid uncontrolled skips." ></td>
	<td class="line x" title="106:270	For example, TEST2.ON(X) in Figure 1 verifies that the string X does notinclude a verb." ></td>
	<td class="line x" title="107:270	Hence, in the sentence:  the atmospheric code contpared favourably with results  the N P_N(code,with,results) is ~ generated." ></td>
	<td class="line x" title="108:270	In general, there is one-two different heuristic rule for each esl rule." ></td>
	<td class="line x" title="109:270	Heuristic rules are designed to take efficient decisions by exploiting purely syntactic constraints." ></td>
	<td class="line x" title="110:270	Such constraints are simple and require a minimum computational effort (essentialy, unification among simple structures)." ></td>
	<td class="line x" title="111:270	In some case, a lower recall is tolerated to avoid overgeneration." ></td>
	<td class="line x" title="112:270	For example, the second TEST ON(Y) rule of Figure 1 verifies that no more than two prepositions are skipped in the string Y. This rule stems from the observation that words located more than three prepositions apart, are rarely semantically related, though a full syntactic parser would eventually detect a relation." ></td>
	<td class="line x" title="113:270	Hence, in the NL segment: 1% accuracy on the night side of the Earth with stars down to visual magnitude tree the triple (accuracy, to, tree) is la_(gt generated, though syntactically correct." ></td>
	<td class="line x" title="114:270	The derivation of esl's is enabled for non adjacent word by virtue of skip rules." ></td>
	<td class="line x" title="115:270	However, interesting information can be lost in presence of more complex phenomena as nested relative clauses or coordination of phrase structures." ></td>
	<td class="line x" title="116:270	To cope with these phenomena, a post syntactic processor has been developed to extract links stemming from coordination among previously detected links." ></td>
	<td class="line x" title="117:270	This processing significantly increases the set of collected esl, and the quality of the derived lexical information." ></td>
	<td class="line x" title="118:270	The contribution of this post syntactic processing device depends heavily on the structure of incoming sentences." ></td>
	<td class="line x" title="119:270	In this phase, simple unification .mechanisms are used, rather than heuristics." ></td>
	<td class="line x" title="120:270	3." ></td>
	<td class="line x" title="121:270	Performance evaluation Recall and Precision M,'my algorithms evaluate their recall and precision against a human reference performer." ></td>
	<td class="line x" title="122:270	This pose many problems, like finding a 'fair' test material, using a large number of judges to render the evaluation less subjective, and finally interpreting the results." ></td>
	<td class="line x" title="123:270	One example of the 450 latter problem is the following: in (Smadja 1993) the nature of a syntactic link between two associated words is detected a posteriori." ></td>
	<td class="line x" title="124:270	The performance of the system, called XTRACT, we evaluated by letting human judges compare their choice against that of the system." ></td>
	<td class="line x" title="125:270	The reported performances are about 80% precision, 90% recall." ></td>
	<td class="line x" title="126:270	One such evaluation experiment is, in our view, questionable, since both the human judges and XTRACT make a decision outside the context of a sentence." ></td>
	<td class="line x" title="127:270	The interpretation of the results then does not take into account how much XTRACT succeeds in identifying syntactic relations as they actually occurred in the test suite." ></td>
	<td class="line x" title="128:270	Another problem is that, a human judge ntay consider not correct a syntactic association on the ground of semantic knowledge 1." ></td>
	<td class="line x" title="129:270	Instead, the performance of a syntactic parser should be evaluated only on a syntactic ground." ></td>
	<td class="line x" title="130:270	We define the linguistic performance of SSA as its ability to approximate the generation of the full set of elementary syntactic links derivable by a complete grammar of the domain." ></td>
	<td class="line x" title="131:270	Given the set I2 of all syntactically valid esl and the set m of esl derived applying SSA, the precision of the system can be defined as the ratio cardinality(f2 m co) / cardinality(Q), while its recall can be expressed by: cardinality(co n ~2) / cardinality(~}), Global evaluations of the precision and recall are estimated by the mean values over the whole corpora." ></td>
	<td class="line x" title="132:270	We designed for testing purposes a full attribute grammar of the Italian legal language, and we selected 150 sentences for which the full grammar was proved correct." ></td>
	<td class="line x" title="133:270	For each parsed sentence, a program automatically computes the esrs globally identified (without repetitions) by the parse trees of each sentence, and compares them with those generated by SSA for the same sentence." ></td>
	<td class="line x" title="134:270	The following Table gives a measure of ~erformance: Esl_type N P N V P N RECALL 69.1 ~Yo' N_V 55 % 67.5 % PRECISION 81.8 % 56 % V_N 86.6 % 59 % 60.5 % To fully appreciate these results, we must consider, first, that the evaluation is on a purely syntactic ground (many collocations detected by 1 It is tmclear whether Smadja considered Otis problem in his evaluation experiment the full grammar and not detected by the SSA are in fact semantically wrong), second, that the domain is particularly complex." ></td>
	<td class="line x" title="135:270	There is an average of 23 trees per sentences in the test set." ></td>
	<td class="line x" title="136:270	In particvlar, the low performances of N_V groups (i.e. the subject relation) is influenced by the very frequent (almost 80'}'0) presence of nested relatives (ex: The income that was perceived during 1988i)is included) and inversions (ex: si considerano esenti da tassei redditi=*it is considered tax-free the income)." ></td>
	<td class="line x" title="137:270	No partial parser could cope with these entangled structttres." ></td>
	<td class="line x" title="138:270	One interesting aspect is that these results seem very stable for the domain." ></td>
	<td class="line x" title="139:270	In fact, incrementally adding new groups of sentences, the perfoemance values do not change significantly." ></td>
	<td class="line x" title="140:270	l'or completeness, we also evaluated the English grammar." ></td>
	<td class="line x" title="141:270	In this case, the evaluation was carried entirely by hand, since no full grammar of English was available to automatically derive the complete set of esl's." ></td>
	<td class="line x" title="142:270	F'irst, a test set of 10 remote sensing abstracts (about 1400 words, 67 sentences) was selected at random." ></td>
	<td class="line x" title="143:270	The results are the following: Esl_type RECALL N _ N 78 % V_N." ></td>
	<td class="line x" title="144:270	81% N_p_N 94 % V pN 87 % N_ V 75 % PRECISION 67 % 58 % 54 '~/o 42 % 57 % Here the recall is rather high, since sentences have a much simple structure." ></td>
	<td class="line x" title="145:270	However, there are many valid long distance pp attachments that for example most existing partial parses would not detect." ></td>
	<td class="line x" title="146:270	The precision is lower because the English parser does not have post morphokGy as yet." ></td>
	<td class="line x" title="147:270	One major source of error at detecting N V pairs are, as expected, comIxmnds." ></td>
	<td class="line x" title="148:270	The most important factors that influence the time complexity are: the number N of sentences (words) of the corpus and the number k of different discontinuous rules (about 20, as we said)." ></td>
	<td class="line x" title="149:270	The global rewriting procedure of SSA depends on the length n of the incoming text segment according to the following expression: *t i=l where e(x) is the cost of the application of a grammar rule, as for in Figure 1, to a segment of 4.51 length x. e(x) is easily seen to depend on: 1." ></td>
	<td class="line x" title="150:270	Predicates that test the syntactic category of a word (e.g. noun(w1)), whose cost is equal to that of a simple unification procedure i.e. 't; 2." ></td>
	<td class="line x" title="151:270	TEST ON predicates, whose cost is not greater than '~*n, where n is the substring length." ></td>
	<td class="line x" title="152:270	We can thus say that the expression e(x) of the complexity of SSA syntactic rules verifies the following inequality: e(n) <3r+ 2'rn = O(n) Hence, the global cost is: N n ~ ke(n i) <~_~3'ck + 2'rk(n -i) = i=1 i=1 = 2'rkn(n + 1) +3'~kn = O(n 2) A significant information is that the processing time needed on a Sun Sparc station by the full grammar to parse the test set of 150 sentences is 6 hours, while SSA takes only 10 minutes." ></td>
	<td class="line x" title="153:270	Portability and scalability These two aspects are obviously related." ></td>
	<td class="line x" title="154:270	The question is: How much, in terms of time and resources, is needed to switch to a different domain, or to update a given domain?" ></td>
	<td class="line x" title="155:270	Since we developed three entirely different applications, we can provide some reliable estimate of these parameters." ></td>
	<td class="line x" title="156:270	The estimate of course is strongly dependent upon the specific system we implemented, however we will frame our evaluation in a way that broadly applies to any system that uses similar techniques." ></td>
	<td class="line x" title="157:270	Morphology: Our experience when switching front the commercial to the legal domain was that, when running the analyzer over the new corpus, about 30,000 words could not be analyzed." ></td>
	<td class="line x" title="158:270	This required the insertion of about 1,500 new elementary lemmata." ></td>
	<td class="line x" title="159:270	Accounting for a new word requires entering the stem without affixes, the elementary lemma of the word and the ending class (see section 2.1)." ></td>
	<td class="line x" title="160:270	Entering a new word takes about 5-10 minutes when the linguist is provided with some onqine help, for example a list of ending classes, browsing and testing facilities, etc. With these facilities, updating the lexicon is a relatively easy job, that does not require a specialized linguist to be performed." ></td>
	<td class="line x" title="161:270	Clearly, when implementing several applications, the global updating effort tends to zero." ></td>
	<td class="line x" title="162:270	This is not the case for statistically based part of speech taggers, that require always a fixed effort to train on a new corpus." ></td>
	<td class="line x" title="163:270	On the long run, it seems that grammar based approaches to morphology have an advantage over pos taggers, in terms of portability." ></td>
	<td class="line x" title="164:270	Our experience is that adding a new rule takes about one-two man days." ></td>
	<td class="line x" title="165:270	First, one must detect the linguistic pattern that is not accounted for in the grammar, and verify whether it can be reasonably accounted for, given the intrinsic limitations of the parsing mechanism adopted." ></td>
	<td class="line x" title="166:270	If the linguist decides that, indeed, adding a new rule is necessary and feasible, he/she implements the rule and test its effects." ></td>
	<td class="line x" title="167:270	Grammar modifications are required to: * Select the esl types of interests; * Define the heuristic rules (TEST ON), as discussed in Section 2.3." ></td>
	<td class="line x" title="168:270	One positive aspect of SSA is that its complexity is O(k) with respect to the number k of grammar rules." ></td>
	<td class="line x" title="169:270	Hence adding new rules does not affect the complexity class of the method." ></td>
	<td class="line x" title="170:270	In summary, portability is an essential feature of SSA." ></td>
	<td class="line x" title="171:270	While other parsers need a non trivial effort to be tuned on clifferent linguistic domains, we need only minimal adjustment to ensure the required coverage of the morphologic lexicon." ></td>
	<td class="line x" title="172:270	However, the activity of lexical extension is needed with every approach." ></td>
	<td class="line x" title="173:270	Portability is also guarantied by the modularity of the apl)roach." ></td>
	<td class="line x" title="174:270	4." ></td>
	<td class="line x" title="175:270	Conclusions." ></td>
	<td class="line x" title="176:270	Shallow methods for corpus analysis claim to have several desirable features, such as limited manual work and high coverage." ></td>
	<td class="line x" title="177:270	Our point is that this is not entirely true." ></td>
	<td class="line x" title="178:270	Fully statistical methods require initial training over the corpus to estimate parameters, and this is not trivial." ></td>
	<td class="line x" title="179:270	Most of all, the effort is exactly the same every since the domain changes." ></td>
	<td class="line x" title="180:270	In addition, a lot of noisy data are collected unless some shallow level of linguistic analysis is added to increase performance." ></td>
	<td class="line x" title="181:270	But even then, reliable data are collected only for a fragment of the corpus." ></td>
	<td class="line x" title="182:270	And what about high coverage?" ></td>
	<td class="line x" title="183:270	On tl'te other side, we wouldn't be here, had traditional NLP techniques had any chance to become truly scalable." ></td>
	<td class="line x" title="184:270	This paper showed, if not else, that a bit more syntax can be added to the recipe, while still meeting important requirements, such as computational complexity and portability." ></td>
	<td class="line x" title="185:270	In media stat virtus: ql'ds could be the moral of this paper, and in general of our research on lexical acquisition." ></td>
	<td class="line x" title="186:270	Of course, we don't know where exactly the perfect balance is, we just seek for a better balance." ></td>
	<td class="line x" title="187:270	452 References." ></td>
	<td class="line x" title="188:270	(Antonacci 1989), F. Antonacci, M.T. l'azienza, M. Russo, P. Velardi, (1989), A Logic based system for text analysis and lexical knowledge acquisitio,l, in Data and Knowledge Engineering, vol 4." ></td>
	<td class="line x" title="189:270	(Basili et al. 1991), R. Basili, M. T. Pazienza, P. Velardi, (1991), Using word association for syntactic disambiguation, in Trends in Artificial Intelligence, E. Ardizzone et al. , Eds., I.NAI n. 549, Springer-Verlag." ></td>
	<td class="line x" title="191:270	(Basili et al. 1992 a) R. Basili, M. T. Pazieuza, P. Velardi, (19921, A shallow Syntax to extract word associations from corpora', in Literary and Linguistic Computiug, vol." ></td>
	<td class="line x" title="192:270	2." ></td>
	<td class="line x" title="193:270	(Basili et al. 1992 b) R. Basili, M. T. Pazienza, P. Velardi, (1992), Computational Lexicons: the neat examples and the odd exemplars, Prec." ></td>
	<td class="line x" title="194:270	of 3rd." ></td>
	<td class="line x" title="195:270	Conf." ></td>
	<td class="line x" title="196:270	on Applied NLP." ></td>
	<td class="line x" title="197:270	(Basili et al.1993a), Basili, R. , M.T. Pazienza, P. Velardi, (19931." ></td>
	<td class="line x" title="198:270	Semi-automatic extraction of linguistic information for syntactic disambiguation, Applied Artificial Intelligence, vol." ></td>
	<td class="line x" title="199:270	4, 1993." ></td>
	<td class="line x" title="200:270	(Basill et al.1993b), Basili, R. , M.T. Pazienza, P. Velardi, (19931." ></td>
	<td class="line x" title="201:270	What can be learned from raw texts ?, Journal of Machine Translation, 8:147-173." ></td>
	<td class="line x" title="202:270	(Basili et a1.1993c), Basili, R. , M.T. Pazienza, P. Velardi, (1993)." ></td>
	<td class="line x" title="203:270	llierarchical clustering of verbs, ACLSIGLEX Workshop on Lexical Acquisition, Columbus Ohio, June." ></td>
	<td class="line x" title="204:270	(Bogges,1991), L. Bogges, R. Agarwal, R. Davis, I)isambiguation of prepositional phrases iu automatically labelled technical text (1991)." ></td>
	<td class="line x" title="205:270	Prec." ></td>
	<td class="line x" title="206:270	of AAAI 1991 (Church and llanks, 19901, K. Church and P. llauks, Word association norm, mutnal information and lexicography, Computational Linguistics, vol." ></td>
	<td class="line x" title="207:270	16, n.1, 1990 (Church et al, 1991), Church, Gale, flanks and Ilindlc, Using statistics in lexicaI analysis, (19911." ></td>
	<td class="line x" title="208:270	Lexical Acquisition, U. Zernik Ed., l.awrence Erlbaum Ass., Publ., 115-164." ></td>
	<td class="line x" title="212:270	(Calzolari and Bindi,1990) N.Calzolari and R. Bindi, Acquisition of lexical informatiou from Corpora, (19901, Prec." ></td>
	<td class="line x" title="213:270	of COLING 90." ></td>
	<td class="line x" title="214:270	(Dahl, 1989), Dahl,V. , 'Discontinous grammars', (1989)." ></td>
	<td class="line x" title="215:270	Computational Intelligence, n. 5, 161-179." ></td>
	<td class="line x" title="216:270	(Fujsaki et a1.,1991) Fujisaki T. , F. Jelinek, J. Cooke, E. Black, T. Nishino, A probabilistic parsing method for sentence disambiguation, (19911." ></td>
	<td class="line x" title="218:270	Cu,'reut trends in Parsing Technology, M. Tomita Ed., Kluwer Ac." ></td>
	<td class="line x" title="220:270	Publ., 1991." ></td>
	<td class="line x" title="221:270	(Ilindle and Rooths,1991) D. llindle, M. l~,ooths, Structural Ambiguity and Lexical P, elatious (1991)." ></td>
	<td class="line x" title="222:270	Prec." ></td>
	<td class="line x" title="223:270	of ACL 1991 (ltindle, 19901, D. llindle, Nouu Classification form predicate-argument structure (199tl)." ></td>
	<td class="line x" title="224:270	Prec." ></td>
	<td class="line x" title="225:270	of AC1." ></td>
	<td class="line x" title="226:270	1990 (Ilindle and Rooths,1991) D. Ilindle, M. Rooths, Structural Ambiguity and Lexical Relations (1991)." ></td>
	<td class="line x" title="227:270	Prec." ></td>
	<td class="line x" title="228:270	of ACL 1991 (llindle and Rooths, 1993) 11." ></td>
	<td class="line x" title="229:270	llindle and M. Rooths, Structural ambiguity and lexical relations (1993)." ></td>
	<td class="line x" title="230:270	(2ompntational Linguistics, vol." ></td>
	<td class="line x" title="231:270	19, n. 1, 1993 (Gale et al, 1992), I!stimating the upper and lower bounds on the performance of word-sense disambiguation progrt, ms, (1992)." ></td>
	<td class="line x" title="232:270	l:'roc, of ACL 1992 (Jelinek et al. , 1990) F. Jelinek, J.l)." ></td>
	<td class="line x" title="233:270	l.al'ferty, F,.I Mecer, Basic methods of probabilistic context f,'ee grammars, (19901." ></td>
	<td class="line x" title="234:270	Research Report R( 216374 IBM YorkTown lleights NY 10598, 1990." ></td>
	<td class="line x" title="235:270	(Marcus, 1980), M. Max'cns, A Theory of Syntactic recoguitiou for Natural I.anguage, MIT Press, 1980 (Marziali,19921, Marziali, A. , 'Robust Methods fro." ></td>
	<td class="line x" title="236:270	parsiug large-scale text archives, I)issertation, Facolth di lugegneria, Univerith 'La Sapieuza' I>,oma, a.a. 1992 ." ></td>
	<td class="line x" title="237:270	(Percira et at." ></td>
	<td class="line x" title="238:270	'1993) F.Pereira, N. Tishby, L. Lee, (19931." ></td>
	<td class="line x" title="239:270	'Distributional Clustering of English Words', in Prec." ></td>
	<td class="line x" title="240:270	of ACI, 93 Columbus, Ohio, June, 1993." ></td>
	<td class="line x" title="241:270	(Rnsso, 1987), M. Russo, 'A generative grammar approach for the morphologic and morphosyntactic analysis of the Italian langnage' (1987)." ></td>
	<td class="line x" title="242:270	3rd." ></td>
	<td class="line x" title="243:270	Conf." ></td>
	<td class="line x" title="244:270	of the F.urol~ean Chapter of the ACI,, Copenhaghen, April 1-3 1987." ></td>
	<td class="line x" title="245:270	(Sekiae et al, 1992) Automatic learuiug for semantic collocations, (19921." ></td>
	<td class="line x" title="246:270	Prec." ></td>
	<td class="line x" title="247:270	of 3rd." ></td>
	<td class="line x" title="248:270	ANLI', 1992 (Smadja,1989), F. Smadja, 'Lexical cooccurences: the missing link', (1989)." ></td>
	<td class="line x" title="249:270	Literary and 1,iuguistic Computing, vol.4, n.3, 1989." ></td>
	<td class="line x" title="250:270	(Smadja,1991), F. Smadja, From N-Grams to collocations: au evaluation of XTRACT, (1991)." ></td>
	<td class="line x" title="251:270	Prec." ></td>
	<td class="line x" title="252:270	of ACI, 199l (Smadja,1990), F. Smadja, K. McKeou, Automatically extracting and rcsprescnting collocations for langultge generation, (1990)." ></td>
	<td class="line x" title="253:270	Prec." ></td>
	<td class="line x" title="254:270	of ACL 1990 (Smadja, 1993), F. Smadja, Retrieving collocations fi'cma text: XTRACT, (1993)." ></td>
	<td class="line x" title="255:270	Computatioual Linguistics, w~l 19, u.l, 1993 (l(esnik and llearst, 1993) P. Resnik, M. llearst, Structural Ambiguity and Conceptual Relations, (1993)." ></td>
	<td class="line x" title="256:270	pt'oc, of the workshop on Very l,arge Corl)ra, Columbus, June 1993 (Iltsuro et a1.,.1993), T. Utsnro, Y. Matsumoto, M. Nagao, verbal case frame acqnisition from bilingual corlx)ra, (1993)." ></td>
	<td class="line x" title="258:270	Prec." ></td>
	<td class="line x" title="259:270	of IJCAI 1993 (Yarowski, 1992) Yarowsky 1)., 'Word-Sense Disambiguation Using Statistical Models of Roger's Categories Trained on Large Corpora', (1992)." ></td>
	<td class="line x" title="261:270	Prec." ></td>
	<td class="line x" title="262:270	of COI,ING-92, Nantes, Aug. 23-28." ></td>
	<td class="line x" title="263:270	(Zernik,1990), tl." ></td>
	<td class="line x" title="264:270	Zernik, P. Jacobs, Tagging for l.earning: Collecting Thematic relations from Corpus (1990)." ></td>
	<td class="line x" title="265:270	Prec." ></td>
	<td class="line x" title="266:270	of COL1NG 1990 (Zeruik,1991), U. Zernik, Ed." ></td>
	<td class="line x" title="267:270	'Lexical Acquisition: Fxploiting on-line resources to build a lexicon', (1991)." ></td>
	<td class="line x" title="268:270	Lawrence Erlbatun Publ., 1991." ></td>
	<td class="line x" title="270:270	453" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="J94-4003
Word Sense Disambiguation Using A Second Language Monolingual Corpus
Dagan, Ido;Itai, Alon;"></td>
	<td class="line x" title="1:730	Word Sense Disambiguation Using a Second Language Monolingual Corpus Ido Dagan* AT&T Bell Laboratories Alon Itai t Technion--Israel Institute of Technology This paper presents a new approach for resolving lexical ambiguities in one language using statistical data from a monolingual corpus of another language." ></td>
	<td class="line x" title="2:730	This approach exploits the differences between mappings of words to senses in different languages." ></td>
	<td class="line x" title="3:730	The paper concentrates on the problem of target word selection in machine translation, for which the approach is directly applicable." ></td>
	<td class="line x" title="4:730	The presented algorithm identifies syntactic relations between words, using a source language parser, and maps the alternative interpretations of these relations to the target language, using a bilingual lexicon." ></td>
	<td class="line x" title="5:730	The preferred senses are then selected according to statistics on lexical relations in the target language." ></td>
	<td class="line x" title="6:730	The selection is based on a statistical model and on a constraint propagation algorithm, which simultaneously handles all ambiguities in the sentence." ></td>
	<td class="line x" title="7:730	The method was evaluated using three sets of Hebrew and German examples and was found to be very useful for disambiguation." ></td>
	<td class="line x" title="8:730	The paper includes a detailed comparative analysis of statistical sense disambiguation methods." ></td>
	<td class="line x" title="9:730	1." ></td>
	<td class="line x" title="10:730	Introduction The resolution of lexical ambiguities in nonrestricted text is one of the most difficult tasks of natural language processing." ></td>
	<td class="line x" title="11:730	A related task in machine translation, on which we focus in this paper, is target word selection." ></td>
	<td class="line x" title="12:730	This is the task of deciding which target language word is the most appropriate equivalent of a source language word in context." ></td>
	<td class="line x" title="13:730	In addition to the alternatives introduced by the different word senses of the source language word, the target language may specify additional alternatives that differ mainly in their usage." ></td>
	<td class="line x" title="14:730	Traditionally, several linguistic levels were used to deal with this problem: syntactic, semantic, and pragmatic." ></td>
	<td class="line x" title="15:730	Computationally, the syntactic methods are the most affordable, but are of no avail in the frequent situation when the different senses of the word show the same syntactic behavior, having the same part of speech and even the same subcategorization frame." ></td>
	<td class="line x" title="16:730	Substantial application of semantic or pragmatic knowledge about the word and its context requires compiling huge amounts of knowledge, the usefulness of which for practical applications in broad domains has not yet been proven (e.g. , Lenat et al. 1990; Nirenburg et al. 1988; Chodorow, Byrd, and Heidron 1985)." ></td>
	<td class="line x" title="17:730	Moreover, such methods usually do not reflect word usages." ></td>
	<td class="line x" title="18:730	Statistical approaches, which were popular several decades ago, have recently reawakened and were found to be useful for computational linguistics." ></td>
	<td class="line x" title="19:730	Within this framework, a possible (though partial) alternative to using manually constructed * AT&T Bell Laboratories, 600 Mountain Avenue, Murray Hill, NJ 07974, USA." ></td>
	<td class="line x" title="20:730	E-mail: dagan@research.att.com." ></td>
	<td class="line x" title="21:730	The work reported here was done while the author was at the Technion--Israel Institute of Technology." ></td>
	<td class="line x" title="22:730	t Department of Computer Science, Technion--Israel Institute of Technology, Haifa 32000, Israel." ></td>
	<td class="line x" title="23:730	E-maih itai@cs.technion.ac.il." ></td>
	<td class="line x" title="24:730	(~) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 4 knowledge can be found in the use of statistical data on the occurrence of lexical relations in large corpora (e.g. , Grishman, Hirschman, and Nhan 1986)." ></td>
	<td class="line oc" title="25:730	The use of such relations (mainly relations between verbs or nouns and their arguments and modifiers) for various purposes has received growing attention in recent research (Church and Hanks 1990; Zernik and Jacobs 1990; Hindle 1990; Smadja 1993)." ></td>
	<td class="line oc" title="26:730	More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment (Hindle and Rooth 1991) and pronoun references (Dagan and Itai 1990, 1991)." ></td>
	<td class="line x" title="27:730	Clearly, statistics on lexical relations can also be useful for target word selection." ></td>
	<td class="line x" title="28:730	Consider, for example, the Hebrew sentence extracted from the foreign news section of the daily Ha-Aretz, September 1990 (transcripted to Latin letters): (1) Nose ze mana' mi-shtei ha-mdinot mi-lahtom 'al hoze shalom." ></td>
	<td class="line x" title="29:730	issue this prevented from-two the-countries from-signing on treaty peace \[ This sentence would translate into English as (2) This issue prevented the two countries from signing a peace treaty." ></td>
	<td class="line x" title="30:730	The verb lahtom has four senses: 'sign,' 'seal,' 'finish,' and 'close'." ></td>
	<td class="line x" title="31:730	The noun hoze means both 'contract' and 'treaty,' where the difference is mainly in usage rather than in the meaning (in Hebrew the word h.oze is used for both sub-senses)." ></td>
	<td class="line x" title="32:730	One possible solution is to consult a Hebrew corpus tagged with word senses, from which we would probably learn that the sense 'sign' of lahtom appears more frequently with hoze as its object than all the other senses." ></td>
	<td class="line x" title="33:730	Thus we should prefer that sense." ></td>
	<td class="line x" title="34:730	However, the size of corpora required to identify lexical relations in a broad domain is very large, and therefore it is usually not feasible to have such corpora manually tagged with word senses) The problem of choosing between 'treaty' and 'contract' cannot be solved using only information on Hebrew, because Hebrew does not distinguish between them." ></td>
	<td class="line x" title="35:730	The solution suggested in this paper is to identify the lexical relations in corpora of the target language, instead of the source language." ></td>
	<td class="line x" title="36:730	We consider word combinations and count how often they appear in the same syntactic relation as in the ambiguous sentence." ></td>
	<td class="line x" title="37:730	For the above example, the noun compound 'peace treaty' appeared 49 times in our corpus (see Section 4.3 for details on our corpus), whereas the compound 'peace contract' did not appear at all; the verb-obj combination 'to sign a treaty' appeared 79 times, whereas none of the other three alternatives appeared more than twice." ></td>
	<td class="line x" title="38:730	Thus, we first prefer 'treaty' to 'contract' because of the noun compound 'peace treaty' and then proceed to prefer 'sign' since it appears most frequently having the object 'treaty'." ></td>
	<td class="line x" title="39:730	The order of selection is determined by a constraint propagation algorithm." ></td>
	<td class="line x" title="40:730	In both cases, the correctly selected word is not the most frequent one: 'close' is more frequent in our corpus than 'sign' and 'contract' is more frequent than 'treaty'." ></td>
	<td class="line x" title="41:730	Also, by using a model of statistical confidence, the algorithm avoids a decision in cases in which no alternative is significantly better than the others." ></td>
	<td class="line x" title="42:730	Our approach can be analyzed from two different points of view." ></td>
	<td class="line x" title="43:730	From that of monolingual sense disambiguation, we exploit the fact that the mapping between words and word senses varies significantly among different languages." ></td>
	<td class="line x" title="44:730	This enables 1 Hearst (1991) suggests a sense disambiguation scheme along this line." ></td>
	<td class="line x" title="45:730	See Section 7 for a comparison of several sense disambiguation methods." ></td>
	<td class="line x" title="46:730	564 Ido Dagan and Alon Itai Word Sense Disambiguation US to map an ambiguous construct from one language to another, obtaining representations in which each sense corresponds to a distinct word." ></td>
	<td class="line x" title="47:730	Now it is possible to collect co-occurrence statistics automatically from a corpus of the other language, without requiring manual tagging of senses." ></td>
	<td class="line x" title="48:730	2 From the point of view of machine translation, we suggest that some ambiguity problems are easier to solve at the level of the target language than the source language." ></td>
	<td class="line x" title="49:730	The source language sentences are considered a noisy source for target language sentences, and our task is to devise a target language model that prefers the most reasonable translation." ></td>
	<td class="line x" title="50:730	Machine translation is thus viewed in part as a recognition problem, and the statistical model we use specifically for target word selection may be compared with other language models in recognition tasks (e.g. , Katz 1987; Jelinek 1990, for speech recognition)." ></td>
	<td class="line x" title="51:730	To a limited extent, this view is shared with the statistical machine translation system of Brown et al.(1990), which employs a target language n-gram model (see Section 8 for a comparison with this system)." ></td>
	<td class="line x" title="53:730	In contrast to this view, previous approaches in machine translation typically resolve examples like (1) by stating various constraints in terms of the source language (Nirenburg 1987)." ></td>
	<td class="line x" title="54:730	As explained above, such constraints cannot be acquired automatically and therefore are usually limited in their coverage." ></td>
	<td class="line x" title="55:730	The experiments we conducted clearly show that statistics on lexical relations are very useful for disambiguation." ></td>
	<td class="line x" title="56:730	Most notable is the result for the set of examples of Hebrew to English translation, which was picked randomly from foreign news sections in the Israeli press." ></td>
	<td class="line x" title="57:730	For this set, the statistical model was applicable for 70% of the ambiguous words, and its selection was then correct for 91% of the cases." ></td>
	<td class="line x" title="58:730	We cite also the results of a later experiment (Dagan, Marcus, and Markovitch 1993) that tested a weaker variant of our method on texts in the computer domain, achieving a precision of 85%." ></td>
	<td class="line x" title="59:730	Both results significantly improve upon a naive method that uses only a priori word probabilities." ></td>
	<td class="line x" title="60:730	These results are comparable to recent reports in the literature (see Section 7)." ></td>
	<td class="line x" title="61:730	It should be emphasized, though, that our results were achieved for a realistic simulation of a broad coverage machine translation system, on randomly selected examples." ></td>
	<td class="line x" title="62:730	We therefore believe that our figures reflect the expected performance of the algorithm in a practical implementation." ></td>
	<td class="line x" title="63:730	On the other hand, most other results relate to a small number of words and senses that were determined by the experimenters." ></td>
	<td class="line x" title="64:730	Section 2 of the paper describes the linguistic model we use, employing a syntactic parser and a bilingual lexicon." ></td>
	<td class="line x" title="65:730	Section 3 presents the statistical model, assuming a multinomial model for a single lexical relation and then using a constraint propagation algorithm to account simultaneously for all relations in the sentence." ></td>
	<td class="line x" title="66:730	Section 4 describes the experimental Setting." ></td>
	<td class="line x" title="67:730	Section 5 presents and analyzes the results of the experiment and cites additional results (Dagan, Marcus, and Markovitch 1993)." ></td>
	<td class="line x" title="68:730	In Section 6 we analyze the limitations of the algorithm in different cases and suggest enhancements to improve it." ></td>
	<td class="line x" title="69:730	We also discuss the possibility of adopting the algorithm for monolingual applications." ></td>
	<td class="line x" title="70:730	Finally, in Section 7 we present a comparative analysis of statistical sense disambiguation methods and then conclude in Section 8." ></td>
	<td class="line x" title="71:730	2 A similar observation underlies the use of parallel bilingual corpora for sense disambiguation (Brown et al. 1991; Gale, Church, and Yarowsky 1992)." ></td>
	<td class="line x" title="72:730	As we explain in Section 7, these corpora are a form of a manually tagged corpus and are more difficult to obtain than monolingual corpora." ></td>
	<td class="line x" title="73:730	Erroneously, the preliminary publication of our method (Dagan, Itai, and Schwall 1991) was cited several times as requiring a parallel bilingual corpus, 565 Computational Linguistics Volume 20, Number 4 2." ></td>
	<td class="line x" title="74:730	The Linguistic Model Our approach is first to use a bilingual lexicon to find all possible translations of each lexically ambiguous word in the source sentence and then use statistical information gathered from target language corpora to choose the most appropriate alternative." ></td>
	<td class="line x" title="75:730	To carry out this task we need the following linguistic tools, which are discussed in detail in the following sections: Section 2.1: Parsers for both the source language and the target language." ></td>
	<td class="line x" title="76:730	These parsers should be capable of locating relevant syntactic relations, such as subj-verb, verb-obj, etc. Section 2.2: A bilingual lexicon that lists alternative translations for each source language word." ></td>
	<td class="line x" title="77:730	If a word belongs to several syntactic categories, there should be a separate list for each one." ></td>
	<td class="line x" title="78:730	Section 2.3: A procedure for mapping the source language syntactic relations to those of the target language." ></td>
	<td class="line x" title="79:730	Such tools have been implemented within the framework of many computational linguistic theories." ></td>
	<td class="line x" title="80:730	We have used McCord's implementation of Slot Grammars (McCord 1990, 1991)." ></td>
	<td class="line x" title="81:730	However, our method could have proceeded just as well using other linguistic models." ></td>
	<td class="line x" title="82:730	The linguistic model will be illustrated by the following Hebrew example, taken from the Ha-Aretz daily newspaper from September, 1990 (transcripted to Latin letters): (3) Diplomatim svurim ki hitztarrfuto shell Hon Sun magdila diplomats believe that the joining of Hon Sun increases et ha-sikkuyim l-hassagat hitqaddmut ba-sihot." ></td>
	<td class="line x" title="83:730	the-chances for-achieving progress in the-talks Here, the ambiguous words in translation to English are magdila, hitqaddmut, and sihot." ></td>
	<td class="line x" title="84:730	To facilitate the reading, we give the translation of the sentence into English, and in each case of an ambiguous selection, all the alternatives are listed within curly brackets, the first alternative being the correct one." ></td>
	<td class="line x" title="85:730	(4) Diplomats believe that the joining of Hon Sun {increases I enlarges I magnifies} the chances for achieving {progress I advance I advancement} in the {talks I conversations I calls}." ></td>
	<td class="line x" title="86:730	The following subsections describe in detail the processing steps of the linguistic model." ></td>
	<td class="line x" title="87:730	These include locating the ambiguous words and the relevant syntactic relations among them in the source language sentence, mapping these relations to alternative relations in the target language, and finally, counting occurrences of these alternatives in a target language corpus." ></td>
	<td class="line x" title="88:730	2.1 Locating the Ambiguous Words in the Source Language Our model defines the different 'senses' of a source word to be all its possible translations to the target language, as listed in a bilingual lexicon." ></td>
	<td class="line x" title="89:730	Some translations can be eliminated by the syntactic environment of the word in the source language." ></td>
	<td class="line x" title="90:730	For example, in the following two sentences the word 'consider' should be translated 566 Ido Dagan and Alon Itai Word Sense Disambiguation differently into Hebrew, owing to the different subcategorization frame in each case: (5) I consider him smart." ></td>
	<td class="line x" title="91:730	(6) I consider going to Japan." ></td>
	<td class="line x" title="92:730	In these examples, the different syntactic subcategorization frames determine two different translations to Hebrew (mah.shiv versus shoqel), thus eliminating some of the ambiguity." ></td>
	<td class="line x" title="93:730	Such syntactic rules that allow us to resolve some of the ambiguities may be encoded in the lexicon (e.g. , Golan, Lappin, and Rimon 1988)." ></td>
	<td class="line x" title="94:730	However, many ambiguities cannot be resolved on syntactic grounds." ></td>
	<td class="line x" title="95:730	The purpose of this work is to resolve the remaining ambiguities using lexical co-occurrence preferences, obtained by statistical methods." ></td>
	<td class="line x" title="96:730	2.2 Locating Syntactic Tuples in Source Language Sentences Our basic concept is the syntactic tuple, which denotes a syntactic relation between two or more words." ></td>
	<td class="line x" title="97:730	It is denoted by the name of the syntactic relation followed by a sequence of words that satisfies the relation, appearing in their base form (without morphological inflections)." ></td>
	<td class="line x" title="98:730	For example (subj-verb: man walk) is a syntactic tuple, which occurs in the sentence 'The man walked home'." ></td>
	<td class="line x" title="99:730	We assume that our parser (or an auxilliary program) can locate the syntactic relation corresponding to a given syntactic tuple in a sentence." ></td>
	<td class="line x" title="100:730	The use of the base form of words is justified by the additional assumption that morphological inflections do not affect the probability of syntactic tuples." ></td>
	<td class="line x" title="101:730	This assumption is not entirely accurate, but it has proven practically useful and reduces the number of distinct tuples." ></td>
	<td class="line x" title="102:730	In our experience, the following syntactic relations proved useful for resolving ambiguities:  Relations between a verb and its subject, complements, and adjuncts, including direct and indirect objects, adverbs, and modifying prepositional phrases." ></td>
	<td class="line x" title="103:730	 Relations between a noun and its complements and adjuncts, including adjectives, modifying nouns in noun compounds, and modifying prepositional phrases." ></td>
	<td class="line x" title="104:730	 Relations between adjectives or adverbs and their modifiers." ></td>
	<td class="line x" title="105:730	4 As mentioned earlier, the full list of syntactic relations depends on the syntactic theory of the parser." ></td>
	<td class="line x" title="106:730	Our model is general and does not depend on any particular list." ></td>
	<td class="line x" title="107:730	However, we have found some desired properties in defining the relevant syntactic relations." ></td>
	<td class="line x" title="108:730	One such property is the use of deep, or canonical, relations, as was already identified by Grishman, Hirschman, and Nhan (1986)." ></td>
	<td class="line x" title="109:730	This property was directly available from the ESG parser (McCord 1990, 1991), which identifies the underlying syntactic function in constructs such as passives and relative clauses." ></td>
	<td class="line x" title="110:730	We have also implemented an additional routine, which modified or filtered some of the relations received from the parser." ></td>
	<td class="line x" title="111:730	This postprocessing routine dealt mainly with function words and prepositional phrases to get a set of more informative relations." ></td>
	<td class="line x" title="112:730	For example, it combined the subject and complement of the verb 'be' (as in 'the man is happy') into a single relation." ></td>
	<td class="line x" title="113:730	Likewise, a verb with its preposition and the head noun of a modifying prepositional phrase (as in sit on the chair) were also combined." ></td>
	<td class="line x" title="114:730	The routine was designed to choose relations that impose considerable restrictions on the possible 567 Computational Linguistics Volume 20, Number 4 (or probable) syntactic tuples." ></td>
	<td class="line x" title="115:730	On the other hand, these relations should not be too specific, to allow statistically meaningful samples." ></td>
	<td class="line x" title="116:730	The first step in resolving an ambiguity is to find all the syntactic tuples containing the ambiguous words." ></td>
	<td class="line x" title="117:730	For (3) we get the following syntactic tuples: (7)." ></td>
	<td class="line x" title="118:730	2." ></td>
	<td class="line x" title="119:730	3. 4." ></td>
	<td class="line x" title="120:730	(subj-verb: hitztarrfut higdil) (verb-obj: higdil sikkuy) (verb-obj: hissig hitqaddmut) (noun-pp: hitqaddmut bsih.a) (these tuples translate as joining-increase, increase-chance, achieve-progress, and progressin-talks)." ></td>
	<td class="line x" title="121:730	In using these tuples, we expect to capture lexical constraints that are imposed by syntactic relations." ></td>
	<td class="line x" title="122:730	2.3 Mapping Syntactic Tuples to the Target Language The set of syntactic tuples in the source language sentence is reflected in its translation to the target language." ></td>
	<td class="line x" title="123:730	As a syntactic tuple is defined by both its syntactic relation and the words that appear in it, we need to map both components to the target language." ></td>
	<td class="line x" title="124:730	By definition, every ambiguous source language word maps to several target language words." ></td>
	<td class="line x" title="125:730	We thus get several alternative target language tuples for each source language tuple that involves an ambiguous word." ></td>
	<td class="line x" title="126:730	For example, for tuple 3 in (7) we obtain three alternatives, corresponding to the three different translations of the word hitqaddmut." ></td>
	<td class="line x" title="127:730	For tuple 4 we obtain nine alternative target tuples, since each of the words hitqaddmut and siha maps to three different English words." ></td>
	<td class="line x" title="128:730	The full mapping of the Hebrew tuples in (7) to English tuples appears in Table 1 (the rightmost column should be ignored for the moment)." ></td>
	<td class="line x" title="129:730	Each of the tuple sets (a-d) in this table denotes the alternatives for translating the corresponding Hebrew tuple." ></td>
	<td class="line x" title="130:730	From a theoretical point of view, the mapping of syntactic relations is more problematic." ></td>
	<td class="line x" title="131:730	There need not be a one-to-one mapping from source language relations to target language ones." ></td>
	<td class="line x" title="132:730	In many cases the mapping depends on the words of the syntactic tuple, as seen in the following example of translating from German to English." ></td>
	<td class="line x" title="133:730	(8) Der Tisch gefaellt mir.--I like the table." ></td>
	<td class="line x" title="134:730	In this example the source language subject (Tisch) becomes the direct object (table) in the target, whereas the direct object (mir) in the source language becomes the subject (I) in the target." ></td>
	<td class="line x" title="135:730	Therefore, the German syntactic tuples (9) (subj-verb: Tisch gefaellt) (verb-obj: gefaellt mir) are mapped to the following English syntactic tuples (10) (verb-obj: like table) (subj-verb: I like) (The Hebrew equivalent is similar to the German structure)." ></td>
	<td class="line x" title="136:730	In practice this is less of a problem." ></td>
	<td class="line x" title="137:730	In most cases, the source language relation has a direct equivalent in the target language." ></td>
	<td class="line x" title="138:730	In many other cases, transformation rules can be encoded, either in the lexicon (if they are word dependent) or as syntactic transformations." ></td>
	<td class="line x" title="139:730	These rules are usually available in machine translation systems that 568 Ido Dagan and Alon Itai Word Sense Disambiguation Table 1 The alternative target syntactic tuples with their counts in the target language corpus Source Tuples Target Tuples Counts a." ></td>
	<td class="line x" title="140:730	(subj-verb: hitztarrfut higdil) (subj-verb: joining increase) 0 (subj-verb: joining enlarge) 0 (subj-verb: joining magnify) 0 b. C. d." ></td>
	<td class="line x" title="141:730	(verb-obj: higdil sikkuy) (verb-obj: hissig hitqaddmut) (noun-pp: hitqaddmut bsih.a) (verb-obj: increase chance) 20 (verb-obj: enlarge chance) 0 (verb-obj: magnify chance) 0 (verb-obj: achieve progress) 29 (verb-obj: achieve advance) 5 (verb-obj: achieve advancement) 1 (noun-pp: progress in talk) 7 (noun-pp: progress in conversation) 0 (noun-pp: progress in call) 0 (noun-pp: advance in talk) 2 (noun-pp: advance in conversation) 0 (noun-pp: advance in call) 2 (noun-pp: advancement in talk) 0 (noun-pp: advancement in conversation) 0 (noun-pp: advancement in call) 0 use the transfer method, as this knowledge is required to generate target language structures." ></td>
	<td class="line x" title="142:730	To facilitate further the mapping of syntactic relations and to avoid errors due to fine distinctions between them, we grouped related syntactic relations into a single 'general class' and mapped this class to the target language." ></td>
	<td class="line x" title="143:730	The important classes used were relations between a verb and its arguments and modifiers (counting as one class all objects, indirect objects, complements, and nouns in modifying prepositional phrases) and between a noun and its arguments and modifiers (counting as one class all modifying nouns in compounds and nouns in modifying prepositional phrases)." ></td>
	<td class="line x" title="144:730	The classification enables us to get more statistical data for each class, as it reduces the number of relations." ></td>
	<td class="line x" title="145:730	The success of using this general level of syntactic relations indicates that even a rough mapping of source to target language relations is useful for the statistical model." ></td>
	<td class="line x" title="146:730	2.4 Counting Syntactic Tuples in the Target Language Corpus We now wish to determine the plausibility of each alternative target word being the translation of an ambiguous source word." ></td>
	<td class="line x" title="147:730	In our model, the plausibility of selecting a target word is determined by the plausibility of the tuples that are obtained from it." ></td>
	<td class="line x" title="148:730	The plausibility of alternative target tuples is in turn determined by their relative frequency in the corpus." ></td>
	<td class="line x" title="149:730	Target syntactic tuples are identified in the corpus similarly to source language tuples, i.e., by a target language parser and a companion routine as described in Section 2.1." ></td>
	<td class="line x" title="150:730	The right column of Table 1 shows the counts obtained for the syntactic tuples of our example in the corpora we used." ></td>
	<td class="line x" title="151:730	The table reveals that the tuples containing the correct target word ('talk,' 'progress,' and 'increase') are indeed more frequent." ></td>
	<td class="line x" title="152:730	569 Computational Linguistics Volume 20, Number 4 However, we still need a decision algorithm to analyze the statistical significance of the data and choose the appropriate word accordingly." ></td>
	<td class="line x" title="153:730	3." ></td>
	<td class="line x" title="154:730	The Statistical Model As seen in the previous section, the linguistic model maps each source language syntactic tuple to several alternative target tuples, in which each alternative corresponds to a different selection of target words." ></td>
	<td class="line x" title="155:730	We wish to select the most plausible target language word for each ambiguous source language word, basing our decision on the counts obtained from the target corpus, as illustrated in Table 1." ></td>
	<td class="line x" title="156:730	To that end, we should define a selection algorithm whose outcome depends on all the syntactic tuples in the sentence." ></td>
	<td class="line x" title="157:730	If the data obtained from the corpus do not substantially support any one of the alternatives, the algorithm should notify the translation system that it cannot reach a statistically meaningful decision." ></td>
	<td class="line x" title="158:730	Our algorithm is based on a statistical model." ></td>
	<td class="line x" title="159:730	However, we wish to point out that we do not see the statistical considerations, as expressed in the model, as fully reflecting the linguistic considerations (syntactic, semantic, or pragmatic) that determine the correct translation." ></td>
	<td class="line x" title="160:730	The model reflects only part of the relevant data and in addition makes statistical assumptions that are only partially satisfied." ></td>
	<td class="line x" title="161:730	Therefore, a statistically based model need not make the correct linguistic choices." ></td>
	<td class="line x" title="162:730	The performance of the model can only be empirically evaluated, the statistical considerations serve only as heuristics." ></td>
	<td class="line x" title="163:730	The role of the statistical considerations is therefore to guide us in constructing heuristics that make use of the linguistic data of the sample (the corpus)." ></td>
	<td class="line x" title="164:730	Our experience shows that the statistical methods are indeed very helpful in establishing and comparing useful decision criteria that reflect various linguistic considerations." ></td>
	<td class="line x" title="165:730	3.1 The Probabilistic Model First we discuss decisions based on a single syntactic tuple (as when only one syntactic tuple in the sentence contains an ambiguous word)." ></td>
	<td class="line x" title="166:730	Denote the source language syntactic tuple T and let there be k alternative target tuples for T, denoted by T1, , Tk." ></td>
	<td class="line x" title="167:730	Let the counts obtained for the target tuples be nl,." ></td>
	<td class="line x" title="168:730	., nk." ></td>
	<td class="line x" title="169:730	For notational convenience, we number the tuples by decreasing frequency, i.e., nl ~ y/2 ~ ''' ~ nkSince our goal is to choose for T one of the target tuples Ti, we can consider T a discrete random variable with multinomial distribution, 3 whose possible values are T1,, Tk." ></td>
	<td class="line x" title="170:730	Let Pi be the probability of obtaining Ti, i.e., the probability that Ti is the correct translation for T. We estimate the probabilities Pi by the counts ni in the obvious way, using the maximum likelihood estimator (Agresti 1990, pp." ></td>
	<td class="line x" title="171:730	40-41)." ></td>
	<td class="line x" title="172:730	The estimator \]9i for Pi is Hi /~i -k ' (1) Y~q=l nj The precision of the estimator depends, of course, on the size of the counts in the computation." ></td>
	<td class="line x" title="173:730	We will incorporate this consideration into the decision algorithm by using confidence intervals." ></td>
	<td class="line x" title="174:730	4 3 A variable that can have one of a finite set of values, each of them having a fixed probability." ></td>
	<td class="line x" title="175:730	4 The maximum likelihood estimator is known to give poor estimates when small counts are involved, and there are several methods to improve it (see Church and Gale 1991, for a presentation and discussion of several methods)." ></td>
	<td class="line x" title="176:730	For our needs this is not necessary in most cases, since we are not going to use the estimate itself, but rather a confidence interval for the ratio between two estimations (see below)." ></td>
	<td class="line x" title="177:730	570 Ido Dagan and Alon Itai Word Sense Disambiguation We now have to establish the criterion for choosing the preferred target language syntactic tuple." ></td>
	<td class="line x" title="178:730	The most reasonable assumption is to choose the tuple with the highest estimated probability, that is Tl--the tuple with the largest observed frequency." ></td>
	<td class="line x" title="179:730	According to the model, the probability that T1 is the right choice is estimated as Pl. This criterion should be subject to the condition that the difference between the alternative probabilities is significant." ></td>
	<td class="line x" title="180:730	For example, if/Yl = 0.51 and/52 = 0.49, the expected success rate in choosing T1 is approximately 0.5." ></td>
	<td class="line x" title="181:730	To prevent the system from making a decision in such cases, we need to impose some conditions on the probabilities Pi." ></td>
	<td class="line x" title="182:730	One possible such condition is that \]Jl exceeds a prespecified threshold (or, as we shall describe below, that the threshold requirement be applied to a confidence interval)." ></td>
	<td class="line x" title="183:730	According to the model, this requirement ensures that the success probability of every decision exceeds the threshold." ></td>
	<td class="line x" title="184:730	Even though this method satisfies the probabilistic model, it is vulnerable to noise in the data, which often causes some relatively small counts to be larger than their true value in the sample." ></td>
	<td class="line x" title="185:730	The noise is introduced in part by inaccuracies in the model and in part because of errors during the automatic collection of the statistical data." ></td>
	<td class="line x" title="186:730	Consequently, the estimated value of Pl may be smaller than its true value, because other counts in Equation 1 are too large, thus, preventing Pl from passing the threshold." ></td>
	<td class="line x" title="187:730	To deal with this problem, we have chosen another criterion for significance--the odds ratio." ></td>
	<td class="line x" title="188:730	We choose the alternative T1 only if all the ratios r;2' exceed a prespecified threshold." ></td>
	<td class="line x" title="189:730	Note that 15i/lfij -ni/nj, and since nl _~ n2 _)  ~_ nk, the ratio tYl/lY2 is less than or equal to all the other ratios." ></td>
	<td class="line x" title="190:730	Therefore, it suffices to check the odds ratio only for ill/P2." ></td>
	<td class="line x" title="191:730	This criterion is less sensitive to noise of the above-mentioned type than/)1, since it depends only on the two largest counts." ></td>
	<td class="line x" title="192:730	3.1.1 Underlying Assumptions." ></td>
	<td class="line x" title="193:730	The use of a probabilistic model necessarily introduces several assumptions on the structure of the corresponding linguistic data." ></td>
	<td class="line x" title="194:730	It is important to point out these assumptions, in order to be aware of possible inconsistencies between the model and the linguistic phenomena for which it is used." ></td>
	<td class="line x" title="195:730	The first assumption is introduced by the use of a multinomial model, which presupposes the following: Assumption 1 The events Ti are mutually disjoint." ></td>
	<td class="line x" title="196:730	This assumption is not entirely valid, since sometimes it is possible to translate a source language word to several target language words, such that all the translations are valid." ></td>
	<td class="line x" title="197:730	For example, consider the Hebrew sentence (from the Ha-Aretz daily newspaper, November 27, 1990) whose English translation is (11) The resignation of Thatcher is not {related I connected} to the negotiations with Damascus." ></td>
	<td class="line x" title="198:730	In this sentence (but not in others), the ambiguous word qshura can equally well be translated to either 'related' or 'connected'." ></td>
	<td class="line x" title="199:730	In terms of the probabilistic model, the two corresponding events, i.e., the two alternative English tuples that contain these words, T1 -(verb-comp: relate to negotiation) and T2 = (verb-comp: connect to negotiation) are 571 Computational Linguistics Volume 20, Number 4 both correct, thus the events T1 and T2 both occur (they are not disjoint)." ></td>
	<td class="line x" title="200:730	However, we have to make this assumption, since the counts we have, ni, from which we estimate the probabilities of the Ti values, count actual occurrences of single syntactic tuples." ></td>
	<td class="line x" title="201:730	In other words, we count the number of times that each of Zl and T2 actually occur, not the number of times in which each of them could occur." ></td>
	<td class="line x" title="202:730	Two additional assumptions are introduced by using counts of the occurrences of syntactic tuples of the target language in order to estimate the translation probabilities of source language tuples: Assumption 2 An occurrence of the source language syntactic tuple T can indeed be translated to one of Zl~~ Tk." ></td>
	<td class="line x" title="203:730	Assumption 3 Every occurrence of the target tuple Ti can be the translation of only the source tuple T. Assumption 2 is an assumption on the completeness of the linguistic model." ></td>
	<td class="line x" title="204:730	It is rather reasonable and depends on the completeness of our bilingual lexicon: if the lexicon gives all possible translations of each ambiguous word, then this assumption will hold, since for each syntactic tuple T we will produce all possible translations3 Assumption 3, which may be viewed as a soundness assumption, does not always hold, since a target language word may be the translation of several source language words." ></td>
	<td class="line x" title="205:730	Consider, for example, the Hebrew tuple T = (verb-obj: heh.ziq lul)." ></td>
	<td class="line x" title="206:730	Lul is ambiguous, meaning either a playpen or a chicken pen." ></td>
	<td class="line x" title="207:730	Accordingly, T can be translated to either T1 = (verb-obj: hold playpen) or T2 = (verb-obj: hold pen)." ></td>
	<td class="line x" title="208:730	In the context of 'hold' the first translation is more likely, and we can therefore expect our model to prefer T1." ></td>
	<td class="line x" title="209:730	However, this might not be the case because Assumption 3 is contradicted." ></td>
	<td class="line x" title="210:730	'Pen' can also be the translation of the Hebrew word 'et (the writing instrument), and thus T2 can be the translation of another Hebrew tuple, T' = (verb~bj: heh.ziq 'et)." ></td>
	<td class="line x" title="211:730	This means that when translating T we are counting occurrences of T2 that correspond to both T and T', 'misleading' the selection criterion." ></td>
	<td class="line x" title="212:730	Section 6.3 illustrates another example in which the assumption is not valid, causing the algorithm to fail to select the correct translation." ></td>
	<td class="line x" title="213:730	We must make this assumption since we use only a target language corpus, which is not related to any source language information." ></td>
	<td class="line x" title="214:730	6 Therefore, when seeing an occurrence of the target language word w, we do not know which source language word is appropriate in the current context." ></td>
	<td class="line x" title="215:730	Consequently, we count its occurrence as a translation of all the source language words for which w is a possible translation." ></td>
	<td class="line x" title="216:730	This implies that sometimes we use inaccurate data, which introduce noise into the statistical model (see Section 6.3 for a discussion of an alternative, but expensive, solution, using a bilingual corpus)." ></td>
	<td class="line x" title="217:730	As we shall see, even though the assumption does not always hold, in most cases this noise does not interfere with the decision algorithm." ></td>
	<td class="line x" title="218:730	5 The problem of constructing a bilingual lexicon that is as complete as possible is beyond the scope of this paper." ></td>
	<td class="line x" title="219:730	A promising approach may be to use aligned bilingual corpora, especially for augmenting existing lexicons with domain-specific terminology (Brown et al. 1993; Dagan, Church, and Gale 1993)." ></td>
	<td class="line x" title="220:730	In any case, it seems that any translation system is limited by the completeness of its bilingual lexicon, which makes our assumption a reasonable one." ></td>
	<td class="line x" title="221:730	6 As explained in the introduction, this is a very important advantage of our method over other methods that use bilingual corpora." ></td>
	<td class="line x" title="222:730	572 Ido Dagan and Alon Itai Word Sense Disambiguation 3.2 Statistical Significance of the Decision Another problem we should address is the statistical significance of the data--what confidence do we have that the data indeed reflect the phenomenon." ></td>
	<td class="line x" title="223:730	If the decision is based on small counts, then the difference in the counts might be due to chance." ></td>
	<td class="line x" title="224:730	For example, we should have more confidence in the odds ratio 151/152 = 3 when nl = 30 and //2 = 10 than when nl = 3 and n2 = 1." ></td>
	<td class="line x" title="225:730	Consequently, we shall use a dynamic threshold for 151/152, which is large when the counts are small and decreases as the counts increase." ></td>
	<td class="line x" title="226:730	A common method for determining the statistical significance of estimates is the use of confidence intervals." ></td>
	<td class="line x" title="227:730	Rather than finding a confidence interval for 151/152, we will bound the log odds ratio, ln(151/152)." ></td>
	<td class="line x" title="228:730	Since the variance Of the log odds ratio is independent of the mean, it converges to the normal distribution faster than the odds ratio itself (Agresti 1990)." ></td>
	<td class="line x" title="229:730	We use a one-tailed interval, as we want only to decide whether ln(151/152) is greater than a specific threshold (i.e. , we need only a lower bound for ln(151/152))." ></td>
	<td class="line x" title="230:730	Using this method, for each desired error probability 0 < ~ < 1, we may determine a value B~ and state that with a probability of at least 1 c~ the true value, ln(pl/p2), is greater than B~." ></td>
	<td class="line x" title="231:730	The confidence interval of a random variable X with normal distribution is ZI-~, where ZI-~ is the confidence coefficient, which may be found in statistical tables, and var is the variance." ></td>
	<td class="line x" title="232:730	In our case, the size of the confidence interval is Z1-~/var\[ln~221' In the appendix we approximate the variance by the following \[ ~22\] 1 1 var in 151 ~ __ _}_ --." ></td>
	<td class="line x" title="233:730	//1 //2 The bound we get is thus 151 //1 Since ~ //2 we get ln(P~2 ) >ln(pP-~)-Zl-~V~n~ + 1 //2 ln/P~) ~>ln/n,~-~)-Zl-c,V/n~+ 1 //2 ;o (2) B~(nl,n2) (or B~ when nl and n2 are understood from the context) is defined to be the right-hand side of Equation 2." ></td>
	<td class="line x" title="234:730	The meaning of the inequality is that for every given pair nl~ n2 we know with confidence 1 c~ that In pl ~ B~ (3) P2 or in other words, B,~ is a lower bound for ln(pl/P2) with this confidence level." ></td>
	<td class="line x" title="235:730	To obtain a decision criterion, we choose a threshold 0, for B~, and decide to choose T1 only if B~ > 0." ></td>
	<td class="line x" title="236:730	(4) 573 Computational Linguistics Volume 20, Number 4 If Equation 4 does not hold, the algorithm makes no decision." ></td>
	<td class="line x" title="237:730	The meaning of this criterion is that only if we know with confidence of at least 1 ~ that ln(pl/p2) > O, will we select the most frequent tuple T1 as the appropriate one." ></td>
	<td class="line x" title="238:730	In terms of statistical decision theory, we say that our null hypothesis is that ln(pl/P2) < 0, and we will make a decision only if we can reject this hypothesis with confidence at least 1 ~." ></td>
	<td class="line x" title="239:730	Note that we cannot compute B~ when one of the counts is zero." ></td>
	<td class="line x" title="240:730	In this case we have used the common correction method of adding 0.5 to each of the counts (Agresti 1990, p. 249)." ></td>
	<td class="line x" title="241:730	7 We shall now demonstrate the use of the decision criterion." ></td>
	<td class="line x" title="242:730	In the experiment we conducted we chose the parameters ~ = 0.1, for which Z~ = 1.282, and 0 = 0.2." ></td>
	<td class="line x" title="243:730	Thus, to choose T1 we require that with confidence level of at least 90% the hypothesis should satisfy ln(pl/P2) > 0.2 (i.e. , Pl/P2 >_ e 02 = 1.22)." ></td>
	<td class="line x" title="244:730	For the alternative translations of tuple c in Table 1 we got nl = 29 and n2 = 5." ></td>
	<td class="line x" title="245:730	For these values Be = 1.137." ></td>
	<td class="line x" title="246:730	In this case Equation 4 is satisfied for 0 = 0.2, and the algorithm selects the word 'progress' as the translation of the Hebrew word hitqaddmut." ></td>
	<td class="line x" title="247:730	In another case we had to translate the Hebrew word ro'sh, which can be translated to either 'top' or 'head,' in the sentence whose translation is (12) Sihanuk stood at the {top \] head} of a coalition of underground groups." ></td>
	<td class="line x" title="248:730	The two alternative syntactic tuples were (a) (verb-pp: standat head) 10 (b) (verb-pp: stand at top) 5 For nl = 10 and n2 = 5, we get Be = -0.009 (a negative value means that it is impossible to ensure with a 90% confidence level that Pl > P2)." ></td>
	<td class="line x" title="249:730	Since Be G 0.2, the algorithm will refrain from making a decision in this case." ></td>
	<td class="line x" title="250:730	This abstention reflects the fact that the difference between the counts is not statistically significant, and choosing the first alternative can be wrong in many of the cases (as seen in the five cases that were observed in the corpus)." ></td>
	<td class="line x" title="251:730	As mentioned above, our motivation was to find a criterion that depends on a dynamic threshold for ~1/\]Y2 (or alternatively nl/n2), so that the threshold will be higher when nl and n2 are smaller." ></td>
	<td class="line x" title="252:730	Our criterion indeed satisfies this requirement." ></td>
	<td class="line x" title="253:730	If we substitute B~ in Equation 4, we get the following equivalent criterion: In nl > 0 + Zl_c~/n~ q1 //2 //2 The above inequality clarifies the roles of the two parameters, ~ and 0:0 specifies a lower bound on In(nl/n2), which is independent of the sample size; c~ reflects the statistical significance." ></td>
	<td class="line x" title="254:730	If c~ is decreased (i.e. , we require more confidence), ZI_~ will increase, and therefore, the component dependent on the sample size will increase." ></td>
	<td class="line x" title="255:730	Since this component is in inverse relation to nl and n2, the penalty for decreasing c~ increases when the sample size decreases." ></td>
	<td class="line x" title="256:730	From this analysis we can derive the criterion for choosing the parameters: if we wish to use small counts, then c~ should be small, and 0 depends on the required ratio between nl and n2." ></td>
	<td class="line x" title="257:730	The optimal values of the parameters should be determined empirically and might depend on the corpora and parsers we use." ></td>
	<td class="line x" title="258:730	7 In this case, smoothing methods (Church and Gale 1991) may improve the correction method." ></td>
	<td class="line x" title="259:730	574 Ido Dagan and Alon Itai Word Sense Disambiguation 3.3 Sentences with Several Syntactic Relations In the previous section, we assumed that the source sentence contains only one ambiguous syntactic tuple." ></td>
	<td class="line x" title="260:730	In general there may be several ambiguous words that appear in several tuples." ></td>
	<td class="line x" title="261:730	We should take advantage of the occurrence patterns of all of the tuples to reach a decision." ></td>
	<td class="line x" title="262:730	Since different relations may favor different translations for an ambiguous word, we should devise a strategy for selecting a consistent translation for all words in the sentence." ></td>
	<td class="line x" title="263:730	We have used the following constraint propagation algorithm, which receives as input the list of all source tuples along with their alternative translations to target tuples: . . ." ></td>
	<td class="line x" title="264:730	Compute B~ of each source tuple." ></td>
	<td class="line x" title="265:730	If the largest B~ is less than the threshold, 8, then stop." ></td>
	<td class="line x" title="266:730	Let T be the source tuple for which B~ is maximal." ></td>
	<td class="line x" title="267:730	Select the translation for the ambiguous words (or word) in T according to T1 (the most frequent target alternative for T)." ></td>
	<td class="line x" title="268:730	Remove T from the list of source tuples." ></td>
	<td class="line x" title="269:730	Propagate the constraint: eliminate target tuples that are inconsistent with this decision." ></td>
	<td class="line x" title="270:730	If now some source tuples become unambiguous, remove them from the list of source tuples." ></td>
	<td class="line x" title="271:730	Repeat this procedure for the remaining list of source tuples, until all ambiguities have been resolved, or the maximal B~ is less than 8." ></td>
	<td class="line x" title="272:730	To illustrate the algorithm, we consider Table 1 using the parameters c~ = 0.1 and 0 = 0.2." ></td>
	<td class="line x" title="273:730	The largest value of B~ occurs for the tuple (verb-obj: higdil sikkuy), for which higdil can be translated to ;increase,' 'magnify,' or 'enlarge'." ></td>
	<td class="line x" title="274:730	The first alternative appeared nl = 20 times, and the other alternatives did not appear at all, (n2 = n3 = 0)." ></td>
	<td class="line x" title="275:730	Adding the correction factor and computing B~ yields B~(nl + 0.5~n2 q-0.5) = B,~(20.5, 0.5) = 1.879 > 0.2 = 8." ></td>
	<td class="line x" title="276:730	Therefore, the word 'increase' was chosen as the translation of higdil." ></td>
	<td class="line x" title="277:730	Since this word appears also in the tuple (subj-verb: hitztarrfut higdil), the' target tuples that include alternative translations of higdil were deleted." ></td>
	<td class="line x" title="278:730	Thus (13) (subj-verb: joining enlarge) (subj-verb: joining magnify) were deleted." ></td>
	<td class="line x" title="279:730	This leaves us with only one alternative (subj-verb: joining increase) as a possible translation of this Hebrew tuple, which is therefore removed from the input list." ></td>
	<td class="line x" title="280:730	We now recompute the values of B~ for the remaining tuples." ></td>
	<td class="line x" title="281:730	The maximal value is obtained for the tuple (14) (verb-obj: hissig hitqaddmut) where B~ (29, 5) = 1.137 > 8." ></td>
	<td class="line x" title="282:730	We, therefore, choose the word 'progress' as a translation for hitqaddmut." ></td>
	<td class="line x" title="283:730	Since this word, hitqaddmut, also appears in the tuple (noun-pp: hitqaddmut bsih.a), we delete the Six target tuples that are inconsistent with the selection of 'progress' (those containing the words 'advance' and 'advancement')." ></td>
	<td class="line x" title="284:730	There now remain only three alternative target tuples for hitqaddmut bsih.a. We now recompute the values of B~." ></td>
	<td class="line x" title="285:730	The maximum value is B~ (7.5~ 0.5) = 0.836 > 0 (note that because tuples inconsistent with the previous decisions were eliminated, 575 Computational Linguistics Volume 20, Number 4 n2 dropped from 2 to 0, thus increasing B~)." ></td>
	<td class="line x" title="286:730	Thus, 'talk' is selected as the translation of siha." ></td>
	<td class="line x" title="287:730	Now all the ambiguities have been resolved and the procedure stops." ></td>
	<td class="line x" title="288:730	In the above example all the ambiguities were resolved since in each stage the value of B~ exceeded the threshold 0 = 0.2." ></td>
	<td class="line x" title="289:730	In some cases not all ambiguities are resolved, though the number of ambiguities may decrease." ></td>
	<td class="line x" title="290:730	It should be noted that other methods may be proposed for combining the statistics of several syntactic relations." ></td>
	<td class="line x" title="291:730	For example, it may make sense to multiply estimates of conditional probabilities of tuples in different relations, in a way that is analogous to n-gram language modeling (Jelinek, Mercer, and Roukos 1992)." ></td>
	<td class="line x" title="292:730	However, such an approach will make it harder to take into account the statistical significance of the estimate (a criterion that is missing in standard n-gram models)." ></td>
	<td class="line x" title="293:730	In our set of examples, the constraint propagation method proved to be successful and did not seem to introduce any errors." ></td>
	<td class="line x" title="294:730	Further experimentation, on much larger data sets, is needed to determine which of the two methods (if any) is substantially superior to the other." ></td>
	<td class="line x" title="295:730	4." ></td>
	<td class="line x" title="296:730	The Experiment To evaluate the proposed disambiguation method, we implemented and tested the method on a random set of examples." ></td>
	<td class="line x" title="297:730	The examples consisted of a set of Hebrew paragraphs and a set of German paragraphs." ></td>
	<td class="line x" title="298:730	In both cases the target language was English." ></td>
	<td class="line x" title="299:730	The Hebrew examples consisted of ten paragraphs picked at random from foreign news sections of the Israeli press." ></td>
	<td class="line x" title="300:730	The paragraphs were selected from several news items and articles that appeared in several daily newspapers." ></td>
	<td class="line x" title="301:730	The target language corpus consisted of American newspaper articles, and the Hansard corpus of the proceedings of the Canadian Parliament." ></td>
	<td class="line x" title="302:730	The domain of foreign news articles was chosen to correspond to some of the topics that appear in the English corpus, s The German examples were chosen at random from the German press, without restricting the topic." ></td>
	<td class="line x" title="303:730	9 Since we did not have a translation system from Hebrew or German to English, we simulated the steps such a system would perform." ></td>
	<td class="line x" title="304:730	Hence, the results we report measure the performance of just the target word selection module and not the performance of a complete translation system." ></td>
	<td class="line x" title="305:730	The latter can be expected to be somewhat lower for a real system, depending on the performance of its other components." ></td>
	<td class="line x" title="306:730	Note, however, that since the disambiguation module is highly immune to noise, it might be more useful in a real system: in such a system some of the alternatives would be totally erroneous." ></td>
	<td class="line x" title="307:730	Since the corresponding syntactic tuples would typically not be found in the corpora, they would be eliminated by our module." ></td>
	<td class="line x" title="308:730	The experiment is described in detail in the following subsections." ></td>
	<td class="line x" title="309:730	It provides an example for a thorough evaluation that is carried out without having a complete system available." ></td>
	<td class="line x" title="310:730	We specifically describe the processing of the Hebrew data, which was performed by a professional translator, supervised by the authors." ></td>
	<td class="line x" title="311:730	The German examples were processed very similarly." ></td>
	<td class="line x" title="312:730	4.1 Locating Ambiguous Words To locate ambiguous words, we simulated a bilingual lexicon and syntactic filters of a translation system." ></td>
	<td class="line x" title="313:730	For every source language word, the translator searched all possible 8 The corpus includes many irrelevant topics as well, which introduce noisy data with respect to the given domain." ></td>
	<td class="line x" title="314:730	9 The German examples were prepared by Ulrike Schwall from the IBM Scientific Center, Heidelberg, Germany." ></td>
	<td class="line x" title="315:730	576 Ido Dagan and Alon Itai Word Sense Disambiguation translations using a Hebrew-English dictionary (Alcalay 1990)." ></td>
	<td class="line x" title="316:730	The list of translations proposed by the dictionary was modified according to the following guidelines, to reflect better the lexicon of a practical translation system: . . 3." ></td>
	<td class="line x" title="317:730	. . Eliminate translations that would be ruled out for syntactic reasons, as explained in Section 2.1." ></td>
	<td class="line x" title="318:730	Consider only content words, ignoring function words and proper nouns." ></td>
	<td class="line x" title="319:730	Assume that multi-word terms, such as 'prime minister,' appear in the lexicon as complete terms." ></td>
	<td class="line x" title="320:730	Thus we did not consider each of their constituents separately." ></td>
	<td class="line x" title="321:730	Also, we did not consider source language words that should be translated to a multi-word target phrase." ></td>
	<td class="line x" title="322:730	Eliminate rare and archaic translations that are not expected in the context of foreign affairs in the current press." ></td>
	<td class="line x" title="323:730	The professional translator added translations that were missing in the dictionary." ></td>
	<td class="line x" title="324:730	In addition, each of the remaining target alternatives for each source word was evaluated as to whether it is a suitable translation in the current context." ></td>
	<td class="line x" title="325:730	This evaluation was later used to judge the selections of the algorithm." ></td>
	<td class="line x" title="326:730	If all the alternatives were considered suitable, then the source word was eliminated from the test set, since any decision for it would have been considered successful." ></td>
	<td class="line x" title="327:730	We ended up with 103 Hebrew and 54 German ambiguous words." ></td>
	<td class="line x" title="328:730	For each Hebrew word we had an average of 3.27 alternative translations and an average of 1.44 correct translations." ></td>
	<td class="line x" title="329:730	The average number of translations of a German word was 3.26, and there were 1.33 correct translations." ></td>
	<td class="line x" title="330:730	4.2 Determining the Syntactic Tuples and Mapping Them to English Since we did not have a Hebrew parser, we have simulated the two steps of determining the source syntactic tuples and mapping them to English by reversing the order of these steps, in the following way: First, the sample sentences were translated manually, as literally as possible, into English." ></td>
	<td class="line x" title="331:730	Then, the resulting English sentences were analyzed, using the ESG parser and the postprocessing routine (see Section 2.2), to identify the relevant syntactic tuples." ></td>
	<td class="line x" title="332:730	The tuples were further classified into 'general classes,' as described in Section 2.3." ></td>
	<td class="line x" title="333:730	The use of these general classes, which was intended to facilitate the mapping of syntactic relations from one language to another, also facilitated our simulation method and caused it to produce realistic output." ></td>
	<td class="line x" title="334:730	At the end of the procedure, we had, for each sample sentence, a data structure similar to Table 1 (without the counts)." ></td>
	<td class="line x" title="335:730	4.3 Acquiring the Statistical Data The statistical data were acquired from the following corpora:  Texts from The Washington Post ~0 million words." ></td>
	<td class="line x" title="336:730	 The Hansard corpus of protocols of the Canadian Parliament--85 million words." ></td>
	<td class="line x" title="337:730	 Associated Press news items--24 million words." ></td>
	<td class="line x" title="338:730	577 Computational Linguistics Volume 20, Number 4 However, the effective size of the corpora was only about 25 million words, owing to two filtering criteria." ></td>
	<td class="line x" title="339:730	First, we considered only sentences whose length did not exceed 25 words, since longer sentences required excessive parse time and contained many parsing errors." ></td>
	<td class="line x" title="340:730	Second, even 35% of the shorter sentences failed to parse and had to be eliminated." ></td>
	<td class="line x" title="341:730	The syntactic tuples were located by the ESG parser and the postprocessing routine mentioned earlier." ></td>
	<td class="line x" title="342:730	For the purpose of evaluation, we gathered only the data required for the given test examples." ></td>
	<td class="line x" title="343:730	Within a practical machine translation system, the disambiguation module would require a database containing all the syntactic tuples of the corpus with their frequency counts." ></td>
	<td class="line x" title="344:730	In the current research project we did not have the computing resources necessary for constructing the complete database (the major cost being parsing time)." ></td>
	<td class="line x" title="345:730	However, such resources are not needed in order to evaluate the proposed method." ></td>
	<td class="line x" title="346:730	Since we evaluated the method only on a relatively small number of random sentences, we first constructed the set of all 'relevant' target tuples, i.e., tuples that should be considered for the test sentences." ></td>
	<td class="line x" title="347:730	Then we scanned the entire corpus and extracted only sentences that contain both words from at least one of the relevant tuples." ></td>
	<td class="line x" title="348:730	Only the extracted sentences were parsed, and their counts were recorded in our database." ></td>
	<td class="line x" title="349:730	Even though this database is much smaller than the full database, for the ambiguous words of the test sentences, both databases provide the same information." ></td>
	<td class="line x" title="350:730	Thus, the success rate for the test sentences is the same for both methods, while requiring a considerably smaller amount of resources at the research phase." ></td>
	<td class="line x" title="351:730	The problem with this method is that for every set of sample sentences the entire corpus has to be scanned." ></td>
	<td class="line x" title="352:730	Thus, a practical system would have to preprocess the corpus to construct a database of the entire corpus." ></td>
	<td class="line x" title="353:730	Then, to resolve ambiguities, only this database need be consulted." ></td>
	<td class="line x" title="354:730	After acquiring all the relevant data, the algorithm of Section 3.3 was executed for each of the test sentences." ></td>
	<td class="line x" title="355:730	5." ></td>
	<td class="line x" title="356:730	Evaluation Two measurements, applicability and precision, are used to evaluate the performance of the algorithm." ></td>
	<td class="line x" title="357:730	The applicability (coverage) denotes the proportion of cases for which the model performed a selection, i.e., those cases for which the bound B~ passed the threshold." ></td>
	<td class="line x" title="358:730	The precision denotes the proportion of cases for which the model performed a correct selection out of all the applicable cases." ></td>
	<td class="line x" title="359:730	We compare the precision of our method, which we term TWS (for Target Word Selection), with that of the Word Frequencies procedure, which always selects the most frequent target word." ></td>
	<td class="line x" title="360:730	In other words, the Word Frequencies method prefers the alternative that has the highest a priori probability of appearing in the target language corpus." ></td>
	<td class="line x" title="361:730	This naive 'straw-man' is less sophisticated than other methods suggested in the literature, but it is useful as a common benchmark since it can be easily implemented." ></td>
	<td class="line x" title="362:730	The success rate of the Word Frequencies procedure can serve as a measure for the degree of lexical ambiguity in a given set of examples, and thus different methods can be partly compared by their degree of success relative to this procedure." ></td>
	<td class="line x" title="363:730	Out of the 103 ambiguous Hebrew words, for 33 the bound B~ did not pass the threshold, achieving an applicability of 68%." ></td>
	<td class="line x" title="364:730	The remaining 70 examples were distributed according to Table 2." ></td>
	<td class="line x" title="365:730	Thus the precision of the statistical model was 91% 578 Ido Dagan and Alon Itai Word Sense Disambiguation Table 2 Hebrew-English translation: Comparison of TWS and Word Frequencies methods for the 70 applicable examples Word Frequencies Correct Incorrect Total Correct 42 22 64 TWS Incorrect 2 4 6 Total 44 26 70 (64/70), 1 whereas relying just on Word Frequencies yields 63% (44/70), providing an improvement of 28%." ></td>
	<td class="line x" title="366:730	The table demonstrates that our algorithm corrects 22 erroneous decisions of the Word Frequencies method, but makes only 2 errors that the Word Frequencies method translates correctly." ></td>
	<td class="line x" title="367:730	This implies that with high confidence our method greatly improves the Word Frequencies method." ></td>
	<td class="line x" title="368:730	The number of Hebrew examples is large enough to permit a meaningful analysis of the statistical significance of the results." ></td>
	<td class="line x" title="369:730	By computing confidence intervals for the distribution of proportions, we claim that with 95% confidence our method succeeds in at least 86% of the applicable examples." ></td>
	<td class="line x" title="370:730	This means that though the figure of 91% might be due to a lucky selection of the random examples, there is only a 5% chance that the real figure is less than 86% (for the given domain and corpus)." ></td>
	<td class="line x" title="371:730	The confidence interval was computed as follows: p~f~_Zl_c~f~) 64 f-~4 . 6 -70 1'65V 7-7-07 0'86' where a = 0.05 and the variance is estimated by \]~(1 f))/n. With the same confidence, our method improves the Word Frequencies method by at least 18% (relative to the actual improvement of 28% in the given test set)." ></td>
	<td class="line x" title="372:730	Let Pl be the proportion of cases for which our method succeeds and the Word Frequencies method fails (Pl = 22/70) and P2 be the proportion of cases for which the Word Frequencies method succeeds and ours fails (P2 = 2/70)." ></td>
	<td class="line x" title="373:730	The confidence interval is for the difference of proportions in multinomial distribution and is computed as follows: Pl -P2 (-lYl -P2 -Zl-o~ v/var(151 152) = ~1 -/~2 Zl_c~ --~ V/~t (1 ~t) + ~2(1 ~2) + 2~1~2 22 2 65 1 4/22." ></td>
	<td class="line x" title="374:730	(70-22)+2.(70-2)+2.22.2 =0.18." ></td>
	<td class="line x" title="375:730	70 70 1." ></td>
	<td class="line x" title="376:730	~V 702 Out of the 54 ambiguous German words, for 27 the bound B~ did not pass the threshold (applicability of 50%)." ></td>
	<td class="line x" title="377:730	The remaining 27 examples were distributed according to Table 3." ></td>
	<td class="line x" title="378:730	Thus, the precision of the statistical model was 78% (21/27), whereas 10 An a posteriori observation showed that in three of the six errors the selection of the model was actually acceptable, and the a priori judgment of the human translator was too restrictive." ></td>
	<td class="line x" title="379:730	For example, in one of these cases the statistics selected the expression 'to begin the talks,' whereas the human translator regarded this expression as incorrect and selected 'to start the talks'." ></td>
	<td class="line x" title="380:730	If we consider these cases as correct, then there are only three selection errors, getting 96% precision." ></td>
	<td class="line x" title="381:730	579 Computational Linguistics Volume 20, Number 4 Table 3 German-English translation: Comparison of TWS and Word Frequencies methods for the 27 applicable examples Word Frequencies Correct Incorrect Total Correct 15 6 21 TWS Incorrect 0 6 6 Total 15 12 27 relying just on Word Frequencies yields 56% (15/27)." ></td>
	<td class="line x" title="382:730	Here our method corrected 6 errors of the Word Frequencies method, without causing any new errors." ></td>
	<td class="line x" title="383:730	We attribute the lower success rate for the German examples to the fact that they were not restricted to topics that are well represented in the corpus." ></td>
	<td class="line x" title="384:730	This poor correspondence between the training and testing texts is reflected also by the low precision of the Word Frequencies method." ></td>
	<td class="line x" title="385:730	This means that the a priori probability of the target words, as estimated from the training corpora, provides a very poor prediction of the correct selection in the test examples." ></td>
	<td class="line x" title="386:730	Relative to the a priori probability, the precision of our method is still 22% higher." ></td>
	<td class="line x" title="387:730	5.1 Additional Results Recently, Dagan, Marcus, and Markovitch have implemented a variant of the disambiguation method of the current paper." ></td>
	<td class="line x" title="388:730	This variant was developed for evaluating a method that estimates the probability of word combinations which do not occur in the training corpus (Dagan, Marcus, and Markovitch 1993)." ></td>
	<td class="line x" title="389:730	In this section we quote their results, providing additional evidence for the effectiveness of the TWS method." ></td>
	<td class="line x" title="390:730	The major difference between the TWS method, as presented in this paper, and the variant described by Dagan, Marcus, and Markovitch (1993), which we term TWS ~, is that the latter does not use any parsing for collecting the statistics from the corpus." ></td>
	<td class="line x" title="391:730	Instead, the counts of syntactic tuples are approximated by counting co-occurrences of the given words of the tuple within a short distance in a sentence." ></td>
	<td class="line x" title="392:730	The approximation takes into account the relative order between the words of the tuple, such that occurrences of a certain syntactic relation are approximated only by word co-occurrences that preserve the most frequent word order for that relation (e.g. , an adjective precedes the noun it modifies)." ></td>
	<td class="line x" title="393:730	The TWS ~ method still assumes that the source sentence to be translated is being parsed, in order to identify the words that are syntactically related to an ambiguous word." ></td>
	<td class="line x" title="394:730	This model is therefore relevant for translation systems that use a parser for the source language, but may not have available a robust target language parser." ></td>
	<td class="line x" title="395:730	The corpus used for evaluating the TWS' method consists of articles posted to the USENET news system." ></td>
	<td class="line x" title="396:730	The articles were collected from news groups that discuss computer-related topics." ></td>
	<td class="line x" title="397:730	The length of the corpus is 8,871,125 words (tokens), and the lexicon size (distinct types, at the string level) is 95,559." ></td>
	<td class="line x" title="398:730	The type of text in this corpus is quite noisy, including short and incomplete sentences as well as much irrelevant information, such as person and device names." ></td>
	<td class="line x" title="399:730	The test set used for the experiment consists of 78 Hebrew sentences that were taken out of a book about computers." ></td>
	<td class="line x" title="400:730	These sentences were processed as described in Section 4, obtaining a set of 269 ambiguous Hebrew words." ></td>
	<td class="line x" title="401:730	The average number of alternative translations per ambiguous word in this set is 5.8, and there are 1.35 correct translations." ></td>
	<td class="line x" title="402:730	580 Ido Dagan and Alon Itai Word Sense Disambiguation Table 4 Comparison of TWS' and Word Frequencies methods for the 173 applicable examples Word Frequencies correct incorrect Total correct 120 28 148 TWS' incorrect 3 22 25 Total 123 50 173 Out of the 269 ambiguous Hebrew words, for 96 the bound B~ did not pass the threshold, achieving an applicability of 64.3%." ></td>
	<td class="line x" title="403:730	The remaining 173 examples were distributed according to Table 4." ></td>
	<td class="line x" title="404:730	For the words that are covered by the TWS' method, the Word Frequencies method has a precision of 71.1% (123/173), whereas the TWS' method has a precision of 85.5%(148/173)." ></td>
	<td class="line x" title="405:730	As can be seen in the table, the TWS' method is correct in almost all the cases it disagrees with the Word Frequencies method (28 out of 31)." ></td>
	<td class="line x" title="406:730	The applicability and precision figures in this experiment are somewhat lower than those achieved for the Hebrew set in our original evaluation of the TWS method (Table 2)." ></td>
	<td class="line x" title="407:730	We attribute this to the fact that the original results were achieved using a parsed corpus, which was about 2.5 times larger and of much higher quality than the one used in the second experiment." ></td>
	<td class="line x" title="408:730	Yet, the new results give additional support for the usefulness of the TWS method, even for noisy data provided by a low quality corpus, without any parsing or tagging, u 6." ></td>
	<td class="line x" title="409:730	Analysis and Possible Enhancements In this section we give a detailed analysis of the selections performed by the algorithm and, in particular, analyze the cases when it failed." ></td>
	<td class="line x" title="410:730	The analysis of these modes suggests possible improvements of the model and indicates its limitations." ></td>
	<td class="line x" title="411:730	As described earlier, the algorithm's failure includes either the cases for which the method was not applicable (no selection), or the cases for which it made an incorrect selection." ></td>
	<td class="line x" title="412:730	The following paragraphs list various reasons for both types." ></td>
	<td class="line x" title="413:730	At the end of the section, we discuss the possibility of adapting our approach to monolingual applications." ></td>
	<td class="line x" title="414:730	6.1 Correct Selection In the cases that were treated correctly by our method, such as the examples given in the previous sections, the statistics succeeded in capturing two major types of disambiguating data." ></td>
	<td class="line x" title="415:730	In preferring 'sign-treaty' upon 'seal-treaty' (in Example 1), the statistics reflect the relevant semantic constraint." ></td>
	<td class="line x" title="416:730	In preferring 'peace-treaty' upon 'peacecontract,' the statistics reflect the lexical usage of 'treaty' in English which differs from the usage of 'contract'." ></td>
	<td class="line x" title="417:730	6.2 Inapplicability 6.2.1 Insufficient Data." ></td>
	<td class="line x" title="418:730	This was the reason for nearly all the cases of inapplicability." ></td>
	<td class="line x" title="419:730	In one of our examples, for instance, none of the alternative relations, 'an investigator of corruption' (the correct one) or 'researcher of corruption' (the incorrect one), 11 It should be mentioned that the work of Dagan, Marcus, and Markovitch (1993) includes further results, evaluating an enhancement of the TWS method using their similarity-based estimation method." ></td>
	<td class="line x" title="420:730	This enhancement is beyond the scope of the current paper and is referred to in the next section." ></td>
	<td class="line x" title="421:730	581 Computational Linguistics Volume 20, Number 4 was observed in the parsed corpus." ></td>
	<td class="line x" title="422:730	In this case it is possible to perform the correct selection if we used only statistics about the co-occurrence of 'corruption' with either 'investigator' or 'researcher' in the same local context, without requiring any syntactic relation." ></td>
	<td class="line x" title="423:730	Statistics on co-occurrence of words in a local context were used recently for monolingual word sense disambiguation (Gale, Church, and Yarowsky 1992b, 1993; Sch6tze 1992, 1993) (see Section 7 for more details and Church and Hanks 1990; Smadja 1993, for other applications of these statistics)." ></td>
	<td class="line x" title="424:730	It is possible to apply these methods using statistics of the target language and thus incorporate them within the framework proposed here for target word selection." ></td>
	<td class="line x" title="425:730	Finding an optimal way of combining the different methods is a subject for further research." ></td>
	<td class="line x" title="426:730	Our intuition, though, as well as some of our initial data, suggests that statistics on word co-occurrence in the local context can substantially increase the applicability of the selection method." ></td>
	<td class="line x" title="427:730	Another way to deal with the lack of statistical data for the specific words in question is to use statistics about similar words." ></td>
	<td class="line x" title="428:730	This is the basis for Sadler's Analogical Semantics (Sadler 1989), which according to his report has not proved effective." ></td>
	<td class="line pc" title="429:730	His results may be improved if more sophisticated methods and larger corpora are used to establish similarity between words (such as in Hindle 1990)." ></td>
	<td class="line x" title="430:730	In particular, an enhancement of our disambiguation method, using similarity-based estimation (Dagan, Marcus, and Markovitch 1993), was evaluated recently." ></td>
	<td class="line x" title="431:730	In this evaluation the applicability of the disambiguation method was increased by 15%, with only a slight decrease in the precision." ></td>
	<td class="line x" title="432:730	The increased applicability was achieved by disambiguating additional cases in which statistical data were not available for any of the alternative tuples, whereas data were available for other tuples containing similar words." ></td>
	<td class="line x" title="433:730	6.2.2 Conflicting Data." ></td>
	<td class="line x" title="434:730	In very few cases two alternatives were supported equally by the statistical data, thus preventing a selection." ></td>
	<td class="line x" title="435:730	In such cases, both alternatives are valid at the independent level of the syntactic relation, but may be inappropriate for the specific context." ></td>
	<td class="line x" title="436:730	For instance, the two alternatives of 'to take a job' or 'to take a position' appeared in one of the examples, but since the general context was about the position of a prime minister, only the latter was appropriate." ></td>
	<td class="line x" title="437:730	To resolve such ambiguities, it may be useful to consider also co-occurrences of the ambiguous word with other words in the broader context (e.g. , Gale, Church, and Yarowsky 1993; Yarkowsky 1992)." ></td>
	<td class="line x" title="438:730	For instance, the word 'minister' seems to co-occur in the same context more frequently with 'position' than with 'job'." ></td>
	<td class="line x" title="439:730	In another example both alternatives were appropriate also for the specific context." ></td>
	<td class="line x" title="440:730	This happened with the German verb werfen, which may be translated (among other options) as 'throw,' 'cast,' or 'score'." ></td>
	<td class="line x" title="441:730	In our example, werfen, appeared in the context of 'to throw/cast light,' and these two correct alternatives had equal frequencies in the corpus ('score' was successfully eliminated): In such situations any selection between the alternatives will be appropriate, and therefore, any algorithm that handles conflicting data would work properly." ></td>
	<td class="line x" title="442:730	However, it is difficult to decide automatically when both alternatives are acceptable and when only one of them is. 6.3 Incorrect Selection 6.3.1 Using an Inappropriate Relation." ></td>
	<td class="line x" title="443:730	One of the examples contained the Hebrew word matzav." ></td>
	<td class="line x" title="444:730	This word has several translations, two of which are 'state' and 'position'." ></td>
	<td class="line x" title="445:730	The phrase that contained this word was 'to put an end to the {statelposition } of war'." ></td>
	<td class="line x" title="446:730	The ambiguous word is involved in two syntactic relations, being a complement of 'put' and also modified by 'war'." ></td>
	<td class="line x" title="447:730	The corresponding frequencies were 582 Ido Dagan and Alon Itai Word Sense Disambiguation (15) (verb-comp: put-position) 320 (verb-comp: put-state) 18 (noun-nobj: state-war) 13 (noun-nobj: position-war) 2 The bound of the odds ratio (B~) for the first relation was higher than for the second, and therefore, this relation determined the translation as 'position'." ></td>
	<td class="line x" title="448:730	However, the correct translation should be 'state', as determined by the second relation." ></td>
	<td class="line x" title="449:730	These data suggest that while ordering the relations (or using any other Weighting mechanism) it may be necessary to give different weights to the different types of syntactic relations." ></td>
	<td class="line x" title="450:730	For instance, it seems reasonable that the object of a noun should receive greater weight in selecting the noun's sense than the verb for which this noun serves as a complement." ></td>
	<td class="line x" title="451:730	Further examination of the example suggests another refinement of our method: it turns out that most of the 320 instances of the tuple (verb-comp: put position) include the preposition 'in,' as part of the common phrase 'put in a position'." ></td>
	<td class="line x" title="452:730	Therefore, these instances should not be considered for the current example, which includes the preposition 'to'." ></td>
	<td class="line x" title="453:730	However, the distinction between different prepositions was lost by our program, as a result of using equivalence classes of syntactic tuples (see Section 2.3)." ></td>
	<td class="line x" title="454:730	This suggests that we should not use an equivalence class when there is enough statistical data for specific tuples." ></td>
	<td class="line x" title="455:730	12 6.3.2 Confusing Senses." ></td>
	<td class="line x" title="456:730	In another example, the Hebrew adjective qatann modified the noun sikkuy, which means 'prospect' or 'chance'." ></td>
	<td class="line x" title="457:730	The word qatann has several translations, two of which are 'small' and 'young'." ></td>
	<td class="line x" title="458:730	In this Hebrew word combination, the correct sense of qatann is necessarily 'small'." ></td>
	<td class="line x" title="459:730	However, the relation that was observed in the corpus was 'young prospect,' relating to the human sense of 'prospect' that appeared in sports articles (a promising young person)." ></td>
	<td class="line x" title="460:730	This borrowed sense of 'prospect' is necessarily inappropriate, since in Hebrew it is represented by the equivalent of 'hope' (tiqwa) and not by sikkuy." ></td>
	<td class="line x" title="461:730	The source of this problem is Assumption 3: a target tuple T might be a translation of several source tuples, and while gathering statistics for T, we cannot distinguish between the different sources, since we use only a target language corpus." ></td>
	<td class="line x" title="462:730	A possible solution is to use an aligned bilingual corpus, as suggested by Sadler (1989), Brown et al.(1991), and Gale et al.(1992a)." ></td>
	<td class="line x" title="465:730	In such a corpus the occurrences of the relation 'young prospect' will be aligned to the corresponding occurrences of the Hebrew word tiqwa and will not be used when the Hebrew word sikkuy is involved." ></td>
	<td class="line x" title="466:730	Yet, it should be brought to mind that an aligned corpus is the result of manual translation, which can be viewed as including a manual tagging of the ambiguous words with their equivalent senses in the target language." ></td>
	<td class="line x" title="467:730	This resource is much more expensive and less available than an untagged monolingual corpus, and it seems to be necessary only for relatively rare situations." ></td>
	<td class="line x" title="468:730	Therefore, considering the trade-off between applicability and precision, it seems better to rely on a significantly larger monolingual corpus than on a smaller bilingual corpus." ></td>
	<td class="line x" title="469:730	An optimal method may exploit both types of corpora, in which the somewhat more accurate, but more expensive, data of a bilingual corpus are augmented by the data of a much larger monolingual corpus." ></td>
	<td class="line x" title="470:730	13 12 We thank the anonymous reviewer for suggesting this point." ></td>
	<td class="line x" title="471:730	13 Even though there are large quantities of translated texts, experience has shown that it is much harder to obtain large bilingual corpora than large monolingual corpora." ></td>
	<td class="line x" title="472:730	As mentioned earlier, a bilingual 583 Computational Linguistics Volume 20, Number 4 6.3.3 Lack of Deep Understanding." ></td>
	<td class="line x" title="473:730	By their nature, statistical methods rely on large quantities of shallow information." ></td>
	<td class="line x" title="474:730	Thus, they are doomed to fail when disambiguation can rely only on deep understanding of the text and no other surface cues are available." ></td>
	<td class="line x" title="475:730	This happened in one of the Hebrew examples, in which the two alternatives were either 'emigration law' or 'immigration law' (the Hebrew word hagira is used for both subsenses)." ></td>
	<td class="line x" title="476:730	While the context indicated that the first alternative is correct (emigration from the Soviet Union), the statistics (which were extracted from texts related to North America) preferred the second alternative." ></td>
	<td class="line x" title="477:730	To translate the above phrase, the program would need deep knowledge, to an extent that seems to far exceed the capabilities of current systems." ></td>
	<td class="line x" title="478:730	Fortunately, our results suggest that such cases are quite rare." ></td>
	<td class="line x" title="479:730	6.4 Monolingual Applications The results of our experiments in the context of machine translation suggest the utility of a similar mechanism even for in word sense disambiguation within a single language." ></td>
	<td class="line x" title="480:730	To select the right sense of a word, in a broad coverage application, it is useful to identify lexical relations between word senses." ></td>
	<td class="line x" title="481:730	However, within corpora of a single language it is possible to identify automatically only relations at the word level, which are, of course, not useful for selecting word senses in that language." ></td>
	<td class="line x" title="482:730	This is where other languages can supply the solution, exploiting the fact that the mapping between words and word senses varies significantly between different languages." ></td>
	<td class="line x" title="483:730	For instance, the English words 'sign' and 'seal' (from Example 1 in the introduction) correspond to two distinct senses of the Hebrew word lahtom." ></td>
	<td class="line x" title="484:730	These senses should be distinguished by most applications of Hebrew understanding programs." ></td>
	<td class="line x" title="485:730	To make this distinction, it is possible to perform the same process that is performed for target word selection, by producing all the English alternatives for the lexical relations involving lahtom." ></td>
	<td class="line x" title="486:730	Then the Hebrew sense that corresponds to the most plausible English lexical relations is preferred." ></td>
	<td class="line x" title="487:730	This process requires a bilingual lexicon that maps each Hebrew sense separately into its possible translations, similar to a Hebrew-Hebrew-English lexicon (analogous to the Oxford English-English-Hebrew dictionary of Hornby et al. \[1986\], which lists the senses of an English word, along with the possible Hebrew translations for each of them)." ></td>
	<td class="line x" title="488:730	In some cases, different senses of a Hebrew word map to the same word also in English." ></td>
	<td class="line x" title="489:730	In these cases, the lexical relations of each sense cannot be identified in an English corpus, and a third language is required to distinguish among these senses." ></td>
	<td class="line x" title="490:730	Alternatively, it is possible to combine our method with other disambiguation methods that have been developed in a monolingual context (see the next section)." ></td>
	<td class="line x" title="491:730	As a long-term vision, one can imagine a multilingual corpora-based environment, which exploits the differences between languages to facilitate the acquisition of knowledge about word senses." ></td>
	<td class="line x" title="492:730	7." ></td>
	<td class="line x" title="493:730	Comparative Analysis of Statistical Sense Disambiguation Methods Until recently, word sense disambiguation seemed to be a problem for which there is no satisfactory solution for broad coverage applications." ></td>
	<td class="line x" title="494:730	Recently, several statistical methods have been developed for solving this problem, suggesting the possibility of robust, yet feasible, disambiguation." ></td>
	<td class="line x" title="495:730	In this section we identify and analyze basic aspects of a statistical sense disambiguation method and compare several proposed corpus of moderate size can be valuable when constructing a bilingual lexicon, thus justifying the effort of maintaining such a corpus." ></td>
	<td class="line x" title="496:730	584 Ido Dagan and Alon Itai Word Sense Disambiguation methods (including ours) along these aspects." ></td>
	<td class="line x" title="497:730	TM This analysis may be useful for future research on sense disambiguation, as well as for the development of sense disambiguation modules in practical systems." ></td>
	<td class="line x" title="498:730	The basic aspects that will be reviewed are . 2." ></td>
	<td class="line x" title="499:730	3. 4." ></td>
	<td class="line x" title="500:730	Information sources used by the disambiguation method." ></td>
	<td class="line x" title="501:730	Acquisition of the required information from training texts." ></td>
	<td class="line x" title="502:730	The computational decision model." ></td>
	<td class="line x" title="503:730	Performance evaluation." ></td>
	<td class="line x" title="504:730	The first three aspects deal with the components of a disambiguation method, as would be implemented for a practical application." ></td>
	<td class="line x" title="505:730	The fourth is a methodological issue, which is relevant for developing, testing, and comparing disambiguation methods." ></td>
	<td class="line x" title="506:730	7.1 Information Sources We identify three major types of information that were used in statistical methods for sense disambiguation: . . 3." ></td>
	<td class="line x" title="507:730	Words appearing in the local, syntactically related, context of the ambiguous word." ></td>
	<td class="line x" title="508:730	Words appearing in the global context of the ambiguous word." ></td>
	<td class="line x" title="509:730	Probabilistic syntactic and morphological characteristics of the ambiguous word." ></td>
	<td class="line x" title="510:730	The first type of information is the one used in the current paper, in which words that are syntactically related to an ambiguous word are used to indicate its most probable sense." ></td>
	<td class="line x" title="511:730	Statistical data on the co-occurrence of syntactically related words with each of the alternative senses reflect semantic and lexical preferences and constraints of these senses." ></td>
	<td class="line x" title="512:730	In addition, these statistics may provide information about the topics of discourse that are typical for each sense." ></td>
	<td class="line x" title="513:730	Ideally, the syntactic relations between words should be identified using a syntactic parser, in both the training and the disambiguation phases." ></td>
	<td class="line x" title="514:730	Since robust syntactic parsers are not widely available, and those that exist are not always accurate, it is possible to use various approximations to identify relevant syntactic relations between words." ></td>
	<td class="line x" title="515:730	Hearst (1991) uses a stochastic part of speech tagger and a simple scheme for partial parsing of short phrases." ></td>
	<td class="line x" title="516:730	The structures achieved by this analysis are used to identify approximated syntactic relations between words." ></td>
	<td class="line x" title="517:730	Brown et al.(1991) make even weaker approximations, using only a stochastic part of speech tagger, and defining relations such as 'the first verb to the right' or 'the first noun to the left'." ></td>
	<td class="line x" title="519:730	Finally, Dagan et al.(1993) (see Section 5.1) assume full parsing at the disambiguation phase, but no preprocessing at the training phase, in which a higher level of noise can be accommodated." ></td>
	<td class="line x" title="521:730	A second type of information is provided by words that occur in the global context of the ambiguous word (Gale, Church, and Yarowsky 1992b, 1993; Yarowsky 1992; Sch6tze 1992)." ></td>
	<td class="line x" title="522:730	Gale et al. and Yarowsky use words that appear within 50 words in each 14 The reader is referred to some of these recent papers for thorough surveys of work on sense disambiguation (Hearst 1991; Gale, Church, and Yarowsky 1992a; Yarowsky 1992)." ></td>
	<td class="line x" title="523:730	585 Computational Linguistics Volume 20, Number 4 direction of the ambiguous word." ></td>
	<td class="line x" title="524:730	is Statistical data are stored about the occurrence of words in the context of each sense and are matched against the context in the disambiguated sentence." ></td>
	<td class="line x" title="525:730	Co-occurrence in the global context provides information about typical topics associated with each sense, in which a topic is represented by words that commonly occur in it." ></td>
	<td class="line x" title="526:730	Schiitze (1992, 1993) uses a variant of this type of information, in which contextvectors are maintained for character four-grams, instead of words." ></td>
	<td class="line x" title="527:730	In addition, the context of an occurrence of an ambiguous word is represented by co-occurrence information of a second order, as a set of context vectors (instead of a set of context words)." ></td>
	<td class="line x" title="528:730	Compared with co-occurrence within syntactic relations, information about the global context is less sensitive to fine semantic and lexical distinctions and is less useful when different senses of a word appear in similar contexts." ></td>
	<td class="line x" title="529:730	On the other hand, the global context contains more words and is therefore more likely to provide enough disambiguating information, in cases in which this distinction can be based ~on the topic of discourse." ></td>
	<td class="line x" title="530:730	From a general perspective, these two types of information represent a common trade-off in statistical language processing: the first type is related to a limited amount of deeper, and more precise linguistic information, whereas the second type provides a large amount of shallow information, which can be applied in a more robust manner." ></td>
	<td class="line x" title="531:730	The two sources of information seem to complement each other and may both be combined in future disambiguation methods." ></td>
	<td class="line x" title="532:730	16 Hearst (1991) incorporates a third type of statistical information to distinguish between different senses of nouns (in addition to the first type discussed above)." ></td>
	<td class="line x" title="533:730	For each occurrence of a sense, several syntactic and morphological characteristics are recorded, such as whether the noun modifies or is modified by another word, whether it is capitalized, and whether it is related to certain prepositional phrases." ></td>
	<td class="line x" title="534:730	Then, in the disambiguation phase, a best match is sought between the information recorded for each sense and the syntactic context of the current occurrence of the noun." ></td>
	<td class="line x" title="535:730	This type of information resembles the information that is defined for lexical items in lexicalist approaches for grammars, such as possible subcategorization frames of a word." ></td>
	<td class="line x" title="536:730	The major difference is that Hearst captures probabilistic preferences of senses for such syntactic constructs." ></td>
	<td class="line x" title="537:730	Grammatical formalisms, on the other hand, usually specify only which constructs are possible and at most distinguish between optional and obligatory ones." ></td>
	<td class="line x" title="538:730	Therefore the information recorded in such grammars cannot distinguish between different senses of a word that potentially have the same subcategorization frames, though in practice each sense might have different probabilistic preferences for different syntactic constructs." ></td>
	<td class="line x" title="539:730	It is clear that each of the different types of information provides some information that is not captured by the others." ></td>
	<td class="line x" title="540:730	However, as the acquisition and manipulation of each type of information requires different tools and resources, it is important to assess the relative contribution, and the 'cost effectiveness,' of each of them." ></td>
	<td class="line x" title="541:730	Such comparative evaluations are not available yet, not even for systems that incorporate several types of data (e.g. , McRoy 1992)." ></td>
	<td class="line x" title="542:730	Further research is therefore needed to com15 The size of the context was determined experimentally, based on evaluations of different sizes of context." ></td>
	<td class="line x" title="543:730	This optimization was performed for the Hansard corpus of the proceedings of the Canadian Parliament." ></td>
	<td class="line x" title="544:730	In general, the size of the global context depends on the corpus and typically consists of a homogeneous unit of discourse." ></td>
	<td class="line x" title="545:730	16 See also Gale, Church, and Yarowsky 1992b (pp." ></td>
	<td class="line x" title="546:730	58-59), and Sch~itze, 1992, 1993, for methods of reducing the number of parameters when using global contexts and Dagan, Marcus, and Markovitch 1993, for increasing the applicability of the use of local context, in cases in which there is no direct statistical evidence." ></td>
	<td class="line x" title="547:730	586 Ido Dagan and Alon Itai Word Sense Disambiguation pare the relative importance of different information types and to find optimal ways of combining them." ></td>
	<td class="line x" title="548:730	7.2 Acquisition of Training Information When training a statistical model for sense disambiguation, it is necessary to associate the acquired statistics with word senses." ></td>
	<td class="line x" title="549:730	This seems to require manual tagging of the training corpus with the appropriate sense for each occurrence of an ambiguous word." ></td>
	<td class="line x" title="550:730	A similar approach is being used for stochastic part of speech taggers and probabilistic parsers, relying on the availability of large, manually tagged (or parsed), corpora for training." ></td>
	<td class="line x" title="551:730	However, this approach is less feasible for sense disambiguation, for two reasons." ></td>
	<td class="line x" title="552:730	First, the size of corpora required to acquire sufficient statistics on lexical cooccurrence is usually much larger than that used for acquiring statistics on syntactic constructs or sequences of parts of speech." ></td>
	<td class="line x" title="553:730	Second, lexical co-occurrence patterns, as well as the definition of senses, may vary a great deal across different domains of discourse." ></td>
	<td class="line x" title="554:730	Consequently, it is usually not sufficient to acquire the statistics from one widely available 'balanced' corpus, as is common for syntactic applications." ></td>
	<td class="line x" title="555:730	A sense disambiguation model should be trained on the same type of texts for which it will be applied, thus increasing the cost of manual tagging." ></td>
	<td class="line x" title="556:730	The need to disambiguate a training corpus before acquiring a statistical model for disambiguation is often termed as the circularity problem." ></td>
	<td class="line x" title="557:730	In the following paragraphs we discuss different methods that were proposed to overcome the circularity problem, without exhaustive manual tagging of the training corpus." ></td>
	<td class="line x" title="558:730	In our opinion, this is the most critical issue in developing feasible sense disambiguation methods." ></td>
	<td class="line x" title="559:730	7.2.1 Bootstrapping." ></td>
	<td class="line x" title="560:730	Bootstrapping, which is a general scheme for reducing the amount of manual tagging, was proposed also for sense disambiguation (Hearst 1991)." ></td>
	<td class="line x" title="561:730	The idea is to tag manually an initial set of occurrences for each sense in the lexicon, acquiring initial training statistics from these instances." ></td>
	<td class="line x" title="562:730	Then, using these statistics, the system tries to disambiguate additional occurrences of ambiguous words." ></td>
	<td class="line x" title="563:730	If such an occurrence can be disambiguated automatically with high confidence, the system acquires additional statistics from this occurrence, as if it were tagged by hand." ></td>
	<td class="line x" title="564:730	Hopefully, the system will incrementally acquire all the relevant statistics, demanding just a small amount of manual tagging." ></td>
	<td class="line x" title="565:730	The results of Hearst (1991) show that at least 10 occurrences of each sense have to be tagged by hand, and in most cases 20-30 occurrences are required to get high precision." ></td>
	<td class="line x" title="566:730	These results, which were achieved for a small set of preselected ambiguous words, suggest that the cost of the bootstrapping approach is still very high." ></td>
	<td class="line x" title="567:730	7.2.2 Clustering Occurrences of an Ambiguous Word." ></td>
	<td class="line x" title="568:730	Sch6tze (1992, 1993) proposes a method that can be viewed as an efficient way of manual tagging." ></td>
	<td class="line x" title="569:730	Instead of presenting all occurrences of an ambiguous word to a human, these occurrences are first clustered using automatic clustering algorithms." ></td>
	<td class="line x" title="570:730	17 Then a human is asked to assign one of the senses of the word to each cluster, by observing several members of the cluster." ></td>
	<td class="line x" title="571:730	Each sense is thus represented by one or more clusters." ></td>
	<td class="line x" title="572:730	At the disambiguation phase, a new occurrence of an ambiguous word is matched against the contexts that were recorded for these clusters, selecting the sense of that cluster which provides the best match." ></td>
	<td class="line x" title="573:730	It is interesting to note that the number of occurrences that had to be observed by a human in the experiments of Sch/itze is of the same order as in the bootstrapping 17 Each occurrence is represented as a context vector, and the vectors are then clustered, 587 Computational Linguistics Volume 20, Number 4 approach: 10-20 members of a cluster were observed, with an average of 2.8 clusters per sense." ></td>
	<td class="line x" title="574:730	As both approaches were tested only on a small number of preselected words, further evaluation is necessary to predict the actual cost of their application to broad domains." ></td>
	<td class="line x" title="575:730	The methods described below, on the other hand, rely on resources that were already available on a large scale, and it is therefore possible to estimate the expected cost of their broad application." ></td>
	<td class="line x" title="576:730	7.2.3 Word Classification." ></td>
	<td class="line x" title="577:730	Yarowsky (1992) proposes a method that completely avoids manual tagging of the training corpus." ></td>
	<td class="line x" title="578:730	This is achieved by estimating parameters for classes of words rather than for individual word senses." ></td>
	<td class="line x" title="579:730	In his work, Yarowsky considered the semantic categories defined in Roget's Thesaurus as classes." ></td>
	<td class="line x" title="580:730	He then mapped (manually) each of the senses of an ambiguous word to one or several of the categories under which this word is listed in the thesaurus." ></td>
	<td class="line x" title="581:730	The task of sense disambiguation thus becomes the task of selecting the appropriate category for each occurrence of an ambiguous word." ></td>
	<td class="line x" title="582:730	18 When estimating the parameters of a category/9 any occurrence of a word that belongs to that category is counted as an occurrence of the category." ></td>
	<td class="line x" title="583:730	This means that each occurrence of an ambiguous word is counted as an occurrence of all the categories to which the word belongs and not just the category that corresponds to the specific occurrence." ></td>
	<td class="line x" title="584:730	A substantial amount of noise is introduced by this training method, which is a consequence of the circularity problem." ></td>
	<td class="line x" title="585:730	To avoid the noise, it would be necessary to tag each occurrence of an ambiguous word with the appropriate category." ></td>
	<td class="line x" title="586:730	As explained by Yarowsky, however, this noise can usually be tolerated." ></td>
	<td class="line x" title="587:730	The 'correct' parameters of a certain class are acquired from all its occurrences, whereas the 'incorrect' parameters are distributed through occurrences of many different classes and usually do not produce statistically significant patterns." ></td>
	<td class="line x" title="588:730	To reduce the noise further, Yarowsky uses a system of weights that assigns lower weights to frequent words, since such words may introduce more noise." ></td>
	<td class="line x" title="589:730	2 The word class method thus overcomes the circularity problem by mapping word senses to classes of words." ></td>
	<td class="line x" title="590:730	However, because of this mapping, the method cannot distinguish between senses that belong to the same class, and it also introduces some level of noise." ></td>
	<td class="line x" title="591:730	7.2.4 A Bilingual Corpus." ></td>
	<td class="line x" title="592:730	Brown et al.(1991) were concerned with sense disambiguation for machine translation." ></td>
	<td class="line x" title="594:730	Having a large aligned bilingual corpus available, they noticed that the target word which corresponds to an occurrence of an ambiguous source word can serve as a tag of the appropriate sense." ></td>
	<td class="line x" title="595:730	This kind of tagging provides sense distinctions when different senses of a source word translate to different target words." ></td>
	<td class="line x" title="596:730	For the purpose of translation, these are exactly the cases for which sense distinction is required." ></td>
	<td class="line x" title="597:730	Conceptually, the use of a bilingual corpus does not eliminate (or reduce) manual tagging of the training corpus." ></td>
	<td class="line x" title="598:730	Such a corpus is a result of manual translation, and it is the translator who provides tagging of senses as a side effect of the translation process." ></td>
	<td class="line x" title="599:730	Practically, whenever a bilingual corpus is available, it pro18 In some cases, the Roget index was found to be incomplete, and a missing category had to be added to the list of possibilities for a word." ></td>
	<td class="line x" title="600:730	19 Yarowsky uses statistics on occurrences of specific words in the global context of the category, but the method can be used to collect other types of statistics, such as the co-occurrence of the category with other categories." ></td>
	<td class="line x" title="601:730	20 The method of acquiring parameters from ambiguous occurrences in a corpus, relying on the 'spreading' of noise, can be used in many contexts." ></td>
	<td class="line x" title="602:730	For example, it was used for acquiring statistics for disambiguating prepositional phrase attachments, counting ambiguous occurrences of prepositional phrases as representing both noun-pp and verb-pp constructs (Hindle and Rooth 1991)." ></td>
	<td class="line x" title="603:730	588 Ido Dagan and Alon Itai Word Sense Disambiguation vides a useful source of a sense tagged corpus." ></td>
	<td class="line x" title="604:730	Gale, Church, and Yarowsky (1992a) have also exploited this resource for achieving large amounts of testing and training materials." ></td>
	<td class="line x" title="605:730	7.2.5 A Bilingual Lexicon and a Monolingual Corpus." ></td>
	<td class="line x" title="606:730	The method of the current paper also exploits the fact that different senses of a word are usually mapped to different words in another language." ></td>
	<td class="line x" title="607:730	However, our work shows that the differences between languages enable us to avoid any form of manual tagging of the corpus (including translation)." ></td>
	<td class="line x" title="608:730	This is achieved by a bilingual lexicon that maps a source language word to all its possible equivalents in the target language." ></td>
	<td class="line x" title="609:730	This approach has practical advantages for the purpose of machine translation, in which a bilingual lexicon needs to be constructed in any case, and very large bilingual corpora are not usually available." ></td>
	<td class="line x" title="610:730	From a theoretical point of view, the difference between the two methods can be made clear if we assume that the bilingual lexicon contains exactly all the different translations of a word which occur in a bilingual corpus." ></td>
	<td class="line x" title="611:730	For a given set of senses that need to be disambiguated, our method requires a bilingual corpus of size k, in which each sense occurs at least once, in order to establish its mapping to a target word." ></td>
	<td class="line x" title="612:730	In addition, a larger monolingual corpus, of size n, is required, to provide enough training examples of typical contexts for each sense." ></td>
	<td class="line x" title="613:730	On the other hand, using a bilingual corpus for training the disambiguation model would require a bilingual corpus of size n, which is significantly larger than k. The savings in resources is achieved since the mapping between the languages is done at the level of single words." ></td>
	<td class="line x" title="614:730	The larger amount of information about word combinations, on the other hand, is acquired from an untagged monolingual corpus, after the mapping has been performed." ></td>
	<td class="line x" title="615:730	Our results show that the precision of the selection algorithm is high despite the additional noise which is introduced by mapping single words independently of their context." ></td>
	<td class="line x" title="616:730	As mentioned in Section 6.3, an optimal method may combine the two methods." ></td>
	<td class="line x" title="617:730	In some sense, the use of a bilingual lexicon resembles the use of a thesaurus in Yarowsky's approach." ></td>
	<td class="line x" title="618:730	Both rely on a manually established mapping of senses to other concepts (classes of words or words in another language) and collect information about the target concepts from an untagged corpus." ></td>
	<td class="line x" title="619:730	In both cases, ambiguous words in the corpus introduce some level of noise: counting an occurrence of a word as an occurrence of all the classes to which it belongs, or counting an occurrence of a target word as an occurrence of all the source words to which it may correspond (a smaller amount of noise is introduced in the latter case, as a mapping to target words is much more finely grained than a mapping to Roget's categories)." ></td>
	<td class="line x" title="620:730	Also, both methods can distinguish only between senses that are distinguished by the mappings they use: either senses that belong to different classes, or senses that correspond to different target words." ></td>
	<td class="line x" title="621:730	An interesting difference, though, relates to the feasibility of implementing the two methods for a new domain of texts (in particular technical domains)." ></td>
	<td class="line x" title="622:730	The construction of a bilingual lexicon for a new domain is relatively straightforward and is often carried out for translation purposes." ></td>
	<td class="line x" title="623:730	The construction of an appropriate classification for the words of a new domain is more complex, and furthermore, it is not clear whether it is possible in every domain to construct a classification that is sufficient for the purpose of sense disambiguation." ></td>
	<td class="line x" title="624:730	7.3 The Computational Decision Model Sense disambiguation methods require a decision model that evaluates the relevant statistics." ></td>
	<td class="line x" title="625:730	Sense disambiguation thus resembles many other decision tasks, and not surprisingly, several common decision algorithms were employed in different works." ></td>
	<td class="line x" title="626:730	These include a Bayesian classifier (Gale, Church, and Yarowsky 1993) and a distance 589 Computational Linguistics Volume 20, Number 4 metric between vectors (Schiitze 1993), both inspired from methods in information retrieval; the use of the flip-flop algorithm for ordering possible informants about the preferred sense, trying to maximize the mutual information between the informant and the ambiguous word (Brown et al. 1991); and the use of confidence intervals to establish the degree of confidence in a certain preference, combined with a constraint propagation algorithm (the current paper)." ></td>
	<td class="line x" title="627:730	At the present stage of research on sense disambiguation, it is difficult to judge whether a certain decision algorithm is significantly superior to others." ></td>
	<td class="line x" title="628:730	21 Yet, these decision models can be characterized by several criteria, which clarify the similarities and differences between them." ></td>
	<td class="line x" title="629:730	As will be explained below, many of the differences are correlated with the different information sources employed by these models." ></td>
	<td class="line x" title="630:730	 Combining several informants: The methods described by Brown et al.(1991) and in the current paper combine several informants (i.e. , statistics about several context words) by choosing the informant that seems most indicative for the selection." ></td>
	<td class="line x" title="632:730	The effect of other, less significant, informants is then discarded." ></td>
	<td class="line x" title="633:730	The Bayesian classifier and the vector distance metric combine all informants simultaneously, in a multiplicative or additive manner, possibly assigning a certain weight to each informant." ></td>
	<td class="line x" title="634:730	 Reducing the number of parameters: Since sense disambiguation relies on statistics about lexical co-occurrence, the number of relevant parameters is very high, especially when co-occurrence in the global context is considered." ></td>
	<td class="line x" title="635:730	For this reason, Schiitze uses two compaction methods: First, 5000 'informative' four-grams are used instead of words." ></td>
	<td class="line x" title="636:730	Second, the 5000 dimensions are decomposed to 97 dimensions, using singular value decomposition." ></td>
	<td class="line x" title="637:730	This method reduces the number of parameters significantly, but has the disadvantage that it is impossible to trace the meaning of the entries in the resulting vectors or to associate them directly with the original co-occurrence statistics." ></td>
	<td class="line x" title="638:730	Gale, Church, and Yarowsky (1992b, pp." ></td>
	<td class="line x" title="639:730	58-59) propose another approach and reduce the number of parameters by selecting the most informative context words for each sense." ></td>
	<td class="line x" title="640:730	The selection of context words is based on a theoretically motivated criterion, borrowed from Mosteller and Wallace (1964, pp." ></td>
	<td class="line x" title="641:730	55-56)." ></td>
	<td class="line x" title="642:730	Finally, Yarowsky's method further reduces the number of parameters, as it records co-occurrences between individual words and word classes." ></td>
	<td class="line x" title="643:730	 Statistical significance of the selection: In the current paper, we use confidence intervals to test whether the statistical preference for a certain sense is significant." ></td>
	<td class="line x" title="644:730	In a simple multiplicative preference score, on the other hand, it is not possible to distinguish whether preferences rely on small or large counts." ></td>
	<td class="line x" title="645:730	The method of Gale et al. remedies this problem indirectly (in most cases) by introducing a sophisticated interpolation between the actual counts of the co-occurrence parameters and the frequency counts of the individual words (see Gale, Church, and Yarowsky 1993, for details)." ></td>
	<td class="line x" title="646:730	In Schiitze's method it is not possible to trace the statistical significance of the parameters since they are the result of extensive processing and compaction of the original statistical data." ></td>
	<td class="line x" title="647:730	21 Once the important information sources for sense selection have been identified, it is possible that different decision algorithms would achieve comparable results." ></td>
	<td class="line x" title="648:730	590 Ido Dagan and Alon Itai Word Sense Disambiguation Resolving all ambiguities simultaneously: In the current paper, the selection of a sense for one word affects the selection for another word through a constraint propagation algorithm." ></td>
	<td class="line x" title="649:730	This property is absent in most other methods." ></td>
	<td class="line x" title="650:730	The differences between various disambiguation methods correlate with the difference in information sources, in particular, whether they use local or global context." ></td>
	<td class="line x" title="651:730	When local context is used, only few syntactically related informants may provide reliable information about the selection." ></td>
	<td class="line x" title="652:730	It is therefore reasonable to base the selection on only one, the most informative informant, and it is also important to test the statistical significance of that informant." ></td>
	<td class="line x" title="653:730	The problem of parameter explosion is less severe, and the number of parameters is comparable to that of a bi-gram language model (and even smaller)." ></td>
	<td class="line x" title="654:730	When using the global context, on the other hand, the number of potential parameters is significantly larger, but each of them is usually less informative." ></td>
	<td class="line x" title="655:730	It is therefore important to take into account as many parameters as possible in each ambiguous case, but it is less important to test for detailed statistical significance, or to worry about the mutual effects of sense selections for adjacent words." ></td>
	<td class="line x" title="656:730	7.4 Performance Evaluation In most of the above-mentioned papers, experimental results are reported for a small set of up to 12 preselected words, usually with two or three senses per word." ></td>
	<td class="line x" title="657:730	In the current paper we have evaluated our method using a random set of example sentences, with no a priori selection of the words." ></td>
	<td class="line x" title="658:730	This standard evaluation method, which is commonly used for other natural language processing tasks, provides a direct prediction for the expected success rate of the method when employed in a practical application." ></td>
	<td class="line x" title="659:730	To compare results on different test data, it is useful to compare the precision of the disambiguation method with some a priori figure that reflects the degree of ambiguity in the text." ></td>
	<td class="line x" title="660:730	Reporting the number of senses per example word corresponds to the expected success rate of random selection." ></td>
	<td class="line x" title="661:730	A more informative figure is the success rate of a naive method that always selects the most frequent sense (the Word Frequencies method in our evaluations)." ></td>
	<td class="line x" title="662:730	The success rate of this naive method is higher than that of random selection and thus provides a tighter lower bound for the desired precision of a proposed disambiguation method." ></td>
	<td class="line x" title="663:730	An important practical issue in evaluation is how to get the test examples, which should be tagged with the correct sense." ></td>
	<td class="line x" title="664:730	In most papers (including ours) the tagging of the test data was done by hand, which limits the size of the testing set." ></td>
	<td class="line x" title="665:730	Preparing one test set by hand may still be reasonable, though time consuming." ></td>
	<td class="line x" title="666:730	However, it is useful to have more than one set, such that results will be reported on a new, unseen, set, while another set is used for developing and tuning the system." ></td>
	<td class="line x" title="667:730	One useful source of tagged examples is an aligned bilingual corpus, which can be used for testing any sense disambiguation method, including methods that do not use bilingual material for training." ></td>
	<td class="line x" title="668:730	Gale proposes to use 'pseudo-words' as another practical source of testing examples (Gale, Church, and Yarowsky 1992b) (equivalently, Schfitze \[1992\] uses 'artificial ambiguous words')." ></td>
	<td class="line x" title="669:730	Pseudo-words are constructed artificially as a union of several different words (say, wl, w2, and w3 define three 'senses' of the pseudo-word x)." ></td>
	<td class="line x" title="670:730	The disambiguation method is presented with texts in which all occurrences of wl, w2, and w3 are considered as occurrences of x and should then select the original word (sense) for each occurrence." ></td>
	<td class="line x" title="671:730	Though testing with this method does not provide results for real ambiguities that occur in the text, it can be very useful while develop591 Computational Linguistics Volume 20, Number 4 ing and tuning the method (Gale shows high correlation between the performance of his method on real sense ambiguities and pseudo-words)." ></td>
	<td class="line x" title="672:730	8." ></td>
	<td class="line x" title="673:730	Conclusions The method presented in this paper takes advantage of two linguistic phenomena, both proven to be very useful for sense disambiguation: the different mapping between words and word senses among different languages, and the importance of lexical co-occurrence within syntactic relations." ></td>
	<td class="line x" title="674:730	The first phenomenon provides the solution for the circularity problem in acquiring sense disambiguation data." ></td>
	<td class="line x" title="675:730	Using a bilingual lexicon and a monolingual corpus of the target language, we can acquire statistics on word senses automatically, without manual tagging." ></td>
	<td class="line x" title="676:730	As explained in Section 7, this method has significant practical and theoretical advantages over the use of aligned bilingual corpora." ></td>
	<td class="line x" title="677:730	We pay for these advantages by introducing an additional level of noise, in mapping individual words independently to the other language." ></td>
	<td class="line x" title="678:730	Our results show, however, that the precision of the selection algorithm is high despite this additional noise." ></td>
	<td class="line x" title="679:730	This work also emphasizes the importance of lexical co-occurrence within syntactic relations for the resolution of lexical ambiguity." ></td>
	<td class="line x" title="680:730	Co-occurrences found in a large corpus reflect a huge amount of semantic knowledge, which was traditionally constructed by hand." ></td>
	<td class="line x" title="681:730	Moreover, frequency data for such co-occurrences reflect both linguistic and domain-specific preferences, thus indicating not only what is possible, but also what is probable." ></td>
	<td class="line x" title="682:730	It is important to notice that frequency information on lexical co-occurrence was found to be much more predictive than single word frequency." ></td>
	<td class="line x" title="683:730	In the three experiments we reported, there were 61 cases in which the two types of information contradicted each other, favoring different target words." ></td>
	<td class="line x" title="684:730	In 56 of these cases (92%), it was the most frequent lexical co-occurrence, and not the most frequent word, that predicted the correct translation." ></td>
	<td class="line x" title="685:730	This result may raise relevant hypotheses for psycholinguistic research, which has indicated the relevance of word frequencies to human sense disambiguation (e.g. , Simpson and Burgess 1988)." ></td>
	<td class="line x" title="686:730	We suggest that the high precision achieved in the experiments relies on two characteristics of the ambiguity phenomena, namely the sparseness and redundancy of the disambiguating data." ></td>
	<td class="line x" title="687:730	By sparseness we mean that within the large space of alternative interpretations produced by ambiguous utterances, only a small portion is commonly used." ></td>
	<td class="line x" title="688:730	Therefore, the chance that an inappropriate interpretation is observed in the corpus (in other contexts) is low." ></td>
	<td class="line x" title="689:730	Redundancy relates to the fact that different informants (such as different lexical relations or deep understanding) tend to support rather than contradict one another, and therefore the chance of picking a 'wrong' informant is low." ></td>
	<td class="line x" title="690:730	It is interesting to compare our method with some aspects of the statistical machine translation system of Brown et al.(1990)." ></td>
	<td class="line x" title="692:730	As mentioned in the introduction, this system also incorporates target language statistics in the translation process." ></td>
	<td class="line x" title="693:730	To translate a French sentence, f, they choose the English sentence, e, that maximizes the term Pr(e)  Pr(f I e)." ></td>
	<td class="line x" title="694:730	The first factor in this product, which represents the target language model, may thus affect any aspect of the translation, including target word selection." ></td>
	<td class="line x" title="695:730	It seems, however, that Brown et al. expect that target word selection would be determined mainly by translation probabilities (the second factor in the above term), which should be derived from a bilingual corpus (Brown et al. 1990, p. 79)." ></td>
	<td class="line x" title="696:730	This view is reflected also in their elaborate method for target word selection (Brown et al. 1991), in which better estimates of translation probabilities are achieved as a result of word sense disambiguation." ></td>
	<td class="line x" title="697:730	Our method, on the other hand, incorporates only 592 Ido Dagan and Alon Itai Word Sense Disambiguation target language probabilities and ignores any notion of translation probabilities." ></td>
	<td class="line x" title="698:730	It thus demonstrates a possible trade-off between these two types of probabilities: using more informative statistics of the target language may compensate for the lack of translation probabilities." ></td>
	<td class="line x" title="699:730	For our system, the more informative statistics are achieved by syntactic analysis of both the source and target languages, instead of the simple tri-gram model used by Brown et al. In a broader sense, this can be viewed as a tradeoff between the different components of a translation system: having better analysis and generation models may reduce some burden from the transfer model." ></td>
	<td class="line x" title="700:730	In our opinion, the method proposed in this paper may have immediate practical value, beyond its theoretical aspects." ></td>
	<td class="line x" title="701:730	As we argue below, we believe that the method is feasible for practical machine translation systems and can provide a cost-effective improvement on target word selection methods." ></td>
	<td class="line x" title="702:730	The identification of syntactic relations in the source sentence is available in any machine translation system that uses some form of syntactic parsing." ></td>
	<td class="line x" title="703:730	Trivially, a bilingual lexicon is available." ></td>
	<td class="line x" title="704:730	A parser for the target language becomes common in many systems that offer bidirectional translation capabilities, requiring parsers for several languages (see Miller 1993, for available language pairs in several commercial machine translation systems)." ></td>
	<td class="line x" title="705:730	If a parser for the target language corpus is not available, it is possible to approximate the statistics using word co-occurrence in a window, as was demonstrated by a variant of our method (Dagan, Marcus, and Markovitch 1993) (see Section 5.1)." ></td>
	<td class="line x" title="706:730	In both cases, the statistical model was shown to handle successfully the noise produced in automatic acquisition of the data." ></td>
	<td class="line x" title="707:730	Substantial effort may be required for collecting a sufficiently large target language corpus." ></td>
	<td class="line x" title="708:730	We have not studied the relation between the corpus size and the performance of the algorithm, but it is our impression that a corpus of several hundred thousand words will prove useful for translation in a well-defined domain." ></td>
	<td class="line x" title="709:730	With current availability of texts in electronic form, = a corpus of this size is feasible in many domains." ></td>
	<td class="line x" title="710:730	The effort of assembling this corpus should be compared with the effort of manually coding sense disambiguation information." ></td>
	<td class="line x" title="711:730	Finally, our method was evaluated by simulating realistic machine translation lexicons, on randomly selected examples, and yielded high performance in two different broad domains (foreign news articles and a software manual)." ></td>
	<td class="line x" title="712:730	It is therefore expected that the results reported here will be reproduced in other domains and systems." ></td>
	<td class="line x" title="713:730	To improve the performance of target word selection further, our method may be combined with other sense disambiguation methods." ></td>
	<td class="line x" title="714:730	As discussed in Section 6.2, it is possible to increase the applicability (coverage) of the selection method by considering word co-occurrence in a limited context and/or by using similarity-based methods that reduce the problem of data sparseness." ></td>
	<td class="line x" title="715:730	To a lesser extent, the use of a bilingual corpus may further increase the precision of the selection (see Section 6.3)." ></td>
	<td class="line x" title="716:730	A practical strategy may be to use a bilingual corpus for enriching the bilingual lexicon, while relying mainly on co-occurrence statistics from a larger monolingual corpus for disambiguation." ></td>
	<td class="line x" title="717:730	In a broader context, this paper promotes the combination of statistical and linguistic models in natural language processing." ></td>
	<td class="line x" title="718:730	It provides an example of how a problem can be first defined in detailed linguistic terms, using an implemented linguistic tool (a syntactic parser, in our case)." ></td>
	<td class="line x" title="719:730	Then, having a well-defined linguistic scenario, we apply a suitable statistical model to highly informative linguistic structures." ></td>
	<td class="line x" title="720:730	According to this view, a complex task, such as machine translation, should be first decomposed 22 Optical character recognition can also be used to acquire relevant texts in electronic form." ></td>
	<td class="line x" title="721:730	In this case, it may be necessary to approximate the statistics using word co-occurrence in a window, since parsing noisy output from optical character recognition is difficult." ></td>
	<td class="line x" title="722:730	593 Computational Linguistics Volume 20, Number 4 on a linguistic basis." ></td>
	<td class="line x" title="723:730	Then, appropriate statistical models can be developed for each sub-problem." ></td>
	<td class="line x" title="724:730	We believe that this approach provides a beneficial compromise between two extremes in natural language processing: either using linguistic models that ignore quantitative information, or using statistical models that are linguistically ignorant." ></td>
	<td class="line x" title="725:730	Appendix Approximatingvar\[ln(~)l To approximate var \[In (~)\], we first approximate In (~)by the first order derivatives (the first term of the Taylor series): (\]91) ~__ ln( pI )__ \[~Xl (X1/\]~22 In ~ ~ '}(Pl --,1 ) In pl,p2 q-(\]92--P2) \[~-~21n(X~22)\]pl,p2 : ln(P~2) qfil--p~lpl \]92--P2p2 : ln(P~2)q-\]91 --\]92'pl P2 (5) We use the following equations (see Agresti 1990): var(x+c) = var(x), var(xl x2) = var(xl) + var(x2) 2." ></td>
	<td class="line x" title="726:730	covariance(xl,x2), var(~) -p(1-p), n (c) var(x) va r C2, covariance(fii, l~j ) PiPj n covariance( x l, x2)  r x1 x2 covamance( ~, ~2 ) = clc2 Using (5) we get var\[ln(~22)\] ~ var\[ln(P~221 +l~lp, ~21 = varI~11-~221 \[\]91\] \[lY2\]_2.covariance\[lYl,tY2 \] = var Pll +var P2 \[pl ~22 _ 1 p1(1 -Pl) + 1 p2(1 -P2) +2 PiP2 p2 n p2 n nplP2 1 1 1 1 1 1 +__~ + =--+--." ></td>
	<td class="line x" title="727:730	npl np2 np~l nl~ nl n2 594 Ido Dagan and Alon Itai Word Sense Disambiguation Acknowledgments Special thanks are due to Ulrike Schwall for her fruitful collaboration." ></td>
	<td class="line x" title="728:730	We are grateful to Mori Rimon, Peter Brown, Ayala Cohen, Ulrike Rackow, Herb Leass, and Bill Gale for their help and comments." ></td>
	<td class="line x" title="729:730	We also thank the anonymous reviewers for their detailed comments, which resulted in additional discussions and clarifications." ></td>
	<td class="line x" title="730:730	This research was partially supported by grant number 120-741 of the Israel Council for Research and Development." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P94-1032
Extracting Noun Phrases From Large-Scale Texts: A Hybrid Approach And Its Automatic Evaluation
Chen, Kuang-Hua;Chen, Hsin-Hsi;"></td>
	<td class="line x" title="1:252	Extracting Noun Phrases from Large-Scale Texts: A Hybrid Approach and Its Automatic Evaluation Kuang-hua Chen and Hsin-Hsi Chen Department of Computer Science and Information Engineering National Taiwan University Taipei, Taiwan, R.O.C. Internet: hh_chen@csie, ntu." ></td>
	<td class="line x" title="2:252	edu.tw Abstract To acquire noun phrases from running texts is useful for many applications, such as word grouping, terminology indexing, etc. The reported literatures adopt pure probabilistic approach, or pure rule-based noun phrases grammar to tackle this problem." ></td>
	<td class="line x" title="3:252	In this paper, we apply a probabilistic chunker to deciding the implicit boundaries of constituents and utilize the linguistic knowledge to extract the noun phrases by a finite state mechanism." ></td>
	<td class="line x" title="4:252	The test texts are SUSANNE Corpus and the results are evaluated by comparing the parse field of SUSANNE Corpus automatically." ></td>
	<td class="line x" title="5:252	The results of this preliminary experiment are encouraging." ></td>
	<td class="line x" title="6:252	1." ></td>
	<td class="line x" title="7:252	Introduction From the cognitive point of view, human being must recognize, learn and understand the entities or concepts (concrete or abstract) in the texts for natural language comprehension." ></td>
	<td class="line x" title="8:252	These entities or concepts are usually described by noun phrases." ></td>
	<td class="line x" title="9:252	The evidences from the language learning of children also show the belief (Snow and Ferguson, 1977)." ></td>
	<td class="line x" title="10:252	Therefore, if we can grasp the noun phases of the texts, we will understand the texts to some extent." ></td>
	<td class="line x" title="11:252	This consideration is also captured by theories of discourse analysis, such as Discourse Representation Theory (Kamp, 1981)." ></td>
	<td class="line x" title="12:252	Traditionally, to make out the noun phrases in a text means to parse the text and to resolve the attachment relations among the constituents." ></td>
	<td class="line x" title="13:252	However, parsing the text completely is very difficult, since various ambiguities cannot be resolved solely by syntactic or semantic information." ></td>
	<td class="line x" title="14:252	Do we really need to fully parse the texts in every application?" ></td>
	<td class="line oc" title="15:252	Some researchers apply shallow or partial parsers (Smadja, 1991; Hindle, 1990) to acquiring specific patterns from texts." ></td>
	<td class="line o" title="16:252	These tell us that it is not necessary to completely parse the texts for some applications." ></td>
	<td class="line x" title="17:252	This paper will propose a probabilistic partial parser and incorporate linguistic knowledge to extract noun phrases." ></td>
	<td class="line x" title="18:252	The partial parser is motivated by an intuition (Abney, 1991): (1) When we read a sentence, we read it chunk by chunk." ></td>
	<td class="line x" title="19:252	Abney uses two level grammar rules to implement the parser through pure LR parsing technique." ></td>
	<td class="line x" title="20:252	The first level grammar rule takes care of the chunking process." ></td>
	<td class="line x" title="21:252	The second level grammar rule tackles the attachment problems among chunks." ></td>
	<td class="line x" title="22:252	Historically, our statisticsbased partial parser is called chunker." ></td>
	<td class="line x" title="23:252	The chunker receives tagged texts and outputs a linear chunk sequences." ></td>
	<td class="line x" title="24:252	We assign a syntactic head and a semantic head to each chunk." ></td>
	<td class="line x" title="25:252	Then, we extract the plausible maximal noun phrases according to the information of syntactic head and semantic head, and a finite state mechanism with only 8 states." ></td>
	<td class="line x" title="26:252	Section 2 will give a brief review of the works for the acquisition of noun phrases." ></td>
	<td class="line x" title="27:252	Section 3 will describe the language model for chunker." ></td>
	<td class="line x" title="28:252	Section 4 will specify how to apply linguistic knowledge to assigning heads to each chunk." ></td>
	<td class="line x" title="29:252	Section 5 will list the experimental results of chunker." ></td>
	<td class="line x" title="30:252	Following Section 5, Section 6 will give the performance of our work on the retrieval of noun phrases." ></td>
	<td class="line x" title="31:252	The possible extensions of the proposed work will be discussed in Section 7." ></td>
	<td class="line x" title="32:252	Section 8 will conclude the remarks." ></td>
	<td class="line x" title="33:252	2." ></td>
	<td class="line x" title="34:252	Previous Works Church (1988) proposes a part of speech tagger and a simple noun phrase extractor." ></td>
	<td class="line x" title="35:252	His noun phrase extractor brackets the noun phrases of input tagged texts according to two probability matrices: one is starting noun phrase matrix; the other is ending noun phrase matrix." ></td>
	<td class="line x" title="36:252	The methodology is a simple version of Garside and Leech's probabilistic parser (1985)." ></td>
	<td class="line x" title="37:252	Church lists a sample text in the Appendix of his paper to show the performance of his work." ></td>
	<td class="line x" title="38:252	It demonstrates only 5 out of 248 noun phrases are omitted." ></td>
	<td class="line x" title="39:252	Because the tested text is too small to assess the results, the experiment for large volume of texts is needed." ></td>
	<td class="line x" title="40:252	234 Bourigault (1992) reports a tool, LEXTER, for extracting terminologies from texts." ></td>
	<td class="line x" title="41:252	LEXTER triggers two-stage processing: 1) analysis (by identification of frontiers), which extracts the maximal-length noun phrase: 2) parsing (the maximal-length noun phrases), which, furthermore, acquires the terminology embedded in the noun phrases." ></td>
	<td class="line x" title="42:252	Bourigault declares the LEXTER extracts 95/'0 maximal-length noun phrases, that is, 43500 out of 46000 from test corpus." ></td>
	<td class="line x" title="43:252	The result is validated by an expert." ></td>
	<td class="line x" title="44:252	However, the precision is not reported in the Boruigault's paper." ></td>
	<td class="line x" title="45:252	Voutilainen (1993) announces NPtool for acquisition of maximal-length noun phrases." ></td>
	<td class="line x" title="46:252	NPtool applies two finite state mechanisms (one is NP-hostile; the other is NP-friendly) to the task." ></td>
	<td class="line x" title="47:252	The two mechanisms produce two NP sets and any NP candidate with at least one occurrence in both sets will be labeled as the 'ok' NP." ></td>
	<td class="line x" title="48:252	The reported recall is 98.5-100% and the precision is 9598% validated manually by some 20000 words." ></td>
	<td class="line x" title="49:252	But from the sample text listed in Appendix of his paper, the recall is about 85%, and we can find some inconsistencies among these extracted noun phrases." ></td>
	<td class="line x" title="50:252	3." ></td>
	<td class="line x" title="51:252	Language Model Parsing can be viewed as optimizing." ></td>
	<td class="line x" title="52:252	Suppose an nword sentencc, w j, w 2 w (including punctuation marks), the parsing task is to find a parsing tree T, such that P(7\]w l, w e  w n) has the maximal probability." ></td>
	<td class="line x" title="53:252	We define T here to be a sequence of chunks, cp c 2  c m, and each c (0 < i <_ m) contains one or more words wj (0 < j _< n)." ></td>
	<td class="line x" title="54:252	For example, the sentence 'parsing can be viewed as optimization'." ></td>
	<td class="line x" title="55:252	consists of 7 words." ></td>
	<td class="line x" title="56:252	Its one possible parsing result under our demand is: (2) \[parsing\] \[can be viewed\] \[as optimization\] \[.\] C 1 C2 C3 C4 Now, the parsing task is to find the best chunk sequence, ('*." ></td>
	<td class="line x" title="57:252	such that (3) C*=argmaxP((,Iw,) Tile ('i is one possible chunk sequence, c\], C 2  Cmi, where m i is the number of chunks of the possible chunk sequence." ></td>
	<td class="line x" title="58:252	To chunk raw text without other information is ve.ry difficult, since the word patterns are many millions." ></td>
	<td class="line x" title="59:252	Therefore, we apply a tagger to preprocessing the raw texts and give each word a unique part of speech." ></td>
	<td class="line x" title="60:252	That is. for an n-word sentence, w 1, w 2  w n (including punctuation marks), we assign part of speeches t l, t 2  t n to the respective words." ></td>
	<td class="line x" title="61:252	Now the real working model is: (4) C* = argmaxP(C~lt,') Using bi-gram language model, we then reduce P(Cilt 1, t 2  tn) as (5), (5) n ~ n P(C, It, ) = P,(c, It, ) r~ C n _~ l-I P,(c, lc,_,,t~) t\],(,it, ) k=l -~ l-I P,(c.ic._,)  P,(c)." ></td>
	<td class="line x" title="62:252	k=l where Pi( ' ) denotes the probability for the i'th chunk sequence and c o denotes the beginning mark of a sentence." ></td>
	<td class="line x" title="63:252	Following (5), formula (4) becomes (6) argmaxP(C~lt~') = argmaxlI P (c, Ic,_, ) x P (c,) k=l = argmax~llog(P ~ (c, Ic,_, )) + log(P~ (c,))l k=l In order to make the expression (6) match the intuition of human being, namely, 1) the scoring metrics are all positive, 2) large value means high score, and 3) the scores are between 0 and 1, we define a score function S(P(  )) shown as (7)." ></td>
	<td class="line x" title="64:252	(7) S(P(  )) = 0 when P(  ) = 0; S(P(." ></td>
	<td class="line x" title="65:252	))= 1.0/(1.0+ABS(Iog(P(." ></td>
	<td class="line x" title="66:252	)))) o/w. We then rewrite (6) as (8)." ></td>
	<td class="line x" title="67:252	(8) C* = argmaxP(C, It,') n~ -= argmaxII P,(q \[c._,) x P, (c)." ></td>
	<td class="line x" title="68:252	f=l = argmax Z \[log(P~ (c, Ic,_, )) + log(P~ (c,))l k=l r~ = argmaxE 18(P ~ (c. Ic._, )) + S(P, (c.))l k=l The final language model is to find a chunk sequence C*, which satisfies the expression (8)." ></td>
	<td class="line x" title="69:252	Dynamic programming shown in (9) is used to find the best chunk sequence." ></td>
	<td class="line x" title="70:252	The score\[i\] denotes the score of position i. The words between position pre\[i\] and position i form the best chunk from the viewpoint of position i. The dscore(cO is the score of the probability 235 P(ci) and the cscore(ci\[ci-l) is the score of the probability P(cilci-l)." ></td>
	<td class="line x" title="71:252	These scores are collected from the training corpus, SUSANNE corpus (Sampson, 1993; Sampson, 1994)." ></td>
	<td class="line x" title="72:252	The details will be touched on in Section 5." ></td>
	<td class="line x" title="73:252	(9) Algorithm input : word sequence wl, w2  wn, and the corresponding POS sequence t~, t2  tn output : a sequence of chunks c~, c2,  , Cm 1." ></td>
	<td class="line x" title="74:252	score\[0\] = 0; prel0l = 0, 2." ></td>
	<td class="line x" title="75:252	for (i = 1: i<n+l; i++) do 3 and 4; 3." ></td>
	<td class="line x" title="76:252	j*= maxarg (score\[prelJ\]l+dscore(cj)+cscore(cjlcj-1)); 0~_j<i where cj = tj+~  ti; Cj-1 = tpre\[j\]+l  tj; 4." ></td>
	<td class="line x" title="77:252	score\[il=scorelpreiJ*ll+dscore(cj*)+cscore(cj*lq*-0; prelil = j*: 5." ></td>
	<td class="line x" title="78:252	for (i=n; i>0; i=preli\]) do output the word Wpre\[i\]+l  wi to form a chunk; 4." ></td>
	<td class="line x" title="79:252	Linguistic Knowledge In order to assign a head to each chunk, we first define priorities of POSes." ></td>
	<td class="line x" title="80:252	X'-theory (Sells, 1985) has defined the X'-equivalences shown as Table 1." ></td>
	<td class="line x" title="81:252	Table 1." ></td>
	<td class="line x" title="82:252	X'-Equivalences R t, ~ X' NP V V' VP A A' AP p p' pp INFL S (I') S' (IP) Table 1 defines five different phrasal structures and the hierarchical structures." ></td>
	<td class="line x" title="83:252	The heads of these phrasal structures are the first level of X'-Equivalences, that is, X. The other grammatical constituents function as the specifiers or modifiers, that is, they are accompanying words not core words." ></td>
	<td class="line x" title="84:252	Following this line, we define the primary priority of POS listed in Table 1." ></td>
	<td class="line x" title="85:252	(10) Primary POS priority 1 : V > N > A > P In order to extract the exact head, we further define Secondary POS priority among the 134 POSes defined in LOB corpus (Johansson, 1986)." ></td>
	<td class="line x" title="86:252	(11) Secondary POS priority is a linear precedence relationship within the primary priorities for coarse POSes I We do not consider the INFL." ></td>
	<td class="line x" title="87:252	since our model will not touch on this structure." ></td>
	<td class="line x" title="88:252	For example, LOB corpus defines four kinds of verbial words under the coarse POS V: VB*, DO*, BE* and HV* 2." ></td>
	<td class="line x" title="89:252	The secondary priority within the coarse POS V is: (12) VB* > I-iV* > DO* > BE* Furthermore, we define the semantic head and the syntactic head (Abney, 1991)." ></td>
	<td class="line x" title="90:252	(13) Semantic head is the head of a phrase according to the semantic usage; but syntactic head is the head based on the grammatical relations." ></td>
	<td class="line x" title="91:252	Both the syntactic head and the semantic head are useful in extracting noun phrases." ></td>
	<td class="line x" title="92:252	For example, if the semantic head of a chunk is the noun and the syntactic one is the preposition, it would be a prepositional phrase." ></td>
	<td class="line x" title="93:252	Therefore, it can be connected to the previous noun chunk to form a new noun phrase." ></td>
	<td class="line x" title="94:252	In some case, we will find some chunks contain only one word, called oneword chunks." ></td>
	<td class="line x" title="95:252	They maybe contain a conjunction, e.g., that." ></td>
	<td class="line x" title="96:252	Therefore." ></td>
	<td class="line x" title="97:252	the syntactic head and the semantic head of one-word chunks are the word itself." ></td>
	<td class="line x" title="98:252	Following these definitions, we extract the noun phrases by procedure (14): (14) (a) Co) (c) (d) Tag the input sentences." ></td>
	<td class="line x" title="99:252	Partition the tagged sentences into chunks by using a probabilistic partial parser." ></td>
	<td class="line x" title="100:252	Decide the syntactic head and the semantic head of each chunk." ></td>
	<td class="line x" title="101:252	According to the syntactic and the semantic heads, extract noun phrase from these chunks and connect as many noun phrases as possible by a finite state mechanism." ></td>
	<td class="line x" title="102:252	raw tagged chunked (TAoPER) NPso, Figure 1." ></td>
	<td class="line x" title="103:252	The Noun Phrases Extraction Procedure Figure 1 shows the procedure." ></td>
	<td class="line x" title="104:252	The input raw texts will be assigned POSes to each word and then pipelined into 2 Asterisk * denotes wildcard." ></td>
	<td class="line x" title="105:252	Therefore, VB* represents VB (verb, base form), VBD (verb, preterite), VBG (present participle), VBN (past participle) and VBZ (3rd singular form of verb)." ></td>
	<td class="line x" title="106:252	236 a chunker." ></td>
	<td class="line x" title="107:252	The tag sets of LOB and SUSANNE are different." ></td>
	<td class="line x" title="108:252	Since the tag set of SUSANNE corpus is subsumed by the tag set of LOB corpus, a TAGMAPPER is used to map tags of SUSANNE corpus to those of LOB corpus." ></td>
	<td class="line x" title="109:252	The chunker will output a sequence of chunks." ></td>
	<td class="line x" title="110:252	Finally, a finite state NPTRACTOR will extract NPs." ></td>
	<td class="line x" title="111:252	Figure 2 shows the finite state mechanism used in our work." ></td>
	<td class="line x" title="112:252	CD* * J.'~ ~'.r,ff~* VBN or P'l _, ,N~w-w,~ '~'~ VBN o~ i~--,,w~ k~ Figure 2." ></td>
	<td class="line x" title="113:252	The Finite State Machine for Noun Phrases The symbols in Figure 2 are tags of LOB corpus." ></td>
	<td class="line x" title="114:252	N* denotes nous: P* denotes pronouns; J* denotes adjectives; A* denotes quantifiers, qualifiers and determiners; IN denotes prepositions: CD* denotes cardinals; OD* denotes ordinals, and NR* denotes adverbial nouns." ></td>
	<td class="line x" title="115:252	Asterisk * denotes a wildcard." ></td>
	<td class="line x" title="116:252	For convenience, some constraints, such as syntactic and semantic head checking, are not shown in Figure 2." ></td>
	<td class="line x" title="117:252	5. First Stage of Experiments Following the procedures depicted in Figure 1, we should train a chunker firstly." ></td>
	<td class="line x" title="118:252	This is done by using the SUSANNE Corpus (Sampson, 1993; Sampson, 1994) as the training texts." ></td>
	<td class="line x" title="119:252	The SUSANNE Corpus is a modified and condensed version of Brown Corpus (Francis and Kucera, 1979)." ></td>
	<td class="line x" title="120:252	It only contains the 1/10 of Brown Corpus, but involves more information than Brown Corpus." ></td>
	<td class="line x" title="121:252	The Corpus consists of four kinds of texts: 1) A: press reportage; 2) G: belles letters, biography, memoirs; 3) J: learned writing; and 4) N: adventure and Western fiction." ></td>
	<td class="line x" title="122:252	The Categories of A, G, J and N are named from respective categories of the Brown Corpus." ></td>
	<td class="line x" title="123:252	Each Category consists of 16 files and each file contains about 2000 words." ></td>
	<td class="line x" title="124:252	The following shows a snapshot of SUSANNE Corpus." ></td>
	<td class="line x" title="125:252	G01:00\]0a YB ~minbrk> \[Oh." ></td>
	<td class="line x" title="126:252	Oh\] G0\]:O0\]0b JJ NORTHERN northern \[O\[S\[Np:s. G01:0010c NN2 liberals liberal .Np:s\] G0\]:0010d VBR are be \[Vab." ></td>
	<td class="line x" title="127:252	Vab\] G0\]:0010e AT the the \[Np:e. G0l:0010f JB chief chief G0\]:fl010g NN2 supporters supporter G01:0010h IO of of \[Po." ></td>
	<td class="line x" title="128:252	G01:0010i JJ civil civi\] \[Np." ></td>
	<td class="line x" title="129:252	G01:0010j NN2 rights right .Np\] G01:0020a CC and and !Po~." ></td>
	<td class="line x" title="130:252	G01:0020b IO of of G01:0020c NNIu integration integration .Po+\]Po\]Np:eI5\] G01:0020d YF +." ></td>
	<td class="line x" title="131:252	Table 2 lists basic statistics of SUSANNE Corpus." ></td>
	<td class="line x" title="132:252	Table 2." ></td>
	<td class="line x" title="133:252	The Overview of SUSANNE Corpus C~e~ofies \[ Files \[ Paragraphs I Sentences \[ Words A 16 767 1445 37'180 G 16 280 1554 37583 J 16 197 1353 36554 N 16 723 2568 38736 To~l I 64 I 1967 I 6920 I 150053 In order to avoid the errors introduced by tagger, the SUSANNE corpus is used as the training and testing texts." ></td>
	<td class="line x" title="134:252	Note the tags of SUSANNE corpus are mapped to LOB corpus." ></td>
	<td class="line x" title="135:252	The 3/4 of texts of each categories of SUSANNE Corpus are both for training the chunker and testing the chunker (inside test)." ></td>
	<td class="line x" title="136:252	The rest texts are only for testing (outside test)." ></td>
	<td class="line x" title="137:252	Every tree structure contained in the parse field is extracted to form a potential chunk grammar and the adjacent tree structures are also extracted to form a potential context chunk grammar." ></td>
	<td class="line x" title="138:252	After the training process, total 10937 chunk grammar rules associated with different scores and 37198 context chunk grammar rules are extracted." ></td>
	<td class="line x" title="139:252	These chunk grammar rules are used in the chunking process." ></td>
	<td class="line x" title="140:252	Table 3 lists the time taken for processing SUSANNE corpus." ></td>
	<td class="line x" title="141:252	This experiment is executed on the Sun Sparc 10, model 30 workstation, T denotes time, W word, C chunk, and S sentence." ></td>
	<td class="line x" title="142:252	Therefore, T/W means the time taken to process a word on average." ></td>
	<td class="line x" title="143:252	\[, A G J N Av." ></td>
	<td class="line x" title="144:252	II Table 3." ></td>
	<td class="line x" title="145:252	The Processing Time T/W T/C T/S 0.00295 0.0071 0.0758 0.00283 0.0069 0.0685 0.00275 0.0073 0.0743 0.00309 0.0066 0.0467 0.00291 1 0.0()70 \] 0.0663 According to Table 3, to process a word needs 0.00291 seconds on average." ></td>
	<td class="line x" title="146:252	To process all SUSANNE corpus needs about 436 seconds, or 7.27 minutes." ></td>
	<td class="line x" title="147:252	In order to evaluate the performance of our chunker, we compare the results of our chunker with the denotation made by the SUSANNE Corpus." ></td>
	<td class="line x" title="148:252	This comparison is based on the following criterion: (15) The content of each chunk should be dominated by one non-terminal node in SUSANNE parse field." ></td>
	<td class="line x" title="149:252	237 This criterion is based on an observation that each nonterminal node has a chance to dominate a chunk." ></td>
	<td class="line x" title="150:252	Table 4 is the experimental results of testing the SUSANNE Corpus according to the specified criterion." ></td>
	<td class="line x" title="151:252	As usual, the symbol C denotes chunk and S denotes sentence." ></td>
	<td class="line x" title="152:252	Table 4." ></td>
	<td class="line x" title="153:252	Experimental Results [t Cat." ></td>
	<td class="line x" title="154:252	C' [ -S -# of correct 4866 380 10480 1022 A # of incorrect 40 14 84 29 total# 4906 394 10564 1051 correct rate 0.99 0.96 0.99 0.97 # of correct 4748 355 10293 1130 G # of incorrect 153 32 133 37 total# 4901 387 10426 1167 correct rate 0.97 0.92 0.99 0,97 # of correct 4335 283 9193 1032 J # of incorrect 170 15 88 23 total# 4505 298 9281 1055 correct rate 0.96 0.95 0.99 0,98 # of correct 5163 536 12717 1906 N # of incorrect 79 42 172 84 total# 5242 578 12889 1990 correct rate 0,98 0.93 0.99 0.96 # of correct 19112 1554 42683 5090 Av." ></td>
	<td class="line x" title="155:252	# of incorrect 442 103 477 173 total# 19554 1657 43160 5263 correct rate 0.98 0.94 0.99 0.97 Table 4 shows the chunker has more than 98% chunk correct rate and 94% sentence correct rate in outside test, and 99% chunk correct rate and 97% sentence correct rate in inside test." ></td>
	<td class="line x" title="156:252	Note that once a chunk is mischopped, the sentence is also mischopped." ></td>
	<td class="line x" title="157:252	Therefore, sentence correct rate is always less than chunk correct rate." ></td>
	<td class="line x" title="158:252	Figure 3 gives a direct view of the correct rate of this chunker." ></td>
	<td class="line x" title="159:252	1 0.94 0 92 09 II g8  Chunk Sentence Chunk Setltence Outside Test Inside Test Figure 3." ></td>
	<td class="line x" title="160:252	The Correct Rate of Experiments 6." ></td>
	<td class="line x" title="161:252	Acquisition of Noun Phrases We employ the SUSANNE Corpus as test corpus." ></td>
	<td class="line x" title="162:252	Since the SUSANNE Corpus is a parsed corpus, we may use it as criteria for evaluation." ></td>
	<td class="line x" title="163:252	The volume of test texts is around 150,000 words including punctuation marks." ></td>
	<td class="line x" title="164:252	The time needed from inputting texts of SUSANNE Corpus to outputting the extracted noun phrases is listed in Table 5." ></td>
	<td class="line x" title="165:252	Comparing with Table 3, the time of combining chunks to form the candidate noun phrases is not significant." ></td>
	<td class="line x" title="166:252	Table 5." ></td>
	<td class="line x" title="167:252	Time for Acquisition of Noun Phrases II A G J N Total II Words Time (see)." ></td>
	<td class="line x" title="168:252	Time/Word 37180 112.32 0.00302 37583 108.80 0.00289 36554 103.04 0.00282 38736 122.72 0.00317 150053 I 446.88 I 0.00298 The evaluation is based on two metrics: precision and recall." ></td>
	<td class="line x" title="169:252	Precision means the correct rate of what the system gets." ></td>
	<td class="line x" title="170:252	Recall indicates the extent to which the real noun phrases retrieved from texts against the real noun phrases contained in the texts." ></td>
	<td class="line x" title="171:252	Table 6 describes how to calculate these metrics." ></td>
	<td class="line x" title="172:252	Table 6." ></td>
	<td class="line x" title="173:252	Contingency Table for Evaluation 1 SUSANNE NP ] non-NP ]l NP systm,l .on NP }} a I b The rows of 'System' indicate our NP-TRACTOR thinks the candidate as an NP or not an NP: the columns of 'SUSANNE' indicate SUSANNE Corpus takes the candidate as an NP or not an NP." ></td>
	<td class="line x" title="174:252	Following Table 6, we will calculate precision and recall shown as (16)." ></td>
	<td class="line x" title="175:252	(16) Precision = a/(a+b) * 100% Recall = a/(a+c) * 100% To calculate the precision and the recall based on the parse field of SUSANNE Corpus is not so straightforward at the first glance." ></td>
	<td class="line x" title="176:252	For example, (17) 3 itself is a noun phrse but it contains four noun phrases." ></td>
	<td class="line x" title="177:252	A tool for extracting noun phrases should output what kind of and how many noun phrases, when it processes the texts like (17)." ></td>
	<td class="line x" title="178:252	Three kinds of noun phrases (maximal noun phrases, minimal noun phrases and ordinary noun phrases) are defined first." ></td>
	<td class="line x" title="179:252	Maximal noun phrases are those noun phrases which are not contained in other noun phrases." ></td>
	<td class="line x" title="180:252	In contrast, minimal noun phrases do not contain any other noun phrases." ></td>
	<td class="line x" title="181:252	3 This example is taken from N06:0280d-N06:0290d, Susanne Corpus (N06 means file N06, 0280 and 0290 are the original line numbers in Brown Corpus." ></td>
	<td class="line x" title="182:252	Recall that the Susanne Corpus is a modified and reduced version of Brown Corpus)." ></td>
	<td class="line x" title="183:252	238 Apparently, a noun phrase may be both a maximal noun phrase and a minimal noun phrase." ></td>
	<td class="line x" title="184:252	Ordinary noun phrases are noun phrases with no restrictions." ></td>
	<td class="line x" title="185:252	Take (17) as an example." ></td>
	<td class="line x" title="186:252	It has three minimal noun phrases, one maximal noun phrases and five ordinary noun phrases." ></td>
	<td class="line x" title="187:252	In general, a noun-phrase extractor forms the front end of other applications, e.g., acquisition of verb subcategorization frames." ></td>
	<td class="line x" title="188:252	Under this consideration, it is not appropriate to taking (17) as a whole to form a noun phrase." ></td>
	<td class="line x" title="189:252	Our system will extract two noun phrases from (17)." ></td>
	<td class="line x" title="190:252	'a black badge of frayed respectability' and 'his neck'." ></td>
	<td class="line x" title="191:252	(17) ilia black badge\] of lfrayed respectabilityll that ought never to have left \[his neck\]\] We calculate the numbers of maximal noun phrases, minimal noun phrases and ordinary noun phrases denoted in SUSANNE Corpus, respectively and compare these numbers with the number of noun phrases extracted by our system." ></td>
	<td class="line x" title="192:252	Table 7 lists the number of ordinary noun phrases (NP), maximal noun phrases (MNP), minimal noun phrases (mNP) in SUSANNE Corpus." ></td>
	<td class="line x" title="193:252	MmNP denotes the maximal noun phrases which are also the minimal noun phrases." ></td>
	<td class="line x" title="194:252	On average, a maximal noun phrase subsumes 1.61 ordinary noun phrases and 1.09 minimal noun phrases." ></td>
	<td class="line x" title="195:252	Table 7." ></td>
	<td class="line x" title="196:252	The Number of Noun Phrases in Corpus A G J N Total jNP\[ MNPI mNPIMmNPI NP I mNP MNP 10063 5614 6503 3207 1.79 1.16 9221 5451 6143 3226 1.69 1.13 8696 4568 5200 2241 1.90 1.14 9851 7895 7908 5993 1.25 1.00 37831 23528 25754 14667 1.61 1.09 To calculate the precision, we examine the extracted noun phrases (ENP) and judge the correctness by the SUSANNE Corpus." ></td>
	<td class="line x" title="197:252	The CNP denotes the correct ordinary noun phrases, CMNP the correct maximal noun phrases." ></td>
	<td class="line x" title="198:252	CmNP correct minimal noun phrases and CMmNP the correct maximal noun phrases which are also the minimal noun phrases." ></td>
	<td class="line x" title="199:252	The results are itemized in Table 8." ></td>
	<td class="line x" title="200:252	The average precision is 95%." ></td>
	<td class="line x" title="201:252	Table 8." ></td>
	<td class="line x" title="202:252	Precision of Our System U ENp I I CMNP I CmNP I C nNP I eci ion A 8011 7660 3709 4348 3047 0.96 G 7431 6943 3626 4366 3028 0.93 J 6457 5958 2701 3134 2005 0.92 N 8861 8559 6319 6637 5808 0.97 To~l 30760 29120 16355 18485 13888 0.95 Here, the computation of recall is ambiguous to some extent." ></td>
	<td class="line x" title="203:252	Comparing columns CMNP and CmNP in Table 8 with columns MNP and mNP in Table 7, 70% of MNP and 72% of mNP in SUSANNE Corpus are extracted, In addition, 95% of MmNP is extracted by our system." ></td>
	<td class="line x" title="204:252	It means the recall for extracting noun phrases that exist independently in SUSANNE Corpus is 95%." ></td>
	<td class="line x" title="205:252	What types of noun phrases are extracted are heavily dependent on what applications we will follow." ></td>
	<td class="line x" title="206:252	We will discuss this point in Section 7." ></td>
	<td class="line x" title="207:252	Therefore, the real number of the applicable noun phrases in the Corpus is not known." ></td>
	<td class="line x" title="208:252	The number should be between the number of NPs and that of MNPs." ></td>
	<td class="line x" title="209:252	In the original design for NP-TRACTO1L a maximal noun phrase which contains clauses or prepositional phrases with prepositions other than 'of' is not considered as an extracted unit." ></td>
	<td class="line x" title="210:252	As the result, the number of such kinds of applicable noun phrases (ANPs) form the basis to calculate recall." ></td>
	<td class="line x" title="211:252	These numbers are listed in Table 9 and the corresponding recalls are also shown." ></td>
	<td class="line x" title="212:252	Table 9." ></td>
	<td class="line x" title="213:252	The limitation of Values for Recall A G J N Av, 1 ANP CNP 7873 7660 7199 6943 6278 5958 8793 8559 30143 29120 I Recall 0.97 0.96 0.95 0.97 0.96 The automatic validation of the experimental results gives us an estimated recall." ></td>
	<td class="line x" title="214:252	Appendix provides a sample text and the extracted noun phrases." ></td>
	<td class="line x" title="215:252	Interested readers could examine the sample text and calculate recall and precision for a comparison." ></td>
	<td class="line x" title="216:252	7." ></td>
	<td class="line x" title="217:252	Applications Identification of noun phrases in texts is useful for many applications." ></td>
	<td class="line x" title="218:252	Anaphora resolution (Hirst, 1981) is to resolve the relationship of the noun phrases, namely, what the antecedent of a noun phrase is. The extracted noun phrases can form the set of possible candidates (or universal in the terminology of discourse representation theory)." ></td>
	<td class="line x" title="219:252	For acquisition of verb subcategorization frames, to bracket the noun phrases in the texts is indispensable." ></td>
	<td class="line x" title="220:252	It can help us to find the boundary of the subject, the object and the prepositional phrase." ></td>
	<td class="line x" title="221:252	We would use the acquired noun phrases for an application of adjective grouping." ></td>
	<td class="line x" title="222:252	The extracted noun phrases may contain adjectives which pre-modify the head noun." ></td>
	<td class="line x" title="223:252	We then utilize the similarity of head nouns to group the adjectives." ></td>
	<td class="line x" title="224:252	In addition, we may give the head noun a semantic tag, such as Roget's Thesaurus provides, and then analyze the adjectives." ></td>
	<td class="line x" title="225:252	To automatically produce the index of a book, 239 we would extract the noun phrases contained in the book, calculate the inverse document frequency (IDF) and their term frequency (TF) (Salton, 1991), and screen out the implausible terms." ></td>
	<td class="line x" title="226:252	These applications also have impacts on identifying noun phrases." ></td>
	<td class="line x" title="227:252	For applications like anaphora resolution and acquisition of verb subcategorization frames, the maximal noun phrases are not suitable." ></td>
	<td class="line x" title="228:252	For applications like grouping adjectives and automatic book indexing, some kinds of maximal noun phrases, such as noun phrases postmodified by 'of' prepositional phrases, are suitable: but some are not, e.g., noun phrases modified by relative clauses." ></td>
	<td class="line x" title="229:252	8." ></td>
	<td class="line x" title="230:252	Concluding Remarks The difficulty of this work is how to extract the real maximal noun phrases." ></td>
	<td class="line x" title="231:252	If we cannot decide the prepositional phrase 'over a husband eyes' is licensed by the verb 'pull', we will not know 'the wool' and 'a husband eyes' are two noun phrases or form a noun pharse combined by the preposition 'over'." ></td>
	<td class="line x" title="232:252	(18) to pull the wool over a husband eyes to sell the books of my uncle In contrast, the noun phrase 'the books of my uncle' is so called maximal noun phrase in current context." ></td>
	<td class="line x" title="233:252	As the result, we conclude that if we do not resolve PPattachment problem (Hindle and Rooth, 1993), to the expected extent, we will not extract the maximal noun phrases." ></td>
	<td class="line x" title="234:252	In our work, the probabilistic chunker decides the implicit boundaries between words and the NPTRACTOR connects the adjacent noun chunks." ></td>
	<td class="line x" title="235:252	When a noun chunk is followed by a preposition chunk, we do not connect the two chunks except the preposition chunk is led by 'of' preposition." ></td>
	<td class="line x" title="236:252	Comparing with other works, our results are evaluated by a parsed corpus automatically and show the high precision." ></td>
	<td class="line x" title="237:252	Although we do not point out the exact recall, we provide estimated values." ></td>
	<td class="line x" title="238:252	The testing scale is large enough (about 150,000 words)." ></td>
	<td class="line x" title="239:252	In contrast, Church (1988) tests a text and extracts the simple noun phrases only." ></td>
	<td class="line x" title="240:252	Bourigault's work (1992) is evaluated manually, and dose not report the precision." ></td>
	<td class="line x" title="241:252	Hence, the real performance is not known." ></td>
	<td class="line x" title="242:252	The work executed by Voutilainen (1993) is more complex than our work." ></td>
	<td class="line x" title="243:252	The input text first is morphologizied, then parsed by constraint grammar, analyzed by two different noun phrases grammar and finally extracted by the occurrences." ></td>
	<td class="line x" title="244:252	Like other works, Voutilainen's work is also evaluated manually." ></td>
	<td class="line x" title="245:252	In this paper, we propose a language model to chunk texts." ></td>
	<td class="line x" title="246:252	The simple but effective chunker could be seen as a linear structure parser, and could be applied to many applications." ></td>
	<td class="line x" title="247:252	A method is presented to extract the noun phrases." ></td>
	<td class="line x" title="248:252	Most importantly, the relations of maximal noun phrases, minimal noun phrases, ordinary noun phrases and applicable noun phrases are distinguished in this work." ></td>
	<td class="line x" title="249:252	Their impacts on the subsequent applications are also addressed." ></td>
	<td class="line x" title="250:252	In addition, automatic evaluation provides a fair basis and does not involve human costs." ></td>
	<td class="line x" title="251:252	The experimental results show that this parser is a useful tool for further research on large volume of real texts." ></td>
	<td class="line x" title="252:252	Acknowledgements We are grateful to Dr. Geoffrey Sampson for his kindly providing SUSANNE Corpus and the details of tag set to US." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C96-1003
Clustering Words With The MDL Principle
Li, Hang;Abe, Naoki;"></td>
	<td class="line x" title="1:199	Clustering Words with the MDL Principle Hang Li and Naoki Abe Theory NEC Laboratory, RWCP* c/o C&C Research Labora.tories, NEC 4-1-1 Miya~zaki Miyamae-ku, Ke~wasa.ki, 216 Japan {lihang,abe} (@sbl.cl.nee.co.jp Abstract We address the probhml of automaticMly constructing a thesaurus by clustering words based on corpus data." ></td>
	<td class="line x" title="2:199	We view this problem as that of estimating a joint distribution over the (:artesian product of a partition of a set of nouns and a partition of a set of verbs, and propose a learning a.lgorithm based on the Mininmm Description Length (MDL) Principle for such estimation." ></td>
	<td class="line x" title="3:199	We empirically compared the performance of our method based on the MDL Principle against the Maximum Likelihood Estimator in word clustering, and found that the former outperforms the latter." ></td>
	<td class="line x" title="4:199	~Ve also evaluated the method by conducting pp-attachment disambiguation experiments using an automaticMly constructed thesaurus." ></td>
	<td class="line x" title="5:199	Our experimental results indicate that such a thesaurus can be used to improve accuracy in disambiguation." ></td>
	<td class="line o" title="6:199	1 Introduction Recently various methods for automatically constructing a thesaurus (hierarchically clustering words) based on corpus data." ></td>
	<td class="line oc" title="7:199	have been proposed (Hindle, 1990; Brown et al. , 1992; Pereira et al. , 1993; Tokunaga et al. , 1995)." ></td>
	<td class="line p" title="8:199	The realization of such an automatic construction method would make it possible to a) save the cost of constructing a thesaurus by hand, b) do away with subjectivity inherent in a hand made thesaurus, and c) make it easier to adapt a natural language processing system to a new domain." ></td>
	<td class="line x" title="9:199	In this paper, we propose a new method for automatic construction of thesauri." ></td>
	<td class="line x" title="10:199	Specifically, we view the problem of automatically clustering words as that of estimating a joint distributiofl over the Cartesian product of a partition of a set of nouns (in general, any set of words) and a partition of a set of w:rbs (in general, any set of words), and propose an est.imation *Real World Computing Partership algorithm using simulated annealing with an energy function based on the blinimum Description Length (MDL) Principle." ></td>
	<td class="line x" title="11:199	The MDL Principle is a well-motivated and theoretically sound principle for data compression and estimation in information theory and statistics." ></td>
	<td class="line x" title="12:199	As a method of statisticM estimation MDL is guaranteed to be near optimal." ></td>
	<td class="line x" title="13:199	We empiricMly evMuated the effectiveness of our method." ></td>
	<td class="line x" title="14:199	In particular, we compared the performance of an MDL-based sinm\]ated anuealilag Mgorithm in hierarchical word clustering against." ></td>
	<td class="line x" title="15:199	that of one based on the Maximum Likelihood Estimator (MLE, for short)." ></td>
	<td class="line x" title="16:199	We found that the MDL-based method performs better than the MLE-based method." ></td>
	<td class="line x" title="17:199	We also evaluated our method by conducting pp-attachment disambiguation experiments using a thesaurus automatically constructed by it and found that disambiguation results can be improved." ></td>
	<td class="line x" title="18:199	Since some words never occur in a corpus, and thus cannot be reliably classified by a method solely based on corpus data, we propose to combine the use of an automatically constructed thesaurus and a hand made thesaurus in disambiguation." ></td>
	<td class="line x" title="19:199	We conducted some experiments in order to test the effectiveness of this strategy." ></td>
	<td class="line x" title="20:199	Our experimental results indicate that combining an automatically constructed thesaurus and a hand made thesaurus widens the coverage 1 of our disambiguation method, while maintaining high accuracy e. 2 The Problem Setting A method of constructing a thesaurus based on corpus data usually consists of the following three steps: (i) Extract co-occurrence data (e.g. case frame data, adjacency data) fl'om a corpus, (ii) Starting from a single class (or each word composing its own class), divide (or merge) word classes 1 ~Cover~tge' refers to the proportion (in percentage) of test data for which the disambiguat.ion method can make a decision." ></td>
	<td class="line x" title="21:199	2'Accuracy' refers to the success rate, given that the disambiguation method makes a decision." ></td>
	<td class="line x" title="22:199	based Oll the co-occurrence data using 8Ollle Sill> ilarity (distance) measure." ></td>
	<td class="line x" title="23:199	(The former apl)roach is called 'divisive', the latter 'agglomerative')." ></td>
	<td class="line x" title="24:199	(iii) Repeat step (ii) until some stopping condition is met, to construct a thesaurus (tree)." ></td>
	<td class="line x" title="25:199	The method we propose here consists of the same three st.eps." ></td>
	<td class="line x" title="26:199	Suppose available to us are frequency data (cooccurrence data)." ></td>
	<td class="line x" title="27:199	between verbs and their case slot." ></td>
	<td class="line x" title="28:199	values extracted from a corpus (step (i))." ></td>
	<td class="line x" title="29:199	We then view the problem of clustering words as that of estimating a probabilistic model (representing a. probability distribution) tllat generates such data We assume that the target model can be defined in the following way." ></td>
	<td class="line x" title="30:199	First, we define a noun partition 'PA. ~ over a given set of nouns'V' and a verb partioll 'Pv over a given set." ></td>
	<td class="line x" title="31:199	of verbs 12." ></td>
	<td class="line x" title="32:199	A noun partition is any set T'-~ satisfying 'P,~ C 2 H, Wc~e'&v('i = A/ and VCi, () E 7)A.', Ci 0 (/j = O. A verb partition 7)v is defined analogously." ></td>
	<td class="line x" title="33:199	In this paper, we call a member of a noun partition 'a, llOUll cluster', and a nlenlbe, r of a verb partition a ~verb cluster'." ></td>
	<td class="line x" title="34:199	We refer to a member of the Cartesian product of a noun partition and a verb partition ( C 'P:v x 'Pv ) simply as 'a cluster'." ></td>
	<td class="line x" title="35:199	We then define a probabilistic model (a joint distribution), written I'(C,, (:v), where random variable C,, assumes a value fl'om a fizcd nouu partition ~PX, and C~." ></td>
	<td class="line x" title="36:199	a va.lue from a fixed verb partition 7)v. Within a given cluster, we assume thai each element is generated with equal probability, i.e., P(c,,,c~,) v. , E c,,,v,,, E c,,, P(,,,,,,) IC." ></td>
	<td class="line x" title="37:199	x <,1 (t) In this paper, we assume that the observed data are generaied by a model belonging to the class of models just de.scribed, and select a model which best explains the data As a result of this, we obtain both noun clusters and verb clusters." ></td>
	<td class="line x" title="38:199	This problem setting is based on the intuit.lye assumption that similar words occur in the sa.me context with roughly equal likelihood, as is made explicit in equation (l)." ></td>
	<td class="line x" title="39:199	Thus selecting a model which best explains the given data is equivalent to finding the most appropriate classification of words base(t on their co-occurrence." ></td>
	<td class="line x" title="40:199	3 Clustering with MDL We now turn to the question of what." ></td>
	<td class="line x" title="41:199	strategy (or criterion) we should employ for estimating the best model." ></td>
	<td class="line x" title="42:199	Our choice is the MDL (Minimum Description I,ength) principle (tlissanen, 1989), a well-known principle of data compression and statistical estimation from inforlnation theory." ></td>
	<td class="line x" title="43:199	MDI, stipulates that the best probability model for given data is that model which requires the least cod(: length \['or encoding of the model itself, as well as the giwql data relative to it a. We refer to the code length for the model aWe refer /.he interested reader to eli aml Abe, 1!195) for explana.tion of ra.tionals behind using the as 'the model description h'ngth' and that for tile data 'the data description length'." ></td>
	<td class="line x" title="44:199	We apply MDI, to the problem of estimating a model consisting of a pair of partitions as described above." ></td>
	<td class="line x" title="45:199	In this context, a model with less clusters tends to be simpler (in t.erms of the number of parameters), but also tends to have a poorer fit." ></td>
	<td class="line x" title="46:199	to the data." ></td>
	<td class="line x" title="47:199	In contrast, a model with more clusters is more complex, but tends to have a better fit to the data." ></td>
	<td class="line x" title="48:199	Thus, there is a trade-off relationship between the simplicity of a model and the goodness of fit to the data." ></td>
	<td class="line x" title="49:199	The model description length quantifies the simplicity (complexity) of a model, and the data description length quantifies the tlt." ></td>
	<td class="line x" title="50:199	to the data." ></td>
	<td class="line x" title="51:199	According to MDL, the model which minimizes the sum total of the two types of description lengths should be selected." ></td>
	<td class="line x" title="52:199	In what follows, we will describe in detail how the description length is to be calculated in our current context, as well as our silnulated annealing algorithm based on MI)L. 3.1 Calculating Description Length We will now describe how the description length for a model is calculated, lh'call that each model is specified by the Cartesian product of a partition of nouns and a partition of verbs, and a number of parameters for them." ></td>
	<td class="line x" title="53:199	Here we let /,', denote the size of the noun partition, and /q, the size of the verb partition." ></td>
	<td class="line x" title="54:199	Tiien, there are k,." ></td>
	<td class="line x" title="55:199	k~,1 free parameters in a model." ></td>
	<td class="line x" title="56:199	Given a model M and data k', its total description length L(J/) 4 is COlnputed as the suni of the model description length L  d('lt), the description length of its parameters I;~,,,,.(M), and data description length Ld,~t(M)." ></td>
	<td class="line x" title="57:199	(We often refer to Lm.od(.'l.\]) qLpar (:'~l) as the model description length)." ></td>
	<td class="line x" title="58:199	Namely, L(:~'I) = L,,~o(~(:~I) + L>.,,.(:~I) + L~,(M) (2) We employ the %inary noun clustering method', in which k,, is fixed at IVt and we are to dechle whether k,~ -1 or k,,." ></td>
	<td class="line x" title="60:199	= 2, which is then to be applied recursiw~ly to the clusters thus obtained." ></td>
	<td class="line x" title="61:199	This is as if we view the noutls as entities a.nd the verbs as features and cluster the entities based on their feat.ures." ></td>
	<td class="line x" title="62:199	Since there are 2Pv'I subsets of the set of llottns .~, and for each 'binary' noun partition we have two different subsets (a special case of which is when one subset is A 'r and the other the empty set 0), the number of possible binary noml partitions is 2tAq/2 = 21~'l-J." ></td>
	<td class="line x" title="63:199	Thus for each I)inary noun partition we need log 21a'l-t = i3jI _ 1 bit.s 5 to describe it." ></td>
	<td class="line x" title="64:199	6 Ilenee L  a(M) is calculated MI)L principle in natural language processing." ></td>
	<td class="line x" title="65:199	~L(M) depends on .';, but we will leave,5' implicit." ></td>
	<td class="line x" title="66:199	5Throughout the paper 'log' denotes the logarit.hnt to the base 2." ></td>
	<td class="line x" title="67:199	6 For further explanation, see (Quinlan and Rivest, 1989)." ></td>
	<td class="line x" title="68:199	as 7 L,,~o<+~,s) = I~rl1 (3) Lpar(k~/), often referred to as the parallleter description length, is calculated by, L,,~,.(M) = 2 . log I,~'t (4) where ISl denotes the input data size, and/,." ></td>
	<td class="line x" title="69:199	\]c,,1 is the nnnlber of (free) parauleters ill tlle nlodel." ></td>
	<td class="line x" title="70:199	It is known that using log ~ = ~ bits to describe each of the parameters will (approximately) minimize the description length (1Rissanen, 1.989)." ></td>
	<td class="line x" title="71:199	FinMly, Ld,t(M) is calculated by Ldat(M)=E f(n,v).logP(n,v) (5) (n,v)ES where f(n,,v) denotes the observed frequency of the noun verb pair (n,v), and P(n,v) the estimated probability of (n, v), which is calculated as follows." ></td>
	<td class="line x" title="72:199	v,,." ></td>
	<td class="line x" title="73:199	c c,,,w, c Cv P(,~,,,~,) f'((::,,,c'~,) (s) ' IC,, x c,.I P(C,,, C,, ) f(C,,, C,, ) (r) Is1 where f(C',~, C,,) denotes the obserw.d frequency of the noun verb pairs belonging to cluster (c,~, <;'~ )." ></td>
	<td class="line x" title="74:199	With tile description length of a model defined in the above manner, we wish to select a model having the minimum description length and output it as the result of clustering." ></td>
	<td class="line x" title="75:199	Since the model description length Lmod is the same for each model, in practice we only need to calculate and compare L'(M) = L,,<,,.(M) + \];d<~,(M)." ></td>
	<td class="line x" title="76:199	3.2 A Sinllllated Annealing-based Algorithm We could ill principle calculate the description length for each model and select, a model with the nfininmm description length, if COlnputation time were of no concern." ></td>
	<td class="line x" title="77:199	However, since the number of probal)ilistic models under consideration is super exponential, this is not feasible in practice." ></td>
	<td class="line x" title="78:199	We employ the 'simulated a.m~ealing technique' to deal with this problem." ></td>
	<td class="line x" title="79:199	Figure 1 shows our (divisive) clustering algorithm s . 4 Advantages of Our Method In this section, we elaborate on the merits of our method." ></td>
	<td class="line x" title="80:199	In." ></td>
	<td class="line x" title="81:199	statistical natural language processing, usually the number of parameters in a probabilistic 7The exact formulation of L,~od(M) is subjective, and it depends on the exact coding scheme used for the description of the models." ></td>
	<td class="line x" title="82:199	SAs we noted earlier, an Mternative would be to employ an agglomerative Mgorithm." ></td>
	<td class="line x" title="83:199	model to be estimated is very large, and therefore such a model is difficult to estimate with a reasonable data size that is available in practice." ></td>
	<td class="line x" title="84:199	(This problem is usually referred to as the 'data sparseness problem')." ></td>
	<td class="line x" title="85:199	We could smooth the estimated probabilities using an existing smoothing technique (e.g. , (Dagan el, al. , 1992; Gale and Church, 1990)), then calculate some similarity measure using the smoothed probabilities, and then cluster words according to it." ></td>
	<td class="line x" title="86:199	There is no guarantee, however, that the employed smoothing method is in any way consistent with the clustering method used subsequently." ></td>
	<td class="line x" title="87:199	Our method based on MDL resolves this issue in a unified fashion." ></td>
	<td class="line x" title="88:199	By employing models that embody the assumption that words belonging to a same class occur in the same context with equal likelihood, our method achieves the smoothing effect as a side effect of the clustering process, where the domains of smoothing coincide with the classes obtained by clustering." ></td>
	<td class="line x" title="89:199	Thus, the coarseness or fineness of clustering also determines the degree of smoothing." ></td>
	<td class="line x" title="90:199	All of these effects fall out naturally as a corollary of the imperatiw?" ></td>
	<td class="line x" title="91:199	of 'best possible estimation', the original motivation behind the MDL principle." ></td>
	<td class="line x" title="92:199	in our simulated annealing algorithm, we could alternatively employ the Maxinmm Likelihood Estimator (MLE) as criterion for the best probabilistic model, instead of MDL." ></td>
	<td class="line x" title="93:199	MLE, as its name suggests, selects a model which maximizes the likelihood of the data, that is, /5 = a.rg maxp I-\[~s P(x)." ></td>
	<td class="line x" title="94:199	This is equivalent to mininfizing the 'data description length' as defined in Section 3, i.e. i 5 = arg minp ~,~-~s log P(x)." ></td>
	<td class="line x" title="95:199	We can see easily that MDL genet:al\[zes MLE, in that it also takes into account the complexity of the model itself." ></td>
	<td class="line x" title="96:199	In the presence of models with varying complexity, MLE tends to overfit the data, and output; a model that is too complex and tailored to fit the specifics of the input data." ></td>
	<td class="line x" title="97:199	If we employ MLE as criterion in our simulated annealing algorithm, it." ></td>
	<td class="line x" title="98:199	will result in selecting a very fine model with many small clusters, most of which will have probabilities estimated as zero." ></td>
	<td class="line x" title="99:199	Thus, in contrast to employing MDL, it will not have the effect of smoothing a.t all." ></td>
	<td class="line x" title="100:199	Purely as a method of estimation as well, the superiority of MI)L over MLE is supported by convincing theoretical findings (c.f.(Barton and Cover, 1991; Yamanishi, 1992))." ></td>
	<td class="line x" title="102:199	For instance, the speed of convergence of the models selected by MDL to the true model is known to be near optiinal." ></td>
	<td class="line x" title="103:199	(The models selected by MDL converge to the true model approximately at the rate of 1/s where s is the nmnber of parameters in the true model, whereas for MLE the rate is l/t, where t is the size of the domain, or in our context, the total number of elements of N' x V)." ></td>
	<td class="line x" title="104:199	'Consistency' is another desirable property of MDL, which is not shared by MLE." ></td>
	<td class="line x" title="105:199	That is, the number of parameAlgorithm: Clustering 1." ></td>
	<td class="line x" title="106:199	Divide the noun set N into two subs0ts." ></td>
	<td class="line x" title="107:199	I)efine a probabilistic model consisting of the l)artition of nouns si)ecified by the two sul)sets and th(' entire set." ></td>
	<td class="line x" title="108:199	of verbs." ></td>
	<td class="line x" title="109:199	2." ></td>
	<td class="line x" title="110:199	do 2.1 Randomly select, one noun, rcmow> it from t.h~; subset it." ></td>
	<td class="line x" title="111:199	belongs to and add it." ></td>
	<td class="line x" title="112:199	to the other." ></td>
	<td class="line x" title="113:199	2.2 C.alcuh~tc the description length for the two models (before and after the mow~') as L1 and Le, respectively." ></td>
	<td class="line x" title="114:199	2.3 Viewing the description length as the energy flmction for annealing, let AL = Le L:." ></td>
	<td class="line x" title="115:199	If AL < 0, fix the mow~, otherwise ascertain the mowe with probability P = eXl)(-AL/T)." ></td>
	<td class="line x" title="116:199	} while (the description length has decreased during the past 10." ></td>
	<td class="line x" title="117:199	INI trials)." ></td>
	<td class="line x" title="118:199	Itere T is the a.nnealing t.enq.)crat.urc whose initial value, is 1 and updated to be 0.97' after 10." ></td>
	<td class="line x" title="119:199	\]NI trials." ></td>
	<td class="line x" title="120:199	3." ></td>
	<td class="line x" title="121:199	If one of the obtained subset is elul)t,y, t\]ll?ll return the IlOll-Olllpty subset, otherwise recursiw,ly apply Clustering on both of the two subsets." ></td>
	<td class="line x" title="122:199	Figure 1: Simulated annealing algorithm for word clustering ters in l;he models selected by MDI~ ('otivorg~' to that of the true model (Rissanen, 1989)." ></td>
	<td class="line x" title="123:199	Both of these prol>erties of MI)I, ar~ Oml>irically w'ri/ied in our present (;Ollt(?x\[,, as will be show,: in t.ho t:(,xl section." ></td>
	<td class="line x" title="124:199	In particular, we haw~ compared l,h(' p(u'forn:a.nc0 of employing an M1)L-based simula.ted annealing against that of one 1)ascd on M\[,I', ill hierarchical woM clust.c'ring." ></td>
	<td class="line x" title="125:199	5 Experimental Results --it." ></td>
	<td class="line x" title="126:199	he con:party they we i the t:rue model and the estimated model." ></td>
	<td class="line x" title="127:199	('l'hc algorithm used for MI,E was lhe same as that showJt in Figure 1, except the 'data description length' replaces the (total) description length' in Sl.ep 2)." ></td>
	<td class="line x" title="128:199	Figure 3(a) plots the number of obtained IIOlllI clusters (leaf nodes in the obtained thesaurus trc~,) w?rsus the input data size, aw;raged ow;r 10 trials." ></td>
	<td class="line x" title="129:199	(The number of noun clusters in the true model is 4)." ></td>
	<td class="line x" title="130:199	Figure 3(b) plots the KI, distance versus the data size, also averaged over l:he san> 10 trials." ></td>
	<td class="line x" title="131:199	The results indicalc that MI)L conw,rges to the true Inode\] fasl.er i.\]ian M I,E. Also, MI,I'; tends to select a mo(h'l overfittil:g the data, while Ml)l, t.cnds to seh>ct a. model which is simple and yet tits the data reasonably well." ></td>
	<td class="line x" title="132:199	-sale l K~ stock sha,'~' t billion million l,'iguro 2: An example thesaurus We desert b c our experimental rcsull s ill th is section." ></td>
	<td class="line x" title="133:199	5.1 Experiment 1: MDL v.s. MLE We COml)ared the performance of elnploying M1)\], as a criterion in our silnulatcd annealing algorithm, against that of employing M IA~; by simulation experiments." ></td>
	<td class="line x" title="134:199	We artificially constructed a true model of word co-occurrence, and then generated data according to its distributiou." ></td>
	<td class="line x" title="135:199	We then used the data." ></td>
	<td class="line x" title="136:199	to estimale a model (clustering words), and measured the I(L distancd ~ between 'l'he K\], distance (relative Clt|,l:Opy), which is widely used in information theory and sta, tist, ics, is a, nleasur,2 of 'dista, n<:c' l>~\[,wcen two distributions 5.2 Experiment 2: Qualitative Evaluation We extracted roughly 180,000 case fl:anles from the bracketed WSJ (Wall Street Journal) corpus of the Penn Tree Bank (Marcus et al. , 1993) as co-occurrence data." ></td>
	<td class="line x" title="137:199	We then eonstrucl.ed a number of thesauri based on these data, using our method." ></td>
	<td class="line x" title="138:199	Figure 2 shows all example thesaurus for the 20 most frequently occurred nouns in the data, constructed based on their appearances as subject and object of roughly 2000 verbs." ></td>
	<td class="line x" title="139:199	The obtained thesaurus seems to agree with human intuition to settle degr(~e. For example, 'million' and 'billion' are classilied in one IIOll\[I chlster, alld 'stock' and 'share' arc classified together." ></td>
	<td class="line x" title="140:199	Not all of tile IlOUII C\]ltsters, however, seem to be meaningful in the useflll sense." ></td>
	<td class="line x" title="141:199	This is probably because the." ></td>
	<td class="line x" title="142:199	data size we had was not large enough." ></td>
	<td class="line x" title="143:199	Pragmatically speaking, however, whethcl: the obtained thesaurus agrees with our intuition in itself is only of secondary concern, since the main lmr pose is to use the constructed t.hcsaurus to help i~uprow~ on a disaml)igual.ion I,ask." ></td>
	<td class="line x" title="144:199	(('.over and Tl,omas, 1991)." ></td>
	<td class="line x" title="145:199	\]t is Mways non-negative a.nd is zero iff the two distributions arc identical." ></td>
	<td class="line x" title="146:199	7 'MDL' 'MLE' -~'',t t' '''', ,+_ __ __ _.~ ,~''-'~',,,,,  I  I, .  ~0 100 1000 10000 100000 I , , , , ',, 'MOL' ',.,,, 'MLE' -~-." ></td>
	<td class="line x" title="148:199	o.e 0.6 0.4 i I I~ 100000 Figure 3: (a) Number of clusters versus data size and (b) KL distance wersus data size 5.3 Experiment 3: Disambiguation We also evaluated our method by using a constructed thesaurus in a pp-attachment disan> bigua.tion experiment." ></td>
	<td class="line x" title="149:199	We used as training data the same 180,000 case fl'ames in Experiment 1." ></td>
	<td class="line x" title="150:199	We also extracted as our test data 172 (verb, no~nll,prep,'noune) patterns Dora the data in the same corpus, which is not used in the training data." ></td>
	<td class="line x" title="151:199	For the 150 words that appear in the position of,oun.e in the test data, we constructed a thesaurus based on the co-occurrences between heads and slot." ></td>
	<td class="line x" title="152:199	values of the fl'ames in the training data." ></td>
	<td class="line x" title="153:199	This is because in our disambiguation test we only need a. thesaurus consisting of these 150 words." ></td>
	<td class="line x" title="154:199	We then applied the learning method proposed in (Li and Abe, 1995) to learn case fl'ame patterns with the constructed thesaurus as input using the same training data." ></td>
	<td class="line x" title="155:199	That is, we used it to learn the conditional distributions P( Classlll,erb, prep), P(Classe \[n, ounl, prep), where Class1 and Classe vary over the internal nodes in a certain 'cut' in the thesaurus tree l0 We then compare Table 1: PP-attachment disaml)iguation results Base Line Word-Based MI) L-Thesaurus MLE-Thesaurus WordNet Cowerage(%,) Accuracy(%) 100 70.:2 19.7 95.1 33.1 93.0 33.7 89.7 49.4 88.2 which are estimated based on the case fl'ame patterns, to determine the a.ttachment site of (prep, not*he)." ></td>
	<td class="line x" title="156:199	More specifically, if the former is larger than the latter, we attach it." ></td>
	<td class="line x" title="157:199	to verb, and if the latter is larger tha.n the former, we attach it." ></td>
	<td class="line x" title="158:199	to n.o'unl, and otherwise (including when both are 1Each 'cut'." ></td>
	<td class="line x" title="159:199	in a t.hesa.urus tree defines a different noun paxt.ition." ></td>
	<td class="line x" title="160:199	See (Li and Abe, 1995) for details." ></td>
	<td class="line x" title="161:199	0), we conclude that we cannot make a decision." ></td>
	<td class="line x" title="162:199	Table 1 shows the results of our pp-attachment disambiguation experiment in terms of 'coverage' and 'accuracy'." ></td>
	<td class="line x" title="163:199	tlere 'coverage' refers to the proportion (in percentage) of the test patterns on which the disambiguation method could make a decision." ></td>
	<td class="line x" title="164:199	'Base Line' refers to tile method of always ~ttaching (prep, noun.~)." ></td>
	<td class="line x" title="165:199	to noun1." ></td>
	<td class="line x" title="166:199	'WordBased', 'MLE-Thesaurus', and 'MDL-Thesaurus' respectively stand tbr using word-based estimates, using a thesaurus constructed by employing MLE, and using a thesaurus constructed by our method." ></td>
	<td class="line x" title="167:199	Note that the coverage of ~MDL-Thesaurus' signifiea.ntly outperformed that of 'Word-Based', while basically maintaining high accuracy (though it drops somewhat), indicating that using an automatically constructed thesaurus can improve disambiguation results in terms of coverage." ></td>
	<td class="line x" title="168:199	We also tested the method proposed in (Li and Abe, 1995) of learning case frames patterns using all existing thesaurus." ></td>
	<td class="line x" title="169:199	In particular, we used this method with WordNet (Miller et al. , 1993) and using the same training data., and then conducted pp-attachment disambiguation experiment using the obtained case frame patterns." ></td>
	<td class="line x" title="171:199	We show the result of this experiment as 'WordNet' in Table 1." ></td>
	<td class="line x" title="172:199	We can see that in terms of 'coverage', ~WordNet' outperforms 'MDL-Thesaurus', but in terms of 'accuracy', 'MDL-Thesaurus' outperforms 'WordNet.'." ></td>
	<td class="line x" title="173:199	These results can be interpreted as follows." ></td>
	<td class="line x" title="174:199	An automa.tically constructed thesaurus is more domaiu dependent and captures the domain dependent features better, and thus using it achieves high accuracy." ></td>
	<td class="line x" title="175:199	On the other hand, since training data." ></td>
	<td class="line x" title="176:199	we had available is insufficient, its coverage is smaller than that of a hand made thesaurus." ></td>
	<td class="line x" title="177:199	In practice, it makes sense to combine both types of thesauri." ></td>
	<td class="line x" title="178:199	More specifically, an atttomatically constructed thesaurus can be used within its coverage, and outside its coverage, a hand made thesaurus can be used." ></td>
	<td class="line x" title="179:199	Given the current state of the word clustering technique (namely, it requires data size that is usually not available, and it tends to be computationally demanding), this strategy is practical." ></td>
	<td class="line x" title="180:199	We show the result of this combined T~bte 2: I)l'-attachinent, disambiguation results M1)l,-'I'h,~saurus + Word Net MI)L-Thesaltrus + \VordNct: + I,A + I)efaull; Coverage(%) Accuracy(~) 54,1 8 7." ></td>
	<td class="line x" title="181:199	l 100 85.5 method a.s 'Ml)l/l'hesaurlts + WordNot'." ></td>
	<td class="line x" title="182:199	it/ TaMe 2." ></td>
	<td class="line x" title="183:199	Our exlmritnenl,al resnlt, shows lltal: elnph)yhag t;he cotn\]>ined nlet.hod does itwrease t.he cow:rage of disainbiguation." ></td>
	<td class="line x" title="184:199	We also tested +M1)I, Thesaurus + WordNel.-tI,A -tl)('fatllt.', which sl:ands for using l.hc' learm~d thesaurus altd \VordNet first+, t.heu t.he lexical associal.iotl valtm l>rO posed by (lIindle a.nd F/.ooth, 1991), and finally tile defa.ull; (i.e. always atl.aching \])/'el), *~ottl+2 l;o no+tn~)." ></td>
	<td class="line x" title="185:199	Our hest disaml)iguatioll rcsull, obtained using t, his last; combined niet.tiod sontewhat improves t, he accuracy rei>orl.ed itt (Li and At><', 1.995) (84.3%)." ></td>
	<td class="line x" title="186:199	6 Conchtding Remarks We have proposed a tnethod of' hierarchical <'hisfeting of words hased on laxge corpus data." ></td>
	<td class="line x" title="187:199	\Vo conclude wit, h the following remarl,:s, \[." ></td>
	<td class="line x" title="188:199	()lip ll/et ho(\[ (>\[' chtst:('ritlg w(wds has(,d cqt th(' MI)L t',ritlciph' is ~h<,reficalty sc.+,rtd." ></td>
	<td class="line x" title="189:199	Our experimental t'esult.s show t.hal: il." ></td>
	<td class="line x" title="190:199	is I+ot t.er to enq)loy MI)I, than M 1,1!" ></td>
	<td class="line x" title="191:199	as estimation <'riWrion in hierarchical word chtstering." ></td>
	<td class="line x" title="192:199	2." ></td>
	<td class="line x" title="193:199	\[lsing a tlwsaltrus consl.rt~cl,cd l>y ottr met hod can inq>rov(; pp-;fl.t, ach)nent, disaml)igtmtion results." ></td>
	<td class="line x" title="194:199	3." ></td>
	<td class="line x" title="195:199	At, t.he Clm:ent, st, a, te of the art." ></td>
	<td class="line x" title="196:199	itt st.al, istical na.t;ttral languag(~ I)rocessing, it." ></td>
	<td class="line x" title="197:199	is b('st. I.o use a cotnbination of an a.ut.ontat.ically const.rucl(>d thesa.urus and a hand made l;hesattrus \['or disatnbigua.l.ion purpose." ></td>
	<td class="line x" title="198:199	'Fhe disaulhiglmtion accttra.cy obtained this way wets 85+5(/c,." ></td>
	<td class="line x" title="199:199	\[u the fut.ttre, hopefillly wit, h target training dat.a size, we plao_ to construct, larger thesauri as well as to test other clustering algorit.hms." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C96-1083
Symbolic Word Clustering For Medium-Size Corpora
Habert, Benoit;Naulleau, Elie;Nazarenko, Adeline;"></td>
	<td class="line x" title="1:134	Symbolic word clustering for medium-size corpora Benoit Habert* and Elie Naulleau* ** and Adeline Nazarenko* *Equipe de Linguistique Inform~tique Ecole NorInale Sup&ieure de Fontenay-St Cloud 31 av." ></td>
	<td class="line x" title="2:134	bombart, F-92260 Fontenay-aux-Roses Firstname." ></td>
	<td class="line x" title="3:134	Name@ens-fcl." ></td>
	<td class="line x" title="4:134	fr **Direction des Etudes et Recherches Electricitd de Fra, nce 1, av." ></td>
	<td class="line x" title="5:134	du G ~z de Gaulle, F-92141 Clamart F irstname." ></td>
	<td class="line x" title="6:134	Name@der." ></td>
	<td class="line x" title="7:134	edfgdf, fr Abstract When trying to identify essential concepts and relationships in a medium-size corpus, it is not always possible to rely on statistical methods, as the frequencies are too low." ></td>
	<td class="line x" title="8:134	We present an alternative method, symbolic, based on the simplification of parse trees." ></td>
	<td class="line x" title="9:134	We discuss the resuits on nominal phrases of two technical corpora, analyzed by two different robust parsers used for terminology updating in an industrial company." ></td>
	<td class="line x" title="10:134	We compare our results with Hindle's scores of similarity." ></td>
	<td class="line x" title="11:134	Subjects Clustering, ontology development, robust parsing, knowledge acquisition from corpora, computational terminology 1 Identifying word classes in medium-size corpora In companies with a wide range of activities, such as EDF, the French electricity company, the rapid evolution of technical domains, the huge amount of textual data involved, its variation in length and style imply building or updating numerous terminologies as NLP resources." ></td>
	<td class="line x" title="12:134	In this context, terminology acquisition is defined as a twofold process." ></td>
	<td class="line x" title="13:134	On one hand, a terminologist must identify the essential entities of the domain and their relationships, that is its ontology." ></td>
	<td class="line x" title="14:134	On the other hand, (s)he must relate these entities and relationships to their linguistic realizations, so as to isolate the lexical entries to be considered as certified terms for the domain." ></td>
	<td class="line x" title="15:134	In this paper, we concentrate on the first issue." ></td>
	<td class="line x" title="16:134	Automatic exploration of a sublanguage corpus constitutes a first step towards identifying the semantic classes and relationships which are relevant for this sublanguage." ></td>
	<td class="line pc" title="17:134	In the past five years, important research on the automatic acquisition of word classes based on lexical distribution has been published (Church and Hanks, 1990; Hindle, 1990; Smadja, 1993; Grei~nstette, 1994; Grishman and Sterling, 1994)." ></td>
	<td class="line n" title="18:134	Most of these approaches, however, need large or even very large corpora in order for word classes to be discovered 1 whereas it is often the case that the data to be processed are insufficient to provide reliable lexical intbrmation." ></td>
	<td class="line n" title="19:134	In other words, it is not always possible to resort to statistical methods." ></td>
	<td class="line x" title="20:134	On the other hand, medium size corpora (between 100,000 and 500,000 words: typically a reference manual) are already too complex and too long to rely on reading only, even with concordances." ></td>
	<td class="line x" title="21:134	For this range of corpora, a pure symbolic approach, which recycles and simplifies analyses produced by robust parsers in order to classify words, offers a viable alternative to statistical methods." ></td>
	<td class="line x" title="22:134	We present this approach in section 2." ></td>
	<td class="line x" title="23:134	Section 3 describes the results on two technical corpora with two different robust parsers." ></td>
	<td class="line oc" title="24:134	Section 4 compares our results to Itindle's ones (Hindle, 1990)." ></td>
	<td class="line o" title="25:134	2 Simplifying parse trees to classify words 2.1 The need for normalized syntactic contexts As Hindle's work proves it, among others (Grishman and Sterling, 1994; Grefenstette, 1994:), the mere existence of robust syntactic parsers makes it possible to parse large corpora in order to automate the discovery of syntactic patterns in the spirit of Harris's distributional hypothesis." ></td>
	<td class="line oc" title="26:134	Itowever, Harris' methodology implies also to simplify and transform each parse tree 2, so as to obtain so-called 'elementary sentences' exhibiting the main conceptual classes for the domain (Sager lIa'or instance, Hindle (Hindle, 1990) needs a six million word corpus in order to extract noun similarities from predicate-argunlent structures." ></td>
	<td class="line x" title="27:134	2Changing passive into active sentences, using a verb instead of a nominalization, and so on." ></td>
	<td class="line x" title="28:134	490 NP\] NPa AP4 I I Nr As I I stenose serre NPo PP2 Pa NP6 I de D9 NPlo le NPll AP12 t NPla AP14 A15 I I I N~ A~r gauche I I tronc eorninun I?igure 1: Parse tree for stenose serre de le hone commun gauche et al. , 1987)." ></td>
	<td class="line x" title="29:134	In order to ~mtomate this normalization, we propose to post-process parse trees so as to emphasize the dependency relationships among the content words and to infer semantic classes." ></td>
	<td class="line x" title="30:134	Our approach can be opposed to the a prior one which consists in building simplified representations while parsing (Basili et al. , 1994; Metzler and Haas, 1989; Smeaton and Sheridan, 19911)." ></td>
	<td class="line x" title="31:134	2.2 R.ecycling the results of robust parsers For the sake of reusability, we chose to add a generic post-processing treatment to the results of robust parsers." ></td>
	<td class="line x" title="32:134	It ilnplies to transduce the trees resulting fl:om different parsers to a common fornlat." ></td>
	<td class="line x" title="33:134	We experimented so t~r two parsers: Aleth(h:am and I,exl;er, which are being used at DEREDI,' for terminology acquisition and updating." ></td>
	<td class="line x" title="34:134	They both analyze corpora of arbitrary length." ></td>
	<td class="line x" title="35:134	AlethGram has been developped winthin the GIIAAL project a. I,EXrI'ER has been developped at DER-EI)F (Bourigault, 1993)." ></td>
	<td class="line x" title="36:134	In this experinlent, we if)cussed on noun phrases, as they are central in most terminologies." ></td>
	<td class="line x" title="37:134	2.3 The simplification algorithm The objective is then to reduce automatically the numerous and complex nominal phrases provided by AlethGram and LEXTEI to elementary trees, 3The Eureka GRAAL project gathers in France (IC1-F, RLI (prime contractor), EDF, Aerospatiale and lenanlt." ></td>
	<td class="line x" title="38:134	which more readily exhibit the flmdamental binary relations, and to classify words with respect to these simplified trees." ></td>
	<td class="line x" title="39:134	For instance, from the parse tree for slenose serve de le tronc eommun gauche 4 (cf.fig." ></td>
	<td class="line x" title="41:134	2, in which non terminal nodes are indexed for reference purposes), the algorithm 5 yields the set of elementary trees of figure 1." ></td>
	<td class="line x" title="42:134	'l'he trees a and c correspond to contiguous words in the original sequence, whereas b and d only appear after modifier removal (see below)." ></td>
	<td class="line x" title="43:134	Two types of simplifications are applied when possible to a given tree: 11.,5'plitting: Each sub-tree immediately dominated by the root is extracted and possibly further simplified." ></td>
	<td class="line x" title="45:134	For instance, removing node NP0 yields two sub-trees: NP\], which is elementary (see below) and PP2, which needs further simplification." ></td>
	<td class="line x" title="46:134	2." ></td>
	<td class="line x" title="47:134	Modifier removal: Within the whole tree, every phrase which represents a modified constituent is replaced by the corresponding non modified constituent." ></td>
	<td class="line x" title="48:134	For example, in NP0, the adjectival modifier scrrc is removed, as well as the determiner and the adjectives 4 Tight stcnosis of left common mainstem." ></td>
	<td class="line x" title="49:134	In both parsers, {,he accents are removed during tile analysis, the lemmas are used instead of inflected fo,'ms. Additionally, fro' simplitication purposes, a contracted word like du is considered as a prepositiondeterminer sequ_enec." ></td>
	<td class="line x" title="50:134	5See (Habet't el; al. , 1.995) for a detailled presental,ion." ></td>
	<td class="line x" title="51:134	The corresponding software, SYCI,AI)E, has been developped by the tirst author." ></td>
	<td class="line x" title="52:134	491 N|)a, NP AP I I N A I I st, chose Serl?e NPv N P,, Nl)~t NP PP ~ I ~ NP AP NP A P N /' Xl' I I I I I I I N A N /I stc~ms~: de N \[ \[ \] I \[ troIlc COIflfft/l\[l ~Tollc.(\]ditch( ~ tronc l)'igm:e 2: I,\]lcmcntary trees for sl.cnose serve de lc tro,m co'mmm~ (l(mchr." ></td>
	<td class="line x" title="53:134	-_coronarien -._gauche -~------___._ a t t ein t e. de~.~ diametre .de --------'-----I~ tr0nc ~ ~,~;tenose de / coronarJ ell /\ / / '~ m rena\],~ / 5~ / ~ presence .de~ /  coronare -. coronarien / \ / '." ></td>
	<td class="line x" title="54:134	I / --_ell.staLe \ coronarJ en L  clrconrzexe / montre_de \ -de artere -\ -~\]roxlmal z -' -' \] k de artere / ~ dJametre de .-.joroximal \ / / ~dr~n \ / / de intervent-riculaire /_ aorti~,e ~ ~, ~' /  /  / '~corortarzen/\ | \ \[ / coronarien --dkffus / \ I \ / / . ~ circonflexe  / \ / k I / lorpzma coronarien existence de \  'ien~ | / / --dia on~\] ~7--k / injec~q '--de artere ~ ~ ~/ g,c   ~ \ c  rJ  --~' non-slgnlr icaEz / ~,." ></td>
	<td class="line x" title="55:134	'~, de carotide4~ -r '~ ~ / ~ \ N mztra ~ ~ eszaue / ~ \ ~7, S / N. ~ (llagnostlC de -d2 cnat;idetdulaJ !e ~ % c;ne arien'-de-'trOnc <rnarien// I ~ ---'." ></td>
	<td class="line x" title="56:134	X -_ / -' ~./ b atheromateux persist  e deI kde artere /.-_severe-/I. ire / / X-~ /severite de_<coronarien / / ~,~ .// / i~ -severeX OOCtUS~ -Cgrl~arlen --ce;;earzen '~'o~ ~'~  / / X -de artere -coronar\] en coronare de artere ' ' --~ de tronc { --severe coronarlen \ | --de tronc -_im3ortant \\severe -~de_ar Sl~tm~-~----___~_coronazzen de artere --'---'!~ a~nte ~ mab~ 1 ~ coronarien diagnostic de -~ frequence de -,1 a~asdemse Figure 3: Example of a strongly connected component ((\]MC corpus) 492 uiodifying I, ro~.c, which l('~ts (.o elenienl;ary I;ree b. W\[i(;li I;\]ie (:lirrolil." ></td>
	<td class="line x" title="57:134	imee is clc'm.~;nlary, t\]io siniplific~lJon process s~ops." ></td>
	<td class="line x" title="58:134	I~efT)re I)rocessing lill(, s(;L ()f oril>;iuM \])aJ:se l;l:ees, OllC llillS\[; dec/a>re 1.|le l;l:ees which li:i/lsi; iv)l; I)e sinll)lilied a.lly fllrl.\]ier." ></td>
	<td class="line x" title="59:134	Ill I:)iis exl)el:inlent;, a.rc (:om~id(:red as e/el\]i(;il\[,itl'y l,he ilOliiinaJ I;l'(;es which exhil)it, a. binary 1;ela.l;\]Oll I)eI;w(;(;l~ l;wo '('oiil;elil'." ></td>
	<td class="line x" title="60:134	words, \[7)r iliSl.a.ii(:e I)ei;weeN /,wo N in &ll N \]) N SCqll011cc." ></td>
	<td class="line x" title="61:134	2.4: lProni (:h:m(:nl;ary ('ont;(:xts I;o word ( '.\].,}It .',4 S ( ~." ></td>
	<td class="line x" title="63:134	S 'l'lle i:esull;iug collo(:~lJons a,e tout, rolled I)y IJie synl.acl;ic felaJ;ionshit)s sl, rll('t;llrillg l, he l)a.r.'q(, t;l'ees, which is liOl." ></td>
	<td class="line x" title="64:134	t;lie case For wi n(low--t)ased a.i)l)roaches ((Jhurch a.nd lla.liks, 199())~ ev(;n wh(;n lJley use i)a.l:l,-oP-Sl)cech la.I)els (Sniasljn, 1993; I)a.ille, 1994)." ></td>
	<td class="line x" title="65:134	Ill l;he ('Xallll)\]( % .qaitr:hc is llOf i:elaJ,ed 1;o s/,<:ltosc', as il." ></td>
	<td class="line x" title="66:134	does iiol~ liiOtti\[3~ this noun." ></td>
	<td class="line x" title="67:134	'l'hc eleiiieii/a.ry l;rces I<~d 1,o oh>sos of syiiDI.C(;ic COllt;C:;',.:Lq." ></td>
	<td class="line x" title="68:134	I'or hlsl;a, ll(:e, frOl\[l {;h(; /ec' corl'(;s|)(:)ll(\[ill~ i;o s/,v/tosc,~{~'#'~'c, t;wo (:lasses o1' (:Oll(,exl;s aye crca.lxxl." ></td>
	<td class="line x" title="69:134	'l'hc Ih'sl, ()tie, <s/cltos,': ~, iu which sl;a.nds Ior t, he lfiw)t, word, conl.a.ins serf+, whereas l.\[i(; second o11(~> N .'7C;P7'C~ (:Oiii;a.illS SC'ItO.S<." ></td>
	<td class="line x" title="70:134	kl; t;he end o1' l;he SilUl)lilic;tl, iou process, I, ll(;s(; classes ha,re I)(:ei~ cOUll)lelied ~licl olJi(;r oiler; (:rea l;e(I. VVe (-laim t,h~l, th(' s(,inant;i(', similaril,y I)elween two lcxical enl, ries is in i)l:Ol)orl;ioli wii;h I;lie mlillt)er of sha, red (:Olll;(:xl,s, \[,hi: insl;mlc(', in ol,, of ore' ((:orl)ora.,,s/,e~tosu,'.ha r(;s 8 conliel,s wit, h l(szom In order I,o get, ~ glohal vision of the similm:il.ies relyi,g on elenient, ary conl.exD;, a. gi'ad)h is C, Olill)lil;c:(\]." ></td>
	<td class="line x" title="72:134	Tim WOl~(ls CO\[lSl;il;llt;,:; l, hc IIO(Ics." ></td>
	<td class="line x" title="73:134	A link corresl~onds 1.o a. Cel:l;&ili lliiliil)er oF shared c.oni;exl;s (a<:c.ordill~ l,O ~t. chosen I.hreshold)." ></td>
	<td class="line x" title="74:134	The edges are labclle, d wiiJi l, he sha.red coiit;cxls." ></td>
	<td class="line x" title="75:134	The sl;l:oiigly colineclx;(I c.oinponeill~.s ~I a.nd t;hc cliques '/ a.l'('~ conil)ul.ed a.s woll, ~s t.hcy ~re l;he tiiosi; t'(;l(; Va.lll; l)a.rl,s oF {tie gra.i)h ~ oil i,opologica.I ~lX)lilidS, '\['lie un(l('.l:lying illl;liil;ion is l;h a,l; a~ COiliieclA;d (:Olll\])Otleli/; I'C'\]itl,(:',S lil:':igjhl)ori/igj words (llollSC\]/ and Savit;ch, \]9!)5) m~d I, hal, the cliques tend l,o isoIal;c,<dmih~i:il;y cla,ssc's." ></td>
	<td class="line x" title="76:134	An ext;rm::t of a connc'ci;ed conll)onenl;, wil;h 3 as a, threshold, a,l)pears in ligu r(; 3." ></td>
	<td class="line x" title="77:134	s'\]'he sub-graphs hi which l.here is ~t 1)aLh I)cl.ween every pair of (lisl>hicl; liO(1CS." ></td>
	<td class="line x" title="78:134	rThc sul><~ra, phs in wlfich l;here is a palJl I)et;wee\]l each lto(le and eve>r?/ olhcr noch: of l;he graph." ></td>
	<td class="line x" title="79:134	3 Results 3.1." ></td>
	<td class="line x" title="80:134	Two corpora We haw; l.esl;ed olir niei.,hod on I.wo i;echnicM niedium-size col:pora The fii:sl; ()li(;> i;he INII-cleaJ: '\[}x:hliOlogjy (}Ol.\])tls (N'I'C) of EI)I', is of a,I)olll;,52,000 words." ></td>
	<td class="line x" title="82:134	'l'he second one, I,he (k)i;<) n~u;y Medicine (JOrl)US (CM(7), is of a.I)ou, ($(), 000 words." ></td>
	<td class="line x" title="83:134	It was buill; for t, he l,;urol)ca.u M I'\]N El,AS t)rojccl." ></td>
	<td class="line x" title="84:134	(Zweigenl)a, ilni, 19)/I) and is used For 1)ilol." ></td>
	<td class="line x" title="85:134	sl,udies in l;erminology exLra.clk)n s. 3.2 A vlsnal lliap of {:OIICOps lUld relationships I@en if iio onl;ology (:~u/ I)c \['ully aJIl;o\]iiat, R:a.ily derived \[;l:Olil a." ></td>
	<td class="line x" title="86:134	('orl)iis (llaJ)erl; ;tll(\[ Na.zarelll,:o, 1996), IJle,gY( JI,A I)1,\] gra.I)hs ('AI.II I)e iise(I I.o I)()oi.slma I) i.he I)ilihting of l, he onl;olog;y o(' a. dolila.iu." ></td>
	<td class="line x" title="87:134	'l'he SY(',I,AI)I,; ii(fl, work gives a <glol>a,I view over t,hc COrl).S which etmhles {m all, ernal;e i)a, ra,digniaJ;ic a, nd sylil;agul~l;ic exl)lora.l, iou of I,he cont;cxl; o\[' a word." ></td>
	<td class="line x" title="88:134	'l'hc gl;al)h (;nat)les 1;o idenl,ify I;lic concel)t,s, I hcir possit)lc t, yl)icaJ I)rOl)erl, ies, a, lld also t, he rcla, l;ionshil)s b(;I;weCll 1;he selecl,cd COilCel)l,s. Tim cliques I)ring ()ill; sitia.ll i)ara.diglllai.ic scl.s of \['orins which, ill a. tirsl, sl.et) > Ca.ll Im iuLer I)relx;d as onl;ologh:M classes rellecl;ing coliCelfl~." ></td>
	<td class="line x" title="89:134	'l'he a.rc lal)Ns l.ticn help Ix) retilie I.llosc chlsses t)y acldiu S sOlile of the Sllrl'Olilidhl~ words whicli axe li()l, pa.i'l; ()\[' t;lie clkluc bul." ></td>
	<td class="line x" title="90:134	which ileverllie-le~s sha,r(; the iiIOSl; siguifica.nl; or SOllle Siiliila.r <Ollbexl,8." ></td>
	<td class="line x" title="91:134	1@0111 the clique {sl,+e~,o,sc, b.<Uos b obsl, r~ml, ion, altcinb:} (of." ></td>
	<td class="line x" title="92:134	fig." ></td>
	<td class="line x" title="93:134	3), one ca, t\] build l lie cla.ss of all'eel;ions which arc Io(:al;ed in l, he I)odv as {Idam.:, occ1.<~7o., s/~.Js<~, Ic,~7o., <:.l<:{li~:ali<.,, ob,~'l, rl,:l, ion, aZl, c'inl, c}." ></td>
	<td class="line x" title="97:134	Siinila.rly, from l, he gt'al)h o\[' I;he (~'M(7 corpus, Oile (:a.li i(leni,i\['y l.ll~ classes of body' ~ii, cs { artcrc, I.'anchc, rcs+sa~l, 'v<'ntri, ~dc, intc',rve, nlriculairc, cft'roli(l~,}, o(' diseases { 'malmli+, arth, crvsclcrose} and oF chirul'gica/ m:ts { l)o*ll,(~gc, rcvasc.ularisatio'n, angioplastic}." ></td>
	<td class="line x" title="98:134	Olic(; l.\]ieS(; (;Oli(:('pts axe identilied, t, hei r i)rolJei;{,i('~S Ca, fl I)C lisl, e(l, t)y i llt;erl)l:el, ing ~ I;he l ld)cls of I lie links, 'l'he al;t;ri hu I~(, of the localizaJJon of l,h(' aJl'ecl;ions is descril)ed l;\]irough three, kinds oF u:lodiliers (lig." ></td>
	<td class="line x" title="99:134	',/):,io,,n,~ (,-, (t<'." ></td>
	<td class="line x" title="100:134	{ a,'Z,.~,'<~ ', t,','<,,u:)),,,;,i,os <' ~,,:lyrics (~ d(; {ca'rotTd<', #tl, crventrTculaTre} aud a(l-,iectivcs rela, l;cd to ;~ q)('(:ific aa'l;ery (~ {coro#utiru, co'ronaricn, diaqonal, ci'lvonfl<~:(;})." ></td>
	<td class="line x" title="101:134	'l'he a l, i;i:iblll;e (legr(:e of (;lie a, fl'ecl, ion is a, lso reveaJed IJlrougjh {~ si,qm/ical, if, n<m-,siqnificati.l; severe, 7m, l)Orl.a.l. , s<;veriZc} . '(41roupe '\['erniinologie el; lnl;elligence Ari;iticielle, I ~ IC--(_I I )171." ></td>
	<td class="line x" title="102:134	| ul;elligcnce A r@icicltc, (7 NI {S 493 etude~ ~evaluatlon a t~.alyse calcul etudeS5 b N ~ essai analyse Figure 4: Polysemy of etude Last, relationships between concepts can be extracted, such as the'part-of' relation between tronc and artere, and segment and artere (fig." ></td>
	<td class="line x" title="103:134	3)." ></td>
	<td class="line x" title="104:134	3.3 Distinguishing word meanings Polysemy and quasi-synonymy often makes the ontological reading of linguistic data difficult." ></td>
	<td class="line x" title="105:134	However, through cliques and edge labels, the SYCLADE structured and documented map of the words helps to capture the word meaning level." ></td>
	<td class="line x" title="106:134	Among a set of connected words where w is similar to wi and wj, cliques bring out coherent subsets where wi and wj are also similar to each other." ></td>
	<td class="line x" title="107:134	We argue that the various cliques in which a word appears represent different axes of similarity and help to identify the different senses of that word." ></td>
	<td class="line x" title="108:134	For instance, in the whole set of words connected to etude (study) in a strongly connected component of the NTC graph (analyse, evaluation, resultat, presentation, principe, calcul, travail), some subsets form cliques with etude." ></td>
	<td class="line x" title="109:134	Two of those cliques (resp." ></td>
	<td class="line x" title="110:134	a and b in fig." ></td>
	<td class="line x" title="111:134	4 threshold of 7) bring out a concrete and a more theoretical use of etude." ></td>
	<td class="line x" title="112:134	The network also enables to distinguish the uses of quasi-synonyms such as eoronaire and coronarien in the CMC corpus." ></td>
	<td class="line x" title="113:134	Even if they are among the most similar adjectives (7 shared contexts) and if they belong to the same clique {coronaire, eoronarien, diagonal, circonflexe}, the fact that eoronarien alone is connected to evaluation adjectives (severe, signifieatif and important) shows that they cannot always substitute to each other." ></td>
	<td class="line oc" title="114:134	4 Towards an adequate similarity esfimatation for the building of ontologies The comparison with the similarity score of (Hindle, 1990) shows that SYCLADE similarity indicator is specifically relevant for ontology bootstrap and tuning." ></td>
	<td class="line oc" title="115:134	Hindle uses the observed frequencies within a specific syntactic pattern (subject/verb, and verb/object) to derive a cooccu,> rence score which is an estimate of mutual information (Church and Hanks, 1990)." ></td>
	<td class="line n" title="116:134	We adapted this score to noun phrase patterns) However the similarity measures based on cooccurrence scores and nominal phrase patterns are less relevant for an ontological analysis." ></td>
	<td class="line x" title="117:134	The subgraph of the chirurgical acts words, which is easy to identify from the SYCLADE graph (fig." ></td>
	<td class="line x" title="118:134	5a), is split in different parts in the similarity graph (fig." ></td>
	<td class="line x" title="119:134	5b)." ></td>
	<td class="line n" title="120:134	This difference stems from the fact that this cooccurrence score overestimates rare events and underlines the collocations specific to each form." ></td>
	<td class="line x" title="121:134	1 For instance, it appears that the relationship between stenose and lesion, which was central in figure 3, with 8 shared contexts, almost diseappears if one considers the number of shared cooccurrences." ></td>
	<td class="line x" title="122:134	Therefore, similarity measures based on cooccurrences and similarity estimation based on shared contexts must not be used in place of each other." ></td>
	<td class="line o" title="123:134	As opposed to Hindle's lists of similar words which are centered on pivot words whose neighbors are all on the same level, in SYCLADE graphs, a word is represented by its role in a whole syntactic and conceptual network." ></td>
	<td class="line x" title="124:134	The graph enables to distinguish the various meanings of words, a crucial feature in the ontological perspective since the meaning level is closer to the concept level than the word level." ></td>
	<td class="line x" title="125:134	In addition, the results are clear and more easily interpretable than those given by a statistical method, because the reader does not have to supply the explanation as to why and how the words are similar." ></td>
	<td class="line x" title="126:134	The building of an ontology, which is a timeconsuming task and which cannot be achieved automatically, can nevertheless be guided." ></td>
	<td class="line x" title="127:134	The SYCLADE graphs based on shared contexts can facilitate this process." ></td>
	<td class="line x" title="128:134	9For instance, for Na PN2 CoocNi,N~ : log 2 ~~ where f(NIPN2) is the fi'equency of noun N1 occurring with N2 in a noun preposition pattern, f(N1) is the frequency of NI as head of any N1PN,~ sequence and f(N2) the frequency of N2 in modifier/argument position of auy N~PN2 sequence and k is the count of NxPN v elementary trees in the corpus." ></td>
	<td class="line x" title="129:134	COOCNAda and CooeAd~N are similarly defined." ></td>
	<td class="line x" title="130:134	1The various cooccurrence scores retrieve sets of collocations which are sharply different fi'om the contexts shown by SYCLADE connected components." ></td>
	<td class="line x" title="131:134	The coll6cations which get the greatest cooccurrence scores seem to characterize medecine phraseology (facteur (de) risque, milieu hospitalier) but not the coronary diseases as such." ></td>
	<td class="line x" title="132:134	494 pontage angioplastie ~ artere \/ revascul~risation pontage angloplastle I her ed~tC~ionl~y!!: sme pont artere stenose l,'igure 5: Similarity among the chirurgical act family Acknowledgments We ~hank (\]hristian 3aequemin (IRIN), Didier Bourigault, Marie-Luce Herviou, JeanDavid Sta (DER EDF), Marie-tl~51~ne Candito (TAI,ANA) and Sophie Aslanides (ELI) for their remarks on a previous version of this l)aper." ></td>
	<td class="line x" title="133:134	We are very gratefid to Serge Heiden (ELI), who has developed G~aphX (ftp://mycroft." ></td>
	<td class="line x" title="134:134	ens-f c:l fr/pub/graphx/), I;hc graph interactive handling software that enabled us to visualize and handle the SYCLADI,3 graphs." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C96-2205
Redefining Similarity In A Thesaurus By Using Corpora
Shinnou, Hiroyuki;"></td>
	<td class="line x" title="1:125	Redefining similarity in a thesaurus by using corpora Hiroyuki Shinnou Ibar~ki University Dept. of Systems Engineering N~k~narusawa, 4-12-1 Hitachi, Ibaraki, 316, Japan shinnou@lily, dse." ></td>
	<td class="line x" title="2:125	ibaraki, ac." ></td>
	<td class="line x" title="3:125	jp 1 Introduction The aim of this paper is to automatically define the similarity I)etween two nouns which are generally used in various domains." ></td>
	<td class="line x" title="4:125	By these similarities, we can construct a large and general thesaurus." ></td>
	<td class="line x" title="5:125	In applications of natural language processing, it is necessary to appropriately measure the similarity between two nouns." ></td>
	<td class="line x" title="6:125	The similarity is usually calculated from a thesaurus." ></td>
	<td class="line oc" title="7:125	Since a handmade thesaurus is not slfitahle for machine use, and expensive to compile, automatical construction of~a thesaurus has been attempted using corpora (Hindle, 1990)." ></td>
	<td class="line n" title="8:125	llowever, the thesaurus constructed by such ways does not contain so many nouns, and these nouns are specified by the used corpus." ></td>
	<td class="line o" title="9:125	In other words, we cannot construct the general thesaurus from only a corpus." ></td>
	<td class="line x" title="10:125	This can be regarded as data sparseness problem that few nouns appear in the corpus." ></td>
	<td class="line x" title="11:125	9b overcome data sparseness, methods to estimate the distribution of unseen eooecurrence frorn the distribution of similar words in the seen cooccurrence has been proposed." ></td>
	<td class="line x" title="12:125	Brown et al. proposed a class-based n-gram model, which generalizes the n-gram model, to predict a word from previous words in a text (Brown et al. , 1992)." ></td>
	<td class="line x" title="13:125	They tackled data sparseness by generalizing the word to the class which contains the word." ></td>
	<td class="line x" title="14:125	Pereira ct al. also basically used the above method, but they proposed a soft clustering scheme, in which membership of a word in a class is probabilistic (Pereira et al. , 1993)." ></td>
	<td class="line x" title="15:125	Brown and Pereira provide the clustering algorithm assigning words to proper classes, based on their own models." ></td>
	<td class="line x" title="16:125	I)agan eL al. proposed a similarity-based model in which each word is generalized, not to its own specific class, but to a set of words which are most similar to it (Dagan et al. , 1993)." ></td>
	<td class="line x" title="17:125	Using this model, they successfully l)redieted which unobserved cooccurrenccs were more likely than others, and estimated the probability of the cooecurrences (Dagan et al. , 1994)." ></td>
	<td class="line x" title="18:125	However, because these schemes look for similar words in the corpus, the number of similarities which we can define is rather small in comparison with the nunlber of similarities for pairs of the whole." ></td>
	<td class="line x" title="19:125	The scheme to look for similar words in the corpus has already taken the influence of data sparseness." ></td>
	<td class="line x" title="20:125	In this paper, we propose a method distinct from the above methods, which use a handmade thesaurus to find similar words." ></td>
	<td class="line x" title="21:125	The proposed method avoids data sparseness by estimating undefined similarities from the similarity in the thesaurus and similarities defined by the corpus." ></td>
	<td class="line x" title="22:125	Thus, the obtained similarities are the same in nmuber as the similarities in the thesaurus, and they reflect the particularity of the domain to which the used corpus belongs." ></td>
	<td class="line x" title="23:125	The use of a tlmsaurus can obviously set up the similar word independent of the tort)us, and has an advantage that some ambiguities in analyzing the corpus are solved." ></td>
	<td class="line x" title="24:125	We have experimented by using Bunrui-goihyon(Bmlrui-goi-hyon, 1994), which is a kind of Japanese handmade thesaurus, and the corpus which consists of Japanese economic newspaper 5 years articles with about 7.85 M sentences." ></td>
	<td class="line x" title="25:125	We evaluate the appropriateness of the obtained similarities." ></td>
	<td class="line x" title="26:125	2 Defining the similarity We call easily judge the similarity of two nouns if they are very similar." ></td>
	<td class="line x" title="27:125	However, the more different they arc, the more difficult it is to define their similarity." ></td>
	<td class="line x" title="28:125	Thus, we can trust that nouns in the class corresponding to the 'leaf' of BunruL goi-hyou are similar to each another, and this is not affected by the domain." ></td>
	<td class="line x" title="29:125	In this paper, we will refer to the class corresponding to the leaf of' Bunrui-goi-hyou the primitive class." ></td>
	<td class="line x" title="30:125	Therefore, tile similarity we have to detine is the silnilarity between these classes." ></td>
	<td class="line x" title="31:125	This method consists of 4 steps." ></td>
	<td class="line x" title="32:125	Step 1 Gather the cooccurrence data from the corpus." ></td>
	<td class="line x" title="33:125	Step 2 Generalize the noun in the cooccurrence data to the primitive class." ></td>
	<td class="line x" title="34:125	Step 3 Measure the similarity between two primitive classes by using the cooccurrence data obtained in step 2." ></td>
	<td class="line x" title="35:125	1131 Step 4 Estimate undefined similarities." ></td>
	<td class="line x" title="36:125	We will describe each step in detail in following subsections." ></td>
	<td class="line x" title="37:125	2.1 Gathering cooccurrenee data (step 1) In order to carry out our method, it is necessary to first gather the cooccurrence data from the corpus." ></td>
	<td class="line x" title="38:125	If a noun (N), a postpostional particle (P), and a verb (V) appear in a sentence in this order, we pick out the cooccurrence data \[N, P, V\]." ></td>
	<td class="line x" title="39:125	In this study, we gathered cooccurrence data only from the postpostional particle 'wo', because 'wo' is the most effective postpostional particle for classifying nouns." ></td>
	<td class="line x" title="40:125	As a corpus, we used five years of Japanese economic newspaper articles." ></td>
	<td class="line x" title="41:125	The corpus has about 7.85 M sentences, and the average number of characters in one sentence was about 49." ></td>
	<td class="line x" title="42:125	From the corpus, we gathered about 4.41 M bits of cooccurrence data (about 1.48 M types) whose postpositional particle was 'wo'." ></td>
	<td class="line x" title="43:125	From them, we removed the cooccurrence data whose frequency was 1, or whose verb does not appear more than 20 times." ></td>
	<td class="line x" title="44:125	In all, we obtained about 3.26 M bits of cooccurfence data, which consisted of about 0.36 M types." ></td>
	<td class="line x" title="45:125	These cooccurrence data are used in the next step." ></td>
	<td class="line x" title="46:125	2.2 Generalizing the word to the class (step 2) In step 2, we generalize the noun in cooccurrence data gathered in step 1 to the primitive class to which this noun belongs." ></td>
	<td class="line x" title="47:125	First, we should explain about Bunrui-goi-hyou." ></td>
	<td class="line x" title="48:125	Bunrui-goi-hyou is a kind of thesaurus with a treelike structure that has a maximum depth of level 6." ></td>
	<td class="line x" title="49:125	Class IDs are assigned to each 'leaf' of the 'tree'." ></td>
	<td class="line x" title="50:125	Each noun has a class ID corresponding to the meaning of the noun." ></td>
	<td class="line x" title="51:125	The class ID corresponds to the primitive class." ></td>
	<td class="line x" title="52:125	Bunrui-goi-hyou has 3,582 primitive classes." ></td>
	<td class="line x" title="53:125	Because many nouns, such as compound nouns, are not in Bunrui-goi-hyou, we cannot always generalize all nouns to primitive classes, 86.0% of the nouns in cooccurrence data gathered in step 1 could be generalized to primitive classes." ></td>
	<td class="line x" title="54:125	In this generalization, the problem of polysemy arises." ></td>
	<td class="line x" title="55:125	A noun has usually several primitive classes because of the polysemy." ></td>
	<td class="line x" title="56:125	We solve some polysemy from the distribution of nouns in cooccurrence data which have the same verb." ></td>
	<td class="line x" title="57:125	This cannot be discussed here for lack of space." ></td>
	<td class="line x" title="58:125	We only report that the cooccurrence data gathered in step 1 contain 572,529 bits of polysemy which consisted of 27,918 types, and 472,273 bits of polysemy ( 18,534 types ) were solved." ></td>
	<td class="line x" title="59:125	In all, we obtained 2,708,135 bits of generalized cooccurrence data, which consisted of 115,330 types." ></td>
	<td class="line oc" title="60:125	2.3 Measuring the similarity between classes (step 3) In step 3, we measure the similarity between two primitive classes by using the method given by Hindle (Hindle, 1990)." ></td>
	<td class="line x" title="61:125	First, we define the nmtual information MI of a verb v and a primitive class C as follows." ></td>
	<td class="line x" title="62:125	'Z~mY2 M (,C)=logs N (eq.1) N N In the above equation, N is the total number of cooccurrence data bits, and f(v) and f(C) are the frequency of v and C in the whole cooccurrence data set respectively, and f(v, C) is the frequency of the cooccurrence data \[C, wo, v\]." ></td>
	<td class="line x" title="63:125	Next, the similarity sire of a class Ci and Cj for a verb v is defined as follows." ></td>
	<td class="line x" title="64:125	min(IfI(v, Ci)I, IMI(v, Ci)l) = :fl(v, Ci)*MI(v, Cj)>O 0 : otherwise Finally, the similarity of Ci and Cj is measured as follows." ></td>
	<td class="line x" title="65:125	SIM(Ci, Cj) = E sire(v, Ci, Cj ) v In eqnation (eq.1), f(v) > 0 because v is the verb in a certain cooccurrence data obtained in step 2." ></td>
	<td class="line x" title="66:125	However, f(C) may be equal to 0 because tile primitive class C is a certain class in all primitive classes." ></td>
	<td class="line x" title="67:125	If f(C) = 0, then MI(v, C) cannot be defined." ></td>
	<td class="line x" title="68:125	So, if f(Ci) = 0 or f(Cj) = 0 for all verb v, then SIM(Ci, Cj) is undefined." ></td>
	<td class="line x" title="69:125	2.4 Estimating the undefined similarity (step 4) There are 3,582 types of primitive classes, so ass2C2 = 6,413,571 similarities must be defined." ></td>
	<td class="line x" title="70:125	Through step 3, there were 2,049,566 similarities which had been defined." ></td>
	<td class="line x" title="71:125	This is 32.0 % of the whole." ></td>
	<td class="line x" title="72:125	In step 4, we estimate undefined similarities by the thesaurus and defined similarities." ></td>
	<td class="line x" title="73:125	Let us estimate the undefined similarity between the classes Ca and Cb." ></td>
	<td class="line x" title="74:125	First, we pick out the set of primitive classes {Ca,, Ca2,' ', Ca, }, such that each class has the common parent node as class Ca in Bunrui-goi-hyou, that is, the class C(~, is the brother node of class Ca." ></td>
	<td class="line x" title="75:125	By the same process, we pick out the set of primitive classes {Cbl, Cb2,''', Cbj } for class Cb." ></td>
	<td class="line x" title="76:125	The similarity in Bunrui-goi-hyou are reliable if its value is large." ></td>
	<td class="line x" title="77:125	Thus, it is reliable the defined SIM(C~k,Cb) and the defined SIM(C~,Cb,,) are close to the undefined SIM(C~,Cb)." ></td>
	<td class="line x" title="78:125	Therefore, we define SIM(C~, Cb) by the average of SIM(C~ k, Cb) and SIM(Ca, Cb~)." ></td>
	<td class="line x" title="79:125	This process corresponds to that the slot in the Fig.l(a) is filled with the average of values in the shade part in the figure." ></td>
	<td class="line x" title="80:125	If 1132 SIM(C4., Cb)." ></td>
	<td class="line x" title="82:125	 C6 Cbi Ca,'' ca ''' cai (a) 1st estimation SIM(Ca, Cb) 'k/' '  Cb \] I cu, 0<'' Ca '' Ca~ (b) 2nd estimation SIM(Ca, G,)  a:: : ~ :: m m J:,: (c) 3rd estimation Figure 1: Estimation of SIM((/~, C~) the undefined pairs are left through above estimations, they are estimated by the ave.rage of SIM (U,,k, (lb,,)." ></td>
	<td class="line x" title="83:125	This process corresponds to that the slot in the Fig.l (b) is filled with the average values in the shade part in the figure." ></td>
	<td class="line x" title="84:125	If undefined pairs still remain, we pick out the set of primitive classes, such that the grandmother node of each class is the same as that of Ca and (;'~, and we repeat the above processes (ef." ></td>
	<td class="line x" title="85:125	Fig.l(('))." ></td>
	<td class="line x" title="86:125	Fig.2 shows the ratio of the number of similarities defined in each process." ></td>
	<td class="line x" title="87:125	r corpUs .3rd estimation,~I 1st estimation I 2LII .,,% I, %H Figure 2: ratio of the number of similarities defined in each process 3 Evaluations First, we evaluate the obtained similarities by comparing them with the similarities in Bunruigoidlyou." ></td>
	<td class="line x" title="88:125	The similarity in Bunrui-goi-hyou are defined by the level of the common parent node of two classes." ></td>
	<td class="line x" title="89:125	Tab.2 shows the average of similarities between two classes, such that these two classes have the common parent node whose level is x in Bunrni-goi-hyou." ></td>
	<td class="line x" title="90:125	Tab.2 shows that the larger the similarity in Bunrui-goi-hyou is, the larger the obtained similarity is. It follows that the obtained similarity is roughly similar to the similarity in Bunrui-goihyou." ></td>
	<td class="line x" title="91:125	Next, we evaluate the appropriateness of the first estimation." ></td>
	<td class="line x" title="92:125	The average of 'coefftcient of variation >' for similarities used in each first cs>l'he coefficient of variation is the stamtard deviation divided by the mean." ></td>
	<td class="line x" title="93:125	the level of the COFIIIIIOII |ntrellt node 1 average of obtained similarities 2.160 3.690 6.51.9 lO.O9O 5 14.815 6 oo Table 2: tendency of obtained similarities timation is 0.384." ></td>
	<td class="line x" title="94:125	And the coetlicient of variation for all similarities measured by the corpus is 2.125." ></td>
	<td class="line x" title="95:125	It follows that similarities used in first estimation are close to each other." ></td>
	<td class="line x" title="96:125	At l~t, we evaluate the appropriateness of the obtained similarity by selecting a verbal meaning." ></td>
	<td class="line x" title="97:125	In this experiment, to measure the similarity in Bunrui-goi-hyou and the similarity obtained by our method." ></td>
	<td class="line x" title="98:125	Because the similarity in Bunruigoi-hyou is rough, multiple answers may arise." ></td>
	<td class="line x" title="99:125	In evaluation of the similarity in Bunrui-goi-hyou, we give a C) if the answer is unique and right, a A if the answers contain the right answer, and  if the answers don't contain the right answer." ></td>
	<td class="line x" title="100:125	\[n evaluation of our similarities, we give a C) if the largest similarity is right, a A if 1st or 2ud largest; similarities is right answer, and  if neither of 1st and 2nd largest similarities is the right answer." ></td>
	<td class="line x" title="101:125	Tab.1 shows the results of evaluations." ></td>
	<td class="line x" title="102:125	\]'his table shows that the similarity obtained by our method is a little better than the similarity in Bunrui-goi-hyou." ></td>
	<td class="line x" title="103:125	4 Remarks It is difficult to extract all knowledge from only a corpus because of ineoml)lete analysis and data sparseness." ></td>
	<td class="line x" title="104:125	In order to avoid these difilculties, the approach to use of different resources from the col pus is promising." ></td>
	<td class="line x" title="105:125	To construct the thesaurus fi'om 1133 exmnple nouns e ~c." ></td>
	<td class="line x" title="106:125	(9) ~ ~ (4) ~ ~#tzo/3) Our method u7 (~, ~, , ~  ) ~ (~,,Nv,~,~!~'  ) 25 (3~, ~'-P ~4, ~, ~, ) 18~ pattern (num." ></td>
	<td class="line x" title="107:125	of meanings ) 16 13 13 22 17, ~(i 19 19 ~' ~N' N&' ~'' / /,~q~, g, ~.~, ~  ) ~, ~E, ~, ~z,u  ) f~, ~, ~, ~  ) '~, ~, ~m, z,  ) ~,.~, ~ v, $, Nm  ) nouns for test 13 (~tI, ~M, I::'--31/, {ziznr~  9 (:b,~.x. ,~,oc:oa:  ) 19 ~,~\]'., 7U/~f,~,) is V~,~/, 4:~--Y, ~  ) s (~,~,~,~  ) is i~, ~2~, ~JN, i~, ) 28 ~, H~,~N, ~,) Total \] 184 I Bunrui-goi-hyou ol/'1 x O /'Ix 14 2 8 17 0 7 0 2 2 1 1 2 8 1 7 9 1 6 1 1 1 1 0 2 ) 14 0 2 13 2 1 $ l 7 0 1 7 0 1 ) ', 12 0 1 10 l 2 3 1 5 3 1 5 7 4 8 9 3 7 16 0 2 14 2 2 7 0 1 8 0 0 14 1 3 16 0 2 13 6 9 16 3 9 _.1 116 I 18 I 50 I 124 I 14 14~ I Table h Result of test of verbal meaning selection a dictionary (Turumaru et al. , 1991), and to make example data from a usable knowledge (Kaneda et al. , 1995) is considered this approach." ></td>
	<td class="line x" title="109:125	The proposed method uses the handmade thesaurus as the different resource from the corpus." ></td>
	<td class="line x" title="110:125	In addition, the statistical data from the corpus are weighted." ></td>
	<td class="line x" title="111:125	However, it will be important in future research to investigate how much weight should be given to each bit of data." ></td>
	<td class="line x" title="112:125	It is difficult to build knowledge corresponding to each domain from zero." ></td>
	<td class="line x" title="113:125	So it is important to extend and modify the existing knowledge corresponding to the purpose of use." ></td>
	<td class="line x" title="114:125	In this method, relatively few bits of cooccurrence data are used because nouns in the cooecurrence data are not on Bunrui-goi-hyou." ></td>
	<td class="line x" title="115:125	If we extend Bunrui-goi-hyou, these unused cooccurrence data may be useful." ></td>
	<td class="line x" title="116:125	And by using the obtained similarities, we can modify Bunrui-goi-hyou." ></td>
	<td class="line x" title="117:125	Since our method construct a thesaurus from the handmade thesaurus by the corpus, it can be considered a method to refine the handmade thesaurus such as to be suitable for the domain of the used corpus." ></td>
	<td class="line x" title="118:125	5 Conclusions In this paper, we proposed a method to define similarities between general nouns used in various domains." ></td>
	<td class="line x" title="119:125	The proposed method redefines the similarity in a handmade thesaurus by using corpora." ></td>
	<td class="line x" title="120:125	The method avoids data sparseness by estimating undefined similarities from the similarity in the thesaurus and similarities defined by corpora." ></td>
	<td class="line x" title="121:125	The obtained similarities are obviously the same in number as the original similarities, and are more appropriate than the original similarities in the thesaurus." ></td>
	<td class="line x" title="122:125	By using Bnnru~-goi-hyou as the handmade thesaurus and newspaper articles with about 7.85 M sentences as a corpus, we confirmed the appropriateness of this method." ></td>
	<td class="line x" title="123:125	In the future, we will extend and modify Bunrui-goi-hyou by the cooecurrence data and the similarities obtained in this study, and will try to classify multiple senses of verbs." ></td>
	<td class="line x" title="124:125	Acknowledgment The corpus used in our experiment is extracted from CD-ROMs ('90 -'94) sold by Nihon Keizai Shinbun company." ></td>
	<td class="line x" title="125:125	We deeply appreciate the Nihon Keizai Shinbun company to permit the use of this corpus and many people who negotiated with the company about the use of this corpus." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P97-1066
Knowledge Acquisition From Texts: Using An Automatic Clustering Method Based On Noun-Modifier Relationship
Assadi, Houssem;"></td>
	<td class="line x" title="1:74	Knowledge Acquisition from Texts : Using an Automatic Clustering Method Based on Noun-Modifier Relationship Houssem Assadi Electricit4 de France DER/IMA and Paris 6 University LAFORIA 1 avenue du G4n4ral de Gaulle, F-92141, Clamart, France houssem, assadi@der, edfgdf, fr Abstract We describe the early stage of our methodology of knowledge acquisition from technical texts." ></td>
	<td class="line x" title="2:74	First, a partial morpho-syntactic analysis is performed to extract 'candidate terms'." ></td>
	<td class="line x" title="3:74	Then, the knowledge engineer, assisted by an automatic clustering tool, builds the 'conceptual fields' of the domain." ></td>
	<td class="line x" title="4:74	We focus on this conceptual analysis stage, describe the data prepared from the results of the morpho-syntactic analysis and show the results of the clustering module and their interpretation." ></td>
	<td class="line x" title="5:74	We found that syntactic links represent good descriptors for candidate terms clustering since the clusters are often easily interpreted as 'conceptual fields'." ></td>
	<td class="line x" title="6:74	1 Introduction Knowledge Acquisition (KA) from technical texts is a growing research area among the KnowledgeBased Systems (KBS) research community since documents containing a large amount of technical knowledge are available on electronic media." ></td>
	<td class="line x" title="7:74	We focus on the methodological aspects of KA from texts." ></td>
	<td class="line x" title="8:74	In order to build up the model of the subject field, we need to perform a corpus-based semantic analysis." ></td>
	<td class="line x" title="9:74	Prior to the semantic analysis, morpho-syntactic analysis is performed by LEXTER, a terminology extraction software (Bourigault et al. , 1996) : LEXTER gives a network of noun phrases which are likely to be terminological units and which are connected by syntactical links." ></td>
	<td class="line x" title="10:74	When dealing with medium-sized corpora (a few hundred thousand words), the terminological network is too voluminous for analysis by hand and it becomes necessary to use data analysis tools to process it." ></td>
	<td class="line x" title="11:74	The main idea to make KA from medium-sized corpora a feasible and efficient task is to perform a robust syntactic analysis (using LEXTER, see section 2) followed by a semi-automatic semantic analysis where automatic clustering techniques are used interactively by the knowledge engineer (see sections 3 and 4)." ></td>
	<td class="line x" title="12:74	We agree with the differential definition of semantics : the meaning of the morpho-lexical units is not defined by reference to a concept, but rather by contrast with other units (Rastier et al. , 1994)." ></td>
	<td class="line oc" title="13:74	In fact, we are considering 'word usage rather than word meanin\]' (Zernik, 1990) following in this the distributional point of view, see (Harris, 1968), (Hindle, 1990)." ></td>
	<td class="line oc" title="14:74	Statistical or probabilistic methods are often used to extract semantic clusters from corpora in order to build lexical resources for ANLP tools (Hindle, 1990), (Zernik, 1990), (Resnik, 1993), or for automatic thesaurus generation (Grefenstette, 1994)." ></td>
	<td class="line x" title="15:74	We use similar techniques, enriched by a preliminaxy morpho-synta~ztic analysis, in order to perform knowledge acquisition and modeling for a specific task (e.g. : electrical network planning)." ></td>
	<td class="line x" title="16:74	Moreover, we are dealing with language for specific purpose texts and not with general texts." ></td>
	<td class="line x" title="17:74	2 The morpho-syntactic analysis : the LEXTER software LEXTER is a terminology extraction software (Bourigault et al. , 1996)." ></td>
	<td class="line x" title="18:74	A corpus of French texts on any technical subject can be fed into it." ></td>
	<td class="line x" title="19:74	LEXTER performs a morpho-syntactic analysis of this corpus and gives a network of noun phrases which are likely to be terminological units." ></td>
	<td class="line x" title="20:74	Any complex term is recursively broken up into two parts : head (e.g. PLANNING in the term REGIONAL NETWORK PLANNING), and expansion (e.g. REGIONAL in the term REGIONAL NETWORK) 1 This analysis allows the organisation of all the candidate terms in a network format, known as the XAll the examples given in this paper are translated from French." ></td>
	<td class="line x" title="21:74	504 'terminological network'." ></td>
	<td class="line x" title="22:74	Each analysed complex candidate term is linked to both its head (H-link) and expansion (E-link)." ></td>
	<td class="line x" title="23:74	LEXTER alSO extracts phraseological units (PU) which are 'informative collocations of the candidate terms'." ></td>
	<td class="line x" title="24:74	For instance, CONSTRUCTION OF THE HIGHVOLTAGE LINE is a PU built with the candidate term HIGH-VOLTAGE LINE." ></td>
	<td class="line x" title="25:74	PUs are recursively broken up into two parts, similarly to the candidate terms, and the links are called H'-link and E'-link." ></td>
	<td class="line x" title="26:74	3 The data for the clustering module The candidate terms extracted by LEXTER can be NPs or adjectives." ></td>
	<td class="line x" title="27:74	In this paper, we focus on NP clustering." ></td>
	<td class="line x" title="28:74	A NP is described by its 'terminological context'." ></td>
	<td class="line x" title="29:74	The four syntactic links of LEXTER Can be used to define this terminological context." ></td>
	<td class="line x" title="30:74	For instance, the 'expansion terminological context' (Eterminological context) of a NP is the set of the candidate terms appearing in the expansion of the more complex candidate term containing the current NP in head position." ></td>
	<td class="line x" title="31:74	For example, the candidate terms (NATIONAL NETWORK, REGIONAL NETWORK, DISPATCHING NETWORK) give the context (NATIONAL, REGIONAL, DISPATCHING) for the noun NETWORK." ></td>
	<td class="line x" title="32:74	If we suppose that the modifiers represent specialisations of a head NP by giving a specific attribute of it, NPs described by similar E-terminological contexts will be semantically close." ></td>
	<td class="line x" title="33:74	These semantic similarities allow the KE to build conceptual fields in the early stages of the KA process." ></td>
	<td class="line x" title="34:74	The links around a NP within a PU are also interesting." ></td>
	<td class="line x" title="35:74	Those candidate terms appearing in the head position in a PU containing a given NP could denote properties or actions related to this NP." ></td>
	<td class="line x" title="36:74	For instance, the PUs LENGTH OF THE LINE and NOMINAL POWER OF THE LINE show two properties (LENGTH and NOMINAL POWER) of the object LINE; the PU CONSTRUCTION OF THE LINE shows an action (CONSTRUCTION) which can be applied to the object LINE." ></td>
	<td class="line x" title="37:74	This definition of the context is original compared to the classical context definitions used in Information Retrieval, where the context of a lexical unit is obtained by examining its neighbours (collocations) within a fixed-size window." ></td>
	<td class="line x" title="38:74	Given that candidate terms extraction in LEXTER is based on a morphosyntactical analysis, our definition allows us to group collocation information disseminated in the corpus under different inflections (the candidate terms of LEXTER are lemmatised) and takes into account the syntactical structure of the candidate terms." ></td>
	<td class="line x" title="39:74	For instance, LEXTER extracts the complex candidate term BUILT DISPATCHING LINE, and analyses it in (BUILT (DISPATCHING LINE)); the adjective BUILT will appear in the terminological context of DISPATCHING LINE and not in that of DISPATCHING." ></td>
	<td class="line x" title="40:74	It is obvious that only the first context is relevant given that BUILT characterises the DISPATCHING LINE and not the DISPATCHING." ></td>
	<td class="line x" title="41:74	To perform NP clustering, we prepared two data sets : in the first, NPs are described by their Eterminological context; in the second one, both the E-terminological context and the H'terminological context (obtained with the H'-link within PUs) are used." ></td>
	<td class="line x" title="42:74	The same filtering method 2 and clustering algorithm are applied in both cases." ></td>
	<td class="line x" title="43:74	Table 1 shows an extract from the first data set." ></td>
	<td class="line x" title="44:74	The columns are labelled by the expansions (nominal or adjectival) of the NPs being clustered." ></td>
	<td class="line x" title="45:74	Each line represents a NP (an individual, in statistical terms) : there is a '1' when the term built with the NP and the expansion exists (e.g. REGIONAL NETWORK is extracted by LEXTER), and a '0' otherwise ('national line' is not extracted by LEXTER)." ></td>
	<td class="line x" title="46:74	NATIONAL DISPATCHING REGIONAL LINE 0 1 0 NETWORK 1 1 1 Table 1: example of the data used for NP clustering In the remainder of this article, we describe the way a KE uses LEXICLASS to build 'conceptual fields' and we also compare the clusterings obtained from the two different data sets." ></td>
	<td class="line x" title="47:74	4 The conceptual analysis : the LEXICLASS software LEXICLASS is a clustering tool written using C language and specialised data analysis functions from Splus TM software." ></td>
	<td class="line x" title="48:74	Given the individuals-variables matrix above, a similarity measure between the individuals is calculated 3 and a hierarchical clustering method is performed with, as input, a similarity matrix." ></td>
	<td class="line x" title="49:74	This kind of methods gives, as a result, a classification tree (or dendrogram) which has to be cut at a given level in order to produce clusters." ></td>
	<td class="line x" title="50:74	For example, this method, applied on a population of 221 NPs (data set 1) gives 2This filtering method is mandatory, given that the chosen clustering algorithm cannot be applied to the whole terminological network (several thousands of terms) and that the results have to be validated by hand." ></td>
	<td class="line x" title="51:74	We have no space to give details about this method, but we must say that it is very important to obtain proper data for clustering 3similarity measures adapted to binary data are used e.g. the Anderberg measure see (Kotz et al. , 1985) 505 21 clusters, figure 1 shows an example of such a cluster." ></td>
	<td class="line x" title="52:74	i AN AUTOMATICALLY FOUND ~ OUTPOST NETWORK CLUSTER, BAR STANDBY ', CABLE PRIMARY ', LINK TRANFORMER UINE TRANSFORMATION LEVEL UNDERGROUND CABLE ', STRUCTURE PART INTERPRETATION BY TI~ KNOWLEDGE ENGINEER STRUCTUI~S und~g~Lmd ~1~ Figure 1: a cluster interpretation The interpretation, by the KE, of the results given by the clustering methods applied on the data of table 1 leads him to define conceptual fields." ></td>
	<td class="line x" title="53:74	Figure 1 shows the transition from an automatically found cluster to a conceptual field : the KE constitutes the conceptual fields of 'the structures'." ></td>
	<td class="line x" title="54:74	He puts some concepts in it by either validating a candidate term (e.g. LINE), or reformulating a candidate term (e.g. PRIMARY is an ellipsis and leads the KE to create the concept primary substation)." ></td>
	<td class="line x" title="55:74	The other candidate terms are not kept because they are considered as non relevant by the KE." ></td>
	<td class="line x" title="56:74	The conceptual fields have to be completed all along the KA process." ></td>
	<td class="line x" title="57:74	At the end of this operation, the candidate terms appearing in a conceptual field are validated." ></td>
	<td class="line x" title="58:74	This first stage of the KA process is also the opportunity for the KE to constitute synonym sets : the synonym terms are grouped, one of them is chosen as a concept label, and the others are kept as the values of a generic attribute labels of the considered concept (see figure 2 for an example)." ></td>
	<td class="line x" title="59:74	l line //conceptual field// : structure //typell : object //labels// : LINE, ELECTRIC LINE, OVERHEAD LINE Figure 2: a partial description of the concept 'line' 5 Discussion  Evaluation of the quality of the clustering procedure  in the majority of the works using clustering methods, the evaluation of the quality of the method used is based on recall and precision parameters." ></td>
	<td class="line x" title="60:74	In our case, it is not possible to have an a priori reference classification." ></td>
	<td class="line x" title="61:74	The reference classification is highly domainand task-dependent." ></td>
	<td class="line x" title="62:74	The only criterion that we have at the present time is a qualitative one : that is the usefulness of the results of the clustering methods for a KE building a conceptual model." ></td>
	<td class="line x" title="63:74	We asked the KE to evaluate the quality of the clusters, by scoring each of them, assuming that there are three types of clusters : 1." ></td>
	<td class="line x" title="64:74	Non relevant clusters." ></td>
	<td class="line x" title="65:74	2." ></td>
	<td class="line x" title="66:74	Relevant clusters that cannot be labelled." ></td>
	<td class="line x" title="67:74	3." ></td>
	<td class="line x" title="68:74	Relevant clusters that can be labelled." ></td>
	<td class="line x" title="69:74	Then an overall clustering score is computed." ></td>
	<td class="line x" title="70:74	This elementary qualitative scoring allowed the KE to say that the clustering obtained with the second data set is better than the one obtained with the first." ></td>
	<td class="line x" title="71:74	LEXICLASS is a generic clustering module, it only needs nominal (or verbal) compounds described by dependancy relationships." ></td>
	<td class="line x" title="72:74	It may use the results of any morpho-syntactic analyzer which provides dependancy relations (e.g. verbobject relationship)." ></td>
	<td class="line x" title="73:74	The interactive conceptual analysis : in the present article, we only described the first step of the KA process (the 'conceptual fields' construction)." ></td>
	<td class="line x" title="74:74	Actually, this process continues in an interactive manner : the system uses the conceptual fields defined by the KE to compute new conceptual structures; these are accepted or rejected by the KE and the exploration of both the terminological network and the documentation continues." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W97-0205
A Lexicon For Underspecified Semantic Tagging
Buitelaar, Paul;"></td>
	<td class="line x" title="1:166	A Lexicon for Underspecified Semantic Tagging Paul Buitelaar Dept. of Computer Science Brandeis University Waltham, MA 02254-9110, USA paulb@cs, brandeis, edu Abstract The paper defends the notion that semantic tagging should be viewed as more than disambiguation between senses." ></td>
	<td class="line x" title="2:166	Instead, semantic tagging should be a first step in the interpretation process by assigning each lexJ.cal item a representation of all of its sy=stematically related senses, from which fuxther semantic processing steps can derive discourse dependent interpretations." ></td>
	<td class="line x" title="3:166	This leads to a new type of semantic lexicon (CoRv.Lzx) that supports underspecified semantic tagging through a design based on systematic polysemous classes and a class-based acquisition of lexical knowledge for specific domains." ></td>
	<td class="line x" title="4:166	1 Underspecified semantic tagging Semantic tagging has mostly been considered as nothing more than disambiguation to be performed along the same lines as part-of-speech tagging: given n lexical items each with m senses apply linguistic heuristics and/or statistical measures to pick the most likely sense for each lexical item (see eg: (Yarowsky, 1Q92) (Stevenson and Wilks, 1997))." ></td>
	<td class="line x" title="5:166	I do not believe this to be the right approach because it blurs the distinction between 'related' (systematic polysemy) and 'unrelated' senses (homonymy : bank bank)." ></td>
	<td class="line x" title="6:166	Although homonyms need to be tagged with a disambiguated sense, this is not necessarily so in the case of systematic polysemy." ></td>
	<td class="line x" title="7:166	There are two reasons for this that I will discuss briefly here." ></td>
	<td class="line x" title="8:166	First, the problem of multiple reference." ></td>
	<td class="line x" title="9:166	Consider this example from the BROWN corpus: \[A long book heavily weighted with milltary technlcalities\]Np, in this edition it is neither so long nor so technical as it was originally." ></td>
	<td class="line x" title="10:166	The discourse marker (it) refers back to an NP that expresses more than one interpretation at the same time." ></td>
	<td class="line x" title="11:166	The head of the NP (book) has a number of systematically related senses that are being expressed simultaneously." ></td>
	<td class="line x" title="12:166	The meaning of book in this sentence cannot be disambiguated between the number of interpretations that are implied: the informational content of the book (military technicalities), its physical appearance (heavily weighted) and the events that are involved in its construction and use (long)." ></td>
	<td class="line x" title="13:166	The example illustrates the fact that disambiguation between related senses is not always possible, which leads to the further question if a discrete distinction between such senses is desirable at all." ></td>
	<td class="line x" title="14:166	A number of researchers have answered this question negatively (see eg: (Pustejovsky, 1995) (Killgariff, 1992))." ></td>
	<td class="line x" title="15:166	Consider these examples from BROWN: (1) fast run-up (of the stock) (2) fast action (by the city government) (3) fast footwork (by Washington) (4) fast weight gaining (5) fast condition (of the track) (6) fast response time (7) fast people (8) fast ball Each use of the adjective 'fast' in these examples has a slightly different interpretation that could be captured in a number of senses, reflecting the different syntactic and semantic patterns." ></td>
	<td class="line x" title="16:166	For instance: 1." ></td>
	<td class="line x" title="17:166	'a fast action' (1, 2, 3, 4) 2." ></td>
	<td class="line x" title="18:166	'a fast state of affairs' (5, 6) 3." ></td>
	<td class="line x" title="19:166	'a fast object' (7, 8) 25 On the other hand all of the interpretations have something in common also, namely the idea of 'speed'." ></td>
	<td class="line x" title="20:166	It seems therefore useful to underspecify the lexical meaning of 'fast' to a representation that captures this primary semantic aspect and gives a general structure for its combination with other lexical items, both locally (in compositional semantics) and globally (in discourse structure)." ></td>
	<td class="line x" title="21:166	Both the multiple reference and the sense enumeration problem show that lexical items mostly have an indefinite number of related but highly discourse dependent interpretations, between which cannot be distinguished by semantic tagging alone." ></td>
	<td class="line x" title="22:166	Instead, semantic tagging should be a first step in the interpretation process by assigning each lexical item a representation of all of its systematically related 'senses'." ></td>
	<td class="line x" title="23:166	Further semantic processing steps derive discourse dependent interpretations from this representation." ></td>
	<td class="line x" title="24:166	Semantic tags are therefore more like pointers to complex knowledge representations, which can be seen as underspecified lexical meanings." ></td>
	<td class="line x" title="25:166	2 CORELEX: A Semantic Lexicon with Systematic Polysemous Classes In this section I describe the structure and content of a lexicon (CORELEX) that builds on the assumptions about lexical semantics and discourse outlined above." ></td>
	<td class="line x" title="26:166	More specifically, it is to be 'structured in such a way that it reflects the lexical semantics of a language in systematic and predictable ways' (Pustejovsky, Boguraev, and Johnston, 1995)." ></td>
	<td class="line x" title="27:166	This assumption is fundamentally different from the design philosophies behind existing lexical semantic resources like WORDNET that do not account for any regularities between senses." ></td>
	<td class="line x" title="28:166	For instance, WORDNET assigns to the noun book the following senses: the content that is being communicated (communicatiofl) and the medium of communication (artifact)." ></td>
	<td class="line x" title="29:166	More accurately, book should be assigned a qualia structure which implies both of these interpretations and connects them to each of the more specific senses that WORDNET assigns: that is, facts, drama and a journal can be part-of the content of a book; a section is part-of both the content and the medium; publication, production and recording are all events in which both the content and the medium aspects of a book can be involved." ></td>
	<td class="line x" title="30:166	An important advantage of the CORELEX approach is more consistency among the assignments of lexical semantic structure." ></td>
	<td class="line x" title="31:166	Consider the senses that WORDNET assigns to door, gate and window: door movable_barrier -,~ artifact entrance ~-~ opening access ~* cognition, knowledge house ~-, ??" ></td>
	<td class="line x" title="32:166	room ~-~ ??" ></td>
	<td class="line x" title="33:166	gate movable_barrier -,~ artifact computer_circult -,~ opening grossAncome -,~ opening window opening -~ opening panel --~ artifact display ~-* cognition, knowledge publication product, production fact dramatic_composltion, dramatic_work record section, subdivision journal Figure I: WORDNET senses for the noun book At the top of the WORDNET hierarchy these seven senses can be reduced to two unrelated 'basic senses': 26 Figure 2: WORDNET senses for the nouns door, window and gate Obviously these are similar words, something which is not expressed in the WORDNET sense assignments." ></td>
	<td class="line x" title="34:166	In the CORELEX approach, these nouns are given the same semantic type, which is underspecifled for any specific 'sense' but assigns them consistently with the same basic lexical semantic structure that expresses the regularities between all of their interpretations." ></td>
	<td class="line x" title="35:166	However, despite its shortcomings WORDNET is a vast resource of lexical semantic knowledge that can m m m mm m \[\] m m n \[\] m m n m m m m m n m m be mined, restructured and extended, which makes it a good starting point for the construction of CORELEX." ></td>
	<td class="line x" title="36:166	The next sections describe how systematic polysem0us classes and underspecified semantic types can be derived from WORDNET." ></td>
	<td class="line x" title="37:166	In this paper I only consider classes of noun,s, but the process described here can also be applied to other parts of speech." ></td>
	<td class="line x" title="38:166	2.1 Systematic polysemous classes We can arrive at classes of systematically polysemous lexical items by investigating which items share the same senses and are thus polysemous in the same way." ></td>
	<td class="line x" title="39:166	This comparison is done at the top levels of the WORDNET hierarchy." ></td>
	<td class="line x" title="40:166	WORDNET does not have an explicit level structure, but for the purpose of this research one can distinguish a set of 32 =basic senses' that partly coincides with, but is not based directly on WORDNET'S list of 26 'top types': act (act), agent (agt), animal (~.m), artifact (art), attribute (air), blunder (bln), cell (cel), chemical (chm), communication (corn), event (evl;), food (rod), form (frm), group_biological (grb), group (grp), group_social (grs), h-m~n (hum), llnear_measure (1me), location (loc), 1ocation_geographical (log), measure (mea), natural_object (nat), phenomenon (p\]m), plant (plt), possession (pos), part (prt), psychological (psy), quantity_definite (qud), quantity_indefinite (qui), relation (re1), space (spc), state (sta), time (tree) Figure 3 shows their distribution among noun stems in the BROWN corpus." ></td>
	<td class="line x" title="41:166	For instance there are 2550 different noun stems (with 49,824 instances) that have each 2 out of the 32 'basic senses' assigned to them in 238 different combinations (a subset of 322 = 1024 possible combinations)." ></td>
	<td class="line x" title="42:166	We now reduce all of WORDNET'S sense assignments to these basic senses." ></td>
	<td class="line x" title="43:166	For instance, the seven different senses that WORDNET assigns to the lexical item book (see Figure I above) can be reduced to the two basic senses: 'art corn'." ></td>
	<td class="line x" title="44:166	We do this for each lexical item and then group them into classes according to their assignments." ></td>
	<td class="line x" title="45:166	From these one can filter out those classes that have only one member because they obviously do not represent a systematically polysemous class." ></td>
	<td class="line x" title="46:166	The lexical items in those classes have a highly idiosyncratic behavior and are most likely homonyms." ></td>
	<td class="line x" title="47:166	This leaves 27 senses comb's stems instances 2 238 2550 49824 3 379 936 35608 4 268 347 22543 5 148 154 15345 6 52 52 5915 7 27 27 5073 8 10 10 3273 9 3 3 1450 I0 1 1 483 11 2 2 959 12 1 1 441 1161 10797 140914 Figure 3: Polysemy of nouns in BROWN a set of 442 polysemous classes, of which Figure 4 gives a selection: act art evt rel act art log act evt nat chin sta com prt frm sta line qud loc psy log pos sta phm pos tel sta click modification reverse berth habitation mooring ascent climb grease ptomaine appendix brickbat index solid vacancy void em fathom fthm inch mil bourn bourne demarcation fairyland rubicon trend vertex barony province accretion usance wastage baronetcy connectedness context efficiency inclusion liquid relationship Figure 4: A selection of polysemous classes Not all of the 442 classes are systematically polysemous." ></td>
	<td class="line x" title="48:166	Consider for example the following classes: Some of these classes are collections of homonyms that are ambigtzotz,s in similar ways, but do not lead to any kind of predictable polysemous behavior, for instance the class 'act anm art' with the lexical items: drill ruff solitaire stud." ></td>
	<td class="line x" title="49:166	Other classes consist of both homonyms and systematically polysemous lexical items like the class act log, which includes caliphate, clearing, emirate, prefecture, repair, wheeling vs. bolivia, charleston, chicago, michigan." ></td>
	<td class="line x" title="50:166	m m act ~nm art act log act plt axt rod loc chmpsy rod hum plt drill ruff solitaire stud bolivia caliphate charleston chicago clearing emirate michigan prefecture repair santiago wheeling chess grapevine rape pike port complex incense mandarin sage swede Figure 5: A selection of ambiguous classes Whereas the first group of nouns express two separated but related meanings (the act of clearing, repair, etc. takes place at a certain location), the second group expresses two meanings that are not related (the charleston dance which was named after the town by the same name)." ></td>
	<td class="line x" title="51:166	The ambiguous classes need to be removed altogether, while the ones with mixed ambiguous and polllsemous lexical items are to be weeded out carefully." ></td>
	<td class="line x" title="52:166	2.2 Underspecified semantic types The next step in the research is to organize the remaining classes into knowledge representations that relate their senses to each other." ></td>
	<td class="line x" title="53:166	These representations are based on Generative Lexicon theory (G), using qualia roles and (dotted) types (Pustejovsky, 19os)." ></td>
	<td class="line x" title="54:166	Qualia roles distinguish different semantic aspects: FORMAL indicates semantic type; CONSTITUTIVE part-whole information; AGENTIVE and TELIC associated events (the first dealing with the origin of the object, the second with its purpose)." ></td>
	<td class="line x" title="55:166	Each role is typed to a specific class of lexical items." ></td>
	<td class="line x" title="56:166	Types are either simple (human, artifact,) or complex (e.g. , information.physical)." ></td>
	<td class="line x" title="57:166	Complex types are called dotted types after the 'dots' that are used as type constructors." ></td>
	<td class="line x" title="58:166	Here I introduce two kinds of dots: Closed clots ''." ></td>
	<td class="line x" title="59:166	connect systematically related types that are always interpreted simultaneonsly." ></td>
	<td class="line x" title="60:166	Open dots 'o' connect systematically related types that are not (normally) interpreted simultaneously." ></td>
	<td class="line x" title="61:166	Both '#*~' and 'aor' denote sets of pairs of objects (a, b), a an object of type ~ and b an object of type ~'." ></td>
	<td class="line x" title="62:166	A condition aRb restricts this set of pairs to only those for which some relation R holds, where R denotes a subset of the Cartesian product of the sets of type ~ objects and type r objects." ></td>
	<td class="line x" title="63:166	The difference between types '#or' and 'cot' is in the nature of the objects they denote." ></td>
	<td class="line x" title="64:166	The type 'aer' denotes sets of pairs of objects where each pair behaves as a complex object in discourse structure." ></td>
	<td class="line x" title="65:166	For instance, the pairs of objects that are introduced by the type informationephysical (book, journal, scoreboard ) are addressed as the complex objects (x:information, y:physical) in discourse." ></td>
	<td class="line x" title="66:166	On the other hand, the type '#or' denotes simply a set of pairs of objects that do not occur together in discourse structure." ></td>
	<td class="line x" title="67:166	For instance, the pairs of objects that are introduced by the type form.artifact (door, gate, window  ) are not (normally) addressed simultaneously in discourse, rather one side of the object is picked out in a particular context." ></td>
	<td class="line x" title="68:166	Nevertheless, the pair as a whole remains active during processing." ></td>
	<td class="line x" title="69:166	The resulting representations can be seen as underspecified lexical meanings and are therefore referred to as underspecified semantic types." ></td>
	<td class="line x" title="70:166	CORELEX currently covers 104 underspecified semantic types." ></td>
	<td class="line x" title="71:166	This section presents a number of examples, for a complete overview see the CORELEX webpage: http://~, ca." ></td>
	<td class="line x" title="72:166	brandeis, edu/'paulb/Cor eLex/corelex, html Closed Dots Consider the underspecified representation for the semantic type actorelation: FORMAL = Q:act.relation CONSTITUTIVE = X:act V Y:relation V Z:act,relation TELIC --P:event (acterelation) A act (R1) A relation(R2,Rs) Figure 6: Representation for type: actorelation The representation introduces a number of objects that are of a certain type." ></td>
	<td class="line x" title="73:166	The FORMAL role introduces an object Q of type actorelation." ></td>
	<td class="line x" title="74:166	The CONSTITUTIVE introduces objects that are in a partwhole relationship with Q. These are either of the same type actorelation or of the simple types act or relation." ></td>
	<td class="line x" title="75:166	The TELIC expresses the event P that can be associated with an object of type acterelation." ></td>
	<td class="line x" title="76:166	For instance, the event of increase as in 'increasing the communication between member states' implies 'increasing' both the act of communicating an object 28 m m m m m m m m m \[\] m mm m m m m m m m m m m mm mm m m m m m RI and the communication relation between two objects R2 and Rs." ></td>
	<td class="line x" title="77:166	All these objects are introduced on the semantic level and correspond to a number of objects that will be realized in syntax." ></td>
	<td class="line x" title="78:166	However, not all semantic objects will be realized in syntax." ></td>
	<td class="line x" title="79:166	(See Section 3.4 for more on the syntax-semantics interface)." ></td>
	<td class="line x" title="80:166	The instances for the type act*relation are given in Figure 7, covering three different systematic polysemous classes." ></td>
	<td class="line x" title="81:166	We could have chosen to include only the instances of the 'act rel' class, but the nouns in the other two classes seem similar enough to describe all of them with the same type." ></td>
	<td class="line x" title="82:166	generative the lexicon should be and if one allows overgeneration of semantic objects." ></td>
	<td class="line x" title="83:166	.nm rod bluepoint capon clam cockle crawdad crawfish crayfish duckling fowl grub hen lamb langouste limpet lobster monkfish mussel octopus panfish partridge pheasant pigeon poultry prawn pullet quail saki scallop scollop shellfish shrimp snail squid whelk whitebait whitefish winkle act evt rel act rel act rel s~a blend competition flux transformation acceleration communication dealings designation discourse gait glide likening negation neologism neology prevention qualifying sharing synchronisation synchronization synchronizing coordination gradation involvement Figure 7: Instances for the type: act*relation Open Dots The type act.relation describes interpretations that can not be separated from each other (the act and relation aspects are intimately connected)." ></td>
	<td class="line x" title="84:166	The following representation for type -nimalofood describes interpretations that can not occur simultaneously but are however related ~." ></td>
	<td class="line x" title="85:166	It therefore uses a 'o' instead of a ''." ></td>
	<td class="line x" title="86:166	as a type constructor: FORMAL = Q:animalofood CONSTITUTIVE = X:an~mal V Y:food TELIC = Pz :act (Rz,'n|mal) V P2 :act (animal,R2) v P3:act(R3,food) Figure 8: Representation for type: animalofood The instances for this type only cover the class ' ~,m rod'." ></td>
	<td class="line x" title="87:166	A case could be made for including also every instance of the class c~-m' because in principal every animal could be eaten." ></td>
	<td class="line x" title="88:166	This is a question of how 1See the literature on animal grinding, for instance (Copestake and Briscoe, 1992) 29 Figure 9: Instances for the type: animalofood 2.3 Homonyms CORELEX is designed around the idea of systematic polysemons classes that exclude homonyms." ></td>
	<td class="line x" title="89:166	Traditionally a lot of research in lexical semantics has been occupied with the problem of ambiguity in homonyms." ></td>
	<td class="line x" title="90:166	Our research shows however that homonyms only make up a fraction of the whole of the lexicon of a language." ></td>
	<td class="line x" title="91:166	Out of the 37,793 noun stems that were derived from WORDNET 1637 are to be viewed as true homonyms because they have two or more unrelated senses, less than 5%." ></td>
	<td class="line x" title="92:166	The remaining 95% are nouns that do have (an indefinite number of) different interpretations, hut all of these are somehow related and should be inferred from a common knowledge representation." ></td>
	<td class="line x" title="93:166	These numbers suggest a stronger emphasis in research on systematic polysemy and less on homonyms, an approach that is advocated here (see also (Killgariff, 1992))." ></td>
	<td class="line x" title="94:166	In CORZLEX homonyms are simply assigned two or more underspecified semantic types, that need to be disambiguated in a traditional way." ></td>
	<td class="line x" title="95:166	There is however an added value also here because each disambiguated type can generate any number of context dependent interpretations." ></td>
	<td class="line x" title="96:166	3 Adapting CORELEx to Domain Specific Corpora The underspectfied semantic type that CORELEX assigns to a noun provides a basic lexical semantic structure that can be seen as the class-wide backbone semantic description on top of which specific information for each lexical item is to be defined." ></td>
	<td class="line x" title="97:166	That is, doors and gates are both artifacts but they have different appearances." ></td>
	<td class="line x" title="98:166	Gates are typically open constructions, whereas doors tend to be solid." ></td>
	<td class="line x" title="99:166	This kind of information however is corpus specific and therefore needs to be adapted specifically to and on the basis of that particular corpus of texts." ></td>
	<td class="line x" title="100:166	This process involves a number of consecutive steps that includes the probabilistic classification of unknown lexical items: 1." ></td>
	<td class="line x" title="101:166	Assignment of underspecified semantic tags to those nouns that are in CORELEX 2." ></td>
	<td class="line x" title="102:166	Running class-sensitive patterns over the (partly) tagged corpus 3." ></td>
	<td class="line x" title="103:166	(a) Constructing a probabilistic classifier from the data obtained in step 2." ></td>
	<td class="line x" title="104:166	(b) Probabilistically tag nouns that are not in CORELEX according to this classifier 4." ></td>
	<td class="line x" title="105:166	Relating the data obtained in step 2." ></td>
	<td class="line x" title="106:166	to one or more qualia roles Step 1." ></td>
	<td class="line x" title="107:166	is trivial, but steps 2." ></td>
	<td class="line x" title="108:166	through 4." ></td>
	<td class="line x" title="109:166	form a complex process of constructing a corpus specific semantic lexicon that is to be used in additional processing for knowledge intensive reasoning steps (i.e. abduction (Hobbs et al. , 1993)) that would solve metaphoric, metonymic and other non-literal use of language." ></td>
	<td class="line x" title="110:166	3.1 Assignment of CORELEX Tags The first step in analyzing a new corpus involves tagging each noun that is in CORELEX with an underspecified semantic tag." ></td>
	<td class="line x" title="111:166	This tag represents the following information: a definition of the type of the noun (FORMAL); a definition of types of possible nouns it can stand in a part-whole relationship with (CONSTITUTIVE); a definition of types of possible verbs it can occur with and their argument structures (AGENTIVE / TELIC)." ></td>
	<td class="line x" title="112:166	CORELEX is implemented as a database of associative arrays, which allows a fast lookup of this information in pattern matching." ></td>
	<td class="line x" title="113:166	3.2 Class-Sensitive Pattern Matching The pattern matcher runs over corpora that are: part-of-speech tagged using a widely used tagger (Brill, 1992); stemmed by using an experimental system that extends the Porter stemmer, a stemming algorithm widely used in information retrieval, with the Celex database on English morphology; (partly) semantically tagged using the CORELEX set of underspecified semantic tags as discussed in the previous section." ></td>
	<td class="line x" title="114:166	There are about 30 different patterns that are arranged around the headnoun of an NP." ></td>
	<td class="line x" title="115:166	They cover 30 the following syntactic constructions that roughly correspond to a VP, an S, an NP and an NP followed by a PP:  verb-headnoun  headnoun-verb  adjective-headnoun  modiflernoun-headnoun  headnoun-preposition-headnoun The patterns assume NP's of the following generic structure 2: PreDet* Det* Num* (Adj INamelNoun)* Noun The heuristics for finding the headnoun is then simply to take the rightmost noun in the NP, which for English is mostly correct." ></td>
	<td class="line x" title="116:166	The verb-headnoun patterns approach that of a true 'verb-obj' analysis by including a normalization of passive constructions as follows: \[Noun Have?" ></td>
	<td class="line x" title="117:166	Be Adv?" ></td>
	<td class="line x" title="118:166	Verb\] =~ \[Verb Noun\] Similarly, the headnoun-verb patterns approach a true 'sub j-verb' analysis." ></td>
	<td class="line x" title="119:166	However, because no deep syntactic analysis is performed, the patterns can only approximate subjects and Objects in this way and I therefore do not refer to these patterns as 'subject-verb' and 'verb-object' respectively." ></td>
	<td class="line x" title="120:166	The pattern matching is class-sensitive in employing the assigned CORELEX tag to determine if the application of this pattern is appropriate." ></td>
	<td class="line x" title="121:166	For instance, one of the headnoun-preposition-headnoun patterns is the following, that is used to detect partwhole (CONSTITUTIVE) relations: PreDet* Det* Num* (Adj \[ Name \[ Noun)* Noun of PreDet* Det* Num* (Adj \[NameJNoun)* Noun Clearly not every syntactic construction that fits this pattern is to be interpreted as the expression of a part-whole relation." ></td>
	<td class="line x" title="122:166	One of the heuristics we therefore use is that the pattern may only apply if both head nouns carry the same CORELEx tag or if the tag of the second head noun subsumes the tag of the first one through a dotted type." ></td>
	<td class="line x" title="123:166	That is, if the second head noun is of a dotted type and the first is of one of its composing types." ></td>
	<td class="line x" title="124:166	For instance, 'paragraph' ~The interpretation of '*' and ''?" ></td>
	<td class="line x" title="125:166	in this section follows that of common usage in regular expressions: 'w indicates 0 or more occurrences; ''?" ></td>
	<td class="line x" title="126:166	indicates 0 or 1 occurrence and 'journal' can be in a part-whole relation to each other because the first is of type information, while the second is of type information*physical." ></td>
	<td class="line x" title="127:166	Similar heuristics can be identified for the application of other patterns." ></td>
	<td class="line x" title="128:166	Recall of the patterns (percentage of nouns that are covered) is on average, among different corpora (wsJ, BROWN, PDGF a corpus we constructed for independent purposes from 1000 medical abstracts in the MEDLINE database on Platelet Derived Growth Factor and DARWIN the complete Origin of Species), about 70% to 80%." ></td>
	<td class="line x" title="129:166	Precision is much harder to measure, but depends both on the accuracy of the output of the part-of-speech tagger and on the accuracy of class-sensitive heuristics." ></td>
	<td class="line x" title="130:166	3.3 Probabilistic Classification The knowledge about the linguistic context of nouns in the corpus that is collected by the pattern matcher is now used to classify unknown nouns." ></td>
	<td class="line x" title="131:166	This involves a similarity measure between the linguistic contexts of classes of nouns that are in CORELEX and the linguistic context of unknown nouns." ></td>
	<td class="line x" title="132:166	For this purpose the pattern matcher keeps two separate arrays, one that collects knowledge only on COrtELEx nouns and the other collecting knowledge on all nouns." ></td>
	<td class="line x" title="133:166	The classifier uses mutual information (MI) scores rather than the raw frequences of the occurring patterns (Church and Hanks, 1990)." ></td>
	<td class="line x" title="134:166	Computing MI scores is by now a standard procedure for measuring the co-occurrence between objects relative to their overall occurrence." ></td>
	<td class="line oc" title="135:166	MI is defined in general as follows: y) I ix y) = log2 P(x) P(y) We can use this definition to derive an estimate of the connectedness between words, in terms of collocations (Smadja, 1993), but also in terms of phrases and grammatical relations (Hindle, 1990)." ></td>
	<td class="line x" title="136:166	For instance the co-occurrence of verbs and the heads of their NP objects iN: size of the corpus, i.e. the number of stems): N Cobj (v n) = log2 /(v) /(n) N N All nouns are now classified by running a similaxity measure over their MI scores and the MI scores of each CoRELEx class." ></td>
	<td class="line x" title="137:166	For this we use the Jaccard measure that compares objects relative to the attributes they share (Grefenstette, 1994)." ></td>
	<td class="line x" title="138:166	In our case the 'attributes' are the different linguistic constructions a noun occurs in: headnoun-verb, adjective-headnoun, modifiernoun-headnoun, etc. The Jaccard measure is defined as the number of attributes shared by two objects divided by the total number of unique attributes shared by both objects: A A+B+C A : attributes shared by both objects B : attributes unique to object 1 C : attributes unique to object 2 The Jaccard scores for each CORELEx class are sorted and the class with the highest score is assigned to the noun." ></td>
	<td class="line x" title="139:166	If the highest score is equal to 0, no class is assigned." ></td>
	<td class="line x" title="140:166	The classification process is evaluated in terms of precision and recall figures, but not directly on the classified unknown nouns, because their precision is hard to measure." ></td>
	<td class="line x" title="141:166	Rather we compute precision and recall on the classification of those nouns that are in CoreLex, because we can check their class automatically." ></td>
	<td class="line x" title="142:166	The assumption then is that the precision and recall figures for the classification of nouns that are known correspond to those that are unknown." ></td>
	<td class="line x" title="143:166	An additional measure of the effectiveness of the classifter is measuring the recall on classification of all nouns, known and unknown." ></td>
	<td class="line x" title="144:166	This number seems to correlate with the size of the corpus, in larger corpora more nouns are being classified, but not necessarily more correctly." ></td>
	<td class="line x" title="145:166	Correct classification rather seems to depend on the homogeneity of the corpus: if it is written in one style, with one theme and so on." ></td>
	<td class="line x" title="146:166	Recall of the classifier (percentage of all nouns that are classified > 0) is on average, among different larger corpora (> 100,000 tokens), about 80% to 90%." ></td>
	<td class="line x" title="147:166	Recall on the nouns in CoRELEx is between 35% and 55%, while precision is between 20% and 40%." ></td>
	<td class="line x" title="148:166	The last number is much better on smaller corpora (70% on average)." ></td>
	<td class="line x" title="149:166	More detailed information about the performance of the classifier, matcher and acquisition tool (see below) can be obtained from (Buitelaar, forthcoming)." ></td>
	<td class="line x" title="150:166	3.4 Lexical Knowledge Acquisition The final step in the process of adapting CORELEx to a specific domain involves the 'translation' of observed syntactic patterns into corresponding semantic ones and generating a semantic lexicon representing that information." ></td>
	<td class="line x" title="151:166	31 There are basically three kinds of semantic patterns that are utilized in a CORELEX lexicon: hyponymy (sub-supertype information) in the FORMAL role, meronymy (part-whole information) in the CONSTITUTIVE role and predicate-argument structure in the TELIC and AGENTIVE roles." ></td>
	<td class="line x" title="152:166	There are no compelling reasons to exclude other kinds of information, but for now we base our basic design on ~, which only includes these three in its definition of qualia structure." ></td>
	<td class="line x" title="153:166	Hyponymic information is acquired through the classification process discussed in Sections 2.2 and 3.3." ></td>
	<td class="line x" title="154:166	Meronymic information is obtained through a translation of various VP and PP patterns into 'has-part' and 'part-of' relations." ></td>
	<td class="line x" title="155:166	Predicate-argument structure finally, is derived from verb-headnoun and headnoun-verb constructions." ></td>
	<td class="line x" title="156:166	The semantic lexicon that is generated in such a way comes in two formats: T2), a Type Description Language based on typed feature-logic (Krieger and Schaefer, 1994a) (Krieger and Schaefer, 1994b) and HTML, the markup language for the World Wide Web." ></td>
	<td class="line x" title="157:166	The first provides a constraintbased formalism that allows CORELEX lexicons to be used stralghtforwardiy in constraint-based grammars." ></td>
	<td class="line x" title="158:166	The second format is used to present a generated semantic lexicon as a semantic index on a World Wide Web document." ></td>
	<td class="line x" title="159:166	We will not elaborate on this further because the subject of semantic indexing is out of the scope of this paper, but we refer to (Pustejovsky et al. , 1997)." ></td>
	<td class="line x" title="160:166	3.5 An Example: The PDGF Lexicon The semantic lexicon we generated for the PDGF corpus covers 1830 noun stems, spread over 81 CORELEX types." ></td>
	<td class="line x" title="161:166	For instance, the noun evidence is of type communication.psychological and the following representation is generated: 4 Conclusion In this paper I discuss the construction of a new type of semantic lexicon that supports underspecifled semantic tagging." ></td>
	<td class="line x" title="162:166	Traditional semantic tagging assumes a number of distinct senses for each lexical item between which the system should choose." ></td>
	<td class="line x" title="163:166	Underspecified semantic tagging however assumes no finite lists of senses, but instead tags each lexical item with a comprehensive knowledge representation from which a specific interpretation can be constructed." ></td>
	<td class="line x" title="164:166	CORZLEx provides such knowledge representations, and as such it is fundamentally different from existing semantic lexicons like WORDNET." ></td>
	<td class="line x" title="165:166	32 'evidence FORMAL '= \[ARG1 = commlmlcation\]\] CLOSED LARG2 psychological J J CONSTITUTIVE -~ I HAS-PAI~ ----TELIC = ip ov,.e \] FIRST L ARG-STRUCT ---~  REST ---.o. FIRST = structure\] 1 REST  Figure 10: Lexical entry for: evidence Additionally, it was shown that CoI~LEx provides for more consistent assignments of lexical semantic structure among classes of lexical items." ></td>
	<td class="line x" title="166:166	Finally, the approach described above allows one to generate domain specific semantic lexicons by enhancing CORELEX lexical entries with corpus based information." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W97-0803
Extending A Thesaurus By Classifying Words
Tokunaga, Takenobu;Fujii, Atsushi;Naoyuki, Sakurai;Tanaka, Hozumi;"></td>
	<td class="line x" title="1:222	Extending a thesaurus by classifying words Tokunaga Takenobu Fujii Atsushi Sakurai Naoyuki Tanaka Hozumi Department of Computer Science Tokyo Institute of Technology take~cs, tit ech." ></td>
	<td class="line x" title="2:222	ac." ></td>
	<td class="line x" title="3:222	jp Iwayama Makoto Advanced Research Lab." ></td>
	<td class="line x" title="4:222	Hitachi Ltd. Abstract This paper proposes a method for extending an existing thesaurus through classification of new words in terms of that thesaurus." ></td>
	<td class="line x" title="5:222	New words are classified on the basis of relative probabilities of.a word belonging to a given word class, with the probabilities calculated using nounverb co-occurrence pairs." ></td>
	<td class="line x" title="6:222	Experiments using the Japanese Bunruigoihy5 thesaurus on about 420,000 co-occurrences showed that new words can be classified correctly with a maximum accuracy of more than 80%." ></td>
	<td class="line x" title="7:222	1 Introduction For most natural language processing (NLP) systems, thesauri comprise indispensable linguistic knowledge." ></td>
	<td class="line x" title="8:222	Roger's International Thesaurus \[Chapman, 1984\] and WordNet \[Miller et al. , 1993\] are typical English thesauri which have been widely used in past NLP research \[Resnik, 1992; Yarowsky, 1992\]." ></td>
	<td class="line x" title="9:222	They are handcrafted, machine-readable and have fairly broad coverage." ></td>
	<td class="line x" title="10:222	However, since these thesauri were originally compiled for human use, they are not always suitable for computer-based natural language processing." ></td>
	<td class="line oc" title="11:222	Limitations of handcrafted thesauri can be summarized as follows \[Hatzivassiloglou and McKeown, 1993; Uramoto, 1996; Hindle, 1990\]." ></td>
	<td class="line x" title="12:222	 limited vocabulary size  unclear classification criteria  building thesauri by hand requires considerable time and effort The vocabulary size of typical handcrafted thesauri ranges from 50,000 to 100,000 words, including general words in broad domains." ></td>
	<td class="line x" title="13:222	From the viewpoint of NLP systems dealing with a particular domain, however, these thesauri include many unnecessary (general) words and do not include necessary domain-specific words." ></td>
	<td class="line x" title="14:222	The second problem with handcrafted thesauri is that their classification is based on the intuition of lexicographers, with their classification criteria not always being clear." ></td>
	<td class="line x" title="15:222	For the purposes of NLP systems, their classification of words is sometimes too coarse and does not provide sufficient distinction between words, or is some times unnecessarily detailed." ></td>
	<td class="line x" title="16:222	Lastly, building thesauri by hand requires significant amounts of time and effort even for restricted domains." ></td>
	<td class="line x" title="17:222	Furthermore, this effort is repeated when a system is ported to another domain." ></td>
	<td class="line oc" title="18:222	This criticism leads us to automatic approaches for building thesauri from large corpora \[Hirschman et al. , 1975; Hindle, 1990; Hatzivassiloglou and McKeown, 1993; Pereira et al. , 1993; Tokunaga et aL, 1995; Ushioda, 1996\]." ></td>
	<td class="line x" title="19:222	Past attempts have basically taken the following steps \[Charniak, 1993\]." ></td>
	<td class="line x" title="20:222	(1) extract word co-occurrences (2) define similarities (distances) between words on the basis of co-occurrences (3) cluster words on the basis of similarities The most crucial part of this approach is gathering word co-occurrence data." ></td>
	<td class="line x" title="21:222	Co-occurrences are usually gathered on the basis of certain relations such as predicateargument, modifier-modified, adjacency, or mixture of these." ></td>
	<td class="line x" title="22:222	However, it is very difficult to gather sufficient co-occurrences to calculate similarities reliably \[Resnik, 1992; Basili et al. , 1992\]." ></td>
	<td class="line x" title="23:222	It is sometimes impractical to build a large thesaurus from scratch based on only co-occurrence data." ></td>
	<td class="line x" title="24:222	Based on this observation, a third approach has been proposed, namely, combining linguistic knowledge and co-occurrence data \[Resnik, 1992; Uramoto, 1996\]." ></td>
	<td class="line x" title="25:222	This approach aims at compensating the sparseness of co~ occurrence data by using existing linguistic knowledge, such as WordNet." ></td>
	<td class="line x" title="26:222	This paper follows this line of research and proposes a method to extend an existing thesaurus by classifying new words in terms of that thesaurus." ></td>
	<td class="line x" title="27:222	In other words, the proposed method identifies appropriate 16 word classes of the thesaurus for a new word which is not included in the thesaurus." ></td>
	<td class="line x" title="28:222	This search process is facilitated based on the probability that a word belongs to a given word class." ></td>
	<td class="line x" title="29:222	The probability is calculated based on word co'occurrences." ></td>
	<td class="line x" title="30:222	As such, this method could also suffer from the data sparseness problem." ></td>
	<td class="line x" title="31:222	As Resnik pointed out, however, using the thesaurus structure (classes) can remedy this problem \[Resnik, 1992\]." ></td>
	<td class="line x" title="32:222	2 Core thesaurus Bunruigoihy$ (BGH for short) \[Hayashi, 1966\] is a typical Japanese thesaurus, which has been used for much NLP research on Japanese." ></td>
	<td class="line x" title="33:222	BGH includes 87,743 words, each of which is assigned an 8 digit class code." ></td>
	<td class="line x" title="34:222	Some words are assigned more than one class code." ></td>
	<td class="line x" title="35:222	The coding system of BGH has a hierarchical structure, that is, the first digit represents the part(s) of speech of the word (1: noun, 2:verb, 3: adjective, 4: others), and the second digit classifies words sharing the same first digit and so on." ></td>
	<td class="line x" title="36:222	Thus BGH can be considered as four trees, each of which has 8 levels in depth (see figure 1), with each leaf as a set of words." ></td>
	<td class="line x" title="37:222	1 2 3 4.1.1~rb) (a~) (otheO 11 12 13 14 15 ! | ! |~ /fif~xx ~." ></td>
	<td class="line x" title="38:222	158 8levels ! 1500  1509 15000  15004 150040  150049 words words Fig." ></td>
	<td class="line x" title="39:222	1 Structure of Bunruigoihy6 (BGH) This paper focuses on classifying only nouns in terms of a class code based on the first 5 digits, namely, up to the fifth level of the noun tree." ></td>
	<td class="line x" title="40:222	Table 1 shows the number of words (#words) and the number of 5 digit class codes (#classes) with respect to each part of speech." ></td>
	<td class="line x" title="41:222	Table 1 Outline of Bunruigoihy3 (BGH) POS noun I verb adj other total #words 55,443 i 21,669 9,890 741 87,743 ~classes 544 165 190 24 842 3 Co-occurrence data Appropriate word classes for a new word are identified based on the probability that the word belongs to different word classes." ></td>
	<td class="line x" title="42:222	This probability is calculated based on co-occurrences of nouns and verbs." ></td>
	<td class="line x" title="43:222	The cooccurrences were extracted from the RWC text base RWC-DB-TEXT-95-1 \[Real World Computing Partnership, 1995\]." ></td>
	<td class="line x" title="44:222	This text base consists of 4 years worth of Mainiti Shimbun \[Mainichi Shimbun, 1991-1994\] newspaper articles, which have been automatically annotated with morphological tags." ></td>
	<td class="line x" title="45:222	The total number of morphemes is about 100 million." ></td>
	<td class="line x" title="46:222	Instead of conducting full parsing on the texts, several heuristics were used in order to obtain dependencies between nouns and verbs in the form of tuples (frequency, noun, postposition, verb)." ></td>
	<td class="line x" title="47:222	Among these tuples, only those which include the postposition 'WO' (typically marking accusative case) were used." ></td>
	<td class="line x" title="48:222	Further, tuples containing nouns in BGH were selected." ></td>
	<td class="line x" title="49:222	In the case of a compound noun, the noun was transformed into the maximal leftmost string contained in BGH 1." ></td>
	<td class="line x" title="50:222	As a result, 419,132 tuples remained including 23,223 noun types and 9,151 verb types." ></td>
	<td class="line x" title="51:222	These were used in the experiments described in section 5." ></td>
	<td class="line x" title="52:222	4 Identifying appropriate word classes 4.1 Probabilistic model The probabilistic model used in this paper is the SVMV model \[Iwayama and Tokunaga, 1994\]." ></td>
	<td class="line x" title="53:222	This model was originally developed for document categorization, in which a new document is classified into certain predefined categories." ></td>
	<td class="line x" title="54:222	For the purposes of this paper, a new word (noun) not appearing in the thesaurus is treated as a new document, and a word class in the thesaurus corresponds to a predefined document category." ></td>
	<td class="line x" title="55:222	Each noun is represented by a set of verbs co-occurring with that noun." ></td>
	<td class="line x" title="56:222	The probability P(c, Iw) is calculated for each word class c,, and the proper classes for a word w are determined based on it." ></td>
	<td class="line x" title="57:222	The SVMV model formalizes the probability P(clw ) as follows." ></td>
	<td class="line x" title="58:222	Conditioning P(clw ) on each possible event gives P(clw) = ~ P(clw, V = v,)P(V = v, lw)." ></td>
	<td class="line x" title="59:222	(1) O, Assuming conditional independence between c and V = v, given w, that is P(clw, V = %) = P(clV = v,), we obtain P(clw) = Z P(c\]V = vOP(V = %\[w)." ></td>
	<td class="line x" title="60:222	(2) Using Bayes' theorem, this becomes P(clw ) = P(c) E P(V = v, lc)P(V = v, lw) ~, P(V = v,) (3) All the probabilities in (3) can be estimated from training data based on the following equations." ></td>
	<td class="line x" title="61:222	In the following, fr(w, v) denotes the frequency that a noun w and a verb v are co-occurring." ></td>
	<td class="line x" title="62:222	1For Japanese compound noun, the final word tends to be a semantic head." ></td>
	<td class="line x" title="63:222	17 P(V = v~lc ) is the probability that a randomly extracted verb co-occurring with a noun is v~, given that the noun belongs to word class c. This is estimated from the relative frequency of v~ co-occurring with the nouns in word class c, namely, E eo/r(w,v,) (4) P(v =,lc) = E, Ewe P(V = v, lw ) is the probability that a randomly extracted verb co-occurring with a noun w is vs. This is estimated from the relative frequency of v, co-occurring with noun w, namely, P(V = = (5) P(V = v,) is the prior probability that a randomly extracted verb co-occurring with a randomly selected noun is v~." ></td>
	<td class="line x" title="64:222	This is estimated from the relative frequency of v~ in the whole training data, namely, (6) P(v P(c) is the prior probability that a randomly selected noun belongs to c. This is estimated from the relative frequency of a verb co-occurring with any noun in class c 2, namely, P(c) = EwEoE Eo E eo (7) 4.2 Searching through the thesaurus As is documented by the fact that we employ the probabilistic model used in document categorization, classifying words in a thesaurus is basically the same as document categorization 3." ></td>
	<td class="line x" title="65:222	Document categorization strategies can be summarized according to the following three types \[Iwayama and Tokunaga, 1995\]." ></td>
	<td class="line x" title="66:222	 the k-nearest neighbor (k-nn) or Memory based reasoning (MBR) approach  the category-based approach  the cluster-based approach The k-nn approach searches for the k documents most similar to a target document in training data, and assigns that category with the highest distribution in the k documents \[Weiss and Kulikowski, 1991\]." ></td>
	<td class="line x" title="67:222	Although the 2This calculation seems be counterintuitive." ></td>
	<td class="line x" title="68:222	A more straightforward calculation would be one based on the relative frequency of words belonging to class c. However, the given estimation is necessary in order to normalize the sum of the probabilities P(clw ) to one." ></td>
	<td class="line x" title="69:222	3As Uramoto mentioned, this task is also similar to word sense disambiguation except for the size of search space \[Uramoto, 1996\]." ></td>
	<td class="line x" title="70:222	k-nn approach has been promising for document categorization \[Masand et al. , 1992\], it requires significant computational resources to calculate the similarity between a target document and every document in training data." ></td>
	<td class="line x" title="71:222	In order to overcome the drawback of the k-nn approach, the category-based approach first makes a cluster for each category consisting of documents assigned the same category, then calculates the similarity between a target document and each of these document clusters." ></td>
	<td class="line x" title="72:222	The number of similarity calculations can be reduced to the number of clusters (categories), saving on computational resources." ></td>
	<td class="line x" title="73:222	Another alternative is the cluster-based approach, which first constructs clusters from training data by using some clustering algorithm, then calculates similarities between a target document and those clusters." ></td>
	<td class="line x" title="74:222	The main difference between category-based and clusterbased approaches resides in the cluster construction." ></td>
	<td class="line x" title="75:222	The former uses categories which have been assigned to documents when constructing clusters, while the latter does not." ></td>
	<td class="line x" title="76:222	In addition, clusters are structured in a tree when a hierarchical clustering algorithm is used for the latter approach." ></td>
	<td class="line x" title="77:222	In this case, one can adopt a top-down tree search strategy for similar clusters, saving further computational overhead." ></td>
	<td class="line x" title="78:222	In this paper, all these approaches are evaluated for word classification, in which a target document corresponds to a target word and a document category corresponds to a thesaurus class code." ></td>
	<td class="line x" title="79:222	5 Experiments In our experiments, the 23,223 nouns described in section 3 were classified in terms of the core thesaurus, BGH, using the three search strategies described in the previous section." ></td>
	<td class="line x" title="80:222	Classification was conducted for each strategy as follows." ></td>
	<td class="line x" title="81:222	k-nn Each noun is considered as a singleton cluster, and the probability that a target noun is classified into each of the non-target noun clusters is calculated." ></td>
	<td class="line x" title="82:222	category-based 10-fold cross validation was conducted for the category-based and cluster-based strategies, in that, 23,223 nouns were randomly divided into 10 groups, and one group of nouns was used for test data while the rest was used for training." ></td>
	<td class="line x" title="83:222	The test group was rotated 10 times, and therefore, all nouns were used as a test case." ></td>
	<td class="line x" title="84:222	The results were averaged over these 10 trials." ></td>
	<td class="line x" title="85:222	Each noun in the training data was categorized according to its BGH 5 digit class code, generating 544 category clusters (see Table 1)." ></td>
	<td class="line x" title="86:222	The probability of each noun in the test data being classified into each of these 544 cluster was calculated." ></td>
	<td class="line x" title="87:222	cluster-based In the case of the category-based approach, each noun in the training data was categorized into the leaf clusters of the BGH tree, that is, 18 the 5 digit class categories 4." ></td>
	<td class="line x" title="88:222	For the cluster-based approach, the nouns were also categorized into the intermediate class categories, that is, the 2 to 4 digit class categories." ></td>
	<td class="line x" title="89:222	Since we use the BGH hierarchy structure instead of constructing a duster hierarchy from scratch, in a strict sense, this does not coincide with the cluster-based approach as described in the previous section." ></td>
	<td class="line x" title="90:222	However, searching through the BGH tree structure in a top down manner still enables us to save greatly on computational resources." ></td>
	<td class="line x" title="91:222	A simple top down search, in which the cluster with the highest probability is followed at each level, allows only one path leading to a single leaf (5 digit class code)." ></td>
	<td class="line x" title="92:222	In order to take into account multiple word senses, we followed several paths at the same time." ></td>
	<td class="line x" title="93:222	More precisely, the difference between the probability of each cluster and the highest probability value for that level was calculated, and clusters for which the difference was within a certain threshold were left as candidate paths." ></td>
	<td class="line x" title="94:222	The threshold was set to 0.2 in this experiments." ></td>
	<td class="line x" title="95:222	The performance of each approach was evaluated on the basis of the number of correctly assigned class codes." ></td>
	<td class="line x" title="96:222	Tables 2 to 4 show the results of each approach." ></td>
	<td class="line x" title="97:222	Columns show the maximum number of class codes assigned to each target word." ></td>
	<td class="line x" title="98:222	For example, the column '10' means that a target word is assigned to up to 10 class codes." ></td>
	<td class="line x" title="99:222	If the correct class code is contained in these assigned codes, the test case is considered to be assigned the correct code." ></td>
	<td class="line x" title="100:222	Rows show the distribution word numbers on the basis of occurrence frequencies in the training data." ></td>
	<td class="line x" title="101:222	Each value in the table is the number of correct cases with its percentage in the parentheses." ></td>
	<td class="line x" title="102:222	Table 2 Results for the k-nn approach freq\k 5 I0 20 30 total,.~ 10 1,733 2,581 3,934 4,902 12,719 (13.6) (20.3) (30.9) (38.5) 10 N 1,817 2,638 3,594 4,231 7,550 100 (24.1) (34.9) (47.6) (56.0) 100,,~ 658 949 1,260 1,455 2,208 500 (29.8) (43.0) (57.1) (65.9) 500 N 132 199 254 300 401 1000 (32.9) (49.6) (63.3) (74.8) 1000 ~ 149 187 236 264 345 (43.2) (54.2) (68.4) (76.5) total 4,489 6,554 9,278 11,152 23,223 (19.3) (28.2) (40.0) (48.0) 4Note that we ignore lower digits, and therefore, lea\] means the categories formed by 5 digit class code." ></td>
	<td class="line x" title="103:222	Table 3 Results for the category-based approach ~eq\k,,~ I0 I0 I00 100,.~ 500 500 i000 1000 total 5 10 20 30 total 2,304 3,442 4,778 5,689 12,719 (18.1) (27.1) (37.6) (44.7) 2,527 3,458 4,449 5,025 7,550 (33.5) (45.8) (58.9) (66.6) 922 1,231 1,511 1,657 2,208 (41.8) (55 8) (68.4) (75.0) 204 250 298 327 (50.9) (62.3) (74.3) (81.5) 181 231 264 289 (52.5) (67.0) (76.5) (83.8) 401 345 6,138 8,612 11,300 12,987 23,223 (26.4) (37.1) (48.7) (55.9) Table 4 Results for the cluster-based approach ~eq\k 10 10 N 100 100 N 500 500 N 1000 1000,.~ 5 10 20 30 total 1,982 2,534 3,026 3,240 12,719 (15.6) (19.9) (23.8) (25.5) 2,385 3,011 3,490 3,690 7,550 (31.6) (39.9) (46.2)(48.9) 8877 1,077 1,205 1,264 2,208 (40.2) (48.8) (54.6) (57.2) 201 227 251 259 (50.1) (56.6)(62.6) (64.6) 401 183 209 231 239 (53.0) (60.6) (67.0) (69.3) 345 total 5,638 7,058 8,203 8,692 23,223 (24.3) (30.4) (35.3) (37.4) 6 Discussion Overall, the category-based approach shows the best performance, followed by the cluster-based approach, k-nn shows the worst performance." ></td>
	<td class="line x" title="104:222	This result contradicts past research \[Iwayama and Tokunaga, 1995; Masand et al. , 1992\]." ></td>
	<td class="line x" title="105:222	One possible explanation for this contradiction may be that the basis of the classification for BGH and our probabilistic model is very different." ></td>
	<td class="line x" title="106:222	In other words, co-occurrences with verbs may not have captured the classification basis of BGH very well." ></td>
	<td class="line x" title="107:222	The performance of k-nn is noticeably worse than that of the others for low frequent words." ></td>
	<td class="line x" title="108:222	This may be due to data sparseness." ></td>
	<td class="line x" title="109:222	Generalizing individual nouns by constructing clusters remedies this problem." ></td>
	<td class="line x" title="110:222	When b is small, namely only categories with high probabilities are assigned, the category-based and duster-based approaches show comparable performance." ></td>
	<td class="line x" title="111:222	When k becomes bigger, however, the category-based approach becomes superior." ></td>
	<td class="line x" title="112:222	Since a beam search was adopted for the cluster-based approach, there was a possibility of falling to follow the correct path." ></td>
	<td class="line x" title="113:222	7 Related work The goal of this paper is the same as that for Uramoto \[Uramoto, 1996\], that is, identifying appropriate word classes for an unknown word in terms of an existing thesaurus." ></td>
	<td class="line x" title="114:222	The significant difference between Uramoto and our research can be summarized as follows." ></td>
	<td class="line x" title="115:222	19  The core thesaurus is different." ></td>
	<td class="line x" title="116:222	Uramoto used ISAMAP \[Tanaka and Nisina, 1987\], which contains about 4,000 words." ></td>
	<td class="line x" title="117:222	 We adopted a probabilistic model, which has a sounder foundation than the Uramoto's." ></td>
	<td class="line x" title="118:222	He used several factors, such as similarity between a target word and words in each classes, class levels and so forth." ></td>
	<td class="line x" title="119:222	These factors are combined into a score by calculating their weighted sum." ></td>
	<td class="line x" title="120:222	The weight for each factor is determined by using held out data." ></td>
	<td class="line x" title="121:222	 We restricted our co-occurrence data to that included the 'WO' postposition, which typically marks the accusative case, while Uramoto used several grammatical relations in tandem." ></td>
	<td class="line x" title="122:222	There are claims that words behave differently depending on their grammatical role, and that they should therefore be classified into different word classes when the role is different \[Tokunaga et al. , 1995\]." ></td>
	<td class="line x" title="123:222	This viewpoint should be taken into account when we construct a thesaurus from scratch." ></td>
	<td class="line x" title="124:222	In our case, however, since we assume a core thesaurus, there is room for argument as to whether we should consider this claim." ></td>
	<td class="line x" title="125:222	Further investigation on this point is needed." ></td>
	<td class="line x" title="126:222	 Our evaluation scheme is more rigid and based on a larger dataset." ></td>
	<td class="line x" title="127:222	We conducted cross validation on nouns appearing in BGH and the judgement of correctness was done automatically, while Uramoto used unknown words as test cases and decided the correctness on a subjective basis." ></td>
	<td class="line x" title="128:222	The number of his test cases was 250, ours is 23223." ></td>
	<td class="line x" title="129:222	The performance of his method was reported to be from 65% to 85% in accuracy, which seems better than ours." ></td>
	<td class="line x" title="130:222	However, it is difficult to compare these two in an absolute sense, because both the evaluation data and code assignment scheme are different." ></td>
	<td class="line x" title="131:222	We identified class codes at the fifth level of BGH, while Uramoto searched for a set of class codes at various levels." ></td>
	<td class="line x" title="132:222	Nakano proposed a method of assigning a BGH class code to new words \[Nakano, 1981\]." ></td>
	<td class="line x" title="133:222	His approach is very different from ours and Uramoto's." ></td>
	<td class="line x" title="134:222	He utilized characteristics of Japanese character classes." ></td>
	<td class="line x" title="135:222	There are three character classes used in writing Japanese, Kanzi, Hiragana and Katakana." ></td>
	<td class="line x" title="136:222	A Kanzi character is an ideogram and has a distinct stand-alone meaning, to a certain extent." ></td>
	<td class="line x" title="137:222	On the other hand, Hiragana and Katakana characters are phonograms." ></td>
	<td class="line x" title="138:222	Nakano first constructed a Kanzi meaning dictionary from BGH by extracting words including a single Kanzi character." ></td>
	<td class="line x" title="139:222	He defined the class code of each Kanzi character to the code of words including only that Kanzi." ></td>
	<td class="line x" title="140:222	He then assigned class codes to new words based on this Kanzi meaning dictionary." ></td>
	<td class="line x" title="141:222	For example, if the class codes of Kanzi Ks and K s are ~1, c~2} and {c31, c32, c~3} respectively, then a word including K, and K~ is assigned the codes {Ctl,Cs2,C31,C32,C33 }." ></td>
	<td class="line x" title="142:222	We applied Nakano's method on the data used in section 55, obtaining the accuracy of 54.6% for 17,736 words." ></td>
	<td class="line x" title="143:222	The average number of codes assigned was 5.75." ></td>
	<td class="line x" title="144:222	His method has several advantages over ours, such as:  no co-occurrence data is required,  not so much computational overhead is required." ></td>
	<td class="line x" title="145:222	However, there are obvious limitations, such as:  it can not handle words not including Kanzi,  ranking or preference of assigned codes is not obtained,  not applicable to languages other than Japanese." ></td>
	<td class="line x" title="146:222	We investigated the overlap of words that were assigned correct classes for our category-based method and Nakano's method." ></td>
	<td class="line x" title="147:222	The parameter k was set to 30 for our method." ></td>
	<td class="line x" title="148:222	The number of words that were assigned correct classes by both methods was 5,995, which represents 46% of the words correctly classified by our method and 62% of the words correctly classified by Nakano's method." ></td>
	<td class="line x" title="149:222	In other words, of the words correctly classifted by one method, only about half can also be also classified correctly by the other method." ></td>
	<td class="line x" title="150:222	This result suggests that these two methods are complementary to each other, rather than competitive, and that the overall performance can be improved by combining them." ></td>
	<td class="line x" title="151:222	8 Conclusion This paper proposed a method for extending an existing thesaurus by classifying new words in terms of that thesaurus." ></td>
	<td class="line x" title="152:222	We conducted experiments using the Japanese Bunruigoihy5 thesaurus and about 420,000 cooccurrence pairs of verbs and nouns, related by the WO postposition." ></td>
	<td class="line x" title="153:222	Our experiments showed that new words can be classified correctly with a maximum accuracy of more than 80% when the category-based search strategy was used." ></td>
	<td class="line x" title="154:222	We only used co-occurrence data including the WO relation (accusative case)." ></td>
	<td class="line x" title="155:222	However, as mentioned in comparison with Uramoto's work, the use of other relations should be investigated." ></td>
	<td class="line x" title="156:222	This paper focused on only 5 digit class codes." ></td>
	<td class="line x" title="157:222	This is mainly because of the data sparseness of co-occurrence data." ></td>
	<td class="line x" title="158:222	We would be able to classify words at deeper levels if we obtained more co-occurrence data." ></td>
	<td class="line x" title="159:222	Another approach would be to construct a hierarchy from a set of words of each class, using a clustering algorithm." ></td>
	<td class="line x" title="160:222	5Nakano's original work used an old version of BGH, which contains 36,263 words." ></td>
	<td class="line x" title="161:222	20 References \[Basili et al. , 1992\] Basili, R. , Pazienza, M. , and Velardi, P. Computational lexicons: The neat examples and the odd exemplars." ></td>
	<td class="line x" title="162:222	In Proceedings of third conference on Applied Natural Language Processing, pp." ></td>
	<td class="line x" title="163:222	96--103." ></td>
	<td class="line x" title="164:222	\[Chapman, 1984\] Chapman, L. R. Roger's International Thesaurus (Fourth Edition)." ></td>
	<td class="line x" title="165:222	Harper & Row." ></td>
	<td class="line x" title="166:222	\[Charniak, 1993\] Charniak, E. Statistical Language Learning." ></td>
	<td class="line x" title="167:222	MIT Press." ></td>
	<td class="line x" title="168:222	\[Hatzivassiloglou and McKeown, 1993\] Hatzivassiloglou, V. , and McKeown, K. R. Towards the automatic identification of adjectival scales: Clustering adjectives according to meaning." ></td>
	<td class="line x" title="169:222	In Proceedings of 31st Annual Meeting of the Association for Computational Linguistics, pp." ></td>
	<td class="line x" title="170:222	172-182." ></td>
	<td class="line x" title="171:222	\[Hayashi, 1966\] Hayashi, O. Bunruigoihy& Syueisyuppan." ></td>
	<td class="line x" title="172:222	(In Japanese)." ></td>
	<td class="line oc" title="173:222	\[Hindle, 1990\] Hindle, D. Noun classification from predicate-argument structures." ></td>
	<td class="line x" title="174:222	In Proceedings of 28th Annual Meeting of the Association for Computational Linguistics, pp." ></td>
	<td class="line x" title="175:222	268-275." ></td>
	<td class="line x" title="176:222	\[Hirschman et al. , 1975\] Hirschman, L. , Grishman, R. , and Sager, N. Grammatically-based automatic word class formation." ></td>
	<td class="line x" title="177:222	Information Processing 8I Management, 11, 39-57." ></td>
	<td class="line x" title="178:222	\[Iwayama and Tokunaga, 1994\] Iwayama, M. , and Tokunaga, T. A probabilistic model for text categorization: Based on a single random variable with multiple values." ></td>
	<td class="line x" title="179:222	In Proceedings of 4th Conference on Applied Natural Language Processing." ></td>
	<td class="line x" title="180:222	\[Iwayama and Tokunaga, 1995\] Iwayama, M. , and Tokunaga, T. Cluster-based text categorization: A comparison of category search strategies." ></td>
	<td class="line x" title="181:222	In Proceedings of A CM SIGIR'95, pp." ></td>
	<td class="line x" title="182:222	273-280." ></td>
	<td class="line x" title="183:222	\[Masand et aL 1992\] Masand, B. , Linoff, G. , and Waltz, D. Classifying news stories using memory based reasoning." ></td>
	<td class="line x" title="184:222	In Proceedings of ACM SIGIR '9~, pp." ></td>
	<td class="line x" title="185:222	59-65." ></td>
	<td class="line x" title="186:222	\[Miller et al. , 1993\] Miller, G. A., Bechwith, R. , Fellbaum, C. , Gross, D. , Miller, K. , and Tengi, R. Five Papers on WordNet." ></td>
	<td class="line x" title="187:222	Tech." ></td>
	<td class="line x" title="188:222	rep. CSL Report 43, Cognitive Science Laboratory, Princeton University." ></td>
	<td class="line x" title="189:222	Revised version." ></td>
	<td class="line x" title="190:222	\[Nakano, 1981\] Nakano, H. Word classification support system." ></td>
	<td class="line x" title="191:222	IPSJ-SIGCL, 25." ></td>
	<td class="line x" title="192:222	\[Pereira et al. , 1993\] Pereira, F. , Tishby, N. , and Lee, L. Distributional clustering of English words." ></td>
	<td class="line x" title="193:222	In Proceedings of 31st Annual Meeting of the Association for Computational Linguistics, pp." ></td>
	<td class="line x" title="194:222	183-190." ></td>
	<td class="line x" title="195:222	\[Real World Computing Partnership, 1995\] Real World Computing Partnership." ></td>
	<td class="line x" title="196:222	RWC text database." ></td>
	<td class="line x" title="197:222	http ://www." ></td>
	<td class="line x" title="198:222	rwcp." ></td>
	<td class="line x" title="199:222	or." ></td>
	<td class="line x" title="200:222	j p/wswg, html." ></td>
	<td class="line x" title="201:222	\[Resnik, 1992\] Resnik, P. A class-based approach to lexical discovery." ></td>
	<td class="line x" title="202:222	In Proceedings of 30th Annual Meeting of the Association for Computational Linguistics, pp." ></td>
	<td class="line x" title="203:222	327-329." ></td>
	<td class="line x" title="204:222	\[Mainichi Shimbun, 1991-1994\] Mainichi Shimbun CD-ROM '91-'94." ></td>
	<td class="line x" title="205:222	\[Tanaka and Nisina, 1987\] Construction of a thesaurus based on superordinate/subordinate relations." ></td>
	<td class="line x" title="206:222	IPSJ-SIGNL, NL64-~, 25-44." ></td>
	<td class="line x" title="207:222	(In Japanese)." ></td>
	<td class="line x" title="208:222	\[Tokunaga et aL, 1995\] Tokunaga, T. , Iwayama, M. , and Tanaka, H. Automatic thesaurus construction based on grammatical relations." ></td>
	<td class="line x" title="209:222	In Proceedings off IJCAI '95, pp." ></td>
	<td class="line x" title="210:222	1308-1313." ></td>
	<td class="line x" title="211:222	\[Uramoto, 1996\] Uramoto, N. Positioning unknown words in a thesaurus by using information extracted from a corpus." ></td>
	<td class="line x" title="212:222	In Proceedings of COLING '96, pp." ></td>
	<td class="line x" title="213:222	956-961." ></td>
	<td class="line x" title="214:222	\[Ushioda, 1996\] Ushioda, A. Hierarchical clustering of words." ></td>
	<td class="line x" title="215:222	In Proceedings off COLING '96, pp." ></td>
	<td class="line x" title="216:222	1159-1162." ></td>
	<td class="line x" title="217:222	\[Weiss and Kulikowski, 1991\] Weiss, S. M., and Kulikowsld, C. Computer Systems That Learn." ></td>
	<td class="line x" title="218:222	Morgan Kaufmann." ></td>
	<td class="line x" title="219:222	\[Yarowsky, 1992\] Yarowsky, D. Word-sense disambiguation using statistical models of Roget's categories trained on large corpora." ></td>
	<td class="line x" title="220:222	In Proceedings of COLING '9& Vol." ></td>
	<td class="line x" title="221:222	2, pp." ></td>
	<td class="line x" title="222:222	454-460 ." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C98-2122
Automatic Retrieval and Clustering of Similar Words
Lin, Dekang;"></td>
	<td class="line x" title="1:108	Automatic Retrieval and Clustering of Similar Words Dekang Lin Department of Computer Science University of Manitoba Winnipeg, Manitoba, Canada R3T 2N2 l indek @ cs.umanitoba.ca Abstract Bootstrapping semantics from text is one of the greatest challenges in natural language learning." ></td>
	<td class="line x" title="2:108	We first define a word similarity measure based on the distributional pattern of words." ></td>
	<td class="line x" title="3:108	The similarity measure allows us to construct a thesaurus using a parsed corpus." ></td>
	<td class="line x" title="4:108	We then present a new evaluation methodology for the automatically constructed thesaurus." ></td>
	<td class="line x" title="5:108	The evaluation results show that the thesaurus is significantly closer to WordNet than Roget Thesaurus is. 1 Introduction The meaning of an unknown word can often be inferred from its context." ></td>
	<td class="line x" title="6:108	Consider the following (slightly modified)example in (Nida, 1975, p. 167): (l) A bottle of tezgiiino is on the table." ></td>
	<td class="line x" title="7:108	Everyone likes tezgiiino." ></td>
	<td class="line x" title="8:108	Tezgaino makes you drunk." ></td>
	<td class="line x" title="9:108	We make tezgiiino out of corn." ></td>
	<td class="line x" title="10:108	The contexts in which the word tezgiiino is used suggest that tezgiiino may be a kind of alcoholic beverage made from corn mash." ></td>
	<td class="line x" title="11:108	Bootstrapping semantics from text is one of the greatest challenges in natural language learning." ></td>
	<td class="line x" title="12:108	It has been argued that similarity plays an important role in word acquisition (Gentner, 1982)." ></td>
	<td class="line x" title="13:108	Identifying similar words is an initial step in learning the definition of a word." ></td>
	<td class="line x" title="14:108	This paper presents a method for making this first step." ></td>
	<td class="line x" title="15:108	For example, given a corpus that includes the sentences in (1), our goal is to be able to infer that tezgiiino is similar to 'beer', 'wine', 'vodka', etc. In addition to the long-term goal of bootstrapping semantics from text, automatic identification of similar words has many immediate applications." ></td>
	<td class="line x" title="16:108	The most obvious one is thesaurus construction." ></td>
	<td class="line x" title="17:108	An automatically created thesaurus offers many advantages over manually constructed thesauri." ></td>
	<td class="line x" title="18:108	Firstly, the terms can be corpusor genre-specific." ></td>
	<td class="line x" title="19:108	Manually constructed general-purpose dictionaries and thesauri include many usages that are very infrequent in a particular corpus or genre of documents." ></td>
	<td class="line x" title="20:108	For example, one of the 8 senses of 'company' in WordNet 1.5 is a 'visitor/visitant', which is a hyponym of 'person'." ></td>
	<td class="line x" title="21:108	This usage of the word is practically never used in newspaper articles." ></td>
	<td class="line x" title="22:108	However, its existance may prevent a co-reference recognizer to rule out the possiblity for personal pronouns to refer to 'company'." ></td>
	<td class="line x" title="23:108	Secondly, certain word usages may be particular to a period of time, which are unlikely to be captured by manually compiled lexicons." ></td>
	<td class="line x" title="24:108	For example, among 274 occurrences of the word 'westerner' in a 45 million word San Jose Mercury corpus, 55% of them refer to hostages." ></td>
	<td class="line x" title="25:108	If one needs to search hostage-related articles, 'westerner' may well be a good search term." ></td>
	<td class="line x" title="26:108	Another application of automatically extracted similar words is to help solve the problem of data sparseness in statistical natural language processing (Dagan et al., 1994; Essen and Steinbiss, 1992)." ></td>
	<td class="line x" title="27:108	When the frequency of a word does not warrant reliable maximum likelihood estimation, its probability can be computed as a weighted sum of the probabilities of words that are similar to it." ></td>
	<td class="line x" title="28:108	It was shown in (Dagan et al., 1997) that a similarity-based smoothing method achieved much better results than backoff smoothing methods in word sense disambiguation." ></td>
	<td class="line x" title="29:108	The remainder of the paper is organized as follows." ></td>
	<td class="line x" title="30:108	The next section is concerned with similarities between words based on their distributional patterns." ></td>
	<td class="line x" title="31:108	The similarity measure can then be used to create a thesaurus." ></td>
	<td class="line x" title="32:108	In Section 3, we evaluate the constructed thesauri by computing the similarity between their entries and entries in manually created thesauri." ></td>
	<td class="line x" title="33:108	Section 4 briefly discuss future work in clustering similar words." ></td>
	<td class="line x" title="34:108	Finally, Section 5 reviews related work and summarize our contributions." ></td>
	<td class="line x" title="35:108	768 2 Word Similarity Our similarity measure is based on a proposal in (Lin, 1997), where the similarity between two objects is defined to be the amount of information contained in the commonality between the objects divided by the amount of information in the descriptions of the objects." ></td>
	<td class="line x" title="36:108	We use a broad-coverage parser (Lin, 1993; Lin, 1994) to extract dependency triples from the text corpus." ></td>
	<td class="line x" title="37:108	A dependency triple consists of two words and the grammatical relationship between them in the input sentence." ></td>
	<td class="line x" title="38:108	For example, the triples extracted from the sentence 'I have a brown dog' are: (2) (have subj I), (I subj-of have), (dog obj-of have), (dog adj-mod brown), (brown adj-mod-of dog), (dog det a), (a det-of dog) We use the notation \]\[w, r, w'l\[ to denote the frequency count of the dependency triple (w, r, w ~) in the parsed corpus." ></td>
	<td class="line x" title="39:108	When w, r, or w ~ is the wild card (,), the frequency counts of all the dependency triples that matches the rest of the pattern are summed up." ></td>
	<td class="line x" title="40:108	For example, Ilcook, obj, *{I is the total occurrences of cook--object relationships in the parsed corpus, and II*, *, *11 is the total number of dependency triples extracted from the parsed corpus." ></td>
	<td class="line x" title="41:108	The description of a word w consists of the frequency counts of all the dependency triples that matches the pattern (w, ,, ,)." ></td>
	<td class="line x" title="42:108	The commonality between two words consists of the dependency triples that appear in the descriptions of both words." ></td>
	<td class="line x" title="43:108	For example, (3) is the the description of the word 'cell'." ></td>
	<td class="line x" title="44:108	(3) Ilcell, Ilcen, Ilcen, Ilcell, Ilcen, Ilcell, Ilcell, Ilcell, Ilcell, Ilcell, Ilcen, Ilcell, Ilcell, subj-of, absorbll=l subj-of, adaptll=l subj-of, behavell=l pobj-of, inl\[=159 pobj-of, inside{{ = 16 pobj-of, intol{--30 nmod-of, abnormality\[\[=3 nmod-of, anemiall=8 nmod-of, architecturell=l obj-of, attackll=6 obj-of, bludgeonl\[=l obj-of, call\[\[=l 1 obj-of, come fromll=3 Ilcell, obj-of, containll=4 Ilcell, obj-of, decoratell=2 Ilcell, nmod, bacteriall=3 Ilcell, nmod, blood vesselll=l IlceU, nmo bodyll=2 Ilcell, nmod, bone marrowll=2 \[\]cell, nmod, burialll=l tlcell, nmod, chameleonll=l Assuming that the frequency counts of the dependency triples are independent of each other, the information contained in the description of a word is the sum of the information contained in each individual frequency count." ></td>
	<td class="line x" title="45:108	To measure the information contained in the statement Ilw, r, w tll=c, we first measure the amount of information in the statement that a randomly selected dependency triple is (w, r, w ~) when we do not know the value of IIw, r,w'lt. We then measure the amount of information in the same statement when we do know the value of \[\[w, r, w ~ IIThe difference between these two amounts is taken to be the information contained in IIw, r, w' II=c, An occurrence of a dependency triple (w, r, w') can be regarded as the co-occurrence of three events: A: a randomly selected word is w; /3: a randomly selected dependency type is r; 6': a randomly selected word is w'." ></td>
	<td class="line x" title="46:108	When the value of IIw, r,w'll is unknown, we assume that A and G' are conditionally independent given B. The probability of A, B and C' cooccurring is estimated by PMLE ( /3 ) PM~.F." ></td>
	<td class="line x" title="47:108	( A I /3 ) PM,* ( C I /3 ) , where PMLE is the maximum likelihood estimation of a probability distribution and PMLE(B) = ll*,*,*ll' PMLE(AIB) = ~, When the value of \[\[w, r, w' \[I is known, we can obtain PMLE(A, .B, C) directly: I~LE(A,B,C) ----llw, r, wll/ll,,,,,lt Let I(w,r,w') denote the amount information contained in llw, r,w'll--c." ></td>
	<td class="line oc" title="48:108	Its value can be com769 simHindle(Wl, W2) ---~(r,w)CT(wx)fqT(w2)Are{su~j-of.obj-of} min(I(wl, r, w), I(w2, r, w) ) simHindle~ (Wl, W2) = ~(r,w)eT(wl)nT(w~) min(I(wl, r, w), I(w2, r, w) ) simcosine(Wl, W2) = ' \[T(wl)nT(w2)\[ %/\[T( wl )\[  IT(w2 ) l simDi~e(Wl w2) : 2xlT(~)nT(w2)l ' IT(wx)l+lT(w2)l T(wl)NT(w2) simJacard(Wl, W2) : iT(wl)l+ T(w2)l_lT(wl)nT(w2)l Figure 1: Other Similarity Measures puted as follows: I(w,r,w') = _ Iog(PMLE(B)PMLE(A\[B)PMLE(CIB)) --(-log PMLE (A,/3, C)) = log IIw,r,w ll*,r,*\[ IIw,r,*llx *,r,w'll It is worth noting that I(w,r,w') is equal to the mutual information between w and w' (Hindle, 1990)." ></td>
	<td class="line x" title="49:108	Let T(w) be the set of pairs (r,w') such that \[w,r,w'llxll*,r,*ll log w,r,*llxll*,r,w'll is positive." ></td>
	<td class="line x" title="50:108	We define the similarity sim(wl, w2) between two words wl and w2 as follows: \]~_~(r,w)ET(wl)NT(w2)(I(wl, r, w) -\[I(w2, r, w) ) ~(r,w)CT(wl) I(wl , r, w) + ~~(r,w)CT(w~) I(w2, r, w) We parsed a 64-million-word corpus consisting of the Wall Street Journal (24 million words), San Jose Mercury (21 million words) and AP Newswire (19 million words)." ></td>
	<td class="line x" title="51:108	From the parsed corpus, we extracted 56.5 million dependency triples (8.7 million unique)." ></td>
	<td class="line x" title="52:108	In the parsed corpus, there are 5469 nouns, 2173 verbs, and 2632 adjectives/adverbs that occurred at least 100 times." ></td>
	<td class="line x" title="53:108	We computed the pairwise similarity between all the nouns, all the verbs and all the adjectives/adverbs, using the above similarity measure." ></td>
	<td class="line x" title="54:108	For each word, we created a thesaurus entry which contains the top-N l words that are most similar to it." ></td>
	<td class="line x" title="55:108	2 The thesaurus entry for word w has the following format: w (pos) : wl, sl, w2, s2,, wlv, 8N where pos is a part of speech, wi is a word, si=sim(w, wi) and si's are ordered in descending ~We used N=200 in our experiments 2The resulting thesaurus is available at: http://www.cs.umanitoba.caflindek/sims.htm." ></td>
	<td class="line x" title="56:108	order." ></td>
	<td class="line x" title="57:108	For example, the top-10 words in the noun, verb, and adjective entries for the word 'brief' are shown below: brief(noun): affidavit 0.13, petition 0.05, memorandum 0.05, motion 0.05, lawsuit 0.05, deposition 0.05, slight 0.05, prospectus 0.04, document 0.04 paper 0.04  brief(verb): tell 0.09, urge 0.07, ask 0.07, meet 0.06, appoint 0.06, elect 0.05, name 0.05, empower 0.05, summon 0.05, overrule 0.04  brief (adjective): lengthy 0.13, short 0.12, recent 0.09, prolonged 0.09, long 0.09, extended 0.09, daylong 0.08, scheduled 0.08, stormy 0.07, planned 0.06  Two words are a pair of respective nearest neighbors (RNNs) if each is the other's most similar word." ></td>
	<td class="line x" title="58:108	Our program found 543 pairs of RNN nouns, 212 pairs of RNN verbs and 382 pairs of RNN adjectives/adverbs in the automatically created thesaurus." ></td>
	<td class="line x" title="59:108	Appendix A lists every 10th of the RNNs." ></td>
	<td class="line x" title="60:108	The result looks very strong." ></td>
	<td class="line x" title="61:108	Few pairs of RNNs in Appendix A have clearly better alternatives." ></td>
	<td class="line x" title="62:108	We also constructed several other thesauri using the same corpus, but with the similarity measures in Figure 1." ></td>
	<td class="line oc" title="63:108	The measure simHindle is the same as the similarity measure proposed in (Hindie, 1990), except that it does not use dependency triples with negative mutual information." ></td>
	<td class="line o" title="64:108	The measure simHindle r is the same as simHindle except that all types of dependency relationships are used, instead of just subject and object relationships." ></td>
	<td class="line x" title="65:108	The measures simcosine, simdice and simJacard are versions of similarity measures commonly used in information retrieval (Frakes and Baeza-Yates, 1992)." ></td>
	<td class="line x" title="66:108	Unlike sim, simaindle and simHindte~, they only 770 2 log P(c)  simwN(Wl, w2) =lIla, Xc16S(wl)Ac2eS(w2)(maXcEsuper(cl)nsuper(c2) logP(ct)+log P(c2) s 2 R(wl)CIR(w2)l simnoget(Wl, w2) = n(wl) + R(w2) where S(w) is the set of senses of w in the WordNet, super(c) is the set of (possibly indirect) superclasses of concept c in the WordNet, R(w) is the set of words that belong to a same Roget category as w. Figure 2: Word similarity measures based on WordNet and Roget make use of the unique dependency triples and ignore their frequency counts." ></td>
	<td class="line x" title="67:108	3 Evaluation In this section, we present an evaluation of automatically constructed thesauri with two manually compiled thesauri, namely, WordNetl.5 (Miller et al., 1990) and Roget Thesaurus." ></td>
	<td class="line x" title="68:108	We first define two word similarity measures that are based on the structures of WordNet and Roget (Figure 2)." ></td>
	<td class="line x" title="69:108	The similarity measure simwN is based on the proposal in (Lin, 1997)." ></td>
	<td class="line x" title="70:108	The similarity measure simnoaet treats all the words in Roget as features." ></td>
	<td class="line x" title="71:108	A word w possesses the feature f if f and w belong to a same Roget category." ></td>
	<td class="line x" title="72:108	The similarity between two words is then defined as the cosine coefficient of the two feature vectors." ></td>
	<td class="line x" title="73:108	With simwu and simnoget, we transform WordNet and Roget into the same format as the automatically constructed thesauri in the previous section." ></td>
	<td class="line x" title="74:108	We now discuss how to measure the similarity between two thesaurus entries." ></td>
	<td class="line x" title="75:108	Suppose two thesaurus entries for the same word are as follows: w : WI,SI,W2, S2,,WN,SN # # # # W: Wl, S1, 71)2, S2, , W/N, JN Their similarity is defined as: (4) Z N /, 2 N i=l For example, (5) is the entry for 'brief (noun)' in our automatically generated thesaurus and (6) and (7) are corresponding entries in WordNet thesaurus and Roget thesaurus." ></td>
	<td class="line x" title="76:108	(5) brief (noun): affidavit 0.13, petition 0.05, memorandum 0.05, motion 0.05, lawsuit 0.05, deposition 0.05, slight 0.05, prospectus 0.04, document 0.04 paper 0.04." ></td>
	<td class="line x" title="77:108	(6) brief (noun): outline 0.96, instrument 0.84, summary 0.84, affidavit 0.80, deposition 0.80, law 0.77, survey 0.74, sketch 0.74, resume 0.74, argument 0.74." ></td>
	<td class="line x" title="78:108	(7) brief (noun): recital 0.77, saga 0.77, autobiography 0.77, anecdote 0.77, novel 0.77, novelist 0.77, tradition 0.70, historian 0.70, tale 0.64." ></td>
	<td class="line x" title="79:108	According to (4), the similarity between (5) and (6) is 0.297, whereas the similarities between (5) and (7) and between (6) and (7) are 0." ></td>
	<td class="line x" title="80:108	Our evaluation was conducted with 4294 nouns that occurred at least 100 times in the parsed corpus and are found in both WordNetl.5 and the Roget Thesaurus." ></td>
	<td class="line x" title="81:108	Table 1 shows the average similarity between corresponding entries in different thesauri and the standard deviation of the average, which is the standard deviation of the data items divided by the square root of the number of data items." ></td>
	<td class="line x" title="82:108	Since the differences among simcosine, simdice and simy,card are very small, we only included the results for simcosine in Table 1 for the sake of brevity." ></td>
	<td class="line o" title="83:108	It can be seen that sim, Hindler and cosine are significantly more similar to WordNet than Roget is, but are significantly less similar to Roget than WordNet is. The differences between Hindle and Hindler clearly demonstrate that the use of other types of dependencies in addition to subject and object relationships is very beneficial." ></td>
	<td class="line o" title="84:108	The performance of sim, Hindler and cosine are quite close." ></td>
	<td class="line x" title="85:108	To determine whether or not the differences are statistically significant, we computed their differences in similarities to WordNet and Roget thesaurus for each individual entry." ></td>
	<td class="line x" title="86:108	Table 2 shows the average and standard deviation of the average difference." ></td>
	<td class="line o" title="87:108	Since the 95% confidence inter771 Table  Evaluation with WordNet and Roget Roget sim Hindle~ cosine Hindle WordNet average aava 0.178397 0.001636 0.212199 0.001484 0.204179 0.001424 0.199402 0.001352 0.164716 0.001200 Roget average WordNet 0.178397 sim 0.149045 Hindle~ 0.14663 cosine 0.135697 Hindle 0.115489 ~av~ 0.001636 0.001429 0.001383 0.001275 0.001140 vals of all the differences in Table 2 are on the positive side, one can draw the statistical conclusion that simis better than simHindler, which is better than simeosine." ></td>
	<td class="line o" title="88:108	Table 2: Distribution of Differences sim-Hindler sim-cosine Hindler-cosine WordNet average aavg 0.008021 0.000428 0.012798 0.000386 0.004777 0.000561 Roget average aavg sim-Hindler 0.002415 0.000401 sim-cosine 0.013349 0.000375 Hindle~-cosine 0.010933 0.000509 4 Future Work Reliable extraction of similar words from text corpus opens up many possibilities for future work." ></td>
	<td class="line x" title="89:108	For example, one can go a step further by constructing a tree structure among the most similar words so that different senses of a given word can be identified with different subtrees." ></td>
	<td class="line x" title="90:108	Let wl,, Wn be a list of words in descending order of their similarity to a given word w. The similarity tree for w is created as follows:  Initialize the similarity tree to consist of a single node w.  For i=l, 2  n, insert wi as a child of wj such that wj is the most similar one to wi among {w, Wl  wi-1}." ></td>
	<td class="line x" title="91:108	For example, Figure 3 shows the similarity tree for the top-40 most similar words to duty." ></td>
	<td class="line x" title="92:108	The first number behind a word is the similarity of the word to its parent." ></td>
	<td class="line x" title="93:108	The second number is the similarity of the word to the root node of the tree." ></td>
	<td class="line x" title="94:108	duty responsibility 0.21 0.21 role 0.12 0.ii \]__action 0.ii 0.i0 change 0.24 0.08 \]rule 0.16 0.08 Irestriction 0.27 0.08 \] I ban 0.30 0.08 \[ Isanction 0.19 0.08 \]schedule 0.ii 0.07 I regulation 0.37 0.07 challenge 0.13 0.07 l issue 0.13 0.07 Ireason 0.14 0.07 \]matter 0.28 0.07 measure 0.22 0.07 ~ obligation 0.12 0.I0 ~ower 0.17 0.08 l__jurisdiction 0.13 0.08 fright 0.12 0.07 \] control 0.20 0.07 l__ground 0.08 0.07 accountability 0.14 0.08 experience 0.12 0.07 )ost 0.14 0.14 __job 0.17 0.i0 I work 0.17 0." ></td>
	<td class="line x" title="95:108	i0 Itraining 0.11 0.07 ____position 0.25 0.10 task 0.10 0.I0 \[ chore 0.ii 0.07 operation 0.10 0.10 I function 0.i0 0.08 I mission 0.12 0.07 I \[~atrol 0.07 0.07 I staff 0.i0 0.07 __.__penalty 0.09 0.09 I fee 0.17 0.08 \[__tariff 0.13 0.08 \] tax 0.19 0.07 reservist 0.07 0.07 Figure 3: Similarity tree for 'duty' Inspection of sample outputs shows that this algorithm works well." ></td>
	<td class="line x" title="96:108	However, formal evaluation of its accuracy remains to be future work." ></td>
	<td class="line x" title="97:108	5 Related Work and Conclusion There have been many approaches to automatic detection of similar words from text corpora." ></td>
	<td class="line oc" title="98:108	Ours is 772 similar to (Grefenstette, 1994; Hindle, 1990; Ruge, 1992) in the use of dependency relationship as the word features, based on which word similarities are computed." ></td>
	<td class="line x" title="99:108	Evaluation of automatically generated lexical resources is a difficult problem." ></td>
	<td class="line oc" title="100:108	In (Hindle, 1990), a small set of sample results are presented." ></td>
	<td class="line x" title="101:108	In (Smadja, 1993), automatically extracted collocations are judged by a lexicographer." ></td>
	<td class="line x" title="102:108	In (Dagan et al., 1993) and (Pereira et al., 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time." ></td>
	<td class="line x" title="103:108	In (Alshawi and Carter, 1994), the collocations and their associated scores were evaluated indirectly by their use in parse tree selection." ></td>
	<td class="line x" title="104:108	The merits of different measures for association strength are judged by the differences they make in the precision and the recall of the parser outputs." ></td>
	<td class="line x" title="105:108	The main contribution of this paper is a new evaluation methodology for automatically constructed thesaurus." ></td>
	<td class="line x" title="106:108	While previous methods rely on indirect tasks or subjective judgments, our method allows direct and objective comparison between automatically and manually constructed thesauri." ></td>
	<td class="line x" title="107:108	The results show that our automatically created thesaurus is significantly closer to WordNet than Roger Thesaurus is. Our experiments also surpasses previous experiments on automatic thesaurus construction in scale and (possibly) accuracy." ></td>
	<td class="line x" title="108:108	Acknowledgement This research has also been partially supported by NSERC Research Grant OGP121338 and by the Institute for Robotics and Intelligent Systems." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="J98-4002
Selective Sampling For Example-Based Word Sense Disambiguation
Fujii, Atsushi;Tokunaga, Takenobu;Inui, Kentaro;Tanaka, Hozumi;"></td>
	<td class="line x" title="1:389	Selective Sampling for Example-based Word Sense Disambiguation Atsushi Fujii* University of Library and Information Science Takenobu Tokunaga * Tokyo Institute of Technology Kentaro Inui t Kyushu Institute of Technology Hozumi Tanaka ~ Tokyo Institute of Technology This paper proposes an efficient example sampling method for example-based word sense disambiguation systems." ></td>
	<td class="line x" title="2:389	To construct a database of practical size, a considerable overhead for manual sense disambiguation (overhead for supervision) is required." ></td>
	<td class="line x" title="3:389	In addition, the time complexity of searching a large-sized database poses a considerable problem (overhead for search)." ></td>
	<td class="line x" title="4:389	To counter these problems, our method selectively samples a smaller-sized effective subset from a given example set for use in word sense disambiguation." ></td>
	<td class="line x" title="5:389	Our method is characterized by the reliance on the notion of training utility: the degree to which each example is informative for future example sampling when used for the training of the system." ></td>
	<td class="line x" title="6:389	The system progressively collects examples by selecting those with greatest utility." ></td>
	<td class="line x" title="7:389	The paper reports the effectiveness of our method through experiments on about one thousand sentences." ></td>
	<td class="line x" title="8:389	Compared to experiments with other example sampling methods, our method reduced both the overhead for supervision and the overhead for search, without the degeneration of the performance of the system." ></td>
	<td class="line x" title="9:389	1." ></td>
	<td class="line x" title="10:389	Introduction Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation (Brown, Della Pietra, and Della Pietra 1991), parsing (Lytinen 1986; Nagao 1994) and text retrieval (Krovets and Croft 1992; Voorhees 1993)." ></td>
	<td class="line x" title="11:389	Various corpus-based approaches to word sense disambiguation have been proposed (Bruce and Wiebe 1994; Charniak 1993; Dagan and Itai 1994; Fujii et al. 1996; Hearst 1991; Karov and Edelman 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Ng and Lee 1996; Niwa and Nitta 1994; Sch~itze 1992; Uramoto 1994b; Yarowsky 1995)." ></td>
	<td class="line x" title="12:389	The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules (some of which are reviewed, for example, by Hirst \[1987\]), corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules." ></td>
	<td class="line x" title="13:389	Our verb sense disambiguation system is based on such an approach, that is, an example-based approach." ></td>
	<td class="line x" title="14:389	A preliminary experiment showed that our system performs well when compared with systems based on other approaches, and motivated * Department of Library and Information Science, University of Library and Information Science, 1-2 Kasuga, Tsukuba, 305-8550, Japan t Department of Artificial Intelligence, Faculty of Computer Science and Systems Engineering, Kyushu Institute of Technology, 680-4, Kawazu, Iizuka, Fukuoka 820-0067, Japan ~t Department of Computer Science, Tokyo Institute of Technology, 2-12-10ookayama Meguroku Tokyo 152-8552, Japan (~) 1998 Association for Computational Linguistics Computational Linguistics Volume 24, Number 4 us to further explore the example-based approach (we elaborate on this experiment in Section 2.3)." ></td>
	<td class="line x" title="15:389	At the same time, we concede that other approaches for word sense disambiguation are worth further exploration, and while we focus on example-based approach in this paper, we do not wish to draw any premature conclusions regarding tlhe relative merits of different generalized approaches." ></td>
	<td class="line x" title="16:389	As with most example-based systems (Fujii et al. 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Uramoto 1994b), our system uses an example database (database, hereafter) that contains example sentences associated with each verb sense." ></td>
	<td class="line x" title="17:389	Given an input sentence containing a polysemous verb, the system chooses the most plausible verb sense from predefined candidates." ></td>
	<td class="line x" title="18:389	In this process, the system computes a scored similarity between the input and examples in the database, and choses the verb sense associated with the example that maximizes the score." ></td>
	<td class="line x" title="19:389	To realize this, we have to manually disambiguate polysemous verbs appearing in examples, prior to their use by the system." ></td>
	<td class="line x" title="20:389	We shall call these examples supervised examples." ></td>
	<td class="line x" title="21:389	A preliminary experiment on eleven polysemous Japanese verbs showed that (a) the more supervised examples we provided to the system, the better it performed, and (b) in order to achieve a reasonable result (say over 80% accuracy), the system needed a hundred-order supervised example set for each verb." ></td>
	<td class="line x" title="22:389	Therefore, in order to build an operational system, the following problems have to be taken into account1: given human resource limitations, it is not reasonable to supervise every example in large corpora ('overhead for supervision'), given the fact that example-based systems, including our system, search the database for the examples most similar to the input, the computational cost becomes prohibitive if one works with a very large database size ('overhead for search')." ></td>
	<td class="line x" title="23:389	These problems suggest a different approach, namely to select a small number of optimally informative examples from given corpora." ></td>
	<td class="line x" title="24:389	Hereafter we will call these examples samples." ></td>
	<td class="line x" title="25:389	Our example sampling method, based on the utility maximization principle, decides on the preference for including a given example in the database." ></td>
	<td class="line x" title="26:389	This decision procedure is usually called selective sampling (Cohn, Atlas, and Ladner 1994)." ></td>
	<td class="line x" title="27:389	The overall control flow of selective sampling systems can be depicted as in Figure 1, where 'system' refers to our verb sense disambiguation system, and 'examples' refers to an unsupervised example set." ></td>
	<td class="line x" title="28:389	The sampling process basically cycles between the word sense disambiguation (WSD) and training phases." ></td>
	<td class="line x" title="29:389	During the WSD phase, the system generates an interpretation for each polysemous verb contained in the input example ('WSD outputs' of Figure 1)." ></td>
	<td class="line x" title="30:389	This phase is equivalent to normal word sense disambiguation execution." ></td>
	<td class="line x" title="31:389	During the training phase, the system selects samples for training from the previously produced outputs." ></td>
	<td class="line x" title="32:389	During this phase, a human expert supervises samples, that is, provides the correct interpretation for the verbs appearing in the samples." ></td>
	<td class="line x" title="33:389	Thereafter, samples are simply incorporated into the database without any computational overhead (as would be associated with globally reestimating parameters in statistics-based systems), meaning that the system can be trained on the remaining examples (the 'residue') for the next iteration." ></td>
	<td class="line x" title="34:389	Iterating between these two 1 Note that these problems are associated with corpus-based approaches in general, and have been identified by a number of researchers (Engelson and Dagan 1996; Lewis and Gale 1994; Uramoto 1994a; Yarowsky 1995)." ></td>
	<td class="line x" title="35:389	574 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling sampling ~WSD~sD out ut~~ :(~~ Figure 1 Flow of control of the example sampling system." ></td>
	<td class="line x" title="36:389	phases, the system progressively enhances the database." ></td>
	<td class="line x" title="37:389	Note that the selective sampiing procedure gives us an optimally informative database of a given size irrespective of the stage at which processing is terminated." ></td>
	<td class="line x" title="38:389	Several researchers have proposed this type of approach for NLP applications." ></td>
	<td class="line x" title="39:389	Engelson and Dagan (1996) proposed a committee-based sampling method, which is currently applied to HMM training for part-of-speech tagging." ></td>
	<td class="line x" title="40:389	This method sets several models (the committee) taken from a given supervised data set, and selects samples based on the degree of disagreement among the committee members as to the output." ></td>
	<td class="line x" title="41:389	This method is implemented for statistics-based models." ></td>
	<td class="line x" title="42:389	How to formalize and map the concept of selective sampling into example-based approaches has yet to be explored." ></td>
	<td class="line x" title="43:389	Lewis and Gale (1994) proposed an uncertainty sampling method for statisticsbased text classification." ></td>
	<td class="line x" title="44:389	In this method, the system always samples outputs with an uncertain level of correctness." ></td>
	<td class="line x" title="45:389	In an example-based approach, we should also take into account the training effect a given example has on other unsupervised examples." ></td>
	<td class="line x" title="46:389	This is introduced as training utility in our method." ></td>
	<td class="line x" title="47:389	We devote Section 4 to further comparison of our approach and other related works." ></td>
	<td class="line x" title="48:389	With respect to the problem of overhead for search, possible solutions would include the generalization of similar examples (Kaji, Kida, and Morimoto 1992; Nomiyama 1993) or the reconstruction of the database using a small portion of useful instances selected from a given supervised example set (Aha, Kibler, and Albert 1991; Smyth and Keane 1995)." ></td>
	<td class="line x" title="49:389	However, such approaches imply a significant overhead for supervision of each example prior to the system's execution." ></td>
	<td class="line x" title="50:389	This shortcoming is precisely what our approach aims to avoid: we aim to reduce the overhead for supervision as well as the overhead for search." ></td>
	<td class="line x" title="51:389	Section 2 describes the basis of our verb sense disambiguation system and preliminary experiment, in which we compared our method with other disambiguation methods." ></td>
	<td class="line x" title="52:389	Section 3 then elaborates on our example sampling method." ></td>
	<td class="line x" title="53:389	Section 4 reports on the results of our experiments through comparison with other proposed selective sampling methods, and discusses theoretical differences between those methods." ></td>
	<td class="line x" title="54:389	2." ></td>
	<td class="line x" title="55:389	Example-based Verb Sense Disambiguation System 2.1 The Basic Idea Our verb sense disambiguation system is based on the method proposed by Kurohashi and Nagao (1994) and later enhanced by Fujii et al.(1996)." ></td>
	<td class="line x" title="57:389	The system uses a database containing examples of collocations for each verb sense and its associated case frame(s)." ></td>
	<td class="line x" title="58:389	575 Computational Linguistics Volume 24, Number 4 I kane (money) } {suri(pickpocket)} sa0eu (wallet) kanojo (she) ga otoko (man) wo toru (to take/steal) ani (brother) urea (horse) aidea (idea) I kare (he) menkyoshou (license) kanojo(she)}ga {shikaku (qualification)}wotoru(toattain) gakusei (student) biza (visa) kare (he) } {shinbun(newspaper)} chichi (father) ga zasshi (journal) wo toru (to subscribe) kyaku (client) {kare (he) {kippu(ticket)} dantai (group) ga heya (room) wo toru (to reserve) ryokoukyaku (passenger) joshu (assistant) hikouki (airplane) Figure 2 A fragment of the database, and the entry associated with the Japanese verb toru." ></td>
	<td class="line x" title="59:389	Figure 2 shows a fragment of the entry associated with the Japanese verb toru." ></td>
	<td class="line x" title="60:389	The verb toru has multiple senses, a sample of which are 'to take/steal,' 'to attain,' 'to subscribe,' and 'to reserve'." ></td>
	<td class="line x" title="61:389	The database specifies the case frame(s) associated with each verb sense." ></td>
	<td class="line x" title="62:389	In Japanese, a complement of a verb consists of a noun phrase (case filler) and its case marker suffix, for example ga (nominative) or wo (accusative)." ></td>
	<td class="line x" title="63:389	The database lists several case filler examples for each case." ></td>
	<td class="line x" title="64:389	The task of the system is to 'interpret' the verbs occurring in the input text, i.e., to choose one sense from among a set of candidates." ></td>
	<td class="line x" title="65:389	2 All verb senses we use are defined in IPAL (information-technology Promotion Agency, 1987), a machine-readable dictionary." ></td>
	<td class="line x" title="66:389	IPAL also contains example case fillers as shown in Figure 2." ></td>
	<td class="line x" title="67:389	Given an input, which is currently limited to a simple sentence, the system identifies the verb sense on the basis of the scored similarity between the input and the examples given for each verb sense." ></td>
	<td class="line x" title="68:389	Let us take the sentence below as an example input: hisho ga shindaisha wo toru." ></td>
	<td class="line x" title="69:389	(secretary-NOM) (sleeping car-ACC) ()?" ></td>
	<td class="line x" title="70:389	In this example, one may consider hisho ('secretary') and shindaisha ('sleeping car') to be semantically similar to joshu ('assistant') and hikouki ('airplane') respectively, and since both collocate with the 'to reserve' sense of toru, one could infer that toru should be interpreted as 'to reserve'." ></td>
	<td class="line x" title="71:389	This resolution originates from the analogy principle (Nagao 1984), and can be called nearest neighbor resolution because the verb in the input is disambiguated by superimposing the sense of the verb appearing in the example of highest similarity." ></td>
	<td class="line x" title="72:389	3 The similarity between an input and an example is estimated based on the similarity between case lers marked with the same case." ></td>
	<td class="line x" title="73:389	Furthermore, since the restrictions imposed by the case fillers in choosing the verb sense are not equally selective, Fujii et al.(1996) proposed a weighted case contribution to disambiguation (CCD) of the verb senses." ></td>
	<td class="line x" title="75:389	This CCD factor is taken into account 2 Note that unlike the automatic acquisition of word sense definitions (Fukumoto and Tsujii 1994; Pustejovsky and Boguraev 1993; Utsuro 1996; Zernik 1989), the task of the system is to identify the best matched category with a given input, from predefined candidates." ></td>
	<td class="line x" title="76:389	3 In this paper, we use 'example-based systems' to refer to systems based on nearest neighbor resolution." ></td>
	<td class="line x" title="77:389	576 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling  nominative accusative Figure 3 The semantic ranges of the nominative and accusative for the verb toru." ></td>
	<td class="line x" title="78:389	database nq-mc~nc nc3-rnllc3 v ()?" ></td>
	<td class="line x" title="79:389	Cs~,c~ G,c2 &,;3 -v (s~)l -~s3,c2 ~s3,C3 -V (S3) J Figure 4 An input and the database." ></td>
	<td class="line x" title="80:389	when computing the score for each sense of the verb in question." ></td>
	<td class="line x" title="81:389	Consider again the case of toru in Figure 2." ></td>
	<td class="line x" title="82:389	Since the semantic range of nouns collocating with the verb in the nominative does not seem to have a strong delinearization in a semantic sense (in Figure 2, the nominative of each verb sense displays the same general concept, i.e., HUMAN), it would be difficult, or even risky, to properly interpret the verb sense based on similarity in the nominative." ></td>
	<td class="line x" title="83:389	In contrast, since the semantic ranges are disparate in tile accusative, it would be feasible to rely more strongly on similarity here." ></td>
	<td class="line x" title="84:389	This argument can be illustrated as in Figure 3, in which the symbols el and e2 denote example case fillers of different case frames, and an input sentence includes two case fillers denoted by x and y. The figure shows the distribution of example case fillers for the respective case frames, denoted in a semantic space." ></td>
	<td class="line x" title="85:389	The semantic similarity between two given case fillers is represented by the physical distance between the two symbols." ></td>
	<td class="line x" title="86:389	In the nominative, since x happens to be much closer to an e2 than any el, x may be estimated to belong to the range of e2's, although x actually belongs to both sets of el's and e2's." ></td>
	<td class="line x" title="87:389	In the accusative, however, y would be properly estimated to belong to the set of el's due to the disjunction of the two accusative case filler sets, even though examples do not fully cover each of the ranges of el's and e2's." ></td>
	<td class="line x" title="88:389	Note that this difference would be critical if example data were sparse." ></td>
	<td class="line x" title="89:389	We will explain the method used to compute CCD in Section 2.2." ></td>
	<td class="line x" title="90:389	2.2 Methodology To illustrate the overall algorithm, we will consider an abstract specification of both an input and the database (Figure 4)." ></td>
	<td class="line x" title="91:389	Let the input be {no1 reel, nc2 mc2, nc3 rnc3, v}, where nci denotes the case filler for the case ci, and mci denotes the case marker for ci, and assume that the interpretation candidates for v are derived from the database as sl, s2 and s3." ></td>
	<td class="line x" title="92:389	The database also contains a set Gi,cj of case filler examples for each case cj of each sense si ('--' indicates that the corresponding case is not allowed)." ></td>
	<td class="line x" title="93:389	During the verb sense disambiguation process, the system first discards those candidates whose case frame does not fit the input." ></td>
	<td class="line x" title="94:389	In the case of Figure 4, s3 is discarded because the case frame of v (s3) does not subcategorize for the case cl. 577 Computational Linguistics Volume 24, Number 4 Table 1 The relation between the length of the path between two nouns nl and n2 in the Bunruigoihyo thesaurus (len(nl, n2)), and their relative similarity (sire(n1, n2))." ></td>
	<td class="line x" title="95:389	fen(n1, n2) 0 2 4 6 8 10 12 sire(n1, n2) 11 10 9 8 7 5 0 In the next step the system computes the score of the remaining candidates and chooses as the most plausible interpretation the one with the highest score." ></td>
	<td class="line x" title="96:389	The score of an interpretation is computed by considering the weighted average of the similarity degrees of the input case fillers with respect to each of the example case lers (in the corresponding case) listed in the database for the sense under evaluation." ></td>
	<td class="line x" title="97:389	Formally, this is expressed by Equation (1), where Score(s) is the score of sense s of the input verb, and SIM(nc, G,c) is the maximum similarity degree between the input case filler nc and the corresponding case fillers in the database example set ~s,c (calculated through Equation (2))." ></td>
	<td class="line x" title="98:389	CCD(c) is the weight factor of case c, which we will explain later in this section." ></td>
	<td class="line x" title="99:389	Score(s) = ~c SIM(n, &,c)' CCD(c) (1) CCD(c) SIM(nc, &,c) = max sim(nc, e) (2) eC G,c With regard to the computation of the similarity between two different case fillers (sim(n~, e) in Equation (1)), we experimentally used two alternative approaches." ></td>
	<td class="line x" title="100:389	The first approach uses semantic resources, that is, hand-crafted thesauri (such as the Roger's thesaurus \[Chapman 1984\] or WordNet \[Miller et al. 1993\] in the case of English, and Bunruigoihyo \[National Language Research Institute 1964\] or EDR \[Japan Electronic Dictionary Research Institute 1995\] in the case of Japanese), based on the intuitively feasible assumption that words located near each other within the structure of a thesaurus have similar meaning." ></td>
	<td class="line x" title="101:389	Therefore, the similarity between two given words is :represented by the length of the path between them in the thesaurus structure (Fujii et al. 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Uramoto 1994b)." ></td>
	<td class="line x" title="102:389	4 We used the similarity function empirically identified by Kurohashi and Nagao in which the relation between the length of the path in the Bunruigoihyo thesaurus and the similarity between words is defined as shown in Table 1." ></td>
	<td class="line x" title="103:389	In this thesaurus, each entry is assigned a seven-digit class code." ></td>
	<td class="line x" title="104:389	In other words, this thesaurus can be considered as a tree, seven levels in depth, with each leaf as a set of words." ></td>
	<td class="line x" title="105:389	Figure 5 shows a fragment of the Bunruigoihyo thesaurus including some of the nouns in both Figure 2 and the input sentence above." ></td>
	<td class="line x" title="106:389	The second approach is based on statistical modeling." ></td>
	<td class="line x" title="107:389	We adopted one typical implementation called the 'vector space model' (VSM) (Frakes and Baeza-Yates 1992; Leacock, Towell, and Voorhees 1993; Salton and McGill 1983; Sch/itze 1992), which has a long history of application in information retrieval (IR) and text categorization (TC) tasks." ></td>
	<td class="line x" title="108:389	In the case of IR/TC, VSM is used to compute the similarity between documents, which is represented by a vector comprising statistical factors of content words in a document." ></td>
	<td class="line x" title="109:389	Similarly, in our case, each noun is represented by a vector comprising 4 Different types of application of hand-crafted thesauri to word sense disambiguation have been proposed, for example, by Yarowsky (1992)." ></td>
	<td class="line x" title="110:389	578 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling I I kare kanojo (he) (she) I IIII otoko joshu hisho kane heya kippu uma (man) (assistant) (secretary)(money) (room) (ticket) (horse) Figure 5 A fragment of the Bunruigoihyo thesaurus." ></td>
	<td class="line x" title="111:389	statistical factors, although statistical factors are calculated in terms of the predicate argument structure in which each noun appears." ></td>
	<td class="line oc" title="112:389	Predicate argument structures, which consist of complements (case filler nouns and case markers) and verbs, have also been used in the task of noun classification (Hindle 1990)." ></td>
	<td class="line x" title="113:389	This can be expressed by Equation (3), where ff is the vector for the noun in question, and items ti represent the statistics for predicate argument structures including n. ff = (h, t2,, ti ) (3) In regard to ti, we used the notion of TF." ></td>
	<td class="line x" title="114:389	IDF (Salton and McGill 1983)." ></td>
	<td class="line x" title="115:389	TF (term frequency) gives each context (a case marker/verb pair) importance proportional to the number of times it occurs with a given noun." ></td>
	<td class="line x" title="116:389	The rationale behind IDF (inverse document frequency) is that contexts that rarely occur over collections of nouns are valuable, and that therefore the IDF of a context is inversely proportional to the number of noun types that appear in that context." ></td>
	<td class="line x" title="117:389	This notion is expressed by Equation (4), wheref((n, c, v)) is the frequency of the tuple (n, c, v), nf((c, v)) is the number of noun types which collocate with verb v in the case c, and N is the number of noun types within the overall co-occurrence data." ></td>
	<td class="line x" title="118:389	N ti =d((n, c, v))." ></td>
	<td class="line x" title="119:389	log nf((c, v)) (4) We compute the similarity between nouns nt and n2 by the cosine of the angle between the two vectors t~ and n2." ></td>
	<td class="line x" title="120:389	This is realized by Equation (5)." ></td>
	<td class="line x" title="121:389	/I/1 ' n2 sire(n1, n2) ~ \]\]~21 (5) We extracted co-occurrence data from the RWC text base RWC-DB-TEXT-95-1 (Real World Computing Partnership 1995)." ></td>
	<td class="line x" title="122:389	This text base consists of four years worth of Mainichi Shimbun newspaper articles (Mainichi Shimbun 1991-1994), which have been automatically annotated with morphological tags." ></td>
	<td class="line x" title="123:389	The total morpheme content is about one hundred million." ></td>
	<td class="line x" title="124:389	Since full parsing is usually expensive, a simple heuristic rule was used to obtain collocations of nouns, case markers, and verbs in the form of tuples (n, c, v)." ></td>
	<td class="line x" title="125:389	This rule systematically associates each sequence of noun and case marker to the verb of highest proximity, and produced 419,132 tuples." ></td>
	<td class="line x" title="126:389	This co-occurrence data was used in the preliminary experiment described in Section 2.3." ></td>
	<td class="line x" title="127:389	s 5 Note that each verb in co-occurrence data should ideally be annotated with its verb sense." ></td>
	<td class="line x" title="128:389	However, there is no existing Japanese text base with sufficient volume of word sense tags." ></td>
	<td class="line x" title="129:389	579 Computational Linguistics Volume 24, Number 4 In Equation (1), CCD(c) expresses the weight factor of the contribution of case c to (current) verb sense disambiguation." ></td>
	<td class="line x" title="130:389	Intuitively, preference should be given to cases displaying case fillers that are classified in semantic categories of greater disjunction." ></td>
	<td class="line x" title="131:389	Thus, c's contribution to the sense disambiguation of a given verb, CCD(c), is likely to be higher if the example case filler sets {gsi,c I i = 1,, n} share fewer elements, as in Equation (6)." ></td>
	<td class="line x" title="132:389	C' 1 r~-I __ ~ CCD(c) = ~,7~ ~ ~ Igs''l + \]s,,cl 2\[s~,c r'l s,,~l j=i+l I&,,I 7 I'G*I ) (6) Here, o~ is a constant for pararneterizing the extent to which CCD influences verb sense disambiguation." ></td>
	<td class="line x" title="133:389	The larger oe is, the stronger is CCD's influence on the system output." ></td>
	<td class="line x" title="134:389	To avoid data sparseness, we smooth each element (noun example) in gsi,c. In practice, this involves generalizing each example noun into a five-digit class based on the Bunruigoihyo thesaurus, as has been commonly used for smoothing." ></td>
	<td class="line x" title="135:389	2.3 Preliminary Experimentation We estimated the performance of our verb sense disambiguation method through an experiment, in which we compared the following five methods:  lower bound (LB), in which the system systematically chooses the most frequently appearing verb sense in the database (Gale, Church, and Yarowsky 1992),  rule-based method (RB), in which the system uses a thesaurus to (automatically) identify appropriate semantic classes as selectional restrictions for each verb complement,  Naive-Bayes method (NB), in which the system interprets a given verb based on the probability that it takes each verb sense,  example-based method using the vector space model (VSM), in which the system uses the above mentioned co-occurrence data extracted from the RWC text base,  example-based method using the Bunruigoihyo thesaurus (BGH), in which the system uses Table 1 for the similarity computation." ></td>
	<td class="line x" title="136:389	In the rule-based method, selectional restrictions are represented by thesaurus classes, and allow only those nouns dominated by the given class in the thesaurus structure as verb complements." ></td>
	<td class="line x" title="137:389	In order to identify appropriate thesaurus classes, we used the association measure proposed by Resnik (1993), which computes the information-theoretic association degree between case fillers and thesaurus classes, for each verb sense (Equation (7))." ></td>
	<td class="line x" title="138:389	6 P(rls, c) A(s,c,r) = P(rls, c )  log p(rlc) (7) 6 Note that previous research has applied this technique to tasks other than verb sense disambiguation, such as syntactic disambiguation (Resnik 1993) and disambiguation of case filler noun senses (Ribas 1995)." ></td>
	<td class="line x" title="139:389	580 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling Here, A(s, c, r) is the association degree between verb sense s and class r (selectional restriction candidate) with respect to case c. P(rls, c) is the conditional probability that a case filler example associated with case c of sense s is dominated by class r in the thesaurus." ></td>
	<td class="line x" title="140:389	P(rlc ) is the conditional probability that a case filler example for case c (disregarding verb sense) is dominated by class r. Each probability is estimated based on training data." ></td>
	<td class="line x" title="141:389	We used the semantic classes defined in the Bunruigoihyo thesaurus." ></td>
	<td class="line x" title="142:389	In practice, every r whose association degree is above a certain threshold is chosen as a selectional restriction (Resnik 1993; Ribas 1995)." ></td>
	<td class="line x" title="143:389	By decreasing the value of the threshold, system coverage can be broadened, but this opens the way for irrelevant (noisy) selectional rules." ></td>
	<td class="line x" title="144:389	The Naive-Bayes method assumes that each case filler included in a given input is conditionally independent of other case fillers: the system approximates the probability that an input x takes a verb sense s (P(slx)), simply by computing the product of the probability that each verb sense s takes nc as a case filler for case c. The verb sense with maximal probability is then selected as the interpretation (Equation (8))." ></td>
	<td class="line x" title="145:389	7 arg msax P(slx) P(s) . P(xls) = arg msax P(x) = argn~axP(s)." ></td>
	<td class="line x" title="146:389	P(xls) argmaxP(s) II P(ncls) c (8) Here, P(ncls) is the probability that a case filler associated with sense s for case c in the training data is nc." ></td>
	<td class="line x" title="147:389	We estimated P(s) based on the distribution of the verb senses in the training data." ></td>
	<td class="line x" title="148:389	In practice, data sparseness leads to not all case fillers nc appearing in the database, so we generalize each nc into a semantic class defined in the Bunruigoihyo thesaurus." ></td>
	<td class="line x" title="149:389	All methods except the lower bound method involve a parametric constant: the threshold value for the association degree (RB), a generalization level for case filler nouns (NB), and a in Equation (6) (VSM and BGH)." ></td>
	<td class="line x" title="150:389	For these parameters, we conducted several trials prior to the actual comparative experiment, to determine the optimal parameter values over a range of data sets." ></td>
	<td class="line x" title="151:389	For our method, we set a extremely large, which is equivalent to relying almost solely on the SIM of the case with the greatest CCD." ></td>
	<td class="line x" title="152:389	However, note that when the SIM of the case with the greatest CCD is equal for multiple verb senses, the system computes the SIM of the case with the second highest CCD." ></td>
	<td class="line x" title="153:389	This process is repeated until only one verb sense remains." ></td>
	<td class="line x" title="154:389	When more than one verb sense is selected for any given method (or none of them remains, for the rule-based method), the system simply selects the verb sense that appears most frequently in the database, s In the experiment, we conducted sixfold cross-validation, that is, we divided the training/test data into six equal parts, and conducted six trials in which a different 7 A number of experimental results have shown the effectiveness of the Naive-Bayes method for word sense disambiguation (Gale, Church, and Yarowsky 1993; Leacock, Towell, and Voorhees 1993; Mooney 1996; Ng 1997; Pedersen, Bruce, and Wiebe 1997)." ></td>
	<td class="line x" title="155:389	8 One may argue that this goes against the basis of the rule-based method, in that, given a proper threshold value for the association degree, the system could improve on accuracy (potentially sacrificing coverage), and that the trade-off between coverage and accuracy is therefore a more appropriate evaluation criterion." ></td>
	<td class="line x" title="156:389	However, our trials on the rule-based method with different threshold values did not show significant correlation between the improvement of accuracy and the degeneration of coverage." ></td>
	<td class="line x" title="157:389	581 Computational Linguistics Volume 24, Number 4 Table 2 The verbs contained in the corpus used, and the accuracy of the different verb sense disambiguation methods (LB: lower bound, RB: rule-based method, NB: Naive-Bayes method, VSM: vector space model, BGH: the Bunruigoihyo thesaurus)." ></td>
	<td class="line x" title="158:389	Verb # of # of Accuracy (%) English Gloss Sentences Senses LB RB NB VSM BGH ataeru give 136 4 66.9 62.1 75.8 84.1 86.0 kakeru hang 160 29 25.6 24.6 67.6 73.4 76.2 kuwaeru add 167 5 53.9 65.6 82.2 84.0 86.8 motomeru require 204 4 85.3 82.4 87.0 85.5 85.5 noru ride 126 10 45.2 52.8 81.4 80.5 85.3 osameru govern 108 8 30.6 45.6 66.0 72.0 74.5 tsukuru make 126 15 25.4 24.9 59.1 56.5 69.9 toru take 84 29 26.2 16.2 56.1 71.2 75.9 umu bear offspring 90 2 83.3 94.7 95.5 92.0 99.4 wakaru understand 60 5 48.3 40.6 71.4 62.5 70.7 yameru stop 54 2 59.3 89.9 92.3 96.2 96.3 total -1,315 -51.4 54.8 76.6 78.6 82.3 part was used as test data each time, and the rest as training data (the database)." ></td>
	<td class="line x" title="159:389	9 We evaluated the performance of each method according to its accuracy, that is, the ratio of the number of correct outputs compared to the total number of inputs." ></td>
	<td class="line x" title="160:389	The training/test data used in the experiment contained about one thousand simple Japanese sentences collected from news articles." ></td>
	<td class="line x" title="161:389	Each sentence in the training/test data contained one or more complement(s) followed by one of the eleven verbs described in Table 2." ></td>
	<td class="line x" title="162:389	In Table 2, the column 'English Gloss' describes typical English translations of the Japanese verbs." ></td>
	<td class="line x" title="163:389	The column '# of Sentences' denotes the number of sentences in the corpus, and '# of Senses' denotes the number of verb senses contained in IPAL." ></td>
	<td class="line x" title="164:389	The column 'accuracy' shows the accuracy of each method." ></td>
	<td class="line x" title="165:389	Looking at Table 2, one can see that our example-based method performed better than the other methods (irrespective of the similarity computation), although the Naive-Bayes method is relatively comparable in performance." ></td>
	<td class="line x" title="166:389	Surprisingly, despite the relatively ad hoc similarity definition used (see Table 1), the Bunruigoihyo thesaurus led to a greater accuracy gain than the vector space model." ></td>
	<td class="line x" title="167:389	In order to estimate the upper bound (limitation) of the disambiguation task, that is, to what extent a human expert makes errors in disambiguation (Gale, Church, and Yarowsky 1992), we analyzed incorrect outputs and found that roughly 30% of the system errors using the Bunruigoihyo thesaurus fell into this category." ></td>
	<td class="line x" title="168:389	It should be noted that while the vector space model requires computational cost (time/memory) of an order proportional to the size of the vector, determination of paths in the Bunruigoihyo thesaurus comprises a trivial cost." ></td>
	<td class="line x" title="169:389	We also investigated errors made by the rule-based method to find a rational explanation for its inferiority." ></td>
	<td class="line x" title="170:389	We found that the association measure in Equation (7) tends to give a greater value to less frequently appearing verb senses and lower level 9 Ideally speaking, training and test data should be drawn from different sources, to simulate a real application." ></td>
	<td class="line x" title="171:389	However, the sentences were already scrambled when provided to us, and therefore we could not identify the original source corresponding to each sentence." ></td>
	<td class="line x" title="172:389	582 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling (more specified) classes, and therefore chosen rules are generally overspecified." ></td>
	<td class="line x" title="173:389	1 Consequently, frequently appearing verb senses are likely to be rejected." ></td>
	<td class="line x" title="174:389	On the other hand, when attempting to enhance the rule set by setting a smaller threshold value for the association score, overgeneralization can be a problem." ></td>
	<td class="line x" title="175:389	We also note that one of the theoretical differences between the rule-based and example-based methods is that the former statically generalizes examples (prior to system usage), while the latter does so dynamically." ></td>
	<td class="line x" title="176:389	Static generalization would appear to be relatively risky for sparse training data." ></td>
	<td class="line x" title="177:389	Although comparison of different approaches to word sense disambiguation should be further investigated, this experimental result gives us good motivation to explore example-based verb sense disambiguation approaches, i.e., to introduce the notion of selective sampling into them." ></td>
	<td class="line x" title="178:389	2.4 Enhancement of Verb Sense Disambiguation Let us discuss how further enhancements to our example-based verb sense disambiguation system could be made." ></td>
	<td class="line x" title="179:389	First, since inputs are simple sentences, information for word sense disambiguation is inadequate in some cases." ></td>
	<td class="line x" title="180:389	External information such as the discourse or domain dependency of each word sense (Guthrie et al. 1991; Nasukawa 1993; Yarowsky 1995) is expected to lead to system improvement." ></td>
	<td class="line x" title="181:389	Second, some idiomatic expressions represent highly restricted collocations, and overgeneralizing them semantically through the use of a thesaurus can cause further errors." ></td>
	<td class="line x" title="182:389	Possible solutions would include one proposed by Uramoto, in which idiomatic expressions are described separately in the database so that the system can control their overgeneralization (Uramoto 1994b)." ></td>
	<td class="line x" title="183:389	Third, a number of existing NLP tools such as JUMAN (a morphological analyzer) (Matsumoto et al. 1993) and QJP (a morphological and syntactic analyzer) (Kameda 1996) could broaden the coverage of our system, as inputs are currently limited to simple, morphologically analyzed sentences." ></td>
	<td class="line x" title="184:389	Finally, it should be noted that in Japanese, case markers can be omitted or topicalized (for example, marked with postposition wa), an issue which our framework does not currently consider." ></td>
	<td class="line x" title="185:389	3." ></td>
	<td class="line x" title="186:389	Example Sampling Algorithm 3.1 Overview Let us look again at Figure 1 in Section 1." ></td>
	<td class="line x" title="187:389	In this figure, 'WSD outputs' refers to a corpus in which each sentence is assigned an expected verb interpretation during the WSD phase." ></td>
	<td class="line x" title="188:389	In the training phase, the system stores supervised samples (with each interpretation simply checked or appropriately corrected by a human) in the database, to be used in a later WSD phase." ></td>
	<td class="line x" title="189:389	In this section, we turn to the problem of which examples should be selected as samples." ></td>
	<td class="line x" title="190:389	Lewis and Gale (1994) proposed the notion of uncertainty sampling for the training of statistics-based text classifiers." ></td>
	<td class="line x" title="191:389	Their method selects those examples that the system classifies with minimum certainty, based on the assumption that there is no need for teaching the system the correct answer when it has answered with sufficiently high certainty." ></td>
	<td class="line x" title="192:389	However, we should take into account the training effect a given example has on other remaining (unsupervised) examples." ></td>
	<td class="line x" title="193:389	In other words, we would like to select samples so as to be able to correctly disambiguate as many examples as possible in the next iteration." ></td>
	<td class="line x" title="194:389	If this is successfully done, the number of examples to be supervised will 10 This problem has also been identified by Charniak (1993)." ></td>
	<td class="line x" title="195:389	583 Computational Linguistics Volume 24, Number 4 el: seito ga (student-NOM) shitsumon wo (question-ACC) yameru (sl) e2: ani ga (brother-NOM) kaisha wo (company-ACC) yameru (s2) Xl: shain ga (employee-NOM) eigyou wo (sales-ACC) yameru ()?" ></td>
	<td class="line x" title="196:389	x2: shouten ga (store-NOM) eigyou wo (sales-ACC) yameru ()?" ></td>
	<td class="line x" title="197:389	x3: koujou ga (factory-NOM) sougyou wo (operation-ACC) yameru ()?" ></td>
	<td class="line x" title="198:389	x4: shisetsu ga (facility-NOM) unten wo (operation-ACC) yameru ()?" ></td>
	<td class="line x" title="199:389	xs: senshu ga (athlete-NOM) renshuu wo (pracfice-ACC) yameru ()?" ></td>
	<td class="line x" title="200:389	x6: musuko ga (son-NOM) kaisha wo (company-ACC) yameru ()?" ></td>
	<td class="line x" title="201:389	x7: kangofu ga (nurse-NOM) byouin wo (hospital-ACC) yameru ()?" ></td>
	<td class="line x" title="202:389	x8: hikoku ga (defendant-NOM) giin wo (congressman-ACC) yameru ()?" ></td>
	<td class="line x" title="203:389	xg: chichi ga (father-NOM) kyoushi wo (teacher-ACC) yameru ()?" ></td>
	<td class="line x" title="204:389	Figure 6 Example of a given corpus associated with the verb yameru." ></td>
	<td class="line x" title="205:389	decrease." ></td>
	<td class="line x" title="206:389	We consider maximization of this effect by means of a training utility function aimed at ensuring that the most useful example at a given point in time is the example with the greatest training utility factor." ></td>
	<td class="line x" title="207:389	Intuitively speaking, the training utility of an example is greater when we can expect greater increase in the interpretation certainty of the remaining examples after training using that example." ></td>
	<td class="line x" title="208:389	To explain this notion intuitively, let us take Figure 6 as an example corpus." ></td>
	<td class="line x" title="209:389	In this corpus, all sentences contain the verb yameru, which has two senses according to IPAL, sl ('to stop (something)') and s2 ('to quit (occupation)')." ></td>
	<td class="line x" title="210:389	In this figure, sentences el and e2 are supervised examples associated with senses Sl and s2, respectively, and xi's are unsupervised examples." ></td>
	<td class="line x" title="211:389	For the sake of enhanced readability, the examples xi's are partitioned according to their verb senses, that is, xl to x5 correspond to sense Sl, and x6 to x9 correspond to sense s2." ></td>
	<td class="line x" title="212:389	In addition, note that examples in the corpus can be readily categorized based on case similarity, that is, into clusters {Xl, X2, X3, X4} ('someone/something stops service'), {Ca, X6, X7} ('someone leaves organization'), {Xs, X9} ('someone quits occupation'), {el}, and {Xs}." ></td>
	<td class="line x" title="213:389	Let us simulate the sampling procedure with this example corpus." ></td>
	<td class="line x" title="214:389	In the initial stage with {el, e2} in the database, x6 and x7 can be interpreted as s2 with greater certainty than for the other xi's, because these two examples are similar to e2." ></td>
	<td class="line x" title="215:389	Therefore, uncertainty sampling selects any example except x6 and x7 as the sample." ></td>
	<td class="line x" title="216:389	However, any one of examples Xl to x4 is more desirable because by way of incorporating one of these examples, we can obtain more xi's with greater certainty." ></td>
	<td class="line x" title="217:389	Assuming that Xl is selected as the sample and incorporated into the database with sense Sl, either of x8 and x9 will be more highly desirable than other unsupervised xi's in the next stage." ></td>
	<td class="line x" title="218:389	Let S be a set of sentences, i.e., a given corpus, and D be the subset of supervised examples stored in the database." ></td>
	<td class="line x" title="219:389	Further, let X be the set of unsupervised examples, realizing Equation (9)." ></td>
	<td class="line x" title="220:389	S = D u X (9) The example sampling procedure can be illustrated as: 1." ></td>
	<td class="line x" title="221:389	WSD(D, X) 2." ></td>
	<td class="line x" title="222:389	e ~ arg maxx~x TU(x) 3." ></td>
	<td class="line x" title="223:389	D ~--D U {e}, X ~-X n {e} 4." ></td>
	<td class="line x" title="224:389	goto 1 where WSD(D, X) is the verb sense disambiguation process on input X using D as the database." ></td>
	<td class="line x" title="225:389	In this disambiguation process, the system outputs the following for 584 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling X X sense I (x e xl x fsense2 (:ex) x,,_y X X A' sense I Ix d sense 2 e t 'x) x ) X (a) (b) Figure 7 The concept of interpretation certainty." ></td>
	<td class="line x" title="226:389	The case where the interpretation certainty of the enclosed x's is great is shown in (a)." ></td>
	<td class="line x" title="227:389	The case where the interpretation certainty of the x's contained in the intersection of senses 1 and 2 is small is shown in (b)." ></td>
	<td class="line x" title="228:389	each input: (a) a set of verb sense candidates with interpretation scores, and (b) an interpretation certainty." ></td>
	<td class="line x" title="229:389	These factors are used for the computation of TU(x), newly introduced in our method." ></td>
	<td class="line x" title="230:389	TU(x) computes the training utility factor for an example x. The sampling algorithm gives preference to examples of maximum utility." ></td>
	<td class="line x" title="231:389	We will explain in the following sections how TU(x) is estimated, based on the estimation of the interpretation certainty." ></td>
	<td class="line x" title="232:389	3.2 Interpretation Certainty Lewis and Gale (1994) estimate certainty of an interpretation as the ratio between the probability of the most plausible text category and the probability of any other text category, excluding the most probable one." ></td>
	<td class="line x" title="233:389	Similarly, in our verb sense disambiguation system, we introduce the notion of interpretation certainty of examples based on the following preference conditions: . 2." ></td>
	<td class="line x" title="234:389	the highest interpretation score is greater, the difference between the highest and second highest interpretation scores is greater." ></td>
	<td class="line x" title="235:389	The rationale for these conditions is given below." ></td>
	<td class="line x" title="236:389	Consider Figure 7, where each symbol denotes an example in a given corpus, with symbols x as unsupervised examples and symbols e as supervised examples." ></td>
	<td class="line x" title="237:389	The curved lines delimit the semantic vicinities (extents) of the two verb senses 1 and 2, respectively." ></td>
	<td class="line x" title="238:389	11 The semantic similarity between two examples is graphically portrayed by the physical distance between the two symbols representing them." ></td>
	<td class="line x" title="239:389	In Figure 7(a), x's located inside a semantic vicinity are expected to be interpreted as being similar to the appropriate example e with high certainty, a fact which is in line with condition 1 above." ></td>
	<td class="line x" title="240:389	However, in Figure 7(b), the degree of certainty for the interpretation of any x located inside the intersection of the two semantic vicinities cannot be great." ></td>
	<td class="line x" title="241:389	This occurs when the case fillers associ11 Note that this method can easily be extended for a verb with more than two senses." ></td>
	<td class="line x" title="242:389	In Section 4, we describe an experiment using multiply polysemous verbs." ></td>
	<td class="line x" title="243:389	585 Computational Linguistics Volume 24, Number 4 100 95 90 85 ' ' ~5  J O ----X  80 i 60 70 80 90 coverage (%) 100 Figure 8 The relation between coverage and accuracy with different A's." ></td>
	<td class="line x" title="244:389	ated with two or more verb senses are not selective enough to allow for a clear-cut delineation between them." ></td>
	<td class="line x" title="245:389	This situation is explicitly rejected by condition 2." ></td>
	<td class="line x" title="246:389	Based on the above two conditions, we compute interpretation certainties using Equation (10), where C(x) is the interpretation certainty of an example x, Scorel(x) and Score2(x) are the highest and second highest scores for x, respectively, and,~, which ranges from 0 to 1, is a parametric constant used to control the degree to which each condition affects the computation of C(x)." ></td>
	<td class="line x" title="247:389	C(x)=A. Scorel(x)+(1 ~).(Scorel(x) Score2(x)) (10) Through a preliminary experiment, we estimated the validity of the notion of interpretation certainty, by the trade-off between accuracy and coverage of the system." ></td>
	<td class="line x" title="248:389	Note that in this experiment, accuracy is the ratio of the number of correct outputs and the number of cases where the interpretation certainty of the output is above a certain threshold." ></td>
	<td class="line x" title="249:389	Coverage is the ratio of the number of cases where the interpretation certainty of the output is above a certain threshold and the number of inputs." ></td>
	<td class="line x" title="250:389	By raising the value of the threshold, accuracy also increases (at least theoretically), while coverage decreases." ></td>
	<td class="line x" title="251:389	The system used the Bunruigoihyo thesaurus for the similarity computation, and was evaluated by way of sixfold cross-validation using the same corpus as that used for the experiment described in Section 2.3." ></td>
	<td class="line x" title="252:389	Figure 8 shows the result of the experiment with several values of,~, from which the optimal )~ value seems to be in the range around 0.5." ></td>
	<td class="line x" title="253:389	It can be seen that, as we assumed, both of the above conditions are essential for the estimation of interpretation certainty." ></td>
	<td class="line x" title="254:389	586 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling certainty x x x a x x x (( x b x (a) A X certainty A' X X (I,~', X (( x x x e x b x x x (b) Figure 9 The concept of training utility." ></td>
	<td class="line x" title="255:389	The case where the training utility of a is greater than that of b because a has more unsupervised neighbors is shown in (a); (b) shows the case where the training utility of a is greater than that of b because b closely neighbors e, contained in the database." ></td>
	<td class="line x" title="256:389	3.3 Training Utility The training utility of an example a is greater than that of another example b when the total interpretation certainty of unsupervised examples increases more after training with example a than with example b. Let us consider Figure 9, in which the x-axis mono-dimensionally denotes the semantic similarity between two unsupervised examples, and the y-axis denotes the interpretation certainty of each example." ></td>
	<td class="line x" title="257:389	Let us compare the training utility of the examples a and b in Figure 9(a)." ></td>
	<td class="line x" title="258:389	Note that in this figure, whichever example we use for training, the interpretation certainty for each unsupervised example (x) neighboring the chosen example increases based on its similarity to the supervised example." ></td>
	<td class="line x" title="259:389	Since the increase in the interpretation certainty of a given x becomes smaller as the similarity to a or b diminishes, the training utility of the two examples can be represented by the shaded areas." ></td>
	<td class="line x" title="260:389	The training utility of a is greater as it has more neighbors than b. On the other hand, in Figure 9(b), b has more neighbors than a. However, since b is semantically similar to e, which is already contained in the database, the total increase in interpretation certainty of its neighbors, i.e. the training utility of b, is smaller than that of a. Let AC(x = s,y) be the difference in the interpretation certainty of y c X after training with x c X, taken with the sense s. TU(x = s), which is the training utility function for x taken with sense s, can be computed by Equation (11)." ></td>
	<td class="line x" title="261:389	TU(x = s) = E AC(x = s,y) (11) yEX It should be noted that in Equation (11), we can replace X with a subset of X that consists of neighbors of x. However, in order to facilitate this, an efficient algorithm to search for neighbors of an example is required." ></td>
	<td class="line x" title="262:389	We will discuss this problem in Section 3.5." ></td>
	<td class="line x" title="263:389	Since there is no guarantee that x will be supervised with any given sense s, it can be risky to rely solely on TU(x = s) for the computation of TU(x)." ></td>
	<td class="line x" title="264:389	We estimate TU(x), by the expected value of x, calculating the average of each TU(x = s), weighted by the probability that x takes sense s. This can be realized by Equation (12), where P(slx ) is the probability that x takes the sense s. TU(x) = E P(slx) ' TU(x = s) (12) s Given the fact that (a) P(sIx ) is difficult to estimate in the current formulation, and (b) the cost of computation for each TU(x = s) is not trivial, we temporarily approximate 587 Computational Linguistics Volume 24, Number 4 TU(x) as in Equation (13), where K is a set of the k-best verb sense(s) of x with respect to the interpretation score in the current state." ></td>
	<td class="line x" title="265:389	1 E TU(x = s) (13) TU(x) ; sEK 3.4 Enhancement of Computation In this section, we discuss how to enhance the computation associated with our example sampling algorithm." ></td>
	<td class="line x" title="266:389	First, we note that computation of TU(x = s) in Equation (11) above becomes time consuming because the system is required to search the whole set of unsupervised examples for examples whose interpretation certainty will increase after x is used for training." ></td>
	<td class="line x" title="267:389	To avoid this problem, we could apply a method used in efficient database search techniques, by which the system can search for neighbor examples of x with optimal time complexity (Utsuro et al. 1994)." ></td>
	<td class="line x" title="268:389	However, in this section, we will explain another efficient algorithm to identify neighbors of x, in which neighbors of case fillers are considered to be given directly by the thesaurus structure." ></td>
	<td class="line x" title="269:389	12 The basic idea is the following: the system searches for neighbors of each case filler of x instead of x as a whole, and merges them as a set of neighbors of x. Note that by dividing examples along the lines of each case filler, we can retrieve neighbors based on the structure of the Bunruigoihyo thesaurus (instead of the conceptual semantic space as in Figure 7)." ></td>
	<td class="line x" title="270:389	Let Nx=s,c be a subset of unsupervised neighbors of x whose interpretation certainty will increase after x is used for training, considering only case c of sense s. The actual neighbor set of x with sense s (Nx=s) is then defined as in Equation (14)." ></td>
	<td class="line x" title="271:389	Nx=s=UNx:s,c (14)  Figure 10 shows a fragment of the thesaurus, in which the x and the y's are unsupervised case filler examples." ></td>
	<td class="line x" title="272:389	Symbols el and e2 are case filler examples stored in the database taken as senses sl and s2, respectively." ></td>
	<td class="line x" title="273:389	The triangles represent subtrees of the structure, and the labels ni represent nodes." ></td>
	<td class="line x" title="274:389	In this figure, it can be seen that the interpretation score of Sl never changes for examples other than the children of n4, after x is used for training with sense Sl." ></td>
	<td class="line x" title="275:389	In addition, incorporating x into the database with sense sl never changes the score of examples y for other sense candidates." ></td>
	<td class="line x" title="276:389	Therefore, Nx=sl,c includes only examples dominated by n4, in other words, examples that are closer to x than el in the thesaurus structure." ></td>
	<td class="line x" title="277:389	Since, during the WSD phase, the system determines el as the supervised neighbor of x for sense Sl, identifying Nx=sl,c does not require any extra computational overhead." ></td>
	<td class="line x" title="278:389	We should point out that the technique presented here is not applicable when the vector space model (see Section 2.2) is used for the similarity computation." ></td>
	<td class="line x" title="279:389	However, automatic clustering algorithms, which assign a hierarchy to a set of words based on the similarity between them (such as the one proposed by Tokunaga, Iwayama, and Tanaka \[1995\]), could potentially facilitate the application of this retrieval method to the vector space model." ></td>
	<td class="line x" title="280:389	Second, sample size at each iteration should ideally be one, so as to avoid the supervision of similar examples." ></td>
	<td class="line x" title="281:389	On the other hand, a small sampling size generates a considerable computation overhead for each iteration of the sampling procedure." ></td>
	<td class="line x" title="282:389	This can be a critical problem for statistics-based approaches, as the reconstruction 12 Utsuro's method requires the constiuction of large-scale similarity templates prior to similarity computation (Utsuro et al. 1994), and this is what we would like to avoid." ></td>
	<td class="line x" title="283:389	588 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling J ?7,2 n5 L 7~3 7~4 el y y y x y e2 y y Figure 10 A fragment of the thesaurus including neighbors of x associated with case c. of statistic classifiers is expensive." ></td>
	<td class="line x" title="284:389	However, example-based systems fortunately do not require reconstruction, and examples simply have to be stored in the database." ></td>
	<td class="line x" title="285:389	Furthermore, in each disambiguation phase, our example-based system needs only to compute the similarity between each newly stored example and its unsupervised neighbors, rather than between every example in the database and every unsupervised example." ></td>
	<td class="line x" title="286:389	Let us reconsider Figure 10." ></td>
	<td class="line x" title="287:389	As mentioned above, when x is stored in the database with sense sl, only the interpretation score of y's dominated by n4, i.e., Nx=sl,c, will be changed with respect to sense sl." ></td>
	<td class="line x" title="288:389	This algorithm reduces the time complexity of each iteration from O(N 2) to O(N), given that N is the total number of examples in a given corpus." ></td>
	<td class="line x" title="289:389	3.5 Discussion 3.5.1 Sense Ambiguity of Case Fillers in Selective Sampling." ></td>
	<td class="line x" title="290:389	The semantic ambiguity of case fillers (nouns) should be taken into account during selective sampling." ></td>
	<td class="line x" title="291:389	Figure 11, which uses the same basic notation as Figure 7, illustrates one possible problem caused by case filler ambiguity." ></td>
	<td class="line x" title="292:389	Let xl be a sense of a case filler x, and Yl and y2 be different senses of a case filler y. On the basis of Equation (10), the interpretation certainty of x and y is small in Figures 11(a) and 11(b), respectively." ></td>
	<td class="line x" title="293:389	However, in the situation shown in Figure 11(b), since (a) the task of distinguishing between the verb senses 1 and 2 is easier, and (b) instances where the sense ambiguity of case fillers corresponds to distinct verb senses will be rare, training using either yl or y2 will be less effective than using a case filler of the type of x. It should also be noted that since Bunruigoihyo is a relatively small-sized thesaurus with limited word sense coverage, this problem is not critical in our case." ></td>
	<td class="line x" title="294:389	However, given other existing thesauri like the EDR electronic dictionary (Japan Electronic Dictionary Research Institute 1995) or WordNet (Miller et al. 1993), these two situations should be strictly differentiated." ></td>
	<td class="line x" title="295:389	3.5.2 A Limitation of our Selective Sampling Method." ></td>
	<td class="line x" title="296:389	Figure 12, where the basic notation is the same as in Figure 7, exemplifies a limitation of our sampling method." ></td>
	<td class="line x" title="297:389	In this figure, the only supervised examples contained in the database are el and e2, and x represents an unsupervised example belonging to sense 2." ></td>
	<td class="line x" title="298:389	Given this scenario, x is informative because (a) it clearly evidences the semantic vicinity of sense 2, and (b) without x as sense 2 in the database, the system may misinterpret other examples neighboring x. However, in our current implementation, the training utility of x would be small because it would be mistakenly interpreted as sense I with great certainty due to its relatively close semantic proximity to el." ></td>
	<td class="line x" title="299:389	Even if x has a number of unsupervised neighbors, the total increment of their interpretation certainty cannot be expected to be large." ></td>
	<td class="line x" title="300:389	This shortcoming often presents itself when the semantic vicinities of different 589 Computational Linguistics Volume 24, Number 4 sense 1 / (.~sense 2 sense 1 sense 2 (a) (b) Figure 11 Two separate scenarios in which the interpretation certainty of x is small." ></td>
	<td class="line x" title="301:389	In (a), interpretation certainty of x is small because x lies in the intersection of distinct verb senses; in (b), interpretation certainty of y is small because y is semantically ambiguous." ></td>
	<td class="line x" title="302:389	sense ~ sense 2 Figure 12 The case where informative example x is not selected." ></td>
	<td class="line x" title="303:389	verb senses are closely aligned or their semantic ranges are not disjunctive." ></td>
	<td class="line x" title="304:389	Here, let us consider Figure 3 again, in which the nominative case would parallel the semantic space shown in Figure 12 more closely than the accusative." ></td>
	<td class="line x" title="305:389	Relying more on the similarity in the accusative (the case with greater CCD) as is done in our system, we aim to map the semantic space in such a way as to achieve higher semantic disparity and minimize this shortcoming." ></td>
	<td class="line x" title="306:389	4." ></td>
	<td class="line x" title="307:389	Evaluation 4.1 Comparative Experimentation ~n order to investigate the effectiveness of our example sampling method, we conducted an experiment in which we compared the following four sampling methods:  a control (random), in which a certain proportion of a given corpus is randomly selected for training,  uncertainty sampling (US), in which examples with minimum interpretation certainty are selected (Lewis and Gale 1994),  committee-based sampling (CBS) (Engelson and Dagan 1996),  our method based on the notion of training utility (TU)." ></td>
	<td class="line x" title="308:389	590 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling We elaborate on uncertainty sampling and committee-based sampling in Section 4.2." ></td>
	<td class="line x" title="309:389	We compared these sampling methods by evaluating the relation between the number of training examples sampled and the performance of the system." ></td>
	<td class="line x" title="310:389	We conducted sixfold cross-validation and carried out sampling on the training set." ></td>
	<td class="line x" title="311:389	With regard to the training/test data set, we used the same corpus as that used for the experiment described in Section 2.3." ></td>
	<td class="line x" title="312:389	Each sampling method uses examples from IPAL to initialize the system, with the number of example case fillers for each case being an average of about 3.7." ></td>
	<td class="line x" title="313:389	For each sampling method, the system uses the Bunruigoihyo thesaurus for the similarity computation." ></td>
	<td class="line x" title="314:389	In Table 2 (in Section 2.3), the column of 'accuracy' for 'BGH' denotes the accuracy of the system with the entire set of training data contained in the database." ></td>
	<td class="line x" title="315:389	Each of the four sampling methods achieved this figure at the conclusion of training." ></td>
	<td class="line x" title="316:389	We evaluated each system performance according to its accuracy, that is the ratio of the number of correct outputs, compared to the total number of inputs." ></td>
	<td class="line x" title="317:389	For the purpose of this experiment, we set the sample size to 1 for each iteration, A = 0.5 for Equation (10), and k = 1 for Equation (13)." ></td>
	<td class="line x" title="318:389	Based on a preliminary experiment, increasing the value of k either did not improve the performance over that for k = 1, or lowered the overall performance." ></td>
	<td class="line x" title="319:389	Figure 13 shows the relation between the number of training data sampled and the accuracy of the system." ></td>
	<td class="line x" title="320:389	In Figure 13, zero on the x-axis represents the system using only the examples provided by 1PAL." ></td>
	<td class="line x" title="321:389	Looking at Figure 13 one can see that compared with random sampling and committee-based sampling, our sampling method reduced the number of the training data required to achieve any given accuracy." ></td>
	<td class="line x" title="322:389	For example, to achieve an accuracy of 80%, the number of training data required for our method was roughly one-third of that for random sampling." ></td>
	<td class="line x" title="323:389	Although the accuracy of our method was surpassed by that of uncertainty sampling for larger sizes of training data, this minimal difference for larger data sizes is overshadowed by the considerable performance gain attained by our method for smaller data sizes." ></td>
	<td class="line x" title="324:389	Since IPAL has, in a sense, been manually selectively sampled in an attempt to model the maximum verb sense coverage, the performance of each method is biased by the initial contents of the database." ></td>
	<td class="line x" title="325:389	To counter this effect, we also conducted an experiment involving the construction of the database from scratch, without using examples from IPAL." ></td>
	<td class="line x" title="326:389	During the initial phase, the system randomly selected one example for each verb sense from the training set, and a human expert provided the correct interpretation to initialize the system." ></td>
	<td class="line x" title="327:389	Figure 14 shows the performance of the various methods, from which the same general tendency as seen in Figure 13 is observable." ></td>
	<td class="line x" title="328:389	However, in this case, our method was generally superior to other methods." ></td>
	<td class="line x" title="329:389	Through these comparative experiments, we can conclude that our example sampling method is able to decrease the number of training data, i.e., the overhead for both supervision and searching, without degrading the system performance." ></td>
	<td class="line x" title="330:389	4.2 Related Work 4.2.1 Uncertainty Sampling." ></td>
	<td class="line x" title="331:389	The procedure for uncertainty sampling (Lewis and Gale 1994) is as follows, where C(x) represents the interpretation certainty for an example x (see our sampling procedure in Section 3.1 for comparison): 1." ></td>
	<td class="line x" title="332:389	WSD(D,X) 2." ></td>
	<td class="line x" title="333:389	e ~ argminxcx C(x) 591 Computational Linguistics Volume 24, Number 4 85 I I I I I 80 {i 65 ~__._ ~---?" ></td>
	<td class="line x" title="334:389	~----Z;:;; = S  ~  ~." ></td>
	<td class="line x" title="335:389	~_  ~  2I~.:.:.: .:'''''= f,<;I  ~  /:',,~' ~  I~  .El  .El-'   /o(., ( .g .,1,'7 ~', ' .~/ /,'7 1 11 TU, US ----~  ' CBS  ~  Jl '!/ random  ~  r I I I I I 0 200 400 600 800 1000 1200 no." ></td>
	<td class="line x" title="337:389	of training data sampled Figure 13 The relation between the number of training data sampled and the accuracy of the system." ></td>
	<td class="line x" title="338:389	3." ></td>
	<td class="line x" title="339:389	D ~ DU {e}, X +XN {e} 4." ></td>
	<td class="line x" title="340:389	goto i Let us discuss the theoretical difference between this and our method." ></td>
	<td class="line x" title="341:389	Considering Figure 9 again, one can see that the concept of training utility is supported by the following properties: . 2." ></td>
	<td class="line x" title="342:389	an example that neighbors more unsupervised examples is more informative (Figure 9(a)), an example less similar to one already existing in the database is more informative (Figure 9(b))." ></td>
	<td class="line x" title="343:389	Uncertainty sampling directly addresses the second property but ignores the first." ></td>
	<td class="line x" title="344:389	It differs from our method more crucially when more unsupervised examples remain, because these unsupervised examples have a greater influence on the computation of training utility." ></td>
	<td class="line x" title="345:389	This can be seen in the comparative experiments in Section 4, in which our method outperformed uncertainty sampling to the highest degree in early stages." ></td>
	<td class="line x" title="346:389	4.2.2 Committee-based Sampling." ></td>
	<td class="line x" title="347:389	In committee-based sampling (Engelson and Dagan 1996), which follows the 'query by committee' principle (Seung, Opper, and 592 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling 85 8O 75 60 55 50 45 0 i i i i /." ></td>
	<td class="line x" title="348:389	.El  ~.Q  # TU, US ----~  CBS  ~  random  ~  I I I I 200 400 600 800 no." ></td>
	<td class="line x" title="349:389	of training data sampled 1000 Figure 14 The relation between the number of training data sampled and the accuracy of the system without using examples from IPAL." ></td>
	<td class="line x" title="350:389	Sompolinsky 1992), the system selects samples based on the degree of disagreement between models randomly taken from a given training set (these models are called 'committee members')." ></td>
	<td class="line x" title="351:389	This is achieved by iteratively repeating the steps given below, in which the number of committee members is given as two without loss of generality:  2." ></td>
	<td class="line x" title="352:389	. draw two models randomly, classify unsupervised example x according to each model, producing classifications C1 and C2, if C1 # C2 (the committee members disagree), select x for the training of the system." ></td>
	<td class="line x" title="353:389	Figure 15 shows a typical disparity evident between committee-based sampling and our sampling method." ></td>
	<td class="line x" title="354:389	The basic notation in this figure is the same as in Figure 7, and both x and y denote unsupervised examples, or more formally D = {el, e2}, and X = {x, y}." ></td>
	<td class="line x" title="355:389	Assume a pair of committee members {el} and {e2 } have been selected from the database D. In this case, the committee members disagree as to the interpretations of both x and y, and consequently, either example can potentially be selected as a sample for the next iteration." ></td>
	<td class="line x" title="356:389	In fact, committee-based sampling tends to require a number of similar examples (similar to el and y) in the database, otherwise committee members taken from the database will never agree." ></td>
	<td class="line x" title="357:389	This is in contrast to our method, in which similar examples are less informative." ></td>
	<td class="line x" title="358:389	In our method, therefore, x is preferred to y as a sample." ></td>
	<td class="line x" title="359:389	This contrast can also correlate to the fact that committee-based sampling is currently applied to statistics-based language models (HMM classifiers), in other words, statistical models generally require that the distribution of the training data 593 Computational Linguistics Volume 24, Number 4 _sense 1 s sense 2 Figure 15 A case where either x or y can be selected in committee-based sampling." ></td>
	<td class="line x" title="360:389	reflects that of the overall text." ></td>
	<td class="line x" title="361:389	Through this argument, one can assume that committeebased sampling is better suited to statistics-based systems, while our method is more suitable for example-based systems." ></td>
	<td class="line x" title="362:389	Engelson and Dagan (1996) criticized uncertainty sampling (Lewis and Gale 1994), which they call a 'single model' approach, as distinct from their 'multiple model' approach: sufficient statistics may yield an accurate 0.51 probability estimate for a class c in a given example, making it certain that c is the appropriate classificationJ 3 However, the certainty that c is the correct classification is low, since there is a 0.49 chance that c is the wrong class for the example." ></td>
	<td class="line x" title="363:389	A single model can be used to estimate only the second type of uncertainty, which does not correlate directly with the utility of additional training." ></td>
	<td class="line x" title="364:389	(p. 325) We note that this criticism cannot be applied to our sampling method, despite the fact that our method falls into the category of a single model approach." ></td>
	<td class="line x" title="365:389	In our sampling method, given sufficient statistics, the increment of the certainty degree for unsupervised examples, i.e., the training utility of additional supervised examples, becomes small (theoretically, for both example-based and statistics-based systems)." ></td>
	<td class="line x" title="366:389	Thus, the utility factor can be considered to correlate directly with additional training, for our method." ></td>
	<td class="line x" title="367:389	5." ></td>
	<td class="line x" title="368:389	Conclusion Corpus-based approaches have recently pointed the way to a promising trend in word sense disambiguation." ></td>
	<td class="line x" title="369:389	However, these approaches tend to require a considerable overhead for supervision in constructing a large-sized database, additionally resulting in a computational overhead to search the database." ></td>
	<td class="line x" title="370:389	To overcome these problems, our method, which is currently applied to an example-based verb sense disambiguation system, selectively samples a smaller-sized subset from a given example set." ></td>
	<td class="line x" title="371:389	This method is expected to be applicable to other example-based systems." ></td>
	<td class="line x" title="372:389	Applicability for other types of systems needs to be further explored." ></td>
	<td class="line x" title="373:389	The process basically iterates through two phases: (normal) word sense disambiguation and a training phase." ></td>
	<td class="line x" title="374:389	During the disambiguation phase, the system is provided with sentences containing a polysemous verb, and searches the database for the 13 By appropriate classification, Engelson and Dagan mean the classification given by a perfectly trained model." ></td>
	<td class="line x" title="375:389	594 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling most semantically similar example to the input (nearest neighbor resolution)." ></td>
	<td class="line x" title="376:389	Thereafter, the verb is disambiguated by superimposing the sense of the verb appearing in the supervised example." ></td>
	<td class="line x" title="377:389	The similarity between the input and an example, or more precisely the similarity between the case fillers included in them, is computed based on an existing thesaurus." ></td>
	<td class="line x" title="378:389	In the training phase, a sample is then selected from the system outputs and provided with the correct interpretation by a human expert." ></td>
	<td class="line x" title="379:389	Through these two phases, the system iteratively accumulates supervised examples into the database." ></td>
	<td class="line x" title="380:389	The critical issue in this process is to decide which example should be selected as a sample in each iteration." ></td>
	<td class="line x" title="381:389	To resolve this problem, we considered the following properties: (a) an example that neighbors more unsupervised examples is more influential for subsequent training, and therefore more informative, and (b) since our verb sense disambiguation is based on nearest neighbor resolution, an example similar to one already existing in the database is redundant." ></td>
	<td class="line x" title="382:389	Motivated by these properties, we introduced and formalized the concept of training utility as the criterion for example selection." ></td>
	<td class="line x" title="383:389	Our sampling method always gives preference to that example which maximizes training utility." ></td>
	<td class="line x" title="384:389	We reported on the performance of our sampling method by way of experiments in which we compared our method with random sampling, uncertainty sampling (Lewis and Gale 1994), and committee-based sampling (Engelson and Dagan 1996)." ></td>
	<td class="line x" title="385:389	The result of the experiments showed that our method reduced both the overhead for supervision and the overhead for searching the database to a larger degree than any of the above three methods, without degrading the performance of verb sense disambiguation." ></td>
	<td class="line x" title="386:389	Through the experiment and discussion, we claim that uncertainty sampling considers property (b) mentioned above, but lacks property (a)." ></td>
	<td class="line x" title="387:389	We also claim that committee-based sampling differs from our sampling method in terms of its suitability to statistics-based systems as compared to example-based systems." ></td>
	<td class="line x" title="388:389	Acknowledgments The authors would like to thank Manabu Okumura (JAIST, Japan), Timothy Baldwin (TITECH, Japan), Michael Zock (LIMSI, France), Dan Tufts (Romanian Academy, Romania) and anonymous reviewers for their comments on an earlier version of this paper." ></td>
	<td class="line x" title="389:389	This research is partially supported by a Research Fellowship of the Japan Society for the Promotion of Science for Young Scientists." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W98-0704
The Use Of WordNet In Information Retrieval
Mandala, Rila;Tokunaga, Takenobu;Tanaka, Hozumi;"></td>
	<td class="line x" title="1:128	The Use of WordNet in Information Retrieval Rila Mandala, Tokunaga Takenobu, and Tanaka Hozumi Department of Computer Science Tokyo Institute of Technology {rila, take, t anaka}@cs, t itech, ac." ></td>
	<td class="line x" title="2:128	j p Abstract WordNet has been used in information retrieval research by many researchers, but failed to improve the performance of their retrieval system." ></td>
	<td class="line x" title="3:128	Thereby in this paper we investigate why the use of WordNet has not been successful." ></td>
	<td class="line x" title="4:128	Based on this analysis we propose a method of making WordNet more useful in information retrieval applications." ></td>
	<td class="line x" title="5:128	Experiments using several standard information retrieval test collections show that our method results in a significant improvement of information retrieval performance." ></td>
	<td class="line x" title="6:128	1 Introduction Development of WordNet began in 1985 at Princeton University (Miller, 1990)." ></td>
	<td class="line x" title="7:128	A team lead by Prof. George Miller aimed to create a source of lexical knowledge whose organization would reflect some of the recent findings of psycholinguistic research into the human lexicon." ></td>
	<td class="line x" title="8:128	WordNet has been used in numerous natural language processing, such as part of speech tagging (Segond et al. , 97), word sense disambiguation (Resnik, 1995), text categorization (Gomez-Hidalgo and Rodriguez, 1997), information extraction (Chai and Biermann, 1997), and so on with considerable success." ></td>
	<td class="line x" title="9:128	However the usefulness of WordNet in information retrieval applications has been debatable." ></td>
	<td class="line x" title="10:128	Information retrieval is concerned with locating documents relevant to a user's information needs from a collection of documents." ></td>
	<td class="line x" title="11:128	The user describes his/her information needs with a query which consists of a number of words." ></td>
	<td class="line x" title="12:128	The information retrieval system compares the query with documents in the collection and returns the documents that are likely to satisfy the user's information requirements." ></td>
	<td class="line x" title="13:128	A fundamental weakness of current information retrieval methods is that the vocabulary that searchers use is often not the same as the one by which the information has been indexed." ></td>
	<td class="line x" title="14:128	Query expansion is one method to solve this problem." ></td>
	<td class="line x" title="15:128	The query is expanded using terms which have similar meaning or bear some relation to those in the query, increasing the chances of matching words in relevant documents." ></td>
	<td class="line x" title="16:128	Expanded terms are generally taken from a thesaurus." ></td>
	<td class="line x" title="17:128	Obviously, given a query, the information retrieval system must present all useful articles to the user." ></td>
	<td class="line x" title="18:128	This objective is measured by recall, i.e. the proportion of relevant articles retrieved by the system." ></td>
	<td class="line x" title="19:128	Conversely, the information retrieval system must not present any useless article to the user." ></td>
	<td class="line x" title="20:128	This criteria is measured by precision, i.e. the proportion of retrieved articles that are relevant." ></td>
	<td class="line x" title="21:128	Voorhees used WordNet as a tool for query expansion (Voorhees, 1994)." ></td>
	<td class="line x" title="22:128	She conducted experiments using the TREC collection (Voorhees and Harman, 1997) in which all terms in the queries were expanded using a combination of synonyms, hypernyms, and hyponyms." ></td>
	<td class="line x" title="23:128	She set the weights of the words contained in the original query to 1, and used a combination of 0.1, 0.3, 0.5, 1, and 2 for the expansion terms." ></td>
	<td class="line x" title="24:128	She then used the SMART Information Retrieval System Engine (Salton, 1971) to retrieve the documents." ></td>
	<td class="line x" title="25:128	Through this method, Voorhees only succeeded in improving the performance on short queries and a tittle with no significant improvement for long queries." ></td>
	<td class="line x" title="26:128	She further tried to use WordNet as a tool for word sense disambiguation (Voorhees, 1993) and applied it to text retrieval, but the performance of retrieval was degraded." ></td>
	<td class="line x" title="27:128	Stairmand (Stairmand, 1997) used WordNet to compute lexical cohesion according to the method suggested by Morris (Morris and Hirst, 199 I), and applied this to information retrieval." ></td>
	<td class="line x" title="28:128	31 ! !" ></td>
	<td class="line x" title="29:128	I ! I I I I i I I I I I I I I I He concluded that his method could not be applied to a fully-functional information retrieval system." ></td>
	<td class="line x" title="30:128	Smeaton (Smeaton and Berrut, 1995) tried to expand the queries of the TREC-4 collection with various strategies of weighting expansion terms, along with manual and automatic word sense disambiguation techniques." ></td>
	<td class="line x" title="31:128	Unfortunately all strategies degraded the retrieval performance." ></td>
	<td class="line x" title="32:128	Instead of matching terms in queries and documents, Richardson (Richardson and Smeaton, 1995) used WordNet to compute the semantic distance between concepts or words and then used this term distance to compute the similarity between a query and a document." ></td>
	<td class="line x" title="33:128	Although he proposed two methods to compute semantic distances, neither of them increased the retrieval performance." ></td>
	<td class="line x" title="34:128	2 What's wrong with WordNet?" ></td>
	<td class="line x" title="35:128	In this section we analyze why WordNet has failed to improve information retrieval performance." ></td>
	<td class="line x" title="36:128	We run exact-match retrieval against 9 small standard test collections in order to observe this phenomenon." ></td>
	<td class="line x" title="37:128	An information retrieval test collection consists of a collection of documents along with a set of test queries." ></td>
	<td class="line x" title="38:128	The set of relevant documents for each test query is also given, so that the performance of the information retrieval system can be measured." ></td>
	<td class="line x" title="39:128	We expand queries using a combination of synonyms, hypernyms, and hyponyms in WordNet." ></td>
	<td class="line x" title="40:128	The results are shown in Table 1." ></td>
	<td class="line x" title="41:128	In Table 1 we show the name of the test collection (Collection), the total number of documents (#Doc) and queries (#Query), and all relevant documents for all queries (#Rel) in that collection." ></td>
	<td class="line x" title="42:128	For each document collection, we indicate the total number of relevant documents retrieved (Rel-ret), the recall (~), the total number of documents retrieved (Retdocs), and the precision t Rel-ret ~ for each of Ret-docs j no expansion (Base), expansion with synonyms (Exp. I), expansion with synonyms and hypernyms (Exp. II), expansion with synonyms and hyponyms (Exp. III), and expansion with synonyms, hypernyms, and hyponyms (Exp. IV)." ></td>
	<td class="line x" title="43:128	From the results in Table 1, we can conclude that query expansion can increase recall performance but unfortunately degrades precision 32 performance." ></td>
	<td class="line x" title="44:128	We thus turned to investigation of why all the relevant documents could not be retrieved with the query expansion method above." ></td>
	<td class="line x" title="45:128	Some of the reasons are stated below :  Two terms that seem to be interrelated have different parts of speech in WordNet." ></td>
	<td class="line x" title="46:128	This is the case between stochastic (adjective) and statistic (noun)." ></td>
	<td class="line x" title="47:128	Since words in WordNet are grouped on the basis of part of speech in WordNet, it is not possible to find a relationship between terms with different parts of speech." ></td>
	<td class="line x" title="48:128	 Most of relationships between two terms are not found in WordNet." ></td>
	<td class="line x" title="49:128	For example how do we know that Sumitomo Bank is a Japanese company ?  Some terms are not included in WordNet (proper name, etc)." ></td>
	<td class="line x" title="50:128	To overcome all the above problems, we propose a method to enrich WordNet with an automatically constructed thesaurus." ></td>
	<td class="line x" title="51:128	The idea underlying this method is that an automatically constructed thesaurus could complement the drawbacks of WordNet." ></td>
	<td class="line x" title="52:128	For example, as we stated earlier, proper names and their interrelations among them are not found in WordNet, but if proper names and other terms have some strong relationship, they often cooccur in the document, so that their relationship may be modelled by an automatically constructed thesaurus." ></td>
	<td class="line x" title="53:128	Polysemous words degrade the precision of information retrieval since all senses of the original query term are considered for expansion." ></td>
	<td class="line x" title="54:128	To overcome the problem of polysemous words, we apply a restriction in that queries are expanded by adding those terms that are most similar to the entirety of query terms, rather than selecting terms that are similar to a single term in the query." ></td>
	<td class="line x" title="55:128	In the next section we describe the details of our method 3 Method 3.1 Co-occurrence-based Thesaurus The general idea underlying the use of term cooccurrence data for thesaurus construction is that words that tend to occur together in documents are likely to have similar, or related, Collection ADI Table 1: Term Expansion Experiment #Doc #Query i #Rel, 82 35 170 Rel-ret Recall Ret-docs Precision Results using WordNet CACM 3204 64 796 Rel-ret Recall Ret-docs Precision i CISI 1460 112 3114 Rel-ret Recall Ret-docs Precision CRAN 1398 225i 1838' Rel-ret ! Recall,~ Ret-docs Precision J i INsPEc 12684 84 2543 Rel-ret i Recall Ret-docs Precision I i LISA 6004 35 ' 339 Rel-ret Recall Ret-docs Precision I I ME\[) 1033 30 696 Rel-ret Recall Ret-docs i Precision I i NPL 11429 100 2083 Rel-ret Recall Ret-docs Precision Th'vIE i 423 24 324 i Rel-ret Recall Ret-docs Precision Base 157 0.9235 2,063 0.0761 738 0.9271 67,950 0.0109 2,952 0.9479 87,895 0.0336 1,769 0.9625 199,469 0.0089 2,508 0.9862 564,809 0.0044 339 1.0000 148,547 0.0023 639 0.9181 12,021 0.0532 2,061 0.9894 267,158 0.0077 324 1.000 23,014 0.0141 Exp. I 159 0.9353 2,295 0.0693 756 0.9497 86,552 0.0087 3015 0.9682 98,844 0.0305 1,801 0.9799 247,212 0.0073 2,531 0.9953 735,931 0.0034 339 1.0000 171,808 0.0020 662 0.9511 16,758 0.0395 2,071 0.9942 395,280 0.0052 324 1.000 29,912 0.0108 Exp. II 166 0.9765 2,542 0.0653 766 0.9623 101,154 0.0076 3,076 0.9878 106,275 0.0289 1,823 0.9918 284,026 0.0064 2,538 0.9980 852,056 0.0030 339 1.0000 184,101 0.0018 670 0.9626 22,316 0.0300 2,073 0.9952 539,048 0.0038 324 1.000 33,650 0.0096 Exp. III 169 0.9941 2,737 0.0617 773 0.9711 109,391 0.0070 3,104 0.9968 108,970 0.0284 1,815 0.9875 287,028 0.0063 2,536 0.9972 869,364 0.0029 339 1.0000 188,289 0.0018 671 0.9640 22,866 0.0293 2,072 0.9942 577,033 0.0036 324 1.000 32,696 0.0095 Exp. IV 169 0.9941 2,782 0.0607 773 0.9711 116,001 0.0067 3,106 0.9974 109,674 0.0283 1,827 0.9940 301,314 0.0060 2,542 0.9996 912,810 0.0028 339 1.0000 189,784 0.0018 673 0.9670 25,250 0.0267 2,074 0.9957 678,828 0.0031 324 1.000 34,443 0.0094 meanings." ></td>
	<td class="line x" title="56:128	Co-occurrence data thus provides a statistical method for automatically identifying semantic relationships that are normally contained in a hand-made thesaurus." ></td>
	<td class="line x" title="57:128	Suppose two words (A and B) occur fa and fb times, respectively, and cooccur fc times, then the similarity between A and B can be calculated using a similarity coefficient such as the Dice Coefficient : 2xf 3.2 Predicate-Argument-based Thesaurus In contrast with the previous section, this method attempts to construct a thesaurus according to predicate-argument structures." ></td>
	<td class="line x" title="58:128	The use of this method for thesaurus construction is based on the idea that there are restrictions on what words can appear in certain environments, and in particular, what words can be arguments of a certain predicate." ></td>
	<td class="line x" title="59:128	For example, a cat may walk, bite, but can not fly." ></td>
	<td class="line x" title="60:128	Each noun may therefore be characterized according to the 33 verbs or adjectives that it occurs with." ></td>
	<td class="line x" title="61:128	Nouns may then be grouped according to the extent to which they appear in similar constructions." ></td>
	<td class="line x" title="62:128	First, all the documents are parsed using the Apple Pie Parser, which is a probabilistic chart parser developed by Satoshi Sekine (Sekine and Grisbman, 1995)." ></td>
	<td class="line x" title="63:128	Then the following syntactic structures are extracted :  Subject-Verb  Verb-Object  Adjective-Noun Each noun has a set of verbs and adjective that it occurs with, and for each such relationship, a dice coefficient value is calculated." ></td>
	<td class="line x" title="64:128	2Xh.b(vi,n i) Csub(Vi, nj) -l(v~)+L,b(nj)' where fsub(Vi, nj) is the frequency of noun nj occurring as the subject of verb vi, fsub(nj) is the frequency of the noun nj occurring as subject of any verb, and f(vi) is the frequency of the verb vi Cobj(Vi, n3) = 2/obj(.,,~) f(vl)+fobj (nj)' where fobi(vi, ni) is the frequency of noun n i occurring as the object of verb vi, fobj(nj) is the frequency of the noun nj occurring as object of any verb, and f(vi) is the frequency of the verb vi  C~aj(a~,n3)= 2/od~(.,,.~) f(ai)'l'fadj(nj) ' where f(ai, nj) is the frequency of noun nj occurring as argument of adjective ai, fadi(nj) is the frequency of the noun n i occurring as argument of any adjective, and f(a 0 is the frequency of the adjective ai We define the object similarity of two nouos with respect to one predicate, as the minimum of each dice coefficient with respect to that predicate, i.e. SI~'t/I, ub(Vi, rlj, nk)=minC.ub(Vi, nj), C.ub(Vi, nk)} SIMobi(vi, n i, n~)=rninCobj (vi, nj), Cob1 (vi, nh) } $IM~dj(ai, n i, nk)=minC~dj(a~, n j), C~dj(a,, nk)} Finally the overall similarity between two nouns is defined as the average of all the similarities between those two nouns for all predicateargument structures." ></td>
	<td class="line x" title="67:128	34 3.3 Expansion Term Weighting Method A query q is represented by a vector -~ = (ql, q2, , qn), where the qi's are the weights of the search terms ti contained in query q. The similarity between a query q and a term tj can be defined as belows : simqt(q, tj) = ~ qi * sirn(ti, tj) ti E q Where the value of sim(ti, tj) can be defined as the average of the similarity values in the three types of thesaurus." ></td>
	<td class="line x" title="68:128	Since in WordNet there are no similarity weights, when there is a relation between two terms in WordNet, their similarity is taken from the average of the similarity between those two terms in the cooccurrence-based and in predicate-argumentbased thesauri." ></td>
	<td class="line x" title="69:128	With respect to the query q, all the terms in the collection can now be ranked according to their simqt." ></td>
	<td class="line x" title="70:128	Expansion terms are terms tj with high simqt(q, tj)." ></td>
	<td class="line x" title="71:128	The weight(q, tj) of an expansion term tj is defined as a function of simqt(q, tj): weight(q, tj) = simqt(q, tj) t, eq qi where 0 _< weight(q, tj) <_ 1." ></td>
	<td class="line x" title="72:128	An expansion term gets a weight of 1 if its similarity to all the terms in the query is 1." ></td>
	<td class="line x" title="73:128	Expansion terms with similarity 0 to all the terms in the query get a weight of 0." ></td>
	<td class="line x" title="74:128	The weight of an expansion term depends both on the entire retrieval query and on the similarity between the terms." ></td>
	<td class="line x" title="75:128	The weight of an expansion term can be interpreted mathematically as the weighted mean of the similarities between the term tj and all the query terms." ></td>
	<td class="line x" title="76:128	The weight of the original query terms are the weighting factors of those similarities." ></td>
	<td class="line x" title="77:128	Therefore the query q is expanded by adding the following query : ~e = (al, a2,  , at) where aj is equal to weight(q, tj) iftj belongs to the top r ranked terms." ></td>
	<td class="line x" title="78:128	Otherwise a i is equal to 0." ></td>
	<td class="line x" title="79:128	The resulting expanded query is : where the o is defined as the concatenation operator." ></td>
	<td class="line x" title="80:128	The method above can accommodate the polysemous word problem, because an expansion term which is taken f~om a different sense to the original query term is given very low weight." ></td>
	<td class="line x" title="81:128	4 Experimental Results In order to evaluate the effectiveness of the proposed method in the previous section we conducted experiments using the WSJ, CACM, INSPEC, CISI, Cranfield, NPL, and LISA test collections." ></td>
	<td class="line x" title="82:128	The WSJ collection comprises part of the TREC collection (Voorhees and Harman, 1997)." ></td>
	<td class="line x" title="83:128	As a baseline we used SMART (Salton, 1971) without expansion." ></td>
	<td class="line x" title="84:128	SMART is an information retrieval engine based on the vector space model in which term weights are calculated based on term frequency, inverse document frequency and document length normalization." ></td>
	<td class="line x" title="85:128	The results are shown in Table 2." ></td>
	<td class="line x" title="86:128	This table shows the average of 11 point uninterpolated recall-precision for each of baseline, expansion using only WordNet, expansion using only predicate-argument-based thesaurus, expansion using only cooccurrence-based thesaurus, and expansion using all of them." ></td>
	<td class="line x" title="87:128	For each method we give the percentage of improvement over the baseline." ></td>
	<td class="line x" title="88:128	It is shown that the performance using the combined thesauri for query expansion is better than both SMART and using just one type of thesaurus." ></td>
	<td class="line x" title="89:128	Table 2: Thesauri Experiment Result using Combined CoU Ba~e WordNet only wsJ 0.245 o.28z (+2.0%) CACM 0.269 0.281 ~+4.5%) INSPEC 0.273 0.283 (+3.7%) czsz 0.2is 0.23z (+7 2%) Cran 0.412 -0.421 ~+= 3%) NPL 0.201 0.210 (+4.2%) LISA i 0.304 0.313 I, (+3,1%) Expand~l with Pred-ar$ Cooccur only 0.258 (+5.2%) 0.29\[ (+8.3%) 0.284 (+4.3%) O. 238 (+9.4%) 0.441 (+7.0%) 0.217 (+8.t%) 0.327 (+7.o%) Combined only 0.294 0.384 (+t0.8%) (+58.7%) 0.297 0.533 (+zo.8%) (+98.2%) 0.328 0.472 (+20.4%) (+73.1%) 0.262 0.301 (+21.8%) (+81.3%) 0.487 0.667 (+zs.3%) (+82.z%) 0.238 0.333 (+Z7.5%) (+65.5%) 0.369 0,485 (+21.4%) (+~9.7%) 35 5 Discussions In this section we discuss why our method of using WordNet is able to improve the performance of information retrieval." ></td>
	<td class="line x" title="90:128	The important points of our method are :  the coverage of WordNet is broadened  weighting method The three types of thesaurus we used have different characteristics." ></td>
	<td class="line x" title="91:128	Automatically constructed thesauri add not only new terms but also new relationships not found in WordNet." ></td>
	<td class="line x" title="92:128	If two terms often cooccur together in a document then those two terms are likely bear some relationship." ></td>
	<td class="line x" title="93:128	Why not only use the automatically constructed thesauri ? The answer to this is that some relationships may be missing in the automatically constructed thesauri." ></td>
	<td class="line x" title="94:128	For example, consider the words tumor and turnout." ></td>
	<td class="line x" title="95:128	These words certainly share the same context, but would never appear in the same document, at least not with a frequency recognized by a cooccurrence-based method." ></td>
	<td class="line x" title="96:128	In general, different words used to describe similar concepts may never be used in the same document, and are thus missed by the cooccurrence methods." ></td>
	<td class="line x" title="97:128	However their relationship may be found in the WordNet thesaurus." ></td>
	<td class="line x" title="98:128	The second point is our weighting method." ></td>
	<td class="line x" title="99:128	As already mentioned before, most attempts at automatically expanding queries by means of WordNet have failed to improve retrieval effectiveness." ></td>
	<td class="line x" title="100:128	The opposite has often been true: expanded queries were less effective than the original queries." ></td>
	<td class="line x" title="101:128	Beside the 'incomplete' nature of WordNet, we believe that a further problem, the weighting of expansion terms, has not been solved." ></td>
	<td class="line x" title="102:128	All weighting methods described in the past researches of query expansion using WordNet have been based on 'trial and error' or adhoc methods." ></td>
	<td class="line x" title="103:128	That is, they have no underlying justification." ></td>
	<td class="line x" title="104:128	The advantages of our weighting method are:  the weight of each expansion term considers the similarity of that term with all terms in the original query, rather than to just one or some query terms." ></td>
	<td class="line x" title="105:128	 the weight of the expansion term accommodates the po\[ysemous word problem." ></td>
	<td class="line x" title="106:128	This method can accommodate the polysemous word problem, because an expansion term taken from a different sense to the original query term sense is given very low weight." ></td>
	<td class="line x" title="107:128	The reason for this is that, the weighting method depends on all query terms and all of the thesauri." ></td>
	<td class="line x" title="108:128	For example, the word bank has many senses in WordNet." ></td>
	<td class="line x" title="109:128	Two such senses are the financial institution and the river edge senses." ></td>
	<td class="line x" title="110:128	In a document collection relating to financial banks, the river sense of bank will generally not be found in the eooccurmnce-based thesaurus because of a lack of articles talking about rivers." ></td>
	<td class="line x" title="111:128	Even though (with small possibility) there may be some documents in the collection talking about rivers, ff the query contained the finance sense of bank then the other terms in the query would also concerned with finance and not rivers." ></td>
	<td class="line x" title="112:128	Thus rivers would only have a relationship with the bank term and there would be no relationships with other terms in the original query, resulting in a low weight." ></td>
	<td class="line x" title="113:128	Since our weighting method depends on both query in its entirety and similarity in the three thesauri, the wrong sense expansion terms are given very low weight." ></td>
	<td class="line x" title="114:128	6 Related Research Smeaton (Smeaton and Berrut, 1995) and Voorhees (Voorhees, 1994) have proposed an expansion method using WordNet." ></td>
	<td class="line x" title="115:128	Our method differs from theirs in that we enrich the coverage of WordNet using two methods of automatic thesatmm construction, and we weight the expausion term appropriately so that it can accommodate the polysemous word problem." ></td>
	<td class="line x" title="116:128	Although Stairmand (Stairmand, 1997) and Richardson (Richardson and Smeaton, 1995) have proposed the use of WordNet in information retrieval, they did not used WordNet in the query expansion framework." ></td>
	<td class="line nc" title="117:128	Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie (Hindle, 1990), although Hindle did not apply it to information retrieval." ></td>
	<td class="line o" title="118:128	Instead, he used mutual information statistics as a Similarity coefficient, wheras we used the Dice coefficient for normalization purposes." ></td>
	<td class="line n" title="119:128	Hindle only extracted the subject-verb and the object-verb predicatearguments, while we also extract adjective-noun predicate-arguments." ></td>
	<td class="line x" title="120:128	Our weighting method follows the Qiu 36 method (Qiu and Frei, 1993), except that Qiu used it to expand terms only from a single automatically constructed thesarus and did not consider the use of more than one thesaurus." ></td>
	<td class="line x" title="121:128	7 Conclusions This paper analyzed why the use of WordNet has failed to improve the retrieval effectiveness in information retrieval applications." ></td>
	<td class="line x" title="122:128	We found that the main reason is that most relationships between terms are not found in WordNet, and some terms, such as proper names, are not ineluded in WordNet." ></td>
	<td class="line x" title="123:128	To overcome this problem we proposed a method to enrich the WordNet with automatically constructed thesauri." ></td>
	<td class="line x" title="124:128	Another problem in query expansion is that of polysemous words." ></td>
	<td class="line x" title="125:128	Instead of using a word sense disambiguation method to select the apropriate sense of each word, we overcame this problem with a weighting method." ></td>
	<td class="line x" title="126:128	Experiments proved that our method of using WordNet in query expansion could improve information retrieval effectiveness." ></td>
	<td class="line x" title="127:128	Future work will include experiments on larger test collections, and the use of WordNet in methods other than query expansion in information retrieval." ></td>
	<td class="line x" title="128:128	8 Acknowledgements The authors would like to thank Mr. Timothy Baldwin (TIT, Japan) for his comments on the earlier version of this paper, Dr. Chris BuckIcy (Cornell Univesity) for the SMART support, and Mr. Satoshi Sekine (New York University) for the Apple Pie Parser support." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="E99-1013
Complementing WordNet With Roget's And Corpus-Based Thesauri For Information Retrieval
Mandala, Rila;Tokunaga, Takenobu;Tanaka, Hozumi;"></td>
	<td class="line x" title="1:153	Proceedings of EACL '99 Complementing WordNet with Roget's and Corpus-based Thesauri for Information Retrieval Rila Mandala, Takenobu Tokunaga and Hozumi Tanaka Abstract This paper proposes a method to overcome the drawbacks of WordNet when applied to information retrieval by complementing it with Roget's thesaurus and corpus-derived thesauri." ></td>
	<td class="line x" title="2:153	Words and relations which are not included in WordNet can be found in the corpus-derived thesauri." ></td>
	<td class="line x" title="3:153	Effects of polysemy can be minimized with weighting method considering all query terms and all of the thesauri." ></td>
	<td class="line x" title="4:153	Experimental results show that our method enhances information retrieval performance significantly." ></td>
	<td class="line x" title="5:153	Department of Computer Science Tokyo Institute of Technology 2-12-1 Oookayama Meguro-Ku Tokyo 152-8522 Japan {rila,take,tanaka}@cs.titech.ac.jp expansion (Voorhees, 1994; Smeaton and Berrut, 1995), computing lexical cohesion (Stairmand, 1997), word sense disambiguation (Voorhees, 1993), and so on, but the results have not been very successful." ></td>
	<td class="line x" title="6:153	Previously, we conducted query expansion experiments using WordNet (Mandala et al. , to appear 1999) and found limitations, which can be summarized as follows : 1 Introduction Information retrieval (IR) systems can be viewed basically as a form of comparison between documents and queries." ></td>
	<td class="line x" title="7:153	In traditional IR methods, this comparison is done based on the use of common index terms in the document and the query (Salton and McGill, 1983)." ></td>
	<td class="line x" title="8:153	The drawback of such methods is that if semantically relevant documents do not contain the same terms as the query, then they will be judged irrelevant by the IR system." ></td>
	<td class="line x" title="9:153	This occurs because the vocabulary that the user uses is often not the same as the one used in documents (Blair and Maron, 1985)." ></td>
	<td class="line x" title="10:153	To avoid the above problem, several researchers have suggested the addition of terms which have similar or related meaning to the query, increasing the chances of matching words in relevant documents." ></td>
	<td class="line x" title="11:153	This method is called query expansion." ></td>
	<td class="line x" title="12:153	A thesaurus contains information pertaining to paradigmatic semantic relations such as term synonymy, hypernymy, and hyponymy (Aitchison and Gilchrist, 1987)." ></td>
	<td class="line x" title="13:153	It is thus natural to use a thesaurus as a source for query expansion." ></td>
	<td class="line x" title="14:153	Many researchers have used WordNet (Miller, 1990) in information retrieval as a tool for query  Interrelated words may have different parts of speech." ></td>
	<td class="line x" title="15:153	 Most domain-specific relationships between words are not found in WordNet." ></td>
	<td class="line x" title="16:153	 Some kinds of words are not included in WordNet, such as proper names." ></td>
	<td class="line x" title="17:153	To overcome all the above problems, we propose a method to enrich WordNet with Roget's Thesaurus and corpus-based thesauri." ></td>
	<td class="line x" title="18:153	The idea underlying this method is that the automatically constructed thesauri can counter all the above drawbacks of WordNet." ></td>
	<td class="line x" title="19:153	For example, as we stated earlier, proper names and their interrelations are not found in WordNet, but if proper names bear some strong relationship with other terms, they often cooccur in documents, as can be modelled by a corpus-based thesaurus." ></td>
	<td class="line x" title="20:153	Polysemous words degrade the precision of information retrieval since all senses of the original query term are considered for expansion." ></td>
	<td class="line x" title="21:153	To overcome the problem of polysemous words, we apply a restriction in that queries are expanded by adding those terms that are most similar to the entirety of the query, rather than selecting terms that are similar to a single term in the query." ></td>
	<td class="line x" title="22:153	In the next section we describe the details of our method." ></td>
	<td class="line x" title="23:153	94 Proceedings of EACL '99 2 Thesauri 2.1 WordNet In WordNet, words are organized into taxonomies where each node is a set of synonyms (a synset) representing a single sense." ></td>
	<td class="line x" title="24:153	There are 4 different taxonomies based on distinct parts of speech and many relationships defined within each." ></td>
	<td class="line x" title="25:153	In this paper we use only noun taxonomy with hyponymy/hypernymy (or is-a) relations, which relates more general and more specific senses (Miller, 1988)." ></td>
	<td class="line x" title="26:153	Figure 1 shows a fragment of the WordNet taxonomy." ></td>
	<td class="line x" title="27:153	The similarity between word wl and we is defined as the shortest path from each sense of wl to each sense of w2, as below (Leacock and Chodorow, 1988; Resnik, 1995) sim(wl, w2) = max\[log(2~) \] where N v is the number of nodes in path p from wl to w2 and D is the maximum depth of the taxonomy." ></td>
	<td class="line x" title="28:153	2.2 Roget's Thesaurus In Roget's Thesaurus (Chapman, 1977), words are classified according to the ideas they express, and these categories of ideas are numbered in sequence." ></td>
	<td class="line x" title="29:153	The terms within a category are further organized by part of speech (nouns, verbs, adjectives, adverbs, prepositions, conjunctions, and interjections)." ></td>
	<td class="line x" title="30:153	Figure 2 shows a fragment of Roget's category." ></td>
	<td class="line x" title="31:153	In this case, our similarity measure treat all the words in Roger as features." ></td>
	<td class="line x" title="32:153	A word w possesses the feature f if f and w belong to the same Roget category." ></td>
	<td class="line x" title="33:153	The similarity between two words is then defined as the Dice coefficient of the two feature vectors (Lin, 1998)." ></td>
	<td class="line x" title="34:153	sim(wl,w2) = 21R(wl) n R(w~)l tn(w,)l + In(w )l where R(w) is the set of words that belong to the same Roget category as w. 2.3 Corpus-based Thesaurus 2.3.1 Co-occurrence-based Thesaurus This method is based on the assumption that a pair of words that frequently occur together in the same document are related to the same subject." ></td>
	<td class="line x" title="35:153	Therefore word co-occurrence information can be used to identify semantic relationships between words (Schutze and Pederson, 1997; Schutze and Pederson, 1994)." ></td>
	<td class="line x" title="36:153	We use mutual information as a tool for computing similarity between words." ></td>
	<td class="line x" title="37:153	Mutual information compares the probability of the co-occurence of words a and b with the independent probabilities of occurrence of a and b (Church and Hanks, 1990)." ></td>
	<td class="line x" title="38:153	P(a, b) I(a, b) = log P(a)P(b) where the probabilities of P(a) and P(b) are estimated by counting the number of occurrences of a and b in documents and normalizing over the size of vocabulary in the documents." ></td>
	<td class="line x" title="39:153	The joint probability is estimated by counting the number of times that word a co-occurs with b and is also normalized over the size of the vocabulary." ></td>
	<td class="line x" title="40:153	2.3.2 Syntactically-based Thesaurus In contrast to the previous section, this method attempts to gather term relations on the basis of linguistic relations and not document cooccurrence statistics." ></td>
	<td class="line oc" title="41:153	Words appearing in similax grammatical contexts are assumed to be similar, and therefore classified into the same class (Lin, 1998; Grefenstette, 1994; Grefenstette, 1992; Ruge, 1992; Hindle, 1990)." ></td>
	<td class="line x" title="42:153	First, all the documents are parsed using the Apple Pie Parser." ></td>
	<td class="line x" title="43:153	The Apple Pie Parser is a natural language syntactic analyzer developed by Satoshi Sekine at New York University (Sekine and Grishman, 1995)." ></td>
	<td class="line x" title="44:153	The parser is a bottom-up probabilistic chart parser which finds the parse tree with the best score by way of the best-first search algorithm." ></td>
	<td class="line x" title="45:153	Its grammar is a semi-context sensitive grammar with two non-terminals and was automatically extracted from Penn Tree Bank syntactically tagged corpus developed at the University of Pennsylvania." ></td>
	<td class="line x" title="46:153	The parser generates a syntactic tree in the manner of a Penn Tree Bank bracketing." ></td>
	<td class="line x" title="47:153	Figure 3 shows a parse tree produced by this parser." ></td>
	<td class="line x" title="48:153	The main technique used by the parser is the best-first search." ></td>
	<td class="line x" title="49:153	Because the grammar is probabilistic, it is enough to find only one parse tree with highest possibility." ></td>
	<td class="line x" title="50:153	During the parsing process, the parser keeps the unexpanded active nodes in a heap, and always expands the active node with the best probability." ></td>
	<td class="line x" title="51:153	Unknown words are treated in a special manner." ></td>
	<td class="line x" title="52:153	If the tagging phase of the parser finds an unknown word, it uses a list of parts-of-speech defined in the parameter file." ></td>
	<td class="line x" title="53:153	This information has been collected from the Wall Street Journal corpus and uses part of the corpus for training and the rest for testing." ></td>
	<td class="line x" title="54:153	Also, it has separate lists for such information as special suffices like -ly, -y, -ed, -d, and -s." ></td>
	<td class="line x" title="55:153	The accuracy of this parser is reported 95 Proceedings of EACL '99 Synonyms/Hypernyms (Ordered by Frequency) of noun correlation 2 senses of correlation Sense 1 correlation, correlativity => reciprocality, reciprocity => relation => abstraction Figure 1: An Example WordNet entry 9." ></td>
	<td class="line x" title="56:153	Relation." ></td>
	<td class="line x" title="57:153	-N. relation, bearing, reference, connection, concern,, cogaation ; correlation c. 12; analogy; similarity c. 17; affinity, homology, alliance, homogeneity, association; approximation c." ></td>
	<td class="line x" title="58:153	(nearness) 197; filiation c." ></td>
	<td class="line x" title="59:153	(consanguinity) 11\[obs3\]; interest; relevancy c. 23; dependency, relationship, relative position." ></td>
	<td class="line x" title="60:153	comparison c. 464; ratio, proportion." ></td>
	<td class="line x" title="61:153	link, tie, bond of union." ></td>
	<td class="line x" title="62:153	Figure 2: A fragment of a Roget's Thesaurus entry as parseval recall 77.45 % and parseval precision 75.58 %." ></td>
	<td class="line x" title="63:153	Using the above parser, the following syntactic structures are extracted :  Subject-Verb a noun is the subject of a verb." ></td>
	<td class="line x" title="64:153	 Verb-Object a noun is the object of a verb." ></td>
	<td class="line x" title="65:153	 Adjective-Noun an adjective modifies a noun." ></td>
	<td class="line x" title="66:153	 Noun-Noun a noun modifies a noun." ></td>
	<td class="line x" title="67:153	Each noun has a set of verbs, adjectives, and nouns that it co-occurs with, and for each such relationship, a mutual information value is calculated." ></td>
	<td class="line x" title="68:153	 I~b(Vi, nj) = log f,~b(~,~,)/g,~b  (fsub(nj)/Ns,~b)(f(Vi)/Nzub) where fsub(vi, nj) is the frequency of noun nj occurring as the subject of verb vi, L~,b(n~) is the frequency of the noun nj occurring as subject of any verb, f(vi) is the frequency of the verb vi, and Nsub is the number of subject clauses." ></td>
	<td class="line x" title="69:153	fob~ (nj,11i )/Nobj  Iobj(Vi, nj) = log (Yob~(nj)/Nob~)(f(vl)/Nob~) where fobj(Vi, nj) is the frequency of noun nj occurring as the object of verb vi, fobj(nj) is the frequency of the noun nj occurring as object of any verb, f(vi) is the frequency of the verb vi, and Nsub is the number of object clauses." ></td>
	<td class="line x" title="70:153	 Iadj(ai,nj) = log Id;(n~'ai)/N*ai (fadj(nj)/Nadj)(f(ai)/ga#4) where f(ai, nj) is the frequency of noun nj occurring as the argument of adjective ai, fadj(nj) is the frequency of the noun nj occurring as the argument of any adjective, f(ai) is the frequency of the adjective ai, and Nadj is the number of adjective clauses." ></td>
	<td class="line x" title="71:153	 Inoun(ni,nj) = log f (~j,~)/N  where (f oun (nj )/ Nnou." ></td>
	<td class="line x" title="72:153	)(f (ni )/ Nnoun ) f(ai,nj) is the frequency of noun nj occurring as the argument of noun hi, fnoun(nj) is the frequency of the noun n~ occurring as the argument of any noun, f(ni) is the frequency of the noun hi, and N.o~,n is the number of noun clauses." ></td>
	<td class="line x" title="73:153	The similarity sim(w,wz) between two words w~ and w2 can be computed as follows : (r,w) 6T(w, )nT(w2) Ir(wl,w)+ (r,w) 6T(wt ) (r,w) eT(w2) Where r is the syntactic relation type, and w is  a verb, if r is the subject-verb or object-verb relation." ></td>
	<td class="line x" title="74:153	 an adjective, if r is the adjective-noun relation." ></td>
	<td class="line x" title="75:153	96 Proceedings of EACL '99 NP DT JJ NN That quill pen VP /N ADJ VBZ JJ CC looks good and VP VP NP VBZ DT JJ NN is a new product Figure 3: An example parse tree  a noun, if r is the noun-noun relation." ></td>
	<td class="line x" title="76:153	and T(w) is the set of pairs (r,w') such that It(w, w') is positive." ></td>
	<td class="line x" title="77:153	3 Combination and Term Expansion Method A query q is represented by the vector -~ = (ql, q2,---, qn), where each qi is the weight of each search term ti contained in query q. We used SMART version 11.0 (Saiton, 1971) to obtain the initial query weight using the formula ltc as belows : (log(tfik) + 1.0) * log(N/nk) ~-~\[(log(tfo + 1.0) * log(N/nj)\] 2 j=l where tfik is the occurrrence frequency of term tk in query qi, N is the total number of documents in the collection, and nk is the number of documents to which term tk is assigned." ></td>
	<td class="line x" title="78:153	Using the above weighting method, the weight of initial query terms lies between 0 and 1." ></td>
	<td class="line x" title="79:153	On the other hand, the similarity in each type of thesaurus does not have a fixed range." ></td>
	<td class="line x" title="80:153	Hence, we apply the following normalization strategy to each type of thesaurus to bring the similarity value into the range \[0, 1\]." ></td>
	<td class="line x" title="81:153	simold -Simmin Simnew = Simmaz -8immin The similarity value between two terms in the combined thesauri is defined as the average of their similarity value over all types of thesaurus." ></td>
	<td class="line x" title="82:153	The similarity between a query q and a term tj can be defined as belows : simqt(q, tj) = Z qi * sim(ti, tj) tiEq where the value of sim(ti, tj) is taken from the combined thesauri as described above." ></td>
	<td class="line x" title="83:153	With respect to the query q, all the terms in the collection can now be ranked according to their simqt." ></td>
	<td class="line x" title="84:153	Expansion terms are terms tj with high simqt (q, t j)." ></td>
	<td class="line x" title="85:153	The weight(q, tj) of an expansion term tj is defined as a function of simqt(q, tj): weight(q, tj) simqt(q, tj) ZtiEq qi where 0 < weight(q, tj) < 1." ></td>
	<td class="line x" title="86:153	The weight of an expansion term depends both on all terms appearing in a query and on the similarity between the terms, and ranges from 0 to 1." ></td>
	<td class="line x" title="87:153	The weight of an expansion term depends both on the entire query and on the similarity between the terms." ></td>
	<td class="line x" title="88:153	The weight of an expansion term can be interpreted mathematically as the weighted mean of the similarities between the term tj and all the query terms." ></td>
	<td class="line x" title="89:153	The weight of the original query terms are the weighting factors of those similarities (Qiu and Frei, 1993)." ></td>
	<td class="line x" title="90:153	Therefore the query q is expanded by adding the following query : ~ee = (al, a2,  , at) where aj is equal to weight(q, tj) if tj belongs to the top r ranked terms." ></td>
	<td class="line x" title="91:153	Otherwise aj is equal to 0." ></td>
	<td class="line x" title="92:153	97 Proceedings of EACL '99 The resulting expanded query is : ~ezpanded '~~ o ~ee where the o is defined as the concatenation operator." ></td>
	<td class="line x" title="93:153	The method above can accommodate polysemy, because an expansion term which is taken from a different sense to the original query term is given a very low weight." ></td>
	<td class="line x" title="94:153	4 Experiments Experiments were carried out on the TREC-7 Collection, which consists of 528,155 documents and 50 topics (Voorhees and Harman, to appear 1999)." ></td>
	<td class="line x" title="95:153	TREC is currently de facto standard test collection in information retrieval community." ></td>
	<td class="line x" title="96:153	Table 1 shows topic-length statistics, Table 2 shows document statistics, and Figure 4 shows an example topic." ></td>
	<td class="line x" title="97:153	We use the title, description, and combined title+description+narrative of these topics." ></td>
	<td class="line x" title="98:153	Note that in the TREC-7 collection the description contains all terms in the title section." ></td>
	<td class="line x" title="99:153	For our baseline, we used SMART version 11.0 (Salton, 1971) as information retrieval engine with the Inc.ltc weighting method." ></td>
	<td class="line x" title="100:153	SMART is an information retrieval engine based on the vector space model in which term weights are calculated based on term frequency, inverse document frequency and document length normalization." ></td>
	<td class="line x" title="101:153	Automatic indexing of a text in SMART system involves the following steps :  Tokenization : The text is first tokenized into individual words and other tokens." ></td>
	<td class="line x" title="102:153	 Stop word removal : Common function words (like the, of, an, etc)." ></td>
	<td class="line x" title="103:153	also called stop words, are removed from this list of tokens." ></td>
	<td class="line x" title="104:153	The SMART system uses a predefined list of 571 stop words." ></td>
	<td class="line x" title="105:153	 Stemming: Various morphological variants of a word are normalized to the same stem." ></td>
	<td class="line x" title="106:153	SMART system uses the variant of Lovin method to apply simple rules for suffix stripping." ></td>
	<td class="line x" title="107:153	 Weighting : The term (word and phrase) vector thus created for a text, is weighted using t f, idf, and length normalization considerations." ></td>
	<td class="line x" title="108:153	Table 3 gives the average of non-interpolated precision using SMART without expansion (baseline), expansion using only WordNet, expansion using only the corpus-based syntactic-relationbased thesaurus, expansion using only the corpusbased co-occurrence-based thesaurus, and expansion using combined thesauri." ></td>
	<td class="line x" title="109:153	For each method we also give the relative improvement over the baseline." ></td>
	<td class="line x" title="110:153	We can see that the combined method outperform the isolated use of each type of thesaurus significantly." ></td>
	<td class="line x" title="111:153	Table 1:TREC-7 Topic length statistics Topic Section Min Max Mean Title 1 3 2.5 Description 5 34 14.3 Narrative 14 92 40.8 All 31 114 57.6 5 Discussion In this section we discuss why our method using WordNet is able to improve information retrieval performance." ></td>
	<td class="line x" title="112:153	The three types of thesaurus we used have different characteristics." ></td>
	<td class="line x" title="113:153	Automatically constructed thesauri add not only new terms but also new relationships not found in WordNet." ></td>
	<td class="line x" title="114:153	If two terms often co-occur in a document then those two terms are likely to bear some relationship." ></td>
	<td class="line x" title="115:153	The reason why we should use not only automatically constructed thesauri is that some relationships may be missing in them For example, consider the words colour and color." ></td>
	<td class="line x" title="116:153	These words certainly share the same context, but would never appear in the same document, at least not with a frequency recognized by a co-occurrence-based method." ></td>
	<td class="line x" title="117:153	In general, different words used to describe similar concepts may never be used in the same document, and are thus missed by cooccurrence methods." ></td>
	<td class="line x" title="118:153	However their relationship may be found in WordNet, Roget's, and the syntacticallybased thesaurus." ></td>
	<td class="line x" title="119:153	One may ask why we included Roget's Thesaurus here which is almost identical in nature to WordNet." ></td>
	<td class="line x" title="120:153	The reason is to provide more evidence in the final weighting method." ></td>
	<td class="line x" title="121:153	Including Roget's as part of the combined thesaurus is better than not including it, although the improvement is not significant (4% for title, 2% for description and 0.9% for all terms in the query)." ></td>
	<td class="line x" title="122:153	One reason is that the coverage of Roget's is very limited." ></td>
	<td class="line x" title="123:153	A second point is our weighting method." ></td>
	<td class="line x" title="124:153	The advantages of our weighting method can be summarized as follows:  the weight of each expansion term considers the similarity of that term to all terms in the 98 Proceedings of EACL '99 Table 2:TREC-7 Document statistics Source Size(Mb) #Docs I Median# t Mean# Words/Doc Words/Doc Disk 4 FT 564 t210,1581 316 412.7 1155,630 588 644.7 FR94 395 Disk 5 FBIS 4701130,47113221543.6 131,896 351 526.5 LA Times 475 Title : ocean remote sensing Description: Identify documents discussing the development and application of spaceborne ocean remote sensing." ></td>
	<td class="line x" title="125:153	Narrative: Documents discussing the development and application of spaceborne ocean remote sensing in oceanography, seabed prospecting and mining, or any marinescience activity are relevant." ></td>
	<td class="line x" title="126:153	Documents that discuss the application of satellite remote sensing in geography, agriculture, forestry, mining and mineral prospecting or any land-bound science are not relevant, nor are references to international marketing or promotional advertizing of any remote-sensing technology." ></td>
	<td class="line x" title="127:153	Synthetic aperture radar (SAR) employed in ocean remote sensing is relevant." ></td>
	<td class="line x" title="128:153	Figure 4: Topics Example original query, rather than to just one query term." ></td>
	<td class="line x" title="129:153	 the weight of an expansion term also depends on its similarity within all types of thesaurus." ></td>
	<td class="line x" title="130:153	Our method can accommodate polysemy, because an expansion term taken from a different sense to the original query term sense is given very low weight." ></td>
	<td class="line x" title="131:153	The reason for this is that the weighting method depends on all query terms and all of the thesauri." ></td>
	<td class="line x" title="132:153	For example, the word bank has many senses in WordNet." ></td>
	<td class="line x" title="133:153	Two such senses are the financial institution and river edge senses." ></td>
	<td class="line x" title="134:153	In a document collection relating to financial banks, the river sense of bank will generally not be found in the cooccurrence-based thesaurus because of a lack of articles talking about rivers." ></td>
	<td class="line x" title="135:153	Even though (with small possibility) there may be some documents in the collection talking about rivers, if the query contained the finance sense of bank then the other terms in the query would also tend to be concerned with finance and not rivers." ></td>
	<td class="line x" title="136:153	Thus rivers would only have a relationship with the bank term and there would be no relations with other terms in the original query, resulting in a low weight." ></td>
	<td class="line x" title="137:153	Since our weighting method depends on both the query in its entirety and similarity over the three thesauri, wrong sense expansion terms are given very low weight." ></td>
	<td class="line x" title="138:153	6 Related Research Smeaton (1995) and Voorhees (1994; 1988) proposed an expansion method using WordNet." ></td>
	<td class="line x" title="139:153	Our method differs from theirs in that we enrich the coverage of WordNet using two methods of automatic thesaurus construction, and we weight the expansion term appropriately so that it can accommodate polysemy." ></td>
	<td class="line x" title="140:153	Although Stairmand (1997) and Richardson (1995) proposed the use of WordNet in information retrieval, they did not use WordNet in the query expansion framework." ></td>
	<td class="line oc" title="141:153	Our syntactic-relation-based thesaurus is based on the method proposed by Hindle (1990), although Hindle did not apply it to information retrieval." ></td>
	<td class="line n" title="142:153	Hindle only extracted subject-verb and object-verb relations, while we also extract adjective-noun and noun-noun relations, in the manner of Grefenstette (1994), who applied his 99 Proceedings of EACL '99 Table 3: Average non-interpolated precision for expansion using single or combined thesauri." ></td>
	<td class="line x" title="143:153	Topic Type Base Title 0.1175 Description 0.1428 All 0.1976 Expanded with WordNet Roget Syntac Cooccur Combined only only only only method 0.1276 0.1236 0.1386 0.1457 0.2314 (+8.6%) (+5.2 %) (+17.9%) (+24.0%) (+96.9%) 0.1509 0,1477 0.1648 0.1693 0.2645 (+5.7%) (+3.4%) (+15.4%) (+18.5%) (+85.2%) 0.2010 0.1999 0.2131 0.2191 0.2724 (+1.7%) (+1.2%) (+7.8%) (+10.8%) (+37.8%) syntactically-based thesaurus to information retrieval with mixed results." ></td>
	<td class="line x" title="144:153	Our system improves on Grefenstette's results since we factor in thesauri which contain hierarchical information absent from his automatically derived thesaurus." ></td>
	<td class="line x" title="145:153	Our weighting method follows the Qiu and Frei (1993) method, except that Qiu used it to expand terms from a single automatically constructed thesarus and did not consider the use of more than one thesaurus." ></td>
	<td class="line x" title="146:153	This paper is an extension of our previous work (Mandala et al. , to appear 1999) in which we ddid not consider the effects of using Roget's Thesaurus as one piece of evidence for expansion and used the Tanimoto coefficient as similarity coefficient instead of mutual information." ></td>
	<td class="line x" title="147:153	7 Conclusions We have proposed the use of different types of thesaurus for query expansion." ></td>
	<td class="line x" title="148:153	The basic idea underlying this method is that each type of thesaurus has different characteristics and combining them provides a valuable resource to expand the query." ></td>
	<td class="line x" title="149:153	Wrong expansion terms can be avoided by designing a weighting term method in which the weight of expansion terms not only depends on all query terms, but also depends on their similarity values in all type of thesaurus." ></td>
	<td class="line x" title="150:153	Future research will include the use of a parser with better performance and the use of more recent term weighting methods for indexing." ></td>
	<td class="line x" title="151:153	8 Acknowledgements The authors would like to thank Mr. Timothy Baldwin (TIT, Japan) and three anonymous referees for useful comments on the earlier version of this paper." ></td>
	<td class="line x" title="152:153	We also thank Dr. Chris Buckley (SabIR Research) for support with SMART, and Dr. Satoshi Sekine (New York University) for providing the Apple Pie Parser program." ></td>
	<td class="line x" title="153:153	This research is partially supported by JSPS project number JSPS-RFTF96P00502." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P99-1004
Measures Of Distributional Similarity
Lee, Lillian;"></td>
	<td class="line x" title="1:249	Measures of Distributional Similarity Lillian Lee Department of Computer Science Cornell University Ithaca, NY 14853-7501 llee@cs, cornell, edu Abstract We study distributional similarity measures for the purpose of improving probability estimation for unseen cooccurrences." ></td>
	<td class="line x" title="2:249	Our contributions are three-fold: an empirical comparison of a broad range of measures; a classification of similarity functions based on the information that they incorporate; and the introduction of a novel function that is superior at evaluating potential proxy distributions." ></td>
	<td class="line x" title="3:249	1 Introduction An inherent problem for statistical methods in natural language processing is that of sparse data -the inaccurate representation in any training corpus of the probability of low frequency events." ></td>
	<td class="line x" title="4:249	In particular, reasonable events that happen to not occur in the training set may mistakenly be assigned a probability of zero." ></td>
	<td class="line x" title="5:249	These unseen events generally make up a substantial portion of novel data; for example, Essen and Steinbiss (1992) report that 12% of the test-set bigrams in a 75%-25% split of one million words did not occur in the training partition." ></td>
	<td class="line x" title="6:249	We consider here the question of how to estimate the conditional cooccurrence probability P(v\[n) of an unseen word pair (n, v) drawn from some finite set N x V. Two state-of-the-art technologies are Katz's (1987) backoff method and Jelinek and Mercer's (1980) interpolation method." ></td>
	<td class="line x" title="7:249	Both use P(v) to estimate P(v\[n) when (n, v) is unseen, essentially ignoring the identity of n. An alternative approach is distance-weighted averaging, which arrives at an estimate for unseen cooccurrences by combining estimates for 25 cooccurrences involving similar words: 1 /P(v\[n) ---~-~mES(n) sim(n, m)P(v\[m) ~-\]mES(n) sim(n, m), (1) where S(n) is a set of candidate similar words and sim(n, m) is a function of the similarity between n and m. We focus on distributional rather than semantic similarity (e.g. , Resnik (1995)) because the goal of distance-weighted averaging is to smooth probability distributions -although the words 'chance' and 'probability' are synonyms, the former may not be a good model for predicting what cooccurrences the latter is likely to participate in." ></td>
	<td class="line x" title="8:249	There are many plausible measures of distributional similarity." ></td>
	<td class="line x" title="9:249	In previous work (Dagan et al. , 1999), we compared the performance of three different functions: the Jensen-Shannon divergence (total divergence to the average), the L1 norm, and the confusion probability." ></td>
	<td class="line x" title="10:249	Our experiments on a frequency-controlled pseudoword disambiguation task showed that using any of the three in a distance-weighted averaging scheme yielded large improvements over Katz's backoff smoothing method in predicting unseen coocurrences." ></td>
	<td class="line x" title="11:249	Furthermore, by using a restricted version of model (1) that stripped incomparable parameters, we were able to empirically demonstrate that the confusion probability is fundamentally worse at selecting useful similar words." ></td>
	<td class="line x" title="12:249	D. Lin also found that the choice of similarity function can affect the quality of automatically-constructed thesauri to a statistically significant degree (1998a) and the ability to determine common morphological roots by as much as 49% in precision (1998b)." ></td>
	<td class="line x" title="13:249	1The term 'similarity-based', which we have used previously, has been applied to describe other models as well (L. Lee, 1997; Karov and Edelman, 1998)." ></td>
	<td class="line x" title="14:249	These empirical results indicate that investigating different similarity measures can lead to improved natural language processing." ></td>
	<td class="line x" title="15:249	On the other hand, while there have been many similarity measures proposed and analyzed in the information retrieval literature (Jones and Furnas, 1987), there has been some doubt expressed in that community that the choice of similarity metric has any practical impact: Several authors have pointed out that the difference in retrieval performance achieved by different measures of association is insignificant, providing that these are appropriately normalised." ></td>
	<td class="line x" title="16:249	(van Rijsbergen, 1979, pg." ></td>
	<td class="line x" title="17:249	38) But no contradiction arises because, as van Rijsbergen continues, 'one would expect this since most measures incorporate the same information'." ></td>
	<td class="line x" title="18:249	In the language-modeling domain, there is currently no agreed-upon best similarity metric because there is no agreement on what the 'same information'the key data that a similarity function should incorporate -is. The overall goal of the work described here was to discover these key characteristics." ></td>
	<td class="line x" title="19:249	To this end, we first compared a number of common similarity measures, evaluating them in a parameter-free way on a decision task." ></td>
	<td class="line x" title="20:249	When grouped by average performance, they fell into several coherent classes, which corresponded to the extent to which the functions focused on the intersection of the supports (regions of positive probability) of the distributions." ></td>
	<td class="line x" title="21:249	Using this insight, we developed an information-theoretic metric, the skew divergence, which incorporates the support-intersection data in an asymmetric fashion." ></td>
	<td class="line x" title="22:249	This function yielded the best performance overall: an average error rate reduction of 4% (significant at the.01 level) with respect to the Jensen-Shannon divergence, the best predictor of unseen events in our earlier experiments (Dagan et al. , 1999)." ></td>
	<td class="line x" title="23:249	Our contributions are thus three-fold: an empirical comparison of a broad range of similarity metrics using an evaluation methodology that factors out inessential degrees of freedom; a proposal, building on this comparison, of a characteristic for classifying similarity functions; and the introduction of a new similarity metric incorporating this characteristic that is superior at evaluating potential proxy distributions." ></td>
	<td class="line x" title="24:249	2} 2 Distributional Similarity Functions In this section, we describe the seven distributional similarity functions we initally evaluated." ></td>
	<td class="line x" title="25:249	2 For concreteness, we choose N and V to be the set of nouns and the set of transitive verbs, respectively; a cooccurrence pair (n, v) results when n appears as the head noun of the direct object of v. We use P to denote probabilities assigned by a base language model (in our experiments, we simply used unsmoothed relative frequencies derived from training corpus counts)." ></td>
	<td class="line x" title="26:249	Let n and m be two nouns whose distributional similarity is to be determined; for notational simplicity, we write q(v) for P(vln ) and r(v) for P(vlm), their respective conditional verb cooccurrence probabilities." ></td>
	<td class="line x" title="27:249	Figure 1 lists several familiar functions." ></td>
	<td class="line x" title="28:249	The cosine metric and Jaccard's coefficient are commonly used in information retrieval as measures of association (Salton and McGill, 1983)." ></td>
	<td class="line x" title="29:249	Note that Jaccard's coefficient differs from all the other measures we consider in that it is essentially combinatorial, being based only on the sizes of the supports of q, r, and q  r rather than the actual values of the distributions." ></td>
	<td class="line x" title="30:249	Previously, we found the Jensen-Shannon divergence (Rao, 1982; J. Lin, 1991) to be a useful measure of the distance between distributions: JS(q,r)=-~l \[D(q aVgq,r)+D(r aVgq,r) \] The function D is the KL divergence, which measures the (always nonnegative) average inefficiency in using one distribution to code for another (Cover and Thomas, 1991): (v) D(pl(V) IIp2(V)) = EPl(V)log Pl p2(v) ' V The function avga, r denotes the average distribution avgq,r(V ) --= (q(v)+r(v))/2; observe that its use ensures that the Jensen-Shannon divergence is always defined." ></td>
	<td class="line x" title="31:249	In contrast, D(qllr ) is undefined if q is not absolutely continuous with respect to r (i.e. , the support of q is not a subset of the support of r)." ></td>
	<td class="line x" title="32:249	2Strictly speaking, some of these functions are dissimilarity measures, but each such function f can be recast as a similarity function via the simple transformation C f, where C is an appropriate constant." ></td>
	<td class="line x" title="33:249	Whether we mean f or C f should be clear from context." ></td>
	<td class="line x" title="34:249	Euclidean distance L1 norm cosine Jaccard's coefficient L2(q,r) = Ll(q,r) = cos(q, r) = Jac(q, r) = ~v (q(v) r(v)) 2 Iq(v) r(v)l V ~-~v q(v)r(v) X/~-~v q(v) 2 V/Y~-v r(v) 2 Iv : q(v) > 0 and r(v) > 0}l Iv I q(v) > 0 or r(v) > O}l Figure 1: Well-known functions The confusion probability has been used by several authors to smooth word cooccurrence probabilities (Sugawara et al. , 1985; Essen and Steinbiss, 1992; Grishman and Sterling, 1993); it measures the degree to which word m can be substituted into the contexts in which n appears." ></td>
	<td class="line x" title="35:249	If the base language model probabilities obey certain Bayesian consistency conditions (Dagan et al. , 1999), as is the case for relative frequencies, then we may write the confusion probability as follows: P(m) conf(q, r, P(m) ) = E q(v)r(v) -p-~(v) ' V Note that it incorporates unigram probabilities as well as the two distributions q and r. Finally, Kendall's % which appears in work on clustering similar adjectives (Hatzivassiloglou and McKeown, 1993; Hatzivassiloglou, 1996), is a nonparametric measure of the association between random variables (Gibbons, 1993)." ></td>
	<td class="line x" title="36:249	In our context, it looks for correlation between the behavior of q and r on pairs of verbs." ></td>
	<td class="line x" title="37:249	Three versions exist; we use the simplest, Ta, here: r(q,r) = E sign \[(q(vl) q(v2))(r(vl) r(v2))\] v,,v 2(l t) where sign(x) is 1 for positive arguments, -1 for negative arguments, and 0 at 0." ></td>
	<td class="line x" title="38:249	The intuition behind Kendall's T is as follows." ></td>
	<td class="line x" title="39:249	Assume all verbs have distinct conditional probabilities." ></td>
	<td class="line x" title="40:249	If sorting the verbs by the likelihoods assigned by q yields exactly the same ordering as that which results from ranking them according to r, then T(q, r) = 1; if it yields exactly the opposite ordering, then T(q, r) --1." ></td>
	<td class="line x" title="41:249	We treat a value of -1 as indicating extreme dissimilarity." ></td>
	<td class="line x" title="42:249	3 It is worth noting at this point that there are several well-known measures from the NLP literature that we have omitted from our experiments." ></td>
	<td class="line oc" title="43:249	Arguably the most widely used is the mutual information (Hindle, 1990; Church and Hanks, 1990; Dagan et al. , 1995; Luk, 1995; D. Lin, 1998a)." ></td>
	<td class="line x" title="44:249	It does not apply in the present setting because it does not measure the similarity between two arbitrary probability distributions (in our case, P(VIn ) and P(VIm)), but rather the similarity between a joint distribution P(X1,X2) and the corresponding product distribution P(X1)P(X2)." ></td>
	<td class="line x" title="45:249	Hamming-type metrics (Cardie, 1993; Zavrel and Daelemans, 1997) are intended for data with symbolic features, since they count feature label mismatches, whereas we are dealing feature Values that are probabilities." ></td>
	<td class="line x" title="46:249	Variations of the value difference metric (Stanfill and Waltz, 1986) have been employed for supervised disambiguation (Ng and H.B. Lee, 1996; Ng, 1997); but it is not reasonable in language modeling to expect training data tagged with correct probabilities." ></td>
	<td class="line x" title="47:249	The Dice coej~cient (Smadja et al. , 1996; D. Lin, 1998a, 1998b) is monotonic in Jaccard's coefficient (van Rijsbergen, 1979), so its inclusion in our experiments would be redundant." ></td>
	<td class="line x" title="48:249	Finally, we did not use the KL divergence because it requires a smoothed base language model." ></td>
	<td class="line x" title="49:249	SZero would also be a reasonable choice, since it indicates zero correlation between q and r. However, it would then not be clear how to average in the estimates of negatively correlated words in equation (1)." ></td>
	<td class="line x" title="50:249	27 3 Empirical Comparison We evaluated the similarity functions introduced in the previous section on a binary decision task, using the same experimental framework as in our previous preliminary comparison (Dagan et al. , 1999)." ></td>
	<td class="line x" title="51:249	That is, the data consisted of the verb-object cooccurrence pairs in the 1988 Associated Press newswire involving the 1000 most frequent nouns, extracted via Church's (1988) and Yarowsky's processing tools." ></td>
	<td class="line x" title="52:249	587,833 (80%) of the pairs served as a training set from which to calculate base probabilities." ></td>
	<td class="line x" title="53:249	From the other 20%, we prepared test sets as follows: after discarding pairs occurring in the training data (after all, the point of similarity-based estimation is to deal with unseen pairs), we split the remaining pairs into five partitions, and replaced each nounverb pair (n, vl) with a noun-verb-verb triple (n, vl, v2) such that P(v2) ~ P(vl)." ></td>
	<td class="line x" title="54:249	The task for the language model under evaluation was to reconstruct which of (n, vl) and (n, v2) was the original cooccurrence." ></td>
	<td class="line x" title="55:249	Note that by construction, (n, Vl) was always the correct answer, and furthermore, methods relying solely on unigram frequencies would perform no better than chance." ></td>
	<td class="line x" title="56:249	Test-set performance was measured by the error rate, defined as T(# of incorrect choices + (# of ties)/2), where T is the number of test triple tokens in the set, and a tie results when both alternatives are deemed equally likely by the language model in question." ></td>
	<td class="line x" title="57:249	To perform the evaluation, we incorporated each similarity function into a decision rule as follows." ></td>
	<td class="line x" title="58:249	For a given similarity measure f and neighborhood size k, let 3f, k(n) denote the k most similar words to n according to f. We define the evidence according to f for the cooccurrence ( n, v~) as Ef, k(n, vi) = \[(m E SLk(n) : P(vilm) > l }l  Then, the decision rule was to choose the alternative with the greatest evidence." ></td>
	<td class="line x" title="59:249	The reason we used a restricted version of the distance-weighted averaging model was that we sought to discover fundamental differences in behavior." ></td>
	<td class="line x" title="60:249	Because we have a binary decision task, Ef,k(n, vl) simply counts the number of k nearest neighbors to n that make the right decision." ></td>
	<td class="line x" title="61:249	If we have two functions f and g such that Ef,k(n, Vl) > Eg,k(n, vi), then the k most similar words according to f are on the whole better predictors than the k most similar words according to g; hence, f induces an inherently better similarity ranking for distance-weighted averaging." ></td>
	<td class="line x" title="62:249	The difficulty with using the full model (Equation (1)) for comparison purposes is that fundamental differences can be obscured by issues of weighting." ></td>
	<td class="line x" title="63:249	For example, suppose the probability estimate ~v(2 -Ll(q, r))." ></td>
	<td class="line x" title="64:249	r(v) (suitably normalized) performed poorly." ></td>
	<td class="line x" title="65:249	We would not be able to tell whether the cause was an inherent deficiency in the L1 norm or just a poor choice of weight function -perhaps (2Ll(q,r)) 2 would have yielded better estimates." ></td>
	<td class="line x" title="66:249	Figure 2 shows how the average error rate varies with k for the seven similarity metrics introduced above." ></td>
	<td class="line x" title="67:249	As previously mentioned, a steeper slope indicates a better similarity ranking." ></td>
	<td class="line x" title="68:249	All the curves have a generally upward trend but always lie far below backoff (51% error rate)." ></td>
	<td class="line x" title="69:249	They meet at k = 1000 because Sf, looo(n) is always the set of all nouns." ></td>
	<td class="line x" title="70:249	We see that the functions fall into four groups: (1) the L2 norm; (2) Kendall's T; (3) the confusion probability and the cosine metric; and (4) the L1 norm, Jensen-Shannon divergence, and Jaccard's coefficient." ></td>
	<td class="line x" title="71:249	We can account for the similar performance of various metrics by analyzing how they incorporate information from the intersection of the supports of q and r." ></td>
	<td class="line x" title="72:249	(Recall that we are using q and r for the conditional verb cooccurrrence probabilities of two nouns n and m)." ></td>
	<td class="line x" title="73:249	Consider the following supports (illustrated in Figure 3): Vq = {veV : q(v)>O} = {vV:r(v)>0} Yqr = {v  V : q(v)r(v) > 0} = Yq n We can rewrite the similarity functions from Section 2 in terms of these sets, making use of the identities ~-~veyq\yq~ q(v) + ~veyq~ q(v) = ~'~-v~U~\Vq~ r(v) + ~v~Vq~ r(v) = 1." ></td>
	<td class="line x" title="74:249	Table 1 lists these alternative forms in order of performance." ></td>
	<td class="line x" title="75:249	28 0.4 0.38 0.36 0.34 ~ 0.32 0.3-0.28 0.26 100 Error rates (averages and ranges) I i i I i I. ,2-*.-Jag~ 200 300 400 500 600 700 800 900 1000 k Figure 2: Similarity metric performance." ></td>
	<td class="line x" title="76:249	Errorbars denote the range of error rates over the five test sets." ></td>
	<td class="line x" title="77:249	Backoff's average error rate was 51%." ></td>
	<td class="line x" title="78:249	L2(q,r) . 2(l l) =,/Eq(v)2-2Eq(v)r(v)+ Er(v) 2 V vq~ v~ = 2 IVq~l IV \ (vq u V~)l 2 IVq \ Vail Iv~ \Vq~l + E E sign\[(q(vl) q(v2))(r(vl) r(v2))\] Vl E(VqA Vr) v2EYq~, + E E sign\[(q(vl)-q(v2))(r(vl)-r(v2))\] Vl eVqr v2EVqUVr conf(q, r, P(m)) cos(q, r) = P(ra) Y\] q(v)r(v)/P(v) v e Vq~ = E q(v)r(v)( E q(v) 2 E r(v)2) -1/2 v~ Vqr ve Vq v~ Vr Ll(q,r) JS(q, r) Jac(q, r) = 2-E (Iq(v)-r(v)l-q(v)-r(v)) vE Vqr = log2 + 1 E (h(q(v) + r(v)) h(q(v)) h(r(v))), v ~ Vq~ = IV~l/IV~ u v~l h( x ) = -x log x Table 1: Similarity functions, written in terms of sums over supports and grouped by average performance." ></td>
	<td class="line x" title="79:249	\ denotes set difference; A denotes symmetric set difference." ></td>
	<td class="line x" title="80:249	We see that for the non-combinatorial functions, the groups correspond to the degree to which the measures rely on the verbs in Vat." ></td>
	<td class="line x" title="81:249	The Jensen-Shannon divergence and the L1 norm can be computed simply by knowing the values of q and r on Vqr." ></td>
	<td class="line x" title="82:249	For the cosine and the confusion probability, the distribution values on Vqr are key, but other information is also incorporated." ></td>
	<td class="line x" title="83:249	The statistic Ta takes into account all verbs, including those that occur neither with 29 v Figure 3: Supports on V n nor m. Finally, the Euclidean distance is quadratic in verbs outside Vat; indeed, Kaufman and Rousseeuw (1990) note that it is 'extremely sensitive to the effect of one or more outliers' (pg." ></td>
	<td class="line x" title="84:249	117)." ></td>
	<td class="line x" title="85:249	The superior performance of Jac(q, r) seems to underscore the importance of the set Vqr." ></td>
	<td class="line x" title="86:249	Jaccard's coefficient ignores the values of q and r on Vqr; but we see that simply knowing the size of Vqr relative to the supports of q and r leads to good rankings." ></td>
	<td class="line x" title="87:249	4 The Skew Divergence Based on the results just described, it appears that it is desirable to have a similarity function that focuses on the verbs that cooccur with both of the nouns being compared." ></td>
	<td class="line x" title="88:249	However, we can make a further observation: with the exception of the confusion probability, all the functions we compared are symmetric, that is, f(q, r) -= f(r, q)." ></td>
	<td class="line x" title="89:249	But the substitutability of one word for another need not symmetric." ></td>
	<td class="line x" title="90:249	For instance, 'fruit' may be the best possible approximation to 'apple', but the distribution of 'apple' may not be a suitable proxy for the distribution of 'fruit'.a In accordance with this insight, we developed a novel asymmetric generalization of the KL divergence, the a-skew divergence: sa(q,r) = D(r \[\[a'q + (1 a)-r) for 0 <_ a < 1." ></td>
	<td class="line x" title="91:249	It can easily be shown that sa depends only on the verbs in Vat." ></td>
	<td class="line x" title="92:249	Note that at a -1, the skew divergence is exactly the KL divergence, and su2 is twice one of the summands of JS (note that it is still asymmetric)." ></td>
	<td class="line x" title="93:249	40n a related note, an anonymous reviewer cited the following example from the psychology literature: we can say Smith's lecture is like a sleeping pill, but 'not the other way round'." ></td>
	<td class="line x" title="94:249	30 We can think of a as a degree of confidence in the empirical distribution q; or, equivalently, (1 a) can be thought of as controlling the amount by which one smooths q by r. Thus, we can view the skew divergence as an approximation to the KL divergence to be used when sparse data problems would cause the latter measure to be undefined." ></td>
	<td class="line x" title="95:249	Figure 4 shows the performance of sa for a = .99." ></td>
	<td class="line x" title="96:249	It performs better than all the other functions; the difference with respect to Jaccard's coefficient is statistically significant, according to the paired t-test, at all k (except k = 1000), with significance level .01 at all k except 100, 400, and 1000." ></td>
	<td class="line x" title="97:249	5 Discussion In this paper, we empirically evaluated a number of distributional similarity measures, including the skew divergence, and analyzed their information sources." ></td>
	<td class="line x" title="98:249	We observed that the ability of a similarity function f(q, r) to select useful nearest neighbors appears to be correlated with its focus on the intersection Vqr of the supports of q and r. This is of interest from a computational point of view because Vqr tends to be a relatively small subset of V, the set of all verbs." ></td>
	<td class="line x" title="99:249	Furthermore, it suggests downplaying the role of negative information, which is encoded by verbs appearing with exactly one noun, although the Jaccard coefficient does take this type of information into account." ></td>
	<td class="line x" title="100:249	Our explicit division of V-space into various support regions has been implicitly considered in other work." ></td>
	<td class="line x" title="101:249	Smadja et al.(1996) observe that for two potential mutual translations X and Y, the fact that X occurs with translation Y indicates association; X's occurring with a translation other than Y decreases one's belief in their association; but the absence of both X and Y yields no information." ></td>
	<td class="line x" title="103:249	In essence, Smadja et al. argue that information from the union of supports, rather than the just the intersection, is important." ></td>
	<td class="line x" title="104:249	D. Lin (1997; 1998a) takes an axiomatic approach to determining the characteristics of a good similarity measure." ></td>
	<td class="line x" title="105:249	Starting with a formalization (based on certain assumptions) of the intuition that the similarity between two events depends on both their commonality and their differences, he derives a unique similarity function schema." ></td>
	<td class="line x" title="106:249	The 0.4 0.38 I 0.36 \[ 0.34 0.32 0.3 0.28 0.26 100 Error rates (averages and ranges) L1 JS ~0 300 ~0 ~0 600 700 800 ~0 1000 k Figure 4: Performance of the skew divergence with respect to the best functions from Figure 2." ></td>
	<td class="line x" title="107:249	definition of commonality is left to the user (several different definitions are proposed for different tasks)." ></td>
	<td class="line x" title="108:249	We view the empirical approach taken in this paper as complementary to Lin's." ></td>
	<td class="line x" title="109:249	That is, we are working in the context of a particular application, and, while we have no mathematical certainty of the importance of the 'common support' information, we did not assume it a priori; rather, we let the performance data guide our thinking." ></td>
	<td class="line x" title="110:249	Finally, we observe that the skew metric seems quite promising." ></td>
	<td class="line x" title="111:249	We conjecture that appropriate values for a may inversely correspond to the degree of sparseness in the data, and intend in the future to test this conjecture on larger-scale prediction tasks." ></td>
	<td class="line x" title="112:249	We also plan to evaluate skewed versions of the Jensen-Shannon divergence proposed by Rao (1982) and J. Lin (1991)." ></td>
	<td class="line x" title="113:249	6 Acknowledgements Thanks to Claire Cardie, Jon Kleinberg, Fernando Pereira, and Stuart Shieber for helpful discussions, the anonymous reviewers for their insightful comments, Fernando Pereira for access to computational resources at AT&T, and Stuart Shieber for the opportunity to pursue this work at Harvard University under NSF Grant No." ></td>
	<td class="line x" title="114:249	IRI9712068." ></td>
	<td class="line x" title="115:249	References Claire Cardie." ></td>
	<td class="line x" title="116:249	1993." ></td>
	<td class="line x" title="117:249	A case-based approach to knowledge acquisition for domain-specific sentence analysis." ></td>
	<td class="line x" title="118:249	In 11th National Conference on Artifical Intelligence, pages 798-803." ></td>
	<td class="line x" title="119:249	Kenneth Ward Church and Patrick Hanks." ></td>
	<td class="line x" title="120:249	1990." ></td>
	<td class="line x" title="121:249	Word association norms, mutual information, and lexicography." ></td>
	<td class="line x" title="122:249	Computational Linguistics, 16(1):22-29." ></td>
	<td class="line x" title="123:249	Kenneth W. Church." ></td>
	<td class="line x" title="124:249	1988." ></td>
	<td class="line x" title="125:249	A stochastic parts program and noun phrase parser for unrestricted text." ></td>
	<td class="line x" title="126:249	In Second Conference on Applied Natural Language Processing, pages 136-143." ></td>
	<td class="line x" title="127:249	Thomas M. Cover and Joy A. Thomas." ></td>
	<td class="line x" title="128:249	1991." ></td>
	<td class="line x" title="129:249	Elements of Information Theory." ></td>
	<td class="line x" title="130:249	John Wiley." ></td>
	<td class="line x" title="131:249	Ido Dagan, Shanl Marcus, and Shanl Markovitch." ></td>
	<td class="line x" title="132:249	1995." ></td>
	<td class="line x" title="133:249	Contextual word similarity and estimation from sparse data." ></td>
	<td class="line x" title="134:249	Computer Speech and Language, 9:123-152." ></td>
	<td class="line x" title="135:249	Ido Dagan, Lillian Lee, and Fernando Pereira." ></td>
	<td class="line x" title="136:249	1999." ></td>
	<td class="line x" title="137:249	Similarity-based models of cooccurrence probabilities." ></td>
	<td class="line x" title="138:249	Machine Learning, 34(13) :43-69." ></td>
	<td class="line x" title="139:249	Ute Essen and Volker Steinbiss." ></td>
	<td class="line x" title="140:249	1992." ></td>
	<td class="line x" title="141:249	Cooccurrence smoothing for stochastic language modeling." ></td>
	<td class="line x" title="142:249	In ICASSP 92, volume 1, pages 161-164." ></td>
	<td class="line x" title="143:249	Jean Dickinson Gibbons." ></td>
	<td class="line x" title="144:249	1993." ></td>
	<td class="line x" title="145:249	Nonparametric Measures of Association." ></td>
	<td class="line x" title="146:249	Sage University Paper series on Quantitative Applications in the Social Sciences, 07-091." ></td>
	<td class="line x" title="147:249	Sage Publications." ></td>
	<td class="line x" title="148:249	Ralph Grishman and John Sterling." ></td>
	<td class="line x" title="149:249	1993." ></td>
	<td class="line x" title="150:249	Smoothing of automatically generated selectional constraints." ></td>
	<td class="line x" title="151:249	In Human Language Technology: Proceedings of the ARPA Workshop, pages 254-259." ></td>
	<td class="line x" title="152:249	Vasileios Hatzivassiloglou and Kathleen McKeown." ></td>
	<td class="line x" title="153:249	1993." ></td>
	<td class="line x" title="154:249	Towards the automatic identification of adjectival scales: Clustering of adjectives according to meaning." ></td>
	<td class="line x" title="155:249	In 31st Annual Meeting of the ACL, pages 172-182." ></td>
	<td class="line x" title="156:249	Vasileios Hatzivassiloglou." ></td>
	<td class="line x" title="157:249	1996." ></td>
	<td class="line x" title="158:249	Do we need linguistics when we have statistics?" ></td>
	<td class="line x" title="159:249	A comparative analysis of the contributions of linguistic cues to a statistical word grouping system." ></td>
	<td class="line x" title="160:249	In Judith L. Klavans and Philip Resnik, editors, The Balancing Act, pages 6794." ></td>
	<td class="line x" title="161:249	MIT Press." ></td>
	<td class="line x" title="162:249	Don Hindle." ></td>
	<td class="line x" title="163:249	1990." ></td>
	<td class="line x" title="164:249	Noun classification from predicate-argument structures." ></td>
	<td class="line x" title="165:249	In 28th Annual Meeting of the A CL, pages 268-275." ></td>
	<td class="line x" title="166:249	Frederick Jelinek and Robert L. Mercer." ></td>
	<td class="line x" title="167:249	1980." ></td>
	<td class="line x" title="168:249	Interpolated estimation of Markov source parameters from sparse data." ></td>
	<td class="line x" title="169:249	In Proceedings of the Workshop on Pattern Recognition in Practice." ></td>
	<td class="line x" title="170:249	William P. Jones and George W. Furnas." ></td>
	<td class="line x" title="171:249	1987." ></td>
	<td class="line x" title="172:249	Pictures of relevance." ></td>
	<td class="line x" title="173:249	Journal of the American Society for Information Science, 38(6):420-442." ></td>
	<td class="line x" title="174:249	Yael Karov and Shimon Edelman." ></td>
	<td class="line x" title="175:249	1998." ></td>
	<td class="line x" title="176:249	Similarity-based word sense disambiguation." ></td>
	<td class="line x" title="177:249	Computational Linguistics, 24(1):41-59." ></td>
	<td class="line x" title="178:249	Slava M. Katz." ></td>
	<td class="line x" title="179:249	1987." ></td>
	<td class="line x" title="180:249	Estimation of probabilities from sparse data for the language model component of a speech recognizer." ></td>
	<td class="line x" title="181:249	IEEE Transactions on Acoustics, Speech and Signal Processing, ASSP-35(3):400--401, March." ></td>
	<td class="line x" title="182:249	Leonard Kanfman and Peter J. Rousseeuw." ></td>
	<td class="line x" title="183:249	1990." ></td>
	<td class="line x" title="184:249	Finding Groups in Data: An Introduction to Cluster Analysis." ></td>
	<td class="line x" title="185:249	John Wiley and Sons." ></td>
	<td class="line x" title="186:249	Lillian Lee." ></td>
	<td class="line x" title="187:249	1997." ></td>
	<td class="line x" title="188:249	Similarity-Based Approaches to Natural Language Processing." ></td>
	<td class="line x" title="189:249	Ph.D. thesis, Harvard University." ></td>
	<td class="line x" title="190:249	Dekang Lin." ></td>
	<td class="line x" title="191:249	1997." ></td>
	<td class="line x" title="192:249	Using syntactic dependency as local context to resolve word sense ambiguity." ></td>
	<td class="line x" title="193:249	In 35th Annual Meeting of the ACL, pages 64-71." ></td>
	<td class="line x" title="194:249	Dekang Lin." ></td>
	<td class="line x" title="195:249	1998a." ></td>
	<td class="line x" title="196:249	Automatic retrieval and clustering of similar words." ></td>
	<td class="line x" title="197:249	In COLING-A CL '98, pages 768-773." ></td>
	<td class="line x" title="198:249	Dekang Lin." ></td>
	<td class="line x" title="199:249	1998b." ></td>
	<td class="line x" title="200:249	An information theoretic definition of similarity." ></td>
	<td class="line x" title="201:249	In Machine Learning: Proceedings of the Fiftheenth International Conference (ICML '98)." ></td>
	<td class="line x" title="202:249	Jianhua Lin." ></td>
	<td class="line x" title="203:249	1991." ></td>
	<td class="line x" title="204:249	Divergence measures based on the Shannon entropy." ></td>
	<td class="line x" title="205:249	IEEE Transactions on Information Theory, 37(1):145-151." ></td>
	<td class="line x" title="206:249	Alpha K. Luk." ></td>
	<td class="line x" title="207:249	1995." ></td>
	<td class="line x" title="208:249	Statistical sense disambiguation with relatively small corpora using dictionary definitions." ></td>
	<td class="line x" title="209:249	In 33rd Annual Meeting of the ACL, pages 181-188." ></td>
	<td class="line x" title="210:249	Hwee Tou Ng and Hian Beng Lee." ></td>
	<td class="line x" title="211:249	1996." ></td>
	<td class="line x" title="212:249	Integrating multiple knowledge sources to disambiguate word sense: An exemplar-based approach." ></td>
	<td class="line x" title="213:249	In 3~th Annual Meeting of the ACL, pages 40--47." ></td>
	<td class="line x" title="214:249	Hwee Tou Ng." ></td>
	<td class="line x" title="215:249	1997." ></td>
	<td class="line x" title="216:249	Exemplar-based word sense disambiguation: Some recent improvements." ></td>
	<td class="line x" title="217:249	In Second Conference on Empirical Methods in Natural Language Processing (EMNLP-2), pages 208-213." ></td>
	<td class="line x" title="218:249	C. Radhakrishna Rao." ></td>
	<td class="line x" title="219:249	1982." ></td>
	<td class="line x" title="220:249	Diversity: Its measurement, decomposition, apportionment and analysis." ></td>
	<td class="line x" title="221:249	SankyhZt: The Indian Journal of Statistics, 44(A):1-22." ></td>
	<td class="line x" title="222:249	Philip Resnik." ></td>
	<td class="line x" title="223:249	1995." ></td>
	<td class="line x" title="224:249	Using information content to evaluate semantic similarity in a taxonomy." ></td>
	<td class="line x" title="225:249	In Proceedings of IJCAI-95, pages 448-453." ></td>
	<td class="line x" title="226:249	Gerard Salton and Michael J. McGill." ></td>
	<td class="line x" title="227:249	1983." ></td>
	<td class="line x" title="228:249	Introduction to Modern Information Retrieval." ></td>
	<td class="line x" title="229:249	McGraw-Hill." ></td>
	<td class="line x" title="230:249	Frank Smadja, Kathleen R. McKeown, and Vasileios Hatzivassiloglou." ></td>
	<td class="line x" title="231:249	1996." ></td>
	<td class="line x" title="232:249	Translating collocations for bilingual lexicons: A statistical approach." ></td>
	<td class="line x" title="233:249	Computational Linguistics, 22(1):1-38." ></td>
	<td class="line x" title="234:249	Craig Stanfill and David Waltz." ></td>
	<td class="line x" title="235:249	1986." ></td>
	<td class="line x" title="236:249	Toward memory-based reasoning." ></td>
	<td class="line x" title="237:249	Communications of the ACM, 29(12):1213-1228." ></td>
	<td class="line x" title="238:249	K. Sugawara, M. Nishimura, K. Toshioka, M. Okochi, and T. Kaneko." ></td>
	<td class="line x" title="239:249	1985." ></td>
	<td class="line x" title="240:249	Isolated word recognition using hidden Markov models." ></td>
	<td class="line x" title="241:249	In ICASSP 85, pages 1-4." ></td>
	<td class="line x" title="242:249	C. J. van Rijsbergen." ></td>
	<td class="line x" title="243:249	1979." ></td>
	<td class="line x" title="244:249	Information Retrieval." ></td>
	<td class="line x" title="245:249	Butterworths, second edition." ></td>
	<td class="line x" title="246:249	Jakub Zavrel and Walter Daelemans." ></td>
	<td class="line x" title="247:249	1997." ></td>
	<td class="line x" title="248:249	Memory-based learning: Using similarity for smoothing." ></td>
	<td class="line x" title="249:249	In 35th Annual Meeting of the A CL, pages 436-443 ." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C00-2104
Experiments In Automated Lexicon Building For Text Searching
Schiffman, Barry;McKeown, Kathleen R.;"></td>
	<td class="line x" title="1:269	Experiments in Automated Lexicon Building for Text Searching Barry Schiffman and Kathleen R. McKeown Department of Computer Science Columbia University New York, NY 10027, USA { bschiff,kathy} @)cs.columbia.edu Abstract This paper describes experiment's in the automat'ic construction of lexicons that would be useflfl in searching large document collect'ions tot text frag~ ments tinct address a specific inibrmation need, such as an answer to a quest'ion." ></td>
	<td class="line x" title="2:269	1 Introduction In develot)ing a syst'em to find answers in text to user questions, we mmovered a major obstacle: Doemnent sentences t'hat contained answers dkl not of_ ten use the same expressions as the question." ></td>
	<td class="line x" title="3:269	While an:;wers in documents and questiolts llse terms that' are relat'e(l to each other, a system that sear(:hes for answers based on the quesl:ion wording will often fail." ></td>
	<td class="line x" title="4:269	3.b address t'his probleln, we develol)ed techniques to al,tomatically build a lexicon of associated terms t'hat can be used to hell) lind al)lIrol/riate bext' seglllent,s. The mismatch })et'ween (tuestion an(l doctlttlent wording was I)rought home to us in an analysis of a testbed of question/answer l/airs." ></td>
	<td class="line x" title="5:269	\~Ze had a collection of newswire articles about the Clinton impeachment t'() use as a small-scale corl)uS fin' development of ;_t system." ></td>
	<td class="line x" title="6:269	V~Ze asked several l)eol)le to 1)ose questions about this well-known t'opic, but we (lid not make the corpus availal)le to our cont'ril)utors." ></td>
	<td class="line x" title="7:269	\~Ze wanted to avoid quest'ions that tracked t'he terminology in t'he corlms too (:losely to sinnllate quest'ions t'o a real-world syst'em." ></td>
	<td class="line x" title="8:269	The result was a set of questions that used language that' rarely nmtched t'he phrasing in the." ></td>
	<td class="line x" title="9:269	corl)us." ></td>
	<td class="line x" title="10:269	\,Ve had expected t'hat' we would be able to make most of these lexical connections with the hel l) of V~rordnet (Miller, 1990)." ></td>
	<td class="line x" title="11:269	For example, consider a simple quest'ion al)out testimony: 'Did Secret Service agents give testimony about' Bill Clinton'?" ></td>
	<td class="line x" title="12:269	There is no reason t'o expect that' the answer would appear 1)aldly st'ated as 'Secret Service." ></td>
	<td class="line x" title="13:269	agents dkl testi(y ' What we need to know is what' testimony is about', where it: occurs, who gives it." ></td>
	<td class="line x" title="14:269	The answer would lie likely to be found in a passage ment'ioning juries, or 1)roseeut'ors, like these tbund in our Clinton corl)uS: Starr immediately brought Secret Service employees before tim grand jury for questioning." ></td>
	<td class="line x" title="15:269	Prosecutors repeat'edly asked Secret Serviee 1)ersonnel to rel)eat' gossil) they may have heard." ></td>
	<td class="line x" title="16:269	Yet, tile V~ordnet synsets fbr 'testinlony' offer: 'evidence, assertion, averment alia asseveration,' not a very hell)tiff selection here." ></td>
	<td class="line x" title="17:269	-Wordnet hypernyms become general quickly: 'declarat'ion,' 'indicat'ion' and 'inforlnation' are only one st, eli u 1) in t'lle hierarehy." ></td>
	<td class="line x" title="18:269	Following these does not lead us into a courtroom." ></td>
	<td class="line x" title="19:269	We asked our cont'ril)ut'ors for a second round of questions, but this time made the corpus available to them, exl)laining t'hat we wanted to be sure the answers were contained in t'he collection of articles." ></td>
	<td class="line x" title="20:269	'J'he result was a set of questions that' mueh more closely matched t'he wording in the corpus." ></td>
	<td class="line x" title="21:269	This was~ in t'aet, what' the 1999 DARPA question-answering (:oml)et'ition did in order t'o ensure that their questions couhl be answered (Singhal, 1!199)." ></td>
	<td class="line x" title="22:269	The sectrod question-answering conference adopted a new approach to gathering questions and verifying separately that' they a.re answerable." ></td>
	<td class="line x" title="23:269	Our intuition is t'hat if we can lind the tyl)ical lexical neighborhoods of concept's, we can efficiently locate a concept described in a query or a question without needing to know the precise way the answer is phrased and without relying on a cost'ly, handbuilt concept' hierarchy." ></td>
	<td class="line x" title="24:269	The example above illustrat'es the 1)oint." ></td>
	<td class="line x" title="25:269	Testimony is given 1) 3, wit'nesses, defendant's, eyewitnesses." ></td>
	<td class="line x" title="26:269	It is solicited by 1)rosecutors, counsels, lawyers." ></td>
	<td class="line x" title="27:269	It is heard by judges, juries at trials, hearings, and recorded in depositions and transcripts." ></td>
	<td class="line x" title="28:269	What' we wanted was a complete description of t'he world of testimony the who, what, when and where of the word." ></td>
	<td class="line x" title="29:269	Or, in other words, the 'metaaboutness' of terms." ></td>
	<td class="line x" title="30:269	To this end, we exl)erimented /tSitlg shallow linguist.k: techniques t'o gat'her and analyze word cooccurrence data in various configurat'ions." ></td>
	<td class="line x" title="31:269	Unlike previous collocation research, we were int'erested in an expansive set' of relationships between words 719 rather than a specific relationship." ></td>
	<td class="line x" title="32:269	More important, we felt that the information we needed could be derived from an analysis that crossed clause and sentence boundaries." ></td>
	<td class="line x" title="33:269	We hyl)othesized that news articles would be coherent so that the sequences of sentences and clauses would be linked conceptually." ></td>
	<td class="line x" title="34:269	We exanfined the nouns in a number of configurations paragraphs, sentences, clauses and sequences of clauses and obtained tile strongest results from configurations that count co-occurrences across the surface subjects of sequences of two to six clauses." ></td>
	<td class="line x" title="35:269	Exl)eriments with multi-clause configurations were generally more accurate in a variety of experiments." ></td>
	<td class="line x" title="36:269	In the next section, we briefly review related research." ></td>
	<td class="line x" title="37:269	In section 3 we describe our experiments." ></td>
	<td class="line x" title="38:269	In section 4, we discuss the problem of evaluation, and look ahead to future directions in the concluding sections." ></td>
	<td class="line x" title="39:269	2 Related Work There has been a large body of work ill the collection of co-occurrence data from a broad spectrum of perspectives, fi'om information retrieval to the developnlent of statistical methods for investigating word similarity and classification." ></td>
	<td class="line x" title="40:269	Our efforts fall somewhere in tile middle." ></td>
	<td class="line x" title="41:269	Compared with document retrieval tasks, we are more closely focused on the words themselves and on specific concepts than on document 'aboutness'." ></td>
	<td class="line x" title="42:269	Jing and Croft (1994) exanfined words and phrases in paragraph units, and found that the association data improves retrieval performance." ></td>
	<td class="line x" title="43:269	Callan (1994) compared paragraph units and fixed windows of text in examining passage-level retrieval." ></td>
	<td class="line x" title="44:269	In the question-answering context, Morton (1999) collected document co-occurrence statistics to uncover 1)art-whole and synonymy relationships to use in a question-answering system." ></td>
	<td class="line x" title="45:269	The key difference here was that co-occurrence was considered on a whole-docmnent basis." ></td>
	<td class="line x" title="46:269	Harabagiu and Maiorano (1999) argued that indexing in question answering should be based on 1)aragraphs." ></td>
	<td class="line x" title="47:269	One recent al)proach to automatic lexicon building has used seed words to lmild up larger sets of semmltically similar words in one or nlore categories (Riloff and Shepherd, 1997)." ></td>
	<td class="line x" title="48:269	In addition, Strzalkowski and Wang (1996) used a bootstrapping technique to identify types of references, and Riloff and Jones (1999) adapted bootstrapping techniques to lexicon building targeted to information extraction." ></td>
	<td class="line x" title="49:269	In the same vein, researchers at Brown University (Caraballo and Charniak, 1999)~ (Berland and Charniak, 1999), (Caraballo, 1999) and (Roark and Charniak, 1998) focused on target constructions, in particular complex noun t)hrases, and searched for information not only on identifying classes of nouns, lint also hypernyms, noun specificity and meronymy." ></td>
	<td class="line x" title="50:269	We have a diflbrent perspective than these lines of inquiry." ></td>
	<td class="line x" title="51:269	They were specifying various semantic relationships and seeking ways to collect similar pairs." ></td>
	<td class="line x" title="52:269	We." ></td>
	<td class="line x" title="53:269	have a less restrictive focus and are relying on surface syntactic information about clauses." ></td>
	<td class="line x" title="54:269	For more than a decade, a variety of statistical techniques have been developed and refilled." ></td>
	<td class="line x" title="55:269	Tile focus of much of this work was to develop the methods themselves." ></td>
	<td class="line x" title="56:269	Church and Hanks (1989) explored tile use of mutual information statistics in ranking co-occurrences within five-word windows." ></td>
	<td class="line x" title="57:269	Smadja (1992) gathered co-occurrences within fiveword windows to find collocations, particularly in specific domains." ></td>
	<td class="line oc" title="58:269	Hindle (1990) classified nouns on the basis of co-occurring patterns of subjectverb and verb-object pairs." ></td>
	<td class="line x" title="59:269	Hatzivassiloglou and MeKeown (1993) clustered adjectives into semantic classes, and Pereira et al.(1993) clustered nouns on their appearance ill verb-object pairs." ></td>
	<td class="line x" title="61:269	We are trying to be less restrictive in learning multiple salient relationshil)s between words rather than seeldng a particular relationship." ></td>
	<td class="line x" title="62:269	Ill a way, our idea is the mirror image of Barzilay and Elhadad (1997), who used Wordnet to identify lexical chains that would coincide with cohesive text segments." ></td>
	<td class="line x" title="63:269	We assunmd that documents are cohesive and that co-occurrence l)atterns call uncover word relationships." ></td>
	<td class="line x" title="64:269	3 Experiments Tile focus of onr experiment was on units of text in which the constituents must fit together in order for the discourse to be coherent." ></td>
	<td class="line x" title="65:269	We made the assumption that the documents in our corpus were coherent and reasoned that if we had enough text, covering a broad range of topics, we could pick out domainindependent associations." ></td>
	<td class="line x" title="66:269	For example, testimony can be about virtually anything, since anything can wind up in a court dispute." ></td>
	<td class="line x" title="67:269	But over a large enough collection of text, the terms that directly relate to tile 'who,' 'what' and 'where' of testimony per se should appear in segments with testimony more frequently than chance." ></td>
	<td class="line x" title="68:269	These associations do not necessarily appear in a dictionary or thesaurus." ></td>
	<td class="line x" title="69:269	When huntans explain all unfamiliar word, they often use scenarios and analogies." ></td>
	<td class="line x" title="70:269	We divided the experiments in two groups: one group that looks at co-occurrences within a single unit, and another that looks at a sequence of units." ></td>
	<td class="line x" title="71:269	In the first group of experinmnts, we considered paragraphs, sentences and clauses, each with and without prepositional phrases." ></td>
	<td class="line x" title="72:269	 Single paragraphs with/without PP  Single sentences with/without PP  Single clauses with/without PP 720 \]in the second group, we considered two clauses and sequences of subject 110un phrases from two to six chmses." ></td>
	<td class="line x" title="73:269	Ill this group, we had:,, Two clauses with/without Pl),, A sequence of subject NPs fl'onl 2 clauses A sequence of subject NPs Dora 3 clauses,, A sequence of subject NPs from 4 clauses  A sequence of subject NPs fi'om 5 clauses,, A sequence of subject NPs from 6 clauses The intuition for the second groul) is that a topic flows from one granmm.tical unit to another so that the salient nouns, l)articularly the surface subjects, in successive clauses should reveal the associations we are seeldng." ></td>
	<td class="line x" title="74:269	'\[lo illustrate the method, consider the three-clause configuration: Say that ~vordi apl)ears in clausc,~." ></td>
	<td class="line x" title="75:269	We maintain a table of all word pairs and increment the entries for O,,o,'(h, ',,,o,'d~ ), where,,0,% is a subject noun in cla'usc,~, clauscn+~, or ell'use,+2." ></td>
	<td class="line x" title="76:269	No effort was made to resolve pronomial references, and these were skipped." ></td>
	<td class="line x" title="77:269	We used nollnS Olfly' because l)reliminary tests showed that pairings between nouns seemed to stand out." ></td>
	<td class="line x" title="78:269	V~Te included tokens that were tagged as 1)roper nallleS when they also have have conlnlon nleanings." ></td>
	<td class="line x" title="79:269	For example, consider the Linguistic Data Consorl;ium at the University of Pennsylvania." ></td>
	<td class="line x" title="80:269	Data, Consortium and University wouM be on tile list used to build the table of nmtchul)s with other nouns, \])lit l)emlsylvania would not." ></td>
	<td class="line x" title="81:269	V~To also collected noun modifiers as well as head nouns as they can carry more information than the surface heads, such as 'business group', ''.science class' or 'crinm scene'." ></td>
	<td class="line x" title="82:269	The corpus consisted of all tile general-interest articles from the New York Tinms newswire in 1996 in the North American News Corlms, and (lid not include either st)orts or l)usiness news." ></td>
	<td class="line x" title="83:269	We tirst removed dul)licate articles." ></td>
	<td class="line x" title="84:269	The data fl'om 1996 was too slmrse for the sequence-of-subjects contiguralions." ></td>
	<td class="line x" title="85:269	'\]'o l)alance the expcrinmnts better, we added another year's worth of newswire articles, from 1995, tbr the sequence-of subject configurations so that we had more than one million matchups for each configuration (Table 1)." ></td>
	<td class="line x" title="86:269	The I)roeess is flflly automatic, requiring no su1)ervision or training examples." ></td>
	<td class="line x" title="87:269	The corpus was tagged with a decision-tree tagger (Schmid, 1994) and parsed with a finite-state parser (Abney, 1996) using a specially written context-fi'ee-grannnar that focused on locating clause boundaries." ></td>
	<td class="line x" title="88:269	The grammar also identified extended noun l)hrases in tile subject position, verb l)hrases and other noun l)hrases and prepositional 1)hrases." ></td>
	<td class="line x" title="89:269	The nouns in the tagged, parsed corl)uS were reduced to their syntactic roots (removing l)lurals from nouns) with a lookup table created t'rom Wordnet (Miller, 1990) and CELEX (1995)." ></td>
	<td class="line x" title="90:269	We." ></td>
	<td class="line x" title="91:269	performed this last step mainly to address the sparse data problem." ></td>
	<td class="line x" title="92:269	There were a substantial nunfl)er of paMngs that occurred only once." ></td>
	<td class="line x" title="93:269	We elinfinated from considerat;ion all such singletons, although it did not al)peal to have much etfect on the overall outcome." ></td>
	<td class="line x" title="94:269	Confi.q Matchups Para +pp 6.5 million Sent 1.7 million Sent +pp 4 million 1 Clause 1.1 million 1 Clause +pp 2.8 million 2 Clause 1.9 million 2 Clause +I)P 5 nfillion Subj 2 Clause 1.1 million* Subj 3 Clause 1.6 million* Subj 4 Clause 2.1 million* Subj 5 Clause 2.6m~ Subj 6 Clause 3.1 million* 'lhble 1: Nmnl)er of matchut)s ibund; tile '*' denotes the inclusion of 1995 data There were about 1.2 million paragraphs, 2.2 million sentences and 3.4 million clauses in the selected portions of the 1996 COl'pus." ></td>
	<td class="line x" title="95:269	The total number of words was 57 million." ></td>
	<td class="line x" title="96:269	Table 2 shows the nmnl)er of distinct nouns." ></td>
	<td class="line x" title="97:269	I I All Extracted No l)ps 74,500 W/pps 91,700 Subjs 51,000 Counts > 1." ></td>
	<td class="line x" title="98:269	44,400 53,900 30,800 Td)le 2: Distinct Nouns, 1996 Data To score the nmtchups in our initial exlmriments, we used the Dice Coeliicient, which l)roduces values i'ronl 0 to 1, to measure the association between pairs of words and then produced an ordered association list fl'om the co-occurrence table, ranked according to the scores of the entries." ></td>
	<td class="line x" title="99:269	2  f,'~q(wo,.,h n,oo,%) score,, = frcq(wordi) + frcq(wordj) One 1)roblem was immediately a l)parent: The quality of tile association lists wxried greatly." ></td>
	<td class="line x" title="101:269	Tile scoring was doing an acceptable job in ranking the words within each list, but tile scores varied greatly from one list to another." ></td>
	<td class="line x" title="102:269	Our initial strategy was to choose a cutoff, which we set at 21 tbr each list, and we tried several alternatives to weed out weak associations." ></td>
	<td class="line x" title="103:269	721 In one method, we filtered the association lists by cross-referencing, removing from the association list for wordi any wordj that failed to reciprocate and to give a high rank to wordi on its association list." ></td>
	<td class="line x" title="104:269	Another similar approach was to try to con> bine evidence fl'om different experiments by taking the results fl'om two configurations into consideration." ></td>
	<td class="line x" title="105:269	A third strategy was to calculate the mutual information between the target word and the other words on its association list." ></td>
	<td class="line x" title="106:269	scorc,,i = p(xy) * log \p(z)p(y) (p(xy) ) Using the mutual information computation provided an way of using a single measure that was able to compare matchups across lists." ></td>
	<td class="line x" title="107:269	We set a threshold of lxl.0 -6 for all matchups." ></td>
	<td class="line x" title="108:269	Thus these association lists vary in length, depending on the distributions for the words, allowing them to grow up to 40, while some ended up with only one or two words." ></td>
	<td class="line x" title="109:269	4 Evaluation The evaluation of a system like ours is problematic." ></td>
	<td class="line x" title="110:269	The judgments we made to determine correctness were not only highly subjective but time-consunfing." ></td>
	<td class="line x" title="111:269	We had 12 large lexicons fl'om the different configurations." ></td>
	<td class="line x" title="112:269	We had chosen a random sample of 10 percent of the 2,700 words that occurred at least 100 times in tile corpus, and manually constructed an answer key, which ended up with ahnost 30,000 entries." ></td>
	<td class="line x" title="113:269	From the resulting 270 words, we discarded 15 of those that coincided with common names of people, such as 'carter,' which could refer to the former American president, Chris Carter (creator of tile television show 'X-Files'), among others." ></td>
	<td class="line x" title="114:269	We thought it better to delay making decisions on how to handle such cases, especially since it would require distinguishing one Carter fl'om another." ></td>
	<td class="line x" title="115:269	Such words presented several difficulties." ></td>
	<td class="line x" title="116:269	Unless the individuals involved were well-known, it was often impossible to distinguish whether the system was making errors or whether the resulting descriptive terms were intbrmative." ></td>
	<td class="line x" title="117:269	Tables 3 and 4 show an example from the answer key tbr the word 'faculty'." ></td>
	<td class="line x" title="118:269	The overall results from the first stage of the process, before the cross-referencing filter are shown in Table 5, ranging from 73% to 80% correct." ></td>
	<td class="line x" title="119:269	The configurations that included prepositional phrases and those that used sequences of subject noun phrases outperformed the configurations that relied on suhjects and objects in a single grammatical unit." ></td>
	<td class="line x" title="120:269	These differences were statistically significant, with p < 0.01 in all eases." ></td>
	<td class="line x" title="121:269	The overall results after cross-referencing, in Table 6, showed improvements of 5 to 10 percentage enrollment hiring adnfinistrator journalism alumnus student school union math engineering curriculum trustee group seminar thesis tenure stair department mathematician educator member ivy arts college chancellor report senate activism university el,airman professor teaching law regent doctorate mtministration academic committee semester board camI)us undergraduate salary council research president adviser mathematics course advisor sociology dean study science teacher cannon provost vote Table 3: Answer Key for Faculty: OK load tratllcway unrest architecture diversity hurdle shield minority revision disburse percent woman clement Table 4: Answer Key ff)r Faculty: Wrong points, while the effect of the number of matchups was diminished." ></td>
	<td class="line x" title="122:269	Here, the subject-sequence configurations showed a distinct advantage." ></td>
	<td class="line x" title="123:269	While more noise might be expected when a large segment of text; is considered, these results support the notion that the nnderlying coherence of a discourse can be recovered with the prol)er selection of linguistic features." ></td>
	<td class="line x" title="124:269	The improvements in each configuration over the corresponding configuration in the first stage were all statistically significant, with p < 0.01." ></td>
	<td class="line x" title="125:269	Likewise, the edge the sequence-of subjects configurations had over tile other configurations, was also statistically significant." ></td>
	<td class="line x" title="126:269	The results fl'om combining the evidence from different configurations, in Table 7, showed a much higher accnrae> but a sharp drop in the total nnmber of associated words found." ></td>
	<td class="line x" title="127:269	The most fl'uitful pairs of experiments were those that combined distinct approaches, for example, tile five-subject configuration with either fifll paragraphs or with sentences with prepositional phrases." ></td>
	<td class="line x" title="128:269	It will remain unclear until we conduct a task-based evaluation whether the smaller number of associations will be harnfful." ></td>
	<td class="line x" title="129:269	The final experiment, computing the mutual information statistic tbr the matchul)s of a key word with co-occurring words was perhaps the most illteresting because it gave us the ability to apply a 722 (Jontig OK Wrong l)ct OK Para +l/l) 3832 1054 78,qent 3773 1270 75 Sent +Pl) 3973 1070 79 \] Clause 3652 1371 73 \] Clauses q-l)l) 3935 1108 78 '!" ></td>
	<td class="line x" title="130:269	Clauses 3695 1328 74 '!" ></td>
	<td class="line x" title="131:269	Clauses -t-l)l) 3983 1018 80 Subj 2 CI 3877 1139 77 Sul)j 3 CI 3899 1117 78 Subj 4 CI 3!)(/5 :1082 78 Sul)j 5 C1 390d 1076 78 Sul)j 6 CI 3909 1066 7)!" ></td>
	<td class="line x" title="132:269	Table 5: Results 13efore Cross Iloferencing Contig ()K Wrong Pet ()K Para q-Pl) 3651} 73/1 83 Sent 3328 742 82 Sent -bpp 3751 8:18 82 :1 Clause 3067 748 80 1 Clauses +1)I / 3659 826 82 2 Cbmses 3048 55d 85 2 Clauses +pp 3232 60d 8d Subj 2 CI 2910 450 87 t-;ul~j 3 CI 3020 4d() 87 Subj 4 CI 3050 d28 88 l~tll).j 5 (J\] ;1:12t3 dd2 88 Subj 6 C1 3237 dd9 88 'lhble 6: lesults After Cross Referencing single threshold across different key words, saving the effort of performing the cross-retbrencing calm> lations and providing a deeper assorl:ment in SOllle C~lSeS." ></td>
	<td class="line x" title="133:269	lilt lnost of the configurations, lltlltllPl illfOrmat.ion gave 118 lllore \Vol'ds, and greater ln'ecision at; the sanle time, but nlost of all, gave us a reasonable threshold to apply throughout the exlicrinlent." ></td>
	<td class="line x" title="134:269	While the accuracies in most of the configurations were close to one another, those that used only sing\]e units tended to be weaker than the multi-clause units." ></td>
	<td class="line x" title="135:269	Note that the paragraI)h contiguration was tested with far more data than any of the others." ></td>
	<td class="line x" title="136:269	Our system maD~s no eth)rt to aeCOllnt for lexical aml)iguil;y. The uses we intend for our lexicon should provide some insulation from the ett'ects of polysemy, since searches will be conducted on a nun> l)er of terms, which should converge to one meaning." ></td>
	<td class="line x" title="137:269	It is clear that in lists for key words with multiple senses, the donfinant sense where there is one, al)pears much lnore frequently, such as 'faculty,' where the meaning of 'teacher' is more t:'re(tuent than the meaning of 'al)ility'." ></td>
	<td class="line x" title="138:269	Figure \] shows the top 21 words in the sequence-otCsix subjects, beibre the cross-referencing iilter was applied." ></td>
	<td class="line x" title="139:269	Twenty of the 21." ></td>
	<td class="line x" title="140:269	entries were scored aeceptal)le." ></td>
	<td class="line x" title="141:269	After the cross-referencing is applied, doctorate,, education and revision were elinfinated." ></td>
	<td class="line x" title="142:269	Contig OK \rong Pcl; OK l~ara 2003 183 92 Sent 1962 222 90 Sent-t2033 213 91 1 Clause 1791 218 89 1 Clause+ 2004 198 91 2 Clause 2028 277 88 2 Clause+ 2:129 24,1 90 Tal)le 7: Results of coml)ining evidence; all configurations were combined with the sequence of six subjects Conlig OK 'Wrong Pet OK Para +pp 4923 807 86 Sent 5193 990 84 Sent +Pl) 4876 775 86 1 Claus(; 52!)!/ 1233 81 1 Clauses-t-l)l) 5047 878 85 2 Clauses 5025 928 84 2 Clauses -I-Pl) d668 728 87 Subj 2 C1 5229 939 85 Subj 3 C1 5187 860 85 Subj ~1 C1 5119 808 86 Subj 5 C1 500'{ 76d 87 Subj 6 CI 4!)80 736 87 Table 8: llesults with mutual information The results from the single clause configuration (Figure 2) were almost as strong, with three erroFs, and a fair amount of overlap between the two." ></td>
	<td class="line x" title="143:269	The word 'admiral' was more difficult %r the ex\])erilllellt ilSilig the l)ice coefficient." ></td>
	<td class="line x" title="144:269	The." ></td>
	<td class="line x" title="145:269	list shows some of l.he confusion arising from our strate.~y Oll prot)er nouns." ></td>
	<td class="line x" title="146:269	Admiral would be expected to occur with many proper ll~tnles, illcluding some that axe st)elled liD; common 11o1111.q, bill the list h)r the single clause q pp configuratkm presented a lmzzling list (Figure 3)." ></td>
	<td class="line x" title="147:269	The sparseness of the data is also al)lmrent, but it was the dog reDxenees that al)peared quite strange at a ghulce: Inspection of the." ></td>
	<td class="line x" title="148:269	articles showed that they callle froln all a.rticle on the pets of famous people." ></td>
	<td class="line x" title="149:269	Note that the dogs did not al)l)ear in top ranks of the sequence of subjects configuration in the Dice experiment (Figure 4), nor were they in the results t'rom the experiments with cross-referencing, combining evidence and mutual information." ></td>
	<td class="line x" title="150:269	After cross-reR;rencing, the much-shorter list for the Sub j-6 configuration had 'aviator', 'break-up', ';commander', 'decoration', 'equal-ot)portunity', 'tleet', 'merino', 'navf', 'pearl', 'promotion', 'rear' ~ alia 'short'." ></td>
	<td class="line x" title="151:269	'l'he combined-evidence list contained only eight words: 'navy', 'short', 'aviator', 'merino', 'dishonor', 'decoration', 'sul)' and 'break-ul)'." ></td>
	<td class="line x" title="152:269	Using the mutual intbrlnation scoring, the list in the Subj-6 configuration tbr admiral had only 723 faculty trustee(51) 0.053; carat)us(d1) (/.045; college(ll3) 0.034; member(369) 0.028; professor(102) 0.028; university(203) 0.027; student(206) 0.025; regent(19) 0.025; tenure(15) 0.025; ctmncellor(28) 0.023; administrator(34) 0.023; provost(12) 0.023; dean(27) 0.021; ahmmus(13) 0.021; math(12) 0.017; revision(8) 0.013; salary(13) 0.013; sociology(7) 0.013; educator(l l) 0.012; doctorate(6) 0.011." ></td>
	<td class="line x" title="153:269	teaching(9) 0.011; Figure 1: Tile top-ranked matchups for 'faculty' from the Subj-6-Clause configuration before cross-referencing." ></td>
	<td class="line x" title="154:269	The nmnbers in parentheses are the number of matchups and the real umnbers following are the scores." ></td>
	<td class="line x" title="155:269	Errors are in bold faculty trustee(31) 0.033; meml)er(266) 0.025; adnfinistrator(31) 0.023; college(42) 0.012; dean(15) 0.012; tenure(8) 0.011; ivy(6) 0.011; staff(a3) 0.01; semester(6) 0.01; regent(7) 0.01; salary(12) 0.01; math(7) 0.008; professor(a1) 0.008; load(6) 0.007; curricuhun(5) 0.006; revision(4) 0.006; minority(ll) 0.006; Figure 2: The top-ranked matchups for 'faculty' under the single clause confignration." ></td>
	<td class="line x" title="156:269	Errors are in bold." ></td>
	<td class="line x" title="157:269	nine words: 'navy', 'general', 'commander', 'vice', 'promotion', 'officer', 'fleet', 'military' and 'smith'." ></td>
	<td class="line x" title="158:269	Finally, the even-sparser mutual information list for the paragraph configuration lists only 'navy' and 'suicide'." ></td>
	<td class="line x" title="159:269	5 Conclusion Our results are encouraging." ></td>
	<td class="line x" title="160:269	We were able to decipher a broad type of word association, and showed that our method of searching sequences of subjects outperformed the snore traditional approaches in finding collocations." ></td>
	<td class="line x" title="161:269	We believe we can use tiffs technique to build a large-scale lexicon to help in difficult information retrieval and information extraction tasks like question answering." ></td>
	<td class="line x" title="162:269	The most interesting aspect of' this work lies in the system's ability to look across several clauses and strengthen tile connections between associated words." ></td>
	<td class="line x" title="163:269	We are able to deal with input that contains numerous errors from the tagging and shallow parsing processes." ></td>
	<td class="line x" title="164:269	Local context has been studied extensively in recent years with sophisticated statistical tools and the availability of enormous amounts of text in digital form." ></td>
	<td class="line x" title="165:269	Perhaps we can expand this perspective to look at a window of perhaps several sentences by extracting the correct linguistic units in order to explore a large range of language processing problems." ></td>
	<td class="line x" title="166:269	admiralnavy(all) 0.027; ayMon(d) 0.024; cheating(5) 0.02; gallantry(3) 0.016; chow(4) 0.015; service,nan(d) 0.013; short(3) 0.013; wardroom(2) 0.012; american(2) 0.012; enos(2) 0.012; selfassessment(2) 0.(/11; merino(2) 0.011; ocelot(2) 0.011; wolfhound(2)0.011; igloo(2)0.011; paprika(2) 0.011; spaniel(2) 0.01; medal(8) 0.01; awe(a) 0.01; pedigree(2) 0.009; te,'rier(2) 0.009; Figure 3: Top-ranked matchups for 'adnfiral' under the clause +pp configuration." ></td>
	<td class="line x" title="167:269	admiral navy(88) 0.071; short(7) 0.03; promotion(ll) 0.027; hal)l)iness(8) 0.026; fleet(ll) 0.024; aviator(5) 0.022; mnbition(8) 0.019; merino(3) 0.019; dishonor(3)0.018; rear(4)0.018; decoration(4) 0.015; sub(a) 0.013; airman(3) 0.013; graveses(2) 0.012; submariner(2) 0.012; equalopportunity(2) 0.012; break-up(2) 0.012; commander(18) 0.012; pearl(7) 0.012; l)rophccy(d) 0.01.2; torturer(2) 0.012; Figure 4: The list for admiral fi'om the Sub j-6 contiguration." ></td>
	<td class="line x" title="168:269	6 Future Work  We will have the scoring key itself evaluated by people who are not involved in tile research." ></td>
	<td class="line x" title="169:269	 ~re are planning to conduct task-based evaluation in question answering." ></td>
	<td class="line x" title="170:269	 We are considering deploying a named entity module to provide sonic classification of which proper nouns should be counted and which should not." ></td>
	<td class="line x" title="171:269	 We 1)lan to experiment with ways to incorporate using examining verbs and making use of surface objects in the configurations with sequences of clauses, as well as strengthen the finite state grammar." ></td>
	<td class="line x" title="172:269	 We will explore using tile system to extract biographic information." ></td>
	<td class="line x" title="173:269	Acknowledgments This material is based upon work supported by tile National Science Foundation under grants Nos." ></td>
	<td class="line x" title="174:269	IIS96-19124 and IRI-96-18797, and work jointly supported by the National Science Foundation and the National Library of Medicine under grant No." ></td>
	<td class="line x" title="175:269	IIS98-17434." ></td>
	<td class="line x" title="176:269	Any opinions, findings, and conclusions or recmmnendations expressed in this material are those of tile authors and do not necessarily reflect the views of the National Science Foundation." ></td>
	<td class="line x" title="177:269	724 References Steven Abney." ></td>
	<td class="line x" title="178:269	1996." ></td>
	<td class="line x" title="179:269	Partial parsing via finite-state cascades." ></td>
	<td class="line x" title="180:269	In Proceedin9s of th, e ESSLLI '95 Robust Parsin9 Workshop." ></td>
	<td class="line x" title="181:269	Regina Barzilay and Michael Elhadad." ></td>
	<td class="line x" title="182:269	1997." ></td>
	<td class="line x" title="183:269	Using lexical chains tbr text smmnarization." ></td>
	<td class="line x" title="184:269	In Pwccedings of the Ntelligent Scalable Text b'ummarization Workshop." ></td>
	<td class="line x" title="185:269	ACL." ></td>
	<td class="line x" title="186:269	Matthew Berland and Eugene Charniak." ></td>
	<td class="line x" title="187:269	1999." ></td>
	<td class="line x" title="188:269	Finding parts in very large corpora." ></td>
	<td class="line x" title="189:269	'l.bchnical Report TR CS99-02, Brown University." ></td>
	<td class="line x" title="190:269	James P. Callan." ></td>
	<td class="line x" title="191:269	1994." ></td>
	<td class="line x" title="192:269	Passage-level evidence in document retrieval." ></td>
	<td class="line x" title="193:269	In Proceedin9s of the Seventeenth Annual Intcunational A CM SIGIR Conference, Dublin, Ireland." ></td>
	<td class="line x" title="194:269	ACM." ></td>
	<td class="line x" title="195:269	Sharon Caraballo and Eugene Charniak." ></td>
	<td class="line x" title="196:269	1999." ></td>
	<td class="line x" title="197:269	Determining the speciticity of nouns from text." ></td>
	<td class="line x" title="198:269	In P~vceedinfls of Co~@rcnce on E,mpi~eal Methods in Nat'u'ral Langua9e Processing." ></td>
	<td class="line x" title="199:269	Sharon Caraballo." ></td>
	<td class="line x" title="200:269	1999." ></td>
	<td class="line x" title="201:269	Automatic acquisition of a hylmrnym-labeled noun hierarchy from text." ></td>
	<td class="line x" title="202:269	In Pwceedings of th, e 37th Annual Meeting of the Association for Comp'utational Linguistics, June." ></td>
	<td class="line x" title="203:269	CELEX, 19!)5." ></td>
	<td class="line x" title="204:269	Tit(; CELEX lezical database Dutch,, English, Ge.rntan." ></td>
	<td class="line x" title="205:269	Centr for Lexical hfformation, Max Planck Institute for Psycholinguisties, Nijmegen." ></td>
	<td class="line x" title="206:269	Kenneth W. Church and Patrk:k Itanks." ></td>
	<td class="line x" title="207:269	1989." ></td>
	<td class="line x" title="208:269	Word association norms, mutual infornmtion and lexicography." ></td>
	<td class="line x" title="209:269	In Proceedings of th.e 27th." ></td>
	<td class="line x" title="210:269	nteetin9 of the ACL." ></td>
	<td class="line x" title="211:269	S&nda ~/\[." ></td>
	<td class="line x" title="212:269	Ilara,bagiu anti S|;even J. Maiorano." ></td>
	<td class="line x" title="213:269	1999." ></td>
	<td class="line x" title="214:269	Finding answers in large collectkms of texts: Paragraph indexiltg -tadductive inference." ></td>
	<td class="line x" title="215:269	In Q'aestion Answering Systema'." ></td>
	<td class="line x" title="216:269	AAAI, November." ></td>
	<td class="line x" title="217:269	Vasileios Hatziw~ssiloglou and Kathleen R. McKeown." ></td>
	<td class="line x" title="218:269	1993." ></td>
	<td class="line x" title="219:269	'lbwards the automatic identification of adjectival scales: Clustering adjectives according to meaning." ></td>
	<td class="line x" title="220:269	In P~vceedin9 s of th, c 31st Annual Meeting of th, e A CL. Donald Hindle." ></td>
	<td class="line x" title="221:269	1990." ></td>
	<td class="line x" title="222:269	Noun classitication ti'om predicate-argument structures." ></td>
	<td class="line x" title="223:269	In PTvceedin9s of the 28th Annual Meeting of the A CL. Yufcng Jing and W. Bruce Croft." ></td>
	<td class="line x" title="224:269	1994." ></td>
	<td class="line x" title="225:269	An association thesaurus for information retrieval, tech." ></td>
	<td class="line x" title="226:269	rep. no 94-17." ></td>
	<td class="line x" title="227:269	2bchnical report, Amherst: University of Massachusetts, Center for Intelligent hfformation Retrieval." ></td>
	<td class="line x" title="228:269	G. Millet'." ></td>
	<td class="line x" title="229:269	1990." ></td>
	<td class="line x" title="230:269	Wordnet: An on-line lexical database." ></td>
	<td class="line x" title="231:269	International.lournal of Lezicoqraphy." ></td>
	<td class="line x" title="232:269	Thomas S. Morton." ></td>
	<td class="line x" title="233:269	1999." ></td>
	<td class="line x" title="234:269	Using coreibrence tor question answering." ></td>
	<td class="line x" title="235:269	In P~vccedings of thc Workshop on Coreference and Its Applications, l)ages 85-89, College Park, Maryland, June." ></td>
	<td class="line x" title="236:269	Association for Computational Linguisties, Association for Computation Linguistics." ></td>
	<td class="line x" title="237:269	Fernando Pereira, Naffali Tishby, and Lillian Lee." ></td>
	<td class="line x" title="238:269	1993." ></td>
	<td class="line x" title="239:269	Distributional clustering of english words." ></td>
	<td class="line x" title="240:269	In Pwcecdings of the 31st Annual Meeting of the ACL." ></td>
	<td class="line x" title="241:269	Ellen Rilotf and Pmsie Jones." ></td>
	<td class="line x" title="242:269	1999." ></td>
	<td class="line x" title="243:269	Learning dietionarics for intbrmation extraction by multilevel bootstral)ping." ></td>
	<td class="line x" title="244:269	In Proceedings of the Sixteenth Na, tional Co~@rencc on Artificial Intelligence." ></td>
	<td class="line x" title="245:269	AAAI." ></td>
	<td class="line x" title="246:269	Ellen Iilotf and Jessica Shepherd." ></td>
	<td class="line x" title="247:269	1997." ></td>
	<td class="line x" title="248:269	A corpusbased approach for building semantic lexicons." ></td>
	<td class="line x" title="249:269	In Proceedings of the Second Conference on Empir~i cal Meth, ods in Natural Langua9 c Processing." ></td>
	<td class="line x" title="250:269	Brian lloark and Eugene Charniak." ></td>
	<td class="line x" title="251:269	1998." ></td>
	<td class="line x" title="252:269	Nounphrasae co-occurrence statistics for semiautomatic semantk: lexicon construction." ></td>
	<td class="line x" title="253:269	In P~vcccdings of thc 36th Annual Meetin9 of the Association for Computational Linguistics and the 17th htternational Conference on Computation Linguistics." ></td>
	<td class="line x" title="254:269	Hehnut Schmid." ></td>
	<td class="line x" title="255:269	1994." ></td>
	<td class="line x" title="256:269	Probabilistic part-of speech tagging using decision trees." ></td>
	<td class="line x" title="257:269	In Proceedings of the International Cor@rence on New Methods in Lan9ua.qe Proecssin9." ></td>
	<td class="line x" title="258:269	Amit Singhal." ></td>
	<td class="line x" title="259:269	1999." ></td>
	<td class="line x" title="260:269	Question and answer track home page." ></td>
	<td class="line x" title="261:269	WWW." ></td>
	<td class="line x" title="262:269	Frank Smadja." ></td>
	<td class="line x" title="263:269	1992." ></td>
	<td class="line x" title="264:269	Retrieving collocations fi'om text: Xtract." ></td>
	<td class="line x" title="265:269	Comp'll, tational Linguistics, Special Issue." ></td>
	<td class="line x" title="266:269	Tomek Strzalkowski and Jin V~rang." ></td>
	<td class="line x" title="267:269	1996." ></td>
	<td class="line x" title="268:269	A selflearning universal concept spotter." ></td>
	<td class="line x" title="269:269	In lhvceedinfls of th, e International 6'm@renee on Computational Linfluisties (Colin 9 199@ ." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W02-1107
Classification Of Adjectival And Non-Adjectival Nouns Based On Their Semantic Behavior By Using A Self-Organizing Semantic Map
Kanzaki, Kyoko;Ma, Qing;Murata, Masaki;Isahara, Hitoshi;"></td>
	<td class="line x" title="1:132	a0a2a1a4a3a6a5a7a5a9a8a11a10a4a8a11a12a7a3a14a13a15a8a11a16a18a17a19a16a18a10a18a20a22a21a24a23a26a25a18a12a27a13a15a8a29a28a30a3a31a1a32a3a31a17a33a21a35a34a35a16a18a17 -a3a6a21a24a23a26a25a18a12a27a13a15a8a29a28a30a3a31a1a30a34a35a16a24a36a33a17a33a5a38a37a39a3a6a5a9a25a14a21a35a16a18a17a40a13a15a41a42a25a18a8a11a43 a44a33a25a18a45a46a3a31a17a32a13a15a8a11a12a47a37a47a25a18a41a33a3a14a28a6a8a11a16a18a43a49a48a30a50a52a51a40a5a9a8a11a17a33a53a52a3a35a44a33a25a18a1a11a10 a54 a43a7a53a31a3a31a17a42a8a4a55a7a8a11a17a33a53a52a44a33a25a18a45a46a3a31a17a32a13a15a8a11a12a2a56a57a3a14a58 Kyoko Kanzaki Qing Ma Masaki Murata Hitoshi Isahara Computational Linguistics Group Communications Research Laboratory {kanzaki, qma, murata, isahara}@crl.go.jp Abstract We treat nouns that behave adjectively, which we call adjectival nouns, extracted from large corpora." ></td>
	<td class="line x" title="2:132	For example, in financial world and world of finance, financial and finance are different parts of speech, but their semantic behaviors are similar to each other." ></td>
	<td class="line x" title="3:132	We investigate how adjectival nouns are similar to adjectives and different from non-adjectival nouns by using self-organizing semantic maps." ></td>
	<td class="line x" title="4:132	We create five kinds of semantic maps, i.e., semantic maps of abstract nouns organized via (1) adjectives, (2) adjectival nouns, (3) non-adjectival nouns and (4) adjectival and adjectival nouns and a semantic map of adjectives, adjectival nouns and non-adjectival nouns organized via collocated abstract nouns, and compare them with each other to find similarities and differences." ></td>
	<td class="line x" title="5:132	1 Introduction In this paper, we propose a method for fundamental research to construct an organized lexicon, in which we classify words depending on not only their part of speech, but also their semantic categories." ></td>
	<td class="line x" title="6:132	We applied both a neural network model and a linguistic method, that is syntactic information, to a large corpora and extracted necessary information." ></td>
	<td class="line oc" title="7:132	To extract semantic information of words such as synonyms and antonyms from corpora, previous research used syntactic structures (Hindle 1990, Hatzivassiloglou 1993 and Tokunaga 1995), response time to associate synonyms and antonyms in psychological experiments (Gross 1989), or extracting related words automatically from corpora (Grefensette 1994)." ></td>
	<td class="line x" title="8:132	Most lexical classification is based on parts of speech, as they have very important semantic information." ></td>
	<td class="line x" title="9:132	For examples, typically, an adjective refers to an attribute, a verb refers to a motion or an event, and a noun refers to an object." ></td>
	<td class="line x" title="10:132	However, in real data, a semantic function of a part of speech is not defined rigidly, as shown in the above examples." ></td>
	<td class="line x" title="11:132	In spite of different parts of speech, they sometimes represent the same or very similar semantic functions." ></td>
	<td class="line x" title="12:132	For examples, there are the following Japanese examples: yuushuu_na seiseki (excellent) (an academic record) an excellent academic record sugure_ta seiseki (excel and suffix of adnominal) (an academic record) an excellent academic record Yuushuu_na (excellent) is an adjective and sugure_ta (excel) is a verb, but they represent the same meaning and same semantic function, that is, an evaluation of an academic record." ></td>
	<td class="line x" title="13:132	In English there are the following examples; financial world world of finance In these examples, financial and finance are different part of speech, but represent same meaning and same semantic function, that is, one of domains." ></td>
	<td class="line x" title="14:132	On the other hand, there are examples in which only semantic function is the same, but the part of speech and meaning of the words are different." ></td>
	<td class="line x" title="15:132	For examples, kandai_na kihuu no hito (gentle) (disposition) (of) (person) a gentle person shinshu no kihuu no hito (initiative) (of) (disposition) (of) (person) a person of initiative In Japanese kandai_na (gentle) is an adjective and shinshu (initiative) is a noun." ></td>
	<td class="line x" title="16:132	They have different parts of speech and meanings, but the same semantic function, that is, they represent characteristics of a person." ></td>
	<td class="line x" title="17:132	In terms of a semantic function of representation of characteristics, both kandai_na (gentle) and shinshu (initiative) are classified in the same category." ></td>
	<td class="line x" title="18:132	In this work we call this type of noun an adjectival noun. It is important for developing high quality natural language processing systems to establish an objective method to represent relationship between words not only by part of speech but also by semantic functions." ></td>
	<td class="line x" title="19:132	However, it is very difficult to extract this type of linguistic phenomena from real data automatically." ></td>
	<td class="line x" title="20:132	We used syntactic and semantic patterns in our previous work (Isahara and Kanzaki 1999) in order to extract these types of examples from large corpora semi-automatically." ></td>
	<td class="line x" title="21:132	In this work, by using syntactic information, we are collecting adjectives and adjectival nouns in the noun + NO (of + Noun) structure that we supposed to have the same semantic functions." ></td>
	<td class="line x" title="22:132	We examined how adjectives and adjectival nouns extracted from corpora are similar or different in the real data and how non-adjectival nouns unlike adjectival nouns are different from adjectives in order to verify the usefulness of self-organizing semantic maps for lexical semantics." ></td>
	<td class="line x" title="23:132	In Section 2, we explain our methodology, based on linguistic information." ></td>
	<td class="line x" title="24:132	In Section 3, we describe a self-organizing semantic map." ></td>
	<td class="line x" title="25:132	In Section 4, we describe the similarities between adjectives and adjectival nouns and the differences between adjectival nouns and non-adjectival nouns by comparing two different self-organizing semantic maps." ></td>
	<td class="line x" title="26:132	In Section 5, we give our conclusion." ></td>
	<td class="line x" title="27:132	2 Methodology Isahara and Kanzaki (1999) classified semantic relations between adjectives and their head nouns from the viewpoints of syntax, semantics and computational treatment." ></td>
	<td class="line x" title="28:132	Among various types of semantic relations extracted in this research, there is a case in which the meanings of adnominal constituents are semantically similar to the features of their head nouns." ></td>
	<td class="line x" title="29:132	Let us consider the Japanese phrases, kanashii kimochi (sad feeling) and yorokobi no kimochi (feeling of delight) as examples." ></td>
	<td class="line x" title="30:132	kanashii kimochi (sad) (feeling) {adjective} {noun} sad feeling yorokobi no kimochi (delight) (of) (feeling) {noun} {postpositional} {noun} feeling of delight (The English translation of the noun + no examples should be read from right to left)." ></td>
	<td class="line x" title="31:132	One meaning of kimochi (feeling) represents the semantic element, [mental state]." ></td>
	<td class="line x" title="32:132	In the above examples, the adjective, kanashii (sad), and noun + no structure, yorokobi no (delight + no), represent the concrete contents of their head noun kimochi (feeling), i.e. they are descriptors of the mental state: kimochi (feeling). The head noun, kimochi (feeling), is a cognate object for kanashii (sad) and yorokobi no (delight + no). Therefore, even though kanashii (sad) and yorokobi no (delight + no) belong to different parts of speech (adjective and noun phrase), they must be classified as the same semantic category, since both carry the same type of meaning." ></td>
	<td class="line x" title="33:132	As for data, necessary expressions are extracted from large corpora: 10 years worth of Japanese newspapers  the Mainichi Shinbun from 1991 to 2000, 100 novels  Shincho-bunko, and 100 kinds of essays." ></td>
	<td class="line x" title="34:132	We extracted 134 abstract nouns used as this kind of head noun semi-automatically by using syntactic patterns that Isahara and Kanzaki(1999) and Kanzaki et al.(2000) used in their paper." ></td>
	<td class="line x" title="36:132	The total number of adnominal constituents appearing with these head nouns in the corpora was 47,248, and the number of different adnominal constituents was 28,063." ></td>
	<td class="line x" title="37:132	We got the list of pairs of a head (abstract) noun and its adnominal constituents (Table 1)." ></td>
	<td class="line x" title="38:132	These adnominal constituents are classified into three types, i.e. adjectives, adjectival nouns and non-adjectival nouns." ></td>
	<td class="line x" title="39:132	Table 1: Example of gathered data Noun Adnominal constituents kimochi (feeling) shiawasena (happy), hokorashii (proud), kanashii (sad),  joutai (status) aimaina (vague), ansei no (repose + no),  kanten (viewpoint) gakumontekina (academic), anzensei no (safety + no),    We classified these head nouns according to the similarities of sets of their adnominal constituents by using a self-organizing system in a neural network model." ></td>
	<td class="line x" title="40:132	This means that we co-classified both head nouns, i.e. abstract nouns, and adnominal constituents at the same time." ></td>
	<td class="line x" title="41:132	3 Self-Organizing Semantic Map In this section, we explain self-organizing semantic maps by a neural network model." ></td>
	<td class="line x" title="42:132	For the analysis of the similarities between adjectives and adjectival nouns, we make some semantic maps based on these adnominal constituents." ></td>
	<td class="line x" title="43:132	We use a self-organizing semantic map to classify words because it distributes words onto a two-dimensional plane and is therefore a visible and continuous representation." ></td>
	<td class="line x" title="44:132	This feature is very feasible to classify word meanings, because they cannot be always classified into an explicit category as hierarchical clustering does." ></td>
	<td class="line x" title="45:132	As for the clustering ability of self-organizing semantic map compared with the multivariate statistical analysis and hierarchical clustering method, it is almost the same as the hierarchical clustering method and superior to multivariate statistical analysis (Ma 2001)." ></td>
	<td class="line x" title="46:132	The semantic map we construct in this paper is one on which nouns, with their adnominal constituents as attributes, are mapped in a semantic order; i.e. nouns with similar meanings are mapped on (i.e. best-matched by) nodes that are topographically close to each other, and words with meanings that are far apart are mapped on nodes that are topographically far apart." ></td>
	<td class="line x" title="47:132	3.1 Learning Data As we mentioned above, we used the list in Table 1 as learning data." ></td>
	<td class="line x" title="48:132	Table 1 shows some example data that was gathered manually and in which the adnominal constituent is a descriptor of its head noun, i.e. a kind of cognate noun." ></td>
	<td class="line x" title="49:132	3.2 Encoding The semantic map of nouns is constructed by first defining each noun as the set of its adnominal constituents." ></td>
	<td class="line x" title="50:132	From Table 1, for example, we can define kimochi (feeling) as the set of its adnominal constituents, i.e. kimochi = {shiawasena (happy), hokorashii (proud), kanashii (sad), kinodokuna (unfortunate),}." ></td>
	<td class="line x" title="51:132	Suppose there is a set of nouns w i ( i = 1, , a0 ) that we are planning to use for self-organizing." ></td>
	<td class="line x" title="52:132	Any noun w i can be defined by a set of its adnominal constituents as w i = { a1( i ), a2( i ), , aa1i( i ) } -------(1) where a j( i ) is the jth adnominal constituent of wi and a2 i is the number of adnominal constituents of wi." ></td>
	<td class="line x" title="53:132	One method of encoding nouns so that they can be treated by SOM is to use random coding, which is a common method used for constructing SOMs (see details in Kohonen (1997))." ></td>
	<td class="line x" title="54:132	By several preceding computer experiments, however, we found that this method is not suitable for our task." ></td>
	<td class="line x" title="55:132	We therefore used a new method as described below." ></td>
	<td class="line x" title="56:132	Suppose we have a correlative matrix (Table 2) where d i j is some metric of correlation (or distance) between nouns w i and w j . We can encode noun w i from the correlative matrix as V (w i ) = [ d i 1, d i 2, , d i a3 ] T . ---------(2) The V (w i ) a4  a3 is the input to the SOM, i.e. x = V (w i ) and n = a5 . Table 2: Correlative matrix of nouns w 1 w 2  wa6 w 1 w 2 wa6 d 11 d 12  d 1a6 d 21 d 22  d 2a6 da61 da62  d wa6 In this paper, di j is measured by If i = j d i j = -------(3) where a7 i and a7 j are respectively the numbers of the adnominal constituents of wi and wj, and cij is the total number of common adnominal constituents of both wi and wj . The term di j is therefore a normalized distance between wi and wj in the context of the number of adnominal constituents they have in common; the smaller di j is, the closer wi and wj are in terms of their adnominal constituents." ></td>
	<td class="line x" title="57:132	4 Experimental Result 4.1 Comparisons of Word Distribution on Semantic Map via Adjectives with ones via Adjectival Nouns and via Non-adjectival Nouns." ></td>
	<td class="line x" title="58:132	In Section 4, we examine adjectival nouns extracted from corpora, whose behaviors are similar to adjectives." ></td>
	<td class="line x" title="59:132	In order to verify the data extracted from corpora manually by using syntactic method we prepare for four kinds of self-organizing semantic maps." ></td>
	<td class="line x" title="60:132	One is a semantic map of head nouns ( a7 i a8 c i j ) + ( a7 j a8 c i j ) a7 i + a7 j a8 c i j 0, otherwise a9 co-occurring with adjectives the second is a semantic map of head nouns co-occurring with adjectival nouns that we extracted from corpora, the third is a semantic map of head nouns co-occurring with non-adjectival nouns and the final one is a semantic map of head nouns co-occurring with both adjectives and adjectival nouns." ></td>
	<td class="line x" title="61:132	As we mentioned in section 2, head nouns distributed on four maps are abstract nouns that represent the concrete content of adnominals, e.g., feeling co-occurring with happy and so on." ></td>
	<td class="line x" title="62:132	We compare a semantic map of head nouns via co-occurring adjectives (Figure 1) with three other maps, that is, a semantic map via adjectival nouns and a semantic map via non-adjectival nouns and a semantic map via adjectives + adjectival nouns." ></td>
	<td class="line x" title="63:132	And then we mark the points of words that are similarly distributed between the semantic map via adjectives and one of other maps (Figure2, 3, 4)." ></td>
	<td class="line x" title="64:132	Input data for neural network model was a list that we mentioned in section 2." ></td>
	<td class="line x" title="65:132	In the ordering phase, the number of learning steps was 10,000, and in the adjustment phase it was 100,000." ></td>
	<td class="line x" title="66:132	After learning the input data, a two-dimensional array, in which a hexagonal topology type of neighborhood, the area that the winner node influences in the learning stage was used." ></td>
	<td class="line x" title="67:132	A self-organizing semantic map of head nouns via adjectives is shown in Figure 1." ></td>
	<td class="line x" title="68:132	We translate some Japanese words on the map into English for the readers convenience." ></td>
	<td class="line x" title="69:132	Figure 1." ></td>
	<td class="line x" title="70:132	Self-organizing semantic map of head nouns via adjectives Figure 2." ></td>
	<td class="line x" title="71:132	A semantic map via adjectives marked via comparison with classification by adjectival nouns." ></td>
	<td class="line x" title="72:132	For examples, viewpoint, standpoint, side on the right hand in Figure 1 are co-occurring with medical, musical, economical, political and so on, and mind, thought, mood are co-occurring with delightful, sad, happy, proud and so on." ></td>
	<td class="line x" title="73:132	Some sets of head nouns are not classified enough because the number of the co-occurring adjectives is not enough, or we could not extract enough of the collocation that we treated." ></td>
	<td class="line x" title="74:132	After we made a semantic map of head nouns via adjectival nouns we compared it with a semantic map of head nouns via adjectives (Comparison1)." ></td>
	<td class="line x" title="75:132	We marked the words in Figure 1 located similarly between two semantic maps (See Figure 2)." ></td>
	<td class="line x" title="76:132	We defined the common sets of words as words located similarly between two semantic maps, i.e., marked words, and they are located within three neighborhoods on the semantic map (See also Figure 2)." ></td>
	<td class="line x" title="77:132	And we also examined the data of non-adjectival nouns as same as the above experience and we marked the common sets of words between two maps, that is, a semantic map via non-adjectival nouns and a semantic map via adjectives (Comparison 2)." ></td>
	<td class="line x" title="78:132	Each square on Figure 2 and 3 refers to a word in Figure 1." ></td>
	<td class="line x" title="79:132	The black marked squares indicate a common words appearing on both a map via adjectives and a map via another data and a circle surrounding squares is common sets of words on both maps." ></td>
	<td class="line x" title="80:132	In Figure 2 we marked 51 words among 134 abstract nouns (38% of all the abstract nouns) on a semantic map via adjectives (Figure 1), which are common in a classification of words on two self-organizing semantic map, i.e., two semantic a0a2a1a4a3a2a5a7a6a8a3a2a9 a6a8a1a11a10a13a12a14a0a16a15a14a15a17a6a8a3a2a9 a15a17a6a19a18a16a0 a10a13a3a2a6a8a9a20a5 a1a4a6a8a9a21a18 a5a7a22a20a3a2a23a21a24a25a22a20a5 a1a4a3a2a3a25a18 a22a20a0a25a26a25a12a14a5 a27 a0a25a26a25a23a20a5a7a28 a29a14a22a21a26a25a12a14a1 a15a17a22a21a26a16a18a16a3a2a30 a6a8a9a4a3a2a9a20a0a2a31a15a32a10a13a33a19a26a25a29a14a0 a15a17a0a2a9a20a5a7a6a8a1a4a0a2a9a20a5 a10a20a26a34a15a14a15a17a6a8a3a2a9 a6a8a9a20a29a14a33a8a6a8a9a21a26a25a5a7a6a8a3a2a9 a33a8a3a2a3a2a35 a24a25a0a16a15a17a5a7a23a20a12a14a0 a12a14a0a2a1a4a6a8a9a21a18a16a0a2a12 a15a17a5a7a28a16a33a8a0 a26a16a18a25a36a13a26a25a9a20a5a17a26a16a24a25a0 a37 a6a19a24a25a23a20a12a14a0 a0a2a9a20a5a7a22a20a23a32a15a17a6a19a26a34a15a17a1 a5a17a26a25a33a8a0a2a9a20a5 a26 a27 a6a8a33a8a6a8a5a7a28 a36a34a6a8a0a2a30a38a10a13a3a39a6a40a9a13a5 a15a17a5a17a26a25a9a21a18a25a10a13a3a14a10a34a6a40a9a13a5 a15a17a6a19a18a16a0 a37 a6a8a0a2a33a19a18 a37 a12a39a26a25a1a4a0a2a30a41a3a2a12a14a35 a26a25a12a14a0a25a26 a15a17a5a17a26a25a5a7a23a20a12a14a0 a6a8a1a11a10a13a33a8a6a8a29a39a26a25a5a7a6a8a3a2a9 a15a17a1a4a0a2a33a8a33 a29a14a3a2a33a8a3a2a12 a0 a37a19a37 a0a2a29a14a5 a29a42a6a40a12a42a29a42a23a13a1a43a15a7a5a17a26a2a9a13a29a42a0 a29a14a3a2a12a14a9a20a0a2a12 a5a7a22a20a0a44a1a4a3a2a1a4a0a39a9a13a5 a3 a37 a5a7a12a14a23a20a5a7a22 a29a14a22a21a26a25a12a39a26a25a29a14a5a7a0a2a12 a6a8a12a14a3a2a9a32a15a17a6a19a18a16a0 a33a8a6 a37 a0 a5a7a0a2a1a11a10a13a0a2a12 a33a8a0a39a36a34a0a2a33 a26a34a15a7a10a13a0a2a29a14a5 a10a13a3a16a15a17a6a8a5a7a6a8a3a2a9 a6a8a9a21a18a16a6a8a29a39a26a25a5a7a6a8a3a2a9 a30a41a22a20a0a2a9 a10a13a3a16a15a14a15a17a6 a27 a33a8a0 a3a2a12a39a18a16a0a2a12 a18a16a0a25a24a25a12a14a0a2a0 a15a17a5a17a26a16a24a25a0 a15a17a5a17a26a25a28a15a17a5a17a26a25a5a7a0 a6a8a9 a29a14a3a2a9a21a18a16a6a8a5a7a6a8a3a2a9 a26a2a10a34a10a13a0a25a26a25a12a39a26a25a9a20a29a14a0 a37 a0a2a0a2a33a8a6a8a9a21a24 a27 a26a16a18a45a29a14a3a2a9a21a18a16a6a8a5a7a6a8a3a2a9 a26a25a9a20a29a14a6a8a0a2a9a20a5 maps via adjectives and via adjectival nouns and these 51 words can be classified into 16 common sets of words." ></td>
	<td class="line x" title="81:132	Figure 3." ></td>
	<td class="line x" title="82:132	A semantic map via adjectives marked via comparison with classification by non-adjectival nouns." ></td>
	<td class="line x" title="83:132	Then, we compared the semantic maps organized via non-adjectival nouns with semantic map via adjectives to find how different these maps are." ></td>
	<td class="line x" title="84:132	Thirty-five marked words from 134 abstract nouns (26%) and 14 common sets of these words, which are common between two maps, i.e., semantic maps via adjective and via non-adjectival nouns, are distributed on semantic maps via adjectives (Figure 3)." ></td>
	<td class="line x" title="85:132	There are 12% more common words and 3 more common sets in Comparison 1 than in Comparison 2." ></td>
	<td class="line x" title="86:132	However, there is a question of why the map organized via non-adjectival nouns still has sets of words common to the map organized via adjective." ></td>
	<td class="line x" title="87:132	Are there any similarities of behaviors between adjectives and non-adjectival nouns?" ></td>
	<td class="line x" title="88:132	We investigated the common co-occurring head nouns in Comparison 2 precisely, and found two facts that caused the existence of these common sets of words in Comparison 2." ></td>
	<td class="line x" title="89:132	One is that some co-occurring words that we classified as non-adjectival nouns are nouns that we must classify as adjectival nouns." ></td>
	<td class="line x" title="90:132	Another is that some non-adjectival nouns refer to people and they are possessors of the modified abstract nouns." ></td>
	<td class="line x" title="91:132	For examples, emotion, mood and thought are common sets in both maps." ></td>
	<td class="line x" title="92:132	Co-occurring adjectives are delight, sad and happy, however, co-occurring non-adjectival nouns are watashi-no (my), haha-no (mothers), sensei-no (teachers), and so on." ></td>
	<td class="line x" title="93:132	From this fact, we can conclude that the existence of common classifications of head nouns between these two semantic maps does not always mean semantic similarity between adjectives and non-adjectival nouns." ></td>
	<td class="line x" title="94:132	From these observations we made a semantic map of head nouns by using both adjectives and adjectival nouns." ></td>
	<td class="line x" title="95:132	If the adjectival nouns work similarly to the adjectives, using both adjectives and adjectival nouns will not influence the distribution and classification of words on the semantic map via adjectives." ></td>
	<td class="line x" title="96:132	On the other hand, if the data of semantic phenomena between adjectives + adjectival nouns and adjectives only are completely different, the distribution and classification of words on the semantic map via adjectives will be influenced by the addition of adjectival nouns." ></td>
	<td class="line x" title="97:132	We mark the point of the common words between them on the semantic map via adjectives (Figure 4)." ></td>
	<td class="line x" title="98:132	Figure 4." ></td>
	<td class="line x" title="99:132	A semantic map via adjectives marked by the common words between classification by adjectives and adjectival nouns and classification by only adjectives." ></td>
	<td class="line x" title="100:132	Eighty-three words among 134 words on this map are classified similarly to the words on the map organized via adjectives, and there are 21 similar sets of words." ></td>
	<td class="line x" title="101:132	This result shows that the distribution of the abstract nouns on the semantic map is not affected by the addition of adjectival nouns." ></td>
	<td class="line x" title="102:132	Therefore, the semantic roles of adjectival nouns for abstract nouns are similar to those of adjectives." ></td>
	<td class="line x" title="103:132	4.2 A Semantic Map Distributed by Adjectives, Adjectival Nouns and Non-adjectival Nouns Organized via Head Nouns." ></td>
	<td class="line x" title="104:132	In this section we made the semantic map of adjectives, adjectival nouns and non-adjectival nouns organized via collocation with abstract nouns to see the semantic distances between them." ></td>
	<td class="line x" title="105:132	As for marks on the map, a0, a1 and a2 indicated, in turn, adjective, adjectival nouns, and non-adjectival nouns." ></td>
	<td class="line x" title="106:132	Figure 5." ></td>
	<td class="line x" title="107:132	Semantic map of adjectives, adjectival nouns and non-adjectival nouns organized via collocation with abstract nouns." ></td>
	<td class="line x" title="108:132	We distributed three kinds of words, that is, adjective, adjectival nouns and non-adjectival nouns on the semantic map based on their head nouns, that is, abstract nouns." ></td>
	<td class="line x" title="109:132	For example, happy has feeling, mood, state, and so on as co-occurring head nouns." ></td>
	<td class="line x" title="110:132	When we made this map, we utilized words (adjectives, adjectival nouns and non-adjectival nouns) that collocate with 10 to 20 abstract nouns, so that the input data for constructing semantic map is fair from the viewpoint of number of co-occurring words." ></td>
	<td class="line x" title="111:132	We selected from them 100 adjectives, 100 adjectival nouns, and 200 non-adjectival nouns at random." ></td>
	<td class="line x" title="112:132	This semantic map is shown in Figure 5." ></td>
	<td class="line x" title="113:132	The semantic map shown in Figure 5 shows that there are three classes on the map." ></td>
	<td class="line x" title="114:132	The upper half part of this semantic map indicates the adjective area, the bottom right half of this map is the adjectival noun area and the bottom left half of this map is the non-adjectival noun area." ></td>
	<td class="line x" title="115:132	Semantic roles of adjectives are isolated from those of nouns, and semantic roles of nouns are divided into two areas, i.e. adjectival and non-adjectival." ></td>
	<td class="line x" title="116:132	The self-organizing mechanism could separate the semantic roles of adjectival nouns from those of non-adjectival nouns." ></td>
	<td class="line x" title="117:132	5 Conclusion We extracted adnominal constituents from corpora and created several self-organizing semantic maps by using them." ></td>
	<td class="line x" title="118:132	First, we compared the semantic maps organized via adjectives and via adjectival nouns." ></td>
	<td class="line x" title="119:132	The common sets of head nouns were 16 sets and common head nouns were 51 words in 134 head nouns, that is, 38% of the head nouns were classified similarly." ></td>
	<td class="line x" title="120:132	Second, we compared the semantic maps organized via adjectives and via non-adjectival nouns." ></td>
	<td class="line x" title="121:132	The common sets of head nouns were 14 sets, and the common head nouns were 35 words in 134 head nouns, that is, 26% of the head nouns were the same classifications." ></td>
	<td class="line x" title="122:132	Some sets of abstract nouns, head noun co-occurring with adjectives, are common with sets of abstract nouns co-occurring with non-adjectival nouns." ></td>
	<td class="line x" title="123:132	However, based on the precise investigation, we could find that the semantic function of adjectives and non-adjectival nouns were different." ></td>
	<td class="line x" title="124:132	Finally, we created a semantic map of abstract nouns by both adjectives and adjectival nouns." ></td>
	<td class="line x" title="125:132	This is because we wanted to see how word distribution on the map changed when we added adjectival nouns to the data for self-organization." ></td>
	<td class="line x" title="126:132	The common sets of head nouns were 21 sets and the common head nouns that did not change were 83 words in 134 abstract nouns, that is, 62% of head nouns were not affected by the addition of adjectival nouns." ></td>
	<td class="line x" title="127:132	This means that adjectival nouns are similar to adjectives in their semantic behavior for abstract nouns." ></td>
	<td class="line x" title="128:132	Then, we showed the semantic map of adjectives, adjectival nouns and non-adjectival nouns organized via co-occurring abstract nouns." ></td>
	<td class="line x" title="129:132	As these three kinds of adnominals were isolated on this map, we could find that the adjectival nouns had specific semantic roles that are different from those of non-adjectival nouns." ></td>
	<td class="line x" title="130:132	From the above evidence, we considered that we a3a5a4a7a6a9a8a11a10a13a12a7a14a16a15a7a17a19a18a21a20a11a22a23a10a25a24a26a6a27a4a7a28a29a6a27a30a21a31 a12a32a14a21a15a32a17a33a18a34a20a35a22a13a10a32a24a25a6a23a4a19a28a36a6a23a30 a31 a12a32a14a21a15a19a17a37a18a11a20a35a22a38a15a32a30 could extract the adjectival nouns similar to adjectives, rather than non-adjectival nouns." ></td>
	<td class="line x" title="131:132	In future work, we need addition and modification of input data and would like to use the accurate distribution of words by using some kind of information such as frequencies1." ></td>
	<td class="line x" title="132:132	And then we will construct a semantic map of words from Japanese large corpora and link words according to semantic behavior while we verify our data extracted from corpora by using a neural network model." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N03-1015
Word Sense Acquisition From Bilingual Comparable Corpora
Kaji, Hiroyuki;"></td>
	<td class="line x" title="1:192	Word Sense Acquisition from Bilingual Comparable Corpora Hiroyuki Kaji Central Research Laboratory, Hitachi, Ltd. 1-280 Higashi-Koigakubo, Kokubunji-shi, Tokyo 185-8601, Japan kaji@crl.hitachi.co.jp Abstract Manually constructing an inventory of word senses has suffered from problems including high cost, arbitrary assignment of meaning to words, and mismatch to domains." ></td>
	<td class="line x" title="2:192	To overcome these problems, we propose a method to assign word meaning from a bilingual comparable corpus and a bilingual dictionary." ></td>
	<td class="line x" title="3:192	It clusters second-language translation equivalents of a first-language target word on the basis of their translingually aligned distribution patterns." ></td>
	<td class="line x" title="4:192	Thus it produces a hierarchy of corpus-relevant meanings of the target word, each of which is defined with a set of translation equivalents." ></td>
	<td class="line x" title="5:192	The effectiveness of the method has been demonstrated through an experiment using a comparable corpus consisting of Wall Street Journal and Nihon Keizai Shimbun corpora together with the EDR bilingual dictionary." ></td>
	<td class="line x" title="6:192	1 Introduction Word Sense Disambiguation (WSD) is an important subtask that is necessary for accomplishing most natural language processing tasks including machine translation and information retrieval." ></td>
	<td class="line x" title="7:192	A great deal of research on WSD has been done over the past decade (Ide and Veronis, 1998)." ></td>
	<td class="line x" title="8:192	In contrast, word sense acquisition has been a human activity; inventories of word senses have been constructed by lexicographers based on their intuition." ></td>
	<td class="line x" title="9:192	Manually constructing an inventory of word senses has suffered from problems such as high cost, arbitrary division of word senses, and mismatch to application domains." ></td>
	<td class="line x" title="10:192	We address the problem of word sense acquisition along the lines of the WSD where word senses are defined with sets of translation equivalents in another language." ></td>
	<td class="line x" title="11:192	Bilingual corpora or second-language corpora enable unsupervised WSD (Brown, et al. , 1991; Dagan and Itai, 1994)." ></td>
	<td class="line x" title="12:192	However, the correspondence between senses of a word and its translations is not one-to-one, and therefore we need to prepare an inventory of word senses, each of which is defined with a set of synonymous translation equivalents." ></td>
	<td class="line x" title="13:192	Although conventional bilingual dictionaries usually group translations according to their senses, the grouping differs by dictionary." ></td>
	<td class="line x" title="14:192	In addition, senses specific to a domain are often missing while many senses irrelevant to the domain or rare senses are included." ></td>
	<td class="line x" title="15:192	To overcome these problems, we propose a method for producing a hierarchy of clusters of translation equivalents from a bilingual corpus and a bilingual dictionary." ></td>
	<td class="line x" title="16:192	To the best of our knowledge, there are two preceding research papers on word sense acquisition (Fukumoto and Tsujii, 1994; Pantel and Lin, 2002)." ></td>
	<td class="line x" title="17:192	Both proposed distributional word clustering algorithms that are characterized by their capabilities to produce overlapping clusters." ></td>
	<td class="line x" title="18:192	According to their algorithms, a polysemous word is assigned to multiple clusters, each of which represents one of its senses." ></td>
	<td class="line x" title="19:192	These and our approach differ in how to define the word sense, i.e., a set of synonyms in the same language versus a set of translation equivalents in another language." ></td>
	<td class="line x" title="20:192	Schuetze (1998) proposed a method for dividing occurrences of a word into classes, each of which consists of contextually similar occurrences." ></td>
	<td class="line x" title="21:192	However, it does not produce definitions of senses such as sets of synonyms and sets of translation equivalents." ></td>
	<td class="line x" title="22:192	2 Basic Idea 2.1 Clustering of translation equivalents Most work on automatic extraction of synonyms from text corpora rests on the idea that synonyms have Edmonton, May-June 2003 Main Papers, pp." ></td>
	<td class="line oc" title="23:192	32-39 Proceedings of HLT-NAACL 2003 similar distribution patterns (Hindle, 1990; Peraira, et al. , 1993; Grefenstette, 1994)." ></td>
	<td class="line x" title="24:192	This idea is also useful for our task, i.e., extracting sets of synonymous translation equivalents, and we adopt the approach to distributional word clustering." ></td>
	<td class="line x" title="25:192	We need to mention that the singularity of our task makes the problem easier." ></td>
	<td class="line x" title="26:192	First, we do not have to cluster all words of a language, but we only have to cluster a small number of translation equivalents for each target word, whose senses are to be extracted, separately." ></td>
	<td class="line x" title="27:192	As a result, the problem of computational efficiency becomes less serious." ></td>
	<td class="line x" title="28:192	Second, even if a translation equivalent itself is polysemous, it is not necessary to consider senses that are irrelevant to the target word." ></td>
	<td class="line x" title="29:192	A translation equivalent usually represents one and only one sense of the target word, at least in case the language-pair is those with different origins like English and Japanese." ></td>
	<td class="line x" title="30:192	Therefore, a non-overlapping clustering algorithm, which is far simpler than overlapping clustering algorithms, is sufficient." ></td>
	<td class="line x" title="31:192	2.2 Translingual distributional word clustering In conventional distributional word clustering, a word is characterized by a vector or weighted set consisting of words in the same language as that of the word itself." ></td>
	<td class="line x" title="32:192	In contrast, we propose a translingual distributional word clustering method, whereby a word is characterized by a vector or weighted set consisting of words in another language." ></td>
	<td class="line x" title="33:192	It is based on the sense-vs.-clue correlation matrix calculation method we originally developed for unsupervised WSD (Kaji and Morimoto, 2002)." ></td>
	<td class="line x" title="34:192	That method presupposes that each sense of a target word x is defined with a synonym set consisting of the target word itself and one or more translation equivalents which represent the sense." ></td>
	<td class="line x" title="35:192	It calculates correlations between the senses of x and the words statistically related to x, which act as clues for determining the sense of x, on the basis of translingual alignment of pairs of related words." ></td>
	<td class="line x" title="36:192	Rows of the resultant correlation matrix are regarded as translingual distribution patterns characterizing translation equivalents." ></td>
	<td class="line x" title="37:192	Sense-vs.-clue correlation matrix calculation method *) 1) Alignment of pairs of related words *) A description of the wild-card pair of related words, which plays an essential role in recovering alignment failure, has been omitted for simplicity." ></td>
	<td class="line x" title="38:192	Let X(x) be the set of clues for determining the sense of a first-language target word x. That is, X(x)={x|(x, x)R X }, where R X denotes the collection of pairs of related words extracted from a corpus of the first language." ></td>
	<td class="line x" title="39:192	Henceforth, the j-th clue for determining the sense of x will be denoted as x(j)." ></td>
	<td class="line x" title="40:192	Furthermore, let Y(x, x(j)) be the set consisting of all second-language counterparts of a first-language pair of related words x and x(j)." ></td>
	<td class="line x" title="41:192	That is, Y(x, x(j)) = {(y, y) | (y, y)R Y, (x, y)D, (x(j), y)D}, where R Y denotes the collection of pairs of related words extracted from a corpus of the second language, and D denotes a bilingual dictionary, i.e., a collection of pairs consisting of a first-language word and a second-language word that are translations of one another." ></td>
	<td class="line x" title="42:192	Then, for each alignment, i.e., pair of (x, x(j)) and (y, y) (Y(x, x(j))), a weighted set of common related words Z((x, x(j)), (y, y )) is constructed as follows: Z((x, x(j)), (y, y )) = {x / w(x) | (x, x)R X, (x(j), x)R X }." ></td>
	<td class="line x" title="43:192	The weight of x, denoted as w(x), is determined as follows: w(x) = 1+MI(y, y) when y (x, y)D, (y, y)R Y, and (y, y)R Y. w(x) = 1 otherwise." ></td>
	<td class="line x" title="44:192	This is where MI(y, y) is the mutual information of y and y." ></td>
	<td class="line x" title="45:192	The coefficient  was set to 5 in the experiment described in Section 4." ></td>
	<td class="line x" title="46:192	2) Calculation of correlation between senses and clues The correlation between the i-th sense S(x, i) and the j-th clue x(j) is defined as: ()() ()() ()() . ),(,,,)(,maxmax ),(,,,)(,max )(,)(),,( ),( )),(,(Y),( ),( )),(,(),(           =     kxSy'yjx'xA ixSy'yjx'xA jx'xMIjx'ixSC kxSy jx'xy'yk ixSy jx'xYy'y This is where MI(x, x(j)) is the mutual information of x and x(j), and A((x, x(j)), (y, y), S(x,i)), the plausibility of alignment of (x, x(j)) with (y, y) suggesting S(x, i), is defined as the weighted sum of the correlations between the sense and the common related words, i.e., () ().),,()w( ),(),,()),(,( )),()),(,((    = y'yjx'xZx' x'ixSCx' ixSy'yjx'xA The correlations between senses and clues are calculated iteratively with the following initial values: C 0 (S(x, i), x(j))=MI(x, x(j))." ></td>
	<td class="line x" title="47:192	The number of iterations was set to 6 in the experiment." ></td>
	<td class="line x" title="48:192	Figure 1 shows how the correlation values converge." ></td>
	<td class="line x" title="49:192	Advantages of using translingually aligned distribution patterns Translingual distributional word clustering has advantages over conventional monolingual distributional word clustering, when they are used to cluster translation equivalents of a target word." ></td>
	<td class="line x" title="50:192	First, it avoids clusters being degraded by polysemous translation equivalents." ></td>
	<td class="line x" title="51:192	Let race be the target word." ></td>
	<td class="line x" title="52:192	One of its translation equivalents, <REESU>, is a polysemous word representing lace as well as race." ></td>
	<td class="line x" title="53:192	According to monolingual distributional word clustering, <REESU> is characterized by a mixture of the distribution pattern for <REESU> representing race and that for <REESU> representing lace, which often results in degraded clusters." ></td>
	<td class="line x" title="54:192	In contrast, according to translingual distributional word clustering, <REESU> is characterized by the distribution pattern for the sense of race that means competition." ></td>
	<td class="line x" title="55:192	Second, translingual distributional word clustering can exclude from the clusters translation equivalents irrelevant to the corpus." ></td>
	<td class="line x" title="56:192	For example, a bilingual dictionary renders <TOKUCHOU> (feature) as a translation of race, but that sense of race is used infrequently." ></td>
	<td class="line x" title="57:192	If it is the case in a given domain,  <TOKUCHOU> has low correlation with most words related to race, and can therefore be excluded from any clusters." ></td>
	<td class="line x" title="58:192	We should also mention the data-sparseness problem that hampers distributional word clustering." ></td>
	<td class="line x" title="59:192	Generally speaking, the problem becomes more difficult in translingual distributional word clustering, since the sparseness of data in two languages is multiplied." ></td>
	<td class="line x" title="60:192	However, the sense-vs.-clue correlation matrix calculation method overcomes this difficulty; it calculates the correlations between senses and clues iteratively to smooth out the sparse data." ></td>
	<td class="line x" title="61:192	Translingual distributional word clustering can also be implemented on the basis of word-for-word alignment of a parallel corpus." ></td>
	<td class="line x" title="62:192	However, availability of large parallel corpora is extremely limited." ></td>
	<td class="line x" title="63:192	In contrast, the sense-vs.-clue correlation calculation method accepts comparable corpora which are available in many domains." ></td>
	<td class="line x" title="64:192	2.3 Similarity based on subordinate distribution pattern Naive translingual distributional word clustering based on the sense-vs.-clue correlation matrix calculation method is outlined in the following steps: 1) Define the sense of a target word by using each translation equivalent." ></td>
	<td class="line x" title="65:192	2) Calculate the sense-vs.-clue correlation matrix for the set of senses resulting from step 1)." ></td>
	<td class="line x" title="66:192	3) Calculate similarities between senses on the basis of distribution patterns shown by the sense-vs.-clue correlation matrix." ></td>
	<td class="line x" title="67:192	4) Cluster senses by using a hierarchical agglomerative clustering method, e.g., the group-average method." ></td>
	<td class="line x" title="68:192	However, this naive method is not effective because some senses usually have duplicated definitions in step 1) despite the fact that the sense-vs.-clue correlation matrix calculation algorithm presupposes a set of senses without duplicated definitions." ></td>
	<td class="line x" title="69:192	The algorithm is based on the one sense per collocation hypothesis, and it results in each clue having a high correlation with one and only one sense." ></td>
	<td class="line x" title="70:192	A clue can never have high correlations with two or more senses, even when they are actually the same sense." ></td>
	<td class="line x" title="71:192	Consequently, synonymous translation equivalents do not necessarily have high similarity." ></td>
	<td class="line x" title="72:192	Figure 2(a) shows parts of distribution patterns for 0.0 0.5 1.0 1.5 2.0 2.5 012345678910 Iteration Cor r e lation C(S1, brand) C(S2, brand) C(S3, brand) C(S1, woman) C(S2, woman) C(S3, woman) S1={promotion, <SENDEN>,  <PUROMOUSHON>, <URIKOMI>, } (an activity intended to help sell a product) S2={promotion, <SHOUKAKU>, <SHOUSHIN>, <TOUYOU>, } (advancement in rank or position) S3={promotion, <SHOUREI>, <SHINKOU>,  <JOCHOU>,} (action to help something develop or succeed) Figure 1." ></td>
	<td class="line x" title="73:192	Convergence of correlation between senses and clues." ></td>
	<td class="line x" title="74:192	{promotion, <SENDEN>}, {promotion,  <PUROMOUSHON>}, and {promotion,  <URIKOMI>} all of which define the sales activity sense of promotion." ></td>
	<td class="line x" title="75:192	We see that most clues for selecting that sense have higher correlation with {promotion, <SENDEN>} than with {promotion,  <PUROMOUSHON>} and {promotion,  <URIKOMI>}." ></td>
	<td class="line x" title="76:192	This is because <SENDEN> is the most dominant translation equivalent of promotion in the corpus." ></td>
	<td class="line x" title="77:192	To resolve the above problem, we calculated the sense-vs.-clue correlation matrix not only for the full set of senses but also for the set of senses excluding one of these senses." ></td>
	<td class="line x" title="78:192	Excluding a definition of the sense, which includes the most dominant translation equivalent, allows most clues for selecting the sense to have the highest correlations with another definition of the same sense, which includes the second most dominant translation equivalent." ></td>
	<td class="line x" title="79:192	Figure 2(b) shows parts of distribution patterns for {promotion,  <PUROMOUSHON>} and {promotion,  <URIKOMI>} shown by the sense-vs.-clue correlation matrix for the set of senses excluding {promotion,  <SENDEN>}." ></td>
	<td class="line x" title="80:192	We see that most clues for selecting the sales activity sense have higher correlations with {promotion, <PUROMOUSHON>} than with {promotion, <URIKOMI>}." ></td>
	<td class="line x" title="81:192	This is because <PUROMOUSHON> is the second most dominant translation equivalent in the corpus." ></td>
	<td class="line x" title="82:192	We also see that the distribution pattern for {promotion, <PUROMOUSHON>} in Fig." ></td>
	<td class="line x" title="83:192	2(b) is more similar to that for {promotion, <SENDEN>} in Fig." ></td>
	<td class="line x" title="84:192	2(a) than that for {promotion,  <PUROMOUSHON>} in Fig." ></td>
	<td class="line x" title="85:192	2(a)." ></td>
	<td class="line x" title="86:192	We call the distribution pattern for sense S 2, resulting from the sense-vs.-clue correlation matrix for the set of senses excluding sense S 1, the distribution pattern for S 2 subordinate to S 1, while we call the distribution pattern for sense S 2, resulting from the sense-vs.-clue correlation matrix for the full set of senses, simply the distribution pattern for S 2 . We define the similarity of S 2 to S 1 as the similarity of the distribution pattern for S 2 subordinate to S 1 to the distribution pattern for S 1 . Calculating the sense-vs.-clue correlation matrix for a set of senses excluding one sense is of course insufficient since three or more translation equivalents may represent the same sense of the target word." ></td>
	<td class="line x" title="87:192	We should calculate the sense-vs.-clue correlation matrices both for the full set of senses and for the set of senses excluding one of these senses again, after merging similar senses into one." ></td>
	<td class="line x" title="88:192	Repeating these procedures enables corpus-relevant but less dominant translation equivalents to be drawn up, while corpus-irrelevant ones are never drawn up." ></td>
	<td class="line x" title="89:192	Thus, a hierarchy of corpus-relevant senses or clusters of corpus-relevant translation equivalents is produced." ></td>
	<td class="line x" title="90:192	3 Proposed Method 3.1 Outline As shown in Fig." ></td>
	<td class="line x" title="91:192	3, our method repeats the following three steps: 1) Calculate sense-vs.-clue correlation matrices both for the full set of senses and for a set of senses excluding each of these senses." ></td>
	<td class="line x" title="92:192	2) Calculate similarities between senses on the basis of distribution patterns and subordinate distribution patterns." ></td>
	<td class="line x" title="93:192	3) Merge each pair of senses with high similarity into one." ></td>
	<td class="line x" title="94:192	The initial set of senses is given as (x)={{x, y 1 }, {x, y 2 }, , {x, y N }} where x is a target word in the first language, and y 1, y 2, , and y N are translation equivalents of x in the second-language." ></td>
	<td class="line x" title="95:192	Translation equivalents that occur less frequently in the second-language corpus can be excluded from the initial 0 1 2 3 4 5 6 7 Accl ai m ad cam pai g n a ffirma tiv e anal ys t s a y Audi Bat m an br and Bu r g er Ki n g car eer cer eal Co caCo l a C onr ail C oor s L i ght Cy r k dis c r i mination employee film Gener a l His p anic indus tr y job la be l l a s t year management Clue Cor r e lation {promotion, <SENDEN>} {promotion, <PUROMOUSHON>} {promotion, <URIKOMI>} (a) Distribution patterns 0 1 2 3 4 5 6 7 Clue Cor r elation (b) Distribution patterns subordinate to {promotion, <SENDEN>} Figure 2." ></td>
	<td class="line x" title="96:192	Distribution Patterns for Some Senses of promotion." ></td>
	<td class="line x" title="97:192	set to shorten the processing time." ></td>
	<td class="line x" title="98:192	The details of the steps are described in the following sections." ></td>
	<td class="line x" title="99:192	3.2 Calculation of sense-vs.-clue correlation matrices First, a sense-vs.-clue correlation matrix is calculated for the full set of senses." ></td>
	<td class="line x" title="100:192	The resulting correlation matrix is denoted as C. That is, C(i, j) is the correlation between the i-th sense S(x,i) of a target word x and its j-th clue x(j)." ></td>
	<td class="line x" title="101:192	Then a set of active senses,  A (x), is determined." ></td>
	<td class="line x" title="102:192	A sense is regarded active if and only if the ratio of clues with which it has the highest correlation exceeds a predetermined threshold  (In the experiment in Section 4,  was set to 0.05)." ></td>
	<td class="line x" title="103:192	That is, {}))(()()( >= ix,SR|ix,Sx A, where R(S(x, i)) denotes the ratio of clues having the highest correlation with S(x, i), i.e., })({)},(max),()({)),(( jx'jkCjiC|jx'ixSR k == . Thus  A (x) consists of senses of the target word x that are relevant to the corpus." ></td>
	<td class="line x" title="104:192	Finally, a sense-vs.-clue correlation matrix is calculated for the set of senses excluding each of the active senses." ></td>
	<td class="line x" title="105:192	The correlation matrix calculated for the set of senses excluding the k-th sense is denoted as C -k . That is, C -k (i, j) (ik) is the correlation between the i-th sense and the j-th clue that is calculated excluding the k-th sense." ></td>
	<td class="line x" title="106:192	C -k (k, j) (j=1, 2, ) are set to zero." ></td>
	<td class="line x" title="107:192	This redundant k-th row is included to maintain the same correspondence between rows and senses as in C. 3.3 Calculation of sense similarity matrix Similarity of the i-th sense S(x, i) to the j-th sense S(x, j), Sim(S(x, i), S(x, j)), is defined as the similarity of the distribution pattern for S(x, i) subordinate to S(x, j) to the distribution pattern of S(x, j)." ></td>
	<td class="line x" title="108:192	Note that this similarity is asymmetric and reflects which sense is more dominant in the corpus." ></td>
	<td class="line x" title="109:192	It is probable that Sim(S(x, i), S(x, j)) is large but Sim(S(x, j), S(x, i)) is not when S(x, j) is more dominant than S(x, i)." ></td>
	<td class="line x" title="110:192	According to the sense-vs.-clue correlation matrix, each sense is characterized by a weighted set of clues." ></td>
	<td class="line x" title="111:192	Therefore, we used the weighted Jaccard coefficient as the similarity measure." ></td>
	<td class="line x" title="112:192	That is, {} {}   = k jk jkj,Cki,C kj,Cki,C jxSixSSim )(),(max )(),(min )),(),,(( when S(x, j) A (x)." ></td>
	<td class="line x" title="113:192	0)),(),,(( =jxSixSSim otherwise." ></td>
	<td class="line x" title="114:192	It should be noted that a sense is characterized by different weighted sets of clues depending on which sense the similarity is calculated." ></td>
	<td class="line x" title="115:192	Note also that inactive senses are neglected because they are not reliable." ></td>
	<td class="line x" title="116:192	3.4 Merging similar senses The set of senses is updated by merging every pair of mutually most-similar senses into one." ></td>
	<td class="line x" title="117:192	That is, (x)  (x)  {S(x, i), S(x, j)} + {S(x, i)S(x, j)} if {maxmax)),(),,(( j' jxSixSSim = ))}},(),',(()),,(),,(({ ixSjxSSimj'xSixSSim, {maxmax)),(),,(( i' jxSixSSim = ))}},(),,(()),,(),,(({ i'xSjxSSimjxSi'xSSim, and >)),(),,(( jxSixSSim . The  is a predetermined threshold for similarity, which is introduced to avoid noisy pairs of senses being merged." ></td>
	<td class="line x" title="118:192	In the experiment in Section 4,  was set to 0.25." ></td>
	<td class="line x" title="119:192	If at least one pair of senses are merged, the whole procedure, i.e., the calculation of sense-vs.-clue matrices through the merger of similar senses, is repeated for the updated set of senses." ></td>
	<td class="line x" title="120:192	Otherwise, the clustering procedure terminates." ></td>
	<td class="line x" title="121:192	Agglomerative clustering methods usually suffer from the problem of when to terminate merging." ></td>
	<td class="line x" title="122:192	In our method described above, the similarity of senses that are merged into one does not necessarily decrease Initial set of senses Sense-vs.-clue correlation matrices Sense similarity matrix Updated set of senses Comparable corpus Bilingual dictionary Calculate similarities between distribution patterns Calculate correlations between senses and clues Merge similar senses Figure 3." ></td>
	<td class="line x" title="123:192	Flow Diagram of Proposed Method." ></td>
	<td class="line x" title="124:192	monotonically, which makes the problem more difficult." ></td>
	<td class="line x" title="125:192	At present, we are forced to output a dendrogram that represents the history of mergers and leave the final decision to humans." ></td>
	<td class="line x" title="126:192	The dendrogram consists of translation equivalents that are included in active senses in the final cycle." ></td>
	<td class="line x" title="127:192	Other translation equivalents are rejected as they are irrelevant to the corpus." ></td>
	<td class="line x" title="128:192	4 Experimental Evaluation 4.1 Experimental settings Our method was evaluated through an experiment using a Wall Street Journal corpus (189 Mbytes) and a Nihon Keizai Shimbun corpus (275 Mbytes)." ></td>
	<td class="line x" title="129:192	First, collected pairs of related words, which we restricted to nouns and unknown words, were obtained from each corpus by extracting pairs of words co-occurring in a window, calculating mutual information of each pair of words, and selecting pairs with mutual information larger than the threshold." ></td>
	<td class="line x" title="130:192	The size of the window was 25 words excluding function words, and the threshold for mutual information was set to zero." ></td>
	<td class="line x" title="131:192	Second, a bilingual dictionary was prepared by collecting pairs of nouns that were translations of one another from the Japan Electronic Dictionary Research Institute (EDR) English-to-Japanese and Japanese-to-English dictionaries." ></td>
	<td class="line x" title="132:192	The resulting dictionary includes 633,000 pairs of 269,000 English nouns and 276,000 Japanese nouns." ></td>
	<td class="line x" title="133:192	Evaluating the performance of word sense acquisition methods is not a trivial task." ></td>
	<td class="line x" title="134:192	First, we do not have a gold-standard sense inventory." ></td>
	<td class="line x" title="135:192	Even if we have one, we have difficulty mapping acquired senses onto those in it." ></td>
	<td class="line x" title="136:192	Second, there is no way to establish the complete set of senses appearing in a large corpus." ></td>
	<td class="line x" title="137:192	Therefore, we evaluated our method on a limited number of target words as follows." ></td>
	<td class="line x" title="138:192	We prepared a standard sense inventory by selecting 60 English target words and defining an average of 3.4 senses per target word manually." ></td>
	<td class="line x" title="139:192	The senses were rather coarse-grained; i.e., they nearly corresponded to groups of translation equivalents within the entries of everyday English-Japanese dictionaries." ></td>
	<td class="line x" title="140:192	We then sampled 100 instances per target word from the Wall Street Journal corpus, and we sense-tagged them manually." ></td>
	<td class="line x" title="141:192	Thus, we estimated the ratios of the senses in the training corpus for each target word." ></td>
	<td class="line x" title="142:192	We defined two evaluative measures, recall of senses and accuracy of sense definitions." ></td>
	<td class="line x" title="143:192	The recall of senses is the proportion of senses with ratios not less than a threshold that are successfully extracted, and it varies with change of the threshold." ></td>
	<td class="line x" title="144:192	We judged that a sense was extracted, when it shared at least one translation equivalent with some active sense in the final cycle." ></td>
	<td class="line x" title="145:192	To evaluate the accuracy of sense definitions while avoiding mapping acquired senses onto those in the standard sense inventory, we regard a set of senses as a set of pairs of synonymous translation equivalents." ></td>
	<td class="line x" title="146:192	Let T S be a set consisting of pairs of translation equivalents belonging to the same sense in the standard sense inventory." ></td>
	<td class="line x" title="147:192	Likewise, let T(k) be a set consisting of pairs of translation equivalents belonging to the same active sense in the k-th cycle." ></td>
	<td class="line x" title="148:192	Further, let U be a set of pairs of translation equivalents that are included in active senses in the final cycle." ></td>
	<td class="line x" title="149:192	Recall and precision of pairs of synonymous translation equivalents in the k-th cycle are defined as: UT kTT kR S S   = )( )( . )( )( )( kT kTT kP S  = . Further, F-measure of pairs of synonymous translation equivalents in the k-th cycle is defined as: )()( )()(2 )( kPkR kPkR kF +  = . The F-measure indicates how well the set of active senses coincides with the set of sense definitions in the standard senses inventory." ></td>
	<td class="line x" title="150:192	Although the current method cannot determine the optimum cycle, humans can identify the set of appropriate senses from a hierarchy of senses at a glance." ></td>
	<td class="line x" title="151:192	Therefore, we define the accuracy of sense definitions as the maximum F-measure in all cycles." ></td>
	<td class="line x" title="152:192	4.2 Experimental results To simplify the evaluation procedure, we clustered translation equivalents that were used to define the senses of each target word in the standard sense inventory, rather than clustering translation equivalents rendered by the EDR bilingual dictionary." ></td>
	<td class="line x" title="153:192	The recall of senses for totally 201 senses of the 60 target words was: 96% for senses with ratios not less than 25%, 87% for senses with ratios not less than 5%, and 78% for senses with ratios not less than 1%." ></td>
	<td class="line x" title="154:192	The accuracy of sense definitions, averaged over the 60 target words, was 77%." ></td>
	<td class="line x" title="155:192	The computational efficiency of our method proved to be acceptable." ></td>
	<td class="line x" title="156:192	It took 13 minutes per target word on a HP9000 C200 workstation (CPU clock: 200 MHz, memory: 32 MB) to produce a hierarchy of clusters of translation equivalents." ></td>
	<td class="line x" title="157:192	Some clustering results are shown in Fig." ></td>
	<td class="line x" title="158:192	4." ></td>
	<td class="line x" title="159:192	These demonstrate that our proposed method shows a great deal of promise." ></td>
	<td class="line x" title="160:192	At the same time, evaluating the results revealed its deficiencies." ></td>
	<td class="line x" title="161:192	The first of these lies in the crucial role of the bilingual dictionary." ></td>
	<td class="line x" title="162:192	It is obvious that a sense is never extracted if the translation equivalents representing it are not included in it." ></td>
	<td class="line x" title="163:192	An exhaustive bilingual dictionary is therefore required." ></td>
	<td class="line x" title="164:192	From this point of view, the EDR bilingual dictionary is fairly good." ></td>
	<td class="line x" title="165:192	The second deficiency lies in the fact that it performs badly for low-frequency or non-topical senses." ></td>
	<td class="line x" title="166:192	For example, the sense of bar as the legal profession was clearly extracted, but its sense as a piece of solid material was not extracted." ></td>
	<td class="line x" title="167:192	We also compared our method with two alternatives: monolingual distributional clustering mentioned in Section 2.2 and naive translingual clustering mentioned in Section 2.3." ></td>
	<td class="line x" title="168:192	Figures 5(a), (b), and (c) show respective examples of clustering obtained by our method, the monolingual method, and the naive translingual method." ></td>
	<td class="line x" title="169:192	Comparing (a) with (b) reveals the superiority of the translingual approach to the monolingual approach, and comparing (a) with (c) reveals the effectiveness of the subordinate distribution pattern introduced in Section 2.3." ></td>
	<td class="line x" title="170:192	Note that deleting the corpus-irrelevant translation equivalents from the dendrograms in both (b) and (c) would not result in appropriate ones." ></td>
	<td class="line x" title="171:192	5 Discussion Our method has several practical advantages." ></td>
	<td class="line x" title="172:192	One of these is that it produces a corpus-dependent inventory of word senses." ></td>
	<td class="line x" title="173:192	That is, the resulting inventory covers most senses relevant to a domain, while it excludes senses irrelevant to the domain." ></td>
	<td class="line x" title="174:192	Second, our method unifies word sense acquisition with word sense disambiguation." ></td>
	<td class="line x" title="175:192	The sense-vs.-clue correlation matrix is originally used for word sense disambiguation." ></td>
	<td class="line x" title="176:192	Therefore, our method guarantees that acquired senses can be distinguished by machines, and further it demonstrates the possibility of automatically optimizing the granularity of word senses." ></td>
	<td class="line x" title="177:192	Some limitations of the present methods are discussed in the following with possible future extensions." ></td>
	<td class="line x" title="178:192	First, our method produces a hierarchy of clusters but cannot produce a set of disjoint clusters." ></td>
	<td class="line x" title="179:192	It is very important to terminate merging senses autonomously during an appropriate cycle." ></td>
	<td class="line x" title="180:192	Comparing distribution patterns (not subordinate ones) may be useful to terminate merging; senses characterized by complementary distribution patterns should not be merged." ></td>
	<td class="line x" title="181:192	Second, the present method assumes that each translation equivalent represents one and only one sense of the target word, but this is not always the case." ></td>
	<td class="line x" title="182:192	[Target word] Resulting dendrogram (English equivalent other than target word) [association] <KANKEI> <KOUSAI>  <TEIKEI> <KANREN> <KYOUDOU> <RENGOU> <KUMIAI> <KYOUKAI> <KAI> <DANTAI> (relation) (friendship) (cooperation) (relation) (cooperation) (federation) (society) (society) (society) (organization) [bar] <URIBA> <KAUNTAA>  <BAA>  <SHOUHEKI> <KOUSHI> <HOUSOU> <BENGOSHI> <HOUTEI> (shop) (counter) (saloon) (obstacle) (lattice) (legal profession) (lawyer) (law court) [discipline] <KUNREN> <GAKKA>  <GAKUMON> <KYOUKA> <CHITSUJO>  <KISEI> <CHOUBATSU> <TOUSEI> <KIRITSU> (training) (subject of study) (learning) (subject of study) (order) (regulation) (punishment) (control) (order) [measure] <SHAKUDO> <RYOU>  <SHISUU>  <SHUDAN> <TAISAKU>  <KIJUN> <HOUREI> <GIAN> <HOUAN> (gauge) (quantity) (index) (means) (counter plan) (standard) (law) (bill) (bill) [promotion] <TOUYOU> <SHOUSHIN> <URIKOMI>   <PUROMOUSHON> <SENDEN> (elevation) (advancement) (sale) (advertising campaign) (advertisement) [traffic] <SHOUGYOU> <TORIHIKI> <BAIBAI>  <TSUUKOU> <KOUTSUU>  <UNYU> (commerce) (trade) (bargain) (passage) (transport) (transport) Figure 4." ></td>
	<td class="line x" title="183:192	Examples of Clustering." ></td>
	<td class="line x" title="184:192	A Japanese Katakana word resulting from transliteration of an English word sometimes represents multiple senses of the English word." ></td>
	<td class="line x" title="185:192	It is necessary to detect and split translation equivalents representing more than one sense of the target word." ></td>
	<td class="line x" title="186:192	Third, not only are acquired senses rather coarse-grained but also generic senses are difficult to acquire." ></td>
	<td class="line x" title="187:192	One of the reasons for this may be that we rely on co-occurrence in the window." ></td>
	<td class="line x" title="188:192	The fact that most distributional word clustering methods use syntactic co-occurrence suggests that it is the most effective tool for extracting pairs of related words." ></td>
	<td class="line x" title="189:192	6 Conclusion We presented a translingual distributional word clustering method enabling word senses, exactly a hierarchy of clusters of translation equivalents, to be acquired from a comparable corpus and a bilingual dictionary." ></td>
	<td class="line x" title="190:192	Its effectiveness was demonstrated through an experiment using Wall Street Journal and Nihon Keizai Shimbun corpora and the EDR bilingual dictionary." ></td>
	<td class="line x" title="191:192	The recall of senses was 87% for senses whose ratios in the corpus were not less than 5%, and the accuracy of sense definitions was 77%." ></td>
	<td class="line x" title="192:192	Acknowledgments: This research was supported by the New Energy and Industrial Technology Development Organization of Japan." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N03-4011
Automatically Discovering Word Senses
Pantel, Patrick;Lin, Dekang;"></td>
	<td class="line x" title="1:39	Automatically Discovering Word Senses Patrick Pantel and Dekang Lin Department of Computing Science University of Alberta Edmonton, Alberta T6G 2E8 Canada {ppantel, lindek}@cs.ualberta.ca Abstract We will demonstrate the output of a distributional clustering algorithm called Clustering by Committee that automatically discovers word senses from text 1." ></td>
	<td class="line x" title="2:39	1 Introduction Using word senses versus word forms is useful in many applications such as information retrieval (Voorhees 1998), machine translation (Hutchins and Sommers 1992), and question-answering (Pasca and Harabagiu 2001)." ></td>
	<td class="line x" title="3:39	The Distributional Hypothesis (Harris 1985) states that words that occur in the same contexts tend to be similar." ></td>
	<td class="line oc" title="4:39	There have been many approaches to compute the similarity between words based on their distribution in a corpus (Hindle 1990; Landauer and Dumais 1997; Lin 1998)." ></td>
	<td class="line o" title="5:39	The output of these programs is a ranked list of similar words to each word." ></td>
	<td class="line x" title="6:39	For example, Lins approach outputs the following similar words for wine and suit: wine: beer, white wine, red wine, Chardonnay, champagne, fruit, food, coffee, juice, Cabernet, cognac, vinegar, Pinot noir, milk, vodka, suit: lawsuit, jacket, shirt, pant, dress, case, sweater, coat, trouser, claim, business suit, blouse, skirt, litigation,  The similar words of wine represent the meaning of wine." ></td>
	<td class="line x" title="7:39	However, the similar words of suit represent a mixture of its clothing and litigation senses." ></td>
	<td class="line x" title="8:39	Such lists of similar words do not distinguish between the multiple senses of polysemous words." ></td>
	<td class="line x" title="9:39	1 The demonstration is currently available online at www.cs.ualberta.ca/~lindek/demos/wordcluster.htm." ></td>
	<td class="line x" title="10:39	We will demonstrate the output of a distributional clustering algorithm called Clustering by Committee (CBC) that discovers word senses automatically from text." ></td>
	<td class="line x" title="11:39	Each cluster that a word belongs to corresponds to a sense of the word." ></td>
	<td class="line x" title="12:39	The following is a sample output from our algorithm: (suit 0.39 (blouse, slack, legging, sweater) 0.20 (lawsuit, allegation, case, charge) ) (plant 0.41 (plant, factory, facility, refinery) 0.20 (shrub, ground cover, perennial, bulb) ) (heart 0.27 (kidney, bone marrow, marrow, liver) 0.17 (psyche, consciousness, soul, mind) ) Each entry shows the clusters to which the headword belongs along with its similarity to the cluster." ></td>
	<td class="line x" title="13:39	The lists of words are the top-4 most similar members to the cluster centroid." ></td>
	<td class="line x" title="14:39	Each cluster corresponds to a sense of the headword." ></td>
	<td class="line x" title="15:39	2 Feature Representation Following (Lin 1998), we represent each word by a feature vector." ></td>
	<td class="line x" title="16:39	Each feature corresponds to a context in which the word occurs." ></td>
	<td class="line x" title="17:39	For example, sip __ is a verbobject context." ></td>
	<td class="line x" title="18:39	If the word wine occurred in this context, the context is a feature of wine." ></td>
	<td class="line x" title="19:39	These features are obtained by parsing a large corpus using Minipar (Lin 1994), a broad-coverage English parser." ></td>
	<td class="line x" title="20:39	The value of the feature is the pointwise mutual information (Manning and Schtze 1999) between the feature and the word." ></td>
	<td class="line x" title="21:39	Let c be a context and F c (w) be the frequency count of a word w occurring in context c. The pointwise mutual information, mi w,c, between c and w is defined as: Edmonton, May-June 2003 Demonstrations, pp." ></td>
	<td class="line x" title="22:39	21-22 Proceedings of HLT-NAACL 2003 () () () N jF N wF N wF cw j c i i c mi    =, where N is the total frequency counts of all words and their contexts." ></td>
	<td class="line x" title="23:39	We compute the similarity between two words w i and w j using the cosine coefficient (Salton and McGill 1983) of their mutual information vectors: ()     = c cw c cw c cwcw ji ji ji mimi mimi w,wsim 22 3 Clustering by Committee CBC finds clusters by first discovering the underlying structure of the data." ></td>
	<td class="line x" title="24:39	It does this by searching for sets of representative elements for each cluster, which we refer to as committees." ></td>
	<td class="line x" title="25:39	The goal is to find committees that unambiguously describe the (unknown) target classes." ></td>
	<td class="line x" title="26:39	By carefully choosing committee members, the features of the centroid tend to be the more typical features of the target class." ></td>
	<td class="line x" title="27:39	For example, our system chose the following committee members to compute the centroid of the state cluster: Illinois, Michigan, Minnesota, Iowa, Wisconsin, Indiana, Nebraska and Vermont." ></td>
	<td class="line x" title="28:39	States like Washington and New York are not part of the committee because they are polysemous." ></td>
	<td class="line x" title="29:39	The centroid of a cluster is constructed by averaging the feature vectors of the committee members." ></td>
	<td class="line x" title="30:39	CBC consists of three phases." ></td>
	<td class="line x" title="31:39	Phase I computes each elements top-k similar elements." ></td>
	<td class="line x" title="32:39	In Phase II, we do a first pass through the data and discover the committees." ></td>
	<td class="line x" title="33:39	The goal is that we form tight committees (high intra-cluster similarity) that are dissimilar from one another (low inter-cluster similarity) and that cover the whole similarity space." ></td>
	<td class="line x" title="34:39	The method is based on finding sub-clusters in the top-similar elements of every given element." ></td>
	<td class="line x" title="35:39	In the final phase of the algorithm, each word is assigned to its most similar clusters (represented by a committee)." ></td>
	<td class="line x" title="36:39	Suppose a word w is assigned to a cluster c. We then remove from w its features that intersect with the features in c. Intuitively, this removes the c sense from w, allowing CBC to discover the less frequent senses of a word and to avoid discovering duplicate senses." ></td>
	<td class="line x" title="37:39	The word w is then assigned to its next most similar cluster and the process is repeated." ></td>
	<td class="line x" title="38:39	4 Conclusion We will demonstrate the senses discovered by CBC for 54,685 words on the 3GB ACQUAINT corpus." ></td>
	<td class="line x" title="39:39	CBC discovered 24,497 polysemous words." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W03-1610
Optimizing Synonym Extraction Using Monolingual And Bilingual Resources
Wu, Hua;Zhou, Ming;"></td>
	<td class="line x" title="1:186	Optimizing Synonym Extraction Using Monolingual and Bilingual Resources Hua WU, Ming ZHOU Microsoft Research Asia 5F Sigma Center, No.49 Zhichun Road, Haidian District Beijing, 100080, China wu_hua_@msn.com, mingzhou@microsoft.com Abstract Automatically acquiring synonymous words (synonyms) from corpora is a challenging task." ></td>
	<td class="line x" title="2:186	For this task, methods that use only one kind of resources are inadequate because of low precision or low recall." ></td>
	<td class="line x" title="3:186	To improve the performance of synonym extraction, we propose a method to extract synonyms with multiple resources including a monolingual dictionary, a bilingual corpus, and a large monolingual corpus." ></td>
	<td class="line x" title="4:186	This approach uses an ensemble to combine the synonyms extracted by individual extractors which use the three resources." ></td>
	<td class="line x" title="5:186	Experimental results prove that the three resources are complementary to each other on synonym extraction, and that the ensemble method we used is very effective to improve both precisions and recalls of extracted synonyms." ></td>
	<td class="line x" title="6:186	1 Introduction This paper addresses the problem of extracting synonymous English words (synonyms) from multiple resources: a monolingual dictionary, a parallel bilingual corpus, and a monolingual corpus." ></td>
	<td class="line x" title="7:186	The extracted synonyms can be used in a number of NLP applications." ></td>
	<td class="line x" title="8:186	In information retrieval and question answering, the synonymous words are employed to bridge the expressions gaps between the query space and the document space (Mandala et al. , 1999; Radev et al. , 2001; Kiyota et al. , 2002)." ></td>
	<td class="line x" title="9:186	In automatic text summarization, synonymous words are employed to identify repetitive information in order to avoid redundant contents in a summary (Barzilay and Elhadad, 1997)." ></td>
	<td class="line x" title="10:186	In language generation, synonyms are employed to create more varied texts (Langkilde and Knight, 1998)." ></td>
	<td class="line x" title="11:186	Up to our knowledge, there are few studies investigating the combination of different resources for synonym extraction." ></td>
	<td class="line x" title="12:186	However, many studies investigate synonym extraction from only one resource." ></td>
	<td class="line oc" title="13:186	The most frequently used resource for synonym extraction is large monolingual corpora (Hindle, 1990; Crouch and Yang, 1992; Grefenstatte, 1994; Park and Choi, 1997; Gasperin et al. , 2001 and Lin, 1998)." ></td>
	<td class="line o" title="14:186	The methods used the contexts around the investigated words to discover synonyms." ></td>
	<td class="line n" title="15:186	The problem of the methods is that the precision of the extracted synonymous words is low because it extracts many word pairs such as cat and dog, which are similar but not synonymous." ></td>
	<td class="line x" title="16:186	Other resources are also used for synonym extraction." ></td>
	<td class="line x" title="17:186	Barzilay and Mckeown (2001), and Shimohata and Sumita (2002) used bilingual corpora to extract synonyms." ></td>
	<td class="line x" title="18:186	However, these methods can only extract synonyms which occur in the bilingual corpus." ></td>
	<td class="line x" title="19:186	Thus, the extracted synonyms are limited." ></td>
	<td class="line x" title="20:186	Besides, Blondel and Sennelart (2002) used monolingual dictionaries to extract synonyms." ></td>
	<td class="line x" title="21:186	Although the precision of this method is high, the coverage is low because the result of this method heavily depends on the definitions of words." ></td>
	<td class="line x" title="22:186	In order to improve the performance of synonym extraction, Curran (2002) used an ensemble method to combine the results of different methods using a monolingual corpus." ></td>
	<td class="line x" title="23:186	Although Curran (2002) showed that the ensemble extractors outperformed the individual extractors, it still cannot overcome the deficiency of the methods using the monolingual corpus." ></td>
	<td class="line x" title="24:186	To overcome the deficiencies of the methods using only one resource, our approach combines both monolingual and bilingual resources to automatically extract synonymous words." ></td>
	<td class="line x" title="25:186	By combining the synonyms extracted by the individual extractors using the three resources, our approach can combine the merits of the individual extractors to improve the performance of synonym extraction." ></td>
	<td class="line x" title="26:186	In fact, our approach can be considered as an ensemble of different resources for synonym extraction." ></td>
	<td class="line x" title="27:186	Experimental results prove that the three resources are complementary to each other on synonym extraction, and that the ensemble method we used is very effective to improve both precisions and recalls of extracted synonyms." ></td>
	<td class="line x" title="28:186	The remainder of this paper is organized as follows." ></td>
	<td class="line x" title="29:186	The next section presents our approach for synonym extraction." ></td>
	<td class="line x" title="30:186	Section 3 describes an implementation of the three individual extractors." ></td>
	<td class="line x" title="31:186	Section 4 presents the evaluation results." ></td>
	<td class="line x" title="32:186	Section 5 discusses our method." ></td>
	<td class="line x" title="33:186	In the last section, we draw the conclusions of this work." ></td>
	<td class="line x" title="34:186	2 Our Approach Instead of using only one kind of resource to extract synonyms, we combine both monolingual and bilingual resources for synonym extraction." ></td>
	<td class="line x" title="35:186	The resources include a monolingual dictionary, an English-Chinese bilingual corpus, and a large corpus of monolingual documents." ></td>
	<td class="line x" title="36:186	Before combining them, we first propose three methods to extract synonyms from the three resources." ></td>
	<td class="line x" title="37:186	Especially, a novel method is proposed to increase the coverage of the extracted synonyms using the bilingual corpus." ></td>
	<td class="line x" title="38:186	Next, we develop an ensemble method to combine the individual extractors." ></td>
	<td class="line x" title="39:186	The advantage of our approach is that it can combine the merits of the individual extractors to improve the precision and recalls of the extracted synonyms." ></td>
	<td class="line x" title="40:186	2.1 Synonym Extraction with a Monolingual Dictionary This section proposes a method to extract synonyms from a monolingual dictionary." ></td>
	<td class="line x" title="41:186	In a monolingual dictionary, each entry is defined by other words and may also be used in the definitions for other words." ></td>
	<td class="line x" title="42:186	For a word in the dictionary, the words used to define it are called hubs and the words whose definitions include this word are called authorities as in (Blondel and Sennelart, 2002)." ></td>
	<td class="line x" title="43:186	We use the hubs and authorities of a word to represent its meaning." ></td>
	<td class="line x" title="44:186	The assumption behind this method is that two words are similar if they have common hubs and authorities." ></td>
	<td class="line x" title="45:186	In this paper, we only use content words as members of hubs and authorities." ></td>
	<td class="line x" title="46:186	We take these hubs and authorities as features of a word." ></td>
	<td class="line x" title="47:186	The vector constructed with them is referred to as the feature vector of a word." ></td>
	<td class="line x" title="48:186	The similarity between two words is calculated through their feature vectors with the cosine measure as shown in Equation (1)." ></td>
	<td class="line x" title="49:186	== = j j i i ww ji vv vv FFwwsim ji 2 2 2 1 21 21211 * )*( ),cos(),( 21 (1) where ),( ),,( ),,( 2211 >=< imimiiiii vwvwvwF Fi is the feature vector of wi; 1=ijv if word ijw is a hub or an authority of the word wi; else, 0=ijv ; 2.2 Synonym Extraction with a Bilingual Corpus This section proposes a novel method to extract synonyms from a bilingual corpus." ></td>
	<td class="line x" title="50:186	It uses the translations of a word to express its meaning." ></td>
	<td class="line x" title="51:186	The assumption of this method is that two words are synonymous if their translations are similar." ></td>
	<td class="line x" title="52:186	Given an English word, we get their translations with an English-Chinese bilingual dictionary." ></td>
	<td class="line x" title="53:186	Each translation is assigned a translation probability, which is trained with a bilingual English-Chinese corpus based on the result of word alignment." ></td>
	<td class="line x" title="54:186	The aligner use the model described in (Wang et al. , 2001)." ></td>
	<td class="line x" title="55:186	In order to deal with the problem of data sparseness, we conduct a simple smoothing by adding 0.5 to the counts of each translation pair as in (2)." ></td>
	<td class="line x" title="56:186	|_|*5.0)( 5.0),()|( ctransecount eccountecp + += (2) where ),( eccount represents the co-occurring frequency of the Chinese word c and the English word e in the sentence pairs." ></td>
	<td class="line x" title="57:186	)(ecount represents the frequency of the English word e occurring in the bilingual corpus." ></td>
	<td class="line x" title="58:186	|_| ctrans represents the number of Chinese translations for a given English word e. The translations and the translation probabilities of a word are used to construct its feature vector." ></td>
	<td class="line x" title="59:186	The similarity of two words is estimated through their feature vectors with the cosine measure as shown in (3)." ></td>
	<td class="line x" title="60:186	== = j j i i cc ji pp pp FFwwsim ji 2 2 2 1 21 21212 * )*( ),cos(),( 21 (3) where ),(  ),,( ),,( 2211 >=< imimiiiii pcpcpcF Fi is the feature vector of wi; ijc is the j th Chinese translation of the word w i; ijp is the translation probability of the word wi is translated into ijc For example, the feature vectors of two words  abandon and  forsake are: forsake: < (, 0.1333), ( o, 0.1333), (, 0.0667) (F+, 0.0667), (/, 0.0667), > abandon: <(, 0.3018), ( o, 0.1126), (F+, 0.0405), (7, 0.0225), ( o, 0.0135),> 2.3 Synonym Extraction with a Monolingual Corpus The context method described in Section 1 is also used for synonym extraction from large monolingual corpora of documents." ></td>
	<td class="line x" title="61:186	This method relies on the assumption that synonymous words tend to have similar contexts." ></td>
	<td class="line x" title="62:186	In this paper, we use the words which have dependency relationships with the investigated word as contexts." ></td>
	<td class="line x" title="63:186	The contexts are obtained by parsing the monolingual documents." ></td>
	<td class="line x" title="64:186	The parsing results are represented by dependency triples which are denoted as <w1, Relation Type, w2>." ></td>
	<td class="line x" title="65:186	For example, the sentence  I declined the invitation is transformed into three triples after parsing: <decline, SUBJ, I>, <decline, OBJ, invitation> and <invitation, DET, the>." ></td>
	<td class="line x" title="66:186	If we name <Relation Type, w2> as an attribute of the word w1, the verb  decline in the above sentence has two attributes <OBJ, invitation> and <SUBJ, I> . Thus, the contexts of a word can be expressed using its attributes." ></td>
	<td class="line x" title="67:186	In this case, two words are synonymous if they have similar attributes." ></td>
	<td class="line x" title="68:186	We use a weighted version of the Dice measure to calculate the similarity of two words." ></td>
	<td class="line x" title="69:186	),(),( )),(),(( ),( 2) 2( 1) 1( 21) 2()1( 213 jwA jatt iwA iatt kkwAwA katt attwWattwW attwWattwW wwsim  " ></td>
	<td class="line x" title="70:186	(4) where kji attattatt,, stands for attributes of words." ></td>
	<td class="line x" title="71:186	),( ji attwW indicates the association strength between the attribute attj with the word iw . )( iwA denotes the attribute set of the word iw . The measure used to measure the association strength between a word and its attributes is weighted mutual information (WMI) (Fung and Mckeown, 1997) as described in (5)." ></td>
	<td class="line x" title="72:186	)()( ),(log*),( ),(),( ji ji ji jiji attpwp attwpattwp attwWMIattwW *= = (5) where N wcountwp i i,*,*)()( = N wrcountattp j ),(*,)( =, ),( wratt j = ),(*, wrcount : frequency of the triples having dependency relation r with the word ww.,*,*)( iwcount : frequency of the triples including word iw . N: number of triples in the corpus." ></td>
	<td class="line x" title="74:186	We use it instead of point-wise mutual information in Lin (1998) because the latter tends to overestimate the association between two parts with low frequencies." ></td>
	<td class="line x" title="75:186	Weighted mutual information meliorates this effect by adding ),( ji attwp . 2.4 Combining the Three Extractors In terms of combining the outputs of the different methods, the ensemble method is a good candidate." ></td>
	<td class="line x" title="76:186	Originally, the ensemble method is a machine learning technique of combining the outputs of several classifiers to improve the classification performance (Dietterich, 2000)." ></td>
	<td class="line x" title="77:186	It has been successfully used in many NLP tasks." ></td>
	<td class="line x" title="78:186	For example, (Curran, 2002) proved that the ensembles of individual extractors using different contexts in the monolingual corpus improve the performance of synonym extraction." ></td>
	<td class="line x" title="79:186	In fact, we can consider the extractors in the previous sections as binary classifiers." ></td>
	<td class="line x" title="80:186	Thus, we use the ensemble method to combine the output of the individual extractors described in the previous sections for synonym extraction." ></td>
	<td class="line x" title="81:186	The method is described in Equation (6)." ></td>
	<td class="line x" title="82:186	)),((),( 3 1 2121" ></td>
	<td class="line x" title="83:186	= *= i ii wwsimawwsim (6) where 3) 2, 1,(i ),( 21 =wwsimi stands for the different similarity measure using different resources described in the previous sections." ></td>
	<td class="line x" title="84:186	)1 and,3,2,1( i" ></td>
	<td class="line x" title="85:186	== ii aia is the weight for the individual extractors." ></td>
	<td class="line x" title="86:186	The reasons that we use the weighted ensemble method are as follows: (1) If the majority of three extractors select the same word as a synonym of a investigated word, it tend to be a real synonym." ></td>
	<td class="line x" title="87:186	This method can ensure it has a high similarity score." ></td>
	<td class="line x" title="88:186	Thus, it will improve the precision of the extracted synonyms." ></td>
	<td class="line x" title="89:186	(2) With this method, it can improve the coverage of the extracted synonyms." ></td>
	<td class="line x" title="90:186	This is because if the similarity score of a candidate with the investigated word is higher than a threshold, our method can select the candidate as a synonym even though it is only suggested by one extractor." ></td>
	<td class="line x" title="91:186	3 Implementation of Individual Extractors For the extractor employing a monolingual dictionary, we use the same online dictionary as in (Blondel and Sennelart, 2002), which is named the Online Plain Text Dictionary." ></td>
	<td class="line x" title="92:186	The dictionary consists of 27 HTML files, which is available from the web site http://www.gutenberg.net/." ></td>
	<td class="line x" title="93:186	With the method described in Section 2.1, the result for the extracted synonyms is shown in Table 1 when the similarity threshold is set to 0.04." ></td>
	<td class="line x" title="94:186	An example is shown as follows: acclimatize: (acclimate, 0.1481; habituate, 0.0976) The numbers in the example are the similarity scores of two words." ></td>
	<td class="line x" title="95:186	Table 1." ></td>
	<td class="line x" title="96:186	Synonyms Extracted from the Monolingual Dictionary Category # Entries # Average Synonyms Noun 16963 4.7 Verb 5084 7.1 For synonym extraction from the bilingual corpus, we use an English-Chinese lexicon, which includes 219,404 English words with each source word having 3 translations on average." ></td>
	<td class="line x" title="97:186	The word translation probabilities are estimated from a bilingual corpus that obtains 170,025 pairs of Chinese-English sentences, including about 2.1 million English words and about 2.5 million Chinese words." ></td>
	<td class="line x" title="98:186	With the method described in Section 2.2, we extracted synonyms as shown in Table 2 when the similarity threshold is set to 0.04." ></td>
	<td class="line x" title="99:186	Table 2." ></td>
	<td class="line x" title="100:186	Synonyms Extracted from the Bilingual corpus Category #Entries #Average Synonyms Noun 26253 10.2 Verb 7364 14.8 For synonym extraction from a monolingual corpus, we use the Wall Street Journal from 1987 to 1992, the size of which is about 500M bytes." ></td>
	<td class="line x" title="101:186	In order to get contexts of words, we parse the corpus with an English parser NLPWIN 1 . From the parsing results, we extracted the following four types of dependency triples." ></td>
	<td class="line x" title="102:186	(a) <verb, OBJ, noun> (b) <verb, SUBJ, noun> (c) <noun, ATTRIB, adjective> (d) <verb, MODS, adjunct> The statistics are shown in Table 3." ></td>
	<td class="line x" title="103:186	Token means the total number of triples in the triple set and type means a unique instance of triple in the corpus." ></td>
	<td class="line x" title="104:186	These triples are used as contexts of words to calculate the similarity between words as described in Section 2.3." ></td>
	<td class="line x" title="105:186	The result is shown in Table 4 when the similarity threshold is set to 0.1." ></td>
	<td class="line x" title="106:186	1 The NLPWIN parser is developed at Microsoft Research." ></td>
	<td class="line x" title="107:186	Its output can be a phrase structure parse tree or a logical form which is represented with dependency triples." ></td>
	<td class="line x" title="108:186	Table 3." ></td>
	<td class="line x" title="109:186	Statistics for Triples # Token # Type OBJ 7,041,382 1,487,543 SUBJ 7,180,572 2,116,761 ATTRIB 4,976,822 1,393,188 MODS 3,557,737 94,004 Total 22,756,512 5,937,496 Table 4." ></td>
	<td class="line x" title="110:186	Synonyms Extracted from the Monolingual Corpus Category Entries Average Synonyms Noun 16963 4.6 Verb 5084 7.1 4 Evaluation 4.1 The Gold Standard The simplest evaluation measure is direct comparison of the extracted synonyms with the manually created thesaurus." ></td>
	<td class="line x" title="111:186	However, the thesaurus coverage is a problem." ></td>
	<td class="line x" title="112:186	In this paper, we combined two thesauri as a gold stardard: WordNet 1.6 http://www.cogsci.princeton.edu/~wn/) and Roget (Rogets II: The New Thesaurus, 1995." ></td>
	<td class="line x" title="113:186	http://www.bartleby.com/thesauri/)." ></td>
	<td class="line x" title="114:186	In WordNet, one synset consists of several synonyms which represent a single sense." ></td>
	<td class="line x" title="115:186	Therefore, a polysemous word occurs in more than one synsets." ></td>
	<td class="line x" title="116:186	For example, the polysemous word  abandon occur in five different synsets: (abandon, forsake, desolate, desert, lurch) (vacate, empty, abandon) (abandon, give up, give) (abandon, give up) (abandon) For a given word, we combine its synonyms from all synsets including the word." ></td>
	<td class="line x" title="117:186	Thus, we get the synonyms of the word  abandon as follows: abandon" ></td>
	<td class="line x" title="118:186	forsake, desolate, desert, lurch, vacate, empty, give up, give For synonyms in Roget, we also combine the synonyms in different synsets into one set as we do for WordNet." ></td>
	<td class="line x" title="119:186	Thus, we get the synonyms of the word  abandon as follows: abandon" ></td>
	<td class="line x" title="120:186	break off, desist, discontinue, give up, leave off, quit, relinquish, remit, stop, desert, forsake, leave, throw over, abdicate, cede, demit, forswear, hand over, quitclaim, render, renounce, resign, surrender, waive, yield, give over, forgo, lay down Combining the results of WordNet and Roget, we can get the synonyms of the word  abandon as follows." ></td>
	<td class="line x" title="121:186	abandon" ></td>
	<td class="line x" title="122:186	desolate, lurch, vacate, empty, give, abdicate, break off, cede, demit, desert, desist, discontinue, forgo, forsake, forswear, give up, give over, hand over, lay down, lay off, leave off, leave, quit, quitclaim, relinquish, remit, stop, swear off, throw over, render, renounce, resign, surrender, waive, yield 4.2 Evaluation Measures The evaluation metrics are precision, recall, and f-measure." ></td>
	<td class="line x" title="123:186	If we use S to indicate the synonyms that our method extracts for a word and GS to denote the synonyms of the word in WordNet and Roget, the methods to calculate the precision, recall, and f-measure of our methods are shown in Equation (7), (8), and (9)." ></td>
	<td class="line x" title="124:186	To investigate the results of more than one word, we calculate the average precision, recall and f-measure, which sum the individual values divided by the number of the investigated words." ></td>
	<td class="line x" title="125:186	|S| |SS| G=precision (7) |S| |SS| G G=recall (8) recallprecision recallprecision2measure-f + **= (9) 4.3 Test Set In order to evaluate our methods, we build up a test set which includes three parts: (a) high-frequency words: occurring more than 100 times; (b) middle-frequency words: occurring more than 10 times and not greater than 100 times; (c) low-frequency words: occurring no greater than 10 times." ></td>
	<td class="line x" title="126:186	Table 5." ></td>
	<td class="line x" title="127:186	Statistics for Nouns and Verbs High Frequency Middle Frequency Low Frequency Noun 600 2000 1000 Verb 340 1300 800 The frequency counts are estimated from Wall Street Journal (1987-1992), from which we randomly extracted 3600 nouns and 2440 verbs." ></td>
	<td class="line x" title="128:186	These Table 6." ></td>
	<td class="line x" title="129:186	Evaluation Results for Nouns High-Frequency Nouns Middle-Frequency Nouns Low-Frequency Nouns Pre Rec F Pre Rec F Pre Rec F 1 0.174 0.140 0.155 0.212 0.137 0.167 0.198 0.119 0.149 2 0.225 0.209 0.217 0.242 0.212 0.226 0.207 0.212 0.209 3 0.118 0.109 0.114 0.117 0.104 0.109 0.099 0.096 0.098 1+2+3 0.240 0.201 0.219 0.271 0.220 0.243 0.222 0.232 0.227 Table 7." ></td>
	<td class="line x" title="130:186	Evaluation Results for Verbs High-Frequency Verbs Middle-Frequency Verbs Low-Frequency Verbs Pre Rec F Pre Rec F Pre Rec F 1 0.228 0.243 0.235 0.272 0.233 0.251 0.209 0.216 0.212 2 0.226 0.312 0.262 0.224 0.292 0.253 0.184 0.275 0.220 3 0.143 0.166 0.154 0.162 0.127 0.142 0.128 0.135 0.132 1+2+3 0.295 0.323 0.308 0.311 0.304 0.307 0.238 0.302 0.266 Note: 1, 2, and 3 represent the extractor using the monolingual dictionary, the bilingual corpus, and the monolingual corpus respectively." ></td>
	<td class="line x" title="131:186	The symbols  Pre,  Rec, and  F represent precision, recall, and f-measure scores." ></td>
	<td class="line x" title="132:186	0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0 0.1 0.2 0.3 0.4 0.5 Recall P r e c i s i o n 2 1 3 1+2+3 Figure 1." ></td>
	<td class="line x" title="133:186	Recall-Precision curves for nouns Figure 2." ></td>
	<td class="line x" title="134:186	Recall-Precision curves for verbs words have synonyms both in our results extracted from the three resources and in the thesauri WordNet and Roget." ></td>
	<td class="line x" title="135:186	The statistics of the test set are shown in Table 5." ></td>
	<td class="line x" title="136:186	4.4 Experimental Results In this section, we compare the extracted synonyms of the nouns and verbs in the test set with those in WordNet and Roget." ></td>
	<td class="line x" title="137:186	For each method, we select those as synonyms whose similarity scores with the investigated word are larger than a given threshold." ></td>
	<td class="line x" title="138:186	A development set is used to determine the thresholds of each method." ></td>
	<td class="line x" title="139:186	The thresholds for getting highest f-measure scores on the development set are selected." ></td>
	<td class="line x" title="140:186	In our experiments, we get 0.04, 0.04, 0.1 and 0.04 for Method 1, Method 2, Method 3 and the combined approach, respectively." ></td>
	<td class="line x" title="141:186	The evaluation results for the individual extractors and the ensemble extractor are shown in Table 6 and Table 7." ></td>
	<td class="line x" title="142:186	We set a1=0.4, a2=0.4 and a3=0.2 in Equation (6) for the ensemble to combine the results from the three resources." ></td>
	<td class="line x" title="143:186	The weights are also obtained with the development set." ></td>
	<td class="line x" title="144:186	In order to examine the performance of each method in more details, we also get the precisions and recalls under different thresholds." ></td>
	<td class="line x" title="145:186	Figure 1 and Figure 2 shows the precision values under different recall values (different thresholds) for all nouns and verbs, respectively." ></td>
	<td class="line x" title="146:186	Among all of the methods, the method combining all of the three resources gets the best results in terms of both precision and recall." ></td>
	<td class="line x" title="147:186	The effect is similar to the ensemble methods for synonym 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Recall P r e c i s i o n 2 1 3 1+2+3 extraction in (Curran 2002)." ></td>
	<td class="line x" title="148:186	However, our method uses an ensemble of different resources instead of one single resource." ></td>
	<td class="line x" title="149:186	During the experiments, we also find the ensemble combining all of the three extractors outperforms the ensembles only combining any two of the three extractors." ></td>
	<td class="line x" title="150:186	This indicates that the extractors using the three different resources are complementary to each other." ></td>
	<td class="line x" title="151:186	For example, the extractor using the monolingual dictionary gets a high precision and the extractor using the bilingual corpus gets a high recall." ></td>
	<td class="line x" title="152:186	Although the extractor using the monolingual corpus achieved much lower precision and recall on synonym extraction, it is still useful to be included in the ensemble." ></td>
	<td class="line x" title="153:186	This shows that the monolingual corpus is complementary to the other two resources on synonym extraction." ></td>
	<td class="line x" title="154:186	The success of our method also indicates that our ensemble method by weighting all extractors is effective for synonym extraction." ></td>
	<td class="line x" title="155:186	Among the methods only using one kind of resource, Method 2, which uses the bilingual corpus, has the highest f-measure scores on both nouns and verbs." ></td>
	<td class="line x" title="156:186	From the results in Figure 1 and Figure 2, we can see that the coverage of synonyms extracted by Method 2 is the highest." ></td>
	<td class="line x" title="157:186	Although it has lower precisions than Method 1 under low recalls, its precisions are higher than those of Method 1 under higher recalls." ></td>
	<td class="line x" title="158:186	This shows that Method 2 can get a good compromise between precision and recall." ></td>
	<td class="line x" title="159:186	We also note that the maximum recall of Method 2 is much larger than that of Method 1." ></td>
	<td class="line x" title="160:186	This is because (1) in Method 1, the words used in the definitions are highly limited." ></td>
	<td class="line x" title="161:186	Thus, the coverage of the synonyms is limited; (2) the advantage of Method 2 is that the coverage of extracted synonyms is high because it can extract the synonyms not occurring in the corpus." ></td>
	<td class="line x" title="162:186	It is different from the method in (Barzilay and Mckeown, 2001; Shimohata and Sumita, 2002), which can only extract the synonyms in the bilingual corpus." ></td>
	<td class="line x" title="163:186	The performance of Method 3 is the worst." ></td>
	<td class="line x" title="164:186	It is caused by two factors: (1) the context model of Method 3 introduces much noise because of the errors of the parser; (2) this method is unable to distinguish synonyms, antonyms, and similar words because they tend to have similar contexts." ></td>
	<td class="line x" title="165:186	From the contexts it uses, method 3 is suitable to extract related words which have the similar usages from the view of syntax." ></td>
	<td class="line x" title="166:186	5 Discussions This paper uses three different methods and resources for synonym extraction." ></td>
	<td class="line x" title="167:186	By using the corpus-based method, we can get some synonyms or near synonyms which can not be found in the hand-built thesauri." ></td>
	<td class="line x" title="168:186	For Example:  handspring" ></td>
	<td class="line x" title="169:186	handstand,  audiology" ></td>
	<td class="line x" title="170:186	otology,  roisterer" ></td>
	<td class="line x" title="171:186	carouser and  parmesan" ></td>
	<td class="line x" title="172:186	gouda . These kinds of synonyms are difficult for hand-built thesauri to cover because they occur too infrequent to be caught by humans." ></td>
	<td class="line x" title="173:186	In addition, this corpus-based method can get synonyms in specific domains while the general thesauri dont provide such fine-grained knowledge." ></td>
	<td class="line x" title="174:186	Comparing the results with the human-built thesauri is not the best way to evaluate synonym extraction because the coverage of the human-built thesaurus is also limited." ></td>
	<td class="line x" title="175:186	However, manually evaluating the results is time consuming." ></td>
	<td class="line x" title="176:186	And it also cannot get the precise evaluation of the extracted synonyms." ></td>
	<td class="line x" title="177:186	Although the human-built thesauri cannot help to precisely evaluate the results, they can still be used to detect the effectiveness of extraction methods." ></td>
	<td class="line x" title="178:186	Conclusion This paper proposes a new method to extract synonyms from three resources: a monolingual dictionary, a bilingual corpus, and a large monolingual corpus." ></td>
	<td class="line x" title="179:186	This method uses a weighted ensemble to combine all of the results of the individual extractors using one of the three resources respectively." ></td>
	<td class="line x" title="180:186	Experimental results prove that the three resources are complementary to each other on synonym extraction, and that the ensemble method we used is very effective to improve both precisions and recalls when the results are compared with the manually-built thesauri WordNet and Roget." ></td>
	<td class="line x" title="181:186	Further, we also propose a new method to extract synonyms from a bilingual corpus." ></td>
	<td class="line x" title="182:186	This method uses the translations of a word to represent its meaning." ></td>
	<td class="line x" title="183:186	The translation probabilities are trained with the bilingual corpus." ></td>
	<td class="line x" title="184:186	The advantage of this method is that it can improve the coverage of the extracted synonyms." ></td>
	<td class="line x" title="185:186	Experiments indicate that this method outperforms the other methods using a monolingual corpus or a monolingual dictionary." ></td>
	<td class="line x" title="186:186	The contribution of this work lies in three aspects: (1) develop a method to combine the results of individual extractors using the three resources on synonym extraction; (2) investigate the performance of the three extraction methods using different resources, exposing the merits and demerits of each method; (3) propose a new method to extract synonyms from a bilingual corpus, which greatly improves the coverage of the extracted synonyms." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C04-1036
Feature Vector Quality And Distributional Similarity
Geffet, Maayan;Dagan, Ido;"></td>
	<td class="line x" title="1:158	Feature Vector Quality and Distributional Similarity Maayan Geffet School of Computer Science and Engineering, Hebrew University Givat Ram Campus, Jerusalem, Israel, 91904 mary@cs.huji.ac.il Ido Dagan Department of Computer Science, Bar-Ilan University Ramat-Gan, Israel, 52900 dagan@cs.biu.ac.il Abstract We suggest a new goal and evaluation criterion for word similarity measures." ></td>
	<td class="line x" title="2:158	The new criterion meaning-entailing substitutability fits the needs of semantic-oriented NLP applications and can be evaluated directly (independent of an application) at a good level of human agreement." ></td>
	<td class="line x" title="3:158	Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results, proposing an objective measure for evaluating feature vector quality." ></td>
	<td class="line x" title="4:158	Finally, a novel feature weighting and selection function is presented, which yields superior feature vectors and better word similarity performance." ></td>
	<td class="line oc" title="5:158	1 Introduction Distributional Similarity has been an active research area for more than a decade (Hindle, 1990), (Ruge, 1992), (Grefenstette, 1994), (Lee, 1997), (Lin, 1998), (Dagan et al. , 1999), (Weeds and Weir, 2003)." ></td>
	<td class="line x" title="6:158	Inspired by Harris distributional hypothesis (Harris, 1968), similarity measures compare a pair of weighted feature vectors that characterize two words." ></td>
	<td class="line x" title="7:158	Features typically correspond to other words that co-occur with the characterized word in the same context." ></td>
	<td class="line x" title="8:158	It is then assumed that different words that occur within similar contexts are semantically similar." ></td>
	<td class="line x" title="9:158	As it turns out, distributional similarity captures a somewhat loose notion of semantic similarity (see Table 1)." ></td>
	<td class="line x" title="10:158	By construction, if two words are distributionally similar then the occurrence of one word in some contexts indicates that the other word is also likely to occur in such contexts." ></td>
	<td class="line x" title="11:158	But it does not ensure that the meaning of the first word is preserved when replacing it with the other one in the given context." ></td>
	<td class="line x" title="12:158	For example, words of similar semantic types, such as company government, tend to come up as distributionally similar, even though they are not substitutable in a meaning preserving sense." ></td>
	<td class="line x" title="13:158	On the other hand, many semantic-oriented applications, such as Question Answering, Paraphrasing and Information Extraction, do need to recognize which words may substitute each other in a meaning preserving manner." ></td>
	<td class="line x" title="14:158	For example, a question about company may be answered by a sentence about firm, but not about government." ></td>
	<td class="line x" title="15:158	Such applications usually utilize reliable taxonomies or ontologies like WordNet, but cannot rely on the loose type of output of distributional similarity measures." ></td>
	<td class="line x" title="16:158	In recent work Dagan and Glickman (2004) observe that applications usually do not require a strict meaning preserving criterion between text expressions, but rather need to recognize that the meaning of one expression entails the other." ></td>
	<td class="line x" title="17:158	Entailment modeling is thus proposed in their work as a generic (application-independent) framework for practical semantic inference." ></td>
	<td class="line x" title="18:158	We suggest adopting such (directional) entailment criterion at the lexical level for judging whether one word can be substituted by another one." ></td>
	<td class="line x" title="19:158	For example, certain questions about companies might be answered by sentences about automakers, since the meaning of automaker entails the meaning of company (though not vice versa)." ></td>
	<td class="line x" title="20:158	In this paper we adapt this new criterion, termed meaning entailing substitutability, as a direct evaluation criterion for the 'correctness' of the output of word similarity measures (as opposed to indirect evaluations through WSD or distance in WordNet)." ></td>
	<td class="line x" title="21:158	Our eventual research goal is improving word similarity measures to predict better the more delicate meaning entailment relationship between words." ></td>
	<td class="line x" title="22:158	As a first step it was necessary to analyze the typical behavior of current similarity measures and categorize their errors (Section 3)." ></td>
	<td class="line x" title="23:158	Our main observation is that the quality of similarity scores nation region state *world island province 1 2 3 4 5 6 *city territory area *town republic african_country 7 8 9 10 11 12 *north *economy *neighbor *member *party *government 13 14 15 16 17 18 *company *industry kingdom european_country place colony 19 20 25 31 36 41 Table 1: The 20 top most similar words of country (and their ranks) in the similarity list by Lin98, followed by the next 4 words in the similarity list that are judged as correct." ></td>
	<td class="line x" title="24:158	Incorrect similarities, under the substitutability criterion, are marked with *." ></td>
	<td class="line x" title="25:158	is often hurt by improper feature weights, which yield rather noisy feature vectors." ></td>
	<td class="line x" title="26:158	We quantify this problem by a new measure for feature vector quality, which is independent of any particular vector similarity measure." ></td>
	<td class="line x" title="27:158	To improve feature vector quality a novel feature weighting function is introduced, called relative feature focus (RFF) (Section 4)." ></td>
	<td class="line x" title="28:158	While having a simple (though non-standard) definition, this function yields improved performance relative to the two suggested evaluation criteria for vector quality and for word similarity." ></td>
	<td class="line x" title="29:158	The underlying idea is that a good characteristic feature for a word w should characterize also multiple words that are highly similar to w. In other words, such feature should have a substantial 'focus' within the close semantic vicinity of w. Applying RFF weighting achieved about 10% improvement in predicting meaning entailing substitutability (Section 5)." ></td>
	<td class="line x" title="30:158	Further analysis shows that RFF also leads to 'cleaner' characteristic feature vectors, which may be useful for additional feature-based tasks like clustering." ></td>
	<td class="line x" title="31:158	2 Background and Definitions In the distributional similarity scheme each word w is represented by a feature vector, where an entry in the vector corresponds to a feature f. Each feature represents another word (or term) with which w co-occurs, and possibly specifies also the syntactic relation between the two words." ></td>
	<td class="line x" title="32:158	The value of each entry is determined by some weight function weight(w,f), which quantifies the degree of statistical association between the feature and the corresponding word." ></td>
	<td class="line x" title="33:158	Typical feature weighting functions include the logarithm of the frequency of word-feature cooccurrence (Ruge, 1992), and the conditional probability of the feature given the word (within probabilistic-based measures) (Pereira et al. , 1993), (Lee, 1997), (Dagan et al. , 1999)." ></td>
	<td class="line nc" title="34:158	Probably the most widely used association weight function is (point-wise) Mutual Information (MI) (Church et al. , 1990), (Hindle, 1990), (Lin, 1998), (Dagan, 2000), defined by: )()( ),(log),( 2 fPwP fwPfwMI = A known weakness of MI is its tendency to assign high weights for rare features." ></td>
	<td class="line p" title="35:158	Yet, similarity measures that utilize MI showed good performance." ></td>
	<td class="line x" title="36:158	In particular, a common practice is to filter out features by minimal frequency and weight thresholds." ></td>
	<td class="line x" title="37:158	A word's vector is then constructed from the remaining features, which we call here active features." ></td>
	<td class="line x" title="38:158	Once feature vectors have been constructed, the similarity between two words is defined by some vector similarity metric." ></td>
	<td class="line x" title="39:158	Different metrics have been used in the above cited papers, such as Weighted Jaccard (Dagan, 2000), cosine (Ruge, 1992), various information theoretic measures (Lee, 1997), and others." ></td>
	<td class="line x" title="40:158	We picked the widely cited and competitive (e.g.(Weeds and Weir, 2003)) measure of Lin (1998) as a representative case, and utilized it for our analysis and as a starting point for improvement." ></td>
	<td class="line x" title="42:158	2.1 Lin's (98) Similarity Measure Lin's similarity measure between two words, w and v, is defined as follows:,),(),( ),(),( ),( )()( )()(      + + = fvweightfwweight fvweightfwweight vwsim vFfwFf vFwFf where F(w) and F(v) are the active features of the two words and the weight function is defined as MI." ></td>
	<td class="line x" title="43:158	A feature is defined as a pair <term, syntacCountryState Ranks CountryEconomy Ranks Broadcast Goods Civil_servant Bloc Nonaligned Neighboring Statistic Border Northwest 24 140 64 30 55 15 165 10 41 50 16 54 77 60 165 43 247 174 Devastate Developed Dependent Industrialized Shattered Club Black Million Electricity 81 36 101 49 16 155 122 31 130 8 78 26 85 141 38 109 245 154 Table 3: The top-10 common features for the word pairs country-state and country-economy, along with their corresponding ranks in the sorted feature lists of the two words." ></td>
	<td class="line x" title="44:158	Feature Weight Commercial-bank, gena0 Destination, pcompa1 Airspace, pcomp a0 Landlocked, mod a1 Trade_balance, gen a0 Sovereignty, pcompa0 Ambition, nn a0 Bourse, gen a0 Politician, gen a0 Border, pcomp a0 8.08 7.9a2 7.83 7.79 7.78 7.78 7.77 7.72 7.54 7.53 Table 2: The top-10 ranking features for country." ></td>
	<td class="line x" title="45:158	tic_relation>." ></td>
	<td class="line x" title="46:158	For example, given the word company the feature <earnings_report, geng969> (genitive) corresponds to the phrase companys earnings report, and <profit, pcompg969> (prepositional complement) corresponds to the profit of the company." ></td>
	<td class="line x" title="47:158	The syntactic relations are generated by the Minipar dependency parser (Lin, 1993)." ></td>
	<td class="line x" title="48:158	The arrows indicate the direction of the syntactic dependency: a downward arrow indicates that the feature is the parent of the target word, and the upward arrow stands for the opposite." ></td>
	<td class="line x" title="49:158	In our implementation we filtered out features with overall frequency lower than 10 in the corpus and with MI weights lower than 4." ></td>
	<td class="line x" title="50:158	(In the tuning experiments the filtered version showed 10% improvement in precision over no feature filtering)." ></td>
	<td class="line x" title="51:158	From now on we refer to this implementation as Lin98." ></td>
	<td class="line x" title="52:158	3 Empirical Analysis of Lin98 and Vector Quality Measure To gain better understanding of distributional similarity we first analyzed the empirical behavior of Lin98, as a representative case for state of the art (see Section 5.1 for corpus details)." ></td>
	<td class="line x" title="53:158	As mentioned in the Introduction, distributional similarity may not correspond very tightly to meaning entailing substitutability." ></td>
	<td class="line x" title="54:158	Under this judgment criterion two main types of errors occur: (1) word pairs that are of similar semantic types, but are not substitutable, like firm and government; and (2) word pairs that are of different semantic types, like firm and contract, which might (or might not) be related only at a topical level." ></td>
	<td class="line x" title="55:158	Table 1 shows the top most similar words for the target word country according to Lin98a3 The two error types are easily recognized, e.g. world and city for the first type, and economy for the second." ></td>
	<td class="line x" title="56:158	A deeper look at the word feature vectors reveals typical reasons for such errors." ></td>
	<td class="line x" title="57:158	In many cases, high ranking features in a word vector, when sorting the features by their weight, do not seem very characteristic for the word meaning." ></td>
	<td class="line x" title="58:158	This is demonstrated in Table 2, which shows the top-10 features in the vector of country." ></td>
	<td class="line x" title="59:158	As can be seen, some of the top features are either too specific (landlocked, airspace), and so are less reliable, or too general (destination, ambition), and hence not indicative and may co-occur with many different types of words." ></td>
	<td class="line x" title="60:158	On the other hand, more characteristic features, like population and governor, occur further down the list, at positions 461 and 832." ></td>
	<td class="line x" title="61:158	Overall, features that characterize well the word meaning are scattered across the ranked list, while many non-indicative features receive high weights." ></td>
	<td class="line x" title="62:158	This may yield high similarity scores for less similar word pairs, while missing other correct similarities." ></td>
	<td class="line x" title="63:158	An objective indication of the problematic feature ranking is revealed by examining the common features that contribute mostly to the similarity score of a pair of similar words." ></td>
	<td class="line x" title="64:158	We look at the common features of the two words and sort them by the sum of their weights in the two word vectors (which is the enumerator of Lin's sim formula in Section 2.1)." ></td>
	<td class="line x" title="65:158	Table 3 shows the top-10 common features for a pair of substitutable words (country state) and non-substitutable words (country economy)." ></td>
	<td class="line x" title="66:158	In both cases the common features are scattered across each feature vector, making it difficult to distinguish between similar and non-similar word pairs." ></td>
	<td class="line x" title="67:158	We suggest that the desired behavior of feature ranking is that the common features of truly similar words will be concentrated at the top ranks of their vectors." ></td>
	<td class="line x" title="68:158	The common features for non-similar words are expected to be scattered all across each of the vectors." ></td>
	<td class="line x" title="69:158	More formally, given a pair of similar words (judged as substitutable) w and v we define the top joint feature rank criterion for evaluating feature vector quality: ],),(),([211 ),,( ))()(( + =  fvrankfwrankn nvwranktop vFwFntopf where rank(w,f) is the features position in the sorted vector of the word w, and n is the number of top joint features to consider (top-n), when sorted by the sum of their weights in the two word vectors." ></td>
	<td class="line x" title="70:158	We thus expect that a good weighting function would yield (on average) a low top-rank score for truly similar words." ></td>
	<td class="line x" title="71:158	4 Relative Feature Focus (RFF) Motivated by the observations above we propose a new feature weight function, called relative feature focus (RFF)." ></td>
	<td class="line x" title="72:158	The basic idea is to promote features which characterize many words that are highly similar to w. These features are considered as having a strong 'focus' around w's meaning." ></td>
	<td class="line x" title="73:158	Features which do not characterize sufficiently many words that are sufficiently similar to w are demoted." ></td>
	<td class="line x" title="74:158	Even if such features happen to have a strong direct association with w they are not considered reliable, as they do not have sufficient statistical mass in w's semantic vicinity." ></td>
	<td class="line x" title="75:158	4.1 RFF Definition RFF is defined as follows." ></td>
	<td class="line x" title="76:158	First, a standard word similarity measure sim is computed to obtain initial approximation of the similarity space (Lin98 was used in this work)." ></td>
	<td class="line x" title="77:158	Then, we define the word set of a feature f, denoted by WS(f), as the set of words for which f is an active feature." ></td>
	<td class="line x" title="78:158	The semantic neighborhood of w, denoted by N(w), is defined as the set of all words v which are considered sufficiently similar to w, satisfying sim(w,v)>s where s is a threshold (0.04 in our experiments)." ></td>
	<td class="line x" title="79:158	RFF is then defined by:  = ),(),( )()( vwsimfwRFF wNfWSv." ></td>
	<td class="line x" title="80:158	That is, we identify all words v that are in the semantic neighborhood of w and are also characterized by f and sum their similarities to w. Notice that RFF is a sum of word similarity values rather than being a direct function of wordfeature association values (which is the more common approach)." ></td>
	<td class="line x" title="81:158	It thus does not depend on the exact co-occurrence level between w and f. Instead, it depends on a more global assessment of the association between f and the semantic vicinity of w. Unlike the entropy measure, used in (Grefenstette, 1994), our 'focused' global view is relative to each individual word w and is not a global independent function of the feature." ></td>
	<td class="line x" title="82:158	We notice that summing the above similarity values captures simultaneously a desired balance between feature specificity and generality, addressing the observations in Section 3." ></td>
	<td class="line x" title="83:158	Some features might characterize just a single word that is very similar to w. But then the sum of similarities will include a single element, yielding a relatively low weight.1 General features may characterize more words within N(f), but then on average the similarity with w over multiple words is likely to become lower, contributing smaller values to the sum." ></td>
	<td class="line x" title="84:158	A reliable feature has to characterize multiple words (not too specific) that are highly similar to w (not too general)." ></td>
	<td class="line x" title="85:158	4.2 Re-computing Similarities Once RFF weights have been computed they are sufficiently accurate to allow for aggressive feature reduction." ></td>
	<td class="line x" title="86:158	In our experiments it sufficed to use only the top 100 features for each word in order to obtain optimal results, since the most informative features now have the highest weights." ></td>
	<td class="line x" title="87:158	Similarity between words is then recomputed over the reduced vectors using Lin's sim function (in Section 2.1), with RFF replacing MI as the new weight function." ></td>
	<td class="line x" title="88:158	1 This is why the sum of similarities is used rather than an average value, which might become too high by chance when computed over just a single element (or very few elements)." ></td>
	<td class="line x" title="89:158	#Words Judge 1 (%) Judge 2 (%) Total (%) Top 10 63.4 / 54.1 62.6 / 53.4 63.0 / 53.7 Top 20 57.0 / 48.3 56.4 / 45.8 56.8 / 47.0 Top 30 55.3 / 45.1 53.3 / 43.4 54.2 / 44.2 Top 40 53.5 / 44.6 51.6 / 42.0 52.6 / 43.3 Table 4: Precision values for Top-N similar words by the RFF / Lin98 methods." ></td>
	<td class="line x" title="90:158	5 Evaluation 5.1 Experimental Setting The performance of the RFF-based similarity measure was evaluated for a sample of nouns and compared with that of Lin98." ></td>
	<td class="line x" title="91:158	The experiment was conducted using an 18 million tokens subset of the Reuters RCV1 corpus,2 parsed by Lins Minipar dependency parser (Lin, 1993)." ></td>
	<td class="line x" title="92:158	We considered first an evaluation based on WordNet data as a gold standard, as in (Lin, 1998; Weeds and Weir, 2003)." ></td>
	<td class="line x" title="93:158	However, we found that many word pairs from the Reuters Corpus that are clearly substitutable are not linked appropriately in WordNet." ></td>
	<td class="line x" title="94:158	We therefore conducted a manual evaluation based on the judgments of two human subjects." ></td>
	<td class="line x" title="95:158	The judgment criterion follows common evaluations of paraphrase acquisition (Lin and Pantel, 2001), (Barzilay and McKeown, 2001), and corresponds to the meaning-entailing substitutability criterion discussed in Section 1." ></td>
	<td class="line x" title="96:158	Two words are judged as substitutable (correct similarity) if there are some contexts in which one of the words can be substituted by the other, such that the meaning of the original word can be inferred from the new one." ></td>
	<td class="line x" title="97:158	Typically substitutability corresponds to certain ontological relations." ></td>
	<td class="line x" title="98:158	Synonyms are substitutable in both directions." ></td>
	<td class="line x" title="99:158	For example, worker and employee entail each other's meanings, as in the context high salaried worker/employee." ></td>
	<td class="line x" title="100:158	Hyponyms typically entail their hypernyms." ></td>
	<td class="line x" title="101:158	For example, dog entails animal, as in I have a dog which entails I have an animal (but not vice versa)." ></td>
	<td class="line x" title="102:158	In some cases part-whole and member-set relations satisfy the meaning-entailing substitutability criterion." ></td>
	<td class="line x" title="103:158	For example, a discussion of division entails in many contexts the meaning of company." ></td>
	<td class="line x" title="104:158	Similarly, the plural form of employee(s) often entails the meaning of staff." ></td>
	<td class="line x" title="105:158	On the other hand, non-synonymous words that share a common hypernym (cohyponyms) like company and government, or country and city, are not substitutable since they always refer to different meanings (such as different entities)." ></td>
	<td class="line x" title="106:158	Our test set included a sample of 30 randomly selected nouns whose corpus frequency is above 2 Known as Reuters Corpus, Volume 1, English Language, 1996-08-20 to 1997-08-19." ></td>
	<td class="line x" title="107:158	500." ></td>
	<td class="line x" title="108:158	For each noun we computed the top 40 most similar words by both similarity measures, yielding a total set of about 1600 (different) suggested word similarity pairs." ></td>
	<td class="line x" title="109:158	Two independent assessors were assigned, each judging half of the test set (800 pairs)." ></td>
	<td class="line x" title="110:158	The output pairs from both methods were mixed so the assessor could not relate a pair with the method that suggested it." ></td>
	<td class="line x" title="111:158	5.2 Similarity Results The evaluation results are displayed in Table 4." ></td>
	<td class="line x" title="112:158	As can be seen RFF outperformed Lin98 by 9-10 percentage points of precision at all Top-N levels, by both judges." ></td>
	<td class="line x" title="113:158	Overall, RFF extracted 111 (21%) more correct similarity pairs than Lin98." ></td>
	<td class="line x" title="114:158	The overall relative recall3 of RFF is quite high (89%), exceeding Lin98 by 16% (73%)." ></td>
	<td class="line x" title="115:158	These figures indicate that our method covers most of the correct similarities found by Lin98, while identifying many additional correct pairs." ></td>
	<td class="line x" title="116:158	We note that the obtained precision values for both judges are very close at all table rows." ></td>
	<td class="line x" title="117:158	To further assess human agreement level for this task the first author of this paper judged two samples of 100 word pairs each, which were selected randomly from the two test sets of the original judges." ></td>
	<td class="line x" title="118:158	The proportions of matching decisions between the author's judgments and the original ones were 91.3% (with Judge 1) and 88.9% (with Judge 2)." ></td>
	<td class="line x" title="119:158	The corresponding Kappa values are 0.83 (very good agreement) and 0.75 (good agreement)." ></td>
	<td class="line x" title="120:158	As for feature reduction, vector sizes were reduced on average to about one third of their original size in the Lin98 method (recall that standard feature reduction, tuned for the corpus, was already applied to the Lin98 vectors)." ></td>
	<td class="line x" title="121:158	3 Relative recall shows the percentage of correct word similarities found by each method relative to the joint set of similarities that were extracted by both methods." ></td>
	<td class="line x" title="122:158	Feature Weight Industry, gen a0 Airport, gen a0 Neighboring, mod a1 Law, gen a0 Economy, gen a0 Population, gen a0 City, gen a0 Impoverished, mod a1 Governor, pcomp a1 Parliament, gen a0 1.21 1.16 1.06 1.04 1.02 1.02 0.93 0.92 0.92 0.91 Table 5: Top-10 features of country by RFF." ></td>
	<td class="line x" title="123:158	5.3 Empirical Observations for RFF We now demonstrate the typical behavior of RFF relative to the observations and motivations of Section 3 (through the same example)." ></td>
	<td class="line x" title="124:158	Table 5 shows the top-10 features of country." ></td>
	<td class="line x" title="125:158	We observe (subjectively) that the list now contains quite indicative and reliable features, where too specific (anecdotal) and too general features were demoted (compare with Table 2)." ></td>
	<td class="line x" title="126:158	More objectively, Table 6 shows that most of the top-10 common features for country-state are now ranked highly for both words." ></td>
	<td class="line x" title="127:158	On the other hand, there are only two common features for the incorrect pair country-economy, both with quite low ranks (compare with Table 3)." ></td>
	<td class="line x" title="128:158	Overall, given the set of all the correct (judged as substitutable) word similarities produced by both methods, the average top joint feature rank of the top-10 common features by RFF is 21, satisfying the desired behavior which was suggested in Section 3." ></td>
	<td class="line x" title="129:158	The same figure is much larger for the Lin98 vectors, which have an average top joint feature rank of 105." ></td>
	<td class="line x" title="130:158	Consequently, Table 7 shows a substantial improvement in the similarity list for country, where most incorrect words, like economy and company, disappeared." ></td>
	<td class="line x" title="131:158	Instead, additional correct similarities, like kingdom and land, were promoted (compare with Table 1)." ></td>
	<td class="line x" title="132:158	Some semantically related but non-substitutable words, like world and city, still remain in the list, but somewhat demoted." ></td>
	<td class="line x" title="133:158	In this case all errors correspond to quite close semantic relatedness, being geographic concepts." ></td>
	<td class="line x" title="134:158	The remaining errors are mostly of the first type discussed in Section 3 pairs of words that are ontologically or thematically related but are not substitutable." ></td>
	<td class="line x" title="135:158	Typical examples are co-hyponyms (country city) or agent-patient and agent-action pairs (industry product, worker job)." ></td>
	<td class="line x" title="136:158	Usually, such word pairs also have highly ranked common features since they naturally appear with similar characteristic features." ></td>
	<td class="line x" title="137:158	It may therefore be difficult to filter out such non-substitutable similarities solely by the standard distributional similarity scheme, suggesting that additional mechanisms are required." ></td>
	<td class="line x" title="138:158	6 Conclusions and Future Work This paper proposed the following contributions: 1." ></td>
	<td class="line x" title="139:158	Considering meaning entailing substitutability as a target goal and evaluation criterion for word similarity." ></td>
	<td class="line x" title="140:158	This criterion is useful for many semantic-oriented NLP applications, and can be evaluated directly by human subjects." ></td>
	<td class="line x" title="141:158	2." ></td>
	<td class="line x" title="142:158	A thorough empirical error analysis of state of the art performance was conducted." ></td>
	<td class="line x" title="143:158	The main observation was deficient quality of the feature vectors which reduces the quality of similarity measures." ></td>
	<td class="line x" title="144:158	3." ></td>
	<td class="line x" title="145:158	Inspired by the qualitative observations we identified a new qualitative condition for feature vector evaluation top joint feature rank." ></td>
	<td class="line x" title="146:158	Thus, feature vector quality can be measured independently of the final similarity output." ></td>
	<td class="line x" title="147:158	4." ></td>
	<td class="line x" title="148:158	Finally, we presented a novel feature weighting function, relative feature focus." ></td>
	<td class="line x" title="149:158	This measure was designed based on error analysis insights and imCountryState Ranks CountryEconomy Ranks Neighboring Industry Impoverished Governor Population City Economy Parliament Citizen Law 3 1 8 10 6 17 5 10 14 4 1 11 8 9 16 18 15 22 25 33 Developed Liberalization 50 100 100 79 Table 6: RFF weighting: Top-10 common features for country-state and countryeconomy along with their corresponding ranks in the two (sorted) feature vectors." ></td>
	<td class="line x" title="150:158	proves performance over all the above criteria." ></td>
	<td class="line x" title="151:158	We intend to further investigate the contribution of our measure to word sense disambiguation and to evaluate its performance for clustering methods." ></td>
	<td class="line x" title="152:158	Error analysis suggests that it might be difficult to improve similarity output further within the common distributional similarity schemes." ></td>
	<td class="line x" title="153:158	We need to seek additional criteria and data types, such as identifying evidence for non-similarity, or analyzing more carefully disjoint features." ></td>
	<td class="line x" title="154:158	Further research is suggested to extend the learning framework towards richer notions of ontology generation." ></td>
	<td class="line x" title="155:158	We would like to distinguish between different ontological relationships that correspond to the substitutability criterion, such as identifying the entailment direction, which was ignored till now." ></td>
	<td class="line x" title="156:158	Towards these goals we plan to investigate combining unsupervised distributional similarity with supervised methods for learning ontological relationships, and with paraphrase acquisition methods." ></td>
	<td class="line x" title="157:158	nation state island region area 1 2 3 4 5 territory *neighbor colony *port republic 6 7 8 9 10 african_country province *city *town kingdom 11 12 13 14 15 *district european_country zone land place 16 17 18 19 20 Table 7: Top-20 most similar words for country and their ranks in the similarity list by the RFF-based measure." ></td>
	<td class="line x" title="158:158	Incorrect similarities (non-substitutable) are marked with *." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C04-1111
Towards Terascale Semantic Acquisition
Pantel, Patrick;Ravichandran, Deepak;Hovy, Eduard H.;"></td>
	<td class="line x" title="1:301	Towards Terascale Knowledge Acquisition Patrick Pantel, Deepak Ravichandran and Eduard Hovy Information Sciences Institute University of Southern California 4676 Admiralty Way Marina del Rey, CA 90292 {pantel,ravichan,hovy}@isi.edu Abstract Although vast amounts of textual data are freely available, many NLP algorithms exploit only a minute percentage of it." ></td>
	<td class="line x" title="2:301	In this paper, we study the challenges of working at the terascale." ></td>
	<td class="line x" title="3:301	We present an algorithm, designed for the terascale, for mining is-a relations that achieves similar performance to a state-of-the-art linguistically-rich method." ></td>
	<td class="line x" title="4:301	We focus on the accuracy of these two systems as a function of processing time and corpus size." ></td>
	<td class="line x" title="5:301	1 Introduction The Natural Language Processing (NLP) community has recently seen a growth in corpus-based methods." ></td>
	<td class="line x" title="6:301	Algorithms light in linguistic theories but rich in available training data have been successfully applied to several applications such as machine translation (Och and Ney 2002), information extraction (Etzioni et al. 2004), and question answering (Brill et al. 2001)." ></td>
	<td class="line x" title="7:301	In the last decade, we have seen an explosion in the amount of available digital text resources." ></td>
	<td class="line x" title="8:301	It is estimated that the Internet contains hundreds of terabytes of text data, most of which is in an unstructured format." ></td>
	<td class="line x" title="9:301	Yet, many NLP algorithms tap into only megabytes or gigabytes of this information." ></td>
	<td class="line x" title="10:301	In this paper, we make a step towards acquiring semantic knowledge from terabytes of data." ></td>
	<td class="line x" title="11:301	We present an algorithm for extracting is-a relations, designed for the terascale, and compare it to a state of the art method that employs deep analysis of text (Pantel and Ravichandran 2004)." ></td>
	<td class="line x" title="12:301	We show that by simply utilizing more data on this task, we can achieve similar performance to a linguisticallyrich approach." ></td>
	<td class="line x" title="13:301	The current state of the art cooccurrence model requires an estimated 10 years just to parse a 1TB corpus (see Table 1)." ></td>
	<td class="line x" title="14:301	Instead of using a syntactically motivated co-occurrence approach as above, our system uses lexico-syntactic rules." ></td>
	<td class="line x" title="15:301	In particular, it finds lexico-POS patterns by making modifications to the basic edit distance algorithm." ></td>
	<td class="line x" title="16:301	Once these patterns have been learnt, the algorithm for finding new is-a relations runs in O(n), where n is the number of sentences." ></td>
	<td class="line x" title="17:301	In semantic hierarchies such as WordNet (Miller 1990), an is-a relation between two words x and y represents a subordinate relationship (i.e. x is more specific than y)." ></td>
	<td class="line x" title="18:301	Many algorithms have recently been proposed to automatically mine is-a (hyponym/hypernym) relations between words." ></td>
	<td class="line x" title="19:301	Here, we focus on is-a relations that are characterized by the questions What/Who is X? For example, Table 2 shows a sample of 10 is-a relations discovered by the algorithms presented in this paper." ></td>
	<td class="line x" title="20:301	In this table, we call azalea, tiramisu, and Winona Ryder instances of the respective concepts flower, dessert and actress." ></td>
	<td class="line x" title="21:301	These kinds of is-a relations would be useful for various purposes such as ontology construction, semantic information retrieval, question answering, etc. The main contribution of this paper is a comparison of the quality of our pattern-based and cooccurrence models as a function of processing time and corpus size." ></td>
	<td class="line x" title="22:301	Also, the paper lays a foundation for terascale acquisition of knowledge." ></td>
	<td class="line x" title="23:301	We will show that, for very small or very large corpora or for situations where recall is valued over precision, the pattern-based approach is best." ></td>
	<td class="line x" title="24:301	2 Relevant Work Previous approaches to extracting is-a relations fall under two categories: pattern-based and cooccurrence-based approaches." ></td>
	<td class="line x" title="25:301	2.1 Pattern-based approaches Marti Hearst (1992) was the first to use a pattern-based approach to extract hyponym relations from a raw corpus." ></td>
	<td class="line x" title="26:301	She used an iterative process to semi-automatically learn patterns." ></td>
	<td class="line x" title="27:301	However, a corpus of 20MB words yielded only 400 examples." ></td>
	<td class="line x" title="28:301	Our pattern-based algorithm is very similar to the one used by Hearst." ></td>
	<td class="line x" title="29:301	She uses seed examples to manually discover her patterns whearas we use a minimal edit distance algorithm to automatically discover the patterns." ></td>
	<td class="line x" title="30:301	771 Riloff and Shepherd (1997) used a semiautomatic method for discovering similar words using a few seed examples by using pattern-based techniques and human supervision." ></td>
	<td class="line x" title="31:301	Berland and Charniak (1999) used similar pattern-based techniques and other heuristics to extract meronymy (part-whole) relations." ></td>
	<td class="line x" title="32:301	They reported an accuracy of about 55% precision on a corpus of 100,000 words." ></td>
	<td class="line x" title="33:301	Girju et al.(2003) improved upon Berland and Charniak's work using a machine learning filter." ></td>
	<td class="line x" title="35:301	Mann (2002) and Fleischman et al.(2003) used part of speech patterns to extract a subset of hyponym relations involving proper nouns." ></td>
	<td class="line x" title="37:301	Our pattern-based algorithm differs from these approaches in two ways." ></td>
	<td class="line x" title="38:301	We learn lexico-POS patterns in an automatic way." ></td>
	<td class="line x" title="39:301	Also, the patterns are learned with the specific goal of scaling to the terascale (see Table 2)." ></td>
	<td class="line oc" title="40:301	2.2 Co-occurrence-based approaches The second class of algorithms uses cooccurrence statistics (Hindle 1990, Lin 1998)." ></td>
	<td class="line o" title="41:301	These systems mostly employ clustering algorithms to group words according to their meanings in text." ></td>
	<td class="line x" title="42:301	Assuming the distributional hypothesis (Harris 1985), words that occur in similar grammatical contexts are similar in meaning." ></td>
	<td class="line x" title="43:301	Curran and Moens (2002) experimented with corpus size and complexity of proximity features in building automatic thesauri." ></td>
	<td class="line x" title="44:301	CBC (Clustering by Committee) proposed by Pantel and Lin (2002) achieves high recall and precision in generating similarity lists of words discriminated by their meaning and senses." ></td>
	<td class="line n" title="45:301	However, such clustering algorithms fail to name their classes." ></td>
	<td class="line x" title="46:301	Caraballo (1999) was the first to use clustering for labeling is-a relations using conjunction and apposition features to build noun clusters." ></td>
	<td class="line x" title="47:301	Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun." ></td>
	<td class="line x" title="48:301	3 Syntactical co-occurrence approach Much of the research discussed above takes a similar approach of searching text for simple surface or lexico-syntactic patterns in a bottom-up approach." ></td>
	<td class="line x" title="49:301	Our co-occurrence model (Pantel and Ravichandran 2004) makes use of semantic classes like those generated by CBC." ></td>
	<td class="line x" title="50:301	Hyponyms are generated in a top-down approach by naming each group of words and assigning that name as a hyponym of each word in the group (i.e. , one hyponym per instance/group label pair)." ></td>
	<td class="line x" title="51:301	The input to the extraction algorithm is a list of semantic classes, in the form of clusters of words, which may be generated from any source." ></td>
	<td class="line x" title="52:301	For example, following are two semantic classes discovered by CBC: (A) peach, pear, pineapple, apricot, mango, raspberry, lemon, cherry, strawberry, melon, blueberry, fig, apple, plum, nectarine, avocado, grapefruit, papaya, banana, cantaloupe, cranberry, blackberry, lime, orange, tangerine, (B) Phil Donahue, Pat Sajak, Arsenio Hall, Geraldo Rivera, Don Imus, Larry King, David Letterman, Conan O'Brien, Rosie O'Donnell, Jenny Jones, Sally Jessy Raphael, Oprah Winfrey, Jerry Springer, Howard Stern, Jay Leno, Johnny Carson,  The extraction algorithm first labels concepts (A) and (B) with fruit and host respectively." ></td>
	<td class="line x" title="53:301	Then, is-a relationships are extracted, such as: apple is a fruit, pear is a fruit, and David Letterman is a host." ></td>
	<td class="line x" title="54:301	An instance such as pear is assigned a hypernym fruit not because it necessarily occurs in any particular syntactic relationship with the word fruit, but because it belongs to the class of instances that does." ></td>
	<td class="line x" title="55:301	The labeling of semantic classes is performed in three phases, as outlined below." ></td>
	<td class="line x" title="56:301	3.1 Phase I In the first phase of the algorithm, feature vectors are extracted for each word that occurs in a semantic class." ></td>
	<td class="line x" title="57:301	Each feature corresponds to a grammatical context in which the word occurs." ></td>
	<td class="line x" title="58:301	For example, catch __ is a verb-object context." ></td>
	<td class="line x" title="59:301	If the word wave occurred in this context, then the context is a feature of wave." ></td>
	<td class="line x" title="60:301	We then construct a mutual information vector MI(e) = (mi e1, mi e2, , mi em ) for each word e, where mi ef is the pointwise mutual information between word e and context f, which is defined as: N c N c N c ef m j ej n i if ef mi   = =  = 1 1 log Table 2." ></td>
	<td class="line x" title="61:301	Sample of 10 is-a relationships discovered by our co-occurrence and pattern-based systems." ></td>
	<td class="line x" title="62:301	CO-OCCURRENCE SYSTEM PATTERN-BASED SYSTEM Word Hypernym Word Hypernym azalea flower American airline bipolar disorder disease Bobby Bonds coach Bordeaux wine radiation therapy cancer treatment Flintstones television show tiramisu dessert salmon fish Winona Ryder actress Table 1." ></td>
	<td class="line x" title="63:301	Approximate processing time on a single Pentium-4 2.5 GHz machine." ></td>
	<td class="line x" title="64:301	TOOL 15 GB ORPUS 1 TB CORPUS POS Tagger 2 days 125 days NP Chunker 3 days 214 days Dependency Parser 56 days 10.2 years Syntactic Parser 5.8 years 388.4 years 772 where n is the number of elements to be clustered, c ef is the frequency count of word e in grammatical context f, and N is the total frequency count of all features of all words." ></td>
	<td class="line x" title="65:301	3.2 Phase II Following (Pantel and Lin 2002), a committee for each semantic class is constructed." ></td>
	<td class="line x" title="66:301	A committee is a set of representative elements that unambiguously describe the members of a possible class." ></td>
	<td class="line x" title="67:301	For example, in one of our experiments, the committees for semantic classes (A) and (B) from Section 3 were: A) peach, pear, pineapple, apricot, mango, raspberry, lemon, blueberry B) Phil Donahue, Pat Sajak, Arsenio Hall, Geraldo Rivera, Don Imus, Larry King, David Letterman 3.3 Phase III By averaging the feature vectors of the committee members of a particular semantic class, we obtain a grammatical template, or signature, for that class." ></td>
	<td class="line x" title="68:301	For example, Figure 1 shows an excerpt of the grammatical signature for semantic class (B)." ></td>
	<td class="line x" title="69:301	The vector is obtained by averaging the feature vectors of the words in the committee of this class." ></td>
	<td class="line x" title="70:301	The V:subj:N:joke feature indicates a subject-verb relationship between the class and the verb joke while N:appo:N:host indicates an apposition relationship between the class and the noun host." ></td>
	<td class="line x" title="71:301	The two columns of numbers indicate the frequency and mutual information scores." ></td>
	<td class="line x" title="72:301	To name a class, we search its signature for certain relationships known to identify class labels." ></td>
	<td class="line x" title="73:301	These relationships, automatically learned in (Pantel and Ravichandran 2004), include appositions, nominal subjects, such as relationships, and like relationships." ></td>
	<td class="line x" title="74:301	We sum up the mutual information scores for each term that occurs in these relationships with a committee of a class." ></td>
	<td class="line x" title="75:301	The highest scoring term is the name of the class." ></td>
	<td class="line x" title="76:301	The syntactical co-occurrence approach has worst-case time complexity O(n 2 k), where n is the number of words in the corpus and k is the featurespace (Pantel and Ravichandran 2004)." ></td>
	<td class="line x" title="77:301	Just to parse a 1 TB corpus, this approach requires approximately 10.2 years (see Table 2)." ></td>
	<td class="line x" title="78:301	4 Scalable pattern-based approach We propose an algorithm for learning highly scalable lexico-POS patterns." ></td>
	<td class="line x" title="79:301	Given two sentences with their surface form and part of speech tags, the algorithm finds the optimal lexico-POS alignment." ></td>
	<td class="line x" title="80:301	For example, consider the following 2 sentences: 1) Platinum is a precious metal." ></td>
	<td class="line x" title="81:301	2) Molybdenum is a metal." ></td>
	<td class="line x" title="82:301	Applying a POS tagger (Brill 1995) gives the following output: Surface Platinum is a precious metal . POS NNP VBZ DT JJ NN . Surface Molybdenum is a metal . POS NNP VBZ DT NN . A very good pattern to generalize from the alignment of these two strings would be Surface is a metal . POS NNP . We use the following notation to denote this alignment: _NNP is a (*s*) metal., where _NNP represents the POS tag NNP." ></td>
	<td class="line x" title="83:301	To perform such alignments we introduce two wildcard operators, skip (*s*) and wildcard (*g*)." ></td>
	<td class="line x" title="84:301	The skip operator represents 0 or 1 instance of any word (similar to the \w* pattern in Perl), while the wildcard operator represents exactly 1 instance of any word (similar to the \w+ pattern in Perl)." ></td>
	<td class="line x" title="85:301	4.1 Algorithm We present an algorithm for learning patterns at multiple levels." ></td>
	<td class="line x" title="86:301	Multilevel representation is defined as the different levels of a sentence such as the lexical level and POS level." ></td>
	<td class="line x" title="87:301	Consider two strings a(1, n) and b(1, m) of lengths n and m respectively." ></td>
	<td class="line x" title="88:301	Let a 1 (1, n) and a 2 (1, n) be the level 1 (lexical level) and level 2 (POS level) representations for the string a(1, n)." ></td>
	<td class="line x" title="89:301	Similarly, let b 1 (1, m) and b 2 (1, m) be the level 1 and level 2 representations for the string b(1, m)." ></td>
	<td class="line x" title="90:301	The algorithm consists of two parts: calculation of the minimal edit distance and retrieval of an optimal pattern." ></td>
	<td class="line x" title="91:301	The minimal edit distance algorithm calculates the number of edit operations (insertions, deletions and replacements) required to change one string to another string." ></td>
	<td class="line x" title="92:301	The optimal pattern is retrieved by {Phil Donahue,Pat Sajak,Arsenio Hall} N:gen:N talk show 93 11.77 television show 24 11.30 TV show 25 10.45 show 255 9.98 audience 23 7.80 joke 5 7.37 V:subj:N joke 39 7.11 tape 10 7.09 poke 15 6.87 host 40 6.47 co-host 4 6.14 banter 3 6.00 interview 20 5.89 N:appo:N host 127 12.46 comedian 12 11.02 King 13 9.49 star 6 7.47 Figure 1." ></td>
	<td class="line x" title="93:301	Excerpt of the grammatical signature for the television host class." ></td>
	<td class="line x" title="94:301	773 keeping track of the edit operations (which is the second part of the algorithm)." ></td>
	<td class="line x" title="95:301	Algorithm for calculating the minimal edit distance between two strings D[0,0]=0 for i = 1 to n do D[i,0] = D[i-1,0] + cost(insertion) for j = 1 to m do D[0,j] = D[0,j-1] + cost(deletion) for i = 1 to n do for j = 1 to m do D[i,j] = min( D[i-1,j-1] + cost(substitution), D[i-1,j] + cost(insertion), D[i,j-1] + cost(deletion) Print (D[n,m]) Algorithm for optimal pattern retrieval i = n, j = m; while i  0 and j  0 if D[i,j] = D[i-1,j] + cost(insertion) print (*s*), i = i-1 else if D[i,j] = D[i,j-1] + cost(deletion) print(*s*), j = j-1 else if a 1i = b 1j print (a 1i ), i = i -1, j = j =1 else if a 2i = b 2j print (a 2i ), i = i -1, j = j =1 else print (*g*), i = i -1, j = j =1 We experimentally set (by trial and error): cost(insertion) = 3 cost(deletion) = 3 cost(substitution) = 0 if a 1i =b 1j = 1 if a 1i b 1j, a 2i =b 2j = 2 if a 1i b 1j, a 2i b 2j 4.2 Implementation and filtering The above algorithm takes O(y 2 ) time for every pair of strings of length at most y. Hence, if there are x strings in the collection, each string having at most length y, the algorithm has time complexity O(x 2 y 2 ) to extract all the patterns in the collection." ></td>
	<td class="line x" title="96:301	Applying the above algorithm on a corpus of 3GB with 50 is-a relationship seeds, we obtain a set of 600 lexico-POS." ></td>
	<td class="line x" title="97:301	Following are two of them: 1) X_JJ#NN|JJ#NN#NN|NN _CC Y_JJ#JJ#NN|JJ |NNS|NN|JJ#NNS|NN#NN|JJ#NN|JJ#NN#NN e.g. caldera or lava lake 2) X_NNP#NNP|NNP#NNP#NNP#NNP#NNP#CC#NNP |NNP|VBN|NN#NN|VBG#NN|NN,_, _DT Y_NN#IN#NN|JJ#JJ#NN|JJ|NN|NN#IN#NNP |NNP#NNP|NN#NN|JJ#NN|JJ#NN#NN e.g. leukemia, the cancer of  Note that we store different POS variations of the anchors X and Y. As shown in example 1, the POS variations of the anchor X are (JJ NN, JJ NN NN, NN)." ></td>
	<td class="line x" title="98:301	The variations for anchor Y are (JJ JJ NN, JJ, etc.)." ></td>
	<td class="line x" title="99:301	The reason is quite straightforward: we need to determine the boundary of the anchors X and Y and a reasonable way to delimit them would be to use POS information." ></td>
	<td class="line x" title="100:301	All the patterns produced by the multi-level pattern learning algorithm were generated from positive examples." ></td>
	<td class="line x" title="101:301	From amongst these patterns, we need to find the most important ones." ></td>
	<td class="line x" title="102:301	This is a critical step because frequently occurring patterns have low precision whereas rarely occurring patterns have high precision." ></td>
	<td class="line x" title="103:301	From the Information Extraction point of view neither of these patterns is very useful." ></td>
	<td class="line x" title="104:301	We need to find patterns with relatively high occurrence and high precision." ></td>
	<td class="line x" title="105:301	We apply the log likelihood principle (Dunning 1993) to compute this score." ></td>
	<td class="line x" title="106:301	The top 15 patterns according to this metric are listed in Table 3 (we omit the POS variations for visibility)." ></td>
	<td class="line x" title="107:301	Some of these patterns are similar to the ones discovered by Hearst (1992) while other patterns are similar to the ones used by Fleischman et al.(2003)." ></td>
	<td class="line x" title="109:301	4.3 Time complexity To extract hyponym relations, we use a fixed number of patterns across a corpus." ></td>
	<td class="line x" title="110:301	Since we treat each sentences independently from others, the algorithm runs in linear time O(n) over the corpus size, where n is number of sentences in the corpus." ></td>
	<td class="line x" title="111:301	5 Experimental Results In this section, we empirically compare the pattern-based and co-occurrence-based models presented in Section 3 and Section 4." ></td>
	<td class="line x" title="112:301	The focus is on the precision and recall of the systems as a function of the corpus size." ></td>
	<td class="line x" title="113:301	5.1 Experimental Setup We use a 15GB newspaper corpus consisting of TREC9, TREC 2002, Yahoo!" ></td>
	<td class="line x" title="114:301	News ~0.5GB, AP newswire ~2GB, New York Times ~2GB, Reuters ~0.8GB, Wall Street Journal ~1.2GB, and various online news website ~1.5GB." ></td>
	<td class="line x" title="115:301	For our experiments, we extract from this corpus six data sets of different sizes: 1.5MB, 15 MB, 150 MB, 1.5GB, 6GB and 15GB." ></td>
	<td class="line x" title="116:301	For the co-occurrence model, we used Minipar (Lin 1994), a broad coverage parser, to parse each data set." ></td>
	<td class="line x" title="117:301	We collected the frequency counts of the grammatical relationships (contexts) output by Minipar and used them to compute the pointwise mutual information vectors described in Section 3.1." ></td>
	<td class="line x" title="118:301	For the pattern-based approach, we use Brills POS tagger (1995) to tag each data set." ></td>
	<td class="line x" title="119:301	5.2 Precision We performed a manual evaluation to estimate the precision of both systems on each dataset." ></td>
	<td class="line x" title="120:301	For each dataset, both systems extracted a set of is-a Table 3." ></td>
	<td class="line x" title="121:301	Top 15 lexico-syntactic patterns discovered by our system." ></td>
	<td class="line x" title="122:301	X, or Y X, _DT Y _(WDT|IN) Y like X and X, (a|an) Y X, _RB known as Y _NN, X and other Y X, Y X ( Y ) Y, including X, Y, or X Y such as X Y, such as X X is a Y X, _RB called Y Y, especially X 774 relationships." ></td>
	<td class="line x" title="123:301	Six sets were extracted for the pattern-based approach and five sets for the cooccurrence approach (the 15GB corpus was too large to process using the co-occurrence model  see dependency parsing time estimates in Table 2)." ></td>
	<td class="line x" title="124:301	From each resulting set, we then randomly selected 50 words along with their top 3 highest ranking is-a relationships." ></td>
	<td class="line x" title="125:301	For example, Table 4 shows three randomly selected names for the pattern-based system on the 15GB dataset." ></td>
	<td class="line x" title="126:301	For each word, we added to the list of hypernyms a human generated hypernym (obtained from an annotator looking at the word without any system or WordNet hyponym)." ></td>
	<td class="line x" title="127:301	We also appended the WordNet hypernyms for each word (only for the top 3 senses)." ></td>
	<td class="line x" title="128:301	Each of the 11 random samples contained a maximum of 350 is-a relationships to manually evaluate (50 random words with top 3 system, top 3 WordNet, and human generated relationship)." ></td>
	<td class="line x" title="129:301	We presented each of the 11 random samples to two human judges." ></td>
	<td class="line x" title="130:301	The 50 randomly selected words, together with the system, human, and WordNet generated is-a relationships, were randomly ordered." ></td>
	<td class="line x" title="131:301	That way, there was no way for a judge to know the source of a relationship nor each systems ranking of the relationships." ></td>
	<td class="line x" title="132:301	For each relationship, we asked the judges to assign a score of correct, partially correct, or incorrect." ></td>
	<td class="line x" title="133:301	We then computed the average precision of the system, human, and WordNet on each dataset." ></td>
	<td class="line x" title="134:301	We also computed the percentage of times a correct relationship was found in the top 3 is-a relationships of a word and the mean reciprocal rank (MRR)." ></td>
	<td class="line x" title="135:301	For each word, a system receives an MRR score of 1 / M, where M is the rank of the first name judged correct." ></td>
	<td class="line x" title="136:301	Table 5 shows the results comparing the two automatic systems." ></td>
	<td class="line x" title="137:301	Table 6 shows similar results for a more lenient evaluation where both correct and partially correct are judged correct." ></td>
	<td class="line x" title="138:301	For small datasets (below 150MB), the patternbased method achieves higher precision since the co-occurrence method requires a certain critical mass of statistics before it can extract useful class signatures (see Section 3)." ></td>
	<td class="line x" title="139:301	On the other hand, the pattern-based approach has relatively constant precision since most of the is-a relationships selected by it are fired by a single pattern." ></td>
	<td class="line x" title="140:301	Once the co-occurrence system reaches its critical mass (at 150MB), it generates much more precise hyponyms." ></td>
	<td class="line x" title="141:301	The Kappa statistics for our experiments were all in the range 0.78  0.85." ></td>
	<td class="line x" title="142:301	Table 7 and Table 8 compare the precision of the pattern-based and co-occurrence-based methods with the human and WordNet hyponyms." ></td>
	<td class="line x" title="143:301	The variation between the human and WordNet scores across both systems is mostly due to the relative cleanliness of the tokens in the co-occurrencebased system (due to the parser used in the approach)." ></td>
	<td class="line x" title="144:301	WordNet consistently generated higher precision relationships although both algorithms approach WordNet quality on 6GB (the patternbased algorithm even surpasses WordNet precision on 15GB)." ></td>
	<td class="line x" title="145:301	Furthermore, WordNet only generated a hyponym 40% of the time." ></td>
	<td class="line x" title="146:301	This is mostly due to the lack of proper noun coverage in WordNet." ></td>
	<td class="line x" title="147:301	On the 6 GB corpus, the co-occurrence approach took approximately 47 single Pentium-4 2.5 GHz processor days to complete, whereas it took the pattern-based approach only four days to complete on 6 GB and 10 days on 15 GB." ></td>
	<td class="line x" title="148:301	5.3 Recall The co-occurrence model has higher precision than the pattern-based algorithm on most datasets." ></td>
	<td class="line x" title="149:301	Table 4." ></td>
	<td class="line x" title="150:301	Is-a relationships assigned to three randomly selected words (using pattern-based system on 15GB dataset)." ></td>
	<td class="line x" title="151:301	RANDOM WORD HUMAN WORDNET PATTERN-BASED SYSTEM (RANKED) Sanwa Bank bank none subsidiary / lender / bank MCI Worldcom Inc. telecommunications company none phone company / competitor / company cappuccino beverage none item / food / beverage Table 5." ></td>
	<td class="line x" title="152:301	Average precision, top-3 precision, and MRR for both systems on each dataset." ></td>
	<td class="line x" title="153:301	PATTERN SYSTEM CO-OCCURRENCE SYSTEM Prec Top-3 MRR Prec Top-3 MRR 1.5MB 38.7% 41.0% 41.0% 4.3% 8.0% 7.3% 15MB 39.1% 43.0% 41.5% 14.6% 32.0% 24.3% 150MB 40.6% 46.0% 45.5% 51.1% 73.0% 67.0% 1.5GB 40.4% 39.0% 39.0% 56.7% 88.0% 77.7% 6GB 46.3% 52.0% 49.7% 64.9% 90.0% 78.8% 15GB 55.9% 54.0% 52.0% Too large to process Table 6." ></td>
	<td class="line x" title="154:301	Lenient average precision, top-3 precision, and MRR for both systems on each dataset." ></td>
	<td class="line x" title="155:301	PATTERN SYSTEM CO-OCCURRENCE SYSTEM Prec Top-3 MRR Prec Top-3 MRR 1.5MB 56.6% 60.0% 60.0% 12.4% 20.0% 15.2% 15MB 57.3% 63.0% 61.0% 23.2% 50.0% 37.3% 150MB 50.7% 56.0% 55.0% 60.6% 78.0% 73.2% 1.5GB 52.6% 51.0% 51.0% 69.7% 93.0% 85.8% 6GB 61.8% 69.0% 67.5% 78.7% 92.0% 86.2% 15GB 67.8% 67.0% 65.0% Too large to process 775 However, Figure 2 shows that the pattern-based approach extracts many more relationships." ></td>
	<td class="line x" title="156:301	Semantic extraction tasks are notoriously difficult to evaluate for recall." ></td>
	<td class="line x" title="157:301	To approximate recall, we defined a relative recall measure and conducted a question answering (QA) task of answering definition questions." ></td>
	<td class="line x" title="158:301	5.3.1 Relative recall Although it is impossible to know the number of is-a relationships in any non-trivial corpus, it is possible to compute the recall of a system relative to another systems recall." ></td>
	<td class="line x" title="159:301	The recall of a system A, R A, is given by the following formula: C C R A A = where C A is the number of correct is-a relationships extracted by A and C is the total number of correct is-a relationships in the corpus." ></td>
	<td class="line x" title="160:301	We define relative recall of system A given system B, R A,B, as: B A B A BA C C R R R ==, Using the precision estimates, P A, from the previous section, we can estimate C A  P A  |A|, where A is the total number of is-a relationships discovered by system A. Hence, BP AP R B A BA   =, Figure 3 shows the relative recall of A = patternbased approach relative to B = co-occurrence model." ></td>
	<td class="line x" title="161:301	Because of sparse data, the pattern-based approach has much higher precision and recall (six times) than the co-occurrence approach on the small 15MB dataset." ></td>
	<td class="line x" title="162:301	In fact, only on the 150MB dataset did the co-occurrence system have higher recall." ></td>
	<td class="line x" title="163:301	With datasets larger than 150MB, the cooccurrence algorithm reduces its running time by filtering out grammatical relationships for words that occurred fewer than k = 40 times and hence recall is affected (in contrast, the pattern-based approach may generate a hyponym for a word that it only sees once)." ></td>
	<td class="line x" title="164:301	5.3.2 Definition questions Following Fleischman et al.(2003), we select the 50 definition questions from the TREC2003 (Voorhees 2003) question set." ></td>
	<td class="line x" title="166:301	These questions are of the form Who is X? and What is X? For each question (e.g. , Who is Niels Bohr?, What is feng shui?) we extract its respective instance (e.g. , Neils Bohr and feng shui), look up their corresponding hyponyms from our is-a table, and present the corresponding hyponym as the answer." ></td>
	<td class="line x" title="167:301	We compare the results of both our systems with WordNet." ></td>
	<td class="line x" title="168:301	We extract at most the top 5 hyponyms provided by each system." ></td>
	<td class="line x" title="169:301	We manually evaluate the three systems and assign 3 classes Correct (C), Partially Correct (P) or Incorrect (I) to each answer." ></td>
	<td class="line x" title="170:301	This evaluation is different from the evaluation performed by the TREC organizers for definition questions." ></td>
	<td class="line x" title="171:301	However, by being consistent across all Total Number of Is-A Relationships vs. Dataset 0 200000 400000 600000 800000 1000000 1200000 1400000 1.5MB 15MB 150MB 1.5GB 6GB 15GB Datasets T o t a l Is A R e la t io n s h ip s s Pattern-based System Co-occurrence-based System Figure 2." ></td>
	<td class="line x" title="172:301	Number of is-a relationships extracted by the pattern-based and co-occurrence-based approaches." ></td>
	<td class="line x" title="173:301	Table 7." ></td>
	<td class="line x" title="174:301	Average precision of the pattern-based system vs. WordNet and human hyponyms." ></td>
	<td class="line x" title="175:301	PRECISION MRR Pat." ></td>
	<td class="line x" title="176:301	WNet Human Pat." ></td>
	<td class="line x" title="177:301	WNet Human 1.5MB 38.7% 45.8% 83.0% 41.0% 84.4% 83.0% 15MB 39.1% 52.4% 81.0% 41.5% 95.0% 91.0% 150MB 40.6% 49.4% 84.0% 45.5% 88.9% 94.0% 1.5GB 40.4% 43.4% 79.0% 39.0% 93.3% 89.0% 6GB 46.3% 46.5% 76.0% 49.7% 75.0% 76.0% 15GB 55.9% 45.6% 79.0% 52.0% 78.0% 79.0% Table 8." ></td>
	<td class="line x" title="178:301	Average precision of the co-occurrencebased system vs. WordNet and human hyponyms." ></td>
	<td class="line x" title="179:301	PRECISION MRR Co-occ WNet Human Co-occ WNet Human 1.5MB 4.3% 42.7% 52.7% 7.3% 87.7% 95.0% 15MB 14.6% 38.1% 48.7% 24.3% 86.6% 95.0% 150MB 51.1% 57.5% 65.8% 67.0% 85.1% 98.0% 1.5GB 56.7% 62.8% 70.3% 77.7% 93.0% 98.0% 6GB 64.9% 68.9% 75.2% 78.8% 94.3% 98.0% Relative Recall (Pattern-based vs. Co-occurrence-based) 0.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 1.5MB 15MB 150MB 1.5GB 6GB 15GB (projected) Datesets R e la t i v e R e c a l l Figure 3." ></td>
	<td class="line x" title="180:301	Relative recall of the pattern-based approach relative to the co-occurrence approach." ></td>
	<td class="line x" title="181:301	776 systems during the process, these evaluations give an indication of the recall of the knowledge base." ></td>
	<td class="line x" title="182:301	We measure the performance on the top 1 and the top 5 answers returned by each system." ></td>
	<td class="line x" title="183:301	Table 9 and Table 10 show the results." ></td>
	<td class="line x" title="184:301	The corresponding scores for WordNet are 38% accuracy in both the top-1 and top-5 categories (for both strict and lenient)." ></td>
	<td class="line x" title="185:301	As seen in this experiment, the results for both the pattern-based and cooccurrence-based systems report very poor performance for data sets up to 150 MB." ></td>
	<td class="line x" title="186:301	However, there is an increase in performance for both systems on the 1.5 GB and larger datasets." ></td>
	<td class="line x" title="187:301	The performance of the system in the top 5 category is much better than that of WordNet (38%)." ></td>
	<td class="line x" title="188:301	There is promise for increasing our system accuracy by reranking the outputs of the top-5 hypernyms." ></td>
	<td class="line x" title="189:301	6 Conclusions There is a long standing need for higher quality performance in NLP systems." ></td>
	<td class="line x" title="190:301	It is possible that semantic resources richer than WordNet will enable them to break the current quality ceilings." ></td>
	<td class="line x" title="191:301	Both statistical and symbolic NLP systems can make use of such semantic knowledge." ></td>
	<td class="line x" title="192:301	With the increased size of the Web, more and more training data is becoming available, and as Banko and Brill (2001) showed, even rather simple learning algorithms can perform well when given enough data." ></td>
	<td class="line x" title="193:301	In this light, we see an interesting need to develop fast, robust, and scalable methods to mine semantic information from the Web." ></td>
	<td class="line x" title="194:301	This paper compares and contrasts two methods for extracting is-a relations from corpora." ></td>
	<td class="line x" title="195:301	We presented a novel pattern-based algorithm, scalable to the terascale, which outperforms its more informed syntactical co-occurrence counterpart on very small and very large data." ></td>
	<td class="line x" title="196:301	Albeit possible to successfully apply linguistically-light but data-rich approaches to some NLP applications, merely reporting these results often fails to yield insights into the underlying theories of language at play." ></td>
	<td class="line x" title="197:301	Our biggest challenge as we venture to the terascale is to use our new found wealth not only to build better systems, but to improve our understanding of language." ></td>
	<td class="line x" title="198:301	Table 9." ></td>
	<td class="line x" title="199:301	QA definitional evaluations for pattern-based system." ></td>
	<td class="line x" title="200:301	TOP-1 TOP5 Strict Lenient Strict Lenient 1.5MB 0% 0% 0% 0% 15MB 0% 0% 0% 0% 150MB 2.0% 2.0% 2.0% 2.0% 1.5GB 16.0% 22.0% 20.0% 22.0% 6GB 38.0% 52.0% 56.0% 62.0% 15GB 38.0% 52.0% 70.0% 74.0% Table 10." ></td>
	<td class="line x" title="201:301	QA definitional evaluations for cooccurrence-based system." ></td>
	<td class="line x" title="202:301	TOP-1 TOP5 Strict Lenient Strict Lenient 1.5MB 0% 0% 0% 0% 15MB 0% 0% 0% 0% 150MB 0% 0% 0% 0% 1.5GB 6.0% 8.0% 6.0% 8.0% 6GB 36.0% 44.0% 60.0% 62.0% 777 References Banko, M. and Brill, E. 2001." ></td>
	<td class="line x" title="203:301	Mitigating the paucity of data problem." ></td>
	<td class="line x" title="204:301	In Proceedings of HLT-2001." ></td>
	<td class="line x" title="205:301	San Diego, CA." ></td>
	<td class="line x" title="206:301	Berland, M. and E. Charniak, 1999." ></td>
	<td class="line x" title="207:301	Finding parts in very large corpora." ></td>
	<td class="line x" title="208:301	In ACL-1999." ></td>
	<td class="line x" title="209:301	pp." ></td>
	<td class="line x" title="210:301	5764." ></td>
	<td class="line x" title="211:301	College Park, MD. Brill, E. , 1995." ></td>
	<td class="line x" title="212:301	Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging." ></td>
	<td class="line x" title="213:301	Computational Linguistics, 21(4):543566." ></td>
	<td class="line x" title="214:301	Brill, E. Lin, J. Banko, M. Dumais, S. and Ng, A. 2001." ></td>
	<td class="line x" title="215:301	Dataintensive question answering." ></td>
	<td class="line x" title="216:301	In Proceedings of the TREC-10 Conference, pp 183189." ></td>
	<td class="line x" title="217:301	Gaithersburg, MD. Caraballo, S. 1999." ></td>
	<td class="line x" title="218:301	Automatic acquisition of a hypernym-labeled noun hierarchy from text." ></td>
	<td class="line x" title="219:301	In Proceedings of ACL-99." ></td>
	<td class="line x" title="220:301	pp 120126, Baltimore, MD. Curran, J. and Moens, M. 2002." ></td>
	<td class="line x" title="221:301	Scaling context space." ></td>
	<td class="line x" title="222:301	In Proceedings of ACL-02." ></td>
	<td class="line x" title="223:301	pp 231238, Philadelphia, PA. Dunning, T. 1993." ></td>
	<td class="line x" title="224:301	Accurate methods for the statistics of surprise and coincidence." ></td>
	<td class="line x" title="225:301	Computational Linguistics 191 (1993), 6174." ></td>
	<td class="line x" title="226:301	Etzioni, O. Cafarella, M. Downey, D. Kok, S. Popescu, A.M. Shaked, T. Soderland, S. Weld, D. S. and Yates, A. 2004." ></td>
	<td class="line x" title="227:301	Webscale information extraction in Know-It All (Preliminary Results)." ></td>
	<td class="line x" title="228:301	To appear in the Conference on WWW." ></td>
	<td class="line x" title="229:301	Fleischman, M. Hovy, E. and Echihabi, A. 2003." ></td>
	<td class="line x" title="230:301	Offline strategies for online question answering: Answering questions before they are asked." ></td>
	<td class="line x" title="231:301	In Proceedings of ACL-03." ></td>
	<td class="line x" title="232:301	pp." ></td>
	<td class="line x" title="233:301	17." ></td>
	<td class="line x" title="234:301	Sapporo, Japan." ></td>
	<td class="line x" title="235:301	Girju, R. Badulescu, A. and Moldovan, D. 2003." ></td>
	<td class="line x" title="236:301	Learning semantic constraints for the automatic discovery of part-whole relations." ></td>
	<td class="line x" title="237:301	In Proceedings of HLT/NAACL-03." ></td>
	<td class="line x" title="238:301	pp." ></td>
	<td class="line x" title="239:301	8087." ></td>
	<td class="line x" title="240:301	Edmonton, Canada." ></td>
	<td class="line x" title="241:301	Harris, Z. 1985." ></td>
	<td class="line x" title="242:301	Distributional structure." ></td>
	<td class="line x" title="243:301	In: Katz, J. J." ></td>
	<td class="line x" title="244:301	(ed)." ></td>
	<td class="line x" title="245:301	The Philosophy of Linguistics." ></td>
	<td class="line x" title="246:301	New York: Oxford University Press." ></td>
	<td class="line x" title="247:301	pp." ></td>
	<td class="line x" title="248:301	2647." ></td>
	<td class="line x" title="249:301	Hearst, M. 1992." ></td>
	<td class="line x" title="250:301	Automatic acquisition of hyponyms from large text corpora." ></td>
	<td class="line x" title="251:301	In COLING-92." ></td>
	<td class="line x" title="252:301	pp." ></td>
	<td class="line x" title="253:301	539545." ></td>
	<td class="line x" title="254:301	Nantes, France." ></td>
	<td class="line oc" title="255:301	Hindle, D. 1990." ></td>
	<td class="line o" title="256:301	Noun classification from predicate-argument structures." ></td>
	<td class="line x" title="257:301	In Proceedings of ACL-90." ></td>
	<td class="line x" title="258:301	pp." ></td>
	<td class="line x" title="259:301	268275." ></td>
	<td class="line x" title="260:301	Pittsburgh, PA. Lin, D. 1994." ></td>
	<td class="line x" title="261:301	Principar an efficient, broad-coverage, principle-based parser." ></td>
	<td class="line x" title="262:301	Proceedings of COLING-94." ></td>
	<td class="line x" title="263:301	pp." ></td>
	<td class="line x" title="264:301	4248." ></td>
	<td class="line x" title="265:301	Kyoto, Japan." ></td>
	<td class="line x" title="266:301	Lin, D. 1998." ></td>
	<td class="line x" title="267:301	Automatic retrieval and clustering of similar words." ></td>
	<td class="line x" title="268:301	In Proceedings of COLING/ACL-98." ></td>
	<td class="line x" title="269:301	pp." ></td>
	<td class="line x" title="270:301	768774." ></td>
	<td class="line x" title="271:301	Montreal, Canada." ></td>
	<td class="line x" title="272:301	Mann, G. S. 2002." ></td>
	<td class="line x" title="273:301	Fine-Grained Proper Noun Ontologies for Question Answering." ></td>
	<td class="line x" title="274:301	SemaNet 02: Building and Using Semantic Networks, Taipei, Taiwan." ></td>
	<td class="line x" title="275:301	Miller, G. 1990." ></td>
	<td class="line x" title="276:301	WordNet: An online lexical database." ></td>
	<td class="line x" title="277:301	International Journal of Lexicography, 3(4)." ></td>
	<td class="line x" title="278:301	Och, F.J. and Ney, H. 2002." ></td>
	<td class="line x" title="279:301	Discriminative training and maximum entropy models for statistical machine translation." ></td>
	<td class="line x" title="280:301	In Proceedings of ACL." ></td>
	<td class="line x" title="281:301	pp." ></td>
	<td class="line x" title="282:301	295302." ></td>
	<td class="line x" title="283:301	Philadelphia, PA. Pantel, P. and Lin, D. 2002." ></td>
	<td class="line x" title="284:301	Discovering Word Senses from Text." ></td>
	<td class="line x" title="285:301	In Proceedings of SIGKDD-02." ></td>
	<td class="line x" title="286:301	pp." ></td>
	<td class="line x" title="287:301	613619." ></td>
	<td class="line x" title="288:301	Edmonton, Canada." ></td>
	<td class="line x" title="289:301	Pantel, P. and Ravichandran, D. 2004." ></td>
	<td class="line x" title="290:301	Automatically labeling semantic classes." ></td>
	<td class="line x" title="291:301	In Proceedings of HLT/NAACL-04." ></td>
	<td class="line x" title="292:301	pp." ></td>
	<td class="line x" title="293:301	321328." ></td>
	<td class="line x" title="294:301	Boston, MA." ></td>
	<td class="line x" title="295:301	Riloff, E. and Shepherd, J. 1997." ></td>
	<td class="line x" title="296:301	A corpus-based approach for building semantic lexicons." ></td>
	<td class="line x" title="297:301	In Proceedings of EMNLP-1997." ></td>
	<td class="line x" title="298:301	Voorhees, E. 2003." ></td>
	<td class="line x" title="299:301	Overview of the question answering track." ></td>
	<td class="line x" title="300:301	In Proceedings of TREC-12 Conference." ></td>
	<td class="line x" title="301:301	NIST, Gaithersburg, MD ." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C04-1116
Term Aggregation: Mining Synonymous Expressions Using Personal Stylistic Variations
Murakami, Akiko;Nasukawa, Tetsuya;"></td>
	<td class="line x" title="1:154	Term Aggregation: Mining Synonymous Expressions using Personal Stylistic Variations Akiko Murakami Tetsuya Nasukawa IBM Research, Tokyo Research Laboratory 1623-14 Shimotsuruma, Yamato, Kanagawa 242-8502, Japan CUakikom, nasukawaCV@jp.ibm.com Abstract We present a text mining method for finding synonymous expressions based on the distributional hypothesis in a set of coherent corpora." ></td>
	<td class="line x" title="2:154	This paper proposes a new methodology to improve the accuracy of a term aggregation system using each authors text as a coherent corpus." ></td>
	<td class="line x" title="3:154	Our approach is based on the idea that one person tends to use one expression for one meaning." ></td>
	<td class="line x" title="4:154	According to our assumption, most of the words with similar context features in each authors corpus tend not to be synonymous expressions." ></td>
	<td class="line x" title="5:154	Our proposed method improves the accuracy of our term aggregation system, showing that our approach is successful." ></td>
	<td class="line x" title="6:154	1 Introduction The replacement of words with a representative synonymous expression dramatically enhances text analysis systems." ></td>
	<td class="line x" title="7:154	We developed a text mining system called TAKMI (Nasukawa, 2001) which can find valuable patterns and rules in text that indicate trends and significant features about specific topics using not only word frequency but also using predicate-argument pairs that indicate dependencies among terms." ></td>
	<td class="line x" title="8:154	The dependency information helps to distinguish between sentences by their meaning." ></td>
	<td class="line x" title="9:154	Here are some examples of sentences from a PC call centers logs, along with the extracted dependency pairs: AF customer broke a tp AXcustomerbreak, breaktp AF end user broke a ThinkPad AXend userbreak, breakThinkPad In these examples, customer and end user and tp and ThinkPad can be assumed to have the same meaning in terms of this analysis for the call centers operations." ></td>
	<td class="line x" title="10:154	Thus, these two sentences have the same meaning, but the differences in expressions prevent us from recognizing their identity." ></td>
	<td class="line x" title="11:154	The variety of synonymous expressions causes a lack of consistency in expressions." ></td>
	<td class="line x" title="12:154	Other examples of synonymous expressions are: customer = cu = cus = cust = end user = user = eu Windows95 = Win95 = w95 One way to address this problem is by assigning canonical forms to synonymous expressions and variations of inconsistent expressions." ></td>
	<td class="line x" title="13:154	The goal of this paper is to find those of synonymous expressions and variations of inconsistent expressions that can be replaced with a canonical form for text analysis." ></td>
	<td class="line x" title="14:154	We call this operation term aggregation." ></td>
	<td class="line x" title="15:154	Term aggregation is different from general synonym finding." ></td>
	<td class="line x" title="16:154	For instance, customer and end user may not be synonyms in general, but we recognize these words as customer in the context of a manufacturers call center logs." ></td>
	<td class="line x" title="17:154	Thus, the words we want to aggregate may not be synonyms, but their role in the sentences are the same in the target domain from the mining perspective." ></td>
	<td class="line x" title="18:154	Yet, we can perform term aggregation using the same methods as in synonym finding, such as using word feature similarities." ></td>
	<td class="line x" title="19:154	There are several approaches for the automatic extraction of synonymous expressions, such as using word context features, but the results of such approaches tend to contain some antonymous expressions as noise." ></td>
	<td class="line x" title="20:154	For instance, a system may extract agent as a synonymous expression for customer, since they share the same feature of being human, and since both words appear as subjects of the same predicates, such as talk, watch, and ask." ></td>
	<td class="line x" title="21:154	In general, it is difficult to distinguish synonymous expressions from antonymous expressions based on their context." ></td>
	<td class="line x" title="22:154	However, if we have a coherent corpus, one in which the use of expressions is consistent for the same meaning, the words extracted from that corpus are guaranteed to have different meanings from each other." ></td>
	<td class="line x" title="23:154	Figure 1: Synonym Extraction System using Coherent Corpus Figure 1 illustrates the idea of such coherent corpora." ></td>
	<td class="line x" title="24:154	Words with similar contexts within incoherent corpora consist of various expressions including synonyms and antonyms, as in the left hand side of this figure, because of the use of synonymous expressions as in the upper right box of the figure." ></td>
	<td class="line x" title="25:154	In contrast, words with similar contexts within each coherent corpus do not contain synonymous expressions, as in the lower right box of the figure." ></td>
	<td class="line x" title="26:154	By using the information about non-synonymous expressions with similar contexts, we can deduce the synonymous expressions from the words with similar contexts within incoherent corpora by removing the non-synonymous expressions." ></td>
	<td class="line x" title="27:154	In this paper, we use a set of textual data written by the same author as a coherent corpus." ></td>
	<td class="line x" title="28:154	Our assumption is that one person tends to use one expression to represent one meaning." ></td>
	<td class="line x" title="29:154	For example, user for customer and agt for agent as in Figure 1." ></td>
	<td class="line x" title="30:154	Our method has three steps: extraction of synonymous expression candidates, extraction of noise candidates, and re-evaluation with these candidates." ></td>
	<td class="line x" title="31:154	In order to evaluate the performance of our method, we conducted some experiments on extracting term aggregation sets." ></td>
	<td class="line x" title="32:154	The experimental results indicate that our method leads to better precision than the basic synonym extraction approach, though the recall rates are slightly reduced." ></td>
	<td class="line x" title="33:154	The rest of this paper is organized as follows." ></td>
	<td class="line x" title="34:154	First we describe the personal stylistic variations in each authors text in Section 2, and in Section 3 we will give an overview of our system." ></td>
	<td class="line x" title="35:154	We will present the experimental results and discussion in Section 4." ></td>
	<td class="line x" title="36:154	We review related work in Section 5 and we consider future work and conclude the paper in Section 6." ></td>
	<td class="line x" title="37:154	2 Personal Stylistic Variations in Each Authors Corpora According to our assumption, each author uses a unique expression to represent one semantic concept, even though various expressions can be used for representing the same meaning." ></td>
	<td class="line x" title="38:154	To evaluate this assumption, we analyzed a call centers corpus, which was typed in by the call takers in a personal computer service call center 1." ></td>
	<td class="line x" title="39:154	Call Taker A B C D E customer 31 62 32 31 286 cust 6 335 2 3 2 eu 345 89 179 402 62 user 5 20 2 3 13 Table 1: The Variation of the Expressions for customer in each Call Takers Text." ></td>
	<td class="line x" title="40:154	Table1 shows variations of the expressions for  customer which were used by the call takers." ></td>
	<td class="line x" title="41:154	This table shows that each call taker mainly used one 1 The IBM PC Help Center unique expression to represent one meaning with a consistency ratio of about 80%, but the other 20% are other expressions." ></td>
	<td class="line x" title="42:154	These results show our assumption holds for the tendency for one expression to have one meaning within the same authors corpus." ></td>
	<td class="line x" title="43:154	However, it also demonstrated that multiple expressions for the same meaning appear within the same authors corpus even though the distribution of the appearences clearly leans toward one expression." ></td>
	<td class="line x" title="44:154	Thus, we should consider this fact when we apply this assumption." ></td>
	<td class="line x" title="45:154	3 Experiments 3.1 Data Overview In our experiments we used one months worth of data stored in the call center, containing about five million words." ></td>
	<td class="line x" title="46:154	The number of unique nouns was 29,961, and the number of unique verbs was 11,737, and 3,350,200 dependency pairs were extracted from the data." ></td>
	<td class="line x" title="47:154	We then created ten subcorpora in such a manner that each of them contains data provided by the same call taker." ></td>
	<td class="line x" title="48:154	The average number of predicate-argument pairs in each subcorpus was 37,454." ></td>
	<td class="line x" title="49:154	In our experiments, we selected ten authors corpus according to their size from the larger one." ></td>
	<td class="line x" title="50:154	To evaluate the experiments, we manually created some evaluation data sets." ></td>
	<td class="line x" title="51:154	The evaluation data sets were made for ten target words, and the average number of variants was 7.8 words for each target word." ></td>
	<td class="line x" title="52:154	Some examples are shown in Table2." ></td>
	<td class="line x" title="53:154	target concept variants customer customer, cu, cus, cust, end user, user, eu HDD harddisk, hdd drive, HD, HDD, hdds, harddrive, hd, H.D battery Battery, batteyr, battery, battary, batt, bat screen display, monitor, moniter, Monitor Table 2: Examples of Evaluation Data For the cannonical expressions for each target word, we simply selected the most frequent expression from the variants." ></td>
	<td class="line x" title="54:154	3.2 Text Analysis Tool for Noisy Data In the call center data there are some difficulties for natural language processing because the data contains a lot of informal writing." ></td>
	<td class="line x" title="55:154	The major problems are; AF Words are often abbreviated AF There are many spelling errors AF Case is used inconsistently Shallow processing is suitable for such noisy data, so we used a Markov-model-based tagger, essentially the same as the one described in (Charniak, 1993) in our experiments 2 . This tagger assigns a POS based on the distribution of the candidate POSs for each word and the probability of POS transitions extracted from a training corpus, and we used a manually annotated corpus of articles from the Wall Street Journal in the Penn Treebank corpus 3 as a training corpus." ></td>
	<td class="line x" title="56:154	This tagger treats an unknown word that did not appear in the training corpus as a noun." ></td>
	<td class="line x" title="57:154	In addition, it assigns a canonical form to words without inflections." ></td>
	<td class="line x" title="58:154	After POS tagging for each sequence of words in a document, it is possible to apply a cascaded set of rules, successively identifying more and more complex phrasal groups." ></td>
	<td class="line x" title="59:154	Therefore, simple patterns will be identified as simple noun groups and verb groups, and these can be composed into a variety of complex NP configurations." ></td>
	<td class="line x" title="60:154	At a still higher level, clause boundaries can be marked, and even (nominal) arguments for (verb) predicates can be identified." ></td>
	<td class="line x" title="61:154	The accuracy of these analyses is lower than the accuracy of the POS assignment." ></td>
	<td class="line x" title="62:154	3.3 Term Aggregation using Personal Stylistic Variations In this section we explain how to aggregate words using these word features." ></td>
	<td class="line x" title="63:154	We have three steps for the term aggregation: creating noun feature vectors, extracting synonymous expressions and noise candidates, and a re-evaluation." ></td>
	<td class="line x" title="64:154	3.3.1 Creating Noun Feature Vectors There is a number of research reports on word similarities, and the major approach is comparing their contexts in the texts." ></td>
	<td class="line x" title="65:154	Contexts can be defined in two different ways: syntactic-based and window-based techniques." ></td>
	<td class="line x" title="66:154	Syntactic-based techniques consider the linguistic information about part-of-speech categories and syntactic groupings/ relationships." ></td>
	<td class="line x" title="67:154	Window-based techniques consider an arbitrary number of words around the given 2 This shallow syntactic parser is called CCAT based on the TEXTRACT architecture (Neff, 2003) developed at IBM Watson Research Center." ></td>
	<td class="line x" title="68:154	3 http:// www.cis.upenn.edu/ treebank/ rank candidate 1 batt 2 batterie 3 bat 4 BTBTBTBT cover 5 BTY 6 batterry 7 BT BT BT BT BT BT BT BT BT BT adapter 8 bezel 9 BT BT BT BT BT BT BT BT BT BT cheque 10 BTBTBTBT screw Table 3: batterys Synonymous Expression Candidates from the Entire Corpus Author A rank candidate 1 battery 2 controller 3 BT BT BT BT BT BT BT BT Cover 4 APM 5 BTBTBTBT screw 6 mark 7 BT BT BT BT BT BT BT BT BT BT cheque 8 diskette 9 checkmark 10 boot Author B rank candidate 1 batt 2 form 3 protector 4 DISKETTE 5 Mwave 6 BT BT BT BT BT BT BT BT BT BT adapter 7 mouse 8 BT BT BT BT BT BT BT BT BT BT cheque 9 checkmark 10 process Table 4: Noise Candidates from Each Authors Corpus word." ></td>
	<td class="line oc" title="69:154	The words we want to aggregate for text analysis are not rigorous synonyms, but the role is the same, so we have to consider the syntactic relation based on the assumptions that words with the same role tend to modify or be modified by similar words (Hindle, 1990; Strzalkowski, 1992)." ></td>
	<td class="line x" title="70:154	On the other hand, window-based techniques are not suitable for our data, because the documents are written by several authors who have a variety of different writing styles (e.g. selecting different prepositions and articles)." ></td>
	<td class="line x" title="71:154	Therefore we consider only syntactic features: dependency pairs, which consist of nouns, verbs, and their relationships." ></td>
	<td class="line x" title="72:154	A dependency pair is written as (noun, verb(with its relationship)) as in the following examples." ></td>
	<td class="line x" title="73:154	(customer, bootAZ) (customer, shut offAZ) (tp, shut offAY) The symbol AZ means the noun modifies the verb, and AY means the verb modifies the noun." ></td>
	<td class="line x" title="74:154	By using these extracted pairs, we can assign a frequency value to each noun and verb as in a vector space model." ></td>
	<td class="line x" title="75:154	We use a noun feature vector (NFV) to evaluate the similarities between nouns." ></td>
	<td class="line x" title="76:154	The NFVs are made for each authors corpora and for the entire corpus, which contains all of the authors corpora." ></td>
	<td class="line x" title="77:154	3.3.2 Extract Synonymous Expression Candidates and Noise Candidates The similarity between two nouns that we used in our approach is defined as the cosine coefficient of the two NFVs." ></td>
	<td class="line x" title="78:154	Then we can get the relevant candidate lists that are sorted by word similarities between nouns and the target word." ></td>
	<td class="line x" title="79:154	The noun list from the entire corpus is based on the similarities between the targets NFV in the entire corpus and the NFVs in the entire corpus." ></td>
	<td class="line x" title="80:154	These words are the synonymous expression candidates, which is the baseline system." ></td>
	<td class="line x" title="81:154	The noun lists from the authors corpora are extracted based on the similarities between the targets NFV in the entire corpus and the NFVs in each authors corpora." ></td>
	<td class="line x" title="82:154	The most similar word in an authors corpus is accepted as a synonymous expression for the target word, and the other similar words in the authors corpus are taken to not have the same meaning as the target word, even though the features are similar." ></td>
	<td class="line x" title="83:154	These words are then taken as the noise candidates, except for the most relevant words in each candidate list." ></td>
	<td class="line x" title="84:154	If there are N authors, then N lists are extracted." ></td>
	<td class="line x" title="85:154	3.3.3 Re-evaluation On the basis of our assumption, we propose a simple approach for re-evaluation: deleting the noise candidates in the synonymous expression candidates." ></td>
	<td class="line x" title="86:154	However, as shown in Section 2, each author does not necessarily use only one expression for one meaning." ></td>
	<td class="line x" title="87:154	For instance, while the call taker B in Table 1 mostly uses cust, he/she also uses other expressions to a considerable degree." ></td>
	<td class="line x" title="88:154	Accordingly if we try to delete all noise candidates, such synonymous expressions will be eliminated from the final result." ></td>
	<td class="line x" title="89:154	To avoid this kind of over-deleting, we classified words into three types, Absolute Term, Candidate Term, and Noise Candidate." ></td>
	<td class="line x" title="90:154	First, we assigned the Candidate Term type to all of the extracted terms from the entire corpus." ></td>
	<td class="line x" title="91:154	Second, the most relevant word extracted from each authors corpus was turned into an Absolute Term." ></td>
	<td class="line x" title="92:154	Third, the words extracted from all of the authors corpora, except for the most relevant word in each authors corpus, were turned into the Noise Candidate type." ></td>
	<td class="line x" title="93:154	In this step an Absolute Term does not change if the word is a noise candidate." ></td>
	<td class="line x" title="94:154	Then the words listed as Absolute Term or Candidate Term are taken as the final results of the reevaluation." ></td>
	<td class="line x" title="95:154	3.4 An Actual Example In this section we will show an actual example of how our system works." ></td>
	<td class="line x" title="96:154	In this example, the target word is battery." ></td>
	<td class="line x" title="97:154	First, the synonymous expression candidates are extracted from the entire corpus using the NFV of the target word in the entire corpus and the NFVs in the entire corpus." ></td>
	<td class="line x" title="98:154	The relevant list is shown in Table 3." ></td>
	<td class="line x" title="99:154	In this candidate list, we can find many synonymous expressions for battery, such as batt, batterie, etc, however we also see some noise, such as cover, adapter, etc. In this step these words are tentavely assigned as Candidate Term." ></td>
	<td class="line x" title="100:154	Second, the noise candidates are extracted from each authors corpora by estimating the similarities between the target words NFV in the entire corpus and the NFVs in the authors corpora." ></td>
	<td class="line x" title="101:154	The noise candidate lists from two authors are shown in Table 4." ></td>
	<td class="line x" title="102:154	The most relevant words in each authors corpora are battery and batt, so the same words in the extracted Candidate Term list are turned into Absolute Term and remain undeleted even when battery and batt appear in the same authors corpus." ></td>
	<td class="line x" title="103:154	The rest of the words in the noise candidate lists are noise, so the same words in the Candidate Term list are turned into Noise Candidate, such as cover, adapter, cheque, and screw." ></td>
	<td class="line x" title="104:154	Finally, we can get the term aggregation result as a list consisting of the words marked Absolute Term and Candidate Term." ></td>
	<td class="line x" title="105:154	The results are shown in Table 5." ></td>
	<td class="line x" title="106:154	batt batterie bat BTY batterry bazel Table 5: Results after Removing the Noise 4 Experimental Results and Discussion For the evaluation, we used general evaluation metrics, precision 4, recall 5, and the F-measure 6 .To measure the systems performance, we calculated the precision and the recall for the top N significant words of the baseline system and the re-evaluated system." ></td>
	<td class="line x" title="107:154	4.1 Estimate of the Size of Cut-off Term In our experiments, we used the metrics of precision and recall to evaluate our method." ></td>
	<td class="line x" title="108:154	These metrics are based on the number of synonymous expressions correctly extracted in the top N ranking." ></td>
	<td class="line x" title="109:154	To define this cut-off term rank N for the data, we did some preliminary experiments with a small amount of data." ></td>
	<td class="line x" title="110:154	With the simple noise deletion approach we expect to increase the precision, however, the recall is not expected to be increased by using this method." ></td>
	<td class="line x" title="111:154	We defined the maximum top value of N as satiation." ></td>
	<td class="line x" title="112:154	Figure 2 shows the performance against rank N for the entire corpus." ></td>
	<td class="line x" title="113:154	We can see the satiation point at 20 in the figure." ></td>
	<td class="line x" title="114:154	Therefore, we set N equal to 20 in our experiments for synonymous expression extraction from the entire corpus." ></td>
	<td class="line x" title="115:154	At the same time, we want to know the highest value of n to obtain the noise candidates." ></td>
	<td class="line x" title="116:154	In each authors corpus a lower recall is acceptable, because we will remove these words as noise from the results of the entire corpus." ></td>
	<td class="line x" title="117:154	These results lead to the conclusion that the window size of the rank N for the entire corpus and the 4 C8D6CTCRCXD7CXD3D2 BP C6D9D1CQCTD6 D3CU D7DDD2D3D2DDD1D7 CRD3D6D6CTCRD8D0DD CTDCD8D6CPCRD8CTCS C6D9D1CQCTD6 D3CU D7DDD2D3D2DDD1D7 CTDCD8D6CPCRD8CTCS 5 CACTCRCPD0D0 BP C6D9D1CQCTD6 D3CU D7DDD2D3D2DDD1D7 CRD3D6D6CTCRD8D0DD CTDCD8D6CPCRD8CTCS C6D9D1CQCTD6 D3CU D7DDD2D3D2DDD1D7 CXD2 CPD2D7DBCTD6 D7CTD8 6 BY A0D1CTCPD7D9D6CTBP BEA2CACTCRCPD0D0A2C8D6CTCRCXD7CXD3D2 CACTCRCPD0D0B7C8D6CTCRCXD7CXD3D2 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 5 10 15 20 25 30 35 40 Recall rank Recall Figure 2: The Recalls of the Synonymous Extraction System Against the Rank rank n for each corpus should have the same value, 20." ></td>
	<td class="line x" title="118:154	During the evaluation, we extracted the synonymous expressions with the top 20 similarities from the entire corpus and removed the noise candidates with the top 20 similarities from each authors corpora." ></td>
	<td class="line x" title="119:154	4.2 Most Relevant Word Approach The basic idea of this method is that one author mostly uses a unique expression to represent one meaning." ></td>
	<td class="line x" title="120:154	According to this idea, the most similar words in each authors corpora tend to be synonymous expression candidates." ></td>
	<td class="line x" title="121:154	Comparing these two methods, one is a system for removing noise and the other is a system for extracting the most similar word." ></td>
	<td class="line x" title="122:154	According to the assumption of one person mostly using one unique expression to represent one meaning, we can extract the synonymous expressions that are the most similar word to the target word in each authors corpus." ></td>
	<td class="line x" title="123:154	In comparison with the approach using the most similar word in each authors corpus and removing the noise, we calculated the recall rates for the most similar word approach." ></td>
	<td class="line x" title="124:154	Table 6 shows the recall rates for the system with the entire corpus, the system using the top word from three authors corpora, five authors corpora, and ten authors corpora." ></td>
	<td class="line x" title="125:154	entire 3 5 10 corpus authors authors authors Recall 0.624 0.114 0.114 0.143 Table 6: The Recall when Defining the Most Similar Words as Answers These results show that the most similar words 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0 2 4 6 8 10 12 Number of Authors Recall Precision F-Measure Figure 3: The Results After Noise Reduction by Using Authors Corpora in the authors corpora are not necessarily synonymous expressions for the target word, since some authors use other expressions in their corpus." ></td>
	<td class="line x" title="126:154	4.3 Noise Deletion Approach For evaluating the deleting noise approach, the performance against the number of authors is shown in Figure 3." ></td>
	<td class="line x" title="127:154	We extracted the top 20 synonymous expression candidates from the entire corpus, and removed the top 20 (except for the most similar words) noise candidates from the authors corpora." ></td>
	<td class="line x" title="128:154	Figure 3 contains the entire corpus result, and the results after removing the noise from three authors corpora, five authors corpora, and ten authors corpora." ></td>
	<td class="line x" title="129:154	This figure shows that the noise reduction approach leads to better precision than the basic approach, but the recall rates are slightly reduced." ></td>
	<td class="line x" title="130:154	This is because they sometimes remove words that are not noise, when an author used several expressions for the same word." ></td>
	<td class="line x" title="131:154	In spite of that, the F-measures are increased, showing the method improves the accuracy by 37% (when using 10 authors corpora)." ></td>
	<td class="line x" title="132:154	In addition, the table indicates that the improvement relative to the number of authors is not yet at a maximum." ></td>
	<td class="line x" title="133:154	5 Related Work There have been many approachs to automatic detection of similar words from text." ></td>
	<td class="line oc" title="134:154	Our method is similar to (Hindle, 1990), (Lin, 1998), and (Gasperin, 2001) in the use of dependency relationships as the word features." ></td>
	<td class="line x" title="135:154	Another approach used the words distribution to cluster the words (Pereira, 1993), and Inoue (Inoue, 1991) also used the word distributional information in the Japanese-English word pairs to resolve the polysemous word problem." ></td>
	<td class="line x" title="136:154	Wu (Wu, 2003) shows one approach to collect synonymous collocation by using translation information." ></td>
	<td class="line x" title="137:154	This time we considered only synonymous expression terms, but the phrasal synonymous expression should be the target of aggregation in text analysis." ></td>
	<td class="line x" title="138:154	Not only synonymous expressions, but abbreviation is one of the most important issues in term aggregation." ></td>
	<td class="line x" title="139:154	Youngja (Youngja, 2001) proposed a method for finding abbreviations and their definitions, using the pattern-based rules which were generated automatically and/or manually." ></td>
	<td class="line x" title="140:154	To re-evaluate the baseline synonym extraction system, we used the authors writing styles, and there are some researches using this approach." ></td>
	<td class="line x" title="141:154	The most famous usage for them is the identification of a unknown author of a certain document (Thisted, 1987)." ></td>
	<td class="line x" title="142:154	6 Conclusion and Future Work This paper describes how to use the coherent corpus for term aggregation." ></td>
	<td class="line x" title="143:154	In this paper we used the personal stylistic variations based on the idea that one person mostly uses one expression for one meaning." ></td>
	<td class="line x" title="144:154	Although variations of personal writing styles are cause of the synonymous expressions in general, we managed to take advantage of such personal writing styles in order to reduce noise for term aggregation system." ></td>
	<td class="line x" title="145:154	We argued mainly about synonymous expressions in this paper, we can extract abbreviations and frequent missspelled words, and they should be considered as terms in term aggregation." ></td>
	<td class="line x" title="146:154	We have to consider not only role-based word similarities, but also string-based similarities." ></td>
	<td class="line x" title="147:154	In general, a wide range of variations in expressions for the same meaning is a problematic feature of noisy data." ></td>
	<td class="line x" title="148:154	However, in our method, we exploit these problematic variations for useful information for improving the accuracy of the system." ></td>
	<td class="line x" title="149:154	This noise removal approach is effective when the data contains various expressions coming from various authors." ></td>
	<td class="line x" title="150:154	Gasperin (Gasperin, 2001) indicated the specific prepositions are relevant to characterize the significant syntactic contexts used for the measurement of word similarity, considering what prepositions do and do not depend on personal writing style remains as future work." ></td>
	<td class="line x" title="151:154	In this paper, our work is based on the call centers logs, but this method is suitable for data from other domains." ></td>
	<td class="line x" title="152:154	For example we anticipate that patent application data will be a suitable resource, because this data includes various expressions, and the expressions are based on each companys terminology." ></td>
	<td class="line x" title="153:154	On the other hand, e-mail data does not seem suitable for our approach because other authors influence the expressions used." ></td>
	<td class="line x" title="154:154	While we restricted ourselves in this work to this specific data, our future work will include an investigation of the character of the data and how it influences our method." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C04-1165
Construction Of An Objective Hierarchy Of Abstract Concepts Via Directional Similarity
Kanzaki, Kyoko;Yamamoto, Eiko;Ma, Qing;Isahara, Hitoshi;"></td>
	<td class="line x" title="1:167	Construction of an Objective Hierarchy of Abstract Concepts via Directional Similarity Kyoko Kanzaki Eiko Yamamoto Hitoshi Isahara Computational Linguistics Group, National Institute of Information and Communications Technology 3-5 Hikari-dai, Seika-cho, Souraku-gun, Kyoto, Japan, {kanzaki, eiko, isahara}@nict.go.jp Qing Ma Faculty of Science and Technology Ryukoku University Seta, Otsu,520-2194, Japan qma@math.ryukoku.ac.jp Abstract The method of organization of word meanings is a crucial issue with lexical databases." ></td>
	<td class="line x" title="2:167	Our purpose in this research is to extract word hierarchies from corpora automatically." ></td>
	<td class="line x" title="3:167	Our initial task to this end is to determine adjective hyperonyms." ></td>
	<td class="line x" title="4:167	In order to find adjective hyperonyms, we utilize abstract nouns." ></td>
	<td class="line x" title="5:167	We constructed linguistic data by extracting semantic relations between abstract nouns and adjectives from corpus data and classifying abstract nouns based on adjective similarity using a self-organizing semantic map, which is a neural network model (Kohonen 1995)." ></td>
	<td class="line x" title="6:167	In this paper we describe how to hierarchically organize abstract nouns (adjective hyperonyms) in a semantic map mainly using CSM." ></td>
	<td class="line x" title="7:167	We compare three hierarchical organizations of abstract nouns, according to CSM, frequency (Tf.CSM) and an alternative similarity measure based on coefficient overlap, to estimate hyperonym relations between words." ></td>
	<td class="line x" title="8:167	1." ></td>
	<td class="line x" title="9:167	Introduction A lexical database is necessary for computers, and even humans, to fully understand a word's meaning because the lexicon is the origin of language understanding and generation." ></td>
	<td class="line x" title="10:167	Progress is being made in lexical database research, notably with hierarchical semantic lexical databases such as WordNet, which is used for NLP research worldwide." ></td>
	<td class="line x" title="11:167	When compiling lexical databases, it is important to consider what rules or phenomena should be described as lexical meanings and how these lexical meanings should be formalized and stored electronically." ></td>
	<td class="line x" title="12:167	This is a common topic of discussion in computational linguistics, especially in the domain of computational lexical semantics." ></td>
	<td class="line x" title="13:167	The method of organization of word meanings is also a crucial issue with lexical databases." ></td>
	<td class="line x" title="14:167	In current lexical databases and/or thesauri, abstract nouns indicating concepts are identified manually and words are classified in a top-down manner based on human intuition." ></td>
	<td class="line x" title="15:167	This is a good way to make a lexical database for users with a specific purpose." ></td>
	<td class="line x" title="16:167	However, word hierarchies based on human intuition tend to vary greatly depending on the lexicographer, and there is often disagreement as to the make-up of the hierarchy." ></td>
	<td class="line x" title="17:167	If we could find an objective method to organize word meanings based on real data, we would avoid this variability." ></td>
	<td class="line x" title="18:167	Our purpose in this research is to extract word hierarchies from corpora automatically." ></td>
	<td class="line x" title="19:167	Our initial task to this end is to determine adjective hyperonyms." ></td>
	<td class="line x" title="20:167	In order to find adjective hyperonyms, we utilize abstract nouns." ></td>
	<td class="line x" title="21:167	Past linguistic research has focused on classifying the semantic relationship between abstract nouns and adjectives (Nemoto 1969, Takahashi 1975)." ></td>
	<td class="line x" title="22:167	We constructed linguistic data by extracting semantic relations between abstract nouns and adjectives from corpus data and classifying abstract nouns based on adjective similarity using a self-organizing semantic map (SOM), which is a neural network model (Kohonen 1995)." ></td>
	<td class="line x" title="23:167	The relative proximity of words in the semantic map indicates their relative similarity." ></td>
	<td class="line x" title="24:167	In previous research, word meanings have been statistically modeled based on syntactic information derived from a corpus." ></td>
	<td class="line oc" title="25:167	Hindle (1990) used noun-verb syntactic relations, and Hatzivassiloglou and McKeown (1993) used coordinated adjective-adjective modifier pairs." ></td>
	<td class="line n" title="26:167	These methods are useful for the organization of words deep within a hierarchy, but do not seem to provide a solution for the top levels of the hierarchy." ></td>
	<td class="line x" title="27:167	To find an objective hierarchical word structure, we utilize the complementary similarity measure (CSM), which estimates a one-to-many relation, such as superordinatesubordinate relations (Hagita and Sawaki 1995, Yamamoto and Umemura 2002)." ></td>
	<td class="line x" title="28:167	In this paper we propose an automated method for constructing adjective hierarchies by connecting strongly related abstract nouns in a top-down fashion within a semantic map, mainly using CSM." ></td>
	<td class="line x" title="29:167	We compare three hierarchical organizations of abstract nouns, according to CSM, frequency (Tf.CSM) and an alternative similarity measure based on coefficient overlap, to estimate hyperonym relations between words." ></td>
	<td class="line x" title="30:167	2." ></td>
	<td class="line x" title="31:167	Linguistic clues to extract adjective hyperonyms from corpora In order to automatically extract adjective hyperonyms we use syntactic and semantic relations between words." ></td>
	<td class="line x" title="32:167	There is a good deal of linguistic research focused on the syntactic and semantic functions of abstract nouns, including Nemoto (1969), Takahashi (1975), and Schmid (2000)." ></td>
	<td class="line x" title="33:167	Takahashi (1975) illustrated the sentential function of abstract nouns with the following examples." ></td>
	<td class="line x" title="34:167	a. Yagi wa seishitsu ga otonashii." ></td>
	<td class="line x" title="35:167	(goat) topic (nature) subject (gentle) The nature of goats is gentle b. Zou wa hana ga nagai." ></td>
	<td class="line x" title="36:167	(elephant) topic (a nose) subject (long) The nose of an elephant is long He examined the differences in semantic function between seishitsu (nature) in (a) and hana (nose) in (b), and explained that seishitsu (nature) in (a) indicates an aspect of something, i.e., the goat, and hana (nose) in (b) indicates part of something, i.e., the elephant." ></td>
	<td class="line x" title="37:167	He recognized abstract nouns in (a) as a hyperonym of the attribute that the predicative adjectives express." ></td>
	<td class="line x" title="38:167	Nemoto (1969) identified expressions such as iro ga akai (the color is red) and hayasa ga hayai (the speed is fast) as a kind of meaning repetition, or tautology." ></td>
	<td class="line x" title="39:167	In this paper we define such abstract nouns that co-occur with adjectives as adjective hyperonyms." ></td>
	<td class="line x" title="40:167	We semi-automatically extracted from corpora 365 abstract nouns used as this kind of head noun, according to the procedures described in Kanzaki et al.(2000)." ></td>
	<td class="line x" title="42:167	We collected abstract nouns from two year's worth of articles from the Mainichi Shinbun newspaper, and extracted adjectives co-occurring with abstract nouns in the manner of (a) above from 100 novels, 100 essays and 42 year's worth of newspaper articles, including 11 year's worth of Mainichi Shinbun articles, 10 year's worth of Nihon Keizai Shinbun (Japanese economic newspaper) articles, 7 year's worth of Sangyoukinyuuryuutsu Shinbun (an economic newspaper) articles, and 14 year's worth of Yomiuri Shinbun articles." ></td>
	<td class="line x" title="43:167	The total number of abstract noun types is 365, the number of adjective types is 10,525, and the total number of adjective tokens is 35,173." ></td>
	<td class="line x" title="44:167	The maximum number of co-occurring adjectives for a given abstract noun is 1,594." ></td>
	<td class="line x" title="45:167	3." ></td>
	<td class="line x" title="46:167	On the Self-Organizing Semantic Map 3.1 Input data Abstract nouns are located in the semantic map based on the similarity of co-occurring adjectives after iteratively learning over input data." ></td>
	<td class="line x" title="47:167	In this research, we focus on abstract nouns co-occurring with adjectives." ></td>
	<td class="line x" title="48:167	In the semantic map, there are 365 abstract nouns co-occurring with adjectives." ></td>
	<td class="line x" title="49:167	The similarities between the 365 abstract nouns are determined according to the number of common co-occurring adjectives." ></td>
	<td class="line x" title="50:167	We made a list such as the following." ></td>
	<td class="line x" title="51:167	OMOI (feeling): ureshii (glad), kanashii (sad), shiawasena (happy),  KIMOCHI (though): ureshii (glad), tanoshii (pleased), hokorashii (proud),  KANTEN (viewpoint): igakutekina (medical), rekishitekina (historical), When two (or more) sets of adjectives with completely different characteristics co-occur with an abstract noun and the meanings of the abstract noun can be distinguished correspondingly, we treat them as two different abstract nouns." ></td>
	<td class="line x" title="52:167	For example, the Japanese abstract noun men is treated as two different abstract nouns with men1 meaning one side (of the characteristics of someone or something) and men2 meaning surface." ></td>
	<td class="line x" title="53:167	The former co-occurs with gentle, kind and so on." ></td>
	<td class="line x" title="54:167	The latter co-occurs with rough, smooth and so on." ></td>
	<td class="line x" title="55:167	3.2 The Self-Organizing Semantic Map Ma (2000) classified co-occurring words using a self-organizing semantic map (SOM)." ></td>
	<td class="line x" title="56:167	We made a semantic map of the abovementioned 365 abstract nouns using SOM, based on the cosine measure." ></td>
	<td class="line x" title="57:167	The distribution of the words in the map gives us a sense of the semantic distribution of the words." ></td>
	<td class="line x" title="58:167	However, we could not precisely identify the relations between words in the map (Fig 1)." ></td>
	<td class="line x" title="59:167	In Fig." ></td>
	<td class="line x" title="60:167	1 lines on the maps indicate close relations between word pairs." ></td>
	<td class="line x" title="61:167	In the cosine-based semantic map, there is no clear correspondence between word similarities and the distribution of abstract nouns in the map." ></td>
	<td class="line x" title="62:167	To solve this problem we introduced the complementary similarity measure (CSM)." ></td>
	<td class="line x" title="63:167	This similarity measure estimates one-to-many relations, such as superordinatesubordinate relations (Hagita and Sawaki 1995, Yamamoto and Umemura 2002)." ></td>
	<td class="line x" title="64:167	We can find the hierarchical distribution of words in the semantic map according to the value of CSM (Fig 2)." ></td>
	<td class="line x" title="65:167	In the CSM-based SOM, lines are concentrated at the bottom right hand corner, that is, most abstract nouns are located at the bottom right-hand corner." ></td>
	<td class="line x" title="66:167	Next, we find hierarchical relations between whole abstract nouns, not between word pairs, on the map automatically." ></td>
	<td class="line x" title="67:167	4." ></td>
	<td class="line x" title="68:167	How to construct hierarchies of nominal adjective hyperonyms in the Semantic Map 4.1 Similarity measures, CSM and Yates correction A feature of CSM is its ability to estimate hierarchical relations between words." ></td>
	<td class="line x" title="69:167	This similarity measure was developed for the recognition of degraded machine-printed text (Hagita and Sawaki, 1995)." ></td>
	<td class="line x" title="70:167	Yates correction is often used in order to increase the accuracy of approximation." ></td>
	<td class="line x" title="71:167	Hierarchical relations can be extracted accurately when the CSM value is high." ></td>
	<td class="line x" title="72:167	Yates correction can extract different relations from high CSM values." ></td>
	<td class="line x" title="73:167	When the CSM value is low, the result is not reliable, in which case we use Yates correction." ></td>
	<td class="line x" title="74:167	According to Yamamoto and Umemura (2002), who adopted CSM to classify words, CSM is calculated as follows." ></td>
	<td class="line x" title="75:167	))(( dbca bcad CSM ++  = Yates correction is calculated as follows." ></td>
	<td class="line x" title="76:167	))()()(( )2/|(| 2 dbcadcba nbcadn Yates ++++  = Here n is the sum of the number of cooccurring adjectives; a indicates the number of times the two labels appear together; b indicates the number of times label 1 occurs but label 2 does not; c is the number of times label 2 occurs but label 1 does not; and d is the number of times neither label occurs." ></td>
	<td class="line x" title="77:167	In our research, each label is an abstract noun, a indicates the number of adjectives co-occurring with both abstract nouns, b and c indicate the number of adjectives co-occurring with either abstract noun Figure 1." ></td>
	<td class="line x" title="78:167	The Cosine-based SOM of word similarity Figure 2." ></td>
	<td class="line x" title="79:167	The CSM-based SOM of word similarity (label 1 and label 2, respectively), and d indicates the number of adjectives co-occurring with neither abstract noun." ></td>
	<td class="line x" title="80:167	We calculated hierarchical relations between word pairs using these similarity measures." ></td>
	<td class="line x" title="81:167	4.2 Construction of a hierarchy of abstract nouns using CSM and Yates' correction The hierarchy construction process is as follows: 1) Based on the results of CSM, koto (matter) is the hyperonym of all abstract nouns." ></td>
	<td class="line x" title="82:167	First, we connect super/sub-ordinate words with the highest CSM value while keeping the super-subordinate relation." ></td>
	<td class="line x" title="83:167	2) When the normalized value of CSM is lower, the number of extracted word pairs becomes increasing overwhelmingly, and the reliability of CSM diminishes." ></td>
	<td class="line x" title="84:167	Word pairs with a normalized CSM value of less than 0.4 are located far from the common hyperonym koto (matter) on the semantic map." ></td>
	<td class="line x" title="85:167	If we construct a hierarchy using CSM values only, a long hierarchy containing irrelevant words emerges." ></td>
	<td class="line x" title="86:167	In this case, the word pairs calculated by Yates' correction are more accurate than those from CSM." ></td>
	<td class="line x" title="87:167	We combine words using Yates correction, when the value of CSM is less than 0.4." ></td>
	<td class="line x" title="88:167	When we connect word pairs with a high Yates value, we find a hyperonym of the super-ordinate noun of the pair and connect the pair to the hyperonym." ></td>
	<td class="line x" title="89:167	If a word pair appears only in the Yates' correction data, that is, we cannot connect the pair with high Yates value to the hyperonym with high CSM value, they are combined with koto (matter)." ></td>
	<td class="line x" title="90:167	3) Finally, if a short hierarchy is contained in a longer hierarchy, it is merged with the longer hierarchy and we insert koto (matter) at the root of all hierarchies." ></td>
	<td class="line x" title="91:167	4.3 Results The number of groups obtained was 161." ></td>
	<td class="line x" title="92:167	At its deepest, the hierarchy was 15 words deep, and at its shallowest, it was 4 words deep." ></td>
	<td class="line x" title="93:167	The following is a breakdown of the number of groups at different depths in the hierarchy." ></td>
	<td class="line x" title="94:167	The greatest concentration of groups is at depth 7." ></td>
	<td class="line x" title="95:167	There are 140 groups from depth 5 to depth 10, which is 87% of all groups." ></td>
	<td class="line x" title="96:167	The word that has the strongest relation with koto (matter) is men1 (side1)." ></td>
	<td class="line x" title="97:167	The number of groups in which koto (matter) and men1 (side1) are hyperonyms is 96 (59.6%)." ></td>
	<td class="line x" title="98:167	The largest number of groups after that is a group in which koto (matter), men1 (side1) and imeeji (image) are hyperonyms." ></td>
	<td class="line x" title="99:167	The number of groups in this case is 59 groups, or 36.6% of the total." ></td>
	<td class="line x" title="100:167	With respect to the value of CSM, the cooccurring adjectives are similar to men1 (side1) and imeeji (image)." ></td>
	<td class="line x" title="101:167	Other words that have a direct relation with koto (matter) are joutai (state) and toki (when)." ></td>
	<td class="line x" title="102:167	They have the most number of groups after men1 (side1) among all the children of koto (matter)." ></td>
	<td class="line x" title="103:167	The number of groups subsumed by joutai (state) group and toki (when) are 21 and 19, respectively." ></td>
	<td class="line x" title="104:167	Other direct hyponyms of koto (matter) are: ki (feeling): 6 groups ippou (while or grow er and er): 3 groups me2 (eyes): 3 groups katachi1 (in the form of): 3 groups iikata (how to say): 2 groups yarikata (how to): 2 groups There is little hierarchical structure to these groups, as they co-occur with few adjectives." ></td>
	<td class="line x" title="105:167	4.4 The Hierarchies of abstract concepts in the semantic map In the following semantic maps, where abstract nouns are distributed using SOM and CSM (see Section 3), hierarchies of abstract nouns are drawn with lines." ></td>
	<td class="line x" title="106:167	The bottom right hand corner is koto (matter), a starting point for the distribution of abstract nouns." ></td>
	<td class="line x" title="107:167	Five main types of hierarchies are found from patterns of lines on the map, as follows: The first figure, Fig.3, is hierarchies of kanji (feeling), kimochi (feeling)  on the semantic map." ></td>
	<td class="line x" title="108:167	The location of hierarchies of yousu (aspect), omomochi (look), kaotsuki (on ones face),  is similar to this type of the location." ></td>
	<td class="line x" title="109:167	Hierarchies of sokumen (one side), imi (meaning), kanten (viewpoint), kenchi (standpoint)  on Depth 4 5 6 7 8 9 Groups 3 16 27 32 23 23 Depth 10 11 12 13 14 15 Groups 19 7 3 4 3 1 Table 1: The depth of the hierarchy by CSM the map are shown in Fig." ></td>
	<td class="line x" title="110:167	4." ></td>
	<td class="line x" title="111:167	The lines of the hierarchies go up from the bottom right hand corner to the upper left hand corner and then turn towards the upper right hand corner." ></td>
	<td class="line x" title="112:167	The location of hierarchies of nouryoku (ability), sainou (talent)  is similar to this one." ></td>
	<td class="line x" title="113:167	The hyperonym of teido (degree) is joutai (state)." ></td>
	<td class="line x" title="114:167	In Fig.5 these abstract nouns are located at the bottom of the map." ></td>
	<td class="line x" title="115:167	The location of hierarchies of kurai (rather than) and hou (comparatively) are similar to this one." ></td>
	<td class="line x" title="116:167	The hierarchies of joutai (state), joukyou (situation), yousou (aspect), jousei (the state of affairs) are shown in Fig.6." ></td>
	<td class="line x" title="117:167	The lines are found at a higher location than the line of teido(degree)." ></td>
	<td class="line x" title="118:167	The lines of the hierarchies of joutai (state), ori (when), sakari (in the hight of), sanaka (while) are similar to these lines." ></td>
	<td class="line x" title="119:167	The lines of the hierarchies of seikaku (character), gaikan (appearance)and utsukushisa (beauty) are similar to each other." ></td>
	<td class="line x" title="120:167	We show the hierarchies of seikaku (character) in Fig.7." ></td>
	<td class="line x" title="121:167	These lines in Fig.7 are located from the right end to the upper left hand corner." ></td>
	<td class="line x" title="122:167	From the following, we can find five main types of hierarchies." ></td>
	<td class="line x" title="123:167	From the starting point  koto (matter), -The hierarchies of men (side), inshou (impression), kanji (feeling), kibun (mood), kimochi (feeling) -The hierarchies of men (side), sokumen (oneside), imi (meaning), kanten (viewpoint), kenchi (standpoint) -The hierarchies of joutai (state), teido (degree) -The hierarchies of joutai (state), jousei (situation) -The hierarchies of men (side), inshou (impression), seikaku (character) or gaikan (appearance) or utsukushisa (beauty)." ></td>
	<td class="line x" title="124:167	The lines in Fig.8 are not peculiar, and appear in an area of the hierarchies of seikaku (characFig.3: Hierarchies of kimochi (feeling) Fig.4:Hierarchies of sokumen (one side) Fig.5:Hierarchies of teido (degree) Fig8: Hierarchies of kanshoku (feel) Fig.6: Hierarchies of jousei (situation) Fig.7:Hierarchies of seikaku (character) ter) in Fig.7." ></td>
	<td class="line x" title="125:167	As Fig.8 shows, the hierarchies of men (side), inshou (impression), kanji (feeling), kanshoku (feel) or kansei (sensitivity) are located in the area of the hierarchies of seikaku (character), above the hierarchies of kimochi (feeling) in Fig.3." ></td>
	<td class="line x" title="126:167	5. Comparison of hierarchies of superordinate nouns of adjectives." ></td>
	<td class="line x" title="127:167	We compare the hierarchy mentioned above with ones obtained from two kinds of data." ></td>
	<td class="line x" title="128:167	1) Hierarchies obtained by: CSM and Yates correction corpus occurrence data (no frequency)." ></td>
	<td class="line x" title="129:167	2) Hierarchies obtained by: Tf.CSM and Yates correction corpus frequency data." ></td>
	<td class="line x" title="130:167	3) Hierarchies obtained by: Overlap coefficient and Yates' correction corpus occurrence data (no frequency)." ></td>
	<td class="line x" title="131:167	As both CSM and the Overlap coefficient are measures of inclusion, we compared CSM and Tf.CSM with the Overlap coefficient." ></td>
	<td class="line x" title="132:167	The number of groups that were obtained by CSM, Tf.CSM and the Overlap coefficient are the following." ></td>
	<td class="line x" title="133:167	Table 2." ></td>
	<td class="line x" title="134:167	Total number of groups obtained from CSM, Tf.CSM and Ovlp (Overlap) groups CSM 161 Tf.CSM 158 Ovlp 240 The Depth of hierarchies obtained from CSM, Tf.CSM, and the Overlap coefficient are as follows: Table 3." ></td>
	<td class="line x" title="135:167	The hierarchy depth for CSM, Tf.CSM, and the Overlap coefficient In the case of CSM, there are 32 groups at depth 7, which is the greatest number of groups." ></td>
	<td class="line x" title="136:167	The greatest concentration of groups is at depth 5 to 10." ></td>
	<td class="line x" title="137:167	In the case of Tf.CSM, the greatest number of groups is 25 at depth 8." ></td>
	<td class="line x" title="138:167	The greatest concentration of groups is at depth 5 to 13." ></td>
	<td class="line x" title="139:167	In the case of the overlap coefficient, the greatest number of groups is 61 at depth 5." ></td>
	<td class="line x" title="140:167	The greatest concentration of groups is at depth 3 to 7." ></td>
	<td class="line x" title="141:167	0 10 20 30 40 50 60 70 345678910112131415 CSM Tf.CSM Ovlp From this result, we can see that hierarchies generated by Tf.CSM are relatively deep, and those generated by the Overlap coefficient are relatively shallow." ></td>
	<td class="line x" title="142:167	In the case of the Overlap coefficient, abstract nouns in lower layers are sometimes directly related to abstract nouns in the highest layers." ></td>
	<td class="line x" title="143:167	On the other hand, in hierarchies generated by CSM and Tf.CSM, abstract nouns in the highest layers are related to those in the lowest layers via abstract nouns in the middle layers." ></td>
	<td class="line x" title="144:167	The following indicates the number of overlapping hierarchies for CSM, Tf.CSM and Overlap." ></td>
	<td class="line x" title="145:167	Table 4." ></td>
	<td class="line x" title="146:167	The number of overlapping hierarchies among CSM, Tf.CSM and Overlap CSM&Tf.CSM 37 CSM&Ovlp 7 Tf.CSM&Ovlp 2 CSM&Tf.CSM&Ovlp 7 The hierarchy generated by Tf.CSM is the deepest, and includes some hierarchies generated by CSM and the Overlap coefficient." ></td>
	<td class="line x" title="147:167	The hierarchy generated by CSM is more similar to the one made by Tf.CSM than that for the Overlap coefficient: the number of completely corresponding hierarchies for CSM and Tf.CSM is 37, that for CSM and the Overlap coefficient is 7, and that for Tf.CSM and the Overlap coefficient is 2." ></td>
	<td class="line x" title="148:167	The total number of hierarchies that correspond completely between CSM, Tf.CSM and the Overlap coefficient is 7, and the number of hierarchies which are generated by two of the methods and included in the third is 57." ></td>
	<td class="line x" title="149:167	depth 3 4 5 6 7 8 9 CSM 0 3 16 27 32 23 23 Tf.CSM 1 5 10 18 13 25 11 Ovlp 32 56 61 57 21 7 2 depth 10 11 12 13 14 15 CSM 19 7 3 4 3 1 Tf.CSM 24 13 14 14 7 2 Ovlp 2 0 0 0 0 0 Figure 9." ></td>
	<td class="line x" title="150:167	Distribution of hierarchy depth for CSM, Tf.CSM, and Overlap coefficient We investigated these 64 hierarchies precisely, checking adjectives appearing at each depth as indicated by an abstract noun in this paper." ></td>
	<td class="line x" title="151:167	In 6 of these hierarchies, the same adjectives were found at all levels of the hierarchy." ></td>
	<td class="line x" title="152:167	In 14 of the remaining 58 hierarchies, the same adjectives were found in all but the deepest level." ></td>
	<td class="line x" title="153:167	These 20 hierarchies are the most plausible in the strict sense of the word." ></td>
	<td class="line x" title="154:167	Below, we give examples of these hierarchies." ></td>
	<td class="line x" title="155:167	In the next stage of this research, we intend to investigate the remaining 44 hierarchies to determine the reason for the difference in adjective content." ></td>
	<td class="line x" title="156:167	The common hyperonym: koto (matter) --men1 (side) --sokumen (one side) --imi (meaning) --kanten (viewpoint) --me2 (eyes) --mikata (view) --hyouka (evaluation) --ippou (while or grow -er and er) --ikioi (force) --sokudo (speed) --jikoku (time) --6." ></td>
	<td class="line x" title="157:167	Conclusion We have suggested how to make a hierarchy of adjectives automatically by connecting strongly-related abstract nouns in a top-down fashion." ></td>
	<td class="line x" title="158:167	We generated a word hierarchy from corpus data by using a combination of two methods: a self-organizing semantic map and a directional similarity measure." ></td>
	<td class="line x" title="159:167	As our directional similarity measure, we utilized the complementary similarity measure (CSM)." ></td>
	<td class="line x" title="160:167	Then we compared the hierarchy generated by CSM with that generated by Tf.CSM and the Overlap coefficient." ></td>
	<td class="line x" title="161:167	In the case of Tf.CSM, the hierarchy is deeper than the others because there are more abstract nouns in the middle layer." ></td>
	<td class="line x" title="162:167	In the case of the Overlap coefficient, the hierarchy is shallow, but there are more hyponyms in the lower layer than with the other two methods." ></td>
	<td class="line x" title="163:167	As a result, the hierarchies generated by CSM have more common hierarchical relations than those generated by the other two methods." ></td>
	<td class="line x" title="164:167	In future work, we will analyze common hierarchies made by the three methods in detail and examine differences among them in order to generate an abstract conceptual hierarchy of adjectives." ></td>
	<td class="line x" title="165:167	We will then compare our hierarchy with thesauri compiled manually." ></td>
	<td class="line x" title="166:167	After we have completed the experiment on Japanese adjectives, we are keen to investigate differences and similarities in adjective hyperonyms between Japanese and other languages such as English by means of our method." ></td>
	<td class="line x" title="167:167	Acknowledgement We would like to thank Dr. Masaki Murata of NICT for allowing us to use his drawing tool." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="J04-3002
Learning Subjective Language
Wiebe, Janyce M.;Wilson, Theresa;Bruce, Rebecca F.;Bell, Matthew;Martin, Melanie J.;"></td>
	<td class="line x" title="1:617	c 2004 Association for Computational Linguistics Learning Subjective Language Janyce Wiebe  Theresa Wilson  University of Pittsburgh University of Pittsburgh Rebecca Bruce  Matthew Bell  University of North Carolina University of Pittsburgh at Asheville Melanie Martin  New Mexico State University Subjectivity in natural language refers to aspects of language used to express opinions, evaluations, and speculations." ></td>
	<td class="line x" title="2:617	There are numerous natural language processing applications for which subjectivity analysis is relevant, including information extraction and text categorization." ></td>
	<td class="line x" title="3:617	The goal of this work is learning subjective language from corpora." ></td>
	<td class="line x" title="4:617	Clues of subjectivity are generated and tested, including low-frequency words, collocations, and adjectives and verbs identified using distributional similarity." ></td>
	<td class="line x" title="5:617	The features are also examined working together in concert." ></td>
	<td class="line x" title="6:617	The features, generated from different data sets using different procedures, exhibit consistency in performance in that they all do better and worse on the same data sets." ></td>
	<td class="line x" title="7:617	In addition, this article shows that the density of subjectivity clues in the surrounding context strongly affects how likely it is that a word is subjective, and it provides the results of an annotation study assessing the subjectivity of sentences with high-density features." ></td>
	<td class="line x" title="8:617	Finally, the clues are used to perform opinion piece recognition (a type of text categorization and genre detection) to demonstrate the utility of the knowledge acquired in this article." ></td>
	<td class="line x" title="9:617	1." ></td>
	<td class="line x" title="10:617	Introduction Subjectivity in natural language refers to aspects of language used to express opinions, evaluations, and speculations (Banfield 1982; Wiebe 1994)." ></td>
	<td class="line x" title="11:617	Many natural language processing (NLP) applications could benefit from being able to distinguish subjective language from language used to objectively present factual information." ></td>
	<td class="line x" title="12:617	Current extraction and retrieval technology focuses almost exclusively on the subject matter of documents." ></td>
	<td class="line x" title="13:617	However, additional aspects of a document influence its relevance, including evidential status and attitude (Kessler, Nunberg, Sch utze 1997)." ></td>
	<td class="line x" title="14:617	Information extraction systems should be able to distinguish between factual information (which should be extracted) and nonfactual information (which should be  Department of Computer Science, University of Pittsburgh, Pittsburgh, PA 15260." ></td>
	<td class="line x" title="15:617	E-mailwiebe,mbell}@cs.pitt.edu." ></td>
	<td class="line x" title="16:617	 Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA 15260." ></td>
	<td class="line x" title="17:617	Email: twilson@cs.pitt.edu." ></td>
	<td class="line x" title="18:617	 Department of Computer Science, University of North Carolina at Asheville, Asheville, NC 28804." ></td>
	<td class="line x" title="19:617	E-mail: bruce@cs.unca.edu  Department of Computer Science, New Mexico State University, Las Cruces, NM 88003." ></td>
	<td class="line x" title="20:617	E-mail: mmartin@cs.nmsu.edu." ></td>
	<td class="line x" title="21:617	Submission received: 20 March 2002; Revised submission received: 30 September 2003; Accepted for publication: 23 January 2004 278 Computational Linguistics Volume 30, Number 3 discarded or labeled as uncertain)." ></td>
	<td class="line x" title="22:617	Question-answering systems should distinguish between factual and speculative answers." ></td>
	<td class="line x" title="23:617	Multi-perspective question answering aims to present multiple answers to the user based upon speculation or opinions derived from different sources (Carbonell 1979; Wiebe et al. 2003)." ></td>
	<td class="line x" title="24:617	Multidocument summarization systems should summarize different opinions and perspectives." ></td>
	<td class="line x" title="25:617	Automatic subjectivity analysis would also be useful to perform flame recognition (Spertus 1997; Kaufer 2000), e-mail classification (Aone, Ramos-Santacruze, and Niehaus 2000), intellectual attribution in text (Teufel and Moens 2000), recognition of speaker role in radio broadcasts (Barzialy et al. 2000), review mining (Terveen et al. 1997), review classification (Turney 2002; Pang, Lee, and Vaithyanathan 2002), style in generation (Hovy 1987), and clustering documents by ideological point of view (Sack 1995)." ></td>
	<td class="line x" title="26:617	In general, nearly any information-seeking system could benefit from knowledge of how opinionated a text is and whether or not the writer purports to objectively present factual material." ></td>
	<td class="line x" title="27:617	To perform automatic subjectivity analysis, good clues must be found." ></td>
	<td class="line x" title="28:617	A huge variety of words and phrases have subjective usages, and while some manually developed resources exist, such as dictionaries of affective language (General-Inquirer 2000; Heise 2000) and subjective features in general-purpose lexicons (e.g. , the attitude adverb features in Comlex [Macleod, Grishman, and Meyers 1998]), there is no comprehensive dictionary of subjective language." ></td>
	<td class="line x" title="29:617	In addition, many expressions with subjective usages have objective usages as well, so a dictionary alone would not suffice." ></td>
	<td class="line x" title="30:617	An NLP system must disambiguate these expressions in context." ></td>
	<td class="line x" title="31:617	The goal of our work is learning subjective language from corpora." ></td>
	<td class="line x" title="32:617	In this article, we generate and test subjectivity clues and contextual features and use the knowledge we gain to recognize subjective sentences and opinionated documents." ></td>
	<td class="line x" title="33:617	Two kinds of data are available to us: a relatively small amount of data manually annotated at the expression level (i.e. , labels on individual words and phrases) of Wall Street Journal and newsgroup data and a large amount of data with existing documentlevel annotations from the Wall Street Journal (opinion pieces, such as editorials and reviews, versus nonopinion pieces)." ></td>
	<td class="line x" title="34:617	Both are used as training data to identify clues of subjectivity." ></td>
	<td class="line x" title="35:617	In addition, we cross-validate the results between the two types of annotation: The clues learned from the expression-level data are evaluated against the document-level annotations, and those learned using the document-level annotations are evaluated against the expression-level annotations." ></td>
	<td class="line x" title="36:617	There were a number of motivations behind our decision to use document-level annotations, in addition to our manual annotations, to identify and evaluate clues of subjectivity." ></td>
	<td class="line x" title="37:617	The document-level annotations were not produced according to our annotation scheme and were not produced for the purpose of training and evaluating an NLP system." ></td>
	<td class="line x" title="38:617	Thus, they are an external influence from outside the laboratory." ></td>
	<td class="line x" title="39:617	In addition, there are a great number of these data, enabling us to evaluate the results on a larger scale, using multiple large test sets." ></td>
	<td class="line x" title="40:617	This and cross-training between the two types of annotations allows us to assess consistency in performance of the various identification procedures." ></td>
	<td class="line x" title="41:617	Good performance in cross-validation experiments between different types of annotations is evidence that the results are not brittle." ></td>
	<td class="line x" title="42:617	We focus on three types of subjectivity clues." ></td>
	<td class="line x" title="43:617	The first are hapax legomena, the set of words that appear just once in the corpus." ></td>
	<td class="line x" title="44:617	We refer to them here as unique words." ></td>
	<td class="line x" title="45:617	The set of all unique words is a feature with high frequency and significantly higher precision than baseline (Section 3.2)." ></td>
	<td class="line x" title="46:617	The second are collocations (Section 3.3)." ></td>
	<td class="line x" title="47:617	We demonstrate a straightforward method for automatically identifying collocational clues of subjectivity in texts." ></td>
	<td class="line x" title="48:617	The method is first used to identify fixed n-grams, such as of the century and get out of here." ></td>
	<td class="line x" title="49:617	Interest279 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language ingly, many include noncontent words that are typically on stop lists of NLP systems (e.g. , of, the, get, out, here in the above examples)." ></td>
	<td class="line x" title="50:617	The method is then used to identify an unusual form of collocation: One or more positions in the collocation may be filled by any word (of an appropriate part of speech) that is unique in the test data." ></td>
	<td class="line x" title="51:617	The third type of subjectivity clue we examine here are adjective and verb features identified using the results of a method for clustering words according to distributional similarity (Lin 1998) (Section 3.4)." ></td>
	<td class="line x" title="52:617	We hypothesized that two words may be distributionally similar because they are both potentially subjective (e.g. , tragic, sad, and poignant are identified from bizarre)." ></td>
	<td class="line x" title="53:617	In addition, we use distributional similarity to improve estimates of unseen events: A word is selected or discarded based on the precision of it together with its n most similar neighbors." ></td>
	<td class="line x" title="54:617	We show that the various subjectivity clues perform better and worse on the same data sets, exhibiting an important consistency in performance (Section 4.2)." ></td>
	<td class="line x" title="55:617	In addition to learning and evaluating clues associated with subjectivity, we address disambiguating them in context, that is, identifying instances of clues that are subjective in context (Sections 4.3 and 4.4)." ></td>
	<td class="line x" title="56:617	We find that the density of clues in the surrounding context is an important influence." ></td>
	<td class="line x" title="57:617	Using two types of annotations serves us well here, too." ></td>
	<td class="line x" title="58:617	It enables us to use manual judgments to identify parameters for disambiguating instances of automatically identified clues." ></td>
	<td class="line x" title="59:617	High-density clues are high precision in both the expression-level and document-level data." ></td>
	<td class="line x" title="60:617	In addition, we give the results of a new annotation study showing that most high-density clues are in subjective text spans (Section 4.5)." ></td>
	<td class="line x" title="61:617	Finally, we use the clues together to perform documentlevel classification, to further demonstrate the utility of the acquired knowledge (Section 4.6)." ></td>
	<td class="line x" title="62:617	At the end of the article, we discuss related work (Section 5) and conclusions (Section 6)." ></td>
	<td class="line x" title="63:617	2." ></td>
	<td class="line x" title="64:617	Subjectivity Subjective language is language used to express private states in the context of a text or conversation." ></td>
	<td class="line x" title="65:617	Private state is a general covering term for opinions, evaluations, emotions, and speculations (Quirk et al. 1985)." ></td>
	<td class="line x" title="66:617	The following are examples of subjective sentences from a variety of document types." ></td>
	<td class="line x" title="67:617	The first two examples are from Usenet newsgroup messages: (1) I had in mind your facts, buddy, not hers." ></td>
	<td class="line x" title="68:617	(2) Nice touch." ></td>
	<td class="line x" title="69:617	Alleges whenever facts posted are not in your persona of what is real. The next one is from an editorial: (3) We stand in awe of the Woodstock generations ability to be unceasingly fascinated by the subject of itself." ></td>
	<td class="line x" title="70:617	(Bad Acid, Wall Street Journal, August 17, 1989) The next example is from a book review: (4) At several different layers, its a fascinating tale." ></td>
	<td class="line x" title="71:617	(George Melloan, Whose Spying on Our Computers? Wall Street Journal, November 1, 1989) 280 Computational Linguistics Volume 30, Number 3 The last one is from a news story: (5) The cost of health care is eroding our standard of living and sapping industrial strength, complains Walter Maher, a Chrysler health-and-benefits specialist." ></td>
	<td class="line x" title="72:617	(Kenneth H. Bacon, Business and Labor Reach a Consensus on Need to Overhaul Health-Care System, Wall Street Journal, November 1, 1989) In contrast, the following are examples of objective sentences, sentences without significant expressions of subjectivity: (6) Bell Industries Inc. increased its quarterly to 10 cents from 7 cents a share." ></td>
	<td class="line x" title="73:617	(7) Northwest Airlines settled the remaining lawsuits filed on behalf of 156 people killed in a 1987 crash, but claims against the jetliners maker are being pursued, a federal judge said." ></td>
	<td class="line x" title="74:617	(Northwest Airlines Settles Rest of Suits, Wall Street Journal, November 1, 1989) A particular model of linguistic subjectivity underlies the current and past research in this area by Wiebe and colleagues." ></td>
	<td class="line x" title="75:617	It is most fully presented in Wiebe and Rapaport (1986, 1988, 1991) and Wiebe (1990, 1994)." ></td>
	<td class="line x" title="76:617	It was developed to support NLP research and combines ideas from several sources in fields outside NLP, especially linguistics and literary theory." ></td>
	<td class="line x" title="77:617	The most direct influences on the model were Dolezel (1973) (types of subjectivity clues), Uspensky (1973) (types of point of view), Kuroda (1973, 1976) (pragmatics of point of view), Chatman (1978) (story versus discourse), Cohn (1978) (linguistic styles for presenting consciousness), Fodor (1979) (linguistic description of opaque contexts), and especially Banfield (1982) (theory of subjectivity versus communication)." ></td>
	<td class="line x" title="78:617	1 The remainder of this section sketches our conceptualization of subjectivity and describes the annotation projects it underlies." ></td>
	<td class="line x" title="79:617	Subjective elements are linguistic expressions of private states in context." ></td>
	<td class="line x" title="80:617	Subjective elements are often lexical (examples are stand in awe, unceasingly, fascinated in (3) and eroding, sapping, and complains in (5))." ></td>
	<td class="line x" title="81:617	They may be single words (e.g. , complains) or more complex expressions (e.g. , stand in awe, what a NP)." ></td>
	<td class="line x" title="82:617	Purely syntactic or morphological devices may also be subjective elements (e.g. , fronting, parallelism, changes in aspect)." ></td>
	<td class="line x" title="83:617	A subjective element expresses the subjectivity of a source, who may be the writer or someone mentioned in the text." ></td>
	<td class="line x" title="84:617	For example, the source of fascinating in (4) is the writer, while the source of the subjective elements in (5) is Maher (according to the writer)." ></td>
	<td class="line x" title="85:617	In addition, a subjective element usually has a target, that is, what the subjectivity is about or directed toward." ></td>
	<td class="line x" title="86:617	In (4), the target is a tale; in (5), the target of Mahers subjectivity is the cost of health care." ></td>
	<td class="line x" title="87:617	Note our parenthetical aboveaccording to the writerconcerning Mahers subjectivity." ></td>
	<td class="line x" title="88:617	Maher is not directly speaking to us but is being quoted by the writer." ></td>
	<td class="line x" title="89:617	Thus, the source is a nested source, which we notate (writer, Maher); this represents the fact that the subjectivity is being attributed to Maher by the writer." ></td>
	<td class="line x" title="90:617	Since sources 1 For additional citations to relevant work from outside NLP, please see Banfield (1982), Fludernik (1993), Wiebe (1994), and Stein and Wright (1995)." ></td>
	<td class="line x" title="91:617	281 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language are not directly addressed by the experiments presented in this article, we merely illustrate the idea here with an example, to give the reader an idea: The Foreign Ministry said Thursday that it was surprised, to put it mildly by the U.S. State Departments criticism of Russias human rights record and objected in particular to the odious section on Chechnya." ></td>
	<td class="line x" title="92:617	(Moscow Times, March 8, 2002] Let us consider some of the subjective elements in this sentence, along with their sources: surprised, to put it mildly: (writer, Foreign Ministry, Foreign Ministry) to put it mildly: (writer, Foreign Ministry) criticism: (writer, Foreign Ministry, Foreign Ministry, U.S. State Department) objected: (writer, Foreign Ministry) odious: (writer, Foreign Ministry) Consider surprised, to put it mildly." ></td>
	<td class="line x" title="93:617	This refers to a private state of the Foreign Ministry (i.e. , it is very surprised)." ></td>
	<td class="line x" title="94:617	This is in the context of The Foreign Ministry said, which is in a sentence written by the writer." ></td>
	<td class="line x" title="95:617	This gives us the three-level source (writer, Foreign Ministry, Foreign Ministry)." ></td>
	<td class="line x" title="96:617	The phrase to put it mildly, which expresses sarcasm, is attributed to the Foreign Ministry by the writer (i.e. , according to the writer, the Foreign Ministry said this)." ></td>
	<td class="line x" title="97:617	So its source is (writer, Foreign Ministry)." ></td>
	<td class="line x" title="98:617	The subjective element criticism has a deeply nested source: According to the writer, the Foreign Ministry said it is surprised by the U.S. State Departments criticism." ></td>
	<td class="line x" title="99:617	The nested-source representation allows us to pinpoint the subjectivity in a sentence." ></td>
	<td class="line x" title="100:617	For example, there is no subjectivity attributed directly to the writer in the above sentence: At the level of the writer, the sentence merely says that someone said something and objected to something (without evaluating or questioning this)." ></td>
	<td class="line x" title="101:617	If the sentence started The magnificent Foreign Ministry said, then we would have an additional subjective element, magnificent, with source (writer)." ></td>
	<td class="line x" title="102:617	Note that subjective does not mean not true." ></td>
	<td class="line x" title="103:617	Consider the sentence John criticized Mary for smoking." ></td>
	<td class="line x" title="104:617	The verb criticized is a subjective element, expressing negative evaluation, with nested source (writer, John)." ></td>
	<td class="line x" title="105:617	But this does not mean that John does not believe that Mary smokes." ></td>
	<td class="line x" title="106:617	(In addition, the fact that John criticized Mary is being presented as true by the writer.)" ></td>
	<td class="line x" title="107:617	Similarly, objective does not mean true." ></td>
	<td class="line x" title="108:617	A sentence is objective if the language used to convey the information suggests that facts are being presented; in the context of the discourse, material is objectively presented as if it were true." ></td>
	<td class="line x" title="109:617	Whether or not the source truly believes the information, and whether or not the information is in fact true, are considerations outside the purview of a theory of linguistic subjectivity." ></td>
	<td class="line x" title="110:617	An aspect of subjectivity highlighted when we are working with NLP applications is ambiguity." ></td>
	<td class="line x" title="111:617	Many words with subjective usages may be used objectively." ></td>
	<td class="line x" title="112:617	Examples are sapping and eroding." ></td>
	<td class="line x" title="113:617	In (5), they are used subjectively, but one can easily imagine objective usages, in a scientific domain, for example." ></td>
	<td class="line x" title="114:617	Thus, an NLP system may not merely consult a list of lexical items to accurately identify subjective language but must disambiguate words, phrases, and sentences in context." ></td>
	<td class="line x" title="115:617	In our terminology, a potential subjective element (PSE) is a linguistic element that may be used to express 282 Computational Linguistics Volume 30, Number 3 Table 1 Data Sets and Annotations used in Experiments." ></td>
	<td class="line x" title="116:617	Annotators M, MM, and T are co-authors of this paper." ></td>
	<td class="line x" title="117:617	D and R are not." ></td>
	<td class="line x" title="118:617	Name Source Number of Words Annotators Type of annotation WSJ-SE Wall Street Journal 18,341 D,M Subjective elements NG-SE Newsgroup 15,413 M Subjective elements NG-FE Newsgroup 88,210 MM,R Flame elements OP1 Wall Street Journal 640,975 M,T Documents Composed of 4 data sets: W9-4,W9-10,W9-22,W-33 OP2 Wall Street Journal 629,690 M,T Documents Composed of 4 data sets: W9-2,W9-20,W9-21,W-23 subjectivity." ></td>
	<td class="line x" title="119:617	A subjective element is an instance of a potential subjective element, in a particular context, that is indeed subjective in that context (Wiebe 1994)." ></td>
	<td class="line x" title="120:617	In this article, we focus on learning lexical items that are associated with subjectivity (i.e. , PSEs) and then using them in concert to disambiguate instances of them (i.e. , to determine whether the instances are subjective elements)." ></td>
	<td class="line x" title="121:617	2.1 Manual Annotations In our subjectivity annotation projects, we do not give the annotators lists of particular words and phrases to look for." ></td>
	<td class="line x" title="122:617	Rather, we ask them to label sentences according to their interpretations in context." ></td>
	<td class="line x" title="123:617	As a result, the annotators consider a large variety of expressions when performing annotations." ></td>
	<td class="line x" title="124:617	We use data that have been manually annotated at the expression level, the sentence level, and the document level." ></td>
	<td class="line x" title="125:617	For diversity, we use data from the Wall Street Journal Treebank as well as data from a corpus of Usenet newsgroup messages." ></td>
	<td class="line x" title="126:617	Table 1 summarizes the data sets and annotations used in this article." ></td>
	<td class="line x" title="127:617	None of the datasets overlap." ></td>
	<td class="line x" title="128:617	The annotation types listed in the table are those used in the experiments presented in this article." ></td>
	<td class="line x" title="129:617	In our first subjectivity annotation project (Wiebe, Bruce, and OHara 1999; Bruce and Wiebe 1999), a corpus of sentences from the Wall Street Journal Treebank Corpus (Marcus, Santorini, and Marcinkiewicz 1993) (corpus WSJ-SE in Table 1) was annotated at the sentence level by multiple judges." ></td>
	<td class="line x" title="130:617	The judges were instructed to classify a sentence as subjective if it contained any significant expressions of subjectivity, attributed to either the writer or someone mentioned in the text, and to classify the sentence as objective, otherwise." ></td>
	<td class="line x" title="131:617	After multiple rounds of training, the annotators independently annotated a fresh test set of 500 sentences from WSJ-SE." ></td>
	<td class="line x" title="132:617	They achieved an average pairwise kappa score of 0.70 over the entire test set, an average pairwise kappa score of 0.80 for the 85% of the test set for which the annotators were somewhat sure of their judgments, and an average pairwise kappa score of 0.88 for the 70% of the test set for which the annotators were very sure of their judgments." ></td>
	<td class="line x" title="133:617	We later asked the same annotators to identify the subjective elements in WSJSE." ></td>
	<td class="line x" title="134:617	Specifically, each annotator was given the subjective sentences he identified in 283 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language the previous study and asked to put brackets around the words he believed caused the sentence to be classified as subjective." ></td>
	<td class="line x" title="135:617	2 For example (subjective elements are in parentheses): They paid (yet) more for (really good stuff)." ></td>
	<td class="line x" title="136:617	(Perhaps youll forgive me) for reposting his response." ></td>
	<td class="line x" title="137:617	No other instructions were given to the annotators and no training was performed for the expression-level task." ></td>
	<td class="line x" title="138:617	A single round of tagging was performed, with no communication between annotators." ></td>
	<td class="line x" title="139:617	There are techniques for analyzing agreement when annotations involve segment boundaries (Litman and Passonneau 1995; Marcu, Romera, and Amorortu 1999), but our focus in this article is on words." ></td>
	<td class="line x" title="140:617	Thus, our analyses are at the word level: Each word is classified as either appearing in a subjective element or not." ></td>
	<td class="line x" title="141:617	Punctuation and numbers are excluded from the analyses." ></td>
	<td class="line x" title="142:617	The kappa value for word agreement in this study is 0.42." ></td>
	<td class="line x" title="143:617	Another two-level annotation project was performed in Wiebe et al.(2001), this time involving document-level and expression-level annotations of newsgroup data (NG-FE in Table 1)." ></td>
	<td class="line x" title="145:617	In that project, we were interested in annotating flames, inflammatory messages in newsgroups or listservs." ></td>
	<td class="line x" title="146:617	Note that inflammatory language is a kind of subjective language." ></td>
	<td class="line x" title="147:617	The annotators were instructed to mark a message as a flame if the main intention of the message is a personal attack and the message contains insulting or abusive language." ></td>
	<td class="line x" title="148:617	After multiple rounds of training, three annotators independently annotated a fresh test set of 88 messages from NG-FE." ></td>
	<td class="line x" title="149:617	The average pairwise percentage agreement is 92% and the average pairwise kappa value is 0.78." ></td>
	<td class="line x" title="150:617	These results are comparable to those of Spertus (1997), who reports 98% agreement on noninflammatory messages and 64% agreement on inflammatory messages." ></td>
	<td class="line x" title="151:617	Two of the annotators were then asked to identify the flame elements in the entire corpus NG-FE." ></td>
	<td class="line x" title="152:617	Flame elements are the subset of subjective elements that are perceived to be inflammatory." ></td>
	<td class="line x" title="153:617	The two annotators were asked to do this in the entire corpus, even those messages not identified as flames, because messages that were not judged to be flames at the document level may contain some individual inflammatory phrases." ></td>
	<td class="line x" title="154:617	As above, no training was performed for the expression-level task, and a single round of tagging was performed, without communication between annotators." ></td>
	<td class="line x" title="155:617	Agreement was measured in the same way as in the subjective-element study above." ></td>
	<td class="line x" title="156:617	The kappa value for flame element annotations in corpus NG-FE is 0.46." ></td>
	<td class="line x" title="157:617	An additional annotation project involved a single annotator, who performed subjective-element annotations on the newsgroup corpus NG-SE." ></td>
	<td class="line x" title="158:617	The agreement results above suggest that good levels of agreement can be achieved at higher levels of classification (sentence and document), but agreement at the expression level is more challenging." ></td>
	<td class="line x" title="159:617	The agreement values are lower for the expression-level annotations but are still much higher than that expected by chance." ></td>
	<td class="line x" title="160:617	Note that our word-based analysis of agreement is a tough measure, because it requires that exactly the same words be identified by both annotators." ></td>
	<td class="line x" title="161:617	Consider the following example from WSJ-SE: D: (played the role well) (obligatory ragged jeans a thicket of long hair and rejection of all things conventional) 2 We are grateful to Aravind Joshi for suggesting this level of annotation." ></td>
	<td class="line x" title="162:617	284 Computational Linguistics Volume 30, Number 3 M: played the role (well) (obligatory) (ragged) jeans a (thicket) of long hair and (rejection) of (all things conventional) Judge D in the example consistently identifies entire phrases as subjective, while judge M prefers to select discrete lexical items." ></td>
	<td class="line x" title="163:617	Despite such differences between annotators, the expression-level annotations proved very useful for exploring hypotheses and generating features, as described below." ></td>
	<td class="line x" title="164:617	Since this article was written, a new annotation project has been completed." ></td>
	<td class="line x" title="165:617	A 10,000-sentence corpus of English-language versions of world news articles has been annotated with detailed subjectivity information as part of a project investigating multiple-perspective question answering (Wiebe et al. 2003)." ></td>
	<td class="line x" title="166:617	These annotations are much more detailed than the annotations used in this article (including, for example, the source of each private state)." ></td>
	<td class="line x" title="167:617	The interannotator agreement scores for the new corpus are high and are improvements over the results of the studies described above (Wilson and Wiebe 2003)." ></td>
	<td class="line x" title="168:617	The current article uses existing document-level subjective classes, namely editorials, letters to the editor, Arts & Leisure reviews, and Viewpoints in the Wall Street Journal." ></td>
	<td class="line x" title="169:617	These are subjective classes in the sense that they are text categories for which subjectivity is a key aspect." ></td>
	<td class="line x" title="170:617	We refer to them collectively as opinion pieces." ></td>
	<td class="line x" title="171:617	All other types of documents in the Wall Street Journal are collectively referred to as nonopinion pieces." ></td>
	<td class="line x" title="172:617	Note that opinion pieces are not 100% subjective." ></td>
	<td class="line x" title="173:617	For example, editorials contain objective sentences presenting facts supporting the writers argument, and reviews contain sentences objectively presenting facts about the product beign reviewed." ></td>
	<td class="line x" title="174:617	Similarly, nonopinion pieces are not 100% objective." ></td>
	<td class="line x" title="175:617	News reports present opinions and reactions to reported events (van Dijk 1988); they often contain segments starting with expressions such as critics claim and supporters argue." ></td>
	<td class="line x" title="176:617	In addition, quoted-speech sentences in which individuals express their subjectivity are often included (Barzilay et al. 2000)." ></td>
	<td class="line x" title="177:617	For concreteness, let us consider WSJ-SE, which, recall, has been manually annotated at the sentence level." ></td>
	<td class="line x" title="178:617	In WSJ-SE, 70% of the sentences in opinion pieces are subjective and 30% are objective." ></td>
	<td class="line x" title="179:617	In nonopinion pieces, 44% of the sentences are subjective and only 56% are objective." ></td>
	<td class="line x" title="180:617	Thus, while there is a higher concentration of subjective sentences in opinion versus nonopinion pieces, there are many subjective sentences in nonopinion pieces and objective sentences in opinion pieces." ></td>
	<td class="line x" title="181:617	An inspection of some data reveals that some editorial and review articles are not marked as such by the Wall Street Journal." ></td>
	<td class="line x" title="182:617	For example, there are articles whose purpose is to present an argument rather than cover a news story, but they are not explicitly labeled as editorials by the Wall Street Journal." ></td>
	<td class="line x" title="183:617	Thus, the opinion piece annotations of data sets OP1 and OP2 in Table 1 have been manually refined." ></td>
	<td class="line x" title="184:617	The annotation instructions were simply to identify any additional opinion pieces that were not marked as such." ></td>
	<td class="line x" title="185:617	To test the reliability of this annotation, two judges independently annotated two Wall Street Journal files, W9-22 and W9-33, each containing approximately 160,000 words." ></td>
	<td class="line x" title="186:617	This is an annotation lite task: With no training, the annotators achieved kappa values of 0.94 and 0.95, and each spent an average of three hours per Wall Street Journal file." ></td>
	<td class="line x" title="187:617	3." ></td>
	<td class="line x" title="188:617	Generating and Testing Subjective Features 3.1 Introduction The goal in this section is to learn lexical subjectivity clues of various types, single words as well as collocations." ></td>
	<td class="line x" title="189:617	Some require no training data, some are learned us285 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language ing the expression-level subjective-element annotations as training data, and some are learned using the document-level opinion piece annotations as training data (i.e. , opinion piece versus nonopinion piece)." ></td>
	<td class="line x" title="190:617	All of the clues are evaluated with respect to the document-level opinion piece annotations." ></td>
	<td class="line x" title="191:617	While these evaluations are our focus, because many more opinion piece than subjective-element data exist, we do evaluate the clues learned from the opinion piece data on the subjective-element data as well." ></td>
	<td class="line x" title="192:617	Thus, we cross-validate the results both ways between the two types of annotations." ></td>
	<td class="line x" title="193:617	Throughout this section, we evaluate sets of clues directly, by measuring the proportion of clues that appear in subjective documents or expressions, seeking those that appear more often than expected." ></td>
	<td class="line x" title="194:617	In later sections, the clues are used together to find subjective sentences and to perform text categorization." ></td>
	<td class="line x" title="195:617	The following paragraphs give details of the evaluation and experimental design used in this section." ></td>
	<td class="line x" title="196:617	The proportion of clues in subjective documents or expressions is their precision." ></td>
	<td class="line x" title="197:617	Specifically, the precision of a set S with respect to opinion pieces is prec(S)= number of instances of members of S in opinion pieces total number of instances of members of S in the data The precision of a set S with respect to subjective elements is prec(S)= number of instances of members of S in subjective elements total number of instances of members of S in the data In the above, S is a set of types (not tokens)." ></td>
	<td class="line x" title="198:617	The counts are of tokens (i.e. , instances or occurrences) of members of S. Why use a set rather than individual items?" ></td>
	<td class="line x" title="199:617	Many good clues of subjectivity occur with low frequency (Wiebe, McKeever, and Bruce 1998)." ></td>
	<td class="line x" title="200:617	In fact, as we shall see below, uniqueness in the corpus is an informative feature for subjectivity classification." ></td>
	<td class="line x" title="201:617	Thus, we do not want to discard low-frequency clues, because they are a valuable source of information, and we do not want to evaluate individual low-frequency lexical items, because the results would be unreliable." ></td>
	<td class="line x" title="202:617	Our strategy is thus to identify and evaluate sets of words and phrases, rather than individual items." ></td>
	<td class="line x" title="203:617	What kinds of results may we expect?" ></td>
	<td class="line x" title="204:617	We cannot expect absolutely high precision with respect to the opinion piece classifications, even for strong clues, for three reasons." ></td>
	<td class="line x" title="205:617	First, for our purposes, the data are noisy." ></td>
	<td class="line x" title="206:617	As mentioned above, while the proportion of subjective sentences is higher in opinion than in nonopinion pieces, the proportions are not 100 and 0: Opinion pieces contain objective sentences, and nonopinion pieces contain subjective sentences." ></td>
	<td class="line x" title="207:617	Second, we are trying to learn lexical items associated with subjectivity, that is, PSEs." ></td>
	<td class="line x" title="208:617	As discussed above, many words and phrases with subjective usages have objective usages as well." ></td>
	<td class="line x" title="209:617	Thus, even in perfect data with no noise, we would not expect 100% precision." ></td>
	<td class="line x" title="210:617	(This is the motivation for the work on density presented in section 4.4.) Third, the distribution of opinions and nonopinions is highly skewed in favor of nonopinions: Only 9% of the articles in the combination of OP1 and OP2 are opinion pieces." ></td>
	<td class="line x" title="211:617	In this work, increases in precision over a baseline precision are used as evidence that promising sets of PSEs have been found." ></td>
	<td class="line x" title="212:617	Our main baseline for comparison is the number of word instances in opinion pieces, divided by the total number of word instances: Baseline Precision = number of word instances in opinion pieces total number of word instances 286 Computational Linguistics Volume 30, Number 3 Table 2 Frequencies and increases in precision of unique words in subjective-element data." ></td>
	<td class="line x" title="213:617	Baseline frequency is the total number of words, and baseline precision is the proportion of words in subjective elements." ></td>
	<td class="line x" title="214:617	WSJ-SE D M freq +prec +prec Unique words 2,615 +.07 +.12 Baseline 18,341.07 .08 Words and phrases with higher proportions than this appear more than expected in opinion pieces." ></td>
	<td class="line x" title="215:617	To further evaluate the quality of a set of PSEs, we also perform the following significance test." ></td>
	<td class="line x" title="216:617	For a set of PSEs in a given data set, we test the significance of the difference between (1) the proportion of words in opinion pieces that are PSEs and (2) the proportion of words in nonopinion pieces that are PSEs, using the z-significance test for two proportions." ></td>
	<td class="line x" title="217:617	Before we continue, there are a few more technical items to mention concerning the data preparation and experimental design:  All of the data sets are stemmed using Karps morphological analyzer (Karp et al. 1994) and part-of-speech tagged using Brills (1992) tagger." ></td>
	<td class="line x" title="218:617	 When the opinion piece classifications are used for training, the existing classifications, assigned by the Wall Street Journal, are used." ></td>
	<td class="line x" title="219:617	Thus, the processes using them as training data may be applied to more data to learn more clues, without requiring additional manual annotation." ></td>
	<td class="line x" title="220:617	 When the opinion piece data are used for testing, the manually refined classifications (described at the end of Section 2.1) are used." ></td>
	<td class="line x" title="221:617	 OP1 and OP2 together comprise eight treebank files." ></td>
	<td class="line x" title="222:617	Below, we often give results separately for the component files, allowing us to assess the consistency of results for the various types of clues." ></td>
	<td class="line x" title="223:617	3.2 Unique Words In this section, we show that low-frequency words are associated with subjectivity in both the subjective-element and opinion piece data." ></td>
	<td class="line x" title="224:617	Apparently, people are creative when they are being opinionated." ></td>
	<td class="line x" title="225:617	Table 2 gives results for unique words in subjective-element data." ></td>
	<td class="line x" title="226:617	Recall that unique words are those that appear just once in the corpus, that is, hapax legomena." ></td>
	<td class="line x" title="227:617	The first row of Table 2 gives the frequency of unique words in WSJ-SE, followed by the percentage-point improvements in precision over baseline for unique words in subjective elements marked by two annotators (denoted as D and M in the table)." ></td>
	<td class="line x" title="228:617	The second row gives baseline frequency and precisions." ></td>
	<td class="line x" title="229:617	Baseline frequency is the total number of words in WSJ-SE." ></td>
	<td class="line x" title="230:617	Baseline precision for an annotator is the proportion of words included in subjective elements by that annotator." ></td>
	<td class="line x" title="231:617	Specifically, consider annotator M. The baseline precision of words in subjective elements marked by M is 0.08, 287 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language Table 3 Frequencies and increases in precision for words that appear exactly once in the data sets composing OP1." ></td>
	<td class="line x" title="232:617	For each data set, baseline frequency is the total number of words, and baseline precision is the proportion of words in opinion pieces." ></td>
	<td class="line x" title="233:617	W9-04 W9-10 W9-22 W9-33 freq +prec freq +prec freq +prec freq +prec Unique words 4,794 +.15 4,763 +.16 4,274 +.11 4,567 +.11 Baseline 156,421 .19 156,334 .18 155,135 .13 153,634 .14 but the precision of unique words in these same annotations is 0.20, 0.12 points higher than the baseline." ></td>
	<td class="line x" title="234:617	This is a 150% improvement over the baseline." ></td>
	<td class="line x" title="235:617	The number of unique words in opinion pieces is also higher than expected." ></td>
	<td class="line x" title="236:617	Table 3 compares the precision of the set of unique words to the baseline precision (i.e. , the precision of the set of all words that appear in the corpus) in the four WSJ files composing OP1." ></td>
	<td class="line x" title="237:617	Before this analysis was performed, numbers were removed from the data (we are not interested in the fact that, say, the number 163,213.01 appears just once in the corpus)." ></td>
	<td class="line x" title="238:617	The number of words in each data set and baseline precisions are listed at the bottom of the table." ></td>
	<td class="line x" title="239:617	The freq columns give total frequencies." ></td>
	<td class="line x" title="240:617	The +prec columns show the percentage-point improvements in precision over baseline." ></td>
	<td class="line x" title="241:617	For example, in W9-10, unique words have precision 0.34: 0.18 baseline plus an improvement over baseline of 0.16." ></td>
	<td class="line x" title="242:617	The difference in the proportion of words that are unique in opinion pieces and the proportion of words that are unique in nonopinion pieces is highly significant, with p < 0.001 (z  22) for all of the data sets." ></td>
	<td class="line x" title="243:617	Note that not only does the set of unique words have higher than baseline precision, the set is a frequent feature." ></td>
	<td class="line x" title="244:617	The question arises, how does corpus size affect the precision of the set of unique words?" ></td>
	<td class="line x" title="245:617	Presumably, uniqueness in a larger corpus is more meaningful than uniqueness in a smaller one." ></td>
	<td class="line x" title="246:617	The results in Figure 1 provide evidence that it is. The y-axis in Figure 1 represents increase in precision over baseline and the x-axis represents corpus size." ></td>
	<td class="line x" title="247:617	Five graphs are plotted, one for the set of words that appear exactly once (uniques), one for the set of words that appear exactly twice ( freq2), one for the set of words that appear exactly three times ( freq3), etc. In Figure 1, increases in precision are given for corpora of size n, where n = 20, 40,, 2420, 2440 documents." ></td>
	<td class="line x" title="248:617	Each data point is an average over 25 sample corpora of size n. The sample corpora were chosen from the concatenation of OP1 and OP2, in which 9% of the documents are opinion pieces." ></td>
	<td class="line x" title="249:617	The sample corpora were created by randomly selecting documents from the large corpus, preserving the 9% distribution of opinion pieces." ></td>
	<td class="line x" title="250:617	At the smallest corpus size (containing 20 documents), the average number of words is 9,617." ></td>
	<td class="line x" title="251:617	At the largest corpus size (containing 2440 documents), the average is 1,225,186 words." ></td>
	<td class="line x" title="252:617	As can be seen in the figure, the precision of unique and other low-frequency words increases with corpus size, with increases tapering off at the largest corpus size tested." ></td>
	<td class="line x" title="253:617	Words with frequency 2 also realize a nice increase, although one that is not as dramatic, in precision over baseline." ></td>
	<td class="line x" title="254:617	Even words of frequency 3, 4, and 5 show modest increases." ></td>
	<td class="line x" title="255:617	To help us understand the importance of low-frequency words in large as opposed to small data sets, we can consider the following analogy." ></td>
	<td class="line x" title="256:617	With collectible trading cards, rare cards are the most valuable." ></td>
	<td class="line x" title="257:617	However, if we have some cards and are trying to determine thier value, looking in only a few packs of cards will not tell us if 288 Computational Linguistics Volume 30, Number 3 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 20 620 1220 1820 2420 Corpus Size (documents) Increase in Precision uniques freq2 freq3 freq4 freq5 Figure 1 Precision of low-frequency words as corpus size increases." ></td>
	<td class="line x" title="258:617	any of our cards are valuable." ></td>
	<td class="line x" title="259:617	Only by looking at many packs of cards can we make a determination as to which are the rare ones." ></td>
	<td class="line x" title="260:617	Only in samples of sufficient size is uniqueness informative." ></td>
	<td class="line x" title="261:617	The results in this section suggest that an NLP system using uniqueness features to recognize subjectivity should determine uniqueness with respect to the test data augmented with an additional store of (unannotated) data." ></td>
	<td class="line x" title="262:617	3.3 Identifying Potentially Subjective Collocations from Subjective-Element and Flame-Element Annotations In this section, we describe experiments in identifying potentially subjective collocations." ></td>
	<td class="line x" title="263:617	Collocations are selected from the subjective-element data (i.e. , NG-SE, NG-FE, and WSJ-SE), using the union of the annotators tags for the data sets tagged by multiple taggers." ></td>
	<td class="line x" title="264:617	The results are then evaluated on opinion piece data." ></td>
	<td class="line x" title="265:617	The selection procedure is as follows." ></td>
	<td class="line x" title="266:617	First, all 1-grams, 2-grams, 3-grams, and 4-grams are extracted from the data." ></td>
	<td class="line x" title="267:617	In this work, each constituent of an n-gram is a word-stem, part-of-speech pair." ></td>
	<td class="line x" title="268:617	For example, (in-prep the-det can-noun) is a 3-gram that matches trigrams consisting of preposition in, followed by determiner the, and ending with noun can." ></td>
	<td class="line x" title="269:617	A subset of the n-grams are then selected based on precision." ></td>
	<td class="line x" title="270:617	The precision of an n-gram is the number of subjective instances of that n-gram in the data divided by the total number of instances of that n-gram in the data." ></td>
	<td class="line x" title="271:617	An instance of an n-gram is subjective if each word occurs in a subjective element in the data." ></td>
	<td class="line x" title="272:617	n-grams are selected based on two criteria." ></td>
	<td class="line x" title="273:617	First, the precision of the n-gram must be greater than the baseline precision (i.e. , the proportion of all word instances that 289 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language are in subjective elements)." ></td>
	<td class="line x" title="274:617	Second, the precision of the n-gram must be greater than the maximum precision of its constituents." ></td>
	<td class="line x" title="275:617	This criterion is used to avoid selecting unnecessarily long collocations." ></td>
	<td class="line x" title="276:617	For example, scumbag is a strongly subjective clue." ></td>
	<td class="line x" title="277:617	If be a scumbag does not have higher precision than scumbag alone, we do not want to select it." ></td>
	<td class="line x" title="278:617	Specifically, let (W1, W2) be a bigram consisting of consecutive words W1 and W2." ></td>
	<td class="line x" title="279:617	(W1,W2) is identified as a potential subjective element if prec(W1, W2)  0.1 and: prec(W1, W2) > max(prec(W1), prec(W2)) For trigrams, we extend the second condition as follows." ></td>
	<td class="line x" title="280:617	Let (W1, W2, W3) be a trigram consisting of consecutive words W1, W2, and W3." ></td>
	<td class="line x" title="281:617	The condition is then prec(W1, W2, W3) > max(prec(W1, W2), prec(W3)) or prec(W1, W2, W3) > max(prec(W1), prec(W2, W3)) The selection of 4-grams is similar to the selection of 3-grams, comparing the 4-gram first with the maximum of the precisions of word W1 and trigram (W2, W3, W4) and then with the maximum of the precisions of trigram (W1,W2,W3) and word W4." ></td>
	<td class="line x" title="282:617	We call the n-gram collocations identified as above fixed-n-grams." ></td>
	<td class="line x" title="283:617	We also define a type of collocation called a unique generalized n-gram (ugen-ngram)." ></td>
	<td class="line x" title="284:617	Such collocations have placeholders for unique words." ></td>
	<td class="line x" title="285:617	As will be seen below, these are our highest-precision features." ></td>
	<td class="line x" title="286:617	To find and select such generalized collocations, we first find every word that appears just once in the corpus and replace it with a new word, UNIQUE (but remembering the part of speech of the original word)." ></td>
	<td class="line x" title="287:617	In essence, we treat the set of single-instance words as a single, frequently occurring word (which occurs with various parts of speech)." ></td>
	<td class="line x" title="288:617	Precisely the same method used for extracting and selecting n-grams above is used to obtain the potentially subjective collocations with one or more positions filled by a UNIQUE, part-of-speech pair." ></td>
	<td class="line x" title="289:617	To test the ugen-n-grams extracted from the subjective-element training data using the method outlined above, we assess their precision with respect to opinion piece data." ></td>
	<td class="line x" title="290:617	As with the training data, all unique words in the test data are replaced by UNIQUE." ></td>
	<td class="line x" title="291:617	When a ugen-n-gram is matched against the test data, the UNIQUE fillers match words (of the appropriate parts of speech) that are unique in the test data." ></td>
	<td class="line x" title="292:617	Table 4 shows the results of testing the fixed-n-gram and the ugen-n-gram patterns identified as described above on the four data sets composing OP1." ></td>
	<td class="line x" title="293:617	The freq columns give total frequencies, and the +prec columns show the improvements in precision from the baseline." ></td>
	<td class="line x" title="294:617	The number of words in each data set and baseline precisions are given at the bottom of the table." ></td>
	<td class="line x" title="295:617	For all n-gram features besides the fixed-4-grams and ugen-4-grams, the proportion of features in opinion pieces is significantly greater than the proportion of features in nonopinion pieces." ></td>
	<td class="line x" title="296:617	3 The question arises, how much overlap is there between instances of fixed-n-grams and instances of ugen-n-grams?" ></td>
	<td class="line x" title="297:617	In the test data of Table 4, there are a total of 8,577 fixed-n-grams instances." ></td>
	<td class="line x" title="298:617	Only 59 of these, fewer than 1% are contained (wholly or in part) in ugen-n-gram instances." ></td>
	<td class="line x" title="299:617	This small intersection set shows that two different types of potentially subjective collocations are being recognized." ></td>
	<td class="line x" title="300:617	3 Specifically, the difference between (1) the number of feature instances in opinion pieces divided by the number of words in opinion pieces and (2) the number of feature instances in nonopinion pieces divided by the number of words in nonopinion pieces is significant (p < 0.05) for all data sets." ></td>
	<td class="line x" title="301:617	290 Computational Linguistics Volume 30, Number 3 Table 4 Frequencies and increases in precision of fixed-n-gram and ugen-n-gram collocations learned from the subjective-element data." ></td>
	<td class="line x" title="302:617	For each data set, baseline frequency is the total number of words, and baseline precision is the proportion of words in opinion pieces." ></td>
	<td class="line x" title="303:617	W9-04 W9-10 W9-22 W9-33 freq +prec freq +prec freq +prec freq +prec fixed-2-grams 1,840 +.07 1,972 +.07 1,933 +.04 1,839 +.05 ugen-2-grams 281 +.21 256 +.26 261 +.17 254 +.17 fixed-3-grams 213 +.08 243 +.09 214 +.05 238 +.05 ugen-3-grams 148 +.29 133 +.27 147 +.16 133 +.15 fixed-4-grams 18 +.15 17 +.06 12 +.29 14 .07 ugen-4-grams 13 +.12 3 +.82 15 +.27 13 +.25 baseline 156,421 .19 156,334 .18 155,135 .13 153,634 .14 Randomly selected examples of our learned collocations that appear in the test data are given in Tables 5 and 6." ></td>
	<td class="line x" title="304:617	It is interesting to note that the unique generalized collocations were learned from the training data by their matching different unique words from the ones they match in the test data." ></td>
	<td class="line x" title="305:617	3.4 Generating Features from Document-Level Annotations Using Distributional Similarity In this section, we identify adjective and verb PSEs using distributional similarity." ></td>
	<td class="line x" title="306:617	Opinion-piece data are used for training, and (a different set of) opinion-piece data and the subjective-element data are used for testing." ></td>
	<td class="line x" title="307:617	With distributional similarity, words are judged to be more or less similar based on their distributional patterning in text (Lee 1999; Lee and Pereira 1999)." ></td>
	<td class="line x" title="308:617	Our Table 5 Random sample of fixed-3-gram collocations in OP1." ></td>
	<td class="line x" title="309:617	one-noun of-prep his-det worst-adj of-prep all-det quality-noun of-prep the-det to-prep do-verb so-adverb in-prep the-det company-noun you-pronoun and-conj your-pronoun have-verb taken-verb the-det rest-noun of-prep us-pronoun are-verb at-prep least-adj but-conj if-prep you-pronoun as-prep a-det weapon-noun continue-verb to-to do-verb purpose-noun of-prep the-det could-modal have-verb be-verb it-pronoun seem-verb to-prep to-pronoun continue-verb to-prep have-verb be-verb the-det do-verb something-noun about-prep cause-verb you-pronoun to-to evidence-noun to-to back-adverb that-prep you-pronoun are-verb i-pronoun be-verb not-adverb of-prep the-det century-noun of-prep money-noun be-prep 291 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language Table 6 Random sample of unique generalized collocations in OP1." ></td>
	<td class="line x" title="310:617	U: UNIQUE." ></td>
	<td class="line x" title="311:617	Pattern Instances U-adj as-prep: drastic as; perverse as; predatory as U-adj in-prep: perk in; unsatisfying in; unwise in U-adverb U-verb: adroitly dodge; crossly butter; unceasingly fascinate U-noun back-adverb: cutting back; hearken back U-verb U-adverb: coexist harmoniously; flouncing tiresomely ad-noun U-noun: ad hoc; ad valorem any-det U-noun: any over-payment; any tapings; any write-off are-verb U-noun: are escapist; are lowbrow; are resonance but-conj U-noun: but belch; but cirrus; but ssa different-adj U-noun: different ambience; different subconferences like-prep U-noun: like hoffmann; like manute; like woodchuck national-adj U-noun: national commonplace; national yonhap particularly-adverb U-adj: particularly galling; particularly noteworthy so-adverb U-adj: so monochromatic; so overbroad; so permissive this-det U-adj: this biennial; this inexcusable; this scurrilous your-pronoun U-noun: your forehead; your manuscript; your popcorn U-adj and-conj U-adj: arduous and raucous; obstreperous and abstemious U-noun be-verb a-det: acyclovir be a; siberia be a U-noun of-prep its-pronoun: outgrowth of its; repulsion of its U-verb and-conj U-verb: wax and brushed; womanize and booze U-verb to-to a-det: cling to a; trek to a are-verb U-adj to-to: are opaque to; are subject to a-det U-noun and-conj: a blindfold and; a rhododendron and a-det U-verb U-noun: a jaundice ipo; a smoulder sofa it-pronoun be-verb U-adverb: it be humanly; it be sooo than-prep a-det U-noun: than a boob; than a menace the-det U-adj and-conj: the convoluted and; the secretive and the-det U-noun that-prep: the baloney that; the cachet that to-to a-det U-adj: to a gory; to a trappist to-to their-pronoun U-noun: to their arsenal; to their subsistence with-prep an-det U-noun: with an alias; with an avalanche 292 Computational Linguistics Volume 30, Number 3 trainingPrec(s) is the precision of s in the training data validationPrec(s) is the precision of s in the validation data testPrec(s) is the precision of s in the test data (similarly for trainingFreq, validationFreq, and testFreq) S = the set of all adjectives (verbs) in the training data for T in [0.01,0.04,,0.70]: for n in [2,3,,40]: retained = {} For s i in S: if trainingPrec({s i }C i,n ) > T: retained = retained {s i }C i,n R T,n = retained ADJ pses = {} (VERB pses = {}) for T in [0.01,0.04,,0.70]: for n in [2,3,,40]: if validationPrec(R T,n )  0.28 (0.23 for verbs) and validationFreq(R T,n )  100: ADJ pses = ADJ pses  R T,n (VERB pses = VERB pses  R T,n ) Results in Table 7 show testPrec(ADJ pses ) and testFreq(ADJ pses )." ></td>
	<td class="line x" title="312:617	Figure 2 Algorithm for selecting adjective and verb features using distributional similarity." ></td>
	<td class="line x" title="313:617	motivation for experimenting with it to identify PSEs was twofold." ></td>
	<td class="line x" title="314:617	First, we hypothesized that words might be distributionally similar because they share pragmatic usages, such as expressing subjectivity, even if they are not close synonyms." ></td>
	<td class="line x" title="315:617	Second, as shown above, low-frequency words appear more often in subjective texts than expected." ></td>
	<td class="line x" title="316:617	We did not want to discard all low-frequency words from consideration but cannot effectively judge the suitability of individual words." ></td>
	<td class="line x" title="317:617	Thus, to decide whether to retain a word as a PSE, we consider the precision not of the individual word, but of the word together with a cluster of words similar to it." ></td>
	<td class="line x" title="318:617	Many variants of distributional similarity have been used in NLP (Lee 1999; Lee and Pereira 1999)." ></td>
	<td class="line x" title="319:617	Dekang Lins (1998) method is used here." ></td>
	<td class="line x" title="320:617	In contrast to many implementations, which focus exclusively on verb-noun relationships, Lins method incorporates a variety of syntactic relations." ></td>
	<td class="line x" title="321:617	This is important for subjectivity recognition, because PSEs are not limited to verb-noun relationships." ></td>
	<td class="line x" title="322:617	In addition, Lins results are freely available." ></td>
	<td class="line x" title="323:617	A set of seed words begins the process." ></td>
	<td class="line x" title="324:617	For each seed s i, the precision of the set {s i }C i,n in the training data is calculated, where C i,n is the set of n words most similar to s i, according to Lins (1998) method." ></td>
	<td class="line x" title="325:617	If the precision of {s i }C i,n is greater than a threshold T, then the words in this set are retained as PSEs." ></td>
	<td class="line x" title="326:617	If it is not, neither s i nor the words in C i,n are retained." ></td>
	<td class="line x" title="327:617	The union of the retained sets will be denoted R T,n, that is, the union of all sets {s i }C i,n with precision on the training set > T. In Wiebe (2000), the seeds (the s i s) were extracted from the subjective-element annotations in corpus WSJ-SE." ></td>
	<td class="line x" title="328:617	Specifically, the seeds were the adjectives that appear at least once in a subjective element in WSJ-SE." ></td>
	<td class="line x" title="329:617	In this article, the opinion piece corpus is used to move beyond the manual annotations and small corpus of the earlier work, and a much looser criterion is used to choose the initial seeds: All of the adjectives (verbs) in the training data are used." ></td>
	<td class="line x" title="330:617	The algorithm for the process is given in Figure 2." ></td>
	<td class="line x" title="331:617	There is one small difference for adjectives and verbs noted in the figure, that is, the precision threshold of 0.28 for 293 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language Table 7 Frequencies and increases in precision for adjective and verb features identified using distributional similarity with filtering." ></td>
	<td class="line x" title="332:617	For each test data set, baseline frequency is the total number of words, and baseline precision is the proportion of words in opinion pieces." ></td>
	<td class="line x" title="333:617	Baseline ADJ pses VERB pses Training Validation Test freq prec freq +prec freq +prec W9-10 W9-22 W9-22 W9-10 W9-33 153,634 .14 1,576 +.12 1,490 +.11 W9-10 W9-33 W9-33 W9-10 W9-22 155,135 .13 859 +.15 535 +.11 W9-22 W9-33 W9-33 W9-22 W9-10 156,334 .18 249 +.22 224 +.10 All pairings of W9-10, W9-22,W9-33 W9-4 156,421 .19 1,872 +.17 1,777 +.15 adjectives versus 0.23 for verbs." ></td>
	<td class="line x" title="334:617	These thresholds were determined using validation data." ></td>
	<td class="line x" title="335:617	Seeds and their clusters are assessed on a training set for many parameter settings (cluster size n from 2 through 40, and precision threshold T from 0.01 through 0.70 by .03)." ></td>
	<td class="line x" title="336:617	As mentioned above, each (n, T) parameter pair yields a set of adjectives R T,n, that is, the union of all sets {s i }C i,n with precision on the training set > T. A subset, ADJ pses, of those sets is chosen based on precision and frequency in a validation set." ></td>
	<td class="line x" title="337:617	Finally, the ADJ pses are tested on the test set." ></td>
	<td class="line x" title="338:617	Table 7 shows the results for four opinion piece test sets." ></td>
	<td class="line x" title="339:617	Multiple trainingvalidation data set pairs are used for each test set, as given in Table 7." ></td>
	<td class="line x" title="340:617	The results are for the union of the adjectives (verbs) chosen for each pair." ></td>
	<td class="line x" title="341:617	The freq columns give total frequencies, and the +prec columns show the improvements in precision from the baseline." ></td>
	<td class="line x" title="342:617	For each data set, the difference between the proportion of instances of ADJ pses in opinion pieces and the proportion in nonopinion pieces is significant (p < 0.001, z  9.2)." ></td>
	<td class="line x" title="343:617	The same is true for VERB pses (p < 0.001, z  4.1)." ></td>
	<td class="line x" title="344:617	In the interests of testing consistency, Table 8 shows the results of assessing the adjective and verb features generated from opinion piece data (ADJ pses and VERB pses Table 8 Average frequencies and increases in precision in subjective-element data of the sets tested in Table 7." ></td>
	<td class="line x" title="345:617	The baselines are the precisions of adjectives/verbs that appear in subjective elements in the subjective-element data." ></td>
	<td class="line x" title="346:617	Adj baseline Verb baseline ADJ pses VERB pses freq prec freq prec freq +prec freq +prec WSJ-SE-D 1,632 .13 2,980 .15 136 +.16 151 +.10 WSJ-SE-M 1,632 .19 2,980 .12 136 +.24 151 +.13 NG-SE 1,104 .37 2,629 .15 185 +.25 275 +.08 294 Computational Linguistics Volume 30, Number 3 Table 9 Frequencies and increases in precision for all features." ></td>
	<td class="line x" title="347:617	For each data set, baseline frequency is the total number of words, and baseline precision is the proportion of words in opinion pieces." ></td>
	<td class="line x" title="348:617	freq: total frequency; +prec: increase in precision over baseline." ></td>
	<td class="line x" title="349:617	W9-04 W9-10 W9-22 W9-33 freq +prec freq +prec freq +prec freq +prec Unique words 4794 +.15 4763 +.16 4274 +.11 4567 +.11 Fixed-2-grams 1840 +.07 1972 +.07 1933 +.04 1839 +.05 ugen-2-grams 281 +.21 256 +.26 261 +.17 254 +.17 Fixed-3-grams 213 +.08 243 +.09 214 +.05 238 +.05 ugen-3-grams 148 +.29 133 +.27 147 +.16 133 +.15 Fixed-4-grams 18 +.15 17 +.06 12 +.29 14 .07 ugen-4-grams 13 +.12 3 +.82 15 +.27 13 +.25 Adjectives 1872 +.17 249 +.22 859 +.15 1576 +.12 Verbs 1777 +.15 224 +.10 535 +.11 1490 +.11 Baseline 156421 .19 156334 .18 155135 .13 153634 .14 in Table 7) on the subjective-element data." ></td>
	<td class="line x" title="350:617	The left side of the table gives baseline figures for each set of subjective-element annotations." ></td>
	<td class="line x" title="351:617	The right side of the table gives the average frequencies and increases in precision over baseline for the ADJ pses and VERB pses sets on the subjective-element data." ></td>
	<td class="line x" title="352:617	The baseline figures in the table are the frequencies and precisions of the sets of adjectives and verbs that appear at least once in a subjective element." ></td>
	<td class="line x" title="353:617	Since these sets include words that appear just once in the corpus (and thus have 100% precision), the baseline precision is a challenging one." ></td>
	<td class="line x" title="354:617	Testing the VERB pses and ADJ pses on the subjective-element data reveals some interesting consistencies for these subjectivity clues." ></td>
	<td class="line x" title="355:617	The precision increases of the VERB pses on the subjective-element data are comparable to their increases on the opinion piece data." ></td>
	<td class="line x" title="356:617	Similarly, the precision increases of the ADJ pses on the subjective-element data are as good as or better than the performance of this set of PSEs on the opinion piece data." ></td>
	<td class="line x" title="357:617	Finally, the precisions increases for the ADJ pses are higher than for the VERB pses on all data sets." ></td>
	<td class="line x" title="358:617	This is again consistent with the higher performance of the ADJ pses sets in the opinion piece data sets." ></td>
	<td class="line x" title="359:617	4." ></td>
	<td class="line x" title="360:617	Features Used in Concert 4.1 Introduction In this section, we examine the various types of clues used together." ></td>
	<td class="line x" title="361:617	In preparation for this work, all instances in OP1 and OP2 of all of the PSEs identified as described in Section 3 have been automatically identified." ></td>
	<td class="line x" title="362:617	All training to define the PSE instances in OP1 was performed on data separate from OP1, and all training to define the PSE instances in OP2 was performed on data separate from OP2." ></td>
	<td class="line x" title="363:617	4.2 Consistency in Precision among Data Sets Table 9 summarizes the results from previous sections in which the opinion piece data are used for testing." ></td>
	<td class="line x" title="364:617	The performance of the various features is consistently good or bad on the same data sets: the performance is better for all features on W9-10 and W9-04 than on W9-22 and W9-33 (except for the ugen-4-grams, which occur with very low frequency, and the verbs, which have low frequency in W9-10)." ></td>
	<td class="line x" title="365:617	This is so despite the fact that the features were generated using different procedures and data: The 295 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language 0." ></td>
	<td class="line x" title="366:617	PSEs = all adjs, verbs, modals, nouns, and adverbs that appear at least once in an SE (except not, will, be, have)." ></td>
	<td class="line x" title="367:617	1." ></td>
	<td class="line x" title="368:617	PSEinsts = the set of all instances of PSEs 2." ></td>
	<td class="line x" title="369:617	HiDensity = {} 3." ></td>
	<td class="line x" title="370:617	For P in PSEinsts: 4." ></td>
	<td class="line x" title="371:617	leftWin(P) = the W words before P 5." ></td>
	<td class="line x" title="372:617	rightWin(P) = the W words after P 6." ></td>
	<td class="line x" title="373:617	density(P) = number of SEs whose first or last word is in leftWin(P) or rightWin(P) 7." ></td>
	<td class="line x" title="374:617	if density(P)  T: HiDensity = HiDensity {P} 8." ></td>
	<td class="line x" title="375:617	prec(PSEinsts)= number of PSEinsts in subject elements |PSEinsts| 9." ></td>
	<td class="line x" title="376:617	prec(HiDensity)= number of HiDensity in subject elements |HiDensity| Figure 3 Algorithm for calculating density in subjective-element data." ></td>
	<td class="line x" title="377:617	adjectives and verbs were generated from WSJ document-level opinion piece classifications; the n-gram features were generated from newsgroup and WSJ expression-level subjective-element classifications; and the unique unigram feature requires no training." ></td>
	<td class="line x" title="378:617	This consistency in performance suggests that the results are not brittle." ></td>
	<td class="line x" title="379:617	4.3 Choosing Density Parameters from Subjective-Element Data In Wiebe (1994), whether a PSE is interpreted to be subjective depends, in part, on how subjective the surrounding context is. We explore this idea in the current work, assessing whether PSEs are more likely to be subjective if they are surrounded by subjective elements." ></td>
	<td class="line x" title="380:617	In particular, we experiment with a density feature to decide whether or not a PSE instance is subjective: If a sufficient number of subjective elements are nearby, then the PSE instance is considered to be subjective; otherwise, it is discarded." ></td>
	<td class="line x" title="381:617	The density parameters are a window size W and a frequency threshold T. In this section, we explore the density of manually annotated PSEs in subjectiveelement data and choose density parameters to use in Section 4.4, in which we apply them to automatically identified PSEs in opinion piece data." ></td>
	<td class="line x" title="382:617	The process for calculating density in the subjective-element data is given in Figure 3." ></td>
	<td class="line x" title="383:617	The PSEs are defined to be all adjectives, verbs, modals, nouns, and adverbs that appear at least once in a subjective element, with the exception of some stop words (line 0 of Figure 3)." ></td>
	<td class="line x" title="384:617	Note that these PSEs depend only on the subjective-element manual annotations, not on the automatically identified features used elsewhere in the article or on the document-level opinion piece classes." ></td>
	<td class="line x" title="385:617	PSEinsts is the set of PSE instances to be disambiguated (line 1)." ></td>
	<td class="line x" title="386:617	HiDensity (initialized on line 2) will be the subset of PSEinsts that are retained." ></td>
	<td class="line x" title="387:617	In the loop, the density of each PSE instance P is calculated." ></td>
	<td class="line x" title="388:617	This is the number of subjective elements that begin or end in the W words preceding or following P (line 6)." ></td>
	<td class="line x" title="389:617	P is retained if its density is at least T (line 7)." ></td>
	<td class="line x" title="390:617	Lines 89 of the algorithm assess the precision of the original (PSEinsts) and new (HiDensity) sets of PSE instances." ></td>
	<td class="line x" title="391:617	If prec(HiDensity) is greater than prec(PSEinsts), then 296 Computational Linguistics Volume 30, Number 3 Table 10 Most frequent entry in the top three precision intervals for each subjective-element data set." ></td>
	<td class="line x" title="392:617	WSJ-SE1-M WSJ-SE1-D WSJ-SE2-M WSJ-SE2-D NG-SE Baseline freq 1,566 1,245 1,167 1,108 3,303 Baseline prec .49 .47 .41 .36 .51 Range .87.92 .951.0 .951.0 .951.0 .951.0 T, W 10, 20 12, 50 20, 50 14, 100 10, 10 freq 76 12 1 1 3 prec .89 1.0 1.0 1.0 1.0 Range .82.87 .90.95 .73.78 .51.56 .67.72 T, W 6, 10 12, 60 46, 190 22, 370 26, 90 freq 63 22 53 221 664 prec .84 .91 .78 .51 .67 Range .77.82 .84.89 .66.71 .46.51 .63.67 T, W 12, 40 12, 80 18, 60 16, 310 8, 30 freq 292 42 53 358 1504 prec .78 .88 .68 .47 .63 there is evidence that the number of subjective elements near a PSE instance is related to its subjectivity in context." ></td>
	<td class="line x" title="393:617	To create more data points for this analysis, WSJ-SE was split into two (WSJ-SE1 and WSJ-SE2) and annotations of the two judges are considered separately." ></td>
	<td class="line x" title="394:617	WSJ-SE2-D, for example, refers to Ds annotations of WSJ-SE2." ></td>
	<td class="line x" title="395:617	The process in Figure 3 was repeated for different parameter settings (T in [1, 2, 4,,48] and W in [1, 10, 20,, 490]) on each of the SE data sets." ></td>
	<td class="line x" title="396:617	To find good parameter settings, the results for each data set were sorted into five-point precision intervals and then sorted by frequency within each interval." ></td>
	<td class="line x" title="397:617	Information for the top three precision intervals for each data set are shown in Table 10, specifically, the parameter values (i.e. , T and W) and the frequency and precision of the most frequent result in each interval." ></td>
	<td class="line x" title="398:617	The intervals are in the rows labeled Range." ></td>
	<td class="line x" title="399:617	For example, the top three precision intervals for WSJ-SE1-M, 0.87-0.92, 0.82-0.87, and 0.77-0.82 (no parameter values yield higher precision than 0.92)." ></td>
	<td class="line x" title="400:617	The top of Table 10 gives baseline frequencies and precisions, which are |PSEinsts| and prec(PSEinsts), respectively, in line 8 of Figure 3." ></td>
	<td class="line x" title="401:617	The parameter values exhibit a range of frequencies and precisions, with the expected trade-off between precision and frequency." ></td>
	<td class="line x" title="402:617	We choose the following parameters to test in Section 4.4: For each data set, for each precision interval whose lower bound is at least 10 percentage points higher than the baseline for that data set, the top two (T, W) pairs yielding the highest frequencies in that interval are chosen." ></td>
	<td class="line x" title="403:617	Among the five data sets, a total of 45 parameter pairs were so selected." ></td>
	<td class="line x" title="404:617	This exercise was completed once, without experimenting with different parameter settings." ></td>
	<td class="line x" title="405:617	4.4 Density for Disambiguation In this section, density is exploited to find subjective instances of automatically identified PSEs." ></td>
	<td class="line x" title="406:617	The process is shown in Figure 4." ></td>
	<td class="line x" title="407:617	There are only two differences between the algorithms in Figures 3 and 4." ></td>
	<td class="line x" title="408:617	First, in Figure 3, density is defined in terms of the number of subjective elements nearby." ></td>
	<td class="line x" title="409:617	However, subjective-element annotations are not available in test data." ></td>
	<td class="line x" title="410:617	Thus in Figure 4, density is defined in terms of the 297 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language 0." ></td>
	<td class="line x" title="411:617	PSEinsts = the set of instances in the test data of all PSEs described in Section 3 1." ></td>
	<td class="line x" title="412:617	HiDensity = {} 2." ></td>
	<td class="line x" title="413:617	For P in PSEinsts: 3." ></td>
	<td class="line x" title="414:617	leftWin(P) = the W words before P 4." ></td>
	<td class="line x" title="415:617	rightWin(P) = the W words after P 5." ></td>
	<td class="line x" title="416:617	density(P) = number of PSEinsts whose first or last word is in leftWin(P) or rightWin(P) 6." ></td>
	<td class="line x" title="417:617	if density(P)  T: HiDensity = HiDensity {P} 7." ></td>
	<td class="line x" title="418:617	prec(PSEinsts)= #ofPSEinsts in OPs |PSEinsts| 8." ></td>
	<td class="line x" title="419:617	prec(HiDensity)= #ofHiDensity in OPs |HiDensity| Figure 4 Algorithm for calculating density in opinion piece (OP) data number of other PSE instances nearby, where PSEinsts consists of all instances of the automatically identified PSEs described in Section 3, for which results are given in Table 9." ></td>
	<td class="line x" title="420:617	Second, in Figure 4, we assess precision with respect to the document-level classes (lines 78)." ></td>
	<td class="line x" title="421:617	The test data are OP1." ></td>
	<td class="line x" title="422:617	An interesting question arose when we were defining the PSE instances: What should be done with words that are identified to be PSEs (or parts of PSEs) according to multiple criteria?" ></td>
	<td class="line x" title="423:617	For example, sunny, radiant, and exhilarating are all unique in corpus OP1, and are all members of the adjective PSE feature defined for testing on OP1." ></td>
	<td class="line x" title="424:617	Collocations add additional complexity." ></td>
	<td class="line x" title="425:617	For example, consider the sequence and splendidly, which appears in the test data." ></td>
	<td class="line x" title="426:617	The sequence and splendidly matches the ugen-2-gram (and-conj U-adj), and the word splendidly is unique." ></td>
	<td class="line x" title="427:617	In addition, a sequence may match more than one n-gram feature." ></td>
	<td class="line x" title="428:617	For example, is it that matches three fixed-n-gram features: is it, is it that, and it that." ></td>
	<td class="line x" title="429:617	In the current experiments, the more PSEs a word matches, the more weight it is given." ></td>
	<td class="line x" title="430:617	The hypothesis behind this treatment is that additional matches represent additional evidence that a PSE instance is subjective." ></td>
	<td class="line x" title="431:617	This hypothesis is realized as follows: Each match of each member of each type of PSE is considered to be a PSE instance." ></td>
	<td class="line x" title="432:617	Thus, among them, there are 11 members in PSEinsts for the five phrases sunny, radiant, exhilarating, and splendidly, and is it that, one for each of the matches mentioned above." ></td>
	<td class="line x" title="433:617	The process in Figure 4 was conducted with the 45 parameter pair values (T and W) chosen from the subjective-element data as described in Section 4.3." ></td>
	<td class="line x" title="434:617	Table 11 shows results for a subset of the 45 parameters, namely, the most frequent parameter pair chosen from the top three precision intervals for each training set." ></td>
	<td class="line x" title="435:617	The bottom of the table gives a baseline frequency and a baseline precision in OP1, defined as |PSEinsts| and prec(PSEinsts), respectively, in line 7 of Figure 4." ></td>
	<td class="line x" title="436:617	The density features result in substantial increases in precision." ></td>
	<td class="line x" title="437:617	Of the 45 parameter pairs, the minimum percentage increase over baseline is 22%." ></td>
	<td class="line x" title="438:617	Fully 24% of the 45 parameter pairs yield increases of 200% or more; 38% yield increases between 100% 298 Computational Linguistics Volume 30, Number 3 Table 11 Results for high-density PSEs in test data OP1 using parameters chosen from subjective-element data." ></td>
	<td class="line x" title="439:617	WSJ-SE1-M WSJ-SE1-D WSJ-SE2-M WSJ-SE2-D NG-SE T, W 10, 20 12, 50 20, 50 14, 100 10, 10 freq 237 3,176 170 10,510 8 prec .87 .72 .97 .57 1.0 T, W 6, 10 12, 60 46, 190 22, 370 26, 90 freq 459 5,289 1,323 21,916 787 prec .68 .68 .95 .37 .92 T, W 12, 40 12, 80 18, 60 16, 310 8, 30 freq 1,398 9,662 906 24,454 3,239 prec .79 .58 .87 .34 .67 PSE baseline: freq = 30,938, prec = .28 and 199%, and 38% yield increases between 22% and 99%." ></td>
	<td class="line x" title="440:617	In addition, the increases are significant." ></td>
	<td class="line x" title="441:617	Using the set of high-density PSEs defined by the parameter pair with the least increase over baseline, we tested the difference in the proportion of PSEs in opinion pieces that are high-density and the proportion of PSEs in nonopinion pieces that are high-density." ></td>
	<td class="line x" title="442:617	The difference between these two proportions is highly significant (z = 46.2, p < 0.0001)." ></td>
	<td class="line x" title="443:617	Notice that, except for one blip (T, W = 6, 10 under WSJ-SE-M), the precisions decrease and the frequencies increase as we go down each column in Table 11." ></td>
	<td class="line x" title="444:617	The same pattern can be observed with all 45 parameter pairs (results not included here because of space considerations)." ></td>
	<td class="line x" title="445:617	But the parameter pairs are ordered in Table 11 based on performance in the manually annotated subjective-element data, not based on performance in the test data." ></td>
	<td class="line x" title="446:617	For example, the entry in the first row, first column (T, W = 10, 20) is the parameter pair giving the highest frequency in the top precision interval of WSJ-SE-M (frequency and precision in WSJ-SE-M, using the process of Figure 3)." ></td>
	<td class="line x" title="447:617	Thus, the relative precisions and frequencies of the parameter pairs are carried over from the training to the test data." ></td>
	<td class="line x" title="448:617	This is quite a strong result, given that the PSEs in the training data are from manual annotations, while the PSEs in the test data are our automatically identified features." ></td>
	<td class="line x" title="449:617	4.5 High-Density Sentence Annotations To assess the subjectivity of sentences with high-density PSEs, we extracted the 133 sentences in corpus OP2 that contain at least one high-density PSE and manually annotated them." ></td>
	<td class="line x" title="450:617	We refer to these sentences as the system-identified sentences." ></td>
	<td class="line x" title="451:617	We chose the density-parameter pair (T, W = 12, 30), based on its precision and frequency in OP1." ></td>
	<td class="line x" title="452:617	This parameter setting yields results that have relatively high precision and low frequency." ></td>
	<td class="line x" title="453:617	We chose a low-frequency setting to make the annotation study feasible." ></td>
	<td class="line x" title="454:617	The extracted sentences were independently annotated by two judges." ></td>
	<td class="line x" title="455:617	One is a coauthor of this article (judge 1), and the other has performed subjectivity annotation before, but is not otherwise involved in this research (judge 2)." ></td>
	<td class="line x" title="456:617	Sentences were annotated according to the coding instructions of Wiebe, Bruce, and OHara (1999) which, recall, are to classify a sentence as subjective if there is a significant expression of subjectivity of either the writer or someone mentioned in the text, in the sentence." ></td>
	<td class="line x" title="457:617	299 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language Table 12 Examples of system-identified sentences." ></td>
	<td class="line x" title="458:617	(1) The outburst of shooting came nearly two weeks after clashes between Moslem worshippers and oo Somali soldiers." ></td>
	<td class="line x" title="459:617	(2.a) But now the refugees are streaming across the border and alarming the world." ></td>
	<td class="line x" title="460:617	ss (2.b) In the middle of the crisis, Erich Honecker was hospitalized with a gall stone operation." ></td>
	<td class="line x" title="461:617	oo (2.c) It is becoming more and more obvious that his gallstone-age communism is dying with him:  ss (3.a) Not brilliantly, because, after all, this was a performer who was collecting paychecks from lounges ss at Hiltons and Holiday Inns, but creditably and with the air of someone for whom Ten Cents a Dance was more than a bit autobiographical." ></td>
	<td class="line x" title="462:617	(3.b) It was an exercise of blending Michelles singing with Susies singing, explained Ms. Stevens." ></td>
	<td class="line x" title="463:617	oo (4) Enlisted men and lower-grade officers were meat thrown into a grinder." ></td>
	<td class="line x" title="464:617	ss (5) If you believe in God and you believe in miracles, theres nothing particularly crazy about that. ss (6) He was much too eager to create something very weird and dynamic, ss catastrophic and jolly like this great and coily thing Lolita. (7) The Bush approach of mixing confrontation with conciliation strikes some people as sensible, perhaps ss even inevitable, because Mr. Bush faces a Congress firmly in the hands of the opposition." ></td>
	<td class="line x" title="465:617	(8) Still, despite their efforts to convince the world that we are indeed alone, the visitors do seem to keep ss coming and, like the recent sightings, theres often a detail or two that suggests they may actually be a little on the dumb side." ></td>
	<td class="line x" title="466:617	(9) As for the women, theyre pathetic." ></td>
	<td class="line x" title="467:617	ss (10) At this point, the truce between feminism and sensationalism gets might uneasy." ></td>
	<td class="line x" title="468:617	ss (11) MMPIs publishers say the test shouldnt be used alone to diagnose ss psychological problems or in hiring; it should be given in conjunction with other tests." ></td>
	<td class="line x" title="469:617	(12) While recognizing that professional environmentalists may feel threatened, ss I intend to urge that UV-B be monitored whenever I can." ></td>
	<td class="line x" title="470:617	Table 13 Sentence annotation contingency table; judge 1 counts are in rows and judge 2 counts are in columns." ></td>
	<td class="line x" title="471:617	Subjective Objective Unsure Subjective 98 2 3 Objective 2 14 0 Unsure 2 11 1 In addition to the subjective and objective classes, a judge can tag a sentence as unsure if he or she is unsure of his or her rating or considers the sentence to be borderline." ></td>
	<td class="line x" title="472:617	An equal number (133) of other sentences were randomly selected from the corpus to serve as controls." ></td>
	<td class="line x" title="473:617	The 133 system-identified sentences and the 133 control sentences were randomly mixed together." ></td>
	<td class="line x" title="474:617	The judges were asked to annotate all 266 sentences, not knowing which were system-identified and which were control." ></td>
	<td class="line x" title="475:617	Each sentence was presented with the sentence that precedes it and the sentence that follows it in the corpus, to provide some context for interpretation." ></td>
	<td class="line x" title="476:617	Table 12 shows examples of the system-identified sentences." ></td>
	<td class="line x" title="477:617	Sentences classified by both judges as objective are marked oo and those classified by both judges as subjective are marked ss." ></td>
	<td class="line x" title="478:617	300 Computational Linguistics Volume 30, Number 3 Table 14 Examples of subjective sentences adjacent to system-identified sentences." ></td>
	<td class="line x" title="479:617	Bathed in cold sweat, I watched these Dantesque scenes, holding tightly the damp hand of Edek or Waldeck who, like me, were convinced that there was no God." ></td>
	<td class="line x" title="480:617	The Japanese are amazed that a company like this exists in Japan, says Kimindo Kusaka, head of the Softnomics Center, a Japanese management-research organization." ></td>
	<td class="line x" title="481:617	And even if drugs were legal, what evidence do you have that the habitual drug user wouldnt continue to rob and steal to get money for clothes, food or shelter?" ></td>
	<td class="line x" title="482:617	The moral cost of legalizing drugs is great, but it is a cost that apparently lies outside the narrow scope of libertarian policy prescriptions." ></td>
	<td class="line x" title="483:617	I doubt that one exists." ></td>
	<td class="line x" title="484:617	They were upset at his committees attempt to pacify the program critics by cutting the surtax paid by the more affluent elderly and making up the loss by shifting more of the burden to the elderly poor and by delaying some benefits by a year." ></td>
	<td class="line x" title="485:617	Judge 1 classified 103 of the system-identified sentences as subjective, 16 as objective, and 14 as unsure." ></td>
	<td class="line x" title="486:617	Judge 2 classified 102 of the system-identified sentences as subjective, 27 as objective; and 4 as unsure." ></td>
	<td class="line x" title="487:617	The contingency table is given in Table 13." ></td>
	<td class="line x" title="488:617	4 The kappa value using all three classes is 0.60, reflecting the highly skewed distribution in favor of subjective sentences, and the disagreement on the lower-frequency classes (unsure and objective)." ></td>
	<td class="line x" title="489:617	Consistent with the findings in Wiebe, Bruce, and OHara (1999), the kappa value for agreement on the sentences for which neither judge is unsure is very high: 0.86." ></td>
	<td class="line x" title="490:617	A different breakdown of the sentences is illuminating." ></td>
	<td class="line x" title="491:617	For 98 of the sentences (call them SS), judges 1 and 2 tag the sentence as subjective." ></td>
	<td class="line x" title="492:617	Among the other sentences, 20 appear in a block of contiguous system-identified sentences that includes a member of SS." ></td>
	<td class="line x" title="493:617	For example, in Table 12, (2.a) and (2.c) are in SS and (2.b) is in the same block of subjective sentences as they are." ></td>
	<td class="line x" title="494:617	Similarly, (3.a) is in SS and (3.b) is in the same block." ></td>
	<td class="line x" title="495:617	Among the remaining 15 sentences, 6 are adjacent to subjective sentences that were not identified by our system (so were not annotated by the judges)." ></td>
	<td class="line x" title="496:617	All of those sentences contain significant expressions of subjectivity of the writer or someone mentioned in the text, the criterion used in this work for classifying a sentence as subjective." ></td>
	<td class="line x" title="497:617	Samples are shown in Table 14." ></td>
	<td class="line x" title="498:617	Thus, 93% of the sentences identified by the system are subjective or are near subjective sentences." ></td>
	<td class="line x" title="499:617	All the sentences, together with their tags and the sentences adjacent to them, are available on the Web at www.cs.pitt.edu/wiebe." ></td>
	<td class="line x" title="500:617	4.6 Using Features for Opinion Piece Recognition In this section, we assess the usefulness of the PSEs identified in Section 3 and listed in Table 9 by using them to perform document-level classification of opinion pieces." ></td>
	<td class="line x" title="501:617	Opinion-piece classification is a difficult task for two reasons." ></td>
	<td class="line x" title="502:617	First, as discussed in Section 2.1, both opinionated and factual documents tend to be composed of a mixture of subjective and objective language." ></td>
	<td class="line x" title="503:617	Second, the natural distribution of documents in our data is heavily skewed toward nonopinion pieces." ></td>
	<td class="line x" title="504:617	Despite these hurdles, using only 4 In contrast, Judge 1 classified only 53 (45%) of the control sentences as subjective, and Judge 2 classified only 47 (36%) of them as subjective." ></td>
	<td class="line x" title="505:617	301 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language our PSEs, we achieve positive results in opinion-piece classification using the basic knearest-neighbor (KNN) algorithm with leave-one-out cross-validation (Mitchell 1997)." ></td>
	<td class="line x" title="506:617	Given a document, the basic KNN algorithm classifies the document according to the majority classification of the documents k closest neighbors." ></td>
	<td class="line x" title="507:617	For our purposes, each document is characterized by one feature, the count of all PSE instances (regardless of type) in the document, normalized by document length in words." ></td>
	<td class="line x" title="508:617	The distance between two documents is simply the absolute value of the difference between the normalized PSE counts for the two documents." ></td>
	<td class="line x" title="509:617	With leave-one-out cross-validation, the set of n documents to be classified is divided into a training set of size n1 and a validation set of size 1." ></td>
	<td class="line x" title="510:617	The one document in the validation set is then classified according to the majority classification of its k closest-neighbor documents in the training set." ></td>
	<td class="line x" title="511:617	This process is repeated until every document is classified." ></td>
	<td class="line x" title="512:617	Which value to use for k is chosen during a preprocessing phase." ></td>
	<td class="line x" title="513:617	During the preprocessing phase, we run the KNN algorithm with leave-one-out cross-validation on a separate training set, for odd values of k from 1 to 15." ></td>
	<td class="line x" title="514:617	The value of k that results in the best classification during the preprocessing phase is the one used for later KNN classification." ></td>
	<td class="line x" title="515:617	For the classification experiment, the data set OP1 was used in the preprocessing phase to select the value of k, and then classification was performed on the 1,222 documents in OP2." ></td>
	<td class="line x" title="516:617	During training on OP1, k equal to 15 resulted in the best classification." ></td>
	<td class="line x" title="517:617	On the test set, OP2, we achieved a classification accuracy of 0.939; the baseline accuracy for choosing the most frequent class (nonopinion pieces) was 0.915." ></td>
	<td class="line x" title="518:617	Our classification accuracy represents a 28% reduction in error and is significantly better than baseline according to McNemars test (Everitt 1997)." ></td>
	<td class="line x" title="519:617	The positive results from the opinion piece classification show the usefulness of the various PSE features when used together." ></td>
	<td class="line x" title="520:617	5." ></td>
	<td class="line x" title="521:617	Relation to Other Work There has been much work in other fields, including linguistics, literary theory, psychology, philosophy, and content analysis, involving subjective language." ></td>
	<td class="line x" title="522:617	As mentioned in Section 2, the conceptualization underlying our manual annotations is based on work in literary theory and linguistics, most directly Dolezel (1973), Uspensky (1973), Kuroda (1973, 1976), Chatman (1978), Cohn (1978), Fodor (1979), and Banfield (1982)." ></td>
	<td class="line x" title="523:617	We also mentioned existing knowledge resources such as affective lexicons (General-Inquirer 2000; Heise 2000) and annotations in more general-purpose lexicons (e.g. , the attitude adverb features in Comlex [Macleod, Grishman, and Meyers 1998])." ></td>
	<td class="line x" title="524:617	Such knowledge may be used in future work to complement the work presented in this article, for example, to seed the distributional-similarity process described in Section 3.4." ></td>
	<td class="line x" title="525:617	There is also work in fields such as content analysis and psychology on statistically characterizing texts in terms of word lists manually developed for distinctions related to subjectivity." ></td>
	<td class="line x" title="526:617	For example, Hart (1984) performs counts on a manually developed list of words and rhetorical devices (e.g. , sacred terms such as freedom) in political speeches to explore potential reasons for public reactions." ></td>
	<td class="line x" title="527:617	Anderson and McMaster (1998) use fixed sets of high-frequency words to assign connotative scores to documents and sections of documents along dimensions such as how pleasant, acrimonious, pious, or confident, the text is. What distinguishes our work from work on subjectivity in other fields is that we focus on (1) automatically learning knowledge from corpora, (2) automatically 302 Computational Linguistics Volume 30, Number 3 performing contextual disambiguation, and (3) using knowledge of subjectivity in NLP applications." ></td>
	<td class="line x" title="528:617	This article expands and integrates the work reported in Wiebe and Wilson (2002), Wiebe, Wilson, and Bell (2001), Wiebe et al.(2001) and Wiebe (2000)." ></td>
	<td class="line x" title="530:617	Previous work in NLP on the same or related tasks includes sentence-level and document-level subjectivity classifications." ></td>
	<td class="line x" title="531:617	At the sentence level, Wiebe, Bruce, and OHara (1999) developed a machine learning system to classify sentences as subjective or objective." ></td>
	<td class="line x" title="532:617	The accuracy of the system was more than 20 percentage points higher than a baseline accuracy." ></td>
	<td class="line x" title="533:617	Five part-of-speech features, two lexical features, and a paragraph feature were used." ></td>
	<td class="line x" title="534:617	These results suggested to us that there are clues to subjectivity that might be learned automatically from text and motivated the work reported in the current article." ></td>
	<td class="line x" title="535:617	The system was tested in 10-fold cross validation experiments using corpus WSJ-SE, a small corpus of only 1,001 sentences." ></td>
	<td class="line x" title="536:617	As discussed in Section 1, a main goal of our current work is to exploit existing document-level annotations, because they enable us to use much larger data sets, they were created outside our research group, and they allow us to assess consistency of performance by cross-validating between our manual annotations and the existing document-level annotations." ></td>
	<td class="line x" title="537:617	Because the document-level data are not annotated at the sentence level, sentence-level classification is not highlighted in this article." ></td>
	<td class="line x" title="538:617	The new sentence annotation study to evaluate sentences with high-density features (Section 4.5) uses different data from WSJ-SE, because some of the features (n-grams and density parameters) were identified using WSJ-SE as training data." ></td>
	<td class="line x" title="539:617	Other previous work in NLP has addressed related document-level classifications." ></td>
	<td class="line x" title="540:617	Spertus (1997) developed a system for recognizing inflammatory messages." ></td>
	<td class="line x" title="541:617	As mentioned earlier in the article, inflammatory language is a type of subjective language, so the task she addresses is closely related to ours." ></td>
	<td class="line x" title="542:617	She uses machine learning to select among manually developed features." ></td>
	<td class="line x" title="543:617	In contrast, the focus in our work is on automatically identifying features from the data." ></td>
	<td class="line x" title="544:617	A number of projects investigating genre detection include editorials as one of the targeted genres." ></td>
	<td class="line x" title="545:617	For example, in Karlgren and Cutting (1994), editorials are one of fifteen categories, and in Kessler, Nunberg, and Sch utze (1997), editorials are one of six." ></td>
	<td class="line x" title="546:617	Given the goal of these works to perform genre detection in general, they use low-level features that are not specific to editorials." ></td>
	<td class="line x" title="547:617	Neither shows significant improvements for editorial recognition." ></td>
	<td class="line x" title="548:617	Argamon, Koppel, and Avneri (1998) address a slightly different task, though it does involve editorials." ></td>
	<td class="line x" title="549:617	Their goal is to distinguish not only, for example, news from editorials, but also these categories in different publications." ></td>
	<td class="line x" title="550:617	Their best results are distinguishing among the news categories of different publications; their lowest results involve editorials." ></td>
	<td class="line x" title="551:617	Because we focus specifically on distinguishing opinion pieces from nonopinion pieces, our results are better than theirs for those categories." ></td>
	<td class="line x" title="552:617	In addition, in contrast to the above studies, the focus of our work is on learning features of subjectivity." ></td>
	<td class="line x" title="553:617	We perform opinion piece recognition in order to assess the usefulness of the various features when used together." ></td>
	<td class="line x" title="554:617	Other previous NLP research has used features similar to ours for other NLP tasks." ></td>
	<td class="line x" title="555:617	Low-frequency words have been used as features in information extraction (Weeber, Vos, and Baayen 2000) and text categorization (Copeck et al. 2000)." ></td>
	<td class="line x" title="556:617	A number of researchers have worked on mining collocations from text to extend lexicographic resources for machine translation and word sense disambiguation (e.g. , Smajda 1993; Lin 1999; Biber 1993)." ></td>
	<td class="line x" title="557:617	In Samuel, Carberry, and Vijay-Shankers (1998) work on identifying collocations for dialog-act recognition, a filter similar to ours was used to eliminate redundant n-gram features: n-grams were eliminated if they contained substrings with the same entropy score as or a better entropy score than the n-gram." ></td>
	<td class="line x" title="558:617	303 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language While it is common in studies of collocations to omit low-frequency words and expressions from analysis, because they give rise to invalid or unrealistic statistical measures (Church and Hanks, 1990), we are able to identify higher-precision collocations by including placeholders for unique words (i.e. , the ugen-n-grams)." ></td>
	<td class="line x" title="559:617	We are not aware of other work that uses such collocations as we do." ></td>
	<td class="line oc" title="560:617	Features identified using distributional similarity have previously been used for syntactic and semantic disambiguation (Hindle 1990; Dagan, Pereira, and Lee 1994) and to develop lexical resources from corpora (Lin 1998; Riloff and Jones 1999)." ></td>
	<td class="line x" title="561:617	We are not aware of other work identifying and using density parameters as described in this article." ></td>
	<td class="line x" title="562:617	Since our experiments, other related work in NLP has been performed." ></td>
	<td class="line x" title="563:617	Some of this work addresses related but different classification tasks." ></td>
	<td class="line x" title="564:617	Three studies classify reviews as positive or negative (Turney 2002; Pang, Lee, and Vaithyanathan 2002; Dave, Lawrence, Pennock 2003)." ></td>
	<td class="line x" title="565:617	The input is assumed to be a review, so this task does not include finding subjective documents in the first place." ></td>
	<td class="line x" title="566:617	The first study listed above (Turney 2002) uses a variation of the semantic similarity procedure presented in Wiebe (2000) (Section 3.4)." ></td>
	<td class="line x" title="567:617	The third (Dave, Lawrence, and Pennock 2003) uses ngram features identified with a variation of the procedure presented in Wiebe, Wilson, and Bell (2001) (Section 3.3)." ></td>
	<td class="line x" title="568:617	Tong (2001) addresses finding sentiment timelines, that is, tracking sentiments over time in multiple documents." ></td>
	<td class="line x" title="569:617	For clues of subjectivity, he uses manually developed lexical rules, rather than automatically learning them from corpora." ></td>
	<td class="line x" title="570:617	Similarly, Gordon et al.(2003) use manually developed grammars to detect some types of subjective language." ></td>
	<td class="line x" title="572:617	Agrawal et al.(2003) partition newsgroup authors into camps based on quotation links." ></td>
	<td class="line x" title="574:617	They do not attempt to recognize subjective language." ></td>
	<td class="line x" title="575:617	The most closely related new work is Riloff, Wiebe, and Wilson (2003), Riloff and Wiebe (2003) and Yu and Hatzivassiloglou (2003)." ></td>
	<td class="line x" title="576:617	The first two focus on finding additional types of subjective clues (nouns and extraction patterns identified using extraction pattern bootstrapping)." ></td>
	<td class="line x" title="577:617	Yu and Hatzivassiloglou (2003) perform opinion text classification." ></td>
	<td class="line x" title="578:617	They also use existing WSJ document classes for training and testing, but they do not include the entire corpus in their experiments, as we do." ></td>
	<td class="line x" title="579:617	Their opinion piece class consists only of editorials and letters to the editor, and their nonopinion class consists only of business and news." ></td>
	<td class="line x" title="580:617	They report an average F-measure of 96.5%." ></td>
	<td class="line x" title="581:617	Our result of 94% accuracy on document level classification is almost comparable." ></td>
	<td class="line x" title="582:617	They also perform sentence-level classification." ></td>
	<td class="line x" title="583:617	We anticipate that knowledge of subjective language may be usefully exploited in a number of NLP application areas and hope that the work presented in this article will encourage others to experiment with subjective language in their applications." ></td>
	<td class="line x" title="584:617	More generally, there are many types of artificial intelligence systems for which state-ofaffairs types such as beliefs and desires are central, including systems that perform plan recognition for understanding narratives (Dyer 1982; Lehnert et al. 1983), for argument understanding (Alvarado, Dyer, and Flowers 1986), for understanding stories from different perspectives (Carbonell 1979), and for generating language under different pragmatic constraints (Hovy 1987)." ></td>
	<td class="line x" title="585:617	Knowledge of linguistic subjectivity could enhance the abilities of such systems to recognize and generate expressions referring to such states of affairs in natural text." ></td>
	<td class="line x" title="586:617	6." ></td>
	<td class="line x" title="587:617	Conclusions Knowledge of subjective language promises to be beneficial for many NLP applications including information extraction, question answering, text categorization, and 304 Computational Linguistics Volume 30, Number 3 summarization." ></td>
	<td class="line x" title="588:617	This article has presented the results of an empirical study in acquiring knowledge of subjective language from corpora in which a number of feature types were learned and evaluated on different types of data with positive results." ></td>
	<td class="line x" title="589:617	We showed that unique words are subjective more often than expected and that unique words are valuable clues to subjectivity." ></td>
	<td class="line x" title="590:617	We also presented a procedure for automatically identifying potentially subjective collocations, including fixed collocations and collocations with placeholders for unique words." ></td>
	<td class="line x" title="591:617	In addition, we used the results of a method for clustering words according to distributional similarity (Lin 1998) to identify adjectival and verbal clues of subjectivity." ></td>
	<td class="line x" title="592:617	Table 9 summarizes the results of testing all of the above types of PSEs." ></td>
	<td class="line x" title="593:617	All show increased precision in the evaluations." ></td>
	<td class="line x" title="594:617	Together, they show consistency in performance." ></td>
	<td class="line x" title="595:617	In almost all cases they perform better or worse on the same data sets, despite the fact that different kinds of data and procedures are used to learn them." ></td>
	<td class="line x" title="596:617	In addition, PSEs learned using expression-level subjective-element data have precisions higher than baseline on document-level opinion piece data, and vice versa." ></td>
	<td class="line x" title="597:617	Having a large stable of PSEs, it was important to disambiguate whether or not PSE instances are subjective in the contexts in which they appear." ></td>
	<td class="line x" title="598:617	We discovered that the density of other potentially subjective expressions in the surrounding context is important." ></td>
	<td class="line x" title="599:617	If a clue is surrounded by a sufficient number of other clues, then it is more likely to be subjective than if there were not." ></td>
	<td class="line x" title="600:617	Parameter values were selected using training data manually annotated at the expression level for subjective elements and then tested on data annotated at the document level for opinion pieces." ></td>
	<td class="line x" title="601:617	All of the selected parameters led to increases in precision on the test data, and most lead to increases over 100%." ></td>
	<td class="line x" title="602:617	Once again we found consistency between expression-level and document-level annotations." ></td>
	<td class="line x" title="603:617	PSE sets defined by density have high precision in both the subjective-element data and the opinion piece data." ></td>
	<td class="line x" title="604:617	The large differences between training and testing suggest that our results are not brittle." ></td>
	<td class="line x" title="605:617	Using a density feature selected from a training set, sentences containing highdensity PSEs were extracted from a separate test set, and manually annotated by two judges." ></td>
	<td class="line x" title="606:617	Fully 93% of the sentences extracted were found to be subjective or to be near subjective sentences." ></td>
	<td class="line x" title="607:617	Admittedly, the chosen density feature is a high-precision, lowfrequency one." ></td>
	<td class="line x" title="608:617	But since the process is fully automatic, the feature could be applied to more unannotated text to identify regions containing subjective sentences." ></td>
	<td class="line x" title="609:617	In addition, because the precision and frequency of the density features are stable across data sets, lower-precision but higher-frequency options are available." ></td>
	<td class="line x" title="610:617	Finally, the value of the various types of PSEs was demonstrated with the task of opinion piece classification." ></td>
	<td class="line x" title="611:617	Using the k-nearest-neighbor classification algorithm with leave-one-out cross-validation, a classification accuracy of 94% was achieved on a large test set, with a reduction in error of 28% from the baseline." ></td>
	<td class="line x" title="612:617	Future work is required to determine how to exploit density features to improve the performance of text categorization algorithms." ></td>
	<td class="line x" title="613:617	Another area of future work is searching for clues to objectivity, such as the politeness features used by Spertus (1997)." ></td>
	<td class="line x" title="614:617	Still another is identifying the type of a subjective expression (e.g. , positive or negative evaluative), extending work such as Hatzivassiloglou and McKeown (1997) on classifying lexemes to the classification of instances in context (compare, e.g., great! and oh great.) In addition, it would be illuminating to apply our system to data annotated with discourse trees (Carlson, Marcu, and Okurowski 2001)." ></td>
	<td class="line x" title="615:617	We hypothesize that most objective sentences identified by our system are dominated in the discourse by subjective sentences and that we are moving toward identifying subjective discourse segments." ></td>
	<td class="line x" title="616:617	305 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language Acknowledgments We thank the anonymous reviewers for their helpful and constructive comments." ></td>
	<td class="line x" title="617:617	This research was supported in part by the Office of Naval Research under grants N00014-95-1-0776 and N00014-01-1-0381." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N04-1041
Automatically Labeling Semantic Classes
Pantel, Patrick;Ravichandran, Deepak;"></td>
	<td class="line x" title="1:196	Automatically Labeling Semantic Classes Patrick Pantel and Deepak Ravichandran Information Sciences Institute University of Southern California 4676 Admiralty Way Marina del Rey, CA 90292 {pantel,ravichan}@isi.edu Abstract Systems that automatically discover semantic classes have emerged in part to address the limitations of broad-coverage lexical resources such as WordNet and Cyc." ></td>
	<td class="line x" title="2:196	The current state of the art discovers many semantic classes but fails to label their concepts." ></td>
	<td class="line x" title="3:196	We propose an algorithm labeling semantic classes and for leveraging them to extract is-a relationships using a top-down approach." ></td>
	<td class="line x" title="4:196	1 Introduction The natural language literature is rich in theories of semantics (Barwise and Perry 1985; Schank and Abelson 1977)." ></td>
	<td class="line x" title="5:196	However, WordNet (Miller 1990) and Cyc (Lenat 1995) aside, the community has had little success in actually building large semantic repositories." ></td>
	<td class="line x" title="6:196	Such broad-coverage lexical resources are extremely useful in applications such as word sense disambiguation (Leacock, Chodorow and Miller 1998) and question answering (Pasca and Harabagiu 2001)." ></td>
	<td class="line x" title="7:196	Current manually constructed ontologies such as WordNet and Cyc have important limitations." ></td>
	<td class="line x" title="8:196	First, they often contain rare senses." ></td>
	<td class="line x" title="9:196	For example, WordNet includes a rare sense of computer that means the person who computes." ></td>
	<td class="line x" title="10:196	Using WordNet to expand queries to an information retrieval system, the expansion of computer will include words like estimator and reckoner." ></td>
	<td class="line x" title="11:196	Also, the words dog, computer and company all have a sense that is a hyponym of person." ></td>
	<td class="line x" title="12:196	Such rare senses make it difficult for a coreference resolution system to use WordNet to enforce the constraint that personal pronouns (e.g. he or she) must refer to a person." ></td>
	<td class="line x" title="13:196	The second problem with these lexicons is that they miss many domain specific senses." ></td>
	<td class="line x" title="14:196	For example, WordNet misses the user-interface-object sense of the word dialog (as often used in software manuals)." ></td>
	<td class="line x" title="15:196	WordNet also contains a very poor coverage of proper nouns." ></td>
	<td class="line x" title="16:196	There is a need for (semi-) automatic approaches to building and extending ontologies as well as for validating the structure and content of existing ones." ></td>
	<td class="line x" title="17:196	With the advent of the Web, we have access to enormous amounts of text." ></td>
	<td class="line x" title="18:196	The future of ontology growing lies in leveraging this data by harvesting it for concepts and semantic relationships." ></td>
	<td class="line x" title="19:196	Moreover, once such knowledge is discovered, mechanisms must be in place to enrich current ontologies with this new knowledge." ></td>
	<td class="line x" title="20:196	To address some of the coverage and specificity problems in WordNet and Cyc, Pantel and Lin (2002) proposed and algorithm, called CBC, for automatically extracting semantic classes." ></td>
	<td class="line x" title="21:196	Their classes consist of clustered instances like the three shown below: (A) multiple sclerosis, diabetes, osteoporosis, cardiovascular disease, Parkinson's, rheumatoid arthritis, heart disease, asthma, cancer, hypertension, lupus, high blood pressure, arthritis, emphysema, epilepsy, cystic fibrosis, leukemia, hemophilia, Alzheimer, myeloma, glaucoma, schizophrenia, (B) Mike Richter, Tommy Salo, John Vanbiesbrouck, Curtis Joseph, Chris Osgood, Steve Shields, Tom Barrasso, Guy Hebert, Arturs Irbe, Byron Dafoe, Patrick Roy, Bill Ranford, Ed Belfour, Grant Fuhr, Dominik Hasek, Martin Brodeur, Mike Vernon, Ron Tugnutt, Sean Burke, Zach Thornton, Jocelyn Thibault, Kevin Hartman, Felix Potvin,  (C) pink, red, turquoise, blue, purple, green, yellow, beige, orange, taupe, white, lavender, fuchsia, brown, gray, black, mauve, royal blue, violet, chartreuse, teal, gold, burgundy, lilac, crimson, garnet, coral, grey, silver, olive green, cobalt blue, scarlet, tan, amber,  A limitation of these concepts is that CBC does not discover their actual names." ></td>
	<td class="line x" title="22:196	That is, CBC discovers a semantic class of Canadian provinces such as Manitoba, Alberta, and Ontario, but stops short of labeling the concept as Canadian Provinces." ></td>
	<td class="line x" title="23:196	Some applications such as question answering would benefit from class labels." ></td>
	<td class="line x" title="24:196	For example, given the concept list (B) and a label goalie/goaltender, a QA system could look for answers to the question Which goaltender won the most Hart Trophys? in the concept." ></td>
	<td class="line x" title="25:196	In this paper, we propose an algorithm for automatically inducing names for semantic classes and for finding instance/concept (is-a) relationships." ></td>
	<td class="line x" title="26:196	Using concept signatures (templates describing the prototypical syntactic behavior of instances of a concept), we extract concept names by searching for simple syntactic patterns such as concept apposition-of instance." ></td>
	<td class="line x" title="27:196	Searching concept signatures is more robust than searching the syntactic features of individual instances since many instances suffer from sparse features or multiple senses." ></td>
	<td class="line x" title="28:196	Once labels are assigned to concepts, we can extract a hyponym relationship between each instance of a concept and its label." ></td>
	<td class="line x" title="29:196	For example, once our system labels list (C) as color, we may extract relationships such as: pink is a color, red is a color, turquoise is a color, etc. Our results show that of the 159,000 hyponyms we extract using this simple method, 68% are correct." ></td>
	<td class="line x" title="30:196	Of the 65,000 proper name hyponyms we discover, 81.5% are correct." ></td>
	<td class="line x" title="31:196	The remainder of this paper is organized as follows." ></td>
	<td class="line x" title="32:196	In the next section, we review previous algorithms for extracting semantic classes and hyponym relationships." ></td>
	<td class="line x" title="33:196	Section 3 describes our algorithm for labeling concepts and for extracting hyponym relationships." ></td>
	<td class="line x" title="34:196	Experimental results are presented in Section 4 and finally, we conclude with a discussion and future work." ></td>
	<td class="line x" title="35:196	2 Previous Work There have been several approaches to automatically discovering lexico-semantic information from text (Hearst 1992; Riloff and Shepherd 1997; Riloff and Jones 1999; Berland and Charniak 1999; Pantel and Lin 2002; Fleischman et al. 2003; Girju et al. 2003)." ></td>
	<td class="line oc" title="36:196	One approach constructs automatic thesauri by computing the similarity between words based on their distribution in a corpus (Hindle 1990; Lin 1998)." ></td>
	<td class="line o" title="37:196	The output of these programs is a ranked list of similar words to each word." ></td>
	<td class="line x" title="38:196	For example, Lins approach outputs the following top-20 similar words of orange: (D) peach, grapefruit, yellow, lemon, pink, avocado, tangerine, banana, purple, Santa Ana, strawberry, tomato, red, pineapple, pear, Apricot, apple, green, citrus, mango A common problem of such lists is that they do not discriminate between the senses of polysemous words." ></td>
	<td class="line x" title="39:196	For example, in (D), the color and fruit senses of orange are mixed up." ></td>
	<td class="line x" title="40:196	Lin and Pantel (2001) proposed a clustering algorithm, UNICON, which generates similar lists but discriminates between senses of words." ></td>
	<td class="line x" title="41:196	Later, Pantel and Lin (2002) improved the precision and recall of UNICON clusters with CBC (Clustering by Committee)." ></td>
	<td class="line x" title="42:196	Using sets of representative elements called committees, CBC discovers cluster centroids that unambiguously describe the members of a possible class." ></td>
	<td class="line x" title="43:196	The algorithm initially discovers committees that are well scattered in the similarity space." ></td>
	<td class="line x" title="44:196	It then proceeds by assigning elements to their most similar committees." ></td>
	<td class="line x" title="45:196	After assigning an element to a cluster, CBC removes their overlapping features from the element before assigning it to another cluster." ></td>
	<td class="line x" title="46:196	This allows CBC to discover the less frequent senses of a word and to avoid discovering duplicate senses." ></td>
	<td class="line x" title="47:196	CBC discovered both the color sense of orange, as shown in list (C) of Section 1, and the fruit sense shown below: (E) peach, pear, apricot, strawberry, banana, mango, melon, apple, pineapple, cherry, plum, lemon, grapefruit, orange, berry, raspberry, blueberry, kiwi,  There have also been several approaches to discovering hyponym (is-a) relationships from text." ></td>
	<td class="line x" title="48:196	Hearst (1992) used seven lexico-syntactic patterns, for example such NP as {NP,}*{(or|and)} NP and NP {, NP}*{,} or other NP." ></td>
	<td class="line x" title="49:196	Berland and Charniak (1999) used similar pattern-based techniques and other heuristics to extract meronymy (part-whole) relations." ></td>
	<td class="line x" title="50:196	They reported an accuracy of about 55% precision on a corpus of 100,000 words." ></td>
	<td class="line x" title="51:196	Girju, Badulescu and Moldovan (2003) improved upon this work by using a machine learning filter." ></td>
	<td class="line x" title="52:196	Mann (2002) and Fleischman et al.(2003) used part of speech patterns to extract a subset of hyponym relations involing proper nouns." ></td>
	<td class="line x" title="54:196	3 Labeling Classes The research discussed above on discovering hyponym relationships all take a bottom up approach." ></td>
	<td class="line x" title="55:196	That is, they use patterns to independently discover semantic relationships of words." ></td>
	<td class="line x" title="56:196	However, for infrequent words, these patterns do not match or, worse yet, generate incorrect relationships." ></td>
	<td class="line x" title="57:196	Ours is a top down approach." ></td>
	<td class="line x" title="58:196	We make use of cooccurrence statistics of semantic classes discovered by algorithms like CBC to label their concepts." ></td>
	<td class="line x" title="59:196	Hyponym relationships may then be extracted easily: one hyponym per instance/concept label pair." ></td>
	<td class="line x" title="60:196	For example, if we labeled concept (A) from Section 1 with disease, then we could extract is-a relationships such as: diabetes is a disease, cancer is a disease, and lupus is a disease." ></td>
	<td class="line x" title="61:196	A concept instance such as lupus is assigned a hypernym disease not because it necessarily occurs in any particular syntactic relationship with disease, but because it belongs to the class of instances that does." ></td>
	<td class="line x" title="62:196	The input to our labeling algorithm is a list of semantic classes, in the form of clusters of words, which may be generated from any source." ></td>
	<td class="line x" title="63:196	In our experiments, we used the clustering outputs of CBC (Pantel and Lin 2002)." ></td>
	<td class="line x" title="64:196	The output of the system is a ranked list of concept names for each semantic class." ></td>
	<td class="line x" title="65:196	In the first phase of the algorithm, we extract feature vectors for each word that occurs in a semantic class." ></td>
	<td class="line x" title="66:196	Phase II then uses these features to compute grammatical signatures of concepts using the CBC algorithm." ></td>
	<td class="line x" title="67:196	Finally, we use simple syntactic patterns to discover class names from each class signature." ></td>
	<td class="line x" title="68:196	Below, we describe these phases in detail." ></td>
	<td class="line x" title="69:196	3.1 Phase I We represent each word (concept instance) by a feature vector." ></td>
	<td class="line x" title="70:196	Each feature corresponds to a context in which the word occurs." ></td>
	<td class="line x" title="71:196	For example, catch __ is a verbobject context." ></td>
	<td class="line x" title="72:196	If the word wave occurred in this context, then the context is a feature of wave." ></td>
	<td class="line x" title="73:196	We first construct a frequency count vector C(e) = (c e1, c e2, , c em ), where m is the total number of features and c ef is the frequency count of feature f occurring in word e. Here, c ef is the number of times word e occurred in a grammatical context f. For example, if the word wave occurred 217 times as the object of the verb catch, then the feature vector for wave will have value 217 for its object-of catch feature." ></td>
	<td class="line x" title="74:196	In Section 4.1, we describe how we obtain these features." ></td>
	<td class="line x" title="75:196	We then construct a mutual information vector MI(e) = (mi e1, mi e2, , mi em ) for each word e, where mi ef is the pointwise mutual information between word e and feature f, which is defined as: N c N c N c ef m j ej n i if ef mi   = =  = 1 1 log (1) where n is the number of words and N =  == n i m j ij c 11 is the total frequency count of all features of all words." ></td>
	<td class="line x" title="76:196	Mutual information is commonly used to measure the association strength between two words (Church and Hanks 1989)." ></td>
	<td class="line x" title="77:196	A well-known problem is that mutual information is biased towards infrequent elements/features." ></td>
	<td class="line x" title="78:196	We therefore multiply mi ef with the following discounting factor: 1,min,min 1 11 11 +                  +   == == m j jf n i ei m j jf n i ei ef ef cc cc c c (2) 3.2 Phase II Following (Pantel and Lin 2002), we construct a committee for each semantic class." ></td>
	<td class="line x" title="79:196	A committee is a set of representative elements that unambiguously describe the members of a possible class." ></td>
	<td class="line x" title="80:196	For each class c, we construct a matrix containing the similarity between each pair of words e i and e j in c using the cosine coefficient of their mutual information vectors (Salton and McGill 1983): ()     = f fe f fe f fefe ji ji ji mimi mimi eesim 22, (3) For each word e, we then cluster its most similar instances using group-average clustering (Han and Kamber 2001) and we store as a candidate committee the highest scoring cluster c' according to the following metric: | c'|  avgsim(c') (4) where |c'| is the number of elements in c' and avgsim(c') is the average pairwise similarity between words in c'." ></td>
	<td class="line x" title="81:196	The assumption is that the best representative for a concept is a large set of very similar instances." ></td>
	<td class="line x" title="82:196	The committee for class c is then the highest scoring candidate committee containing only words from c. For example, below are the committee members discovered for the semantic classes (A), (B), and (C) from Section 1: 1) cardiovascular disease, diabetes, multiple sclerosis, osteoporosis, Parkinson's, rheumatoid arthritis 2) Curtis Joseph, John Vanbiesbrouck, Mike Richter, Tommy Salo 3) blue, pink, red, yellow 3.3 Phase III By averaging the feature vectors of the committee members of a particular semantic class, we obtain a grammatical template, or signature, for that class." ></td>
	<td class="line x" title="83:196	For example, Figure 1 shows an excerpt of the grammatical signature for concept (B) in Section 1." ></td>
	<td class="line x" title="84:196	The vector is obtained by averaging the feature vectors for the words Curtis Joseph, John Vanbiesbrouck, Mike Richter, and Tommy Salo (the committee of this concept)." ></td>
	<td class="line x" title="85:196	The -V:subj:N:sprawl feature indicates a subject-verb relationship between the concept and the verb sprawl while N:appo:N:goaltender indicates an apposition relationship between the concept and the noun goaltender." ></td>
	<td class="line x" title="86:196	The (-) in a relationship means that the right hand side of the relationship is the head (e.g. sprawl is the head of the subject-verb relationship)." ></td>
	<td class="line x" title="87:196	The two columns of numbers indicate the frequency and mutual information score for each feature respectively." ></td>
	<td class="line x" title="88:196	In order to discover the characteristics of human naming conventions, we manually named 50 concepts discovered by CBC." ></td>
	<td class="line x" title="89:196	For each concept, we extracted the relationships between the concept committee and the assigned label." ></td>
	<td class="line x" title="90:196	We then added the mutual information scores for each extracted relationship among the 50 concepts." ></td>
	<td class="line x" title="91:196	The top-4 highest scoring relationships are:  Apposition (N:appo:N) e.g.  Oracle, a company known for its progressive employment policies,   Nominal subject (-N:subj:N) e.g.  Apple was a hot young company, with Steve Jobs in charge." ></td>
	<td class="line x" title="92:196	 Such as (-N:such as:N) e.g.  companies such as IBM must be weary   Like (-N:like:N) e.g.  companies like Sun Microsystems do no shy away from such challenges,  To name a class, we simply search for these syntactic relationships in the signature of a concept." ></td>
	<td class="line x" title="93:196	We sum up the mutual information scores for each term that occurs in these relationships with a committee of a class." ></td>
	<td class="line x" title="94:196	The highest scoring term is the name of the class." ></td>
	<td class="line x" title="95:196	For example, the top-5 scoring terms that occurred in these relationships with the signature of the concept represented by the committee {Curtis Joseph, John Vanbiesbrouck, Mike Richter, Tommy Salo} are: 1) goalie 40.37 2) goaltender 33.64 3) goalkeeper 19.22 4) player 14.55 5) backup 9.40 The numbers are the total mutual information scores of each name in the four syntactic relationships." ></td>
	<td class="line x" title="96:196	4 Evaluation In this section, we present an evaluation of the class labeling algorithm and of the hyponym relationships discovered by our system." ></td>
	<td class="line x" title="97:196	4.1 Experimental Setup We used Minipar (Lin 1994), a broad coverage parser, to parse 3GB of newspaper text from the Aquaint (TREC-9) collection." ></td>
	<td class="line x" title="98:196	We collected the frequency counts of the grammatical relationships (contexts) output by Minipar and used them to compute the pointwise mutual information vectors described in Section 3.1." ></td>
	<td class="line x" title="99:196	We used the 1432 noun clusters extracted by CBC 1 as the list of concepts to name." ></td>
	<td class="line x" title="100:196	For each concept, we then used our algorithm described in Section 3 to extract the top-20 names for each concept." ></td>
	<td class="line x" title="101:196	1 Available at http://www.isi.edu/~pantel/demos.htm {Curtis Joseph, John Vanbiesbrouck, Mike Richter, Tommy Salo} -N:gen:N pad 57 11.19 backup 29 9.95 crease 7 9.69 glove 52 9.57 stick 20 9.15 shutout 17 8.80 -N:conj:N Hasek 15 12.36 Martin Brodeur 12 12.26 Belfour 13 12.22 Patrick Roy 10 11.90 Dominik Hasek 7 11.20 Roy 6 10.01 -V:subj:N sprawl 11 6.69 misplay 6 6.55 smother 10 6.54 skate 28 6.43 turn back 10 6.28 stop 453 6.19 N:appo:N goaltender 449 10.79 goalie 1641 10.76 netminder 57 10.39 goalkeeper 487 9.69 N:conj:N Martin Brodeur 11 12.49 Dominik Hasek 11 12.33 Ed Belfour 10 12.04 Curtis Joseph 7 11.46 Tom Barrasso 5 10.85 Byron Dafoe 5 10.80 Chris Osgood 4 10.25 Figure 1." ></td>
	<td class="line x" title="102:196	Excerpt of the grammatical signature for the goalie/goaltender concept." ></td>
	<td class="line x" title="103:196	4.2 Labeling Precision Out of the 1432 noun concepts, we were unable to name 21 (1.5%) of them." ></td>
	<td class="line x" title="104:196	This occurs when a concepts committee members do not occur in any of the four syntactic relationships described in Section 0." ></td>
	<td class="line x" title="105:196	We performed a manual evaluation of the remaining 1411 concepts." ></td>
	<td class="line x" title="106:196	We randomly selected 125 concepts and their top-5 highest ranking names according to our algorithm." ></td>
	<td class="line x" title="107:196	Table 1 shows the first 10 randomly selected concepts (each concept is represented by three of its committee members)." ></td>
	<td class="line x" title="108:196	For each concept, we added to the list of names a human generated name (obtained from an annotator looking at only the concept instances)." ></td>
	<td class="line x" title="109:196	We also appended concept names extracted from WordNet." ></td>
	<td class="line x" title="110:196	For each concept that contains at least five instances in the WordNet hierarchy, we named the concept with the most frequent common ancestor of each pair of instances." ></td>
	<td class="line x" title="111:196	Up to five names were generated by WordNet for each concept." ></td>
	<td class="line x" title="112:196	Because of the low coverage of proper nouns in WordNet, only 33 of the 125 concepts we evaluated had WordNet generated labels." ></td>
	<td class="line x" title="113:196	We presented to three human judges the 125 randomly selected concepts together with the system, human, and WordNet generated names randomly ordered." ></td>
	<td class="line x" title="114:196	That way, there was no way for a judge to know the source of a label nor the systems ranking of the labels." ></td>
	<td class="line x" title="115:196	For each name, we asked the judges to assign a score of correct, partially correct, or incorrect." ></td>
	<td class="line x" title="116:196	We then computed the mean reciprocal rank (MRR) of the system, human, and WordNet labels." ></td>
	<td class="line x" title="117:196	For each concept, a naming scheme receives a score of 1 / M where M is the rank of the first name judged correct." ></td>
	<td class="line x" title="118:196	Table 2 shows the results." ></td>
	<td class="line x" title="119:196	Table 3 shows similar results for a more lenient evaluation where M is the rank of the first name judged correct or partially correct." ></td>
	<td class="line x" title="120:196	Our system achieved an overall MRR score of 77.1%." ></td>
	<td class="line x" title="121:196	We performed much better than the baseline WordNet (19.9%) because of the lack of coverage (mostly proper nouns) in the hierarchy." ></td>
	<td class="line x" title="122:196	For the 33 concepts that WordNet named, it achieved a score of 75.3% and a lenient score of 82.7%, which is high considering the simple algorithm we used to extract labels using WordNet." ></td>
	<td class="line x" title="123:196	The Kappa statistic (Siegel and Castellan Jr. 1988) measures the agreements between a set of judges assessments correcting for chance agreements: ( )() ()EP EPAP K   = 1 (5) where P(A) is the probability of agreement between the judges and P(E) is the probability that the judges agree Table 1." ></td>
	<td class="line x" title="124:196	Labels assigned to 10 randomly selected concepts (each represented by three committee members." ></td>
	<td class="line x" title="125:196	CBC CONCEPT HUMAN LABEL WORDNET LABELS SYSTEM LABELS (RANKED) BMG, EMI, Sony record label none label / company / album / machine / studio Preakness Stakes, Preakness, Belmont Stakes horse race none race / event / run / victory / start Olympia Snowe, Susan Collins, James Jeffords US senator none republican / senator / chairman / supporter / conservative Eldoret, Kisumu, Mombasa African city none city / port / cut off / town / southeast Bronze Star, Silver Star, Purple Heart medal decoration / laurel wreath / medal / medallion / palm distinction / set / honor / symbol Mike Richter, Tommy Salo, John Vanbiesbrouck NHL goalie none goalie / goaltender / goalkeeper / player / backup Dodoma, Mwanza, Mbeya African city none facilitator / town fresco, wall painting, Mural art painting / picture painting / world / piece / floor / symbol Qinghua University, Fudan University, Beijing University university none university / institution / stockholder / college / school Federal Bureau of Investigation, Drug Enforcement Administration, FBI governmental department law enforcement agency agency / police / investigation / department / FBI by chance on an assessment." ></td>
	<td class="line x" title="126:196	An experiment with K  0.8 is generally viewed as reliable and 0.67 < K < 0.8 allows tentative conclusions." ></td>
	<td class="line x" title="127:196	The Kappa statistic for our experiment is K = 0.72." ></td>
	<td class="line x" title="128:196	The human labeling is at a disadvantage since only one label was generated per concept." ></td>
	<td class="line x" title="129:196	Therefore, the human scores either 1 or 0 for each concept." ></td>
	<td class="line x" title="130:196	Our systems highest ranking name was correct 72% of the time." ></td>
	<td class="line x" title="131:196	Table 4 shows the percentage of semantic classes with a correct label in the top 1-5 ranks returned by our system." ></td>
	<td class="line x" title="132:196	Overall, 41.8% of the top-5 names extracted by our system were judged correct." ></td>
	<td class="line x" title="133:196	The overall accuracy for the top-4, top-3, top-2, and top-1 names are 44.4%, 48.8%, 58.5%, and 72% respectively." ></td>
	<td class="line x" title="134:196	Hence, the name ranking of our algorithm is effective." ></td>
	<td class="line x" title="135:196	4.3 Hyponym Precision The 1432 CBC concepts contain 18,000 unique words." ></td>
	<td class="line x" title="136:196	For each concept to which a word belongs, we extracted up to 3 hyponyms, one for each of the top-3 labels for the concept." ></td>
	<td class="line x" title="137:196	The result was 159,000 hyponym relationships." ></td>
	<td class="line x" title="138:196	24 are shown in the Appendix." ></td>
	<td class="line x" title="139:196	Two judges annotated two random samples of 100 relationships: one from all 159,000 hyponyms and one from the subset of 65,000 proper nouns." ></td>
	<td class="line x" title="140:196	For each instance, the judges were asked to decide whether the hyponym relationship was correct, partially correct or incorrect." ></td>
	<td class="line x" title="141:196	Table 5 shows the results." ></td>
	<td class="line x" title="142:196	The strict measure counts a score of 1 for each correctly judged instance and 0 otherwise." ></td>
	<td class="line x" title="143:196	The lenient measure also gives a score of 0.5 for each instance judged partially correct." ></td>
	<td class="line x" title="144:196	Many of the CBC concepts contain noise." ></td>
	<td class="line x" title="145:196	For example, the wine cluster: Zinfandel, merlot, Pinot noir, Chardonnay, Cabernet Sauvignon, cabernet, riesling, Sauvignon blanc, Chenin blanc, sangiovese, syrah, Grape, Chianti  contains some incorrect instances such as grape, appelation, and milk chocolate." ></td>
	<td class="line x" title="146:196	Each of these instances will generate incorrect hyponyms such as grape is wine and milk chocolate is wine." ></td>
	<td class="line x" title="147:196	This hyponym extraction task would likely serve well for evaluating the accuracy of lists of semantic classes." ></td>
	<td class="line x" title="148:196	Table 5 shows that the hyponyms involving proper nouns are much more reliable than common nouns." ></td>
	<td class="line x" title="149:196	Since WordNet contains poor coverage of proper nouns, these relationships could be useful to enrich it." ></td>
	<td class="line x" title="150:196	4.4 Recall Semantic extraction tasks are notoriously difficult to evaluate for recall." ></td>
	<td class="line x" title="151:196	To approximate recall, we conducted two question answering (QA) tasks: answering definition questions and performing QA information retrieval." ></td>
	<td class="line x" title="152:196	Table 2." ></td>
	<td class="line x" title="153:196	MRR scores for the human evaluation of naming 125 random concepts." ></td>
	<td class="line x" title="154:196	JUDGE HUMAN LABELS WordNet Labels System Labels 1 100% 18.1% 74.4% 2 91.2% 20.0% 78.1% 3 89.6% 21.6% 78.8% Combined 93.6% 19.9% 77.1% Table 3." ></td>
	<td class="line x" title="155:196	Lenient MRR scores for the human evaluation of naming 125 random concepts." ></td>
	<td class="line x" title="156:196	JUDGE HUMAN LABELS WordNet Labels System Labels 1 100% 22.8% 85.0% 2 96.0% 20.8% 86.5% 3 92.0% 21.8% 85.2% Combined 96.0% 21.8% 85.6% Table 4." ></td>
	<td class="line x" title="157:196	Percentage of concepts with a correct name in the top-5 ranks returned by our system." ></td>
	<td class="line x" title="158:196	JUDGE TOP-1 TOP-2 TOP-3 TOP-4 TOP-5 1 68.8% 75.2% 78.4% 83.2% 84.0% 2 73.6% 80.0% 81.6% 83.2% 84.8% 3 73.6% 80.0% 82.4% 84.0% 88.8% Combined 72.0% 78.4% 80.8% 83.5% 85.6% Table 5." ></td>
	<td class="line x" title="159:196	Accuracy of 159,000 extracted hyponyms and a subset of 65,000 proper noun hyponyms." ></td>
	<td class="line x" title="160:196	JUDGE All Nouns Proper Nouns Strict Lenient Strict Lenient 1 62.0% 68.0% 79.0% 82.0% 2 74.0% 76.5% 84.0% 85.5% Combined 68.0% 72.2% 81.5% 83.8% Definition Questions We chose the 50 definition questions that appeared in the QA track of TREC2003 (Voorhees, 2003)." ></td>
	<td class="line x" title="161:196	For example: Who is Aaron Copland? and What is the Kama Sutra? For each question we looked for at most five corresponding concepts in our hyponym list." ></td>
	<td class="line x" title="162:196	For example, for Aaron Copland, we found the following hypernyms: composer, music, and gift." ></td>
	<td class="line x" title="163:196	We compared our system with the concepts in WordNet and Fleischman et al.s instance/concept relations (Fleischman et al. 2003)." ></td>
	<td class="line x" title="164:196	Table 6 shows the percentage of correct answers in the top-1 and top-5 returned answers from each system." ></td>
	<td class="line x" title="165:196	All systems seem to have similar performance on the top-1 answers, but our system has many more answers in the top-5." ></td>
	<td class="line x" title="166:196	This shows that our system has comparatively higher recall for this task." ></td>
	<td class="line x" title="167:196	Information (Passage) Retrieval Passage retrieval is used in QA to supply relevant information to an answer pinpointing module." ></td>
	<td class="line x" title="168:196	The higher the performance of the passage retrieval module, the higher will be the performance of the answer pinpointing module." ></td>
	<td class="line x" title="169:196	The passage retrieval module can make use of the hyponym relationships that are discovered by our system." ></td>
	<td class="line x" title="170:196	Given a question such as What color , the likelihood of a correct answer being present in a retrieved passage is greatly increased if we know the set of all possible colors and index them in the document collection appropriately." ></td>
	<td class="line x" title="171:196	We used the hyponym relations learned by our system to perform semantic indexing on a QA passage retrieval task." ></td>
	<td class="line x" title="172:196	We selected the 179 questions from the QA track of TREC-2003 that had an explicit semantic answer type (e.g. What band was Jerry Garcia with? and What color is the top stripe on the U.S. flag?)." ></td>
	<td class="line x" title="173:196	For each expected semantic answer type corresponding to a given question (e.g. band and color), we indexed the entire TREC-2002 IR collection with our systems hyponyms." ></td>
	<td class="line x" title="174:196	We compared the passages returned by the passage retrieval module with and without the semantic indexing." ></td>
	<td class="line x" title="175:196	We counted how many of the 179 questions had a correct answer returned in the top-1 and top-100 passages." ></td>
	<td class="line x" title="176:196	Table 7 shows the results." ></td>
	<td class="line x" title="177:196	Our system shows small gains in the performance of the IR output." ></td>
	<td class="line x" title="178:196	In the top-1 category, the performance improved by 20%." ></td>
	<td class="line x" title="179:196	This may lead to better answer selections." ></td>
	<td class="line x" title="180:196	5 Conclusions and Future Work Current state of the art concept discovery algorithms generate lists of instances of semantic classes but stop short of labeling the classes with concept names." ></td>
	<td class="line x" title="181:196	Class labels would serve useful in applications such as question answering to map a question concept into a semantic class and then search for answers within that class." ></td>
	<td class="line x" title="182:196	We propose here an algorithm for automatically labeling concepts that searches for syntactic patterns within a grammatical template for a class." ></td>
	<td class="line x" title="183:196	Of the 1432 noun concepts discovered by CBC, our system labelled 98.5% of them with an MRR score of 77.1% in a human evaluation." ></td>
	<td class="line x" title="184:196	Hyponym relationships were then easily extracted, one for each instance/concept label pair." ></td>
	<td class="line x" title="185:196	We extracted 159,000 hyponyms and achieved a precision of 68%." ></td>
	<td class="line x" title="186:196	On a subset of 65,000 proper names, our performance was 81.5%." ></td>
	<td class="line x" title="187:196	This work forms an important attempt to building large-scale semantic knowledge bases." ></td>
	<td class="line x" title="188:196	Without being able to automatically name a cluster and extract hyponym/hypernym relationships, the utility of automatically generated clusters or manually compiled lists of terms is limited." ></td>
	<td class="line x" title="189:196	Of course, it is a serious open question how many names each cluster (concept) should have, and how good each name is. Our method begins to address this thorny issue by quantifying the name assigned to a class and by simultaneously assigning a number that can be interpreted to reflect the strength of membership of each element to the class." ></td>
	<td class="line x" title="190:196	This is potentially a significant step away from traditional all-or-nothing semantic/ontology representations to a concept representation Table 6." ></td>
	<td class="line x" title="191:196	Percentage of correct answers in the Top-1 and Top-5 returned answers on 50 definition questions." ></td>
	<td class="line x" title="192:196	SYSTEM Top-1 Top-5 Strict Lenient Strict Lenient WordNet 38% 38% 38% 38% Fleischman 36% 40% 42% 44% Our System 36% 44% 60% 62% Table 7." ></td>
	<td class="line x" title="193:196	Percentage of questions where the passage retrieval module returns a correct answer in the Top-1 and Top-100 ranked passages (with and without semantic indexing)." ></td>
	<td class="line x" title="194:196	CORRECT TOP-1 Correct Top-100 With semantic indexing 43 / 179 134 / 179 Without semantic indexing 36 / 179 131 / 179 scheme that is more nuanced and admits multiple names and graded set memberships." ></td>
	<td class="line x" title="195:196	Acknowledgements The authors wish to thank the reviewers for their helpful comments." ></td>
	<td class="line x" title="196:196	This research was partly supported by NSF grant #EIA-0205111." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W04-1216
Named Entity Recognition In Biomedical Texts Using An HMM Model
Zhao, Shaojun;"></td>
	<td class="line x" title="1:99	Named Entity Recognition in Biomedical Texts using an HMM Model Shaojun Zhao Department of Computing Science University of Alberta Edmonton, Canada, T6G 2H8 shaojun@cs.ualberta.ca Abstract Although there exists a huge number of biomedical texts online, there is a lack of tools good enough to help people get information or knowledge from them." ></td>
	<td class="line x" title="2:99	Named entity Recognition (NER) becomes very important for further processing like information retrieval, information extraction and knowledge discovery." ></td>
	<td class="line x" title="3:99	We introduce a Hidden Markov Model (HMM) for NER, with a word similarity-based smoothing." ></td>
	<td class="line x" title="4:99	Our experiment shows that the word similarity-based smoothing can improve the performance by using huge unlabeled data." ></td>
	<td class="line x" title="5:99	While many systems have laboriously hand-coded rules for all kinds of word features, we show that word similarity is a potential method to automatically get word formation, prefix, suffix and abbreviation information automatically from biomedical texts, as well as useful word distribution information." ></td>
	<td class="line x" title="6:99	1 Introduction In the Message Understanding Conference (MUC), Named entity Recognition aims to classify proper nouns, dates, time, measures and locations, etc. Many researchers adapt their systems from MUC to the biomedical domain, such as (Fukuda et al 1998), (Proux et al 1998), (Nobata et al 2000), (Collier et al 2000), (Gaizauskas et al 2000), (Kazama et al 2002), (Takeuchi et al 2002), (Lee et al 2003) and (Zhou et al 2004)." ></td>
	<td class="line x" title="7:99	As opposed to rule-based systems, machine learning-based systems could train their models on labeled data." ></td>
	<td class="line x" title="8:99	But due to the irregular forms of biomedical texts, people still need to carefully choose word features for their systems." ></td>
	<td class="line x" title="9:99	This work requires domain specific knowledge." ></td>
	<td class="line x" title="10:99	How to get the domain knowledge automatically is a question that has not been fully investigated." ></td>
	<td class="line x" title="11:99	Our system is built on an HMM model with the words themselves as the features." ></td>
	<td class="line x" title="12:99	Huge unlabeled corpus is gathered from MEDLINE." ></td>
	<td class="line x" title="13:99	Word similarity information is computed from the corpus and we use a word similarity-based smoothing to overcome the data sparseness." ></td>
	<td class="line x" title="14:99	2 Data Preparation 2.1 Labeled Data Our labeled data is from GENIA 3.02 (Ohta et al 2002), which contains 2,000 abstracts (360K words)." ></td>
	<td class="line x" title="15:99	It has been annotated with semantic information such as DNA, protein annotations." ></td>
	<td class="line x" title="16:99	These are useful for training models." ></td>
	<td class="line x" title="17:99	It contains Part of Speech (POS) information as well." ></td>
	<td class="line x" title="18:99	Although POS is not considered very useful for NER in newspaper articles, it can dramatically improve the performance of NER in biomedical texts (Zhou et al 2004)." ></td>
	<td class="line x" title="19:99	Our model is trained from this labeled data." ></td>
	<td class="line x" title="20:99	2.2 Unlabeled Data We downloaded 17G XML abstract data from MEDLINE, which contains 1,381,132 abstracts." ></td>
	<td class="line x" title="21:99	Compared to the labeled data, we have far more unlabeled data, and the amount of available unlabeled data increases every day." ></td>
	<td class="line x" title="22:99	We used this unlabeled data for computing word similarity." ></td>
	<td class="line x" title="23:99	We extracted 66,303,526 proximity relationships from the unlabeled data." ></td>
	<td class="line x" title="24:99	3 Distributional Word Similarity Words that tend to appear in the same contexts tend to have similar meanings. (Harris 1968)." ></td>
	<td class="line oc" title="25:99	For example, the words corruption and abuse are similar because both of them can be subjects of verbs like arouse, become, betray, cause, continue, cost, exist, force, go on, grow, have, increase, lead to, and persist, etc, and both of them can modify nouns like accusation, act, allegation, appearance, and case, etc. Many methods have been proposed to compute distributional similarity between words, e.g., (Hindle, 1990), (Pereira et al. 1993), (Grefenstette 1994) and (Lin 1998)." ></td>
	<td class="line o" title="26:99	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared." ></td>
	<td class="line x" title="27:99	84 3.1 Proximity-based Similarity It is natural to use dependency relationship (Mel'uk, 1987) as features, but a parser has to be available." ></td>
	<td class="line x" title="28:99	Since biomedical text is highly irregular, and is very different from text like newspaper, a parser developed for the newspaper domain may not perform very well on biomedical text." ></td>
	<td class="line x" title="29:99	Since most dependency relationships involve words that are situated close to one another, the dependency relationships can often be approximated by cooccurrence relationships within a small window (Turney 2001); (Terra and Clarke 2003)." ></td>
	<td class="line x" title="30:99	We define the features of the word w to be the first non-stop word on either side of w and the intervening stop words (which can be defined as the top-k most frequent words in the corpus)." ></td>
	<td class="line x" title="31:99	For example, for a sentence He got a job from this company. (Considering a, from and this to be stop words.), the features of job provided by this sentence are shown in Table 1." ></td>
	<td class="line x" title="32:99	Features Frequency (left, got) 0.50 (left, a) 0.50 (right,from) 0.33 (right, this) 0.33 (right, company) 0.33   Table 1: Features for word job 3.2 Computing Word Similarity Once the contexts of a word are represented as a feature vector, the similarity between two words can be computed using their context vectors." ></td>
	<td class="line x" title="33:99	We use (u 1, u 2  u n ) and (v 1, v 2  v n ) to denote the feature vectors for the words u and v respectively, where n is the number of feature types extracted from a corpus." ></td>
	<td class="line x" title="34:99	We use f i to denote the ith feature." ></td>
	<td class="line x" title="35:99	The point-wise mutual information (PMI) between a feature f i and a word u measures the strength association between them." ></td>
	<td class="line x" title="36:99	It is defined as: () ( ) () ()          = uPfP ufP ufpmi i i i, log, where P(f i,u) is the probability of f i co-occurring with u; P(f i ) is the probability of f i co-occurring with any word; and P(u) is the probability of any feature co-occurring with u. The similarity between word u and v is defined as the Cosine of PMI: () () () () ()   == =   = n i i n i i n i ii word vfpmiufpmi vfpmiufpmi vusim 1 2 1 2 1,,,,, Different similarity measures of distributional similarity can affect the quality of the result to s statistically significant degree." ></td>
	<td class="line x" title="37:99	(Zhao and Lin 2004) shows that the Cosine of PMI is a significantly better similarity measure than several other commonly used similarity measures." ></td>
	<td class="line x" title="38:99	Similar words are computed for each word in the unlabeled data." ></td>
	<td class="line x" title="39:99	Only a subset of the similarity information is useful, because the similarity of words outside of the training data and test data vocabulary is not used." ></td>
	<td class="line x" title="40:99	We only take into account the similar words that occur in the training data more than 10 times and only those word pairs which have point-wise mutual information greater than a threshold (0.04)." ></td>
	<td class="line x" title="41:99	Table 2 shows the computing result for IL-0 1 : Similar Words Similarity interleukin-0 0.510891 IL-00 0.486665 IFN-gamma 0.44945 TNF-alpha 0.44702 GM-CSF 0.438226 TNF 0.37703 IL-0beta 0.365072 interferon-gamma 0.350704 IL0 0.336974   Table 2: Similar words for IL-0 Table 2 also shows that the similar words can capture word formation (IL-00, IL-0beta, and IL0 etc) and abbreviation (interleukin-0) information." ></td>
	<td class="line x" title="42:99	A complete list of these word pairs and their similarity is available online 2." ></td>
	<td class="line x" title="43:99	The rule-based system may not able to capture words like IL-0ra, IL-0Ralpha, which are in the similar word list of IL-0, and it is very likely that they belong to the same semantic category." ></td>
	<td class="line x" title="44:99	Many different kinds of expressions for numbers (like 0, 00-00, 00.00, -00, 0/0, five, six, 0-, iii, IV etc) are grouped together automatically." ></td>
	<td class="line x" title="45:99	4 HMM Model and Smoothing Schema We follow the HMM model introduced in (Zhou et al 2004)." ></td>
	<td class="line x" title="46:99	The structure of an HMM model contains States and observations." ></td>
	<td class="line x" title="47:99	In our model, each state is represented by a semantic tag, or a POS tag if the semantic tag is not available; each observation contains a word sequence." ></td>
	<td class="line x" title="48:99	The main computing difficulty in (Zhou et al 2004) is the probability of a tag given a word sequence: formula (1)." ></td>
	<td class="line x" title="49:99	We use formula (2) to estimate formula (1)." ></td>
	<td class="line x" title="50:99	If the bigram is unseen in the training data, we use formula (3)." ></td>
	<td class="line x" title="51:99	If the unigram is also unseen, we use the unknown information which is 1 We changed any single digit to 0." ></td>
	<td class="line x" title="52:99	2 http://www.cs.ualberta.ca/~shaojun/biolist.txt 85 gathered from the low frequency words in the training data." ></td>
	<td class="line x" title="53:99	( ) () (3) | (2),| (1) | 1 tt ttt t wordtagP wordwordtagP cewordsequentagP + We find that about 26% of the bigrams (word t, word t+1 ) in the testing data is unseen, so the smoothing is critical." ></td>
	<td class="line x" title="54:99	In order to compute formula (1), we can use the back-off (Katz 1987); (Bikel et al 1999) approach." ></td>
	<td class="line x" title="55:99	Baseline1 and Baseline2 in our system use different back-off schema." ></td>
	<td class="line x" title="56:99	The following formula is introduced in (Lee 1999) for word similarity-based smoothing: )4( ),( )|(),( )|( )( )( 1     +   = tt tt wSw tt wSw tttt tt wwsim wtagPwwsim wtagP where S(w) is a set of candidate similar words and sim(w,w) is the similarity between word w and w." ></td>
	<td class="line x" title="57:99	Word similarity-based smoothing approach is used in our system to make advantage of the huge unlabeled corpus." ></td>
	<td class="line x" title="58:99	In order to plug the word similarity-based smoothing into our HMM model, we made several extensions to formula (4)." ></td>
	<td class="line x" title="59:99	For each word w, we define p as the distribution of ws tags, which are annotated in the training data." ></td>
	<td class="line x" title="60:99	We use the KL-Divergence to compute the distance between two distributions: () () ( ) () ( )  = x xp xp xpppKLD 2 1 log|| 121 We define the similarity between the tag distributions of word w and w as: () ()()wtagPwtagPKLD wwsim tag + = ||||1 1, The harmonic average of word similarity and tag distribution similarity is defined as the similarity of word w and w used in our system." ></td>
	<td class="line x" title="61:99	() () () () ()wwsimwwsim wwsimwwsim wws tagword tagword +  =,,,,2, So, we get formula (5) and (6)." ></td>
	<td class="line x" title="62:99	Formula (5) is for bigram smoothing and formula (6) is for unigram smoothing." ></td>
	<td class="line x" title="63:99	() ()( ) () () () () ()( ) () () () (6), |, | (5),,|,,| 11 11 11 11 11 111 1     ++ ++ ++ ++    ++  +++ +   =   = tt tt tt tt wSw tt wSw tttt tt wSw tt wSw ttttt ttt wws wtagPwws wtagP wws wwtagPwws wwtagP Because it is natural to back-off from bigram to unigram, in our system, a back-off smoothing approach is combined with the word similaritybased smoothing." ></td>
	<td class="line x" title="64:99	We follow these procedures to compute formula (1)." ></td>
	<td class="line x" title="65:99	1." ></td>
	<td class="line x" title="66:99	Check the frequency of the bigram (w t, w t+1 )." ></td>
	<td class="line x" title="67:99	If the frequency is high (>10), use formula (2)." ></td>
	<td class="line x" title="68:99	Stop." ></td>
	<td class="line x" title="69:99	2." ></td>
	<td class="line x" title="70:99	Check the frequency of the unigram (w t )." ></td>
	<td class="line x" title="71:99	If the frequency of the unigram is high (>30), use formula (3)." ></td>
	<td class="line x" title="72:99	Stop." ></td>
	<td class="line x" title="73:99	3." ></td>
	<td class="line x" title="74:99	Try formula (5) for bigram smoothing, and check the frequency summary of the similar words involved in the smoothing." ></td>
	<td class="line x" title="75:99	If the summary is high (>10), use formula (5)." ></td>
	<td class="line x" title="76:99	Stop." ></td>
	<td class="line x" title="77:99	4." ></td>
	<td class="line x" title="78:99	Try formula (6) for unigram smoothing, and check the frequency summary for this case." ></td>
	<td class="line x" title="79:99	If the summary is high (>30), use formula (6)." ></td>
	<td class="line x" title="80:99	Stop." ></td>
	<td class="line x" title="81:99	5." ></td>
	<td class="line x" title="82:99	If the bigram is not unseen, use formula (2)." ></td>
	<td class="line x" title="83:99	Stop." ></td>
	<td class="line x" title="84:99	6." ></td>
	<td class="line x" title="85:99	If the unigram is not unseen, use formula (3)." ></td>
	<td class="line x" title="86:99	Stop." ></td>
	<td class="line x" title="87:99	7." ></td>
	<td class="line x" title="88:99	Use low frequency (<5) word information in the training data and formula (3)." ></td>
	<td class="line x" title="89:99	Our Baseline1 uses step 5, 6 and 7; Baseline2 uses step 1, 2, 5, 6 and 7." ></td>
	<td class="line x" title="90:99	5 Experiment Result The experiment results are shown in Table 3: Methods R P F-score Baseline1 64.77% 59.87% 62.22% Baseline2 66.99% 61.25% 63.99% Our system 69.41% 62.98% 66.04% Table 3: Performance comparison The Baseline2 outperforms Baseline1 because it prevents from using low frequency unigrams, and our system outperforms Baseline1 and Baseline2 because it prevents from using low frequency bigrams and unigrams." ></td>
	<td class="line x" title="91:99	Our system benefits from huge unlabeled corpus." ></td>
	<td class="line x" title="92:99	6 Conclusion We trained an HMM model on labelled data to recognize named entities in biomedical texts." ></td>
	<td class="line x" title="93:99	Word similarity information was computed from huge unlabeled data." ></td>
	<td class="line x" title="94:99	A word similarity-based smoothing method was integrated into the system, and improved the overall performance." ></td>
	<td class="line x" title="95:99	We would like to see if it could also be plugged into other existing systems, and hopefully also improve their performance." ></td>
	<td class="line x" title="96:99	We also argue that the automatically acquired similar words are rich with word features, such as word formation, prefix, suffix, abbreviation, expression variation and clustering information." ></td>
	<td class="line x" title="97:99	We will further investigate the usefulness of them in the future." ></td>
	<td class="line x" title="98:99	86 7 Acknowledgements Thanks to Dekang Lin and other members in the Natural Language Processing Group at the University of Alberta for helpful discussion, the anonymous reviewers for their insightful comments." ></td>
	<td class="line x" title="99:99	This material is based upon work supported by the Alberta Ingenuity Centre for Machine Learning (AICML)." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="J05-4002
Co-Occurrence Retrieval: A Flexible Framework For Lexical Distributional Similarity
Weeds, Julie;Weir, David J.;"></td>
	<td class="line x" title="1:515	Co-occurrence Retrieval: A Flexible Framework for Lexical Distributional Similarity Julie Weeds and David Weir  University of Sussex Techniques that exploit knowledge of distributional similarity between words have been proposed in many areas of Natural Language Processing." ></td>
	<td class="line x" title="2:515	For example, in language modeling, the sparse data problem can be alleviated by estimating the probabilities of unseen co-occurrences of events from the probabilities of seen co-occurrences of similar events." ></td>
	<td class="line x" title="3:515	In other applications, distributional similarity is taken to be an approximation to semantic similarity." ></td>
	<td class="line x" title="4:515	However, due to the wide range of potential applications and the lack of a strict definition of the concept of distributional similarity, many methods of calculating distributional similarity have been proposed or adopted." ></td>
	<td class="line x" title="5:515	In this work, a flexible, parameterized framework for calculating distributional similarity is proposed." ></td>
	<td class="line x" title="6:515	Within this framework, the problem of finding distributionally similar words is cast as one of co-occurrence retrieval (CR) for which precision and recall can be measured by analogy with the way they are measured in document retrieval." ></td>
	<td class="line x" title="7:515	As will be shown, a number of popular existing measures of distributional similarity are simulated with parameter settings within the CR framework." ></td>
	<td class="line x" title="8:515	In this article, the CR framework is then used to systematically investigate three fundamental questions concerning distributional similarity." ></td>
	<td class="line x" title="9:515	First, is the relationship of lexical similarity necessarily symmetric, or are there advantages to be gained from considering it as an asymmetric relationship?" ></td>
	<td class="line x" title="10:515	Second, are some co-occurrences inherently more salient than others in the calculation of distributional similarity?" ></td>
	<td class="line x" title="11:515	Third, is it necessary to consider the difference in the extent to which each word occurs in each co-occurrence type?" ></td>
	<td class="line x" title="12:515	Two application-based tasks are used for evaluation: automatic thesaurus generation and pseudo-disambiguation." ></td>
	<td class="line x" title="13:515	It is possible to achieve significantly better results on both these tasks by varying the parameters within the CR framework rather than using other existing distributional similarity measures; it will also be shown that any single unparameterized measure is unlikely to be able to do better on both tasks." ></td>
	<td class="line x" title="14:515	This is due to an inherent asymmetry in lexical substitutability and therefore also in lexical distributional similarity." ></td>
	<td class="line x" title="15:515	1." ></td>
	<td class="line x" title="16:515	Introduction Over recent years, approaches to a broad range of natural language processing (NLP) applications have been proposed that require knowledge about the similarity of words." ></td>
	<td class="line x" title="17:515	The application areas in which these approaches have been proposed range from speech recognition and parse selection to information retrieval (IR) and natural language  Department of Informatics, University of Sussex, Falmer, Brighton, BN1 9QH, UK." ></td>
	<td class="line x" title="18:515	Submission received: 4 May 2004; revised submission received: 16 November 2004; accepted for publication: 16 April 2005." ></td>
	<td class="line x" title="19:515	 2006 Association for Computational Linguistics Computational Linguistics Volume 31, Number 4 generation." ></td>
	<td class="line x" title="20:515	For example, language models that incorporate substantial lexical knowledge play a key role in many statistical NLP techniques (e.g. , in speech recognition and probabilistic parse selection)." ></td>
	<td class="line x" title="21:515	However, they are difficult to acquire, since many plausible combinations of events are not seen in corpus data." ></td>
	<td class="line x" title="22:515	Brown et al.(1992) report that one can expect 14.7% of the word triples in any new English text to be unseen in a training corpus of 366 million English words." ></td>
	<td class="line x" title="24:515	In our own experiments with grammatical relation data extracted by a Robust Accurate Statistical Parser (RASP) (Briscoe and Carroll 1995; Carroll and Briscoe 1996) from the British National Corpus (BNC), we found that 14% of noun-verb direct-object co-occurrence tokens and 49% of noun-verb direct-object co-occurrence types in one half of the data set were not seen in the other half." ></td>
	<td class="line x" title="25:515	A statistical technique using a language model that assigns a zero probability to these previously unseen events will rule the correct parse or interpretation of the utterance impossible." ></td>
	<td class="line pc" title="26:515	Similarity-based smoothing (Hindle 1990; Brown et al. 1992; Dagan, Marcus, and Markovitch 1993; Pereira, Tishby, and Lee 1993; Dagan, Lee, and Pereira 1999) provides an intuitively appealing approach to language modeling." ></td>
	<td class="line x" title="27:515	In order to estimate the probability of an unseen co-occurrence of events, estimates based on seen occurrences of similar events can be combined." ></td>
	<td class="line x" title="28:515	For example, in a speech recognition task, we might predict that cat is a more likely subject of growl than the word cap, even though neither co-occurrence has been seen before, based on the fact that cat is similar to words that do occur as the subject of growl (e.g. , dog and tiger), whereas cap is not." ></td>
	<td class="line x" title="29:515	However, what is meant when we say that cat is similar to dog?" ></td>
	<td class="line x" title="30:515	Are we referring to their semantic similarity, e.g., the components of meaning they share by virtue of both being carnivorous four-legged mammals?" ></td>
	<td class="line x" title="31:515	Or are we referring to their distributional similarity, e.g., in keeping with the Firthian tradition, 1 the fact that these words tend to occur as the arguments of the same verbs (e.g. , eat, feed, sleep) and tend to be modified by the same adjectives (e.g. , hungry and playful)." ></td>
	<td class="line x" title="32:515	In some applications, the knowledge required is clearly semantic." ></td>
	<td class="line x" title="33:515	In IR, documents might be usefully retrieved that use synonymous terms or terms subsuming those specified in a users query (Xu and Croft 1996)." ></td>
	<td class="line x" title="34:515	In natural language generation (including text simplification), possible words for a concept should be similar in meaning rather than just in syntactic or distributional behavior." ></td>
	<td class="line x" title="35:515	In these application areas, distributional similarity can be taken to be an approximation to semantic similarity." ></td>
	<td class="line x" title="36:515	The underlying idea is based largely on the central claim of the distributional hypothesis (Harris 1968), that is: The meaning of entities, and the meaning of grammatical relations among them, is related to the restriction of combinations of these entities relative to other entities." ></td>
	<td class="line oc" title="37:515	This hypothesized relationship between distributional similarity and semantic similarity has given rise to a large body of work on automatic thesaurus generation (Hindle 1990; Grefenstette 1994; Lin 1998a; Curran and Moens 2002; Kilgarriff 2003)." ></td>
	<td class="line x" title="38:515	There are inherent problems in evaluating automatic thesaurus extraction techniques, and much research assumes a gold standard that does not exist (see Kilgarriff [2003] and Weeds [2003] for more discussion of this)." ></td>
	<td class="line x" title="39:515	A further problem for distributional similarity methods for automatic thesaurus generation is that they do not offer any obvious way to distinguish between linguistic relations such as synonymy, antonymy, and hyponymy (see Caraballo [1999] and Lin et al. [2003] for work on this)." ></td>
	<td class="line x" title="40:515	Thus, one may question 1 You shall know a word by the company it keeps.(Firth 1957) 440 Weeds and Weir Co-occurrence Retrieval the benefit of automatically generating a thesaurus if one has access to large-scale manually constructed thesauri (e.g. , WordNet [Fellbaum 1998], Rogets [Roget 1911], the Macquarie [Bernard 1990] and Moby 2 )." ></td>
	<td class="line x" title="41:515	Automatic techniques give us the opportunity to model language change over time or across domains and genres." ></td>
	<td class="line x" title="42:515	McCarthy et al.(2004) investigate using distributional similarity methods to find predominant word senses within a corpus, making it possible to tailor an existing resource (WordNet) to specific domains." ></td>
	<td class="line x" title="44:515	For example, in the computing domain, the word worm is more likely to be used in its malicious computer program sense than in its earthworm sense." ></td>
	<td class="line x" title="45:515	This domain knowledge will be reflected in a thesaurus automatically generated from a computing-specific corpus, which will show increased similarity between worm and virus and reduced similarity between worm and caterpillar." ></td>
	<td class="line x" title="46:515	In other application areas, however, the requirement for similar words to be semantically related as well as distributionally related is less clear." ></td>
	<td class="line x" title="47:515	For example, in prepositional phrase attachment ambiguity resolution, it is necessary to decide whether the prepositional phrase attaches to the verb or the noun as in the examples (1) and (2)." ></td>
	<td class="line x" title="48:515	1." ></td>
	<td class="line x" title="49:515	Mary ((visited their cottage) with her brother)." ></td>
	<td class="line x" title="50:515	2." ></td>
	<td class="line x" title="51:515	Mary (visited (their cottage with a thatched roof))." ></td>
	<td class="line x" title="52:515	Hindle and Rooth (1993) note that the correct decision depends on all four lexical events (the verb, the object, the preposition, and the prepositional object)." ></td>
	<td class="line x" title="53:515	However, a statistical model built on the basis of four lexical events must cope with extremely sparse data." ></td>
	<td class="line x" title="54:515	One approach (Resnik 1993; Li and Abe 1998; Clark and Weir 2000) is to induce probability distributions over semantic classes rather than lexical items." ></td>
	<td class="line x" title="55:515	For example, a cottage is a type of building and a brother is a type of person, and so the co-occurrence of any type of building and any type of person might increase the probability that the PP in example (1) attaches to the verb." ></td>
	<td class="line x" title="56:515	However, it is unclear whether the classes over which probability distributions are induced need to be semantic or whether they could be purely distributional." ></td>
	<td class="line x" title="57:515	If we know that two words tend to behave the same way with respect to prepositional phrase attachment, does it matter whether they mean similar things?" ></td>
	<td class="line x" title="58:515	Other arguments for using semantic classes over distributional classes can similarly be disputed (Weeds 2003)." ></td>
	<td class="line x" title="59:515	For example, it is not necessary for a class of objects to have a name or symbolic label for us to know that the objects are similar and to exploit that information." ></td>
	<td class="line x" title="60:515	Distributional classes do conflate word senses, but in a task such as PP-attachment ambiguity resolution, we are unlikely to be working with sense-tagged examples and therefore it is for word forms that we will wish to estimate probabilities of different attachments." ></td>
	<td class="line x" title="61:515	Finally, distributional classes may be over-fitted to a specific corpus, but this may be beneficial to the extent that the over-fitting reflects a specific domain or dialect." ></td>
	<td class="line x" title="62:515	Further, recent empirical evidence suggests that techniques based on distributional similarity may perform as well on this task as those based on semantic similarity." ></td>
	<td class="line x" title="63:515	Li (2002) shows that using a fairly small corpus (126,084 sentences from the Wall Street Journal) and a distributional similarity technique, it is possible to outperform a state-of-the-art, WordNet-based technique in terms of accuracy, although not in terms of coverage." ></td>
	<td class="line x" title="64:515	Pantel and Lin (2000) report performance of 84.3% using an unsupervised approach to prepositional phrase attachment based on distributional similarity 2 The Moby Thesaurus is a product of the Moby Project, which was released into the public domain by Grady Ward in 1996." ></td>
	<td class="line x" title="65:515	441 Computational Linguistics Volume 31, Number 4 techniques." ></td>
	<td class="line x" title="66:515	This significantly outperforms previous unsupervised techniques and is drawing close to the state-of-the-art supervised techniques (88.2%)." ></td>
	<td class="line x" title="67:515	Having discussed why distributional similarity is important, we now turn to how to formulate it." ></td>
	<td class="line x" title="68:515	As we have said, two words are distributionally similar if they appear in similar contexts." ></td>
	<td class="line x" title="69:515	We therefore need to consider what is meant by context." ></td>
	<td class="line x" title="70:515	For example, two words could be considered to appear in the same context if they appear in the same sentence, the same document, or the same grammatical dependency relation." ></td>
	<td class="line x" title="71:515	The effect of the type of context used is discussed by Kilgarriff and Yallop (2000)." ></td>
	<td class="line x" title="72:515	They show that the use of sentence-level and document-level context leads to looser thesauri more akin to Rogets, whereas the use of grammatical dependency relation level context leads to tighter thesauri more akin to WordNet." ></td>
	<td class="line x" title="73:515	The use of grammatical dependency relations as context gives us a tighter thesaurus because it restricts distributionally similar words to those that are plausibly inter-substitutable (Church et al. 1994), giving us the following definition of distributional similarity: The distributional similarity of two words is the extent to which they can be inter-substituted without changing the plausibility 3 of the sentence." ></td>
	<td class="line x" title="74:515	This concept of lexical substitutability highlights the relationship between distributional similarity and semantic similarity, since semantic similarity can be thought of as the degree of synonymy that exists between two words, where synonymy is defined (Church et al. 1994) as follows: Two words are absolute synonyms if they can be inter-substituted in all possible contexts without changing the meaning." ></td>
	<td class="line x" title="75:515	In our empirical work, we focus on finding semantic relationships between words such as synonymy, antonymy and hyponymy that might be found in a tighter thesaurus such as WordNet." ></td>
	<td class="line x" title="76:515	Hence, the proposed framework is based on the concept of substitutability, and we use grammatical dependency relations as context." ></td>
	<td class="line x" title="77:515	However, since the framework is based on features, there is no reason why someone wishing to find topical relationships between words, as might be found in Rogets, could not use the framework." ></td>
	<td class="line x" title="78:515	We simply do not repeat the earlier work of Kilgarriff and Yallop (2000)." ></td>
	<td class="line x" title="79:515	However, a number of questions still remain, which this work does investigate: 1." ></td>
	<td class="line x" title="80:515	Is lexical substitutability and therefore distributional similarity symmetric?" ></td>
	<td class="line x" title="81:515	The concept of substitution is inherently asymmetric." ></td>
	<td class="line x" title="82:515	It is possible to measure the appropriateness of substituting word A for word B without measuring the appropriateness of substituting word B for word A. Similarity has been defined in terms of inter-substitutability; but we ask whether there is something in the inherent asymmetry of substitution that can be exploited by an asymmetric measure of distributional similarity." ></td>
	<td class="line x" title="83:515	2." ></td>
	<td class="line x" title="84:515	Are all contexts equally important?" ></td>
	<td class="line x" title="85:515	For example, some verbs, e.g., have and get, are selectionally weak in the constraints they place on their arguments (Resnik 1993)." ></td>
	<td class="line x" title="86:515	Should such contexts be considered on equal terms with selectionally strong contexts in the calculation of distributional similarity?" ></td>
	<td class="line x" title="87:515	3 We use plausible sentence to refer to a sentence that might be observed in naturally occurring language data." ></td>
	<td class="line x" title="88:515	442 Weeds and Weir Co-occurrence Retrieval 3." ></td>
	<td class="line x" title="89:515	Is it necessary to consider the difference in extent to which each word appears in each context?" ></td>
	<td class="line x" title="90:515	Is it enough to know that both words can occur in each context, or do similar words occur in similar contexts with similar probabilities?" ></td>
	<td class="line x" title="91:515	In order to answer these questions, we take a pragmatic, application-oriented approach to evaluation that is based on the assumption that we want to know which words are distributionally similar because particular applications can make use of this information." ></td>
	<td class="line x" title="92:515	However, high performance in one application area is not necessarily correlated with high performance in another application area (Weeds and Weir 2003a)." ></td>
	<td class="line x" title="93:515	Thus, it is not clear that the same characteristics that make a distributional similarity measure useful in one application will make it useful in another." ></td>
	<td class="line x" title="94:515	For example, with regard to the question about symmetry, in some applications we may prefer a word A that can be substituted for word B in all of the contexts in which B occurs." ></td>
	<td class="line x" title="95:515	In other applications, we may prefer a word A that can be substituted for word B in all of the contexts in which A occurs." ></td>
	<td class="line x" title="96:515	For example, asked for a semantically related word to dog,wemightsayanimal, since animal can generally be used in place of dog, whereas we might be less likely to say dog for animal,sincedog cannot generally be used in place of animal." ></td>
	<td class="line x" title="97:515	This preference in the direction of the relationship between the two words is not necessarily maintained when one considers language modeling in the face of sparse data." ></td>
	<td class="line x" title="98:515	If we want to learn what other contexts animal can occur in, we might look at the co-occurrences of words such as dog, since we know that dog can generally be replaced by animal.Ifwewantto learn what other contexts dog can occur in, we are less likely to look at the co-occurrences of animal, since we know that animal can occur in contexts in which dog cannot." ></td>
	<td class="line x" title="99:515	Rather than attempt to find a single universally optimal distributional similarity measure, or propose using a radically different distributional similarity measure in each possible application, we propose a flexible, parameterized framework for calculating distributional similarity (Section 2)." ></td>
	<td class="line x" title="100:515	Within this framework, we cast the problem of finding distributionally similar words as one of co-occurrence retrieval (CR), for which we can measure precision and recall by analogy with the way that they are measured in document retrieval." ></td>
	<td class="line x" title="101:515	Different models within this framework allow us to investigate how frequency information is incorporated into the distributional similarity measure." ></td>
	<td class="line x" title="102:515	Different parameter settings within each model allow us to investigate asymmetry in similarity." ></td>
	<td class="line x" title="103:515	In Section 3 we discuss the data and the neighbor set comparison technique used throughout our empirical work." ></td>
	<td class="line x" title="104:515	In Section 4 we discuss a number of existing distributional similarity measures and discuss the extent to which these can be simulated by settings within the CR framework." ></td>
	<td class="line x" title="105:515	In Section 5 we evaluate the CR framework on a semantic task (WordNet prediction) and on a language modeling task (pseudo-disambiguation)." ></td>
	<td class="line x" title="106:515	2." ></td>
	<td class="line x" title="107:515	Co-occurrence Retrieval In this section, we present a flexible framework for distributional similarity." ></td>
	<td class="line x" title="108:515	This framework directly defines a similarity function, does not require smoothing of the base language model, and allows us to systematically explore the questions about similarity raised in Section 1." ></td>
	<td class="line x" title="109:515	In our approach, similarity between words is viewed as a measure of how appropriate it is to use one word (or its distribution) in place of the other." ></td>
	<td class="line x" title="110:515	Like relative entropy (Cover and Thomas 1991), it is inherently asymmetric, since we can 443 Computational Linguistics Volume 31, Number 4 measure how appropriate it is to use word A instead of word B separately from how appropriate it is to use word B instead of word A. The framework presented here is general to the extent that it can be used to compute similarities for any set of objects where each object has an associated set of features or co-occurrence types and these co-occurrence types have associated frequencies that may be used to form probability estimates." ></td>
	<td class="line x" title="111:515	Throughout our discussion, the word for which we are finding neighbors will be referred to as the target word.Ifweare computing the similarity between the target word and another word, then the second word is a potential neighbor of the target word." ></td>
	<td class="line x" title="112:515	A target words nearest neighbors are the potential neighbors that have the highest similarity with the target word." ></td>
	<td class="line x" title="113:515	2.1 Basic Concepts Let us imagine that we have formed descriptions of each word in terms of the other words with which they co-occur in various specified grammatical relations in some corpus." ></td>
	<td class="line x" title="114:515	For example, the noun cat might have the co-occurrence types dobj-of, feed and ncmod-by, hungry." ></td>
	<td class="line x" title="115:515	Now let us imagine that we have lost (or accidentally deleted) the description for word w 2, but before this happened we had noticed that the description of word w 2 was very similar to that of word w 1." ></td>
	<td class="line x" title="116:515	For example, the noun dog might also have the co-occurrence types dobj-of, feed and ncmod-by, hungry." ></td>
	<td class="line x" title="117:515	Hence, we decide that we can use the description of word w 1 instead of the description of word w 2 and are hopeful that nobody will notice." ></td>
	<td class="line x" title="118:515	How well we do will depend on the validity of substituting w 1 for w 2, or, in other words, the similarity between w 1 and w 2 . The task we have set ourselves can be seen as co-occurrence retrieval (CR)." ></td>
	<td class="line x" title="119:515	By analogy with information retrieval, where there is a set of documents that we would like to retrieve and a set of documents that we do retrieve, we have a scenario where there is a set of co-occurrences that we would like to retrieve, the co-occurrences of w 2, and a set of co-occurrences that we have retrieved, the co-occurrences of w 1 .Continuing the analogy, we can measure how well we have done in terms of precision and recall, where precision tells us how much of what was retrieved was correct and recall tells us how much of what we wanted to retrieve was retrieved." ></td>
	<td class="line x" title="120:515	Our flexible framework for distributional similarity is based on this notion of cooccurrence retrieval." ></td>
	<td class="line x" title="121:515	As the distribution of word B moves away from being identical to that of word A, its similarity with A can decrease along one or both of two dimensions." ></td>
	<td class="line x" title="122:515	When B occurs in contexts that word A does not, the result is a loss of precision, but B may remain a high-recall neighbor." ></td>
	<td class="line x" title="123:515	For example, we might expect the noun animal to be a high-recall neighbor of the noun dog." ></td>
	<td class="line x" title="124:515	When B does not occur in contexts that A does occur in, the result is a loss of recall but B may remain a highprecision neighbor." ></td>
	<td class="line x" title="125:515	For example, we might expect the noun dog to be a high-precision neighbor of the noun animal." ></td>
	<td class="line x" title="126:515	We can explore the merits of symmetry and asymmetry in a similarity measure by varying the relative importance attached to precision and recall." ></td>
	<td class="line x" title="127:515	This was the first question posed about distributional similarity in Section 1." ></td>
	<td class="line x" title="128:515	The remainder of this section is devoted to defining two types of co-occurrence retrieval model (CRM)." ></td>
	<td class="line x" title="129:515	Additive models are based on the Boolean concept of two objects either sharing or not sharing a particular feature (where objects are words and features are co-occurrence types)." ></td>
	<td class="line x" title="130:515	Difference-weighted models incorporate the difference in extent to which each word has each feature." ></td>
	<td class="line x" title="131:515	Exploring the two types of models, both defined on the same concepts of precision and recall, allows us to investigate the third question posed in Section 1: Is a shared context worth the same, regardless of the difference in the extent to which each word appears in that context?" ></td>
	<td class="line x" title="132:515	444 Weeds and Weir Co-occurrence Retrieval We also use the CR framework to investigate the second question posed about distributional similarity, Should all contexts be treated equally?, by using different weight functions within each type of model." ></td>
	<td class="line x" title="133:515	Weight functions decide which cooccurrence types are features of a word and determine the relative importance of features." ></td>
	<td class="line x" title="134:515	In previous work (Weeds and Weir 2003b), we experimented with weight functions based on combinatorial, probabilistic, and mutual information (MI)." ></td>
	<td class="line x" title="135:515	These allow us to define type-based, token-based, and MI-based CRMs, respectively." ></td>
	<td class="line x" title="136:515	This work extends the previous work by also considering weighted mutual information (WMI) (Fung and McKeown 1997), the t-test (Manning and Sch utze 1999), the z-test (Fontenelle et al. 1994), and an approximation to the log-likelihood ratio (Manning and Sch utze 1999) as weight functions." ></td>
	<td class="line x" title="137:515	2.2 Additive Models Having considered the intuition behind calculating precision and recall for cooccurrence retrieval, we now formulate this formally in terms of an additive model." ></td>
	<td class="line x" title="138:515	We first need to consider for each word w which co-occurrence types will be retrieved, or predicted, by it and, conversely, required in a description of it." ></td>
	<td class="line x" title="139:515	We will refer to these co-occurrence types as the features of w, F(w): F(w) ={c : D(w, c) > 0} (1) where D(w, c) is the weight associated with word w and co-occurrence type c. Possible weight functions will be described in Section 2.3." ></td>
	<td class="line x" title="140:515	The shared features of word w 1 and word w 2 are referred to as the set of True Positives, TP(w 1, w 2 ), which will be abbreviated to TP in the rest of this article: TP(w 1, w 2 ) = F(w 1 )  F(w 2 )(2) The precision of w 1 s retrieval of w 2 s features is the proportion of w 1 s features that are shared by both words, where each feature is weighted by its relative importance according to w 1 : P add (w 1, w 2 ) = summationtext TP D(w 1, c) summationtext F(w 1 ) D(w 1, c) (3) The recall of w 1 s retrieval of w 2 s features is the proportion of w 2 s features that are shared by both words, where each feature is weighted by its relative importance according to w 2 : R add (w 1, w 2 ) = summationtext TP D(w 2, c) summationtext F(w 2 ) D(w 2, c) (4) 445 Computational Linguistics Volume 31, Number 4 Table 1 Weight functions." ></td>
	<td class="line x" title="141:515	D type (w, c) = braceleftbigg 1ifP(c|w) > 0 0 otherwise D tok (w, c) = P(c|w) D mi (w, c) = I(w, c) = log parenleftBig P(c, w) P(c)P(w) parenrightBig D wmi (w, c) = P(c, w)  log parenleftBig P(c, w) P(c)P(w) parenrightBig D t (w, c) = P(c, w)P(c)P(w) radicalBig P(c, w) N D z (w, c) = P(c, w)P(c)P(w) radicalBig P(c).P(w) N D allr (w, c) = 2  parenleftBig log L parenleftBig F(w, c), F(w), F(c) N parenrightBig  log L parenleftBig F(w, c), F(w), F(w, c) F(w) parenrightBigparenrightBig Precision and recall both lie in the range [0,1] and are both equal to one when each word has exactly the same features." ></td>
	<td class="line x" title="142:515	It should also be noted that the recall of w 1 s retrieval of w 2 is equal to the precision of w 2 s retrieval of w 1, i.e., R add (w 1, w 2 ) = P add (w 2, w 1 )." ></td>
	<td class="line x" title="143:515	2.3 Weight Functions The weight function plays two important roles." ></td>
	<td class="line x" title="144:515	First, it determines which cooccurrences of w 1 and w 2 are important enough to be considered part of their description, or by analogy with document retrieval, which co-occurrences we want to retrieve for w 2 and which co-occurrences we have retrieved using the description of w 1 .Itis then used to weight contexts by their importance." ></td>
	<td class="line x" title="145:515	In the latter case, D(w 1, c) tells us the retrieval processs perceived relevance of co-occurrence type c,andD(w 2, c) tells us the actual relevance of co-occurrence type c. The weight functions we have considered so far are summarized in Table 1." ></td>
	<td class="line x" title="146:515	Each weight function can be used to define its own CRM, which we will now discuss in more detail." ></td>
	<td class="line x" title="147:515	Additive type-based CRM (D type )." ></td>
	<td class="line x" title="148:515	In this CRM, the precision of w 1 s retrieval of w 2 is the proportion of co-occurrence types occurring with w 1 that also occur with w 2,andthe recall of w 1 s retrieval of w 2 is the proportion of verb co-occurrence types (or distinct verbs) occurring with w 2 that also occur with w 1 . In this case, the summed values of D are always 1, and hence the expressions for precision and recall can be simplified: P add type (w 1, w 2 ) = summationtext TP D type (w 1, c) summationtext F(w 1 ) D type (w 1, c) = |TP| |F(w 1 )| (5) 446 Weeds and Weir Co-occurrence Retrieval R add type (w 1, w 2 ) = summationtext TP D type (w 2, c) summationtext F(w 2 ) D type (w 2, c) = |TP| |F(w 2 )| (6) Additive token-based CRM (D tok )." ></td>
	<td class="line x" title="149:515	In this CRM, the precision of w 1 s retrieval of w 2 is the proportion of co-occurrence tokens occurring with w 1 that also occur with w 2,andthe recall of w 1 s retrieval of w 2 is the proportion of co-occurrence tokens occurring with w 2 that also occur with w 1 . Hence, words have the same features as in the type-based CRM, but each feature is given a weight based on its probability of occurrence." ></td>
	<td class="line x" title="150:515	Since F(w) = {c : D(w, c) > 0}={c : P(c|w) > 0}, it follows that summationtext F(w) D tok (w, c) = 1, and therefore the expressions for precision and recall can be simplified: P add tok (w 1, w 2 ) = summationtext TP D tok (w 1, c) summationtext F(w 1 ) D tok (w 1, c) = summationdisplay TP P(c, w 1 )(7) R add tok (w 1, w 2 ) = summationtext TP D tok (w 2, c) summationtext F(w 2 ) D tok (w 2, c) = summationdisplay TP P(c, w 2 )(8) Additive MI-based CRM (D mi )." ></td>
	<td class="line x" title="151:515	Using pointwise mutual information (MI) (Church and Hanks 1989) as the weight function means that a co-occurrence c is considered a feature of word n if the probability of their co-occurrence is greater than would be expected if words occurred independently." ></td>
	<td class="line x" title="152:515	In addition, more informative co-occurrences contribute more to the sums in the calculation of precision and recall and hence have more weight." ></td>
	<td class="line x" title="153:515	Additive WMI-based CRM (D wmi )." ></td>
	<td class="line x" title="154:515	Weighted mutual information (WMI) (Fung and McKeown 1997) has been proposed as an alternative to MI, particularly when MI might lead to the over-association of low-frequency events." ></td>
	<td class="line x" title="155:515	In this function, the pointwise MI is multiplied by the probability of the co-occurrence; hence, reducing the weight assigned to low-probability events." ></td>
	<td class="line x" title="156:515	Additive t-test based CRM (D t )." ></td>
	<td class="line x" title="157:515	The t-test (Manning and Sch utze 1999) is a standard statistical test that has been proposed for collocation analysis." ></td>
	<td class="line x" title="158:515	It measures the (signed) difference between the observed probability of co-occurrence and the expected probability of co-occurrence, as would be observed if words occurred independently." ></td>
	<td class="line x" title="159:515	The difference is divided by the standard deviation in the observed distribution." ></td>
	<td class="line x" title="160:515	Similarly to MI, this score obviously gives more weight to co-occurrences that occur more than would be expected, and its use as the weight function results in any co-occurrences that occur less than would be expected being ignored." ></td>
	<td class="line x" title="161:515	Additive z-test based CRM (D z )." ></td>
	<td class="line x" title="162:515	The z-test (Fontenelle et al. 1994) is almost identical to the t-test." ></td>
	<td class="line x" title="163:515	However, using the z-test, the (signed) difference between the observed probability of co-occurrence and the expected probability of co-occurrence is divided by the standard deviation in the expected distribution." ></td>
	<td class="line x" title="164:515	Additive log-likelihood ratio based CRM (D allr )." ></td>
	<td class="line x" title="165:515	The log-likelihood ratio (Manning and Sch utze 1999) considers the difference (as a log ratio) in probability of the observed frequencies of co-occurrences and individual words occurring under the null hypoth447 Computational Linguistics Volume 31, Number 4 esis, that words occur independently, and under the alternative hypothesis, that they do not." ></td>
	<td class="line x" title="166:515	H 0 : P(c|w) = p = P(c|w)(9) H 1 : P(c|w) = p 1 negationslash= p 2 = P(c|n) (10) If f (w, c) is the frequency of w and c occurring together, f (w) is the total frequency of w occurring in any context, f (c) is the total frequency of c occurring with any word, and N is the grand total of co-occurrences, then the log-likelihood ratio can be written: Log(w, c) = 2.log L(H 0 ) L(H 1 ) (11) = 2." ></td>
	<td class="line x" title="167:515	         log L parenleftBig f (w, c), f (w), f (c) N parenrightBig + log L parenleftBig f (c)  f (w, c), N  f (w), f (c) N parenrightBig  log L parenleftBig f (w, c), f (w), f (w, c) f (w) parenrightBig  log L parenleftBig f (c)  f (w, c), N  f (w), f (c)f (w, c) Nf (w) parenrightBig          (12) where L(k, n, x) = x k (1  x) nk (13) In our implementation (see Table 1), an approximation to this formula is used, which we term the ALLR weight function." ></td>
	<td class="line x" title="168:515	We use an approximation because the terms that represent the probabilities of the other contexts (i.e. , seeing f (c)  f (w, c) under each hypothesis) tend towards  as N increases (since the probabilities tend towards zero)." ></td>
	<td class="line x" title="169:515	Since N is very large in our experiments (approximately 2,000,000), we found that using the full formula led to many weights being undefined." ></td>
	<td class="line x" title="170:515	Further, since in this case the probability of seeing other contexts will be approximately equal under each hypothesis, it is a reasonable approximation to make." ></td>
	<td class="line x" title="171:515	Another potential problem with using the log-likelihood ratio as the weight function is that it is always positive, since the observed distribution is always more probable than the hypothesized distribution." ></td>
	<td class="line x" title="172:515	All of the other weight functions assign a zero or negative weight to co-occurrence types that do not occur with a given word and thus these zero frequency co-occurrence types are never selected as features." ></td>
	<td class="line x" title="173:515	This is advantageous in the computation of similarity, since computing the sums over all co-occurrence types rather than just those co-occurring with at least one of the words is (1) very computationally expensive and (2) due to their vast number, the effect of these zero frequency co-occurrence types tends to outweigh the effect of those co-occurrence types that have actually occurred." ></td>
	<td class="line x" title="174:515	Giving such weight to these shared non-occurrences seems unintuitive and has been shown by Lee (1999) to be undesirable in the calculation of distributional similarity." ></td>
	<td class="line x" title="175:515	Hence, when using the 448 Weeds and Weir Co-occurrence Retrieval ALLR as the weight function, we use the additional restriction that P(c, w) > 0 when selecting features." ></td>
	<td class="line x" title="176:515	2.4 Difference-Weighted Models In additive models, no distinction is made between features that have occurred to the same extent with each word and features that have occurred to different extents with each word." ></td>
	<td class="line x" title="177:515	For example, if two words have the same features, they are considered identical, regardless of whether the feature occurs with the same probability with each word or not." ></td>
	<td class="line x" title="178:515	Here, we define a type of model that allows us to capture the difference in the extent to which each word has each feature." ></td>
	<td class="line x" title="179:515	We do this by defining the similarity of two words with respect to an individual feature, using the same principles that we use to define the similarity of two words with respect to all their features." ></td>
	<td class="line x" title="180:515	First, we define an extent function, E(w, c), which is the extent to which w 1 goes with c and which may be, but is not necessarily, the same as the weight function D(n, w)." ></td>
	<td class="line x" title="181:515	Possible extent functions will be discussed in Section 2.5." ></td>
	<td class="line x" title="182:515	Having defined this function, we can measure the precision and recall of individual features." ></td>
	<td class="line x" title="183:515	The precision of an individual feature c retrieved by w 1 is the extent to which both words go with c divided by the extent to which w 1 goes with c. The recall of the retrieval of c by w 1 is the extent to which both words go with c divided by the extent to which w 2 goes with c. P(w 1, w 2, c) = min(E(w 1, c), E(w 2, c)) E(w 1, c) (14) R(w 2, w 1, c) = min(E(w 1, c), E(w 2, c)) E(w 2, c) (15) Precision and recall of an individual feature, like precision and recall of a distribution, lie in the range [0,1]." ></td>
	<td class="line x" title="184:515	We can now redefine precision and recall of a distribution as follows: P dw (w 1, w 2 ) = summationtext TP D(w 1, c) P(w 1, w 2, c) summationtext F(w 1 ) D(w 1, c) (16) R dw (w 1, w 2 ) = summationtext TP D(w 2, c) R(w 1, w 2, c) summationtext F(w 2 ) D(w 2, c) (17) Using precision and recall of individual features as weights in the definitions of precision and recall of a distribution captures the intuition that retrieval of a co-occurrence type is not a black-and-white matter." ></td>
	<td class="line x" title="185:515	Features that are shared to a similar extent are considered more important in the calculation of distributional similarity." ></td>
	<td class="line x" title="186:515	449 Computational Linguistics Volume 31, Number 4 Table 2 Extent functions." ></td>
	<td class="line x" title="187:515	E type (w, c) = P(c|w) E tok (w, c) = P(c|w) E mi (w, c) = I(w, c) = log parenleftBig P(c, w) P(c)P(w) parenrightBig E wmi (w, c) = P(c, w).log parenleftBig P(c, w) P(c)P(w) parenrightBig E t (w, c) = P(c, w)P(c).P(w) radicalBig P(c, w) N E z (w, c) = P(c, w)P(c).P(w) radicalBig P(c).P(w) N E allr (w, c) = 2." ></td>
	<td class="line x" title="188:515	parenleftBig log L parenleftBig f (w, c), f (w), f (c) N parenrightBig  log L parenleftBig f (w, c), f (w), f (w, c) f (w) parenrightBigparenrightBig 2.5 Extent Functions The extent functions we have considered so far are summarized in Table 2." ></td>
	<td class="line x" title="189:515	Note that in general, the extent function is the same as the weight function, which leads to a standard simplification of the expressions for precision and recall in the differenceweighted CRMs." ></td>
	<td class="line x" title="190:515	For example, in the difference-weighted MI-based model we get the expressions: P dw mi (w 1, w 2 ) = summationtext TP I(w 1, c)  min(I(w 1, c),I(w 2, c)) I(w 1, c) summationtext F(w 1 ) I(w 1, c) = summationtext TP min(I(w 1, c), I(w 2, c)) summationtext F(w 1 ) I(w 1, c) (18) R dw mi (w 1, w 2 ) = summationtext TP I(w 2, c)  min(I(w 2, c),I(w 1, c)) I(w 2, c) summationtext F(w 2 ) I(w 2, c) = summationtext TP min(I(w 2, c), I(w 1, c)) summationtext F(w 2 ) I(w 2, c) (19) Similar expressions can be derived for the WMI-based CRM,thet-test based CRM,the z-test based CRM,andtheALLR-based CRM." ></td>
	<td class="line x" title="191:515	An interesting special case is the differenceweighted token-based CRM." ></td>
	<td class="line x" title="192:515	In this case, since summationtext F(w) P(c|w) = 1, we derive the following expressions for precision and recall: P dw tok (w 1, w 2 ) = summationtext TP P(c|w 1 )  min(P(c|w 1 ), P(c|w 2 )) P(c|w 1 ) summationtext F(w 1 ) P(c|w 1 ) = summationdisplay TP min(P(c|w 1 ), P(c|w 2 )) (20) 450 Weeds and Weir Co-occurrence Retrieval R dw tok (w 1, w 2 ) = summationtext TP P(c|w 2 )  min(P(c|w 2 ), P(c|w 1 )) P(c|w 2 ) summationtext F(w 2 ) P(c|w 2 ) = summationdisplay TP min(P(c|w 2 ), P(c|w 1 )) = P dw tok (w 1, w 2 ) (21) Note that although we have defined separate precision and recall functions, we have arrived at the same expression for both in this model." ></td>
	<td class="line x" title="193:515	As a result, this model is symmetric." ></td>
	<td class="line x" title="194:515	The only CRM in which we use a different extent and weight function is the difference-weighted type-based CRM." ></td>
	<td class="line x" title="195:515	This is because there is no difference between types and tokens for an individual feature; i.e., their retrieval is equivalent." ></td>
	<td class="line x" title="196:515	In this case, the following expressions for precision and recall are derived: P dw type (w 1, w 2 ) = summationtext TP D type (w 1, c) P type (w 1, w 2, c) summationtext F(w 1 ) D type (w 1, c) = summationtext TP min(P(c|w 1 ), P(c|w 2 )) P(c|w 1 ) |F(w 1 )| (22) R dw type (w 1, w 2 ) = summationtext TP D type (w 2, c) R type (w 1, w 2, c) summationtext F(w 2 ) D type (w 2, c) = summationtext TP min(P(c|w 2 ), P(c|w 1 )) P(c|w 2 ) |F(w 2 )| (23) Note that this is different from the additive token-based model because, although every token is effectively considered in this model, tokens are not weighted equally." ></td>
	<td class="line x" title="197:515	In this model, tokens are treated differently according to which type they belong." ></td>
	<td class="line x" title="198:515	The importance of the retrieval (or non-retrieval) of a single token depends on the proportion of the tokens for its particular type that it constitutes." ></td>
	<td class="line x" title="199:515	2.6 Combining Precision and Recall We have, so far, been concerned with defining a pair of numbers that represents the similarity between two words." ></td>
	<td class="line x" title="200:515	However, in applications, it is normally necessary to compute a single number in order to determine neighborhood or cluster membership." ></td>
	<td class="line x" title="201:515	The classic way to combine precision and recall in IR is to compute the F-score; that is, the harmonic mean of precision and recall: F = m h (P,R) = 2 P R P +R (24) However, we do not wish to assume that a good substitute requires both high precision and high recall of the target distribution." ></td>
	<td class="line x" title="202:515	It may be that, in some situations, the best word to use in place of another word is one that only retrieves correct cooccurrences (i.e. , it is a high-precision neighbor) or it may be one that retrieves all of the required co-occurrences (i.e. , it is a high-recall neighbor)." ></td>
	<td class="line x" title="203:515	The other factor in each case may play only a secondary role or no role at all." ></td>
	<td class="line x" title="204:515	We can retain generality and investigate whether high precision or high recall or high precision and high recall are required for high similarity by computing a weighted 451 Computational Linguistics Volume 31, Number 4 Table 3 Table of special values of  and ." ></td>
	<td class="line x" title="205:515	Special Case 1 harmonic mean of precision and recall (F-score)  0 weighted arithmetic mean of precision and recall 1 0 precision 00recal 0.5 0 unweighted arithmetic mean arithmetic mean of the harmonic mean and the weighted arithmetic mean of precision and recall: 4 m h (P(w 1, w 2 ),R(w 1, w 2 )) = 2.P(w 1, w 2 ).R(w 1, w 2 ) P(w 1, w 2 ) +R(w 1, w 2 ) (25) m a (P(w 1, w 2 ),R(w 1, w 2 )) = .P(w 1, w 2 ) + (1 ).R(w 1, w 2 ) (26) sim(w 1, w 2 ) = .m h (P(w 1, w 2 ),R(w 1, w 2 )) +(1 ).m a (P(w 1, w 2 ),R(w 1, w 2 )) (27) where both  and  lie in the range [0,1]." ></td>
	<td class="line x" title="206:515	The resulting similarity, sim(w 1, w 2 ), will also lie in the range [0,1] where 0 is low and 1 is high." ></td>
	<td class="line x" title="207:515	This formula can be used in combination with any of the models for precision and recall outlined earlier." ></td>
	<td class="line x" title="208:515	Precision and recall can be computed once for every pair of words (and every model) whereas similarity depends on the values of  and ." ></td>
	<td class="line x" title="209:515	The flexibility allows us to investigate empirically the relative significance of the different terms and thus whether one (or more) might be omitted in future work." ></td>
	<td class="line x" title="210:515	Table 3 summarizes some special parameter settings." ></td>
	<td class="line x" title="211:515	2.7 Discussion We have developed a framework based on the concept of co-occurrence retrieval (CR)." ></td>
	<td class="line x" title="212:515	Within this framework we have defined a number of models (CRMs) that allow us to systematically explore three questions about similarity." ></td>
	<td class="line x" title="213:515	First, is similarity between words necessarily a symmetric relationship, or can we gain an advantage by considering it as an asymmetric relationship?" ></td>
	<td class="line x" title="214:515	Second, are some features inherently more salient than others?" ></td>
	<td class="line x" title="215:515	Third, does the difference in extent to which each word takes each feature matter?" ></td>
	<td class="line x" title="216:515	The CRMs and the parameter settings therein correspond to alternative possibilities." ></td>
	<td class="line x" title="217:515	First, a high-precision neighbor is not necessarily a high-recall neighbor (and, conversely, a high-recall neighbor is not necessarily a high-precision neighbor) and therefore we are not constrained to a symmetric relationship of similarity between 4 This is as opposed to using a standard weighted F-score (Manning and Sch utze 1999), which uses just one parameter : F  = PR R+(1)P . We did not use this weighting because we wished to investigate the differences between using an arithmetic mean and a harmonic mean." ></td>
	<td class="line x" title="218:515	452 Weeds and Weir Co-occurrence Retrieval words." ></td>
	<td class="line x" title="219:515	Second, the use of different weight functions varies the relative importance attached to features." ></td>
	<td class="line x" title="220:515	Finally, difference-weighted models contrast with additive models in considering the difference in extent to which each word takes each feature." ></td>
	<td class="line x" title="221:515	3." ></td>
	<td class="line x" title="222:515	Data and Experimental Techniques The rest of this paper is concerned with evaluation of the proposed framework; first, by comparing it to existing distributional similarity measures, and second, by evaluating performance on two tasks." ></td>
	<td class="line x" title="223:515	Throughout our empirical work, we use one data-set and one neighbor set comparison technique, which we now discuss in advance of presenting any of our actual experiments." ></td>
	<td class="line x" title="224:515	3.1 Data The data used for all our experimental work was noun-verb direct-object data extracted from the BNC by a Robust Accurate Statistical Parser (RASP) (Briscoe and Carroll 1995; Carroll and Briscoe 1996)." ></td>
	<td class="line x" title="225:515	We constructed a list of nouns that occur in both our data set and WordNet ordered by their frequency in our corpus data." ></td>
	<td class="line x" title="226:515	Since we are interested in the effects of word frequency on word similarity, we selected 1,000 high-frequency nouns and 1,000 low-frequency nouns." ></td>
	<td class="line x" title="227:515	The 1,000 high-frequency nouns were selected as the nouns with frequency ranks of 11,000; this corresponds to a frequency range of [586,20871]." ></td>
	<td class="line x" title="228:515	The low-frequency nouns were selected as the nouns with frequency ranks of 3,0014,000; this corresponds to a frequency range of [72,121]." ></td>
	<td class="line x" title="229:515	For each target noun, 80% of the available data was randomly selected as training data and the other 20% was set aside as test data." ></td>
	<td class="line x" title="230:515	5 The training data was used to compute similarity scores between all possible pairwise combinations of the 2,000 nouns and to provide (MLE) estimates of noun-verb co-occurrence probabilities in the pseudodisambiguation task." ></td>
	<td class="line x" title="231:515	The test data provides unseen co-occurrences for the pseudodisambiguation task." ></td>
	<td class="line x" title="232:515	Although we only consider similarity between nouns based on co-occurrences with verbs in the direct-object position, the generality of the techniques proposed is not so restricted." ></td>
	<td class="line x" title="233:515	Any of the techniques can be applied to other parts of speech, other grammatical relations, and other types of context." ></td>
	<td class="line x" title="234:515	We restricted the scope of our experimental work solely for computational and evaluation reasons." ></td>
	<td class="line x" title="235:515	However, we could have chosen to look at the similarity between verbs or between adjectives." ></td>
	<td class="line x" title="236:515	6 We chose nouns as a starting point since nouns tend to allow less sense extensions than verbs and adjectives (Pustejovsky 1995)." ></td>
	<td class="line x" title="237:515	Further, the noun hyponymy hierarchy in WordNet, which will be used as a pseudo-gold standard for comparison, is widely recognized in this area of research." ></td>
	<td class="line x" title="238:515	Some previous work on distributional similarity between nouns has used only a single grammatical relation (e.g. , Lee 1999), whereas other work has considered multiple grammatical relations (e.g. , Lin 1998a)." ></td>
	<td class="line x" title="239:515	We consider only a single grammatical relation because we believe that it is important to evaluate the usefulness of each grammatical relation in calculating similarity before deciding how to combine information from 5 This results in a single 80:20 split of the complete data set, in which we are guaranteed that the original relative frequencies of the target nouns are maintained." ></td>
	<td class="line x" title="240:515	6 The use of grammatical relations to model context precludes finding similarities between words of different parts of speech." ></td>
	<td class="line x" title="241:515	Since we are looking at similarity in terms of substitutability, we would not expect to find a word of one part of speech substitutable for a word of another part of speech." ></td>
	<td class="line x" title="242:515	453 Computational Linguistics Volume 31, Number 4 different relations." ></td>
	<td class="line x" title="243:515	In previous work (Weeds 2003), we found that considering the subject relation as well as the direct-object relation did not improve performance on a pseudo-disambiguation task." ></td>
	<td class="line x" title="244:515	Our last restriction was to only consider 2,000 of the approximately 35,000 nouns occurring in the corpus." ></td>
	<td class="line x" title="245:515	This restriction was for computational efficiency and to avoid computing similarities based on the potentially unreliable descriptions of very lowfrequency words." ></td>
	<td class="line x" title="246:515	However, since our evaluation is comparative, we do not expect our results to be affected by this or any of the other restrictions." ></td>
	<td class="line x" title="247:515	3.2 Neighbor Set Comparison Technique In several of our experiments, we measure the overlap between two different similarity measures." ></td>
	<td class="line x" title="248:515	We use a neighbor set comparison technique adapted from Lin (1997)." ></td>
	<td class="line x" title="249:515	In order to compare two neighbor sets of size k, we transform each neighbor set so that each neighbor is given a rank score of k  rank." ></td>
	<td class="line x" title="250:515	Potential neighbors not within a given rank distance k of the noun score zero." ></td>
	<td class="line x" title="251:515	This transformation is required since scores computed on different scales are to be compared and because we wish to only consider neighbors up to a certain rank distance." ></td>
	<td class="line x" title="252:515	The similarity between two neighbor sets S and S prime is computed as the cosine of the rank score vectors: C(S, S prime ) = summationtext wSS prime s(w)  s prime (w) summationtext k i=1 i 2 (28) where s(w)ands prime (w) are the rank scores of the words within each neighbor set S and S prime respectively." ></td>
	<td class="line x" title="253:515	In previous work (Weeds and Weir 2003b), having computed the similarity between neighbor sets for each noun according to each pair of measures under consideration, we computed the mean similarity across all high-frequency nouns and all low-frequency nouns." ></td>
	<td class="line x" title="254:515	However, since the use of the CR framework requires parameter optimization, here, we randomly select 60% of the nouns to form a development set and use the remaining 40% as a test set." ></td>
	<td class="line x" title="255:515	Thus, any parameters are optimized over the development set nouns and performance measured at these settings over the test set." ></td>
	<td class="line x" title="256:515	4." ></td>
	<td class="line x" title="257:515	Alternative Distributional Similarity Measures In this section, we consider related work on distributional similarity measures and the extent to which some of these measures can be simulated within the CR framework." ></td>
	<td class="line x" title="258:515	However, there is a large body of work on distributional similarity measures; for a more extensive review, see Weeds (2003)." ></td>
	<td class="line x" title="259:515	Here, we concentrate on a number of more popular measures: the Dice Coefficient, Jaccards Coefficient, the L 1 Norm, the -skew divergence measure, Hindles measure, and Lins MI-based measure." ></td>
	<td class="line x" title="260:515	4.1 The Dice Coefficient The Dice Coefficient (Frakes and Baeza-Yates 1992) is a popular combinatorial similarity measure adopted from the field of Information Retrieval for use as a measure of lexical 454 Weeds and Weir Co-occurrence Retrieval distributional similarity." ></td>
	<td class="line x" title="261:515	It is computed as twice the ratio between the size of the intersection of the two feature sets and the sum of the sizes of the individual feature sets: sim dice (w 1, w 2 ) = 2 |F(w 1 )  F(w 2 )| |F(w 1 )|+|F(w 2 )| where F(w) ={c : P(c|w) > 0} (29) According to this measure, the similarity between words with no shared features is zero and the similarity between words with identical feature sets is 1." ></td>
	<td class="line x" title="262:515	However, as shown below, this formula is equivalent to a special case in the CR framework: the harmonic mean of precision and recall (or F-score) using the additive type-based CRM." ></td>
	<td class="line x" title="263:515	m h (P add type (w 1, w 2 ),R add type (w 1, w 2 ))= 2 P add type (w 1, w 2 ) R add type (w 1, w 2 ) P add type (w 1, w 2 ) +R add type (w 1, w 2 ) = 2  |TP| |F(w 1 )|  |TP| |F(w 2 )| |TP| |F(w 1 )| + |TP| |F(w 2 )| = 2 |TP||TP| |TP||F(w 1 )|+|TP||F(w 2 )| = 2 |TP| |F(w 1 )|+|F(w 2 )| = 2 |F(w 1 )  F(w 2 )| |F(w 1 )|+|F(w 2 )| = sim dice (w 1, w 2 ) (30) Thus, when  is set to 1 in the additive type-based CRM, the Dice Coefficient is exactly replicated." ></td>
	<td class="line x" title="264:515	4.2 Jaccards Coefficient Jaccards Coefficient (Salton and McGill 1983), also known as the Tanimoto Coefficient (Resnik 1993), is another popular combinatorial similarity measure." ></td>
	<td class="line x" title="265:515	It can be defined as the proportion of features belonging to either word that are shared by both words; that is, the ratio between the size of the intersection of the feature sets and the size of the union of feature sets: sim jacc (w 1, w 2 ) = |F(w 1 )  F(w 2 )| |F(w 1 )  F(w 2 )| (31) As with the Dice Coefficient, the similarity between words with no shared cooccurrences is zero and the similarity between words with identical features is 1." ></td>
	<td class="line x" title="266:515	Further, as shown by van Rijsbergen (1979), the Dice Coefficient and Jaccards Coefficient are monotonic in one another." ></td>
	<td class="line x" title="267:515	Thus, although in general the scores computed by each will be different, the orderings or rankings of objects will be the same." ></td>
	<td class="line x" title="268:515	In other words, for all k and w,thek nearest neighbors of word w according to Jaccards Coefficient will be identical to the k nearest neighbors of word w according to the Dice Coefficient and the harmonic mean of precision and recall in the additive type-based CRM." ></td>
	<td class="line x" title="269:515	455 Computational Linguistics Volume 31, Number 4 4.3 The L 1 Norm The L 1 Norm (Kaufman and Rousseeuw 1990) is a member of a family of measures known as the Minkowski Distance, for measuring the distance 7 between two points in space." ></td>
	<td class="line x" title="270:515	The L 1 Norm is also known as the Manhattan Distance, the taxi-cab distance, the city-block distance, and the absolute value distance, since it represents the distance traveled between the two points if you can only travel in orthogonal directions." ></td>
	<td class="line x" title="271:515	When used to calculate lexical distributional similarity, the dimensions of the vector space are co-occurrence types and the values of the vector components are the probabilities of the co-occurrence types given the word." ></td>
	<td class="line x" title="272:515	Thus the L 1 distance between two words, w 1 and w 2, can be written as: dist L 1 (w 1, w 2 ) = summationdisplay c |P(c|w 1 )  P(c|w 2 )| (32) However, noting the algebraic equivalence A + B |A  B|2  min(A, B)andusing basic probability theory, we can rewrite the L 1 Norm as follows: dist L 1 (w 1, w 2 ) = summationdisplay c |P(c|w 1 )  P(c|w 2 )| = summationdisplay c P(c|w 1 ) + P(c|w 2 )  2  min(P(c|w 1 ), P(c|w 2 )) = summationdisplay c P(c|w 1 ) + summationdisplay c P(c|w 2 )  2  summationdisplay c min(P(c|w 1 ), P(c|w 2 )) = 2  2  summationdisplay c min(P(c|w 1 ), P(c|w 2 )) (33) However, min(P(c|w 1 ), P(c|w 2 )) > 0 if and only if c  TP." ></td>
	<td class="line x" title="273:515	Hence: dist L 1 (w 1, w 2 ) = 2  2  summationdisplay TP min(P(c|w 1 ), P(c|w 2 ) = 2  2  sim dw tok (w 1, w 2 ) (34) In other words, the L 1 Norm is directly related to the difference-weighted tokenbased CRM." ></td>
	<td class="line x" title="274:515	The constant and multiplying factors are required, since the CRM defines a similarity in the range [0,1], whereas the L 1 Norm defines a distance in the range [0,2] (where 0 distance is equivalent to 1 on the similarity scale)." ></td>
	<td class="line x" title="275:515	4.4 The -skew Divergence Measure The -skew divergence measure (Lee 1999, 2001) is a popular approximation to the Kullback-Leibler divergence measure 8 (Kullback and Leibler 1951; Cover and Thomas 1991)." ></td>
	<td class="line x" title="276:515	It is an approximation developed to be used when unreliable MLE probabilities 7 Distance measures, also referred to as divergence and dissimilarity measures, can be viewed as the inverse of similarity measures; that is, an increase in distance correlates with a decrease in similarity." ></td>
	<td class="line x" title="277:515	8 The Kullback-Leibler divergence measure is also often referred to as relative entropy. 456 Weeds and Weir Co-occurrence Retrieval would result in the actual Kullback-Leibler divergence measure being equal to .Itis defined (Lee 1999) as: dist  (q, r) = D(r||.q + (1 ).r) (35) for 0    1, and where: D(p||q) = summationdisplay x p(x)log p(x) q(x) (36) In effect, the q distribution is smoothed with the r distribution, which results in it always being non-zero when the r distribution is non-zero." ></td>
	<td class="line x" title="278:515	The parameter  controls the extent to which the measure approximates the Kullback-Leibler divergence measure." ></td>
	<td class="line x" title="279:515	When  is close to 1, the approximation is close while avoiding the problem with zero probabilities associated with using the Kullback-Leibler divergence measure." ></td>
	<td class="line x" title="280:515	This theoretical justification for using a very high value of  (e.g. , 0.99) is also borne out by empirical evidence (Lee 2001)." ></td>
	<td class="line x" title="281:515	The -skew divergence measure retains the asymmetry of the Kullback-Leibler divergence, and Weeds (2003) discusses the significance in the direction in which it is calculated." ></td>
	<td class="line x" title="282:515	For the purposes of this paper, we will find the neighbors of w 2 by optimizing: 9 dist  (P(c|w 1 ), P(c|w 2 )) (37) Due to the form of the -skew divergence measure, we do not expect any of the CRMs to exactly simulate it." ></td>
	<td class="line x" title="283:515	However, this measure does take into account the differences between the probabilities of co-occurrences in each distribution (as a log ratio) and therefore we might expect that it will be fairly closely simulated by the differenceweighted token-based CRM." ></td>
	<td class="line x" title="284:515	Further, the -skew divergence measure is asymmetric." ></td>
	<td class="line x" title="285:515	dist  (w 1, w 2 ) measures the cost of using the distribution of w 1 instead of w 2 and is calculated over the verbs that occur with w 2 . As such, we might expect that dist  will be a high-recall measure, since recall is calculated over the co-occurrences of w 2 . In order to determine how close any approximation is in practice, we compared the 200 nearest neighbors according to dist  and different parameter settings within the CR framework for 1,000 high-frequency nouns and for 1,000 low-frequency nouns, using the data and the neighbor set comparison technique described in Section 3." ></td>
	<td class="line x" title="286:515	Table 4 shows the optimal parameters in each CRM for simulating dist , computed over the development set, and the mean similarity at these settings over both the development set and the test set." ></td>
	<td class="line x" title="287:515	From these results, we can make the following observations." ></td>
	<td class="line x" title="288:515	First, the differences in mean similarities over the development set and the test set are minimal." ></td>
	<td class="line x" title="289:515	Thus, performance of the models with respect to different parameter settings appears stable across different words." ></td>
	<td class="line x" title="290:515	Second, the differences between the models are fairly small." ></td>
	<td class="line x" title="291:515	The differenceweighted token-based CRM achieves a fairly close approximation to dist ,butthe 9 This is what Weeds (2003) refers to as dist 1 . 457 Computational Linguistics Volume 31, Number 4 Table 4 Optimized similarities between CRMs and dist  and corresponding parameter settings." ></td>
	<td class="line x" title="292:515	Target Noun Frequency high low Optimal Devel." ></td>
	<td class="line x" title="293:515	Test Optimal Devel." ></td>
	<td class="line x" title="294:515	Test Parameters Sim." ></td>
	<td class="line x" title="295:515	Sim." ></td>
	<td class="line x" title="296:515	Parameters Sim." ></td>
	<td class="line x" title="297:515	Sim." ></td>
	<td class="line x" title="298:515	CRM    sim add type 0.25 0.4 0.74 0.75 0.5 0.3 0.66 0.66 sim add tok 0.5 0.0 0.77 0.78 0.5 0.0 0.67 0.66 sim add mi 0.0 0.0 0.76 0.77 0.25 0.1 0.72 0.73 sim add wmi 0.25 0.0 0.71 0.72 0.25 0.1 0.79 0.79 sim add t 0.5 0.0 0.84 0.85 0.5 0.2 0.71 0.71 sim add z 0.5 0.0 0.79 0.80 0.5 0.1 0.63 0.63 sim add allr 0.25 0.0 0.70 0.71 0.5 0.0 0.64 0.63 sim dw type 0.0 0.25 0.70 0.71 0.0 0.0 0.52 0.53 sim dw tok   0.79 0.80   0.58 0.58 sim dw mi 0.0 0.0 0.66 0.68 0.0 0.0 0.60 0.60 sim dw wmi 0.0 0.1 0.66 0.67 0.0 0.1 0.58 0.58 sim dw t 0.5 0.1 0.82 0.83 0.5 0.3 0.69 0.69 sim dw z 0.5 0.0 0.78 0.80 0.5 0.1 0.64 0.64 sim dw allr 0.75 0.0 0.53 0.54 0.75 0.0 0.48 0.48 overall best approximation is achieved by the additive t-test based CRM." ></td>
	<td class="line x" title="299:515	Although none of the CRMs are able to simulate dist  exactly, the closeness of approximation achieved in the best cases (greater than 0.7) is substantially higher than the degree of overlap observed between other measures of distributional similarity." ></td>
	<td class="line x" title="300:515	Weeds, Weir, and McCarthy (2004) report an average overlap of 0.4 between neighbor sets produced using dist  and Jaccards Measure and an average overlap of 0.48 between neighbor sets produced using dist  and Lins similarity measure." ></td>
	<td class="line x" title="301:515	A third observation is that all of the asymmetric models get closest at high levels of recall for both highand low-frequency nouns." ></td>
	<td class="line x" title="302:515	For example, Figure 1 illustrates the variation in mean similarity between neighbor sets with the parameters  and  for the additive t-test based model." ></td>
	<td class="line x" title="303:515	As can be seen, similarity between neighbor sets is significantly higher at high recall settings (low ) within the model than at highprecision settings (high ), which suggests that dist  has high-recall CR characteristics." ></td>
	<td class="line oc" title="304:515	4.5 Hindles Measure Hindle (1990) proposed an MI-based measure, which he used to show that nouns could be reliably clustered based on their verb co-occurrences." ></td>
	<td class="line o" title="305:515	We consider the variant of 458 Weeds and Weir Co-occurrence Retrieval Figure 1 Variation (with parameters  and ) in development set mean similarity between neighbor sets of the additive t-test based CRM and of dist  . Hindles Measure proposed by (Lin 1998a), which overcomes the problem associated with calculating MI for word-feature combinations that do not occur: sim hind (w 1, w 2 ) = summationdisplay T(w 1 )T(w 2 ) min(I(c, w 1 ), I(c, w 2 )) (38) where T(w 1 ) ={c : I(c, n) > 0}." ></td>
	<td class="line x" title="306:515	This expression is the same as the numerator in the expressions for precision and recall in the difference-weighted MI-based CRM: P dw mi (w 1, w 2 ) = summationtext TP I(w 1, c)  min(I(w 1, c),I(w 2, c)) I(w 1, c) summationtext F(w 1 ) I(w 1, c) = summationtext TP min(I(w 1, c), I(w 2, c)) summationtext F(w 1 ) I(w 1, c) (39) R dw mi (w 1, w 2 ) = summationtext TP I(w 2, c)  min(I(w 2, c),I(w 1, c)) I(w 2, c) summationtext F(w 2 ) I(w 2, c) = summationtext TP min(I(w 2, c), I(w 1, c)) summationtext F(w 2 ) I(w 2, c) (40) since TP = T(w 1 )  T(w 2 )." ></td>
	<td class="line x" title="307:515	However, we also note that the denominator in the expression for recall depends only on w 2, and therefore, for a given w 2, is a constant." ></td>
	<td class="line x" title="308:515	Since w 2 is the target word, it will remain the same as we calculate each neighbor set." ></td>
	<td class="line x" title="309:515	Accordingly, the value of recall for each potential neighbor w 1 of w 2 will be the value of sim hind divided by a constant." ></td>
	<td class="line x" title="310:515	Hence, neighbor sets derived using sim hind are identical to those obtained using recall (= 0, = 0) in the difference-weighted MI-based CRM." ></td>
	<td class="line x" title="311:515	4.6 Lins Measure Lin (1998a) proposed a measure of lexical distributional similarity based on his information-theoretic similarity theorem (Lin 1997, 1998b): The similarity between A and B is measured by the ratio between the amount of information needed to state the commonality of A and B and the information needed to fully describe what A and B are." ></td>
	<td class="line x" title="312:515	459 Computational Linguistics Volume 31, Number 4 If the features of a word are grammatical relation contexts, the similarity between two words w 1 and w 2 can be written according to Lins measure as: sim lin (w 1, w 2 ) = summationtext T(w 1 )T(w 2 ) (I(w 1, c) + I(w 2, c)) summationtext T(w 1 ) I(w 1, c) + summationtext T(w 2 ) I(w 2, c) (41) where T(w) ={c : I(w, c) > 0}." ></td>
	<td class="line x" title="313:515	There are parallels between sim lin and sim dice in that both measures compute a ratio between what is shared by the descriptions of both nouns and the sum of the descriptions of each noun." ></td>
	<td class="line x" title="314:515	The major difference appears to be the use of MI, and hence we predicted that there would be a close relationship between sim lin and the harmonic mean in the additive MI-based CRM." ></td>
	<td class="line x" title="315:515	This relationship is shown below: m h (P add mi (w 1, w 2 ),R add mi (w 1, w 2 )) = 2 P add mi (w 1, w 2 ) R add mi (w 1, w 2 ) P add mi (w 1, w 2 ) +R add mi (w 1, w 2 ) (42) = 2  summationtext TP I(w 1, c) summationtext F(w 1 ) I(w 1, c)  summationtext TP I(w 2, c) summationtext F(w 2 ) I(w 2, c) summationtext TP I(w 1, c) summationtext F(w 1 ) I(w 1, c) + summationtext TP I(w 2, c) summationtext F(w 2 ) I(w 2, c) (43) = 2  summationtext TP I(w 1, c)  summationtext TP I(w 2, c) summationtext TP I(w 2, c)  summationtext F(w 1 ) I(w 1, c) + summationtext TP I(w 1, c)  summationtext F(w 2 ) I(w 2, c) (44) Now if summationtext TP I(w 1, c) = summationtext TP I(w 2, c), it follows: m h (P add mi (w 1, w 2 ),R add mi (w 1, w 2 )) = 2  summationtext TP I(w 1, c) summationtext F(w 1 ) I(w 1, c) + summationtext F(w 2 ) I(w 2, c) (45) = summationtext TP I(w 1, c) + I(w 2, c) summationtext F(w 1 ) I(w 1, c) + summationtext F(w 2 ) I(w 2, c) (46) = summationtext T(w 1 )T(w 2 ) (I(w 1, c) + I(w 2, c)) summationtext T(w 1 ) I(w 1, c) + summationtext T(w 2 ) I(w 2, c) since T(w) = F(w) (47) = sim lin (w 1, w 2 ) (48) Thus, when the additive MI-based model is used, = 1 and the condition summationtext TP I(w 1, c) = summationtext TP I(w 2, c) holds, the CR framework reduces to sim lin . However, this last necessary condition for equivalence is not one we can expect to hold for many (if any) pairs of words." ></td>
	<td class="line x" title="316:515	In order to investigate how good an approximation the harmonic mean is to sim lin in practice, we compared neighbor sets according to each measure using the neighbor set comparison technique outlined earlier." ></td>
	<td class="line x" title="317:515	Figure 2 illustrates the variation in mean similarity between neighbor sets with the parameters  and .At= 1, the average similarity between neighbor rankings was 0.967 for high-frequency nouns and 0.923 for low-frequency nouns." ></td>
	<td class="line x" title="318:515	This is significantly higher than similarities between other standard similarity measures." ></td>
	<td class="line x" title="319:515	However, the optimal approximation of sim lin was found using = 0.75 and = 0.5 in the additive MI-based CRM." ></td>
	<td class="line x" title="320:515	With these settings, the development set similarity was 0.987 for high460 Weeds and Weir Co-occurrence Retrieval frequency nouns and 0.977 for low-frequency nouns." ></td>
	<td class="line x" title="321:515	This suggests that sim lin allows more compensation for lack of recall by precision and vice versa than the harmonic mean." ></td>
	<td class="line x" title="322:515	4.7 Discussion We have seen that five of the existing lexical distributional similarity measures are (approximately) equivalent to settings within the CR framework and for one other, a weak approximation can be made." ></td>
	<td class="line x" title="323:515	The CR framework, however, more than simulates existing measures of distributional similarity." ></td>
	<td class="line x" title="324:515	It defines a space of distributional similarity measures that is already populated with a few named measures." ></td>
	<td class="line x" title="325:515	By exploring the space, we can discover the desirable characteristics of distributional similarity measures." ></td>
	<td class="line x" title="326:515	It may be that the most useful measure within this space has already been discovered, or it may be that a new optimal combination of characteristics is discovered." ></td>
	<td class="line x" title="327:515	The primary goal, however, is to understand how different characteristics relate to high performance in different applications and thus explain why one measure performs better than another." ></td>
	<td class="line x" title="328:515	With this goal in mind, we now turn to the applications of distributional similarity." ></td>
	<td class="line x" title="329:515	In the next section, we consider what characteristics of distributional similarity measures are desirable in two different application areas: (1) automatic thesaurus generation and (2) language modeling." ></td>
	<td class="line x" title="330:515	5." ></td>
	<td class="line x" title="331:515	Application-Based Evaluation As discussed by Weeds (2003), evaluation is a major problem in this area of research." ></td>
	<td class="line x" title="332:515	In some areas of natural language research, evaluation can be performed against a gold standard or against human plausibility judgments." ></td>
	<td class="line x" title="333:515	The first of these approaches is taken by Curran and Moens (2002), who evaluate a number of different distributional similarity measures and weight functions against a gold standard thesaurus compiled from Rogets,theMacquarie thesaurus, and the Moby thesaurus." ></td>
	<td class="line x" title="334:515	However, we argue that this approach can only be considered when distributional similarity is required as an approximation to semantic similarity and that, in any case, it is not ideal since it is not Figure 2 Variation (with parameters  and ) in development set mean similarity between neighbor sets of the additive MI-based CRM and of sim lin . 461 Computational Linguistics Volume 31, Number 4 clear that there is a single right answer as to which words are most distributionally similar." ></td>
	<td class="line x" title="335:515	The best measure of distributional similarity will be the one that returns the most useful neighbors in the context of a particular application and thus leads to the best performance in that application." ></td>
	<td class="line x" title="336:515	This section investigates whether the desirable characteristics of a lexical distributional similarity measure in an automatic thesaurus generation task (WordNet prediction) are the same as those in a language modeling task (pseudo-disambiguation)." ></td>
	<td class="line x" title="337:515	5.1 WordNet Prediction Task In this section, we evaluate the ability of distributional similarity measures to predict semantic similarity by making comparisons with WordNet." ></td>
	<td class="line x" title="338:515	An underlying assumption of this approach is that WordNet is a gold standard for semantic similarity, which, as is discussed by Weeds (2003), is unrealistic." ></td>
	<td class="line x" title="339:515	However, it seems reasonable to suppose that a distributional similarity measure that more closely predicts a semantic measure based on WordNet is more likely to be a good predictor of semantic similarity." ></td>
	<td class="line x" title="340:515	We chose WordNet as our gold standard for semantic similarity since, as discussed by Kilgarriff and Yallop (2000), distributional similarity scores calculated over grammatical relation level context tend to be more similar to tighter thesauri, such as WordNet, than looser thesauri such as Rogets. 5.1.1 Experimental Set-Up." ></td>
	<td class="line x" title="341:515	There are a number of ways to measure the distance between two nouns in the WordNet noun hierarchy (see Budanitsky [1999] for a review)." ></td>
	<td class="line x" title="342:515	In previous work (Weeds and Weir 2003b), we used the WordNet-based similarity measure first proposed in Lin (1997) and used in Lin (1998a): wn sim lin (w 1, w 2 ) = max c 1 S(w 1 )c 2 S(w 2 ) parenleftbigg max csup(c 1 )sup(c 2 ) 2logP(c) log (P(c 1 )) + log (P(c 2 )) parenrightbigg (49) where S(w) is the set of senses of the word w in WordNet, sup(c) is the set of possibly indirect super-classes of concept c in WordNet, and P(c) is the probability that a randomly selected word refers to an instance of concept c (estimated over some corpus such as SemCor [Miller et al. 1994])." ></td>
	<td class="line x" title="343:515	However, in other research (Budanitsky and Hirst 2001; Patwardhan, Banerjee, and Pedersen 2003; McCarthy, Koeling, and Weeds 2004), it has been shown that the distance measure of Jiang and Conrath (1997) (referred to herein as the JC measure) is a superior WordNet-based semantic similarity measure: wn dist JC (w 1, w 2 ) = max c 1 S(w 1 )c 2 S(w 2 ) parenleftbigg max csup(c 1 )sup(c 2 ) 2log(c)  log P(c 1 )  log P(c 2 ) parenrightbigg (50) In our work, we make an empirical comparison of neighbors derived using a WordNet-based measure and each of the distributional similarity measures using the technique discussed in Section 3." ></td>
	<td class="line x" title="344:515	We have carried out the same experiments using both the Lin measure and the JC measure." ></td>
	<td class="line x" title="345:515	Correlation between distributional similarity measures and the WordNet measure tends to be slightly higher when using the JC measure 462 Weeds and Weir Co-occurrence Retrieval Table 5 Optimized similarities between distributional neighbor sets and WordNet derived neighbor sets." ></td>
	<td class="line x" title="346:515	Noun Frequency high low Optimal Devel Test Optimal Devel Test Parameters Corr." ></td>
	<td class="line x" title="347:515	Corr." ></td>
	<td class="line x" title="348:515	Parameters Corr." ></td>
	<td class="line x" title="349:515	Corr." ></td>
	<td class="line x" title="350:515	Measure (C) (C) (C) (C) sim add type 0.25 0.5 0.323 0.327 0.5 0.25 0.281 0.275 sim add tok 0.25 0.3 0.302 0.310 0.25 0.0 0.266 0.263 sim add mi 0.25 0.2 0.334 0.342 0.25 0.2 0.290 0.283 sim add wmi 0.25 0.2 0.282 0.293 0.25 0.0 0.274 0.266 sim add t 0.5 0.2 0.330 0.338 0.5 0.2 0.292 0.286 sim add z 0.5 0.1 0.324 0.332 0.5 0.1 0.280 0.276 sim add allr 0.25 0.2 0.298 0.304 0.25 0.1 0.272 0.267 sim dw type 0.0 0.4 0.306 0.310 0.0 0.0 0.221 0.219 sim dw tok   0.285 0.294   0.212 0.211 sim dw mi 0.0 0.2 0.324 0.333 0.0 0.0 0.266 0.261 sim dw wmi 0.0 0.1 0.273 0.281 0.0 0.1 0.223 0.220 sim dw t 0.5 0.2 0.328 0.333 0.5 0.3 0.289 0.282 sim dw z 0.5 0.1 0.324 0.329 0.5 0.2 0.280 0.276 sim dw allr 0.75 0.2 0.263 0.265 0.75 0.0 0.226 0.225 sim dice 0.295 0.299 0.123 0.123 sim jacc 0.295 0.299 0.123 0.123 dist L1 0.285 0.294 0.212 0.211 dist  0.310 0.317 0.289 0.281 sim hind 0.320 0.326 0.267 0.261 sim lin 0.313 0.323 0.192 0.186 wnsim lin 0.907 0.907 0.884 0.883 (percentage increase in similarity of approximately 10%), but the relative differences between distributional similarity measures remain approximately the same." ></td>
	<td class="line x" title="351:515	Here, for brevity, we present results just using the JC measure." ></td>
	<td class="line x" title="352:515	5.1.2 Results." ></td>
	<td class="line x" title="353:515	As before, we present the results separately for the 1,000 high-frequency target nouns and for the 1,000 low-frequency target nouns." ></td>
	<td class="line x" title="354:515	Table 5 shows the optimal parameter settings for each CRM (computed over the development set) and the mean similarities with the JC measure at these settings in both the development set and the test set." ></td>
	<td class="line x" title="355:515	It also shows the mean similarities over the development set and the test set for each of the existing similarity measures discussed in Section 4." ></td>
	<td class="line x" title="356:515	For reference, we also present the mean similarity for the WordNet-based measure wn sim lin . For ease 463 Computational Linguistics Volume 31, Number 4 Figure 3 Bar chart illustrating test set similarity with WordNet for each distributional similarity measure." ></td>
	<td class="line x" title="357:515	of comparison, the test set correlation values for each distributional measure are also illustrated in Figure 3." ></td>
	<td class="line x" title="358:515	We would expect a mean overlap score of 0.08 by chance." ></td>
	<td class="line x" title="359:515	Standard deviations in the observed test set mean similarities were all less than 0.1, and thus any difference between mean scores of greater than 0.016 is significant at the 99% level, and differences greater than 0.007 are significant at the 90% level." ></td>
	<td class="line x" title="360:515	Thus, from the results in Table 5 we can make the following observations." ></td>
	<td class="line x" title="361:515	First, the best-performing distributional similarity measures, in terms of WordNet prediction, for both highand low-frequency nouns, are the MI-based and the t-test based CRMs." ></td>
	<td class="line x" title="362:515	The additive MI-based CRM performs the best for high-frequency nouns and the additive t-test based CRM performs the best for low-frequency nouns." ></td>
	<td class="line x" title="363:515	However, the differences between these models are not statistically significant." ></td>
	<td class="line x" title="364:515	These CRMs perform substantially better than all of the unparameterized distributional similarity measures, of which the best performing are sim hind and sim lin for high-frequency nouns and dist 1 for low-frequency nouns." ></td>
	<td class="line x" title="365:515	Second, the difference-weighted versions of each model generally perform slightly worse than their additive counterparts." ></td>
	<td class="line x" title="366:515	Thus, the difference in extent to which each word occurs in each context does not appear to be a factor in determining semantic similarity." ></td>
	<td class="line x" title="367:515	Third, all of the measures perform significantly better for high-frequency nouns than for low-frequency nouns." ></td>
	<td class="line x" title="368:515	However, some of the measures (sim lin, sim jacc and sim dice ) perform considerably worse for low-frequency nouns." ></td>
	<td class="line x" title="369:515	We now consider the effects of  and  in the CRMs on performance." ></td>
	<td class="line x" title="370:515	The pattern of variation across the CRMs was very similar." ></td>
	<td class="line x" title="371:515	This pattern is illustrated using one of the best-performing CRMs (sim add mi ) in Figure 4." ></td>
	<td class="line x" title="372:515	With reference to this figure and to the results for the other models (not shown), we make the following observations." ></td>
	<td class="line x" title="373:515	464 Weeds and Weir Co-occurrence Retrieval Figure 4 Variation in similarity with WordNet with respect to  and  for the additive MI-based CRM." ></td>
	<td class="line x" title="374:515	First, for highand low-frequency nouns, similarity with WordNet is higher for low values of  than for high values of ." ></td>
	<td class="line x" title="375:515	In other words, neighbors according to the WordNet based measure tend to have high-recall retrieval of the target nouns co-occurrences." ></td>
	<td class="line x" title="376:515	Second, a high value of  leads to high performance for high-frequency nouns but poor performance for low-frequency nouns." ></td>
	<td class="line x" title="377:515	This suggests that WordNetderived neighbors of high-frequency target nouns also have high-precision retrieval of the target nouns co-occurrences, whereas the WordNet-derived neighbors of lowfrequency target nouns do not." ></td>
	<td class="line x" title="378:515	This also explains why particular existing measures (Jaccards / the Dice Coefficient and Lins Measure), which are very similar to a = 1 setting in the CR framework, perform well for high-frequency nouns but poorly for low-frequency nouns." ></td>
	<td class="line x" title="379:515	5.1.3 Discussion." ></td>
	<td class="line x" title="380:515	Our results in this section are comparable to those of Curran and Moens (2002), who showed that combining the t-test with Jaccards coefficient outperformed combining MI with Jaccards coefficient by approximately 10% in a comparison against a gold-standard thesaurus." ></td>
	<td class="line x" title="381:515	However, we do not find a significant difference between using the t-test and MI in similarity calculation." ></td>
	<td class="line x" title="382:515	Further, we found that using a combination of precision and recall weighted towards recall performs substantially better than using the harmonic mean (which is equivalent to Jaccards measure)." ></td>
	<td class="line x" title="383:515	In our experiments, the development-set similarity using the harmonic mean in the additive MI-based CRM was 0.312 for high-frequency nouns and 0.153 for low-frequency nouns, and the development-set similarity using the harmonic mean in the additive t-test based CRM was 0.294 for high-frequency nouns and 0.129 for low-frequency nouns." ></td>
	<td class="line x" title="384:515	5.2 Pseudo-Disambiguation Task Pseudo-disambiguation tasks have become a standard evaluation technique (Gale, Church, and Yarowsky 1992; Sch utze 1992; Pereira, Tishby, and Lee 1993; Sch utze 1998; Lee 1999; Dagan, Lee, and Pereira 1999; Golding and Roth 1999; Rooth et al. 1999; EvenZohar and Roth 2000; Lee 2001; Clark and Weir 2002) and, in the current setting, we may use a nouns neighbors to decide which of two co-occurrences is the most likely." ></td>
	<td class="line x" title="385:515	Although pseudo-disambiguation is an artificial task, it has relevance in at least two application areas." ></td>
	<td class="line x" title="386:515	First, by replacing occurrences of a particular word in a test suite with 465 Computational Linguistics Volume 31, Number 4 a pair of words from which a technique must choose, we recreate a simplified version of the word sense disambiguation task; that is, we choose between a fixed number of homonyms based on local context." ></td>
	<td class="line x" title="387:515	The second is in language modeling where we wish to estimate the probabilities of co-occurrences of events but, due to the sparse data problem, it is often the case that a possible co-occurrence has not been seen in the training data." ></td>
	<td class="line x" title="388:515	5.2.1 Experimental Set-up." ></td>
	<td class="line x" title="389:515	A typical approach to performing pseudo-disambiguation is as follows." ></td>
	<td class="line x" title="390:515	A large set of noun-verb direct-object pairs is extracted from a corpus, of which a portion is used as test data and another portion is used as training data." ></td>
	<td class="line x" title="391:515	The training data can be used to construct a language model and/or determine the distributionally nearest neighbors of each noun." ></td>
	<td class="line x" title="392:515	Noun-verb pairs (n, v 1 ) in the test data are replaced with noun-verb-verb triples (n, v 1, v 2 ) and the task is to decide which of the two verbs is the most likely to take the noun as its direct object." ></td>
	<td class="line x" title="393:515	Performance is usually measured as error rate." ></td>
	<td class="line x" title="394:515	We will now discuss the details of our own experimental set-up." ></td>
	<td class="line x" title="395:515	As already discussed (Section 3), 80% of the noun-verb direct-object data extracted from the BNC for each of 2,000 nouns was used to compute the similarity between nouns and is also used as the language model in the pseudo-disambiguation task, and 20% of the data was set aside as test data, providing unseen co-occurrences for this pseudo-disambiguation task." ></td>
	<td class="line x" title="396:515	In order to construct the test set from the test data, we took all 10 of the test data set aside for each target noun and modified it as follows." ></td>
	<td class="line x" title="397:515	We converted each noun-verb pair (n, v 1 ) in the test data into a noun-verb-verb triple (n, v 1, v 2 )." ></td>
	<td class="line x" title="398:515	v 2 was randomly selected from the verbs that have the same frequency, calculated over all the training data, as v 1 plus or minus 1." ></td>
	<td class="line x" title="399:515	If there are no other verbs within this frequency range, then the test instance is discarded." ></td>
	<td class="line x" title="400:515	This method ensures that there is no systematic bias towards v 2 being of a higher or lower frequency than v 1 . We also ensured that (n, v 2 )hasnot been seen in the test or training data." ></td>
	<td class="line x" title="401:515	Ten test instances 11 were then selected for each target noun in a two-step process of (1) while more than ten triples remained, discarding duplicate triples and (2) randomly selecting ten triples from those remaining after step 1." ></td>
	<td class="line x" title="402:515	At this point, we have 10,000 test instances pertaining to high-frequency nouns and 10,000 test instances pertaining to low-frequency nouns, and there are no biases towards the higher-frequency or lower-frequency nouns within these sets." ></td>
	<td class="line x" title="403:515	Each of these sets was split into five disjoint subsets, each containing two instances for each target noun." ></td>
	<td class="line x" title="404:515	We use these five subsets in two ways." ></td>
	<td class="line x" title="405:515	First, we perform five-fold cross validation." ></td>
	<td class="line x" title="406:515	In five-fold cross validation, we compute the optimal parameter settings in four of the subsets and the error rate at this optimal parameter setting in the remaining subset." ></td>
	<td class="line x" title="407:515	This is repeated five times with a different subset held out each time." ></td>
	<td class="line x" title="408:515	We then compute an average optimal error rate." ></td>
	<td class="line x" title="409:515	We cannot, however, compute an average optimal parameter setting, since this would assume a convex relationship between parameter settings and error rate." ></td>
	<td class="line x" title="410:515	In order to study the relationship between parameter settings and error rate, we combine three of the sets to form a development set and two of the sets to form a test set." ></td>
	<td class="line x" title="411:515	The development set is used to optimize parameters and the test set 10 Unlike Lee (1999), we do not delete instances from the test data that occur in the training data." ></td>
	<td class="line x" title="412:515	This is discussed in detail in (Weeds 2003), but our main justification for this approach is that a single co-occurrence of (n, v 1 ) compared to zero co-occurrences of (n, v 2 ) is not necessarily sufficient evidence to conclude that the population probability of (n, v 1 ) is greater than that of (n, v 2 )." ></td>
	<td class="line x" title="413:515	11 Ten being less than the minimum number (14) of (possibly) indistinct co-occurrences for any target noun in the original test data." ></td>
	<td class="line x" title="414:515	466 Weeds and Weir Co-occurrence Retrieval to determine error rates at the optimal settings." ></td>
	<td class="line x" title="415:515	In graphs showing the relationship between error rate and parameter settings, it is the error rate in this development set that is shown." ></td>
	<td class="line x" title="416:515	In the case of the CRMs, the parameters that are optimized are , ,and k (the number of nearest neighbors)." ></td>
	<td class="line x" title="417:515	12 For the existing measures, the only parameter to be optimized is k. Having constructed the test sets, the task is to take each test instance (n, v 1, v 2 )and use the nearest neighbors of noun n (as computed from the training data) to decide which of (n, v 1 )and(n, v 2 ) was the original co-occurrence." ></td>
	<td class="line x" title="418:515	Each of ns neighbors, m,is given a vote that is equal to the difference in frequencies of the co-occurrences (m, v 1 ) and (m, v 2 ) and that it casts to the verb with which it occurs most frequently." ></td>
	<td class="line x" title="419:515	Thus, we distinguish between cases where a neighbor occurs with each verb approximately the same number of times and where a neighbor occurs with one verb significantly more often than the other." ></td>
	<td class="line x" title="420:515	The votes for each verb are summed over all of the k nearest neighbors of n, and the verb with the most votes wins." ></td>
	<td class="line x" title="421:515	Performance is measured as error rate." ></td>
	<td class="line x" title="422:515	Error rate = 1 T parenleftBig # of incorrect choices + #ofties 2 parenrightBig (51) where T is the number of test instances and a tie results when the neighbors cannot decide between the two alternatives." ></td>
	<td class="line x" title="423:515	5.2.2 Results." ></td>
	<td class="line x" title="424:515	In this section, we present results on the pseudo-disambiguation task for all of the CRMs described in Section 2." ></td>
	<td class="line x" title="425:515	We also compare the results with the six existing distributional similarity measures (Section 4) and the two WordNet-based measures (Section 5.1)." ></td>
	<td class="line x" title="426:515	A baseline for these experiments is the performance obtained by a technique that backs-off to the unigram probabilities of the verbs being disambiguated." ></td>
	<td class="line x" title="427:515	By construction of the test set, this should be approximately 0.5." ></td>
	<td class="line x" title="428:515	The actual empirical figures are 0.553 for the high-frequency noun test set and 0.586 for the low-frequency noun test set." ></td>
	<td class="line x" title="429:515	The deviation from 0.5 is due to the unigram probabilities of the verbs not being exactly equal and to their being calculated over a larger data set than just the training data for the 2,000 target nouns." ></td>
	<td class="line x" title="430:515	These baseline error-rates are also different from what is observed when all 1,999 potential neighbors are considered." ></td>
	<td class="line x" title="431:515	In this case, we obtain an error rate of 0.6885 for the high-frequency noun test set and 0.6178 for the lowfrequency noun test set." ></td>
	<td class="line x" title="432:515	These differences are due to the fact that the correct choice verb, but not the incorrect choice verb, has occurred, possibly many times, with the target noun in the training data, but a noun is not considered as a potential neighbor of itself." ></td>
	<td class="line x" title="433:515	The results are summarized in Table 6." ></td>
	<td class="line x" title="434:515	The table gives the average optimal error rates for each measure, and for highand low-frequency nouns, calculated using fivefold cross validation." ></td>
	<td class="line x" title="435:515	For ease of comparison, the cross-validated average optimal error rates are illustrated in Figure 5." ></td>
	<td class="line x" title="436:515	Standard deviation in the mean optimal error rate across the five folds was always less than 0.15 and thus differences greater than 0.028 are significant at the 99% level and differences greater than 0.012 are significant at the 90% level." ></td>
	<td class="line x" title="437:515	From the results, we make the following observations." ></td>
	<td class="line x" title="438:515	12 We also experimented with optimizing a similarity threshold t, but found that optimizing k gave better results (Weeds 2003)." ></td>
	<td class="line x" title="439:515	467 Computational Linguistics Volume 31, Number 4 Table 6 Mean optimal error rates using five-fold cross-validation (when optimizing k,  and )." ></td>
	<td class="line x" title="440:515	Noun Frequency Measure Noun Frequency Measure high low high low sim add type 0.196 0.197 sim dw type 0.214 0.185 sim add tok 0.219 0.241 sim dw tok 0.234 0.202 sim add mi 0.178 0.169 sim dw mi 0.187 0.176 sim add wmi 0.173 0.192 sim dw wmi 0.171 0.192 sim add t 0.154 0.172 sim dw t 0.163 0.186 sim add z 0.164 0.183 sim dw z 0.167 0.193 sim add allr 0.170 0.211 sim dw allr 0.171 0.215 sim dice 0.215 0.204 sim jacc 0.215 0.204 dist L 1 0.234 0.202 dist 1 0.230 0.192 sim hind 0.201 0.18 sim lin 0.193 0.181 wn sim lin 0.295 0.294 wn dist JC 0.302 0.295 baseline 0.553 0.586 First, the best measure appears to be the additive t-test based CRM." ></td>
	<td class="line x" title="441:515	This significantly outperforms all but one (the z-test based CRM) of the other measures for highfrequency nouns." ></td>
	<td class="line x" title="442:515	For low-frequency nouns, slightly higher performance is obtained using the additive MI-based CRM." ></td>
	<td class="line x" title="443:515	This difference, however, is not statistically significant." ></td>
	<td class="line x" title="444:515	Second, all of the distributional similarity measures perform considerably better than the WordNet-based measures 13 at this task for highand low-frequency nouns." ></td>
	<td class="line x" title="445:515	Third, for many measures, performance over high-frequency nouns is not significantly higher (and is in some cases lower) than over low-frequency nouns." ></td>
	<td class="line x" title="446:515	This suggests that distributional similarity can be used in language modeling even when there is relatively little corpus data over which to calculate distributional similarity." ></td>
	<td class="line x" title="447:515	We now consider the effects of the different parameters on performance." ></td>
	<td class="line x" title="448:515	Since we use the development set to determine the optimal parameters, we consider performance on the development set as each parameter is varied." ></td>
	<td class="line x" title="449:515	Table 7 shows the optimized parameter settings in the development set, error rate at these settings in the development set, and error rate at these settings in the test set." ></td>
	<td class="line x" title="450:515	For the CRMs, we considered how the performance varies with each parameter when the other parameters are held constant at their optimum values." ></td>
	<td class="line x" title="451:515	Figure 6 shows how performance varies with , and Figure 7 shows how performance varies with  for the additive and difference-weighted t-test based and MI-based CRMs." ></td>
	<td class="line x" title="452:515	For reference, the optimal error rates for the best performing existing distributional similarity measure (sim lin ) is also shown as a straight line on each graph." ></td>
	<td class="line x" title="453:515	We do not show the variation with respect to k for any of the measures, but this was fairly similar for all measures and is as would be expected." ></td>
	<td class="line x" title="454:515	To begin with, considering 13 However, for this task, in contrast to earlier work, wn sim lin gives slightly, although insignificantly, better performance than wn dist JC . 468 Weeds and Weir Co-occurrence Retrieval Figure 5 Bar chart illustrating cross-validated optimal error rates for each measure when k is optimised." ></td>
	<td class="line x" title="455:515	more neighbors increases performance, since more neighbors allow decisions to be made in a greater number of cases." ></td>
	<td class="line x" title="456:515	However, when k increases beyond an optimal value, a greater number of these decisions will be in the wrong direction, since these words are not very similar to the target word, leading to a decrease in performance." ></td>
	<td class="line x" title="457:515	In a small number of cases (when using the ALLR-based CRMs or the WMI-based CRMs for high frequency nouns), performance peaks at k = 1." ></td>
	<td class="line x" title="458:515	This suggests that these measures may be very good at finding a few very close neighbors." ></td>
	<td class="line x" title="459:515	The majority of models, including the additive t-test based and additive MI-based CRMs, perform significantly better at low values of  (0.25-0.5) and high values of  (around 0.8)." ></td>
	<td class="line x" title="460:515	This indicates that a potential neighbor with high-precision retrieval of informative features is more useful than one with high-recall retrieval." ></td>
	<td class="line x" title="461:515	In other words, it seems that it is better to sacrifice being able to make decisions on every test instance with a small number of neighbors in favor of not having neighbors that predict incorrect verb co-occurrences." ></td>
	<td class="line x" title="462:515	This also suggests why we saw fairly low performance by the skew divergence measure on this task, since it is closest to a high-recall setting in the additive t-test based model." ></td>
	<td class="line x" title="463:515	The low values of  indicate that a combination of precision and recall that is closer to a weighted arithmetic mean is generally better than one that is closer to an unweighted harmonic mean." ></td>
	<td class="line x" title="464:515	However, this does not hold for the t-test based CRMs for low-frequency nouns." ></td>
	<td class="line x" title="465:515	Here a higher value of  is optimal, indicating that, in this case, requiring both recall and precision results in high performance." ></td>
	<td class="line x" title="466:515	6." ></td>
	<td class="line x" title="467:515	Conclusions and Future Directions Our main contribution is the development of a framework, first presented in a preliminary form in Weeds and Weir (2003b), that is based on the concept of lexical substi469 Computational Linguistics Volume 31, Number 4 Table 7 Summary of results on pseudo-disambiguation task when optimizing ,  and k. Noun Frequency high low Optimal Devel." ></td>
	<td class="line x" title="468:515	Test Optimal Devel." ></td>
	<td class="line x" title="469:515	Test Parameters Error Error Parameters Error Error Measure k k sim add type 0.25 0.8 150 0.193 0.193 0.25 0.75 100 0.192 0.200 sim add tok 0 0.8 250 0.211 0.224 0.5 0.1 130 0.234 0.233 sim add mi 0.25 0.8 170 0.175 0.186 0.5 0.8 120 0.169 0.178 sim add wmi 0.0 1.0 1 0.175 0.169 0.75 0.0 100 0.183 0.182 sim add t 0.25 0.8 190 0.153 0.155 0.5 0.7 110 0.165 0.176 sim add z 0.25 0.7 40 0.165 0.163 0.5 1.0 250 0.174 0.188 sim add allr 0.0 0.9 1 0.170 0.169 0.25 0.6 90 0.204 0.210 sim dw type 0 0.6 50 0.208 0.215 0.25 0.3 190 0.177 0.188 sim dw tok n/a n/a 60 0.227 0.234 n/a n/a 50 0.194 0.206 sim dw mi 0.25 0.8 100 0.181 0.193 0.5 0.7 160 0.172 0.173 sim dw wmi 0.0 0.0 1 0.172 0.170 0.25 0.1 450 0.183 0.190 sim dw t 0.5 0.8 120 0.156 0.165 0.75 0.6 250 0.179 0.187 sim dw z 0.5 0.7 50 0.166 0.171 0.75 0.9 400 0.187 0.199 sim dw allr 0.0 0.9 1 0.171 0.169 0.5 1.0 180 0.208 0.212 sim lin n/a n/a 50 0.190 0.199 n/a n/a 80 0.179 0.186 tutability." ></td>
	<td class="line x" title="470:515	Here, we cast the problem of measuring distributional similarity as one of co-occurrence retrieval (CR), for which we can measure precision and recall by analogy with the way they are measured in document retrieval." ></td>
	<td class="line x" title="471:515	This CR framework has then allowed us to systematically explore various characteristics of distributional similarity measures." ></td>
	<td class="line x" title="472:515	First, we asked whether lexical substitutability is necessarily symmetric." ></td>
	<td class="line x" title="473:515	To this end, we have explored the merits of symmetry and asymmetry in a similarity measure by varying the relative importance attached to precision and recall." ></td>
	<td class="line x" title="474:515	We have seen that as the distribution of word B moves away from being identical to that of word A, its similarity with A can decrease along one or both of two dimensions." ></td>
	<td class="line x" title="475:515	When B occurs in contexts that word A does not, precision is lost but B may remain a high-recall neighbor of word A. When B does not occur in contexts that A does, recall is lost but B may remain a high-precision neighbor of word A. Through our experimental work, which is more thorough than that presented in Weeds and Weir (2003b), we have shown that the kind of neighbor preferred appears to depend on the application in hand." ></td>
	<td class="line x" title="476:515	High-precision neighbors were more useful in the language modeling task of pseudo-disambiguation and high-recall neighbors were more highly correlated with WordNet-derived neighbor sets." ></td>
	<td class="line x" title="477:515	Thus, similarity appears to be inherently asymmetric." ></td>
	<td class="line x" title="478:515	Further, it would seem 470 Weeds and Weir Co-occurrence Retrieval Figure 6 Performance of CRMs with respect to  (at optimal values of k and )." ></td>
	<td class="line x" title="479:515	unlikely that any single, unparameterized measure of distributional similarity would be able to do better on both tasks." ></td>
	<td class="line x" title="480:515	Second, we asked whether all contexts are equally important in the calculation of distributional similarity." ></td>
	<td class="line x" title="481:515	To this end, we have explored the way in which frequency information is utilized using different co-occurrence retrieval models (CRMs)." ></td>
	<td class="line x" title="482:515	Using different weight functions, we have investigated the relative importance of different co-occurrence types." ></td>
	<td class="line x" title="483:515	In earlier work (Weeds and Weir 2003b), we saw that using MI to weight features gave improved performance on the two evaluation tasks over typebased or token-based CRMs." ></td>
	<td class="line x" title="484:515	Here, we have seen that further gains can be made by using the t-test as a weight function." ></td>
	<td class="line x" title="485:515	This leads to significant improvements on the pseudodisambiguation task for all nouns and marginal improvements on the WordNet prediction task for low-frequency nouns." ></td>
	<td class="line x" title="486:515	To some extent, this supports the findings of Curran and Moens (2002), who investigated a number of weight functions for distributional similarity and showed that the t-test performed better than a number of other weight functions including MI." ></td>
	<td class="line x" title="487:515	Third, we asked whether it is necessary to consider the difference in extent to which each word appears in each context." ></td>
	<td class="line x" title="488:515	To this end, we have herein proposed differenceFigure 7 Performance of CRMs with respect to  (at optimal values of k and )." ></td>
	<td class="line x" title="489:515	471 Computational Linguistics Volume 31, Number 4 weighted versions of each model in which the similarity of two words in respect of an individual feature is defined using the same principles that we use to define the similarity of two words in respect of all their features." ></td>
	<td class="line x" title="490:515	We have compared these difference-weighted CRMs to their additive counterparts and shown that differenceweighting does not seem to be a major factor and does not improve results when using the best-performing CRMs." ></td>
	<td class="line x" title="491:515	Another important contribution of this work on co-occurrence retrieval is a better understanding of existing distributional similarity measures." ></td>
	<td class="line x" title="492:515	By comparing existing measures with the CR framework, we can analyze their CR characteristics." ></td>
	<td class="line x" title="493:515	As discussed in Weeds and Weir (2003b), the Dice Coefficient and Jaccards Coefficient are exactly simulated by = 1 in the additive type-based model and Lins Measure is almost equivalent to the harmonic mean of precision and recall in the additive MI-based model." ></td>
	<td class="line x" title="494:515	Here, we also show that the L 1 Norm is exactly simulated by the (unparameterized) difference-weighted token-based model, Hindles Measure is exactly simulated by = 0,= 0 in the additive MI-based model, and the -skew divergence measure is most similar to high-recall settings in the additive t-test based CRM." ></td>
	<td class="line x" title="495:515	Knowing that Lins Measure is almost equivalent to the harmonic mean of precision and recall in the additive MI-based model explains why this measure does badly on the WordNet prediction task for low-frequency nouns." ></td>
	<td class="line x" title="496:515	We have seen that recall is more important than precision in the WordNet prediction task, whereas the nearest neighbors of a target noun according to Lins Measure have both high precision and high recall." ></td>
	<td class="line x" title="497:515	Conversely, knowing that the -skew divergence measure is most closely approximated by highrecall settings in the additive t-test based model explains why this measure performs poorly on the pseudo-disambiguation task, since we have seen that high precision is required for optimal performance on this task." ></td>
	<td class="line x" title="498:515	Finally, our evaluation of measures has been performed over a set of 2,000 nouns, and we have shown that the performance of distributional similarity techniques for low-frequency nouns is not significantly lower than for high-frequency nouns." ></td>
	<td class="line x" title="499:515	This suggests that distributional techniques might be used even when there is relatively little data available." ></td>
	<td class="line x" title="500:515	In the distributional domain, this means that we can use probability estimation techniques for rare words with greater confidence." ></td>
	<td class="line x" title="501:515	In the semantic domain, we might be able to use distributional techniques to extend existing semantic resources to cover rare or new words or automatically generate domain-, genre-, or dialect-specific resources." ></td>
	<td class="line x" title="502:515	There are a number of major directions in which this work can be extended." ></td>
	<td class="line x" title="503:515	First, although the set of CRMs defined here is more extensive than that defined in Weeds and Weir (2003b), it is still not exhaustive, and other models might be proposed." ></td>
	<td class="line x" title="504:515	Further, it would be interesting to combine CRMs with the feature reweighting scheme of Geffet and Dagan (2004)." ></td>
	<td class="line x" title="505:515	These authors compare distributional similarity scores with human judgments of semantic entailment and show that substantial (approximately 10%) improvements over using Lins Measure can be achieved by first calculating similarity using Lins Measure and then recalculating similarity using a relative feature focus score, which indicates how many of a words nearest neighbors shared that feature." ></td>
	<td class="line x" title="506:515	Second, there are other potential application-based tasks that could be used to evaluate CRMs and distributional similarity methods in general." ></td>
	<td class="line x" title="507:515	In particular, we see potential for the use of distributional similarity methods in prepositional phrase attachment ambiguity resolution." ></td>
	<td class="line x" title="508:515	This task has been previously tackled using semantic classes to predict what is ultimately distributional information." ></td>
	<td class="line x" title="509:515	Accordingly, we believe that it should be possible to do better using the CR framework." ></td>
	<td class="line x" title="510:515	472 Weeds and Weir Co-occurrence Retrieval Finally, in order to be able to truly rival manually generated thesauri, distributional techniques need to be able to distinguish between different semantic relations such as synonymy, antonymy, and hyponymy." ></td>
	<td class="line x" title="511:515	These are important linguistic distinctions, particularly in the semantic domain, since we are unlikely, say, to want to replace a word with its antonym." ></td>
	<td class="line x" title="512:515	Weeds, Weir, and McCarthy (2004) give preliminary results on the the use of precision and recall to distinguish between hypernyms and hyponyms in sets of distributionally related words." ></td>
	<td class="line x" title="513:515	Acknowledgments This research was supported by an Engineering and Physical Sciences Research Council (EPSRC) studentship to the first author." ></td>
	<td class="line x" title="514:515	The authors would like to thank John Carroll, Mirella Lapata, Adam Kilgarriff, Bill Keller, Steve Clark, James Curran, Darren Pearce, Diana McCarthy, and Mark McLauchlan for helpful discussions and insightful comments throughout the course of the research." ></td>
	<td class="line x" title="515:515	We would also like to thank the anonymous reviewers of this paper for their comments and suggestions." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P05-1016
Inducing Ontological Co-Occurrence Vectors
Pantel, Patrick;"></td>
	<td class="line x" title="1:208	Proceedings of the 43rd Annual Meeting of the ACL, pages 125132, Ann Arbor, June 2005." ></td>
	<td class="line x" title="2:208	c2005 Association for Computational Linguistics Inducing Ontological Co-occurrence Vectors Patrick Pantel Information Sciences Institute University of Southern California 4676 Admiralty Way Marina del Rey, CA 90292 pantel@isi.edu Abstract In this paper, we present an unsupervised methodology for propagating lexical cooccurrence vectors into an ontology such as WordNet." ></td>
	<td class="line x" title="3:208	We evaluate the framework on the task of automatically attaching new concepts into the ontology." ></td>
	<td class="line x" title="4:208	Experimental results show 73.9% attachment accuracy in the first position and 81.3% accuracy in the top-5 positions." ></td>
	<td class="line x" title="5:208	This framework could potentially serve as a foundation for ontologizing lexical-semantic resources and assist the development of other largescale and internally consistent collections of semantic information." ></td>
	<td class="line x" title="6:208	1 Introduction Despite considerable effort, there is still today no commonly accepted semantic corpus, semantic framework, notation, or even agreement on precisely which aspects of semantics are most useful (if at all)." ></td>
	<td class="line x" title="7:208	We believe that one important reason for this rather startling fact is the absence of truly wide-coverage semantic resources." ></td>
	<td class="line x" title="8:208	Recognizing this, some recent work on wide coverage term banks, like WordNet (Miller 1990) and CYC (Lenat 1995), and annotated corpora, like FrameNet (Baker et al. 1998), Propbank (Kingsbury et al. 2002) and Nombank (Meyers et al. 2004), seeks to address the problem." ></td>
	<td class="line x" title="9:208	But manual efforts such as these suffer from two drawbacks: they are difficult to tailor to new domains, and they have internal inconsistencies that can make automating the acquisition process difficult." ></td>
	<td class="line x" title="10:208	In this work, we introduce a general framework for inducing co-occurrence feature vectors for nodes in a WordNet-like ontology." ></td>
	<td class="line x" title="11:208	We believe that this framework will be useful for a variety of applications, including adding additional semantic information to existing semantic term banks by disambiguating lexical-semantic resources." ></td>
	<td class="line x" title="12:208	Ontologizing semantic resources Recently, researchers have applied textand web-mining algorithms for automatically creating lexical semantic resources like similarity lists (Lin 1998), semantic lexicons (Riloff and Shepherd 1997), hyponymy lists (Shinzato and Torisawa 2004; Pantel and Ravichandran 2004), partwhole lists (Girgu et al. 2003), and verb relation graphs (Chklovski and Pantel 2004)." ></td>
	<td class="line x" title="13:208	However, none of these resources have been directly linked into an ontological framework." ></td>
	<td class="line x" title="14:208	For example, in VERBOCEAN (Chklovski and Pantel 2004), we find the verb relation to surpass is-stronger-than to hit, but it is not specified that it is the achieving sense of hit where this relation applies." ></td>
	<td class="line x" title="15:208	We term ontologizing a lexical-semantic resource as the task of sense disambiguating the resource." ></td>
	<td class="line x" title="16:208	This problem is different but not orthogonal to word-sense disambiguation." ></td>
	<td class="line x" title="17:208	If we could disambiguate large collections of text with high accuracy, then current methods for building lexical-semantic resources could easily be applied to ontologize them by treating each words senses as separate words." ></td>
	<td class="line x" title="18:208	Our method does not require the disambiguation of text." ></td>
	<td class="line x" title="19:208	Instead, it relies on the principle of distributional similarity and that polysemous words that are similar in one sense are dissimilar in their other senses." ></td>
	<td class="line x" title="20:208	125 Given the enriched ontologies produced by our method, we believe that ontologizing lexicalsemantic resources will be feasible." ></td>
	<td class="line x" title="21:208	For example, consider the example verb relation to surpass isstronger-than to hit from above." ></td>
	<td class="line x" title="22:208	To disambiguate the verb hit, we can look at all other verbs that to surpass is stronger than (for example, in VERBOCEAN, to surpass is-stronger-than to overtake and to surpass is-stronger-than to equal)." ></td>
	<td class="line x" title="23:208	Now, we can simply compare the lexical co-occurrence vectors of overtake and equal with the ontological feature vectors of the senses of hit (which are induced by our framework)." ></td>
	<td class="line x" title="24:208	The sense whose feature vector is most similar is selected." ></td>
	<td class="line x" title="25:208	It remains to be seen in future work how well this approach performs on ontologizing various semantic resources." ></td>
	<td class="line x" title="26:208	In this paper, we focus on the general framework for inducing the ontological co-occurrence vectors and we apply it to the task of linking new terms into the ontology." ></td>
	<td class="line x" title="27:208	2 Relevant work Our framework aims at enriching WordNet-like ontologies with syntactic features derived from a non-annotated corpus." ></td>
	<td class="line x" title="28:208	Others have also made significant additions to WordNet." ></td>
	<td class="line x" title="29:208	For example, in eXtended WordNet (Harabagiu et al. 1999), the rich glosses in WordNet are enriched by disambiguating the nouns, verbs, adverbs, and adjectives with synsets." ></td>
	<td class="line x" title="30:208	Another work has enriched WordNet synsets with topically related words extracted from the Web (Agirre et al. 2001)." ></td>
	<td class="line x" title="31:208	While this method takes advantage of the redundancy of the web, our source of information is a local document collection, which opens the possibility for domain specific applications." ></td>
	<td class="line x" title="32:208	Distributional approaches to building semantic repositories have shown remarkable power." ></td>
	<td class="line x" title="33:208	The underlying assumption, called the Distributional Hypothesis (Harris 1985), links the semantics of words to their lexical and syntactic behavior." ></td>
	<td class="line x" title="34:208	The hypothesis states that words that occur in the same contexts tend to have similar meaning." ></td>
	<td class="line oc" title="35:208	Researchers have mostly looked at representing words by their surrounding words (Lund and Burgess 1996) and by their syntactical contexts (Hindle 1990; Lin 1998)." ></td>
	<td class="line n" title="36:208	However, these representations do not distinguish between the different senses of words." ></td>
	<td class="line x" title="37:208	Our framework utilizes these principles and representations to induce disambiguated feature vectors." ></td>
	<td class="line x" title="38:208	We describe these representations further in Section 3." ></td>
	<td class="line x" title="39:208	In supervised word sense disambiguation, senses are commonly represented by their surrounding words in a sense-tagged corpus (Gale et al. 1991)." ></td>
	<td class="line x" title="40:208	If we had a large collection of sensetagged text, then we could extract disambiguated feature vectors by collecting co-occurrence features for each word sense." ></td>
	<td class="line x" title="41:208	However, since there is little sense-tagged text available, the feature vectors for a random WordNet concept would be very sparse." ></td>
	<td class="line x" title="42:208	In our framework, feature vectors are induced from much larger untagged corpora (currently 3GB of newspaper text)." ></td>
	<td class="line x" title="43:208	Another approach to building semantic repositories is to collect and merge existing ontologies." ></td>
	<td class="line x" title="44:208	Attempts to automate the merging process have not been particularly successful (Knight and Luk 1994; Hovy 1998; Noy and Musen 1999)." ></td>
	<td class="line x" title="45:208	The principal problems of partial and unbalanced coverage and of inconsistencies between ontologies continue to hamper these approaches." ></td>
	<td class="line x" title="46:208	3 Resources The framework we present in Section 4 propagates any type of lexical feature up an ontology." ></td>
	<td class="line x" title="47:208	In previous work, lexicals have often been represented by proximity and syntactic features." ></td>
	<td class="line x" title="48:208	Consider the following sentence: The tsunami left a trail of horror." ></td>
	<td class="line x" title="49:208	In a proximity approach, a word is represented by a window of words surrounding it." ></td>
	<td class="line x" title="50:208	For the above sentence, a window of size 1 would yield two features (-1:the and +1:left) for the word tsunami." ></td>
	<td class="line x" title="51:208	In a syntactic approach, more linguistically rich features are extracted by using each grammatical relation in which a word is involved (e.g. the features for tsunami are determiner:the and subject-of:leave)." ></td>
	<td class="line x" title="52:208	For the purposes of this work, we consider the propagation of syntactic features." ></td>
	<td class="line x" title="53:208	We used Minipar (Lin 1994), a broad coverage parser, to analyze text." ></td>
	<td class="line x" title="54:208	We collected the statistics on the grammatical relations (contexts) output by Minipar and used these as the feature vectors." ></td>
	<td class="line x" title="55:208	Following Lin (1998), we measure each feature f for a word e not by its frequency but by its pointwise mutual information, mi ef : 126 ( ) () ()fPeP feP mi ef  =, log 4 Inducing ontological features The resource described in the previous section yields lexical feature vectors for each word in a corpus." ></td>
	<td class="line x" title="56:208	We term these vectors lexical because they are collected by looking only at the lexicals in the text (i.e. no sense information is used)." ></td>
	<td class="line x" title="57:208	We use the term ontological feature vector to refer to a feature vector whose features are for a particular sense of the word." ></td>
	<td class="line x" title="58:208	In this section, we describe our framework for inducing ontological feature vectors for each node of an ontology." ></td>
	<td class="line x" title="59:208	Our approach employs two phases." ></td>
	<td class="line x" title="60:208	A divide-and-conquer algorithm first propagates syntactic features to each node in the ontology." ></td>
	<td class="line x" title="61:208	A final sweep over the ontology, which we call the Coup phase, disambiguates the feature vectors of lexicals (leaf nodes) in the ontology." ></td>
	<td class="line x" title="62:208	4.1 Divide-and-conquer phase In the first phase of the algorithm, we propagate features up the ontology in a bottom-up approach." ></td>
	<td class="line x" title="63:208	Figure 1 gives an overview of this phase." ></td>
	<td class="line x" title="64:208	The termination condition of the recursion is met when the algorithm processes a leaf node." ></td>
	<td class="line x" title="65:208	The feature vector that is assigned to this node is an exact copy of the lexical feature vector for that leaf (obtained from a large corpus as described in Section 3)." ></td>
	<td class="line x" title="66:208	For example, for the two leaf nodes labeled chair in Figure 2, we assign to both the same ambiguous lexical feature vector, an excerpt of which is shown in Figure 3." ></td>
	<td class="line x" title="67:208	When the recursion meets a non-leaf node, like chairwoman in Figure 2, the algorithm first recursively applies itself to each of the nodes children." ></td>
	<td class="line x" title="68:208	Then, the algorithm selects those features common to its children to propagate up to its own ontological feature vector." ></td>
	<td class="line x" title="69:208	The assumption here is that features of other senses of polysemous words will not be propagated since they will not be common across the children." ></td>
	<td class="line x" title="70:208	Below, we describe the two methods we used to propagate features: Shared and Committee." ></td>
	<td class="line x" title="71:208	Shared propagation algorithm The first technique for propagating features to a concept node n from its children C is the simplest and scored best in our evaluation (see Section 5.2)." ></td>
	<td class="line x" title="72:208	The goal is that the feature vector for n Input: A node n and a corpus C. Step 1: Termination Condition: If n is a leaf node then assign to n its lexical feature vector as described in Section 3." ></td>
	<td class="line x" title="73:208	Step 2: Recursion Step: For each child c of n, reecurse on c and C. Assign a feature vector to n by propagating features from its children." ></td>
	<td class="line x" title="74:208	Output: A feature vector assigned to each node of the tree rooted by n. Figure 1." ></td>
	<td class="line x" title="75:208	Divide-and-conquer phase." ></td>
	<td class="line x" title="76:208	chair stool armchair chaiselongue taboret music stool step stool cutty stool desk chair chair seating furniture furniture furniture bedmirror table concept leaf node Legend: chair chairman president chairwoman vice chairman vice chairman chairwoman leader Decomposable object Figure 2." ></td>
	<td class="line x" title="77:208	Subtrees of WordNet illustrating two senses of chair." ></td>
	<td class="line x" title="78:208	'chair' conjunction: sofa 77 11.8 professor 11 6.0 dining room 2 5.6 cushion 1 4.5 council member 1 4.4 President 9 2.9 foreign minister 1 2.8 nominal subject Ottoman 8 12.1 director 22 9.1 speaker 8 8.6 Joyner 2 8.22 recliner 2 7.7 candidate 1 3.5 Figure 3." ></td>
	<td class="line x" title="79:208	Excerpt of a lexical feature vector for the word chair." ></td>
	<td class="line x" title="80:208	Grammatical relations are in italics (conjunction and nominal-subject)." ></td>
	<td class="line x" title="81:208	The first column of numbers are frequency counts and the other are mutual information scores." ></td>
	<td class="line x" title="82:208	In bold are the features that intersect with the induced ontological feature vector for the parent concept of chairs chairwoman sense." ></td>
	<td class="line x" title="83:208	127 represents the general grammatical behavior that its children will have." ></td>
	<td class="line x" title="84:208	For example, for the concept node furniture in Figure 2, we would like to assign features like object-of:clean since mosttypes of furniture can be cleaned." ></td>
	<td class="line x" title="85:208	However, even though you can eat on a table, we do not want the feature on:eat for the furniture concept since we do not eat on mirrors or beds." ></td>
	<td class="line x" title="86:208	In the Shared propagation algorithm, we propagate only those features that are shared by at least t children." ></td>
	<td class="line x" title="87:208	In our experiments, we experimentally set t = min(3, |C|)." ></td>
	<td class="line x" title="88:208	The frequency of a propagated feature is obtained by taking a weighted sum of the frequency of the feature across its children." ></td>
	<td class="line x" title="89:208	Let f i be the frequency of the feature for child i, let c i be the total frequency of child i, and let N be the total frequency of all children." ></td>
	<td class="line x" title="90:208	Then, the frequency f of the propagated feature is given by:  = i i i N c ff (1) Committee propagation algorithm The second propagation algorithm finds a set of representative children from which to propagate features." ></td>
	<td class="line x" title="91:208	Pantel and Lin (2002) describe an algorithm, called Clustering By Committee (CBC), which discovers clusters of words according to their meanings in test." ></td>
	<td class="line x" title="92:208	The key to CBC is finding for each class a set of representative elements, called a committee, which most unambiguously describe the members of the class." ></td>
	<td class="line x" title="93:208	For example, for the color concept, CBC discovers the following committee members: purple, pink, yellow, mauve, turquoise, beige, fuchsia Words like orange and violet are avoided because they are polysemous." ></td>
	<td class="line x" title="94:208	For a given concept c, we build a committee by clustering its children according to their similarity and then keep the largest and most interconnected cluster (see Pantel and Lin (2002) for details)." ></td>
	<td class="line x" title="95:208	The propagated features are then those that are shared by at least two committee members." ></td>
	<td class="line x" title="96:208	The frequency of a propagated feature is obtained using Eq." ></td>
	<td class="line x" title="97:208	1 where the children i are chosen only among the committee members." ></td>
	<td class="line x" title="98:208	Generating committees using CBC works best for classes with many members." ></td>
	<td class="line x" title="99:208	In its original application (Pantel and Lin 2002), CBC discovered a flat list of coarse concepts." ></td>
	<td class="line x" title="100:208	In the finer grained concept hierarchy of WordNet, there are many fewer children for each concept so we expect to have more difficulty finding committees." ></td>
	<td class="line x" title="101:208	4.2 Coup phase At the end of the Divide-and-conquer phase, the non-leaf nodes of the ontology contain disambiguated features 1." ></td>
	<td class="line x" title="102:208	By design of the propagation algorithm, each concept node feature is shared by at least two of its children." ></td>
	<td class="line x" title="103:208	We assume that two polysemous words, w 1 and w 2, that are similar in one sense will be dissimilar in its other senses." ></td>
	<td class="line x" title="104:208	Under the distributional hypothesis, similar words occur in the same grammatical contexts and dissimilar words occur in different grammatical contexts." ></td>
	<td class="line x" title="105:208	We expect then that most features that are shared between w 1 and w 2 will be the grammatical contexts of their similar sense." ></td>
	<td class="line x" title="106:208	Hence, mostly disambiguated features are propagated up the ontology in the Divide-and-conquer phase." ></td>
	<td class="line x" title="107:208	However, the feature vectors for the leaf nodes remain ambiguous (e.g. the feature vectors for both leaf nodes labeled chair in Figure 2 are identical)." ></td>
	<td class="line x" title="108:208	In this phase of the algorithm, leaf node feature vectors are disambiguated by looking at the parents of their other senses." ></td>
	<td class="line x" title="109:208	Leaf nodes that are unambiguous in the ontology will have unambiguous feature vectors." ></td>
	<td class="line x" title="110:208	For ambiguous leaf nodes (i.e. leaf nodes that have more than one concept parent), we apply the algorithm described in Figure 4." ></td>
	<td class="line x" title="111:208	Given a polysemous leaf node n, we remove from its ambiguous 1 By disambiguated features, we mean that the features are co-occurrences with a particular sense of a word; the features themselves are not sense-tagged." ></td>
	<td class="line x" title="112:208	Input: A node n and the enriched ontology O output from the algorithm in Figure 1." ></td>
	<td class="line x" title="113:208	Step 1: If n is not a leaf node then return." ></td>
	<td class="line x" title="114:208	Step 2: Remove from ns feature vector all features that intersect with the feature vector of any of ns other senses parent concepts, but are not in ns parent concept feature vector." ></td>
	<td class="line x" title="115:208	Output: A disambiguated feature vector for each leaf node n. Figure 4." ></td>
	<td class="line x" title="116:208	Coup phase." ></td>
	<td class="line x" title="117:208	128 feature vector those features that intersect with the ontological feature vector of any of its other senses parent concept but that are not in its own parents ontological feature vector." ></td>
	<td class="line x" title="118:208	For example, consider the furniture sense of the leaf node chair in Figure 2." ></td>
	<td class="line x" title="119:208	After the Divide-and-conquer phase, the node chair is assigned the ambiguous lexical feature vector shown in Figure 3." ></td>
	<td class="line x" title="120:208	Suppose that chair only has one other sense in WordNet, which is the chairwoman sense illustrated in Figure 2." ></td>
	<td class="line x" title="121:208	The features in bold in Figure 3 represent those features of chair that intersect with the ontological feature vector of chairwoman." ></td>
	<td class="line x" title="122:208	In the Coup phase of our system, we remove these bold features from the furniture sense leaf node chair." ></td>
	<td class="line x" title="123:208	What remains are features like chair and sofa, chair and cushion, Ottoman is a chair, and recliner is a chair." ></td>
	<td class="line x" title="124:208	Similarly, for the chairwoman sense of chair, we remove those features that intersect with the ontological feature vector of the chair concept (the parent of the other chair leaf node)." ></td>
	<td class="line x" title="125:208	As shown in the beginning of this section, concept node feature vectors are mostly unambiguous after the Divide-and-conquer phase." ></td>
	<td class="line x" title="126:208	However, the Divide-and-conquer phase may be repeated after the Coup phase using a different termination condition." ></td>
	<td class="line x" title="127:208	Instead of assigning to leaf nodes ambiguous lexical feature vectors, we use the leaf node feature vectors from the Coup phase." ></td>
	<td class="line x" title="128:208	In our experiments, we did not see any significant performance difference by skipping this extra Divide-and-conquer step." ></td>
	<td class="line x" title="129:208	5 Experimental results In this section, we provide a quantitative and qualitative evaluation of our framework." ></td>
	<td class="line x" title="130:208	5.1 Experimental Setup We used Minipar (Lin 1994), a broad coverage parser, to parse two 3GB corpora (TREC-9 and TREC-2002)." ></td>
	<td class="line x" title="131:208	We collected the frequency counts of the grammatical relations (contexts) output by Minipar and used these to construct the lexical feature vectors as described in Section 3." ></td>
	<td class="line x" title="132:208	WordNet 2.0 served as our testing ontology." ></td>
	<td class="line x" title="133:208	Using the algorithm presented in Section 4, we induced ontological feature vectors for the noun nodes in WordNet using the lexical co-occurrence features from the TREC-2002 corpus." ></td>
	<td class="line x" title="134:208	Due to memory limitations, we were only able to propagate features to one quarter of the ontology." ></td>
	<td class="line x" title="135:208	We experimented with both the Shared and Committee propagation models described in Section 4.1." ></td>
	<td class="line x" title="136:208	5.2 Quantitative evaluation To evaluate the resulting ontological feature vectors, we considered the task of attaching new nodes into the ontology." ></td>
	<td class="line x" title="137:208	To automatically evaluate this, we randomly extracted a set of 1000 noun leaf nodes from the ontology and accumulated lexical feature vectors for them using the TREC-9 corpus (a separate corpus than the one used to propagate features, but of the same genre)." ></td>
	<td class="line x" title="138:208	We experimented with two test sets:  Full: The 424 of the 1000 random nodes that existed in the TREC-9 corpus  Subset: Subset of Full where only nodes that do not have concept siblings are kept (380 nodes)." ></td>
	<td class="line x" title="139:208	For each random node, we computed the similarity of the node with each concept node in the ontology by computing the cosine of the angle (Salton and McGill 1983) between the lexical feature vector of the random node e i and the ontological feature vector of the concept nodes e j : ()     = f fe f fe f fefe ji ji ji mimi mimi eesim 22, We only kept those similar nodes that had a similarity above a threshold  . We experimentally set  = 0.1." ></td>
	<td class="line x" title="140:208	Top-K accuracy We collected the top-K most similar concept nodes (attachment points) for each node in the test sets and computed the accuracy of finding a correct attachment point in the top-K list." ></td>
	<td class="line x" title="141:208	Table 1 shows the result." ></td>
	<td class="line x" title="142:208	We expected the algorithm to perform better on the Subset data set since only concepts that have exclusively lexical children must be considered for attachment." ></td>
	<td class="line x" title="143:208	In the Full data set, the algorithm must consider each concept in the ontology as a potential attachment point." ></td>
	<td class="line x" title="144:208	However, considering the top-5 best attachments, the algorithm performed equally well on both data sets." ></td>
	<td class="line x" title="145:208	The Shared propagation algorithm performed consistently slightly better than the Committee method." ></td>
	<td class="line x" title="146:208	As described in Section 4.1, building a 129 committee performs best for concepts with many children." ></td>
	<td class="line x" title="147:208	Since many nodes in WordNet have few direct children, the Shared propagation method is more appropriate." ></td>
	<td class="line x" title="148:208	One possible extension of the Committee propagation algorithm is to find committee members from the full list of descendants of a node rather than only its immediate children." ></td>
	<td class="line x" title="149:208	Precision and Recall We computed the precision and recall of our system on varying numbers of returned attachments." ></td>
	<td class="line x" title="150:208	Figure 5 and Figure 6 show the attachment precision and recall of our system when the maximum number of returned attachments ranges between 1 and 5." ></td>
	<td class="line x" title="151:208	In Figure 5, we see that the Shared propagation method has better precision than the Committee method." ></td>
	<td class="line x" title="152:208	Both methods perform similarly on recall." ></td>
	<td class="line x" title="153:208	The recall of the system increases most dramatically when returning two attachments without too much of a hit on precision." ></td>
	<td class="line x" title="154:208	The low recall when returning only one attachment is due to both system errors and also to the fact that many nodes in the hierarchy are polysemous." ></td>
	<td class="line x" title="155:208	In the next section, we discuss further experiments on polysemous nodes." ></td>
	<td class="line x" title="156:208	Figure 6 illustrates the large difference on both precision and recall when using the simpler Subset data set." ></td>
	<td class="line x" title="157:208	All 95% confidence bounds in Figure 5 and Figure 6 range between 2.8% and 5.3%." ></td>
	<td class="line x" title="158:208	Polysemous nodes 84 of the nodes in the Full data set are polysemous (they are attached to more than one concept node in the ontology)." ></td>
	<td class="line x" title="159:208	On average, these nodes have 2.6 senses for a total of 219 senses." ></td>
	<td class="line x" title="160:208	Figure 7 compares the precision and recall of the system on all nodes in the Full data set vs. the 84 polysemous nodes." ></td>
	<td class="line x" title="161:208	The 95% confidence intervals range between 3.8% and 5.0% for the Full data set and between 1.2% and 9.4% for the polysemous nodes." ></td>
	<td class="line x" title="162:208	The precision on the polysemous nodes is consistently better since these have more possible correct attachments." ></td>
	<td class="line x" title="163:208	Clearly, when the system returns at most one or two attachments, the recall on the polysemous nodes is lower than on the Full set." ></td>
	<td class="line x" title="164:208	However, it is interesting to note that recall on the polysemous nodes equals the recall on the Full set after K=3." ></td>
	<td class="line x" title="165:208	Table 1." ></td>
	<td class="line x" title="166:208	Correct attachment point in the top-K attachments (with 95% conf)." ></td>
	<td class="line x" title="167:208	K Shared (Full) Committee (Full) Shared (Subset) Committee (Subset) 1 73.9%  4.5% 72.0%  4.9% 77.4%  3.6% 76.1%  5.1% 2 78.7%  4.1% 76.6%  4.2% 80.7%  4.0% 79.1%  4.5% 3 79.9%  4.0% 78.2%  4.2% 81.2%  3.9% 80.5%  4.8% 4 80.6%  4.1% 79.0%  4.0% 81.5%  4.1% 80.8%  5.0% 5 81.3%  3.8% 79.5%  3.9% 81.7%  4.1% 81.3%  4.9% Figure 5." ></td>
	<td class="line x" title="168:208	Attachment precision and recall for the Shared and Committee propagation methods when returning at most K attachments (on the Full set)." ></td>
	<td class="line x" title="169:208	Precision and Recall (Shared and Committee) vs. Number of Returned Attachments 0.5 0.6 0.7 0.8 0.9 1 12345 K Precision (Shared) Recall (Shared) Precision (Committee) Recall (Committee) Precision and Recall (Full and Subset) vs. Number of Returned Attachments 0.5 0.6 0.7 0.8 0.9 1 12345 K Precision (Full) Recall (Full) Precision (Subset) Recall (Subset) Figure 6." ></td>
	<td class="line x" title="170:208	Attachment precision and recall for the Full and Subset data sets when returning at most K attachments (using the Shared propagation method)." ></td>
	<td class="line x" title="171:208	130 5.3 Qualitative evaluation Inspection of errors revealed that the system often makes plausible attachments." ></td>
	<td class="line x" title="172:208	Table 2 shows some example errors generated by our system." ></td>
	<td class="line x" title="173:208	For the word arsenic, the system attached it to the concept trioxide, which is the parent of the correct attachment." ></td>
	<td class="line x" title="174:208	The system results may be useful to help validate the ontology." ></td>
	<td class="line x" title="175:208	For example, for the word law, the system attached it to the regulation (as an organic process) and ordinance (legislative act) concepts." ></td>
	<td class="line x" title="176:208	According to WordNet, law has seven possible attachment points, none of which are a legislative act." ></td>
	<td class="line x" title="177:208	Hence, the system has found that in the TREC-9 corpus, the word law has a sense of legislative act." ></td>
	<td class="line x" title="178:208	Similarly, the system discovered the symptom sense of vomiting." ></td>
	<td class="line x" title="179:208	The system discovered a potential anomaly in WordNet with the word slob." ></td>
	<td class="line x" title="180:208	The system classified slob as follows: fool  simpleton  someone whereas WordNet classifies it as: vulgarian  unpleasant person  unwelcome person  someone The ontology could use this output to verify if fool should link in the unpleasant person subtree." ></td>
	<td class="line x" title="181:208	Capitalization is not very trustworthy in large collections of text." ></td>
	<td class="line x" title="182:208	One of our design decisions was to ignore the case of words in our corpus, which in turn caused some errors since WordNet is case sensitive." ></td>
	<td class="line x" title="183:208	For example, the lexical node Munch (Norwegian artist) was attached to the munch concept (food) by error because our system accumulated all features of the word Munch in text regardless of its capitalization." ></td>
	<td class="line x" title="184:208	6 Discussion One question that remains unanswered is how clean an ontology must be in order for our methodology to work." ></td>
	<td class="line x" title="185:208	Since the structure of the ontology guides the propagation of features, a very noisy ontology will result in noisy feature vectors." ></td>
	<td class="line x" title="186:208	However, the framework is tolerant to some amount of noise and can in fact be used to correct some errors (as shown in Section 5.3)." ></td>
	<td class="line x" title="187:208	We showed in Section 1 how our framework can be used to disambiguate lexical-semantic resources like hyponym lists, verb relations, and unknown words or terms." ></td>
	<td class="line x" title="188:208	Other avenues of future work include: Adapting/extending existing ontologies It takes a large amount of time to build resources like WordNet." ></td>
	<td class="line x" title="189:208	However, adapting existing resources to a new corpus might be possible using our framework." ></td>
	<td class="line x" title="190:208	Once we have enriched the ontology with features from a corpus, we can rearrange the ontological structure according to the inter-conceptual similarity of nodes." ></td>
	<td class="line x" title="191:208	For example, consider the word computer in WordNet, which has two senses: a) a machine; and b) a person who calculates." ></td>
	<td class="line x" title="192:208	In a computer science corpus, sense b) occurs very infrequently and possibly a new sense of computer (e.g. a processing chip) occurs." ></td>
	<td class="line x" title="193:208	A system could potentially remove sense b) since the similarity of the other children of b) and computer is very low." ></td>
	<td class="line x" title="194:208	It could also uncover the new processing chip sense by finding a high similarity between computer and the processing chip concept." ></td>
	<td class="line x" title="195:208	Validating ontologies This is a holy grail problem in the knowledge representation community." ></td>
	<td class="line x" title="196:208	As a small step, our framework can be used to flag potential anomalies to the knowledge engineer." ></td>
	<td class="line x" title="197:208	What makes a chair different from a recliner?" ></td>
	<td class="line x" title="198:208	Given an enriched ontology, we can remove from the feature vectors of chair and recliner those features that occur in their parent furniture concept." ></td>
	<td class="line x" title="199:208	The features that remain describe their different syntactic behaviors in text." ></td>
	<td class="line x" title="200:208	Figure 7." ></td>
	<td class="line x" title="201:208	Attachment precision and recall on the Full set vs. the polysemous nodes in the Full set when the system returns at most K attachments." ></td>
	<td class="line x" title="202:208	Precision and Recall (All vs. Polysemous Nodes) 0.4 0.5 0.6 0.7 0.8 0.9 1 12345 K Precision (All) Recall (All) Precision (Polysemous) Recall (Polysemous) 131 7 Conclusions We presented a framework for inducing ontological feature vectors from lexical co-occurrence vectors." ></td>
	<td class="line x" title="203:208	Our method does not require the disambiguation of text." ></td>
	<td class="line x" title="204:208	Instead, it relies on the principle of distributional similarity and the fact that polysemous words that are similar in one sense tend to be dissimilar in their other senses." ></td>
	<td class="line x" title="205:208	On the task of attaching new words to WordNet using our framework, our experiments showed that the first attachment has 73.9% accuracy and that a correct attachment is in the top-5 attachments with 81.3% accuracy." ></td>
	<td class="line x" title="206:208	We believe this work to be useful for a variety of applications." ></td>
	<td class="line x" title="207:208	Not only can sense selection tasks such as word sense disambiguation, parsing, and semantic analysis benefit from our framework, but more inference-oriented tasks such as question answering and text summarization as well." ></td>
	<td class="line x" title="208:208	We hope that this work will assist with the development of other large-scale and internally consistent collections of semantic information." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P05-1077
Randomized Algorithms And NLP: Using Locality Sensitive Hash Functions For High Speed Noun Clustering
Ravichandran, Deepak;Pantel, Patrick;Hovy, Eduard H.;"></td>
	<td class="line x" title="1:231	Proceedings of the 43rd Annual Meeting of the ACL, pages 622629, Ann Arbor, June 2005." ></td>
	<td class="line x" title="2:231	c2005 Association for Computational Linguistics Randomized Algorithms and NLP: Using Locality Sensitive Hash Function for High Speed Noun Clustering Deepak Ravichandran, Patrick Pantel, and Eduard Hovy Information Sciences Institute University of Southern California 4676 Admiralty Way Marina del Rey, CA 90292." ></td>
	<td class="line x" title="3:231	{ravichan, pantel, hovy}@ISI.EDU Abstract In this paper, we explore the power of randomized algorithm to address the challenge of working with very large amounts of data." ></td>
	<td class="line x" title="4:231	We apply these algorithms to generate noun similarity lists from 70 million pages." ></td>
	<td class="line x" title="5:231	We reduce the running time from quadratic to practically linear in the number of elements to be computed." ></td>
	<td class="line x" title="6:231	1 Introduction In the last decade, the field of Natural Language Processing (NLP), has seen a surge in the use of corpus motivated techniques." ></td>
	<td class="line x" title="7:231	Several NLP systems are modeled based on empirical data and have had varying degrees of success." ></td>
	<td class="line x" title="8:231	Of late, however, corpusbased techniques seem to have reached a plateau in performance." ></td>
	<td class="line x" title="9:231	Three possible areas for future research investigation to overcoming this plateau include: 1." ></td>
	<td class="line x" title="10:231	Working with large amounts of data (Banko and Brill, 2001) 2." ></td>
	<td class="line x" title="11:231	Improving semi-supervised and unsupervised algorithms." ></td>
	<td class="line x" title="12:231	3." ></td>
	<td class="line x" title="13:231	Using more sophisticated feature functions." ></td>
	<td class="line x" title="14:231	The above listing may not be exhaustive, but it is probably not a bad bet to work in one of the above directions." ></td>
	<td class="line x" title="15:231	In this paper, we investigate the first two avenues." ></td>
	<td class="line x" title="16:231	Handling terabytes of data requires more efficient algorithms than are currently used in NLP." ></td>
	<td class="line x" title="17:231	We propose a web scalable solution to clustering nouns, which employs randomized algorithms." ></td>
	<td class="line x" title="18:231	In doing so, we are going to explore the literature and techniques of randomized algorithms." ></td>
	<td class="line x" title="19:231	All clustering algorithms make use of some distance similarity (e.g. , cosine similarity) to measure pair wise distance between sets of vectors." ></td>
	<td class="line x" title="20:231	Assume that we are given n points to cluster with a maximum of k features." ></td>
	<td class="line x" title="21:231	Calculating the full similarity matrix would take time complexity n2k." ></td>
	<td class="line x" title="22:231	With large amounts of data, say n in the order of millions or even billions, having an n2k algorithm would be very infeasible." ></td>
	<td class="line x" title="23:231	To be scalable, we ideally want our algorithm to be proportional to nk." ></td>
	<td class="line x" title="24:231	Fortunately, we can borrow some ideas from the Math and Theoretical Computer Science community to tackle this problem." ></td>
	<td class="line x" title="25:231	The crux of our solution lies in defining Locality Sensitive Hash (LSH) functions." ></td>
	<td class="line x" title="26:231	LSH functions involve the creation of short signatures (fingerprints) for each vector in space such that those vectors that are closer to each other are more likely to have similar fingerprints." ></td>
	<td class="line x" title="27:231	LSH functions are generally based on randomized algorithms and are probabilistic." ></td>
	<td class="line x" title="28:231	We present LSH algorithms that can help reduce the time complexity of calculating our distance similarity atrix to nk." ></td>
	<td class="line x" title="29:231	Rabin (1981) proposed the use of hash functions from random irreducible polynomials to create short fingerprint representations for very large strings." ></td>
	<td class="line x" title="30:231	These hash function had the nice property that the fingerprint of two identical strings had the same fingerprints, while dissimilar strings had different fingerprints with a very small probability of collision." ></td>
	<td class="line x" title="31:231	Broder (1997) first introduced LSH." ></td>
	<td class="line x" title="32:231	He proposed the use of Min-wise independent functions to create fingerprints that preserved the Jaccard sim622 ilarity between every pair of vectors." ></td>
	<td class="line x" title="33:231	These techniques are used today, for example, to eliminate duplicate web pages." ></td>
	<td class="line x" title="34:231	Charikar (2002) proposed the use of random hyperplanes to generate an LSH function that preserves the cosine similarity between every pair of vectors." ></td>
	<td class="line x" title="35:231	Interestingly, cosine similarity is widely used in NLP for various applications such as clustering." ></td>
	<td class="line x" title="36:231	In this paper, we perform high speed similarity list creation for nouns collected from a huge web corpus." ></td>
	<td class="line x" title="37:231	We linearize this step by using the LSH proposed by Charikar (2002)." ></td>
	<td class="line x" title="38:231	This reduction in complexity of similarity computation makes it possible to address vastly larger datasets, at the cost, as shown in Section 5, of only little reduction in accuracy." ></td>
	<td class="line x" title="39:231	In our experiments, we generate a similarity list for each noun extracted from 70 million page web corpus." ></td>
	<td class="line x" title="40:231	Although the NLP community has begun experimenting with the web, we know of no work in published literature that has applied complex language analysis beyond IR and simple surface-level pattern matching." ></td>
	<td class="line x" title="41:231	2 Theory The core theory behind the implementation of fast cosine similarity calculation can be divided into two parts: 1." ></td>
	<td class="line x" title="42:231	Developing LSH functions to create signatures; 2." ></td>
	<td class="line x" title="43:231	Using fast search algorithm to find nearest neighbors." ></td>
	<td class="line x" title="44:231	We describe these two components in greater detail in the next subsections." ></td>
	<td class="line x" title="45:231	2.1 LSH Function Preserving Cosine Similarity We first begin with the formal definition of cosine similarity." ></td>
	<td class="line x" title="46:231	Definition: Let u and v be two vectors in a k dimensional hyperplane." ></td>
	<td class="line x" title="47:231	Cosine similarity is defined as the cosine of the angle between them: cos((u,v))." ></td>
	<td class="line x" title="48:231	We can calculate cos((u,v)) by the following formula: cos((u,v)) = |u.v||u||v| (1) Here (u,v) is the angle between the vectors u and v measured in radians." ></td>
	<td class="line x" title="49:231	|u.v| is the scalar (dot) product of u and v, and |u| and |v| represent the length of vectors u and v respectively." ></td>
	<td class="line x" title="50:231	The LSH function for cosine similarity as proposed by Charikar (2002) is given by the following theorem: Theorem: Suppose we are given a collection of vectors in a k dimensional vector space (as written as Rk)." ></td>
	<td class="line x" title="51:231	Choose a family of hash functions as follows: Generate a spherically symmetric random vector r of unit length from this k dimensional space." ></td>
	<td class="line x" title="52:231	We define a hash function, hr, as: hr(u) = braceleftbigg 1 : r.u  0 0 : r.u < 0 (2) Then for vectors u and v, Pr[hr(u) = hr(v)] = 1 (u,v)pi (3) Proof of the above theorem is given by Goemans and Williamson (1995)." ></td>
	<td class="line x" title="53:231	We rewrite the proof here for clarity." ></td>
	<td class="line x" title="54:231	The above theorem states that the probability that a random hyperplane separates two vectors is directly proportional to the angle between the two vectors (i,e. , (u,v))." ></td>
	<td class="line x" title="55:231	By symmetry, we have Pr[hr(u) negationslash= hr(v)] = 2Pr[u.r  0,v.r < 0]." ></td>
	<td class="line x" title="56:231	This corresponds to the intersection of two half spaces, the dihedral angle between which is ." ></td>
	<td class="line x" title="57:231	Thus, we have Pr[u.r  0,v.r < 0] = (u,v)/2pi." ></td>
	<td class="line x" title="58:231	Proceeding we have Pr[hr(u) negationslash= hr(v)] = (u,v)/pi and Pr[hr(u) = hr(v)] = 1  (u,v)/pi." ></td>
	<td class="line x" title="59:231	This completes the proof." ></td>
	<td class="line x" title="60:231	Hence from equation 3 we have, cos((u,v)) = cos((1Pr[hr(u) = hr(v)])pi) (4) This equation gives us an alternate method for finding cosine similarity." ></td>
	<td class="line x" title="61:231	Note that the above equation is probabilistic in nature." ></td>
	<td class="line x" title="62:231	Hence, we generate a large (d) number of random vectors to achieve the process." ></td>
	<td class="line x" title="63:231	Having calculated hr(u) with d random vectors for each of the vectors u, we apply equation 4 to find the cosine distance between two vectors." ></td>
	<td class="line x" title="64:231	As we generate more number of random vectors, we can estimate the cosine similarity between two vectors more accurately." ></td>
	<td class="line x" title="65:231	However, in practice, the number (d) of random vectors required is highly domain dependent, i.e., it depends on the value of the total number of vectors (n), features (k) and the way the vectors are distributed." ></td>
	<td class="line x" title="66:231	Using d random vectors, we 623 can represent each vector by a bit stream of length d. Carefully looking at equation 4, we can observe that Pr[hr(u) = hr(v)] = 1  (hamming distance)/d1." ></td>
	<td class="line x" title="67:231	Thus, the above theorem, converts the problem of finding cosine distance between two vectors to the problem of finding hamming distance between their bit streams (as given by equation 4)." ></td>
	<td class="line x" title="68:231	Finding hamming distance between two bit streams is faster and highly memory efficient." ></td>
	<td class="line x" title="69:231	Also worth noting is that this step could be considered as dimensionality reduction wherein we reduce a vector in k dimensions to that of d bits while still preserving the cosine distance between them." ></td>
	<td class="line x" title="70:231	2.2 Fast Search Algorithm To calculate the fast hamming distance, we use the search algorithm PLEB (Point Location in Equal Balls) first proposed by Indyk and Motwani (1998)." ></td>
	<td class="line x" title="71:231	This algorithm was further improved by Charikar (2002)." ></td>
	<td class="line x" title="72:231	This algorithm involves random permutations of the bit streams and their sorting to find the vector with the closest hamming distance." ></td>
	<td class="line x" title="73:231	The algorithm given in Charikar (2002) is described to find the nearest neighbor for a given vector." ></td>
	<td class="line x" title="74:231	We modify it so that we are able to find the top B closest neighbor for each vector." ></td>
	<td class="line x" title="75:231	We omit the math of this algorithm but we sketch its procedural details in the next section." ></td>
	<td class="line x" title="76:231	Interested readers are further encouraged to read Theorem 2 from Charikar (2002) and Section 3 from Indyk and Motwani (1998)." ></td>
	<td class="line x" title="77:231	3 Algorithmic Implementation In the previous section, we introduced the theory for calculation of fast cosine similarity." ></td>
	<td class="line x" title="78:231	We implement it as follows: 1." ></td>
	<td class="line x" title="79:231	Initially we are given n vectors in a huge k dimensional space." ></td>
	<td class="line x" title="80:231	Our goal is to find all pairs of vectors whose cosine similarity is greater than a particular threshold." ></td>
	<td class="line x" title="81:231	2." ></td>
	<td class="line x" title="82:231	Choose d number of (d << k) unit random vectors {r0,r1,,rd} each of k dimensions." ></td>
	<td class="line x" title="83:231	A k dimensional unit random vector, in general, is generated by independently sampling a 1Hamming distance is the number of bits which differ between two binary strings." ></td>
	<td class="line x" title="84:231	Gaussian function with mean 0 and variance 1, k number of times." ></td>
	<td class="line x" title="85:231	Each of the k samples is used to assign one dimension to the random vector." ></td>
	<td class="line x" title="86:231	We generate a random number from a Gaussian distribution by using Box-Muller transformation (Box and Muller, 1958)." ></td>
	<td class="line x" title="87:231	3." ></td>
	<td class="line x" title="88:231	For every vector u, we determine its signature by using the function hr(u) (as given by equation 4)." ></td>
	<td class="line x" title="89:231	We can represent the signature of vector u as: u = {hr1(u),hr2(u),,hrd(u)}." ></td>
	<td class="line x" title="90:231	Each vector is thus represented by a set of a bit streams of length d. Steps 2 and 3 takes O(nk) time (We can assume d to be a constant since d << k)." ></td>
	<td class="line x" title="91:231	4." ></td>
	<td class="line x" title="92:231	The previous step gives n vectors, each of them represented by d bits." ></td>
	<td class="line x" title="93:231	For calculation of fast hamming distance, we take the original bit index of all vectors and randomly permute them (see Appendix A for more details on random permutation functions)." ></td>
	<td class="line x" title="94:231	A random permutation can be considered as random jumbling of the bits of each vector2." ></td>
	<td class="line x" title="95:231	A random permutation function can be approximated by the following function: pi(x) = (ax + b)mod p (5) where, p is prime and 0 < a < p, 0  b < p, and a and b are chosen at random." ></td>
	<td class="line x" title="96:231	We apply q different random permutation for every vector (by choosing random values for a and b, q number of times)." ></td>
	<td class="line x" title="97:231	Thus for every vector we have q different bit permutations for the original bit stream." ></td>
	<td class="line x" title="98:231	5." ></td>
	<td class="line x" title="99:231	For each permutation function pi, we lexicographically sort the list of n vectors (whose bit streams are permuted by the function pi) to obtain a sorted list." ></td>
	<td class="line x" title="100:231	This step takes O(nlogn) time." ></td>
	<td class="line x" title="101:231	(We can assume q to be a constant)." ></td>
	<td class="line x" title="102:231	6." ></td>
	<td class="line x" title="103:231	For each sorted list (performed after applying the random permutation function pi), we calculate the hamming distance of every vector with 2The jumbling is performed by a mapping of the bit index as directed by the random permutation function." ></td>
	<td class="line x" title="104:231	For a given permutation, we reorder the bit indexes of all vectors in similar fashion." ></td>
	<td class="line x" title="105:231	This process could be considered as column reording of bit vectors." ></td>
	<td class="line x" title="106:231	624 B of its closest neighbors in the sorted list." ></td>
	<td class="line x" title="107:231	If the hamming distance is below a certain predetermined threshold, we output the pair of vectors with their cosine similarity (as calculated by equation 4)." ></td>
	<td class="line x" title="108:231	Thus, B is the beam parameter of the search." ></td>
	<td class="line x" title="109:231	This step takes O(n), since we can assume B,q,d to be a constant." ></td>
	<td class="line x" title="110:231	Why does the fast hamming distance algorithm work?" ></td>
	<td class="line x" title="111:231	The intuition is that the number of bit streams, d, for each vector is generally smaller than the number of vectors n (ie." ></td>
	<td class="line x" title="112:231	d << n)." ></td>
	<td class="line x" title="113:231	Thus, sorting the vectors lexicographically after jumbling the bits will likely bring vectors with lower hamming distance closer to each other in the sorted lists." ></td>
	<td class="line x" title="114:231	Overall, the algorithm takes O(nk+nlogn) time." ></td>
	<td class="line x" title="115:231	However, for noun clustering, we generally have the number of nouns, n, smaller than the number of features, k." ></td>
	<td class="line x" title="116:231	(i.e., n < k)." ></td>
	<td class="line x" title="117:231	This implies logn << k and nlogn << nk." ></td>
	<td class="line x" title="118:231	Hence the time complexity of our algorithm is O(nk + nlogn)  O(nk)." ></td>
	<td class="line x" title="119:231	This is a huge saving from the original O(n2k) algorithm." ></td>
	<td class="line x" title="120:231	In the next section, we proceed to apply this technique for generating noun similarity lists." ></td>
	<td class="line oc" title="121:231	4 Building Noun Similarity Lists A lot of work has been done in the NLP community on clustering words according to their meaning in text (Hindle, 1990; Lin, 1998)." ></td>
	<td class="line x" title="122:231	The basic intuition is that words that are similar to each other tend to occur in similar contexts, thus linking the semantics of words with their lexical usage in text." ></td>
	<td class="line x" title="123:231	One may ask why is clustering of words necessary in the first place?" ></td>
	<td class="line x" title="124:231	There may be several reasons for clustering, but generally it boils down to one basic reason: if the words that occur rarely in a corpus are found to be distributionally similar to more frequently occurring words, then one may be able to make better inferences on rare words." ></td>
	<td class="line x" title="125:231	However, to unleash the real power of clustering one has to work with large amounts of text." ></td>
	<td class="line x" title="126:231	The NLP community has started working on noun clustering on a few gigabytes of newspaper text." ></td>
	<td class="line x" title="127:231	But with the rapidly growing amount of raw text available on the web, one could improve clustering performance by carefully harnessing its power." ></td>
	<td class="line x" title="128:231	A core component of most clustering algorithms used in the NLP community is the creation of a similarity matrix." ></td>
	<td class="line x" title="129:231	These algorithms are of complexity O(n2k), where n is the number of unique nouns and k is the feature set length." ></td>
	<td class="line x" title="130:231	These algorithms are thus not readily scalable, and limit the size of corpus manageable in practice to a few gigabytes." ></td>
	<td class="line x" title="131:231	Clustering algorithms for words generally use the cosine distance for their similarity calculation (Salton and McGill, 1983)." ></td>
	<td class="line x" title="132:231	Hence instead of using the usual naive cosine distance calculation between every pair of words we can use the algorithm described in Section 3 to make noun clustering web scalable." ></td>
	<td class="line x" title="133:231	To test our algorithm we conduct similarity based experiments on 2 different types of corpus: 1." ></td>
	<td class="line x" title="134:231	Web Corpus (70 million web pages, 138GB), 2." ></td>
	<td class="line x" title="135:231	Newspaper Corpus (6 GB newspaper corpus) 4.1 Web Corpus We set up a spider to download roughly 70 million web pages from the Internet." ></td>
	<td class="line x" title="136:231	Initially, we use the links from Open Directory project3 as seed links for our spider." ></td>
	<td class="line x" title="137:231	Each webpage is stripped of HTML tags, tokenized, and sentence segmented." ></td>
	<td class="line x" title="138:231	Each document is language identified by the software TextCat4 which implements the paper by Cavnar and Trenkle (1994)." ></td>
	<td class="line x" title="139:231	We retain only English documents." ></td>
	<td class="line x" title="140:231	The web contains a lot of duplicate or near-duplicate documents." ></td>
	<td class="line x" title="141:231	Eliminating them is critical for obtaining better representation statistics from our collection." ></td>
	<td class="line x" title="142:231	The problem of identifying near duplicate documents in linear time is not trivial." ></td>
	<td class="line x" title="143:231	We eliminate duplicate and near duplicate documents by using the algorithm described by Kolcz et al.(2004)." ></td>
	<td class="line x" title="145:231	This process of duplicate elimination is carried out in linear time and involves the creation of signatures for each document." ></td>
	<td class="line x" title="146:231	Signatures are designed so that duplicate and near duplicate documents have the same signature." ></td>
	<td class="line x" title="147:231	This algorithm is remarkably fast and has high accuracy." ></td>
	<td class="line x" title="148:231	This entire process of removing non English documents and duplicate (and near-duplicate) documents reduces our document set from 70 million web pages to roughly 31 million web pages." ></td>
	<td class="line x" title="149:231	This represents roughly 138GB of uncompressed text." ></td>
	<td class="line x" title="150:231	We identify all the nouns in the corpus by using a noun phrase identifier." ></td>
	<td class="line x" title="151:231	For each noun phrase, we identify the context words surrounding it." ></td>
	<td class="line x" title="152:231	Our context window length is restricted to two words to 3http://www.dmoz.org/ 4http://odur.let.rug.nl/vannoord/TextCat/ 625 Table 1: Corpus description Corpus Newspaper Web Corpus Size 6GB 138GB Unique Nouns 65,547 655,495 Feature size 940,154 1,306,482 the left and right of each noun." ></td>
	<td class="line x" title="153:231	We use the context words as features of the noun vector." ></td>
	<td class="line x" title="154:231	4.2 Newspaper Corpus We parse a 6 GB newspaper (TREC9 and TREC2002 collection) corpus using the dependency parser Minipar (Lin, 1994)." ></td>
	<td class="line x" title="155:231	We identify all nouns." ></td>
	<td class="line x" title="156:231	For each noun we take the grammatical context of the noun as identified by Minipar5." ></td>
	<td class="line x" title="157:231	We do not use grammatical features in the web corpus since parsing is generally not easily web scalable." ></td>
	<td class="line x" title="158:231	This kind of feature set does not seem to affect our results." ></td>
	<td class="line x" title="159:231	Curran and Moens (2002) also report comparable results for Minipar features and simple word based proximity features." ></td>
	<td class="line x" title="160:231	Table 1 gives the characteristics of both corpora." ></td>
	<td class="line x" title="161:231	Since we use grammatical context, the feature set is considerably larger than the simple word based proximity feature set for the newspaper corpus." ></td>
	<td class="line x" title="162:231	4.3 Calculating Feature Vectors Having collected all nouns and their features, we now proceed to construct feature vectors (and values) for nouns from both corpora using mutual information (Church and Hanks, 1989)." ></td>
	<td class="line x" title="163:231	We first construct a frequency count vector C(e) = (ce1,ce2,,cek), where k is the total number of features and cef is the frequency count of feature f occurring in word e. Here, cef is the number of times word e occurred in context f. We then construct a mutual information vector MI(e) = (mie1,mie2,,miek) for each word e, where mief is the pointwise mutual information between word e and feature f, which is defined as: mief = log cef Nsummationtext n i=1 cif N  summationtextk j=1 cej N (6) where n is the number of words and N = 5We perform this operation so that we can compare the performance of our system to that of Pantel and Lin (2002)." ></td>
	<td class="line x" title="164:231	summationtextn i=1 summationtextm j=1 cij is the total frequency count of all features of all words." ></td>
	<td class="line x" title="165:231	Having thus obtained the feature representation of each noun we can apply the algorithm described in Section 3 to discover similarity lists." ></td>
	<td class="line x" title="166:231	We report results in the next section for both corpora." ></td>
	<td class="line x" title="167:231	5 Evaluation Evaluating clustering systems is generally considered to be quite difficult." ></td>
	<td class="line x" title="168:231	However, we are mainly concerned with evaluating the quality and speed of our high speed randomized algorithm." ></td>
	<td class="line x" title="169:231	The web corpus is used to show that our framework is webscalable, while the newspaper corpus is used to compare the output of our system with the similarity lists output by an existing system, which are calculated using the traditional formula as given in equation 1." ></td>
	<td class="line x" title="170:231	For this base comparison system we use the one built by Pantel and Lin (2002)." ></td>
	<td class="line x" title="171:231	We perform 3 kinds of evaluation: 1." ></td>
	<td class="line x" title="172:231	Performance of Locality Sensitive Hash Function; 2." ></td>
	<td class="line x" title="173:231	Performance of fast Hamming distance search algorithm; 3." ></td>
	<td class="line x" title="174:231	Quality of final similarity lists." ></td>
	<td class="line x" title="175:231	5.1 Evaluation of Locality sensitive Hash function To perform this evaluation, we randomly choose 100 nouns (vectors) from the web collection." ></td>
	<td class="line x" title="176:231	For each noun, we calculate the cosine distance using the traditional slow method (as given by equation 1), with all other nouns in the collection." ></td>
	<td class="line x" title="177:231	This process creates similarity lists for each of the 100 vectors." ></td>
	<td class="line x" title="178:231	These similarity lists are cut off at a threshold of 0.15." ></td>
	<td class="line x" title="179:231	These lists are considered to be the gold standard test set for our evaluation." ></td>
	<td class="line x" title="180:231	For the above 100 chosen vectors, we also calculate the cosine similarity using the randomized approach as given by equation 4 and calculate the mean squared error with the gold standard test set using the following formula: errorav = radicalBiggsummationdisplay i (CSreal,i CScalc,i)2/total (7) where CSreal,i and CScalc,i are the cosine similarity scores calculated using the traditional (equation 1) and randomized (equation 4) technique re626 Table 2: Error in cosine similarity Number of random vectors d Average error in cosine similarity Time (in hours) 1 1.0000 0.4 10 0.4432 0.5 100 0.1516 3 1000 0.0493 24 3000 0.0273 72 10000 0.0156 241 spectively." ></td>
	<td class="line x" title="181:231	i is the index over all pairs of elements that have CSreal,i >= 0.15 We calculate the error (errorav) for various values of d, the total number of unit random vectors r used in the process." ></td>
	<td class="line x" title="182:231	The results are reported in Table 26." ></td>
	<td class="line x" title="183:231	As we generate more random vectors, the error rate decreases." ></td>
	<td class="line x" title="184:231	For example, generating 10 random vectors gives us a cosine error of 0.4432 (which is a large number since cosine similarity ranges from 0 to 1)." ></td>
	<td class="line x" title="185:231	However, generation of more random vectors leads to reduction in error rate as seen by the values for 1000 (0.0493) and 10000 (0.0156)." ></td>
	<td class="line x" title="186:231	But as we generate more random vectors the time taken by the algorithm also increases." ></td>
	<td class="line x" title="187:231	We choose d = 3000 random vectors as our optimal (time-accuracy) cut off." ></td>
	<td class="line x" title="188:231	It is also very interesting to note that by using only 3000 bits for each of the 655,495 nouns, we are able to measure cosine similarity between every pair of them to within an average error margin of 0.027." ></td>
	<td class="line x" title="189:231	This algorithm is also highly memory efficient since we can represent every vector by only a few thousand bits." ></td>
	<td class="line x" title="190:231	Also the randomization process makes the the algorithm easily parallelizable since each processor can independently contribute a few bits for every vector." ></td>
	<td class="line x" title="191:231	5.2 Evaluation of Fast Hamming Distance Search Algorithm We initially obtain a list of bit streams for all the vectors (nouns) from our web corpus using the randomized algorithm described in Section 3 (Steps 1 to 3)." ></td>
	<td class="line x" title="192:231	The next step involves the calculation of hamming distance." ></td>
	<td class="line x" title="193:231	To evaluate the quality of this search algorithm we again randomly choose 100 vectors (nouns) from our collection." ></td>
	<td class="line x" title="194:231	For each of these 100 vectors we manually calculate the hamming distance 6The time is calculated for running the algorithm on a single Pentium IV processor with 4GB of memory with all other vectors in the collection." ></td>
	<td class="line x" title="195:231	We only retain those pairs of vectors whose cosine distance (as manually calculated) is above 0.15." ></td>
	<td class="line x" title="196:231	This similarity list is used as the gold standard test set for evaluating our fast hamming search." ></td>
	<td class="line x" title="197:231	We then apply the fast hamming distance search algorithm as described in Section 3." ></td>
	<td class="line x" title="198:231	In particular, it involves steps 3 to 6 of the algorithm." ></td>
	<td class="line x" title="199:231	We evaluate the hamming distance with respect to two criteria: 1." ></td>
	<td class="line x" title="200:231	Number of bit index random permutations functions q; 2." ></td>
	<td class="line x" title="201:231	Beam search parameter B. For each vector in the test collection, we take the top N elements from the gold standard similarity list and calculate how many of these elements are actually discovered by the fast hamming distance algorithm." ></td>
	<td class="line x" title="202:231	We report the results in Table 3 and Table 4 with beam parameters of (B = 25) and (B = 100) respectively." ></td>
	<td class="line x" title="203:231	For each beam, we experiment with various values for q, the number of random permutation function used." ></td>
	<td class="line x" title="204:231	In general, by increasing the value for beam B and number of random permutation q, the accuracy of the search algorithm increases." ></td>
	<td class="line x" title="205:231	For example in Table 4 by using a beam B = 100 and using 1000 random bit permutations, we are able to discover 72.8% of the elements of the Top 100 list." ></td>
	<td class="line x" title="206:231	However, increasing the values of q and B also increases search time." ></td>
	<td class="line x" title="207:231	With a beam (B) of 100 and the number of random permutations equal to 100 (i.e. , q = 1000) it takes 570 hours of processing time on a single Pentium IV machine, whereas with B = 25 and q = 1000, reduces processing time by more than 50% to 240 hours." ></td>
	<td class="line x" title="208:231	We could not calculate the total time taken to build noun similarity list using the traditional technique on the entire corpus." ></td>
	<td class="line x" title="209:231	However, we estimate that its time taken would be at least 50,000 hours (and perhaps even more) with a few of Terabytes of disk space needed." ></td>
	<td class="line x" title="210:231	This is a very rough estimate." ></td>
	<td class="line x" title="211:231	The experiment was infeasible." ></td>
	<td class="line x" title="212:231	This estimate assumes the widely used reverse indexing technique, where in one compares only those vector pairs that have at least one feature in common." ></td>
	<td class="line x" title="213:231	5.3 Quality of Final Similarity Lists For evaluating the quality of our final similarity lists, we use the system developed by Pantel and Lin (2002) as gold standard on a much smaller data set." ></td>
	<td class="line x" title="214:231	We use the same 6GB corpus that was used for train627 Table 3: Hamming search accuracy (Beam B = 25) Random permutations q Top 1 Top 5 Top 10 Top 25 Top 50 Top 100 25 6.1% 4.9% 4.2% 3.1% 2.4% 1.9% 50 6.1% 5.1% 4.3% 3.2% 2.5% 1.9% 100 11.3% 9.7% 8.2% 6.2% 5.7% 5.1% 500 44.3% 33.5% 30.4% 25.8% 23.0% 20.4% 1000 58.7% 50.6% 48.8% 45.0% 41.0% 37.2% Table 4: Hamming search accuracy (Beam B = 100) Random permutations q Top 1 Top 5 Top 10 Top 25 Top 50 Top 100 25 9.2% 9.5% 7.9% 6.4% 5.8% 4.7% 50 15.4% 17.7% 14.6% 12.0% 10.9% 9.0% 100 27.8% 27.2% 23.5% 19.4% 17.9% 16.3% 500 73.1% 67.0% 60.7% 55.2% 53.0% 50.5% 1000 87.6% 84.4% 82.1% 78.9% 75.8% 72.8% ing by Pantel and Lin (2002) so that the results are comparable." ></td>
	<td class="line x" title="215:231	We randomly choose 100 nouns and calculate the top N elements closest to each noun in the similarity lists using the randomized algorithm described in Section 3." ></td>
	<td class="line x" title="216:231	We then compare this output to the one provided by the system of Pantel and Lin (2002)." ></td>
	<td class="line x" title="217:231	For every noun in the top N list generated by our system we calculate the percentage overlap with the gold standard list." ></td>
	<td class="line x" title="218:231	Results are reported in Table 5." ></td>
	<td class="line x" title="219:231	The results shows that we are able to retrieve roughly 70% of the gold standard similarity list." ></td>
	<td class="line x" title="220:231	In Table 6, we list the top 10 most similar words for some nouns, as examples, from the web corpus." ></td>
	<td class="line x" title="221:231	6 Conclusion NLP researchers have just begun leveraging the vast amount of knowledge available on the web." ></td>
	<td class="line x" title="222:231	By searching IR engines for simple surface patterns, many applications ranging from word sense disambiguation, question answering, and mining semantic resources have already benefited." ></td>
	<td class="line x" title="223:231	However, most language analysis tools are too infeasible to run on the scale of the web." ></td>
	<td class="line x" title="224:231	A case in point is generating noun similarity lists using co-occurrence statistics, which has quadratic running time on the input size." ></td>
	<td class="line x" title="225:231	In this paper, we solve this problem by presenting a randomized algorithm that linearizes this task and limits memory requirements." ></td>
	<td class="line x" title="226:231	Experiments show that our method generates cosine similarities between pairs of nouns within a score of 0.03." ></td>
	<td class="line x" title="227:231	In many applications, researchers have shown that more data equals better performance (Banko and Brill, 2001; Curran and Moens, 2002)." ></td>
	<td class="line x" title="228:231	Moreover, at the web-scale, we are no longer limited to a snapshot in time, which allows broader knowledge to be learned and processed." ></td>
	<td class="line x" title="229:231	Randomized algorithms provide the necessary speed and memory requirements to tap into terascale text sources." ></td>
	<td class="line x" title="230:231	We hope that randomized algorithms will make other NLP tools feasible at the terascale and we believe that many algorithms will benefit from the vast coverage of our newly created noun similarity list." ></td>
	<td class="line x" title="231:231	Acknowledgement We wish to thank USC Center for High Performance Computing and Communications (HPCC) for helping us use their cluster computers." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W05-1504
Parsing With Soft And Hard Constraints On Dependency Length
Eisner, Jason M.;Smith, Noah A.;"></td>
	<td class="line x" title="1:345	Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 3041, Vancouver, October 2005." ></td>
	<td class="line x" title="2:345	c2005 Association for Computational Linguistics Parsing with Soft and Hard Constraints on Dependency Length Jason Eisner and Noah A. Smith Department of Computer Science / Center for Language and Speech Processing Johns Hopkins University, Baltimore, MD 21218 USA {jason,nasmith}@cs.jhu.edu Abstract In lexicalized phrase-structure or dependency parses, a words modifiers tend to fall near it in the string." ></td>
	<td class="line x" title="3:345	We show that a crude way to use dependency length as a parsing feature can substantially improve parsing speed and accuracy in English and Chinese, with more mixed results on German." ></td>
	<td class="line x" title="4:345	We then show similar improvements by imposing hard bounds on dependency length and (additionally) modeling the resulting sequence of parse fragments." ></td>
	<td class="line x" title="5:345	This simple vine grammar formalism has only finite-state power, but a context-free parameterization with some extra parameters for stringing fragments together." ></td>
	<td class="line x" title="6:345	We exhibit a linear-time chart parsing algorithm with a low grammar constant." ></td>
	<td class="line x" title="7:345	1 Introduction Many modern parsers identify the head word of each constituent they find." ></td>
	<td class="line x" title="8:345	This makes it possible to identify the word-to-word dependencies implicit in a parse.1 (Some parsers, known as dependency parsers, even return these dependencies as their primary output.)" ></td>
	<td class="line x" title="9:345	Why bother to identify these dependencies?" ></td>
	<td class="line x" title="10:345	The typical reason is to model the fact that some word pairs are more likely than others to engage in a dependency relationship.2 In this paper, we propose a different reason to identify dependencies in candidate parses: to evaluate not the dependencys word pair but its length (i.e. , the string distance between the two words)." ></td>
	<td class="line x" title="11:345	Dependency lengths differ from  This work was supported by NSF ITR grant IIS-0313193 to the first author and a fellowship from the Fannie and John Hertz Foundation to the second author." ></td>
	<td class="line x" title="12:345	The views expressed are not necessarily endorsed by the sponsors." ></td>
	<td class="line x" title="13:345	The authors thank Mark Johnson, Eugene Charniak, Charles Schafer, Keith Hall, and John Hale for helpful discussion and Elliott Drabek and Markus Dreyer for insights on (respectively) Chinese and German parsing." ></td>
	<td class="line x" title="14:345	They also thank an anonymous reviewer for suggesting the German experiments." ></td>
	<td class="line x" title="15:345	1In a phrase-structure parse, if phrase X headed by word token x is a subconstituent of phrase Y headed by word token y negationslash= x, then x is said to depend on y. In a more powerful compositional formalism like LTAG or CCG, dependencies can be extracted from the derivation tree." ></td>
	<td class="line x" title="16:345	2It has recently been questioned whether these bilexical features actually contribute much to parsing performance (Klein and Manning, 2003; Bikel, 2004), at least when one has only a million words of training." ></td>
	<td class="line x" title="17:345	typical parsing features in that they cannot be determined from tree-local information." ></td>
	<td class="line x" title="18:345	Though lengths are not usually considered, we will see that bilexical dynamic-programming parsing algorithms can easily consider them as they build the parse." ></td>
	<td class="line x" title="19:345	Soft constraints." ></td>
	<td class="line x" title="20:345	Like any other feature of trees, dependency lengths can be explicitly used as features in a probability model that chooses among trees." ></td>
	<td class="line x" title="21:345	Such a model will tend to disfavor long dependencies (at least of some kinds), as these are empirically rare." ></td>
	<td class="line x" title="22:345	In the first part of the paper, we show that such features improve a simple baseline dependency parser." ></td>
	<td class="line x" title="23:345	Hard constraints." ></td>
	<td class="line x" title="24:345	If the bias against long dependencies is strengthened into a hard constraint that absolutely prohibits long dependencies, then the parser turns into a partial parser with only finite-state power." ></td>
	<td class="line x" title="25:345	In the second part of the paper, we show how to perform chart parsing in asymptotic linear time with a low grammar constant." ></td>
	<td class="line x" title="26:345	Such a partial parser does less work than a full parser in practice, and in many cases recovers a more precise set of dependencies (with little loss in recall)." ></td>
	<td class="line x" title="27:345	2 Short Dependencies in Langugage We assume that correct parses exhibit a shortdependency preference: a words dependents tend to be close to it in the string.3 If the jth word of a sentence depends on the ith word, then|ij|tends to be 3 In this paper, we consider only a crude notion of closeness: the number of intervening words." ></td>
	<td class="line x" title="28:345	Other distance measures could be substituted or added (following the literature on heavy-shift and sentence comprehension), including the phonological, morphological, syntactic, or referential (given/new) complexity of the intervening material (Gibson, 1998)." ></td>
	<td class="line x" title="29:345	In parsing, the most relevant previous work is due to Collins (1997), who considered three binary features of the intervening material: did it contain (a) any word tokens at all, (b) any verbs, (c) any commas or colons?" ></td>
	<td class="line x" title="30:345	Note that (b) is effective because it measures the length of a dependency in terms of the number of alternative attachment sites that the dependent skipped over, a notion that could be generalized." ></td>
	<td class="line x" title="31:345	Similarly, McDonald et al.(2005) separately considered each of the intervening POS tags." ></td>
	<td class="line x" title="33:345	30 small." ></td>
	<td class="line x" title="34:345	This implies that neither i nor j is modified by complex phrases that fall between i and j. In terms of phrase structure, it implies that the phrases modifying word i from a given side tend to be (1) few in number, (2) ordered so that the longer phrases fall farther from i, and (3) internally structured so that the bulk of each phrase falls on the side of j away from i. These principles can be blamed for several linguistic phenomena." ></td>
	<td class="line x" title="35:345	(1) helps explain the late closure or attach low heuristic (e.g. , Frazier, 1979; Hobbs and Bear, 1990): a modifier such as a PP is more likely to attach to the closest appropriate head." ></td>
	<td class="line x" title="36:345	(2) helps account for heavy-shift: when an NP is long and complex, take NP out, put NP on the table, and give NP to Mary are likely to be rephrased as take out NP, put on the table NP, and give Mary NP." ></td>
	<td class="line x" title="37:345	(3) explains certain non-canonical word orders: in English, a nouns left modifier must become a right modifier if and only if it is right-heavy (a taller politician vs. a politician taller than all her rivals4), and a verbs left modifier may extrapose its rightheavy portion (An aardvark walked in who had circumnavigated the globe5)." ></td>
	<td class="line x" title="38:345	Why should sentences prefer short dependencies?" ></td>
	<td class="line x" title="39:345	Such sentences may be easier for humans to produce and comprehend." ></td>
	<td class="line x" title="40:345	Each word can quickly discharge its responsibilities, emitting or finding all its dependents soon after it is uttered or heard; then it can be dropped from working memory (Church, 1980; Gibson, 1998)." ></td>
	<td class="line x" title="41:345	Such sentences also succumb nicely to disambiguation heuristics that assume short dependencies, such as low attachment." ></td>
	<td class="line x" title="42:345	Thus, to improve comprehensibility, a speaker can make stylistic choices that shorten dependencies (e.g. , heavyshift), and a language can categorically prohibit some structures that lead to long dependencies (*a taller-than-all-her-rivals politician; *the sentence 4Whereas *a politician taller and *a taller-than-all-herrivals politician are not allowed." ></td>
	<td class="line x" title="43:345	The phenomenon is pervasive." ></td>
	<td class="line x" title="44:345	5This actually splits the heavy left dependent [an aardvark who] into two non-adjacent pieces, moving the heavy second piece." ></td>
	<td class="line x" title="45:345	By slightly stretching the aardvark-who dependency in this way, it greatly shortens aardvark-walked." ></td>
	<td class="line x" title="46:345	The same is possible for heavy, non-final right dependents: I met an aardvark yesterday who had circumnavigated the globe again stretches aardvark-who, which greatly shortens met-yesterday." ></td>
	<td class="line x" title="47:345	These examples illustrate (3) and (2) respectively." ></td>
	<td class="line x" title="48:345	However, the resulting non-contiguous constituents lead to non-projective parses that are beyond the scope of this paper." ></td>
	<td class="line x" title="49:345	that another sentence that had center-embedding was inside was incomprehensible)." ></td>
	<td class="line x" title="50:345	Such functionalist pressures are not all-powerful." ></td>
	<td class="line x" title="51:345	For example, many languages use SOV basic word order where SVO (or OVS) would give shorter dependencies." ></td>
	<td class="line x" title="52:345	However, where the data exhibit some short-dependency preference, computer parsers as well as human parsers can obtain speed and accuracy benefits by exploiting that fact." ></td>
	<td class="line x" title="53:345	3 Soft Constraints on Dependency Length We now enhance simple baseline probabilistic parsers for English, Chinese, and German so that they consider dependency lengths." ></td>
	<td class="line x" title="54:345	We confine ourselves (throughout the paper) to parsing part-ofspeech (POS) tag sequences." ></td>
	<td class="line x" title="55:345	This allows us to ignore data sparseness, out-of-vocabulary, smoothing, and pruning issues, but it means that our accuracy measures are not state-of-the-art." ></td>
	<td class="line x" title="56:345	Our techniques could be straightforwardly adapted to (bi)lexicalized parsers on actual word sequences, though not necessarily with the same success." ></td>
	<td class="line x" title="57:345	3.1 Grammar Formalism Throughout this paper we will use split bilexical grammars, or SBGs (Eisner, 2000), a notationally simpler variant of split head-automaton grammars, or SHAGs (Eisner and Satta, 1999)." ></td>
	<td class="line x" title="58:345	The formalism is context-free." ></td>
	<td class="line x" title="59:345	We define here a probabilistic version,6 which we use for the baseline models in our experiments." ></td>
	<td class="line x" title="60:345	They are only baselines because the SBG generative process does not take note of dependency length." ></td>
	<td class="line x" title="61:345	An SBG is an tuple G = (,$,L,R)." ></td>
	<td class="line x" title="62:345	 is an alphabet of words." ></td>
	<td class="line x" title="63:345	(In our experiments, we parse only POS tag sequences, so  is actually an alphabet of tags)." ></td>
	<td class="line x" title="64:345	$ negationslash  is a distinguished root symbol; let  = {$}." ></td>
	<td class="line x" title="65:345	L and R are functions from  to probabilistic epsilon1-free finite-state automata over ." ></td>
	<td class="line x" title="66:345	Thus, for each w , the SBG specifies left and right probabilistic FSAs, Lw and Rw." ></td>
	<td class="line x" title="67:345	We use Lw(G) :  [0,1] to denote the probabilistic context-free language of phrases headed by w. Lw(G) is defined by the following simple topdown stochastic process for sampling from it: 6There is a straightforward generalization to weighted SBGs, which need not have a stochastic generative model." ></td>
	<td class="line x" title="68:345	31 1." ></td>
	<td class="line x" title="69:345	Sample from the finite-state language L(Lw) a sequence  = w1w2 wlscript   of left children, and from L(Rw) a sequence  = w1w2 wr   of right children." ></td>
	<td class="line x" title="70:345	Each sequence is found by a random walk on its probabilistic FSA." ></td>
	<td class="line x" title="71:345	We say the children depend on w. 2." ></td>
	<td class="line x" title="72:345	For each i from lscript to r with i negationslash= 0, recursively sample i   from the context-free language Lwi(G)." ></td>
	<td class="line x" title="73:345	It is this step that indirectly determines dependency lengths." ></td>
	<td class="line x" title="74:345	3." ></td>
	<td class="line x" title="75:345	Return lscript 21w12 r  , a concatenation of strings." ></td>
	<td class="line x" title="76:345	Notice that ws left children  were generated in reverse order, so w1 and w1 are its closest children while wlscript and wr are the farthest." ></td>
	<td class="line x" title="77:345	Given an input sentence  = w1w2 wn , a parser attempts to recover the highest-probability derivation by which $ could have been generated from L$(G)." ></td>
	<td class="line x" title="78:345	Thus, $ plays the role of w0." ></td>
	<td class="line x" title="79:345	A sample derivation is shown in Fig." ></td>
	<td class="line x" title="80:345	1a." ></td>
	<td class="line x" title="81:345	Typically, L$ and R$ are defined so that $ must have no left children (lscript = 0) and at most one right child (r  1), the latter serving as the conventional root of the parse." ></td>
	<td class="line x" title="82:345	3.2 Baseline Models In the experiments reported here, we defined only very simple automata for Lw and Rw (w  )." ></td>
	<td class="line x" title="83:345	However, we tried three automaton types, of varying quality, so as to evaluate the benefit of adding length-sensitivity at three different levels of baseline performance." ></td>
	<td class="line x" title="84:345	In model A (the worst), each automaton has topology circlering a1a0a27, with a single state q1, so token ws left dependents are conditionally independent of one another given w. In model C (the best), each automaton circleringcirclering a1a0a27 has an extra state q0 that allows the first (closest) dependent to be chosen differently from the rest." ></td>
	<td class="line x" title="85:345	Model B is a compromise:7 it is like model A, but each type w   may have an elevated or reduced probability of having no dependents at all." ></td>
	<td class="line x" title="86:345	This is accomplished by using automata circleringcirclering a1a0a27 as in model C, which allows the stopping probabilities p(STOP | q0) and p(STOP |q1) to differ, but tying the conditional dis7It is equivalent to the dependency model with valence of Klein and Manning (2004)." ></td>
	<td class="line x" title="87:345	tributions p(q0 wq1 | q0,STOP) and p(q1 wq1 | q1,STOP)." ></td>
	<td class="line x" title="88:345	Finally, in3, L$ and R$ are restricted as above, so R$ gives a probability distribution over  only." ></td>
	<td class="line x" title="89:345	3.3 Length-Sensitive Models None of the baseline models AC explicitly model the distance between a head and child." ></td>
	<td class="line x" title="90:345	We enhanced them by multiplying in some extra length-sensitive factors when computing a trees probability." ></td>
	<td class="line x" title="91:345	For each dependency, an extra factor p(|) is multiplied in for the probability of the dependencys length  =|ij|, where i and j are the positions of the head and child in the surface string.8 Again we tried three variants." ></td>
	<td class="line x" title="92:345	In one version, this new probability p(|) is conditioned only on the direction d = sign(ij) of the dependency." ></td>
	<td class="line x" title="93:345	In another version, it is conditioned only on the POS tag h of the head." ></td>
	<td class="line x" title="94:345	In a third version, it is conditioned on d, h, and the POS tag c of the child." ></td>
	<td class="line x" title="95:345	3.4 Parsing Algorithm Fig." ></td>
	<td class="line x" title="96:345	2a gives a variant of Eisner and Sattas (1999) SHAG parsing algorithm, adapted to SBGs, which are easier to understand.9 (We will modify this algorithm later in 4)." ></td>
	<td class="line x" title="97:345	The algorithm obtains O(n3) runtime, despite the need to track the position of head words, by exploiting the conditional independence between a heads left children and right children." ></td>
	<td class="line x" title="98:345	It builds half-constituents denoted by a64a64 (a head word together with some modifying phrases on the right, i.e., w1 r) and a0a0 (a head word together with some modifying phrases on the left, i.e., lscript 1w)." ></td>
	<td class="line x" title="99:345	A new dependency is introduced when a64a64 + a0a0 are combined to get a72a72 or a8a8 (a pair of linked head words with all the intervening phrases, i.e., w1 rprimelscriptprime prime1wprime, where w is respectively the parent or child of wprime)." ></td>
	<td class="line x" title="100:345	One can then combine a72a72 + a64a64 = a64a64, or 8Since the  values are fully determined by the tree but every p( | )  1, this crude procedure simply reduces the probability mass of every legal tree." ></td>
	<td class="line x" title="101:345	The resulting model is deficient (does not sum to 1); the remaining probability mass goes to impossible trees whose putative dependency lengths  are inconsistent with the tree structure." ></td>
	<td class="line x" title="102:345	We intend in future work to explore non-deficient models (log-linear or generative), but even the present crude approach helps." ></td>
	<td class="line x" title="103:345	9The SHAG notation was designed to highlight the connection to non-split HAGs." ></td>
	<td class="line x" title="104:345	32 a0a0 + a8a8 = a0a0 . Only O(n3) combinations are possible in total when parsing a length-n sentence." ></td>
	<td class="line x" title="105:345	3.5 A Note on Word Senses [This section may be skipped by the casual reader.]" ></td>
	<td class="line x" title="106:345	A remark is necessary about :w and :wprime in Fig." ></td>
	<td class="line x" title="107:345	2a, which represent senses of the words at positions h and hprime." ></td>
	<td class="line x" title="108:345	Like past algorithms for SBGs (Eisner, 2000), Fig." ></td>
	<td class="line x" title="109:345	2a is designed to be a bit more general and integrate sense disambiguation into parsing." ></td>
	<td class="line x" title="110:345	It formally runs on an input  = W1 Wn  , where each Wi   is a confusion set over possible values of the ith word wi." ></td>
	<td class="line x" title="111:345	The algorithm recovers the highest-probability derivation that generates $ for some    (i.e. ,  = w1 wn with (i)wiWi)." ></td>
	<td class="line x" title="112:345	This extra level of generality is not needed for any of our experiments, but it is needed for SBG parsers to be as flexible as SHAG parsers." ></td>
	<td class="line x" title="113:345	We include it in this paper to broaden the applicability of both Fig." ></td>
	<td class="line x" title="114:345	2a and our extension of it in4." ></td>
	<td class="line x" title="115:345	The senses can be used in an SBG to pass a finite amount of information between the left and right children of a word, just as SHAGs allow.10 For example, to model the fronting of a direct object, an SBG might use a special sense of a verb, whose automata tend to generate both one more noun in  and one fewer noun in ." ></td>
	<td class="line x" title="116:345	Senses can also be used to pass information between parents and children." ></td>
	<td class="line x" title="117:345	Important uses are to encode lexical senses, or to enrich the dependency parse with constituent labels or depen10Fig." ></td>
	<td class="line x" title="118:345	2a enhances the Eisner-Satta version with explicit senses while matching its asymptotic performance." ></td>
	<td class="line x" title="119:345	On this point, see (Eisner and Satta, 1999, 8 and footnote 6)." ></td>
	<td class="line x" title="120:345	However, it does have a practical slowdown, in that START-LEFT nondeterministically guesses every possible sense of Wi, and these senses are pursued separately." ></td>
	<td class="line x" title="121:345	To match the Eisner-Satta algorithm, we should not need to commit to a words sense until we have seen all its left children." ></td>
	<td class="line x" title="122:345	That is, left triangles and left trapezoids should not carry a sense :w at all, except for the completed left triangle (marked F) that is produced by FINISHLEFT." ></td>
	<td class="line x" title="123:345	FINISH-LEFT should choose a sense w of Wh according to the final state q, which reflects knowledge of Whs left children." ></td>
	<td class="line x" title="124:345	For this strategy to work, the transitions in Lw (used by ATTACH-LEFT) must not depend on the particular sense w but only on W. In other words, all Lw : w  Wh are really copies of a shared LWh, except that they may have different final states." ></td>
	<td class="line x" title="125:345	This requirement involves no loss of generality, since the nondeterministic shared LWh is free to branch as soon as it likes onto paths that commit to the various senses w. dency labels (Eisner, 2000)." ></td>
	<td class="line x" title="126:345	For example, the input token Wi = {bank1/N/NP, bank2/N/NP, bank3/V/VP, bank3/V/S}   allows four senses of bank, namely two nominal meanings, and two syntactically different versions of the verbal meaning, whose automata require them to expand into VP and S phrases respectively." ></td>
	<td class="line x" title="127:345	The cubic runtime is proportional to the number of ways of instantiating the inference rules in Fig." ></td>
	<td class="line x" title="128:345	2a: O(n2(n + tprime)tg2), where n = || is the input length, g = maxni=1|Wi| bounds the size of a confusion set, t bounds the number of states per automaton, and tprime  t bounds the number of automaton transitions from a state that emit the same word." ></td>
	<td class="line x" title="129:345	For deterministic automata, tprime = 1.11 3.6 Probabilistic Parsing It is easy to make the algorithm of Fig." ></td>
	<td class="line x" title="130:345	2a lengthsensitive." ></td>
	<td class="line x" title="131:345	When a new dependency is added by an ATTACH rule that combines a64a64 + a0a0, the annotations on a64a64 and a0a0 suffice to determine the dependencys length  = |hhprime|, direction d = sign(hhprime), head word w, and child word wprime.12 So the additional cost of such a dependency, e.g. p( | d,w,wprime), can be included as the weight of an extra antecedent to the rule, and so included in the weight of the resulting a8a8 or a72a72 . To execute the inference rules in Fig." ></td>
	<td class="line x" title="132:345	2a, we use a prioritized agenda." ></td>
	<td class="line x" title="133:345	Derived items such as a64a64, a0a0, a8a8, and a72a72 are prioritized by their Viterbi-inside probabilities." ></td>
	<td class="line x" title="134:345	This is known as uniform-cost search or shortest-hyperpath search (Nederhof, 2003)." ></td>
	<td class="line x" title="135:345	We halt as soon as a full parse (the accept item) pops from the agenda, since uniform-cost search (as a special case of the A algorithm) guarantees this to be the maximumprobability parse." ></td>
	<td class="line x" title="136:345	No other pruning is done." ></td>
	<td class="line x" title="137:345	11Confusion-set parsing may be regarded as parsing a particular lattice with n states and ng arcs." ></td>
	<td class="line x" title="138:345	The algorithm can be generalized to lattice parsing, in which case it has runtime O(m2(n + tprime)t) for a lattice of n states and m arcs." ></td>
	<td class="line x" title="139:345	Roughly, h : w is replaced by an arc, while i is replaced by a state and i1 is replaced by the same state." ></td>
	<td class="line x" title="140:345	12For general lattice parsing, it is not possible to determine  while applying this rule." ></td>
	<td class="line x" title="141:345	There h and hprime are arcs in the lattice, not integers, and different paths from h to hprime might cover different numbers of words." ></td>
	<td class="line x" title="142:345	Thus, if one still wanted to measure dependency length in words (rather than in, say, milliseconds of speech), each item would have to record its width explicitly, leading in general to more items and increased runtime." ></td>
	<td class="line x" title="143:345	33 With a prioritized agenda, a probability model that more sharply discriminates among parses will typically lead to a faster parser." ></td>
	<td class="line x" title="144:345	(Low-probability constituents languish at the back of the agenda and are never pursued)." ></td>
	<td class="line x" title="145:345	We will see that the lengthsensitive models do run faster for this reason." ></td>
	<td class="line x" title="146:345	3.7 Experiments with Soft Constraints We trained models AC, using unsmoothed maximum likelihood estimation, on three treebanks: the Penn (English) Treebank (split in the standard way, 221 train/23 test, or 950K/57K words), the Penn Chinese Treebank (80% train/10% test or 508K/55K words), and the German TIGER corpus (80%/10% or 539K/68K words).13 Estimation was a simple matter of counting automaton events and normalizing counts into probabilities." ></td>
	<td class="line x" title="147:345	For each model, we also trained the three length-sensitive versions described in3.3." ></td>
	<td class="line x" title="148:345	The German corpus contains non-projective trees." ></td>
	<td class="line x" title="149:345	None of our parsers can recover non-projective dependencies (nor can our models produce them)." ></td>
	<td class="line x" title="150:345	This fact was ignored when counting events for maximum likelihood estimation: in particular, we always trained Lw and Rw on the sequence of ws immediate children, even in non-projective trees." ></td>
	<td class="line x" title="151:345	Our results (Tab." ></td>
	<td class="line x" title="152:345	1) show that sharpening the probabilities with the most sophisticated distance factors p( | d,h,c), consistently improved the speed of all parsers.14 The change to the code is trivial." ></td>
	<td class="line x" title="153:345	The only overhead is the cost of looking up and multiplying in the extra distance factors." ></td>
	<td class="line x" title="154:345	Accuracy also improved over the baseline models of English and Chinese, as well as the simpler baseline models of German." ></td>
	<td class="line x" title="155:345	Again, the most sophisticated distance factors helped most, but even the simplest distance factor usually obtained most of the accuracy benefit." ></td>
	<td class="line x" title="156:345	German model C fell slightly in accuracy." ></td>
	<td class="line x" title="157:345	The speedup here suggests that the probabilities were sharpened, but often in favor of the wrong parses." ></td>
	<td class="line x" title="158:345	We did not analyze the errors on German; it may 13Heads were extracted for English using Michael Collins rules and Chinese using Fei Xias rules (defaulting in both cases to right-most heads where the rules fail)." ></td>
	<td class="line x" title="159:345	German heads were extracted using the TIGER Java API; we discarded all resulting dependency structures that were cyclic or unconnected (6%)." ></td>
	<td class="line x" title="160:345	14We measure speed abstractly by the number of items built and pushed on the agenda." ></td>
	<td class="line x" title="161:345	be relevant that 25% of the German sentences contained a non-projective dependency between nonpunctuation tokens." ></td>
	<td class="line x" title="162:345	Studying the parser output for English, we found that the length-sensitive models preferred closer attachments, with 19.7% of tags having a nearer parent in the best parse under model C with p(|d,h,c) than in the original model C, 77.7% having a parent at the same distance, and only 2.5% having a farther parent." ></td>
	<td class="line x" title="163:345	The surviving long dependencies (at any length > 1) tended to be much more accurate, while the (now more numerous) length-1 dependencies were slightly less accurate than before." ></td>
	<td class="line x" title="164:345	We caution that length sensitivitys most dramatic improvements to accuracy were on the worse baseline models, which had more room to improve." ></td>
	<td class="line x" title="165:345	The better baseline models (B and C) were already able to indirectly capture some preference for short dependencies, by learning that some parts of speech were unlikely to have multiple left or multiple right dependents." ></td>
	<td class="line x" title="166:345	Enhancing B and C therefore contributed less, and indeed may have had some harmful effect by over-penalizing some structures that were already appropriately penalized.15 It remains to be seen, therefore, whether distance features would help state-of-the art parsers that are already much better than model C. Such parsers may already incorporate features that indirectly impose a good model of distance, though perhaps not as cheaply." ></td>
	<td class="line x" title="167:345	4 Hard Dependency-Length Constraints We have seen how an explicit model of distance can improve the speed and accuracy of a simple probabilistic dependency parser." ></td>
	<td class="line x" title="168:345	Another way to capitalize on the fact that most dependencies are local is to impose a hard constraint that simply forbids long dependencies." ></td>
	<td class="line x" title="169:345	The dependency trees that satisfy this constraint yield a regular string language.16 The constraint prevents arbitrarily deep center-embedding, as well as arbitrarily many direct dependents on a given head, 15Owing to our deficient model." ></td>
	<td class="line x" title="170:345	A log-linear or discriminative model would be trained to correct for overlapping penalties and would avoid this risk." ></td>
	<td class="line x" title="171:345	Non-deficient generative models are also possible to design, along lines similar to footnote 16." ></td>
	<td class="line x" title="172:345	16One proof is to construct a strongly equivalent CFG without center-embedding (Nederhof, 2000)." ></td>
	<td class="line x" title="173:345	Each nonterminal has the form w,q,i,j, where w  , q is a state of Lw or Rw, and i,j  {0,1,k1, k}." ></td>
	<td class="line x" title="174:345	We leave the details as an exercise." ></td>
	<td class="line x" title="175:345	34 English (Penn Treebank) Chinese (Chinese Treebank) German (TIGER Corpus) recall (%) runtime model recall (%) runtime model recall (%) runtime model model train test test size train test test size train test test size A (1 state) 62.0 62.2 93.6 1,878 50.7 49.3 146.7 782 70.9 72.0 53.4 1,598 + p( | d) 70.1 70.6 97.0 2,032 59.0 58.0 161.9 1,037 72.3 73.0 53.2 1,763 + p( | h) 70.5 71.0 94.7 3,091 60.5 59.1 148.3 1,759 73.1 74.0 48.3 2,575 + p( | d,h,c) 72.8 73.1 70.4 16,305 62.2 60.6 106.7 7,828 75.0 75.1 31.6 12,325 B (2 states, tied arcs) 69.7 70.4 93.5 2,106 56.7 56.2 151.4 928 73.7 75.1 52.9 1,845 + p( | d) 72.6 73.2 95.3 2,260 60.2 59.5 156.9 1,183 72.9 73.9 52.6 2,010 + p( | h) 73.1 73.7 92.1 3,319 61.6 60.7 144.2 1,905 74.1 75.3 47.6 2,822 + p( | d,h,c) 75.3 75.6 67.7 16,533 62.9 61.6 104.0 7,974 75.2 75.5 31.5 12,572 C (2 states) 72.7 73.1 90.3 3,233 61.8 61.0 148.3 1,314 75.6 76.9 48.5 2,638 + p( | d) 73.9 74.5 91.7 3,387 61.5 60.6 154.7 1,569 74.3 75.0 48.9 2,803 + p( | h) 74.3 75.0 88.6 4,446 63.1 61.9 141.9 2,291 75.2 76.3 44.3 3,615 + p( | d,h,c) 75.3 75.5 66.6 17,660 63.4 61.8 103.4 8,360 75.1 75.2 31.0 13,365 Table 1: Dependency parsing of POS tag sequences with simple probabilistic split bilexical grammars." ></td>
	<td class="line x" title="176:345	The models differ only in how they weight the same candidate parse trees." ></td>
	<td class="line x" title="177:345	Length-sensitive models are larger but can improve dependency accuracy and speed." ></td>
	<td class="line x" title="178:345	(Recall is measured as the fraction of non-punctuation tags whose correct parent (if not the $ symbol) was correctly recovered by the parser; it equals precision, unless the parser left some sentences unparsed (or incompletely parsed, as in 4), in which case precision is higher." ></td>
	<td class="line x" title="179:345	Runtime is measured abstractly as the average number of items (i.e. , a64a64, a0a0, a8a8, a72a72 ) built per word." ></td>
	<td class="line x" title="180:345	Model size is measured as the number of nonzero parameters.)" ></td>
	<td class="line x" title="181:345	either of which would allow the non-regular language {anbcn : 0 < n < }." ></td>
	<td class="line x" title="182:345	It does allow arbitrarily deep rightor left-branching structures." ></td>
	<td class="line x" title="183:345	4.1 Vine Grammars The tighter the bound on dependency length, the fewer parse trees we allow and the faster we can find them using the algorithm of Fig." ></td>
	<td class="line x" title="184:345	2a." ></td>
	<td class="line oc" title="185:345	If the bound is too tight to allow the correct parse of some sentence, we would still like to allow an accurate partial parse: a sequence of accurate parse fragments (Hindle, 1990; Abney, 1991; Appelt et al. , 1993; Chen, 1995; Grefenstette, 1996)." ></td>
	<td class="line x" title="186:345	Furthermore, we would like to use the fact that some fragment sequences are presumably more likely than others." ></td>
	<td class="line x" title="187:345	Our partial parses will look like the one in Fig." ></td>
	<td class="line x" title="188:345	1b." ></td>
	<td class="line x" title="189:345	where 4 subtrees rather than 1 are dependent on $." ></td>
	<td class="line x" title="190:345	This is easy to arrange in the SBG formalism." ></td>
	<td class="line x" title="191:345	We merely need to construct our SBG so that the automaton R$ is now permitted to generate multiple childrenthe roots of parse fragments." ></td>
	<td class="line x" title="192:345	This R$ is a probabilistic finite-state automaton that describes legal or likely root sequences in ." ></td>
	<td class="line x" title="193:345	In our experiments in this section, we will train it to be a first-order (bigram) Markov model." ></td>
	<td class="line x" title="194:345	(Thus we construct R$ in the usual way to have ||+ 1 states, and train it on data like the other left and right automata." ></td>
	<td class="line x" title="195:345	During generation, its state remembers the previously generated root, if any." ></td>
	<td class="line x" title="196:345	Recall that we are working with POS tag sequences, so the roots, like all other words, are tags in .)" ></td>
	<td class="line x" title="197:345	The 4 subtrees in Fig." ></td>
	<td class="line x" title="198:345	1b appear as so many bunches of grapes hanging off a vine." ></td>
	<td class="line x" title="199:345	We refer to the dotted dependencies upon $ as vine dependencies, and the remaining, bilexical dependencies as tree dependencies." ></td>
	<td class="line x" title="200:345	One might informally use the term vine grammar (VG) for any generative formalism, intended for partial parsing, in which a parse is a constrained sequence of trees that cover the sentence." ></td>
	<td class="line x" title="201:345	In general, a VG might use a two-part generative process: first generate a finite-state sequence of roots, then expand the roots according to some more powerful formalism." ></td>
	<td class="line x" title="202:345	Conveniently, however, SBGs and other dependency grammars can integrate these two steps into a single formalism." ></td>
	<td class="line x" title="203:345	4.2 Feasible Parsing Now, for both speed and accuracy, we will restrict the trees that may hang from the vine." ></td>
	<td class="line x" title="204:345	We define a feasible parse under our SBG to be one in which all tree dependencies are short, i.e., their length never exceeds some hard bound k. The vine dependencies may have unbounded length, of course, as in Fig." ></td>
	<td class="line x" title="205:345	1b." ></td>
	<td class="line x" title="206:345	Sentences with feasible parses form a regular language." ></td>
	<td class="line x" title="207:345	This would also be true under other definitions of feasibility, e.g., we could have limited the depth or width of each tree on the vine." ></td>
	<td class="line x" title="208:345	However, that would have ruled out deeply right-branching trees, which are very common in language, and 35 (a) $ would d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d96d97d97d97d97d97d97d97d97d97d97d97d97d97d97d97d97d97d97d97d97d101d101d101d101d101 d89d89d89d89d89 d91d91d91d91d91d91d91d91d91d91d91d91d91d91d91d91 d91d91d91d91d91d91d91d91d91d91d91d91d91d91d91d91 d91d91d91d91d91d91d91d91d91d91d91d91 Accordingd89d89d89d89d89, changesd98d98d98d98d98d98d98d98d98d98d101d101d101d101d101 cut d92d92d92d92d92d92d92d92d92d92 d93d93d93d93d93d93d93d93d93d93d93d93d93d93d93 to d92d92d92d92d92d92d92d92d92d92 the rule filingsd101d101d101d101d101 by d89d89d89d89d89 . estimatesd101d101d101d101d101 insider more d89d89d89d89d89 some than d92d92d92d92d92d92d92d92d92d92 thirdd101d101d101d101d101 a (b) $ According d87d87d87d87, wouldd103d103d103d103 d87d87d87d87 to d91d91d91d91d91d91d91d91 changesd99d99d99d99d99d99d99d99d103d103d103d103 cut d91d91d91d91d91d91d91d91 d92d92d92d92d92d92d92d92d92d92d92 estimatesd103d103d103d103 the rule filingsd103d103d103d103 by d87d87d87d87 . some insider more d87d87d87d87 than d91d91d91d91d91d91d91d91 thirdd103d103d103d103 a Figure 1: (a) A dependency tree on words." ></td>
	<td class="line x" title="209:345	(Our experiments use only POS tags)." ></td>
	<td class="line x" title="210:345	(b) A partial parse for the same sentence retaining only tree dependencies of length  k = 3." ></td>
	<td class="line x" title="211:345	The roots of the 4 resulting parse fragments are now connected only by their dotted-line vine dependencies on $." ></td>
	<td class="line x" title="212:345	Transforming (a) into (b) involves grafting subtrees rooted at According, ,, and . onto the vine." ></td>
	<td class="line x" title="213:345	are also the traditional way to describe finite-state sublanguages within a context-free grammar." ></td>
	<td class="line x" title="214:345	By contrast, our limitation on dependency length ensures regularity while still allowing (for any bound k  1) arbitrarily wide and deep trees, such as ab rootyz. Our goal is to find the best feasible parse (if any)." ></td>
	<td class="line x" title="215:345	Rather than transform the grammar as in footnote 16, our strategy is to modify the parser so that it only considers feasible parses." ></td>
	<td class="line x" title="216:345	The interesting problem is to achieve linear-time parsing with a grammar constant that is as small as for ordinary parsing." ></td>
	<td class="line x" title="217:345	We also correspondingly modify the training data so that we only train on feasible parses." ></td>
	<td class="line x" title="218:345	That is, we break any long dependencies and thereby fragment each training parse (a single tree) into a vine of one or more restricted trees." ></td>
	<td class="line x" title="219:345	When we break a childto-parent dependency, we reattach the child to $.17 This process, grafting, is illustrated in Fig." ></td>
	<td class="line x" title="220:345	1." ></td>
	<td class="line x" title="221:345	Although this new parse may score less than 100% recall of the original dependencies, it is the best feasible parse, so we would like to train the parser to find it.18 By training on the modified data, we learn more 17Any dependency covering the child must also be broken to preserve projectivity." ></td>
	<td class="line x" title="222:345	This case arises later; see footnote 25." ></td>
	<td class="line x" title="223:345	18Although the parser will still not be able to find it if it is non-projective (possible in German)." ></td>
	<td class="line x" title="224:345	Arguably we should have defined feasible to also require projectivity, but we did not." ></td>
	<td class="line x" title="225:345	appropriate statistics for both R$ and the other automata." ></td>
	<td class="line x" title="226:345	If we trained on the original trees, we would inaptly learn that R$ always generates a single root rather than a certain kind of sequence of roots." ></td>
	<td class="line x" title="227:345	For evaluation, we score tree dependencies in our feasible parses against the tree dependencies in the unmodified gold standard parses, which are not necessarily feasible." ></td>
	<td class="line x" title="228:345	We also show oracle performance." ></td>
	<td class="line x" title="229:345	4.3 Approach #1: FSA Parsing Since we are now dealing with a regular language, it is possible in principle to use a weighted finitestate automaton (FSA) to search for the best feasible parse." ></td>
	<td class="line x" title="230:345	The idea is to find the highest-weighted path that accepts the input string  = w1w2 wn." ></td>
	<td class="line x" title="231:345	Using the Viterbi algorithm, this takes time O(n)." ></td>
	<td class="line x" title="232:345	The trouble is that this linear runtime hides a constant factor, which depends on the size of the relevant part of the FSA and may be enormous for any correct FSA.19 Consider an example from Fig 1b." ></td>
	<td class="line x" title="233:345	After nondeterministically reading w1 w11 = According." ></td>
	<td class="line x" title="234:345	insider along the correct path, the FSA state must record (at least) that insider has no parent yet and that R$ and Rcut are in particular states that 19The full runtime is O(nE), where E is the number of FSA edges, or for a tighter estimate, the number of FSA edges that can be traversed by reading ." ></td>
	<td class="line x" title="235:345	36 may still accept more children." ></td>
	<td class="line x" title="236:345	Else the FSA cannot know whether to accept a continuation w12 wn." ></td>
	<td class="line x" title="237:345	In general, after parsing a prefix w1 wj, the FSA state must somehow record information about all incompletely linked words in the past." ></td>
	<td class="line x" title="238:345	It must record the sequence of past words wi (i  j) that still need a parent or child in the future; if wi still needs a child, it must also record the state of Rwi." ></td>
	<td class="line x" title="239:345	Our restriction to dependency lengthk is what allows us to build a finite-state machine (as opposed to some kind of pushdown automaton with an unbounded number of configurations)." ></td>
	<td class="line x" title="240:345	We need only build the finitely many states where the incompletely linked words are limited to at most w0 = $ and the k most recent words, wjk+1 wj." ></td>
	<td class="line x" title="241:345	Other states cannot extend into a feasible parse, and can be pruned." ></td>
	<td class="line x" title="242:345	However, this still allows the FSA to be in O(2ktk+1) different states after reading w1 wj." ></td>
	<td class="line x" title="243:345	Then the runtime of the Viterbi algorithm, though linear in n, is exponential in k. 4.4 Approach #2: Ordinary Chart Parsing A much better idea for most purposes is to use a chart parser." ></td>
	<td class="line x" title="244:345	This allows the usual dynamic programming techniques for reusing computation." ></td>
	<td class="line x" title="245:345	(The FSA in the previous section failed to exploit many such opportunities: exponentially many states would have proceeded redundantly by building the same wj+1wj+2wj+3 constituent.)" ></td>
	<td class="line x" title="246:345	It is simple to restrict our algorithm of Fig." ></td>
	<td class="line x" title="247:345	2a to find only feasible parses." ></td>
	<td class="line x" title="248:345	It is the ATTACH rules a64a64 + a0a0 that add dependencies: simply use a side condition to block them from applying unless |hhprime|k (short tree dependency) or h = 0 (vine dependency)." ></td>
	<td class="line x" title="249:345	This ensures that all a72a72 and a8a8 will have widthk or have their left edge at 0." ></td>
	<td class="line x" title="250:345	One might now incorrectly expect runtime linear in n: the number of possible ATTACH combinations is reduced from O(n3) to O(nk2), because i and hprime are now restricted to a narrow range given h. Unfortunately, the half-constituents a64a64 and a0a0 may still be arbitrarily wide, thanks to arbitrary rightand left-branching: a feasible vine parse may be a sequence of wide trees a0a0a64a64 . Thus there are O(n2k) possible COMPLETE combinations, not to mention O(n2) ATTACH-RIGHT combinations for which h = 0." ></td>
	<td class="line x" title="251:345	So the runtime remains quadratic." ></td>
	<td class="line x" title="252:345	4.5 Approach #3: Specialized Chart Parsing How, then, do we get linear runtime and a reasonable grammar constant?" ></td>
	<td class="line x" title="253:345	We give two ways to achieve runtime of O(nk2)." ></td>
	<td class="line x" title="254:345	First, we observe without details that we can easily achieve this by starting instead with the algorithm of Eisner (2000),20 rather than Eisner and Satta (1999), and again refusing to add long tree dependencies." ></td>
	<td class="line x" title="255:345	That algorithm effectively concatenates only trapezoids, not triangles." ></td>
	<td class="line x" title="256:345	Each is spanned by a single dependency and so has widthk. The vine dependencies do lead to wide trapezoids, but these are constrained to start at 0, where $ is. So the algorithm tries at most O(nk2) combinations of the form h i+ i j (like the ATTACH combinations above) and O(nk) combinations of the form 0 i + i j, where ihk,jik. The precise runtime is O(nk(k + tprime)tg3)." ></td>
	<td class="line x" title="257:345	We now propose a hybrid linear-time algorithm that further improves runtime to O(nk(k + tprime)tg2), saving a factor of g in the grammar constant.21 We observe that since within-tree dependencies must have length  k, they can all be captured within Eisner-Satta trapezoids of width  k. So our VG parse a0a0a64a64  can be assembled by simply concatenating a sequence ( a0a0 a8a8  a72a72  a64a64 ) of these narrow trapezoids interspersed with width-0 triangles." ></td>
	<td class="line x" title="258:345	As this is a regular sequence, we can assemble it in linear time from left to right (rather than in the order of Eisner and Satta (1999)), multiplying the items probabilities together." ></td>
	<td class="line x" title="259:345	Whenever we start adding the right half a72a72  a64a64 of a tree along the vine, we have discovered that trees root, so we multiply in the probability of a $root dependency." ></td>
	<td class="line x" title="260:345	Formally, our hybrid parsing algorithm restricts the original rules of Fig." ></td>
	<td class="line x" title="261:345	2a to build only trapezoids of width  k and triangles of width < k.22 The additional inference rules in Fig." ></td>
	<td class="line x" title="262:345	2b then assemble the final VG parse as just described." ></td>
	<td class="line x" title="263:345	20With a small change that when two items are combined, the right item (rather than the left) must be simple." ></td>
	<td class="line x" title="264:345	21This savings comes from building the internal structure of a trapezoid from both ends inward rather than from left to right." ></td>
	<td class="line x" title="265:345	The corresponding unrestricted algorithms (Eisner, 2000; Eisner and Satta, 1999, respectively) have exactly the same runtimes with k replaced by n. 22For the experiments of 4.7, where k varied by type, we restricted these rules as tightly as possible given h and hprime." ></td>
	<td class="line x" title="266:345	37 (a) ST AR TLE FT : w  W h q init (L w) a0a0 q h h: w 1 h n ST AR TRI GH T: q init (R w) a64a64q h: w h a0a0F i h: w ST AR TVI NE : q init (R $) a64a64q 0: $ 0 FI NI SH -L EF T: a0a0 q i h: w q final (L w) a0a0F i h: w FI NI SH -R IG HT : a64a64q h: w i q final (R w) a64a64F h: w i EN DVI NE : a64a64F 0: $ n accept AT TA CH -L EF T:   a64a64F hprime :w prime i 1 a0a0 q i h: w  qw prime  r Lw a8a8 r hprime :w prime h: w AT TA CH -R IG HT :   a64a64q h: w i 1 a0a0F i hprime :w prime  qw prime  r Rw a72a72r hprime :w prime h: w CO M PL ET ELE FT : a0a0F i hprime :w prime a8a8 q hprime :w prime h: w a0a0 q i h: w CO M PL ET ERI GH T: a72a72q hprime :w prime h: w a64a64F hprime :w prime i a64a64q h: w i Figure 2: (a) An algorithm that parses W 1  .W n in cubic time O( n2 (n +t prime ) tg2 )." ></td>
	<td class="line x" title="267:345	Adapted with impro vements from (Eisner and Satta, 1999, Fig." ></td>
	<td class="line x" title="268:345	3)." ></td>
	<td class="line x" title="269:345	The parentheses in the AT TA CH rules indicate the deduction of an intermediate item that for gets i." ></td>
	<td class="line x" title="270:345	(b) If the AT TA CH rules are restricted to apply only when case |h  hprime|  k, and the CO M PL ET E rules only when |h  i| < k, then the additional rules in (b) will assemble the resulting fragments into avine parse." ></td>
	<td class="line x" title="271:345	In this case, AT TA CH -R IG HT should also be restricted to h > 0, to pre vent duplicate deri vations." ></td>
	<td class="line x" title="272:345	The runtime is O( nk (k + tprime ) tg2 ),dominated by the AT TA CH rules; the rules in (b) require only O( nk tg2 + ng ttprime )time." ></td>
	<td class="line x" title="273:345	Each algorithm is specified as acollection of deducti ve inference rules." ></td>
	<td class="line x" title="274:345	Once one has deri ved all antecedent items abo ve the horizon tal line and an y side conditions to the right of the line, one may deriv ethe consequent item belo w the line." ></td>
	<td class="line x" title="275:345	Weighted agenda-based deduction is handled in the usual way (Nederhof, 2003; Eisner et al. , 200 5)." ></td>
	<td class="line x" title="276:345	The probabilities go verning the automaton Lw, namely p( start at q), p( qw prime  r |q ), and p( stop | q), are respecti vely associated with the axiomatic items q  init (L w ), qw prime  r  Lw,and q  final (L w )." ></td>
	<td class="line x" title="277:345	An acoustic score p( observ ation at h | w) could be associated with the item w  W h." ></td>
	<td class="line x" title="278:345	(b) TR EE -S TA RT : a64a64q 0: $ i 1 a0a0F i i:w a8a8 a64a64q i:w 0: $ TR EE -L EF T: a8a8 a64a64q i:w 0: $ a8a8F i:w j: x a8a8 a64a64q j: x 0: $ GR AF TVI NE : a8a8 a64a64q i:w 0: $ q w r R$ a88a88a121 a88a88a121r i:w 0: $ TR EE -R IG HT : a88a88a121 a88a88a121q i:w 0: $ a72a72F j: x i:w a88a88a121 a88a88a121q j: x 0: $ TR EE -E ND : a88a88a121 a88a88a121q i:w 0: $ a64a64F i:w i a64a64q 0: $ i SE AL -L EF T: a8a8 q hprime :w prime h: w q final (L w) a8a8F hprime :w prime h: w SE AL -R IG HT : a72a72q hprime :w prime h: w q final (R w) a72a72F hprime :w prime h: w 38 0.4 0.5 0.6 0.7 0.8 0.9 1 0.3 0.4 0.5 0.6 0.7 0.8 0.9 recall precision E C G k = 1 Model C, no boundsingle bound (English) (Chinese) (German) Figure 3: Trading precision and recall: Imposing bounds can improve precision at the expense of recall, for English and Chinese." ></td>
	<td class="line x" title="279:345	German performance suffers more." ></td>
	<td class="line x" title="280:345	Bounds shown are k = {1,2,,10,15,20}." ></td>
	<td class="line x" title="281:345	The dotted lines show constant Fmeasure of the unbounded model." ></td>
	<td class="line x" title="282:345	4.6 Experiments with Hard Constraints Our experiments used the asymptotically fast hybrid parsing algorithm above." ></td>
	<td class="line x" title="283:345	We used the same left and right automata as in model C, the best-performing model from 3.2." ></td>
	<td class="line x" title="284:345	However, we now define R$ to be a first-order (bigram) Markov model (4.1)." ></td>
	<td class="line x" title="285:345	We trained and tested on the same headed treebanks as before (3.7), except that we modified the training trees to make them feasible (4.2)." ></td>
	<td class="line x" title="286:345	Results are shown in Figures 3 (precision/recall tradeoff) and 4 (accuracy/speed tradeoff), for k  {1,2,,10,15,20}." ></td>
	<td class="line x" title="287:345	Dots correspond to different values of k. On English and Chinese, some values of k actually achieve better F-measure accuracy than the unbounded parser, by eliminating errors.23 We observed that changing R$ from a bigram to a unigram model significantly hurt performance, showing that it is in fact useful to empirically model likely sequences of parse fragments." ></td>
	<td class="line x" title="288:345	4.7 Finer-Grained Hard Constraints The dependency length bound k need not be a single value." ></td>
	<td class="line x" title="289:345	Substantially better accuracy can be retained if each dependency typeeach (h,c,d) = (head tag, child tag, direction) tuplehas its own 23Because our prototype implementation of each kind of parser (baseline, soft constraints, single-bound, and typespecific bounds) is known to suffer from different inefficiencies, runtimes in milliseconds are not comparable across parsers." ></td>
	<td class="line x" title="290:345	To give a general idea, 60-word English sentences parsed in around 300ms with no bounds, but at around 200ms with either a distance model p(|d,h,c) or a generous hard bound of k = 10." ></td>
	<td class="line x" title="291:345	bound k(h,c,d)." ></td>
	<td class="line x" title="292:345	We call these type-specific bounds: they create a many-dimensional space of possible parsers." ></td>
	<td class="line x" title="293:345	We measured speed and accuracy along a sensible path through this space, gradually tightening the bounds using the following process: 1." ></td>
	<td class="line x" title="294:345	Initialize each bound k(h,c,d) to the maximum distance observed in training (or 1 for unseen triples).24 2." ></td>
	<td class="line x" title="295:345	Greedily choose a bound k(h,c,d) such that, if its value is decremented and trees that violate the new bound are accordingly broken, the fewest dependencies will be broken.25 3." ></td>
	<td class="line x" title="296:345	Decrement the bound k(h,c,d) and modify the training data to respect the bound by breaking dependencies that violate the bound and grafting the loose portion onto the vine." ></td>
	<td class="line x" title="297:345	Retrain the parser on the training data." ></td>
	<td class="line x" title="298:345	4." ></td>
	<td class="line x" title="299:345	If all bounds are not equal to 1, go to step 2." ></td>
	<td class="line x" title="300:345	The performance of every 200th model along the trajectory of this search is plotted in Fig." ></td>
	<td class="line x" title="301:345	4.26 The graph shows that type-specific bounds can speed up the parser to a given level with less loss in accuracy." ></td>
	<td class="line x" title="302:345	5 Related Work As discussed in footnote 3, Collins (1997) and McDonald et al.(2005) considered the POS tags intervening between a head and child." ></td>
	<td class="line x" title="304:345	These soft constraints were very helpful, perhaps in part because they helped capture the short dependency preference (2)." ></td>
	<td class="line x" title="305:345	Collins used them as conditioning variables and McDonald et al. as log-linear features, whereas our3 predicted them directly in a deficient model." ></td>
	<td class="line x" title="306:345	As for hard constraints (4), our limitation on dependency length can be regarded as approximating a context-free language by a subset that is a regular 24In the case of the German TIGER corpus, which contains non-projective dependencies, we first make the training trees into projective vines by raising all non-projective child nodes to become heads on the vine." ></td>
	<td class="line x" title="307:345	25Not counting dependencies that must be broken indirectly in order to maintain projectivity." ></td>
	<td class="line x" title="308:345	(If word 4 depends on word 7 which depends on word 2, and the 4  7 dependency is broken, making 4 a root, then we must also break the 2  7 dependency.)" ></td>
	<td class="line x" title="309:345	26Note that k(h,c,right) = 7 bounds the width of a64a64 + a0a0 = a8a8 . For a finer-grained approach, we could instead separately bound the widths of a64a64 and a0a0, say by kr(h,c,right) = 4 and kl(h,c,right) = 2." ></td>
	<td class="line x" title="310:345	39 language." ></td>
	<td class="line x" title="311:345	Our vines then let us concatenate several strings in this subset, which typically yields a superset of the original context-free language." ></td>
	<td class="line x" title="312:345	Subset and superset approximations of (weighted) CFLs by (weighted) regular languages, usually by preventing center-embedding, have been widely explored; Nederhof (2000) gives a thorough review." ></td>
	<td class="line x" title="313:345	We limit all dependency lengths (not just centerembedding).27 Further, we derive weights from a modified treebank rather than by approximating the true weights." ></td>
	<td class="line x" title="314:345	And though regular grammar approximations are useful for other purposes, we argue that for parsing it is more efficient to perform the approximation in the parser, not in the grammar." ></td>
	<td class="line x" title="315:345	Brants (1999) described a parser that encoded the grammar as a set of cascaded Markov models." ></td>
	<td class="line x" title="316:345	The decoder was applied iteratively, with each iteration transforming the best (or n-best) output from the previous one until only the root symbol remained." ></td>
	<td class="line x" title="317:345	This is a greedy variant of CFG parsing where the grammar is in Backus-Naur form." ></td>
	<td class="line x" title="318:345	Bertsch and Nederhof (1999) gave a linear-time recognition algorithm for the recognition of the regular closure of deterministic context-free languages." ></td>
	<td class="line x" title="319:345	Our result is related; instead of a closure of deterministic CFLs, we deal in a closure of CFLs that are assumed (by the parser) to obey some constraint on trees (like a maximum dependency length)." ></td>
	<td class="line x" title="320:345	6 Future Work The simple POS-sequence models we used as an experimental baseline are certainly not among the best parsers available today." ></td>
	<td class="line x" title="321:345	They were chosen to illustrate how modeling and exploiting distance in syntax can affect various performance measures." ></td>
	<td class="line x" title="322:345	Our approach may be helpful for other kinds of parsers as well." ></td>
	<td class="line x" title="323:345	First, we hope that our results will generalize to more expressive grammar formalisms such as lexicalized CFG, CCG, and TAG, and to more expressively weighted grammars, such as log-linear models that can include head-child distance among other rich features." ></td>
	<td class="line x" title="324:345	The parsing algorithms we presented also admit inside-outside variants, allowing iterative estimation methods for log-linear models (see, e.g., Miyao and Tsujii, 2002)." ></td>
	<td class="line x" title="325:345	27Of course, this still allows right-branching or leftbranching to unbounded depth." ></td>
	<td class="line x" title="326:345	0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 0 20 40 60 80 100 runtime (items/word) English F k = 1 2 3 1520 Model C, baselinesoft constraint single boundtype-specific bounds 0.4 0.5 0.6 0.7 0.8 0.9 1 0 20 40 60 80 100 120 140 160 runtime (items/word) Chinese F k = 1 2 3 1520 Model C, baselinesoft constraint single boundtype-specific bounds 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 0 10 20 30 40 50 60 runtime (items/word) German F k = 1 2 3 15 20 Model C, baselinesoft constraint single boundtype-specific bounds Figure 4: Trading off speed and accuracy by varying the set of feasible parses: The baseline (no length bound) is shown as +." ></td>
	<td class="line x" title="327:345	Tighter bounds always improve speed, except for the most lax bounds, for which vine construction overhead incurs a slowdown." ></td>
	<td class="line x" title="328:345	Type-specific bounds tend to maintain good Fmeasure at higher speeds than the single-bound approach." ></td>
	<td class="line x" title="329:345	The vertical error bars show the oracle accuracy for each experiment (i.e. , the F-measure if we had recovered the best feasible parse, as constructed from the gold-standard parse by grafting: see 4.2)." ></td>
	<td class="line x" title="330:345	Runtime is measured as the number of items per word (i.e. , a64a64, a0a0, a8a8, a72a72, a8a8a64a64, a88a88a121 a88a88a121 ) built by the agenda parser." ></td>
	<td class="line x" title="331:345	The soft constraint point marked with  represents the p( | d,h,c)-augmented model from 3." ></td>
	<td class="line x" title="332:345	40 Second, fast approximate parsing may play a role in more accurate parsing." ></td>
	<td class="line x" title="333:345	It might be used to rapidly compute approximate outside-probability estimates to prioritize best-first search (e.g. , Caraballo and Charniak, 1998)." ></td>
	<td class="line x" title="334:345	It might also be used to speed up the early iterations of training a weighted parsing model, which for modern training methods tends to require repeated parsing (either for the best parse, as by Taskar et al. , 2004, or all parses, as by Miyao and Tsujii, 2002)." ></td>
	<td class="line x" title="335:345	Third, it would be useful to investigate algorithmic techniques and empirical benefits for limiting dependency length in more powerful grammar formalisms." ></td>
	<td class="line x" title="336:345	Our runtime reduction from O(n3)  O(nk2) for a length-k bound applies only to a split bilexical grammar.28 Various kinds of synchronous grammars, in particular, are becoming important in statistical machine translation." ></td>
	<td class="line x" title="337:345	Their high runtime complexity might be reduced by limiting monolingual dependency length (for a related idea see Schafer and Yarowsky, 2003)." ></td>
	<td class="line x" title="338:345	Finally, consider the possibility of limiting dependency length during grammar induction." ></td>
	<td class="line x" title="339:345	We reason that a learner might start with simple structures that focus on local relationships, and gradually relax this restriction to allow more complex models." ></td>
	<td class="line x" title="340:345	7 Conclusion We have described a novel reason for identifying headword-to-headword dependencies while parsing: to consider their length." ></td>
	<td class="line x" title="341:345	We have demonstrated that simple bilexical parsers of English, Chinese, and German can exploit a short-dependency preference. Notably, soft constraints on dependency length can improve both speed and accuracy, and hard constraints allow improved precision and speed with some loss in recall (on English and Chinese, remarkably little loss)." ></td>
	<td class="line x" title="342:345	Further, for the hard constraint lengthk, we have given an O(nk2) partial parsing algorithm for split bilexical grammars; the grammar constant is no worse than for state-ofthe-art O(n3) algorithms." ></td>
	<td class="line x" title="343:345	This algorithm strings together the partial trees roots along a vine. 28The obvious reduction for unsplit head automaton grammars, say, is only O(n4)  O(n3k), following (Eisner and Satta, 1999)." ></td>
	<td class="line x" title="344:345	Alternatively, one can convert the unsplit HAG to a split one that preserves the set of feasible (length  k) parses, but then g becomes prohibitively large in the worst case." ></td>
	<td class="line x" title="345:345	Our approach might be adapted to richer parsing formalisms, including synchronous ones, and should be helpful as an approximation to full parsing when fast, high-precision recovery of syntactic information is needed." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W05-1516
Strictly Lexical Dependency Parsing
Wang, Qin Iris;Schuurmans, Dale;Lin, Dekang;"></td>
	<td class="line x" title="1:171	Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 152159, Vancouver, October 2005." ></td>
	<td class="line x" title="2:171	c2005 Association for Computational Linguistics Strictly Lexical Dependency Parsing Qin Iris Wang and Dale Schuurmans Dekang Lin Department of Computing Science Google, Inc. University of Alberta 1600 Amphitheatre Parkway Edmonton, Alberta, Canada, T6G 2E8 Mountain View, California, USA, 94043 {wqin,dale}@cs.ualberta.ca lindek@google.com Abstract We present a strictly lexical parsing model where all the parameters are based on the words." ></td>
	<td class="line x" title="3:171	This model does not rely on part-of-speech tags or grammatical categories." ></td>
	<td class="line x" title="4:171	It maximizes the conditional probability of the parse tree given the sentence." ></td>
	<td class="line x" title="5:171	This is in contrast with most previous models that compute the joint probability of the parse tree and the sentence." ></td>
	<td class="line x" title="6:171	Although the maximization of joint and conditional probabilities are theoretically equivalent, the conditional model allows us to use distributional word similarity to generalize the observed frequency counts in the training corpus." ></td>
	<td class="line x" title="7:171	Our experiments with the Chinese Treebank show that the accuracy of the conditional model is 13.6% higher than the joint model and that the strictly lexicalized conditional model outperforms the corresponding unlexicalized model based on part-of-speech tags." ></td>
	<td class="line x" title="8:171	1 Introduction There has been a great deal of progress in statistical parsing in the past decade (Collins, 1996; Collins, 1997; Chaniak, 2000)." ></td>
	<td class="line x" title="9:171	A common characteristic of these parsers is their use of lexicalized statistics." ></td>
	<td class="line x" title="10:171	However, it was discovered recently that bi-lexical statistics (parameters that involve two words) actually played much smaller role than previously believed." ></td>
	<td class="line x" title="11:171	It was found in (Gildea, 2001) that the removal of bi-lexical statistics from a state-of-the-art PCFG parser resulted very small change in the output." ></td>
	<td class="line x" title="12:171	Bikel (2004) observed that the bi-lexical statistics accounted for only 1.49% of the bigram statistics used by the parser." ></td>
	<td class="line x" title="13:171	When considering only bigram statistics involved in the highest probability parse, this percentage becomes 28.8%." ></td>
	<td class="line x" title="14:171	However, even when the bi-lexical statistics do get used, they are remarkably similar to their back-off values using part-of-speech tags." ></td>
	<td class="line x" title="15:171	Therefore, the utility of bi-lexical statistics becomes rather questionable." ></td>
	<td class="line x" title="16:171	Klein and Manning (2003) presented an unlexicalized parser that eliminated all lexicalized parameters." ></td>
	<td class="line x" title="17:171	Its performance was close to the state-of-the-art lexicalized parsers." ></td>
	<td class="line x" title="18:171	We present a statistical dependency parser that represents the other end of spectrum where all statistical parameters are lexical and the parser does not require part-of-speech tags or grammatical categories." ></td>
	<td class="line x" title="19:171	We call this strictly lexicalized parsing." ></td>
	<td class="line x" title="20:171	A part-of-speech lexicon has always been considered to be a necessary component in any natural language parser." ></td>
	<td class="line x" title="21:171	This is true in early rule-based as well as modern statistical parsers and in dependency parsers as well as constituency parsers." ></td>
	<td class="line x" title="22:171	The need for part-of-speech tags arises from the sparseness of natural language data." ></td>
	<td class="line x" title="23:171	They provide generalizations of words that are critical for parsers to deal with the sparseness." ></td>
	<td class="line x" title="24:171	Words belonging to the same part-of-speech are expected to have the same syntactic behavior." ></td>
	<td class="line x" title="25:171	Instead of part-of-speech tags, we rely on distributional word similarities computed automatically from a large unannotated text corpus." ></td>
	<td class="line x" title="26:171	One of the benefits of strictly lexicalized parsing is that 152 fundsinvestors continue to pour cash into moneyMany 01 2 3 456 78 9 the parser can be trained with a treebank that only contains the dependency relationships between words." ></td>
	<td class="line x" title="27:171	The annotators do not need to annotate parts-of-speech or non-terminal symbols (they dont even have to know about them), making the construction of the treebank easier." ></td>
	<td class="line x" title="28:171	Strictly lexicalized parsing is especially beneficial for languages such as Chinese, where partsof-speech are not as clearly defined as English." ></td>
	<td class="line x" title="29:171	In Chinese, clear indicators of a word's part-ofspeech such as suffixes -ment, -ous or function words such as the, are largely absent." ></td>
	<td class="line x" title="30:171	In fact, monolingual Chinese dictionaries that are mainly intended for native speakers almost never contain part-of-speech information." ></td>
	<td class="line x" title="31:171	In the next section, we present a method for modeling the probabilities of dependency trees." ></td>
	<td class="line x" title="32:171	Section 3 applies similarity-based smoothing to the probability model to deal with data sparseness." ></td>
	<td class="line x" title="33:171	We then present experimental results with the Chinese Treebank in Section 4 and discuss related work in Section 5." ></td>
	<td class="line x" title="34:171	2 A Probabilistic Dependency Model Let S be a sentence." ></td>
	<td class="line x" title="35:171	The dependency structure T of S is a directed tree connecting the words in S. Each link in the tree represents a dependency relationship between two words, known as the head and the modifier." ></td>
	<td class="line x" title="36:171	The direction of the link is from the head to the modifier." ></td>
	<td class="line x" title="37:171	We add an artificial root node () at the beginning of each sentence and a dependency link from  to the head of the sentence so that the head of the sentence can be treated in the same way as other words." ></td>
	<td class="line x" title="38:171	Figure 1 shows an example dependency tree." ></td>
	<td class="line x" title="39:171	We denote a dependency link l by a triple (u, v, d), where u and v are the indices (u < v) of the words connected by l, and d specifies the direction of the link l. The value of d is either L or R. If d = L, v is the index of the head word; otherwise, u is the index of the head word." ></td>
	<td class="line x" title="40:171	Dependency trees are typically assumed to be projective (without crossing arcs), which means that if there is an arc from h to m, h is an ancestor of all the words between h and m. Let F(S) be the set of possible directed, projective trees spanning on S. The parsing problem is to find () ( )STP SFT |maxarg  Generative parsing models are usually defined recursively from top down, even though the decoders (parsers) for such models almost always take a bottom-up approach." ></td>
	<td class="line x" title="41:171	The model proposed here is a bottom-up one." ></td>
	<td class="line x" title="42:171	Like previous approaches, we decompose the generation of a parse tree into a sequence of steps and define the probability of each step." ></td>
	<td class="line x" title="43:171	The probability of the tree is simply the product of the probabilities of the steps involved in the generation process." ></td>
	<td class="line x" title="44:171	This scheme requires that different sequences of steps must not lead to the same tree." ></td>
	<td class="line x" title="45:171	We achieve this by defining a canonical ordering of the links in a dependency tree." ></td>
	<td class="line x" title="46:171	Each generation step corresponds to the construction of a dependency link in the canonical order." ></td>
	<td class="line x" title="47:171	Given two dependency links l and l' with the heads being h and h' and the modifiers being m and m', respectively, the order between l and l' are determined as follows:  If h  h' and there is a directed path from one (say h) to the other (say h), then l precedes l.  If h  h' and there does not exist a directed path between h and h, the order between l and l is determined by the order of h and h in the sentence (h precedes h  l precedes l)." ></td>
	<td class="line x" title="48:171	 If h = h' and the modifiers m and m are on different sides of h, the link with modifier on the right precedes the other." ></td>
	<td class="line x" title="49:171	 If h = h' and the modifiers m and m are on the same side of the head h, the link with its modifier closer to h precedes the other one." ></td>
	<td class="line x" title="50:171	Figure 1." ></td>
	<td class="line x" title="51:171	An Example Dependency Tree." ></td>
	<td class="line x" title="52:171	153 For example, the canonical order of the links in the dependency tree in Figure 1 is: (1, 2, L), (5, 6, R), (8, 9, L), (7, 9, R), (5, 7, R), (4, 5, R), (3, 4, R), (2, 3, L), (0, 3, L)." ></td>
	<td class="line x" title="53:171	The generation process according to the canonical order is similar to the head outward generation process in (Collins, 1999), except that it is bottom-up whereas Collins models are top-down." ></td>
	<td class="line x" title="54:171	Suppose the dependency tree T is constructed in steps G 1, , G N in the canonical order of the dependency links, where N is the number of words in the sentence." ></td>
	<td class="line x" title="55:171	We can compute the probability of T as follows: () ()  =  = = N i ii N GGSGP SGGGP STP 1 11 21,,,| |,,, | Following (Klein and Manning, 2004), we require that the creation of a dependency link from head h to modifier m be preceded by placing a left STOP and a right STOP around the modifier m and STOP between h and m. Let L w E (and R w E ) denote the event that there are no more modifiers on the left (and right) of a word w. Suppose the dependency link created in the step i is (u, v, d)." ></td>
	<td class="line x" title="56:171	If d = L, G i is the conjunction of the four events: R u E, L u E, L v E and link L (u, v)." ></td>
	<td class="line x" title="57:171	If d = R, G i consists of four events: L v E, R v E, R u E and link R (u, v)." ></td>
	<td class="line x" title="58:171	The event G i is conditioned on 11,,, i GGS, which are the words in the sentence and a forest of trees constructed up to step i-1." ></td>
	<td class="line x" title="59:171	Let L w C (and R w C ) be the number of modifiers of w on its left (and right)." ></td>
	<td class="line x" title="60:171	We make the following independence assumptions:  Whether there is any more modifier of w on the d side depends only on the number of modifiers already found on the d side of w. That is, d w E depends only on w and d w C.  Whether there is a dependency link from a word h to another word m depends only on the words h and m and the number of modifiers of h between m and h. That is, o link R (u,v) depends only on u, v, and R u C . o link L (u,v) depends only on u, v, and L v C . Suppose G i corresponds to a dependency link (u, v, L)." ></td>
	<td class="line x" title="61:171	The probability ( ) 11,,,| ii GGSGP can be computed as: ( ) ()() ()() ()() L vL L v L v R u R u L u L u iL L v R u L u ii CvuvulinkPCvEP CuEPCuEP GGSvulinkEEEP GGSGP,,|,,|1,|,|,,,|,,,,,,,| 11 11  = =   The events R w E and L w E correspond to the STOP events in (Collins, 1999) and (Klein and Manning, 2004)." ></td>
	<td class="line x" title="62:171	They are crucial for modeling the number of dependents." ></td>
	<td class="line x" title="63:171	Without them, the parse trees often contain some obvious errors, such as determiners taking arguments, or prepositions having arguments on their left (instead of right)." ></td>
	<td class="line x" title="64:171	Our model requires three types of parameters:  ( ) d w d w CwEP,|, where w is a word, d is a direction (left or right)." ></td>
	<td class="line x" title="65:171	This is the probability of a STOP after taking d w C modifiers on the d side." ></td>
	<td class="line x" title="66:171	 ( )( ) R uR CvuvulinkP,,|, is the probability of v being the ( 1+ R u C )th modifier of u on the right." ></td>
	<td class="line x" title="67:171	 ( )( ) L vL CvuvulinkP,,|, is the probability of u being the ( 1+ L v C )th modifier of v on the left." ></td>
	<td class="line x" title="68:171	The Maximum Likelihood estimations of these parameters can be obtained from the frequency counts in the training corpus:  C(w, c, d): the frequency count of w with c modifiers on the d side." ></td>
	<td class="line x" title="69:171	 C(u, v, c, d): If d = L, this is the frequency count words u and v co-occurring in a sentence and v has c modifiers between itself and u. If d = R, this is the frequency count words u and v co-occurring in a sentence and u has c modifiers between itself and v.  K(u, v, c, d): similar to C(u, v, c, d) with an additional constraint that link d (u, v) is true." ></td>
	<td class="line x" title="70:171	154 () () ()   = cc d w d w dcwC dcwC CwEP ',',,,,|, where c = d w C ; () () ()RcvuC RcvuK CvuvulinkP R uR,,,,,,,,|, =, where c = R u C ; () () ()LcvuC LcvuK CvuvulinkP L vL,,,,,,,,|, =, where c = L v C . We compute the probability of the tree conditioned on the words." ></td>
	<td class="line x" title="71:171	All parameters in our model are conditional probabilities where the left sides of the conditioning bar are binary variables." ></td>
	<td class="line x" title="72:171	In contrast, most previous approaches compute joint probability of the tree and the words in the tree." ></td>
	<td class="line x" title="73:171	Many of their model parameters consist of the probability of a word in a given context." ></td>
	<td class="line x" title="74:171	We use a dynamic programming algorithm similar to chart parsing as the decoder for this model." ></td>
	<td class="line x" title="75:171	The algorithm builds a packed parse forest from bottom up in the canonical order of the parser trees." ></td>
	<td class="line x" title="76:171	It attaches all the right children before attaching the left ones to maintain the canonical order as required by our model." ></td>
	<td class="line x" title="77:171	3 Similarity-based Smoothing 3.1 Distributional Word Similarity Words that tend to appear in the same contexts tend to have similar meanings." ></td>
	<td class="line x" title="78:171	This is known as the Distributional Hypothesis in linguistics (Harris, 1968)." ></td>
	<td class="line oc" title="79:171	For example, the words test and exam are similar because both of them follow verbs such as administer, cancel, cheat on, conduct,  and both of them can be preceded by adjectives such as academic, comprehensive, diagnostic, difficult,  Many methods have been proposed to compute distributional similarity between words (Hindle, 1990; Pereira et al. , 1993; Grefenstette, 1994; Lin, 1998)." ></td>
	<td class="line o" title="80:171	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared." ></td>
	<td class="line o" title="81:171	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed." ></td>
	<td class="line x" title="82:171	We define the features of a word w to be the set of words that occurred within a small context window of w in a large corpus." ></td>
	<td class="line x" title="83:171	The context window of an instance of w consists of the closest nonstop-word on each side of w and the stop-words in between." ></td>
	<td class="line x" title="84:171	In our experiments, the set of stop-words are defined as the top 100 most frequent words in the corpus." ></td>
	<td class="line x" title="85:171	The value of a feature w' is defined as the point-wise mutual information between the w' and w: () () ()()         = ' ', log', wPwP wwP wwPMI where P(w, w) is the probability of w and w cooccur in a context window." ></td>
	<td class="line x" title="86:171	The similarity between two vectors is computed as the cosine of the angle between the vectors." ></td>
	<td class="line x" title="87:171	The following are the top similar words for the word keystone obtained from the English Gigaword Corpus: centrepiece 0.28, figment 0.27, fulcrum 0.21, culmination 0.20, albatross 0.19, bane 0.19, pariahs 0.18, lifeblood 0.18, crux 0.18, redoubling 0.17, apotheosis 0.17, cornerstones 0.17, perpetuation 0.16, forerunners 0.16, shirking 0.16, cornerstone 0.16, birthright 0.15, hallmark 0.15, centerpiece 0.15, evidenced 0.15, germane 0.15, gist 0.14, reassessing 0.14, engrossed 0.14, Thorn 0.14, biding 0.14, narrowness 0.14, linchpin 0.14, enamored 0.14, formalised 0.14, tenths 0.13, testament 0.13, certainties 0.13, forerunner 0.13, re-evaluating 0.13, antithetical 0.12, extinct 0.12, rarest 0.12, imperiled 0.12, remiss 0.12, hindrance 0.12, detriment 0.12, prouder 0.12, upshot 0.12, cosponsor 0.12, hiccups 0.12, premised 0.12, perversion 0.12, destabilisation 0.12, prefaced 0.11,  3.2 Similarity-based Smoothing The parameters in our model consist of conditional probabilities P(E|C) where E is the binary variable link d (u, v) or d w E and the context C is either [ ] d w Cw, or [ ] d w Cvu,,, which involves one or two words in the input sentence." ></td>
	<td class="line x" title="88:171	Due to the sparseness of natural language data, the contexts observed in the training data only covers a tiny fraction of the contexts whose probability distribution are needed during parsing." ></td>
	<td class="line x" title="89:171	The standard approach is to back off the probability to word classes (such as part-of-speech tags)." ></td>
	<td class="line x" title="90:171	We have taken a different approach." ></td>
	<td class="line x" title="91:171	We search in the train155 ing data to find a set of similar contexts to C and estimate the probability of E based on its probabilities in the similar contexts that are observed in the training corpus." ></td>
	<td class="line x" title="92:171	Similarity-based smoothing was used in (Dagan et al. , 1999) to estimate word co-occurrence probabilities." ></td>
	<td class="line x" title="93:171	Their method performed almost 40% better than the more commonly used back-off method." ></td>
	<td class="line x" title="94:171	Unfortunately, similarity-based smoothing has not been successfully applied to statistical parsing up to now." ></td>
	<td class="line x" title="95:171	In (Dagan et al. , 1999), the bigram probability P(w 2 |w 1 ) is computed as the weighted average of the conditional probability of w 2 given similar words of w 1 ." ></td>
	<td class="line x" title="96:171	() () () () ()   = 11 ' 12 1 11 12 '| ', | wSw MLESIM wwP wnorm wwsim wwP where () 11 ', wwsim denotes the similarity (or an increasing function of the similarity) between w 1 and w 1, S(w 1 ) denote the set of words that are most similar to w 1 and norm(w 1 ) is the normalization factor () ( ) ()   = 11 ' 111 ', wSw wwsimwnorm . The underlying assumption of this smoothing scheme is that a word is more likely to occur after w 1 if it tends to occur after similar words of w 1 . We make a similar assumption: the probability P(E|C) of event E given the context C is computed as the weight average of P(E|C) where C is a similar context of C and is attested in the training corpus: () () () () ()   = OCSC MLESIM CEP Cnorm CCsim CEP ' '| ', | where S(C) is the set of top-K most similar contexts of C (in the experiments reported in this paper, K = 50); O is the set of contexts observed in the training corpus, sim(C,C) is the similarity between two contexts and norm(C) is the normalization factor." ></td>
	<td class="line x" title="97:171	In our model, a context is either [ ] d w Cw, or [ ] d w Cvu,, . Their similar contexts are defined as: []()[](){ } []()[]{})('),(',',',, ',', ' vSvuSuCvuCvuS wSwCwCwS d w d w d w d w = = where S(w) is the set of top-K similar words of w (K = 50)." ></td>
	<td class="line x" title="98:171	Since all contexts used in our model contain at least one word, we compute the similarity between two contexts, sim(C, C), as the geometric average of the similarities between corresponding words: [ ][ ]( ) ( ) [][ ]()() ()',',,',',,, ',,',, ' ' vvsimuusimCvuCvusim wwsimCwCwsim d w d w d w d w = = Similarity-smoothed probability is only necessary when the frequency count of the context C in the training corpus is low." ></td>
	<td class="line x" title="99:171	We therefore compute P(E | C) =  P MLE (E | C) + (1   ) P SIM (E | C) where the smoothing factor 5|| 1|| + + = C C  and |C| is the frequency count of the context C in the training data." ></td>
	<td class="line x" title="100:171	A difference between similarity-based smoothing in (Dagan et al. , 1999) and our approach is that our model only computes probability distributions of binary variables." ></td>
	<td class="line x" title="101:171	Words only appear as parts of contexts on the right side of the conditioning bar." ></td>
	<td class="line x" title="102:171	This has two important implications." ></td>
	<td class="line x" title="103:171	Firstly, when a context contains two words, we are able to use the cross product of the similar words, whereas (Dagan et al. , 1999) can only use the similar words of one of the words." ></td>
	<td class="line x" title="104:171	This turns out to have significant impact on the performance (see Section 4)." ></td>
	<td class="line x" title="105:171	Secondly, in (Dagan et al. , 1999), the distribution P(|w 1 ) may itself be sparsely observed." ></td>
	<td class="line x" title="106:171	When ( ) 12 '| wwP MLE is 0, it is often due to data sparseness." ></td>
	<td class="line x" title="107:171	Their smoothing scheme therefore tends to under-estimate the probability values." ></td>
	<td class="line x" title="108:171	This problem is avoided in our approach." ></td>
	<td class="line x" title="109:171	If a context did not occur in the training data, we do not include it in the average." ></td>
	<td class="line x" title="110:171	If it did occur, the Maximum Likelihood estimation is reasonably accurate even if the context only occurred a few times, since the entropy of the probability distribution is upper-bounded by log 2." ></td>
	<td class="line x" title="111:171	4 Experimental Results We experimented with our parser on the Chinese Treebank (CTB) 3.0." ></td>
	<td class="line x" title="112:171	We used the same data split as (Bikel, 2004): Sections 1-270 and 400-931 as 156 the training set, Sections 271-300 as testing and Sections 301-325 as the development set." ></td>
	<td class="line x" title="113:171	The CTB contains constituency trees." ></td>
	<td class="line x" title="114:171	We converted them to dependency trees using the same method and the head table as (Bikel, 2004)." ></td>
	<td class="line x" title="115:171	Parsing Chinese generally involve segmentation as a preprocessing step." ></td>
	<td class="line x" title="116:171	We used the gold standard segmentation in the CTB." ></td>
	<td class="line x" title="117:171	The distributional similarities between the Chinese words are computed using the Chinese Gigaword corpus." ></td>
	<td class="line x" title="118:171	We did not segment the Chinese corpus when computing the word similarity." ></td>
	<td class="line x" title="119:171	We measure the quality of the parser by the undirected accuracy, which is defined as the number of correct undirected dependency links divided by the total number of dependency links in the corpus (the treebank parse and the parser output always have the same number of links)." ></td>
	<td class="line x" title="120:171	The results are summarized in Table 1." ></td>
	<td class="line x" title="121:171	It can be seen that the performance of the parser is highly correlated with the length of the sentences." ></td>
	<td class="line x" title="122:171	Max Sentence Length 10 15 20 40 Undirected Accuracy 90.8 85.6 84.0 79.9 Table 1." ></td>
	<td class="line x" title="123:171	Evaluation Results on CTB 3.0 We also experimented with several alternative models for dependency parsing." ></td>
	<td class="line x" title="124:171	Table 2 summerizes the results of these models on the test corpus with sentences up to 40 words long." ></td>
	<td class="line x" title="125:171	One of the characteristics of our parser is that it uses the similar words of both the head and the modifier for smoothing." ></td>
	<td class="line x" title="126:171	The similarity-based smoothing method in (Dagan et al. , 1999) uses the similar words of one of the words in a bigram." ></td>
	<td class="line x" title="127:171	We can change the definition of similar context as follows so that only one word in a similar context of C may be different from a word in C (see Model (b) in Table 2): [ ]( ) []{}[]{})(',',)(',,',, vSvCvuuSuCvu CvuS d w d w d w = where w is either v or u depending on whether d is L or R. This change led to a 2.2% drop in accuracy (compared with Model (a) in Table 2), which we attribute to the fact that many contexts do not have similar contexts in the training corpus." ></td>
	<td class="line x" title="128:171	Since most previous parsing models maximize the joint probability of the parse tree and the sentence P(T, S) instead of P(T | S), we also implemented a joint model (see Model (c) in Table 2): () ( ) ( ) ()()  =   = N i d hii d hi d h R mi R m L mi L m i iii iiii ChmPChEP CmEPCmEP STP 1,|,|1,|,|, where h i and m i are the head and the modifier of the i'th dependency link." ></td>
	<td class="line x" title="129:171	The probability ( ) i i d hii ChmP,| is smoothed by averaging the probabilities ( ) i i d hii ChmP,'|, where h i is a similar word of h i, as in (Dagan et al. , 1999)." ></td>
	<td class="line x" title="130:171	The result was a dramatic decrease in accuracy from the conditional models 79.9%." ></td>
	<td class="line x" title="131:171	to 66.3%." ></td>
	<td class="line x" title="132:171	Our use of distributional word similarity can be viewed as assigning soft clusters to words." ></td>
	<td class="line x" title="133:171	In contrast, parts-of-speech can be viewed as hard clusters of words." ></td>
	<td class="line x" title="134:171	We can modify both the conditional and joint models to use part-of-speech tags, instead of words." ></td>
	<td class="line x" title="135:171	Since there are only a small number of tags, the modified models used MLE without any smoothing except using a small constant as the probability of unseen events." ></td>
	<td class="line x" title="136:171	Without smoothing, maximizing the conditional model is equivalent to maximizing the joint model." ></td>
	<td class="line x" title="137:171	The accuracy of the unlexicalized models (see Model (d) and Model (e) in Table 2) is 71.1% which is considerably lower than the strictly lexicalized conditional model, but higher than the strictly lexicalized joint model." ></td>
	<td class="line x" title="138:171	This demonstrated that soft clusters obtained through distributional word similarity perform better than the part-of-speech tags when used appropriately." ></td>
	<td class="line x" title="139:171	Models Accuracy (a) Strictly lexicalized conditional model 79.9 (b) At most one word is different in a similar context 77.7 (c) Strictly lexicalized joint model 66.3 (d) Unlexicalized conditional models 71.1 (e) Unlexicalized joint models 71.1 Table 2." ></td>
	<td class="line x" title="140:171	Performance of Alternative Models 157 5 Related Work Previous parsing models (e.g. , Collins, 1997; Charniak, 2000) maximize the joint probability P(S, T) of a sentence S and its parse tree T. We maximize the conditional probability P(T | S)." ></td>
	<td class="line x" title="141:171	Although they are theoretically equivalent, the use of conditional model allows us to take advantage of similarity-based smoothing." ></td>
	<td class="line x" title="142:171	Clark et al.(2002) also computes a conditional probability of dependency structures." ></td>
	<td class="line x" title="144:171	While the probability space in our model consists of all possible non-projective dependency trees, their probability space is constrained to all the dependency structures that are allowed by a Combinatorial Category Grammar (CCG) and a category dictionary (lexicon)." ></td>
	<td class="line x" title="145:171	They therefore do not need the STOP markers in their model." ></td>
	<td class="line x" title="146:171	Another major difference between our model and (Clark et al. , 2002) is that the parameters in our model consist exclusively of conditional probabilities of binary variables." ></td>
	<td class="line x" title="147:171	Ratnaparkhis maximum entropy model (Ratnaparkhi, 1999) is also a conditional model." ></td>
	<td class="line x" title="148:171	However, his model maximizes the probability of the action during each step of the parsing process, instead of overall quality of the parse tree." ></td>
	<td class="line x" title="149:171	Yamada and Matsumoto (2002) presented a dependency parsing model using support vector machines." ></td>
	<td class="line x" title="150:171	Their model is a discriminative model that maximizes the differences between scores of the correct parse and the scores of the top competing incorrect parses." ></td>
	<td class="line x" title="151:171	In many dependency parsing models such as (Eisner, 1996) and (MacDonald et al. , 2005), the score of a dependency tree is the sum of the scores of the dependency links, which are computed independently of other links." ></td>
	<td class="line x" title="152:171	An undesirable consequence of this is that the parser often creates multiple dependency links that are separately likely but jointly improbable (or even impossible)." ></td>
	<td class="line x" title="153:171	For example, there is nothing in such models to prevent the parser from assigning two subjects to a verb." ></td>
	<td class="line x" title="154:171	In the DMV model (Klein and Manning, 2004), the probability of a dependency link is partly conditioned on whether or not there is a head word of the link already has a modifier." ></td>
	<td class="line x" title="155:171	Our model is quite similar to the DMV model, except that we compute the conditional probability of the parse tree given the sentence, instead of the joint probability of the parse tree and the sentence." ></td>
	<td class="line x" title="156:171	There have been several previous approaches to parsing Chinese with the Penn Chinese Treebank (e.g. , Bikel and Chiang, 2000; Levy and Manning, 2003)." ></td>
	<td class="line x" title="157:171	Both of these approaches employed phrasestructure joint models and used part-of-speech tags in back-off smoothing." ></td>
	<td class="line x" title="158:171	Their results were evaluated with the precision and recall of the bracketings implied in the phrase structure parse trees." ></td>
	<td class="line x" title="159:171	In contrast, the accuracy of our model is measured in terms of the dependency relationships." ></td>
	<td class="line x" title="160:171	A dependency tree may correspond to more than one constituency trees." ></td>
	<td class="line x" title="161:171	Our results are therefore not directly comparable with the precision and recall values in previous research." ></td>
	<td class="line x" title="162:171	Moreover, it was argued in (Lin 1995) that dependency based evaluation is much more meaningful for the applications that use parse trees, since the semantic relationships are generally embedded in the dependency relationships." ></td>
	<td class="line x" title="163:171	6 Conclusion To the best of our knowledge, all previous natural language parsers have to rely on part-of-speech tags." ></td>
	<td class="line x" title="164:171	We presented a strictly lexicalized model for dependency parsing that only relies on word statistics." ></td>
	<td class="line x" title="165:171	We compared our parser with an unlexicalized parser that employs the same probabilistic model except that the parameters are estimated using gold standard tags in the Chinese Treebank." ></td>
	<td class="line x" title="166:171	Our experiments show that the strictly lexicalized parser significantly outperformed its unlexicalized counter-part." ></td>
	<td class="line x" title="167:171	An important distinction between our statistical model from previous parsing models is that all the parameters in our model are conditional probability of binary variables." ></td>
	<td class="line x" title="168:171	This allows us to take advantage of similarity-based smoothing, which has not been successfully applied to parsing before." ></td>
	<td class="line x" title="169:171	Acknowledgements The authors would like to thank Mark Steedman for suggesting the comparison with unlexicalized parsing in Section 4 and the anonymous reviewers for their comments." ></td>
	<td class="line x" title="170:171	This work was supported in part by NSERC, the Alberta Ingenuity Centre for Machine Learning and the Canada Research 158 Chairs program." ></td>
	<td class="line x" title="171:171	Qin Iris Wang was also supported by iCORE Scholarship." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-1015
Espresso: Leveraging Generic Patterns For Automatically Harvesting Semantic Relations
Pantel, Patrick;Pennacchiotti, Marco;"></td>
	<td class="line x" title="1:192	Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 113120, Sydney, July 2006." ></td>
	<td class="line x" title="2:192	c2006 Association for Computational Linguistics Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations Patrick Pantel Information Sciences Institute University of Southern California 4676 Admiralty Way Marina del Rey, CA 90292 pantel@isi.edu Marco Pennacchiotti ART Group DISP University of Rome Tor Vergata Viale del Politecnico 1 Rome, Italy pennacchiotti@info.uniroma2.it Abstract In this paper, we present Espresso, a weakly-supervised, general-purpose, and accurate algorithm for harvesting semantic relations." ></td>
	<td class="line x" title="3:192	The main contributions are: i) a method for exploiting generic patterns by filtering incorrect instances using the Web; and ii) a principled measure of pattern and instance reliability enabling the filtering algorithm." ></td>
	<td class="line x" title="4:192	We present an empirical comparison of Espresso with various state of the art systems, on different size and genre corpora, on extracting various general and specific relations." ></td>
	<td class="line x" title="5:192	Experimental results show that our exploitation of generic patterns substantially increases system recall with small effect on overall precision." ></td>
	<td class="line x" title="6:192	1 Introduction Recent attention to knowledge-rich problems such as question answering (Pasca and Harabagiu 2001) and textual entailment (Geffet and Dagan 2005) has encouraged natural language processing researchers to develop algorithms for automatically harvesting shallow semantic resources." ></td>
	<td class="line x" title="7:192	With seemingly endless amounts of textual data at our disposal, we have a tremendous opportunity to automatically grow semantic term banks and ontological resources." ></td>
	<td class="line oc" title="8:192	To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al. 2005), and word similarity lists (Hindle 1990)." ></td>
	<td class="line x" title="9:192	Many recent efforts have also focused on extracting semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2006), and other relations." ></td>
	<td class="line x" title="10:192	The following desiderata outline the properties of an ideal relation harvesting algorithm:  Performance: it must generate both high precision and high recall relation instances;  Minimal supervision: it must require little or no human annotation;  Breadth: it must be applicable to varying corpus sizes and domains; and  Generality: it must be applicable to a wide variety of relations (i.e. , not just is-a or part-of)." ></td>
	<td class="line n" title="11:192	To our knowledge, no previous harvesting algorithm addresses all these properties concurrently." ></td>
	<td class="line x" title="12:192	In this paper, we present Espresso, a generalpurpose, broad, and accurate corpus harvesting algorithm requiring minimal supervision." ></td>
	<td class="line x" title="13:192	The main algorithmic contribution is a novel method for exploiting generic patterns, which are broad coverage noisy patterns  i.e., patterns with high recall and low precision." ></td>
	<td class="line x" title="14:192	Insofar, difficulties in using these patterns have been a major impediment for minimally supervised algorithms resulting in either very low precision or recall." ></td>
	<td class="line x" title="15:192	We propose a method to automatically detect generic patterns and to separate their correct and incorrect instances." ></td>
	<td class="line x" title="16:192	The key intuition behind the algorithm is that given a set of reliable (high precision) patterns on a corpus, correct instances of a generic pattern will fire more with reliable patterns on a very large corpus, like the Web, than incorrect ones." ></td>
	<td class="line x" title="17:192	Below is a summary of the main contributions of this paper:  Algorithm for exploiting generic patterns: Unlike previous algorithms that require significant manual work to make use of generic patterns, we propose an unsupervised Webfiltering method for using generic patterns; and  Principled reliability measure: We propose a new measure of pattern and instance reliability which enables the use of generic patterns." ></td>
	<td class="line x" title="18:192	113 Espresso addresses the desiderata as follows:  Performance: Espresso generates balanced precision and recall relation instances by exploiting generic patterns;  Minimal supervision: Espresso requires as input only a small number of seed instances;  Breadth: Espresso works on both small and large corpora  it uses Web and syntactic expansions to compensate for lacks of redundancy in small corpora;  Generality: Espresso is amenable to a wide variety of binary relations, from classical is-a and part-of to specific ones such as reaction and succession." ></td>
	<td class="line x" title="19:192	Previous work like (Girju et al. 2006) that has made use of generic patterns through filtering has shown both high precision and high recall, at the expensive cost of much manual semantic annotation." ></td>
	<td class="line x" title="20:192	Minimally supervised algorithms, like (Hearst 1992; Pantel et al. 2004), typically ignore generic patterns since system precision dramatically decreases from the introduced noise and bootstrapping quickly spins out of control." ></td>
	<td class="line x" title="21:192	2 Relevant Work To date, most research on relation harvesting has focused on is-a and part-of." ></td>
	<td class="line x" title="22:192	Approaches fall into two categories: patternand clustering-based." ></td>
	<td class="line x" title="23:192	Most common are pattern-based approaches." ></td>
	<td class="line x" title="24:192	Hearst (1992) pioneered using patterns to extract hyponym (is-a) relations." ></td>
	<td class="line x" title="25:192	Manually building three lexico-syntactic patterns, Hearst sketched a bootstrapping algorithm to learn more patterns from instances, which has served as the model for most subsequent pattern-based algorithms." ></td>
	<td class="line x" title="26:192	Berland and Charniak (1999) proposed a system for part-of relation extraction, based on the (Hearst 1992) approach." ></td>
	<td class="line x" title="27:192	Seed instances are used to infer linguistic patterns that are used to extract new instances." ></td>
	<td class="line x" title="28:192	While this study introduces statistical measures to evaluate instance quality, it remains vulnerable to data sparseness and has the limitation of considering only one-word terms." ></td>
	<td class="line x" title="29:192	Improving upon (Berland and Charniak 1999), Girju et al.(2006) employ machine learning algorithms and WordNet (Fellbaum 1998) to disambiguate part-of generic patterns like Xs Y and X of Y." ></td>
	<td class="line x" title="31:192	This study is the first extensive attempt to make use of generic patterns." ></td>
	<td class="line x" title="32:192	In order to discard incorrect instances, they learn WordNetbased selectional restrictions, like X(scene#4)s Y(movie#1)." ></td>
	<td class="line x" title="33:192	While making huge grounds on improving precision/recall, heavy supervision is required through manual semantic annotations." ></td>
	<td class="line x" title="34:192	Ravichandran and Hovy (2002) focus on scaling relation extraction to the Web." ></td>
	<td class="line x" title="35:192	A simple and effective algorithm is proposed to infer surface patterns from a small set of instance seeds by extracting substrings relating seeds in corpus sentences." ></td>
	<td class="line x" title="36:192	The approach gives good results on specific relations such as birthdates, however it has low precision on generic ones like is-a and partof." ></td>
	<td class="line x" title="37:192	Pantel et al.(2004) proposed a similar, highly scalable approach, based on an edit-distance technique, to learn lexico-POS patterns, showing both good performance and efficiency." ></td>
	<td class="line x" title="39:192	Espresso uses a similar approach to infer patterns, but we make use of generic patterns and apply refining techniques to deal with wide variety of relations." ></td>
	<td class="line x" title="40:192	Other pattern-based algorithms include (Riloff and Shepherd 1997), who used a semi-automatic method for discovering similar words using a few seed examples, KnowItAll (Etzioni et al. 2005) that performs large-scale extraction of facts from the Web, Mann (2002) who used part of speech patterns to extract a subset of is-a relations involving proper nouns, and (Downey et al. 2005) who formalized the problem of relation extraction in a coherent and effective combinatorial model that is shown to outperform previous probabilistic frameworks." ></td>
	<td class="line x" title="41:192	Clustering approaches have so far been applied only to is-a extraction." ></td>
	<td class="line x" title="42:192	These methods use clustering algorithms to group words according to their meanings in text, label the clusters using its members lexical or syntactic dependencies, and then extract an is-a relation between each cluster member and the cluster label." ></td>
	<td class="line x" title="43:192	Caraballo (1999) proposed the first attempt, which used conjunction and apposition features to build noun clusters." ></td>
	<td class="line x" title="44:192	Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun." ></td>
	<td class="line x" title="45:192	The advantage of clustering approaches is that they permit algorithms to identify is-a relations that do not explicitly appear in text, however they generally fail to produce coherent clusters from fewer than 100 million words; hence they are unreliable for small corpora." ></td>
	<td class="line x" title="46:192	3 The Espresso Algorithm Espresso is based on the framework adopted in (Hearst 1992)." ></td>
	<td class="line x" title="47:192	It is a minimally supervised bootstrapping algorithm that takes as input a few seed instances of a particular relation and iteratively learns surface patterns to extract more instances." ></td>
	<td class="line x" title="48:192	The key to Espresso lies in its use of generic patters, i.e., those broad coverage noisy patterns that 114 extract both many correct and incorrect relation instances." ></td>
	<td class="line x" title="49:192	For example, for part-of relations, the pattern X of Y extracts many correct relation instances like wheel of the car but also many incorrect ones like house of representatives." ></td>
	<td class="line x" title="50:192	The key assumption behind Espresso is that in very large corpora, like the Web, correct instances generated by a generic pattern will be instantiated by some reliable patterns, where reliable patterns are patterns that have high precision but often very low recall (e.g. , X consists of Y for part-of relations)." ></td>
	<td class="line x" title="51:192	In this section, we describe the overall architecture of Espresso, propose a principled measure of reliability, and give an algorithm for exploiting generic patterns." ></td>
	<td class="line x" title="52:192	3.1 System Architecture Espresso iterates between the following three phases: pattern induction, pattern ranking/selection, and instance extraction." ></td>
	<td class="line x" title="53:192	The algorithm begins with seed instances of a particular binary relation (e.g. , is-a) and then iterates through the phases until it extracts  1 patterns or the average pattern score decreases by more than  2 from the previous iteration." ></td>
	<td class="line x" title="54:192	In our experiments, we set  1 = 5 and  2 = 50%." ></td>
	<td class="line x" title="55:192	For our tokenization, in order to harvest multiword terms as relation instances, we adopt a slightly modified version of the term definition given in (Justeson 1995), as it is one of the most commonly used in the NLP literature: ((Adj|Noun)+|((Adj|Noun)*(NounPrep)?)(Adj|Noun)*)Noun Pattern Induction In the pattern induction phase, Espresso infers a set of surface patterns P that connects as many of the seed instances as possible in a given corpus." ></td>
	<td class="line x" title="56:192	Any pattern learning algorithm would do." ></td>
	<td class="line x" title="57:192	We chose the state of the art algorithm described in (Ravichandran and Hovy 2002) with the following slight modification." ></td>
	<td class="line x" title="58:192	For each input instance {x, y}, we first retrieve all sentences containing the two terms x and y. The sentences are then generalized into a set of new sentences S x,y by replacing all terminological expressions by a terminological label, TR." ></td>
	<td class="line x" title="59:192	For example: Because/IN HF/NNP is/VBZ a/DT weak/JJ acid/NN and/CC x is/VBZ a/DT y is generalized as: Because/IN TR is/VBZ a/DT TR and/CC x is/VBZ a/DT y Term generalization is useful for small corpora to ease data sparseness." ></td>
	<td class="line x" title="60:192	Generalized patterns are naturally less precise, but this is ameliorated by our filtering step described in Section 3.3." ></td>
	<td class="line x" title="61:192	As in the original algorithm, all substrings linking terms x and y are then extracted from S x,y, and overall frequencies are computed to form P. Pattern Ranking/Selection In (Ravichandran and Hovy 2002), a frequency threshold on the patterns in P is set to select the final patterns." ></td>
	<td class="line x" title="62:192	However, low frequency patterns may in fact be very good." ></td>
	<td class="line x" title="63:192	In this paper, instead of frequency, we propose a novel measure of pattern reliability, r , which is described in detail in Section 3.2." ></td>
	<td class="line x" title="64:192	Espresso ranks all patterns in P according to reliability r  and discards all but the top-k, where k is set to the number of patterns from the previous iteration plus one." ></td>
	<td class="line x" title="65:192	In general, we expect that the set of patterns is formed by those of the previous iteration plus a new one." ></td>
	<td class="line x" title="66:192	Yet, new statistical evidence can lead the algorithm to discard a pattern that was previously discovered." ></td>
	<td class="line x" title="67:192	Instance Extraction In this phase, Espresso retrieves from the corpus the set of instances I that match any of the patterns in P. In Section 3.2, we propose a principled measure of instance reliability, r , for ranking instances." ></td>
	<td class="line x" title="68:192	Next, Espresso filters incorrect instances using the algorithm proposed in Section 3.3 and then selects the highest scoring m instances, according to r , as input for the subsequent iteration." ></td>
	<td class="line x" title="69:192	We experimentally set m=200." ></td>
	<td class="line x" title="70:192	In small corpora, the number of extracted instances can be too low to guarantee sufficient statistical evidence for the pattern discovery phase of the next iteration." ></td>
	<td class="line x" title="71:192	In such cases, the system enters an expansion phase, where instances are expanded as follows: Web expansion: New instances of the patterns in P are retrieved from the Web, using the Google search engine." ></td>
	<td class="line x" title="72:192	Specifically, for each instance {x, y} I, the system creates a set of queries, using each pattern in P instantiated with y. For example, given the instance Italy, country and the pattern Y such as X, the resulting Google query will be country such as *." ></td>
	<td class="line x" title="73:192	New instances are then created from the retrieved Web results (e.g. Canada, country) and added to I. The noise generated from this expansion is attenuated by the filtering algorithm described in Section 3.3." ></td>
	<td class="line x" title="74:192	Syntactic expansion: New instances are created from each instance {x, y} I by extracting sub-terminological expressions from x corresponding to the syntactic head of terms." ></td>
	<td class="line x" title="75:192	For ex115 ample, the relation new record of a criminal conviction part-of FBI report expands to: new record part-of FBI report, and record part-of FBI report." ></td>
	<td class="line x" title="76:192	3.2 Pattern and Instance Reliability Intuitively, a reliable pattern is one that is both highly precise and one that extracts many instances." ></td>
	<td class="line x" title="77:192	The recall of a pattern p can be approximated by the fraction of input instances that are extracted by p. Since it is non-trivial to estimate automatically the precision of a pattern, we are wary of keeping patterns that generate many instances (i.e. , patterns that generate high recall but potentially disastrous precision)." ></td>
	<td class="line x" title="78:192	Hence, we desire patterns that are highly associated with the input instances." ></td>
	<td class="line x" title="79:192	Pointwise mutual information (Cover and Thomas 1991) is a commonly used metric for measuring this strength of association between two events x and y: () () ()()yPxP yxP yxpmi, log, = We define the reliability of a pattern p, r  (p), as its average strength of association across each input instance i in I, weighted by the reliability of each instance i: () () I ir pipmi pr Ii pmi            =   max ),( where r  (i) is the reliability of instance i (defined below) and max pmi is the maximum pointwise mutual information between all patterns and all instances." ></td>
	<td class="line x" title="80:192	r  (p) ranges from [0,1]." ></td>
	<td class="line x" title="81:192	The reliability of the manually supplied seed instances are r  (i) = 1." ></td>
	<td class="line x" title="82:192	The pointwise mutual information between instance i = {x, y} and pattern p is estimated using the following formula: (),**,,*,,, log, pyx ypx pipmi = where |x, p, y| is the frequency of pattern p instantiated with terms x and y and where the asterisk (*) represents a wildcard." ></td>
	<td class="line x" title="83:192	A well-known problem is that pointwise mutual information is biased towards infrequent events." ></td>
	<td class="line x" title="84:192	We thus multiply pmi(i, p) with the discounting factor suggested in (Pantel and Ravichandran 2004)." ></td>
	<td class="line x" title="85:192	Estimating the reliability of an instance is similar to estimating the reliability of a pattern." ></td>
	<td class="line x" title="86:192	Intuitively, a reliable instance is one that is highly associated with as many reliable patterns as possible (i.e. , we have more confidence in an instance when multiple reliable patterns instantiate it)." ></td>
	<td class="line x" title="87:192	Hence, analogous to our pattern reliability measure, we define the reliability of an instance i, r  (i), as: () () P pr pipmi ir Pp pmi    =   max ),( where r  (p) is the reliability of pattern p (defined earlier) and max pmi is as before." ></td>
	<td class="line x" title="88:192	Note that r  (i) and r  (p) are recursively defined, where r  (i) = 1 for the manually supplied seed instances." ></td>
	<td class="line x" title="89:192	3.3 Exploiting Generic Patterns Generic patterns are high recall / low precision patterns (e.g, the pattern X of Y can ambiguously refer to a part-of, is-a and possession relations)." ></td>
	<td class="line x" title="90:192	Using them blindly increases system recall while dramatically reducing precision." ></td>
	<td class="line x" title="91:192	Minimally supervised algorithms have typically ignored them for this reason." ></td>
	<td class="line x" title="92:192	Only heavily supervised approaches, like (Girju et al. 2006) have successfully exploited them." ></td>
	<td class="line x" title="93:192	Espressos recall can be significantly increased by automatically separating correct instances extracted by generic patterns from incorrect ones." ></td>
	<td class="line x" title="94:192	The challenge is to harness the expressive power of the generic patterns while remaining minimally supervised." ></td>
	<td class="line x" title="95:192	The intuition behind our method is that in a very large corpus, like the Web, correct instances of a generic pattern will be instantiated by many of Espressos reliable patterns accepted in P. Recall that, by definition, Espressos reliable patterns extract instances with high precision (yet often low recall)." ></td>
	<td class="line x" title="96:192	In a very large corpus, like the Web, we assume that a correct instance will occur in at least one of Espressos reliable pattern even though the patterns recall is low." ></td>
	<td class="line x" title="97:192	Intuitively, our confidence in a correct instance increases when, i) the instance is associated with many reliable patterns; and ii) its association with the reliable patterns is high." ></td>
	<td class="line x" title="98:192	At a given Espresso iteration, where P R represents the set of previously selected reliable patterns, this intuition is captured by the following measure of confidence in an instance i = {x, y}: () () ()   = R Pp p T pr iSiS  where T is the sum of the reliability scores r  (p) for each pattern p  P R, and () ( ),**,,*,,, log, pyx ypx pipmiiS p  == 116 where pointwise mutual information between instance i and pattern p is estimated with Google as follows: () pyx ypx iS p  ,, An instance i is rejected if S(i) is smaller than some threshold ." ></td>
	<td class="line x" title="99:192	Although this filtering may also be applied to reliable patterns, we found this to be detrimental in our experiments since most instances generated by reliable patterns are correct." ></td>
	<td class="line x" title="100:192	In Espresso, we classify a pattern as generic when it generates more than 10 times the instances of previously accepted reliable patterns." ></td>
	<td class="line x" title="101:192	4 Experimental Results In this section, we present an empirical comparison of Espresso with three state of the art systems on the task of extracting various semantic relations." ></td>
	<td class="line x" title="102:192	4.1 Experimental Setup We perform our experiments using the following two datasets:  TREC: This dataset consists of a sample of articles from the Aquaint (TREC-9) newswire text collection." ></td>
	<td class="line x" title="103:192	The sample consists of 5,951,432 words extracted from the following data files: AP890101  AP890131, AP890201  AP890228, and AP890310  AP890319." ></td>
	<td class="line x" title="104:192	 CHEM: This small dataset of 313,590 words consists of a college level textbook of introductory chemistry (Brown et al. 2003)." ></td>
	<td class="line x" title="105:192	Each corpus is pre-processed using the Alembic Workbench POS-tagger (Day et al. 1997)." ></td>
	<td class="line x" title="106:192	Below we describe the systems used in our empirical evaluation of Espresso." ></td>
	<td class="line x" title="107:192	 RH02: The algorithm by Ravichandran and Hovy (2002) described in Section 2." ></td>
	<td class="line x" title="108:192	 GI03: The algorithm by Girju et al.(2006) described in Section 2." ></td>
	<td class="line x" title="110:192	 PR04: The algorithm by Pantel and Ravichandran (2004) described in Section 2." ></td>
	<td class="line x" title="111:192	 ESP-: The Espresso algorithm using the pattern and instance reliability measures, but without using generic patterns." ></td>
	<td class="line x" title="112:192	 ESP+: The full Espresso algorithm described in this paper exploiting generic patterns." ></td>
	<td class="line x" title="113:192	For ESP+, we experimentally set  from Section 3.3 to  = 0.4 for TREC and  = 0.3 for CHEM by manually inspecting a small set of instances." ></td>
	<td class="line x" title="114:192	Espresso is designed to extract various semantic relations exemplified by a given small set of seed instances." ></td>
	<td class="line x" title="115:192	We consider the standard is-a and part-of relations as well as the following more specific relations:  succession: This relation indicates that a person succeeds another in a position or title." ></td>
	<td class="line x" title="116:192	For example, George Bush succeeded Bill Clinton and Pope Benedict XVI succeeded Pope John Paul II." ></td>
	<td class="line x" title="117:192	We evaluate this relation on the TREC-9 corpus." ></td>
	<td class="line x" title="118:192	 reaction: This relation occurs between chemical elements/molecules that can be combined in a chemical reaction." ></td>
	<td class="line x" title="119:192	For example, hydrogen gas reacts-with oxygen gas and zinc reacts-with hydrochloric acid." ></td>
	<td class="line x" title="120:192	We evaluate this relation on the CHEM corpus." ></td>
	<td class="line x" title="121:192	 production: This relation occurs when a process or element/object produces a result 1." ></td>
	<td class="line x" title="122:192	For example, ammonia produces nitric oxide." ></td>
	<td class="line x" title="123:192	We evaluate this relation on the CHEM corpus." ></td>
	<td class="line x" title="124:192	For each semantic relation, we manually extracted a small set of seed examples." ></td>
	<td class="line x" title="125:192	The seeds were used for both Espresso as well as RH02." ></td>
	<td class="line x" title="126:192	Table 1 lists a sample of the seeds as well as sample outputs from Espresso." ></td>
	<td class="line x" title="127:192	4.2 Precision and Recall We implemented the systems outlined in Section 4.1, except for GI03, and applied them to the 1 Production is an ambiguous relation; it is intended to be a causation relation in the context of chemical reactions." ></td>
	<td class="line x" title="128:192	Table 1." ></td>
	<td class="line x" title="129:192	Sample seeds used for each semantic relation and sample outputs from Espresso." ></td>
	<td class="line x" title="130:192	The number in the parentheses for each relation denotes the total number of seeds used as input for the system." ></td>
	<td class="line x" title="131:192	Is-a (12) Part-Of (12) Succession (12) Reaction (13) Production (14) Seeds wheat :: crop George Wendt :: star nitrogen :: element diborane :: substance leader :: panel city :: region ion :: matter oxygen :: water Khrushchev :: Stalin Carla Hills :: Yeutter Bush :: Reagan Julio Barbosa :: Mendes magnesium :: oxygen hydrazine :: water aluminum metal :: oxygen lithium metal :: fluorine gas bright flame :: flares hydrogen :: metal hydrides ammonia :: nitric oxide copper :: brown gas Espresso Picasso :: artist tax :: charge protein :: biopolymer HCl :: strong acid trees :: land material :: FBI report oxygen :: air atom :: molecule Ford :: Nixon Setrakian :: John Griesemer Camero Cardiel :: Camacho Susan Weiss :: editor hydrogen :: oxygen Ni :: HCl carbon dioxide :: methane boron :: fluorine electron :: ions glycerin :: nitroglycerin kidneys :: kidney stones ions :: charge 117 Table 8." ></td>
	<td class="line x" title="132:192	System performance: CHEM/production." ></td>
	<td class="line x" title="133:192	SYSTEM INSTANCES PRECISION * REL RECALL  RH02 197 57.5% 0.80 ESP196 72.5% 1.00 ESP+ 1676 55.8% 6.58 TREC and CHEM datasets." ></td>
	<td class="line x" title="134:192	For each output set, per relation, we evaluate the precision of the system by extracting a random sample of instances (50 for the TREC corpus and 20 for the CHEM corpus) and evaluating their quality manually using two human judges (a total of 680 instances were annotated per judge)." ></td>
	<td class="line x" title="135:192	For each instance, judges may assign a score of 1 for correct, 0 for incorrect, and  for partially correct." ></td>
	<td class="line x" title="136:192	Example instances that were judged partially correct include analyst is-a manager and pilot is-a teacher." ></td>
	<td class="line x" title="137:192	The kappa statistic (Siegel and Castellan Jr. 1988) on this task was  = 0.69 2 . The precision for a given set of instances is the sum of the judges scores divided by the total instances." ></td>
	<td class="line x" title="138:192	Although knowing the total number of correct instances of a particular relation in any nontrivial corpus is impossible, it is possible to compute the recall of a system relative to another systems recall." ></td>
	<td class="line x" title="139:192	Following (Pantel et al. 2004), we define the relative recall of system A given system B, R A|B, as: BP AP C C R R R B A B A C C C C B A BA B A   ==== | where R A is the recall of A, C A is the number of correct instances extracted by A, C is the (unknown) total number of correct instances in the corpus, P A is As precision in our experiments, 2 The kappa statistic jumps to  = 0.79 if we treat partially correct classifications as correct." ></td>
	<td class="line x" title="140:192	and |A| is the total number of instances discovered by A. Tables 2  8 report the total number of instances, precision, and relative recall of each system on the TREC-9 and CHEM corpora 34." ></td>
	<td class="line x" title="141:192	The relative recall is always given in relation to the ESPsystem." ></td>
	<td class="line x" title="142:192	For example, in Table 2, RH02 has a relative recall of 5.31 with ESP-, which means that the RH02 system outputs 5.31 times more correct relations than ESP(at a cost of much lower precision)." ></td>
	<td class="line x" title="143:192	Similarly, PR04 has a relative recall of 0.23 with ESP-, which means that PR04 outputs 4.35 fewer correct relations than ESP(also with a smaller precision)." ></td>
	<td class="line x" title="144:192	We did not include the results from GI03 in the tables since the system is only applicable to part-of relations and we did not reproduce it." ></td>
	<td class="line x" title="145:192	However, the authors evaluated their system on a sample of the TREC9 dataset and reported 83% precision and 72% recall (this algorithm is heavily supervised)." ></td>
	<td class="line x" title="146:192	* Because of the small evaluation sets, we estimate the 95% confidence intervals using bootstrap resampling to be in the order of  10-15% (absolute numbers)." ></td>
	<td class="line x" title="147:192	 Relative recall is given in relation to ESP-." ></td>
	<td class="line x" title="148:192	Table 2." ></td>
	<td class="line x" title="149:192	System performance: TREC/is-a." ></td>
	<td class="line x" title="150:192	SYSTEM INSTANCES PRECISION * REL RECALL  RH02 57,525 28.0% 5.31 PR04 1,504 47.0% 0.23 ESP4,154 73.0% 1.00 ESP+ 69,156 36.2% 8.26 Table 4." ></td>
	<td class="line x" title="151:192	System performance: TREC/part-of." ></td>
	<td class="line x" title="152:192	SYSTEM INSTANCES PRECISION * REL RECALL  RH02 12,828 35.0% 42.52 ESP132 80.0% 1.00 ESP+ 87,203 69.9% 577.22 Table 3." ></td>
	<td class="line x" title="153:192	System performance: CHEM/is-a." ></td>
	<td class="line x" title="154:192	SYSTEM INSTANCES PRECISION * REL RECALL  RH02 2556 25.0% 3.76 PR04 108 40.0% 0.25 ESP200 85.0% 1.00 ESP+ 1490 76.0% 6.66 Table 5." ></td>
	<td class="line x" title="155:192	System performance: CHEM/part-of." ></td>
	<td class="line x" title="156:192	SYSTEM INSTANCES PRECISION * REL RECALL  RH02 11,582 33.8% 58.78 ESP111 60.0% 1.00 ESP+ 5973 50.7% 45.47 Table 7." ></td>
	<td class="line x" title="157:192	System performance: CHEM/reaction." ></td>
	<td class="line x" title="158:192	SYSTEM INSTANCES PRECISION * REL RECALL  RH02 6,083 30% 53.67 ESP40 85% 1.00 ESP+ 3102 91.4% 89.39 Table 6." ></td>
	<td class="line x" title="159:192	System performance: TREC/succession." ></td>
	<td class="line x" title="160:192	SYSTEM INSTANCES PRECISION * REL RECALL  RH02 49,798 2.0% 36.96 ESP55 49.0% 1.00 ESP+ 55 49.0% 1.00 118 In all tables, RH02 extracts many more relations than ESP-, but with a much lower precision, because it uses generic patterns without filtering." ></td>
	<td class="line x" title="161:192	The high precision of ESPis due to the effective reliability measures presented in Section 3.2." ></td>
	<td class="line x" title="162:192	4.3 Effect of Generic Patterns Experimental results, for all relations and the two different corpus sizes, show that ESPgreatly outperforms the other methods on precision." ></td>
	<td class="line x" title="163:192	However, without the use of generic patterns, the ESPsystem shows lower recall in all but the production relation." ></td>
	<td class="line x" title="164:192	As hypothesized, exploiting generic patterns using the algorithm from Section 3.3 substantially improves recall without much deterioration in precision." ></td>
	<td class="line x" title="165:192	ESP+ shows one to two orders of magnitude improvement on recall while losing on average below 10% precision." ></td>
	<td class="line x" title="166:192	The succession relation in Table 6 was the only relation where Espresso found no generic pattern." ></td>
	<td class="line x" title="167:192	For other relations, Espresso found from one to five generic patterns." ></td>
	<td class="line x" title="168:192	Table 4 shows the power of generic patterns where system recall increases by 577 times with only a 10% drop in precision." ></td>
	<td class="line x" title="169:192	In Table 7, we see a case where the combination of filtering with a large increase in retrieved instances resulted in both higher precision and recall." ></td>
	<td class="line x" title="170:192	In order to better analyze our use of generic patterns, we performed the following experiment." ></td>
	<td class="line x" title="171:192	For each relation, we randomly sampled 100 instances for each generic pattern and built a gold standard for them (by manually tagging each instance as correct or incorrect)." ></td>
	<td class="line x" title="172:192	We then sorted the 100 instances according to the scoring formula S(i) derived in Section 3.3 and computed the average precision, recall, and F-score of each top-K ranked instances for each pattern 5 . Due to lack of space, we only present the graphs for four of the 22 generic patterns: X is a Y for the is-a relation of Table 2, X in the Y for the part-of relation of Table 4, X in Y for the part-of relation of Table 5, and X and Y for the reaction relation of Table 7." ></td>
	<td class="line x" title="173:192	Figure 1 illustrates the results." ></td>
	<td class="line x" title="174:192	In each figure, notice that recall climbs at a much faster rate than precision decreases." ></td>
	<td class="line x" title="175:192	This indicates that the scoring function of Section 3.3 effectively separates correct and incorrect instances." ></td>
	<td class="line x" title="176:192	In Figure 1a), there is a big initial drop in precision that accounts for the poor precision reported in Table 1." ></td>
	<td class="line x" title="177:192	Recall that the cutoff points on S(i) were set to  = 0.4 for TREC and  = 0.3 for CHEM." ></td>
	<td class="line x" title="178:192	The figures show that this cutoff is far from the maximum F-score." ></td>
	<td class="line x" title="179:192	An interesting avenue of future work would be to automatically determine the proper threshold for each individual generic pattern instead of setting a uniform threshold." ></td>
	<td class="line x" title="180:192	5 We can directly compute recall here since we built a gold standard for each set of 100 samples." ></td>
	<td class="line x" title="181:192	Figure 1." ></td>
	<td class="line x" title="182:192	Precision, recall and F-score curves of the Top-K% ranking instances of patterns X is a Y (TREC/is-a), X in Y (TREC/part-of), X in the Y (CHEM/part-of), and X and Y (CHEM/reaction)." ></td>
	<td class="line x" title="183:192	a) TREC/is-a: 'X is a Y' 0 0.2 0.4 0.6 0.8 1 5 152535455 65758595 Top-K% d) CHEM/reaction: 'X and Y' 0 0.2 0.4 0.6 0.8 1 5 152535455565758595 Top-K% c) CHEM/part-of: 'X in Y' 0 0.2 0.4 0.6 0.8 1 5 152535455565758595 Top-K% b) TREC/part-of: 'X in the Y' 0 0.2 0.4 0.6 0.8 1 5 152535455565758595 Top-K% 119 5 Conclusions We proposed a weakly-supervised, generalpurpose, and accurate algorithm, called Espresso, for harvesting binary semantic relations from raw text." ></td>
	<td class="line x" title="184:192	The main contributions are: i) a method for exploiting generic patterns by filtering incorrect instances using the Web; and ii) a principled measure of pattern and instance reliability enabling the filtering algorithm." ></td>
	<td class="line x" title="185:192	We have empirically compared Espressos precision and recall with other systems on both a small domain-specific textbook and on a larger corpus of general news, and have extracted several standard and specific semantic relations: isa, part-of, succession, reaction, and production." ></td>
	<td class="line x" title="186:192	Espresso achieves higher and more balanced performance than other state of the art systems." ></td>
	<td class="line x" title="187:192	By exploiting generic patterns, system recall substantially increases with little effect on precision." ></td>
	<td class="line x" title="188:192	There are many avenues of future work both in improving system performance and making use of the relations in applications like question answering." ></td>
	<td class="line x" title="189:192	For the former, we plan to investigate the use of WordNet to automatically learn selectional constraints on generic patterns, as proposed by (Girju et al. 2006)." ></td>
	<td class="line x" title="190:192	We expect here that negative instances will play a key role in determining the selectional restrictions." ></td>
	<td class="line x" title="191:192	Espresso is the first system, to our knowledge, to emphasize concurrently performance, minimal supervision, breadth, and generality." ></td>
	<td class="line x" title="192:192	It remains to be seen whether one could enrich existing ontologies with relations harvested by Espresso, and it is our hope that these relations will benefit NLP applications." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-1045
Selection Of Effective Contextual Information For Automatic Synonym Acquisition
Hagiwara, Masato;Ogawa, Yasuhiro;Toyama, Katsuhiko;"></td>
	<td class="line x" title="1:132	Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 353360, Sydney, July 2006." ></td>
	<td class="line x" title="2:132	c2006 Association for Computational Linguistics Selection of Effective Contextual Information for Automatic Synonym Acquisition Masato Hagiwara, Yasuhiro Ogawa, and Katsuhiko Toyama Graduate School of Information Science, Nagoya University Furo-cho, Chikusa-ku, Nagoya, JAPAN 464-8603 {hagiwara, yasuhiro, toyama}@kl.i.is.nagoya-u.ac.jp Abstract Various methods have been proposed for automatic synonym acquisition, as synonyms are one of the most fundamental lexical knowledge." ></td>
	<td class="line x" title="3:132	Whereas many methods are based on contextual clues of words, little attention has been paid to what kind of categories of contextual information are useful for the purpose." ></td>
	<td class="line x" title="4:132	This study has experimentally investigated the impact of contextual information selection, by extracting three kinds of word relationships from corpora: dependency, sentence co-occurrence, and proximity." ></td>
	<td class="line x" title="5:132	The evaluation result shows that while dependency and proximity perform relatively well by themselves, combination of two or more kinds of contextual information gives more stable performance." ></td>
	<td class="line x" title="6:132	Weve further investigated useful selection of dependency relations and modification categories, and it is found that modification has the greatest contribution, even greater than the widely adopted subjectobject combination." ></td>
	<td class="line x" title="7:132	1 Introduction Lexical knowledge is one of the most important resources in natural language applications, making it almost indispensable for higher levels of syntactical and semantic processing." ></td>
	<td class="line x" title="8:132	Among many kinds of lexical relations, synonyms are especially useful ones, having broad range of applications such as query expansion technique in information retrieval and automatic thesaurus construction." ></td>
	<td class="line oc" title="9:132	Various methods (Hindle, 1990; Lin, 1998; Hagiwara et al. , 2005) have been proposed for synonym acquisition." ></td>
	<td class="line x" title="10:132	Most of the acquisition methods are based on distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts, and it has been experimentally shown considerably plausible." ></td>
	<td class="line x" title="11:132	However, whereas many methods which adopt the hypothesis are based on contextual clues concerning words, and there has been much consideration on the language models such as Latent Semantic Indexing (Deerwester et al. , 1990) and Probabilistic LSI (Hofmann, 1999) and synonym acquisition method, almost no attention has been paid to what kind of categories of contextual information, or their combinations, are useful for word featuring in terms of synonym acquisition." ></td>
	<td class="line nc" title="12:132	For example, Hindle (1990) used cooccurrences between verbs and their subjects and objects, and proposed a similarity metric based on mutual information, but no exploration concerning the effectiveness of other kinds of word relationship is provided, although it is extendable to any kinds of contextual information." ></td>
	<td class="line x" title="13:132	Lin (1998) also proposed an information theorybased similarity metric, using a broad-coverage parser and extracting wider range of grammatical relationship including modifications, but he didnt further investigate what kind of relationships actually had important contributions to acquisition, either." ></td>
	<td class="line x" title="14:132	The selection of useful contextual information is considered to have a critical impact on the performance of synonym acquisition." ></td>
	<td class="line x" title="15:132	This is an independent problem from the choice of language model or acquisition method, and should therefore be examined by itself." ></td>
	<td class="line x" title="16:132	The purpose of this study is to experimentally investigate the impact of contextual information selection for automatic synonym acquisition." ></td>
	<td class="line x" title="17:132	Because nouns are the main target of 353 synonym acquisition, here we limit the target of acquisition to nouns, and firstly extract the cooccurrences between nouns and three categories of contextual information  dependency, sentence co-occurrence, and proximity  from each of three different corpora, and the performance of individual categories and their combinations are evaluated." ></td>
	<td class="line x" title="18:132	Since dependency and modification relations are considered to have greater contributions in contextual information and in the dependency category, respectively, these categories are then broken down into smaller categories to examine the individual significance." ></td>
	<td class="line x" title="19:132	Because the consideration on the language model and acquisition methods is not the scope of the current study, widely used vector space model (VSM), tfidf weighting scheme, and cosine measure are adopted for similarity calculation." ></td>
	<td class="line x" title="20:132	The result is evaluated using two automatic evaluation methods we proposed and implemented: discrimination rate and correlation coefficient based on the existing thesaurus WordNet." ></td>
	<td class="line x" title="21:132	This paper is organized as follows: in Section 2, three kinds of contextual information we use are described, and the following Section 3 explains the synonym acquisition method." ></td>
	<td class="line x" title="22:132	In Section 4 the evaluation method we employed is detailed, which consists of the calculation methods of reference similarity, discrimination rate, and correlation coefficient." ></td>
	<td class="line x" title="23:132	Section 5 provides the experimental conditions and results of contextual information selection, followed by dependency and modification selection." ></td>
	<td class="line x" title="24:132	Section 6 concludes this paper." ></td>
	<td class="line x" title="25:132	2 Contextual Information In this study, we focused on three kinds of contextual information: dependency between words, sentence co-occurrence, and proximity, that is, cooccurrence with other words in a window, details of which are provided the following sections." ></td>
	<td class="line x" title="26:132	2.1 Dependency The first category of the contextual information we employed is the dependency between words in a sentence, which we suppose is most commonly used for synonym acquisition as the context of words." ></td>
	<td class="line x" title="27:132	The dependency here includes predicateargument structure such as subjects and objects of verbs, and modifications of nouns." ></td>
	<td class="line x" title="28:132	As the extraction of accurate and comprehensive grammatical relations is in itself a difficult task, the sodependent mod ncmodxmodcmoddetmod arg_mod arg aux conj subj_or_dobj subj ncsubj xsubj csubj comp obj clausal obj2dobj iobjxcompccomp mod subj obj Figure 1: Hierarchy of grammatical relations and groups phisticated parser RASP Toolkit (Briscoe and Carroll, 2002) was utilized to extract this kind of word relations." ></td>
	<td class="line x" title="29:132	RASP analyzes input sentences and provides wide variety of grammatical information such as POS tags, dependency structure, and parsed trees as output, among which we paid attention to dependency structure called grammatical relations (GRs) (Briscoe et al. , 2002)." ></td>
	<td class="line x" title="30:132	GRs represent relationship among two or more words and are specified by the labels, which construct the hierarchy shown in Figure 1." ></td>
	<td class="line x" title="31:132	In this hierarchy, the upper levels correspond to more general relations whereas the lower levels to more specific ones." ></td>
	<td class="line x" title="32:132	Although the most general relationship in GRs is dependent, more specific labels are assigned whenever possible." ></td>
	<td class="line x" title="33:132	The representation of the contextual information using GRs is as follows." ></td>
	<td class="line x" title="34:132	Take the following sentence for example: Shipments have been relatively level since January, the Commerce Department noted." ></td>
	<td class="line x" title="35:132	RASP outputs the extracted GRs as n-ary relations as follows: (ncsubj note Department obj) (ncsubj be Shipment _) (xcomp _ be level) (mod _ level relatively) (aux _ be have) (ncmod since be January) (mod _ Department note) (ncmod _ Department Commerce) 354 (detmod _ Department the) (ncmod _ be Department) While most of GRs extracted by RASP are binary relations of head and dependent, there are some relations that contain additional slot or extra information regarding the relations, as shown ncsubj and ncmod in the above example." ></td>
	<td class="line x" title="36:132	To obtain the final representation that we require for synonym acquisition, that is, the co-occurrence between words and their contexts, these relationships must be converted to binary relations, i.e., co-occurrence." ></td>
	<td class="line x" title="37:132	We consider the concatenation of all the rest of the target word as context: Department ncsubj:note:*:obj shipment ncsubj:be:*:_ January ncmod:since:be:* Department mod:_:*:note Department ncmod:_:*:Commerce Commerce ncmod:_:Department:* Department detmod:_:*:the Department ncmod:_:be:* The slot for the target word is replaced by * in the context." ></td>
	<td class="line x" title="38:132	Note that only the contexts for nouns are extracted because our purpose here is the automatic extraction of synonymous nouns." ></td>
	<td class="line x" title="39:132	2.2 Sentence Co-occurrence As the second category of contextual information, we used the sentence co-occurrence, i.e., which sentence words appear in." ></td>
	<td class="line x" title="40:132	Using this context is, in other words, essentially the same as featuring words with the sentences in which they occur." ></td>
	<td class="line x" title="41:132	Treating single sentences as documents, this featuring corresponds to exploiting transposed termdocument matrix in the information retrieval context, and the underlying assumption is that words that commonly appear in the similar documents or sentences are considered semantically similar." ></td>
	<td class="line x" title="42:132	2.3 Proximity The third category of contextual information, proximity, utilizes tokens that appear in the vicinity of the target word in a sentence." ></td>
	<td class="line x" title="43:132	The basic assumption here is that the more similar the distribution of proceeding and succeeding words of the target words are, the more similar meaning these two words possess, and its effectiveness has been previously shown (Macro Baroni and Sabrina Bisi, 2004)." ></td>
	<td class="line x" title="44:132	To capture the word proximity, we consider a window with a certain radius, and treat the label of the word and its position within the window as context." ></td>
	<td class="line x" title="45:132	The contexts for the previous example sentence, when the window radius is 3, are then: shipment R1:have shipment R2:be shipment R3:relatively January L1:since January L2:level January L3:relatively January R1:, January R2:the January R3:Commerce Commerce L1:the Commerce L2:, Commerce L3:January Commerce R1:Department Note that the proximity includes tokens such as punctuation marks as context, because we suppose they offer useful contextual information as well." ></td>
	<td class="line x" title="46:132	3 Synonym Acquisition Method The purpose of the current study is to investigate the impact of the contextual information selection, not the language model itself, we employed one of the most commonly used method: vector space model (VSM) and tfidf weighting scheme." ></td>
	<td class="line x" title="47:132	In this framework, each word is represented as a vector in a vector space, whose dimensions correspond to contexts." ></td>
	<td class="line x" title="48:132	The elements of the vectors given by tfidf are the co-occurrence frequencies of words and contexts, weighted by normalized idf." ></td>
	<td class="line x" title="49:132	That is, denoting the number of distinct words and contexts as N and M, respectively, wi = t[tf(wi,c1)idf(c1)  tf(wi,cM)idf(cM)], (1) where tf(wi,cj) is the co-occurrence frequency of word wi and context cj." ></td>
	<td class="line x" title="50:132	idf(cj) is given by idf(cj) = log(N/df(cj))max k log(N/df(vk)), (2) where df(cj) is the number of distinct words that co-occur with context cj." ></td>
	<td class="line x" title="51:132	Although VSM and tfidf are naive and simple compared to other language models like LSI and PLSI, they have been shown effective enough for the purpose (Hagiwara et al. , 2005)." ></td>
	<td class="line x" title="52:132	The similarity between two words are then calculated as the cosine value of two corresponding vectors." ></td>
	<td class="line x" title="53:132	4 Evaluation This section describes the evaluation methods we employed for automatic synonym acquisition." ></td>
	<td class="line x" title="54:132	The evaluation is to measure how similar the obtained similarities are to the true similarities." ></td>
	<td class="line x" title="55:132	We firstly prepared the reference similarities from the existing thesaurus WordNet as described in Section 4.1, 355 and by comparing the reference and obtained similarities, two evaluation measures, discrimination rate and correlation coefficient, are calculated automatically as described in Sections 4.2 and 4.3." ></td>
	<td class="line x" title="56:132	4.1 Reference similarity calculation using WordNet As the basis for automatic evaluation methods, the reference similarity, which is the answer value that similarity of a certain pair of words should take, is required." ></td>
	<td class="line x" title="57:132	We obtained the reference similarity using the calculation based on thesaurus tree structure (Nagao, 1996)." ></td>
	<td class="line x" title="58:132	This calculation method requires no other resources such as corpus, thus it is simple to implement and widely used." ></td>
	<td class="line x" title="59:132	The similarity between word sense wi and word sense vj is obtained using tree structure as follows." ></td>
	<td class="line x" title="60:132	Let the depth1 of node wi be di, the depth of node vj be dj, and the maximum depth of the common ancestors of both nodes be ddca." ></td>
	<td class="line x" title="61:132	The similarity between wi and vj is then calculated as sim(wi,vj) = 2ddcad i +dj, (3) which takes the value between 0.0 and 1.0." ></td>
	<td class="line x" title="62:132	Figure 2 shows the example of calculating the similarity between the word senses hill and coast. The number on the side of each word sense represents the words depth." ></td>
	<td class="line x" title="63:132	From this tree structure, the similarity is obtained: sim(hill,coast) = 235+5 = 0.6." ></td>
	<td class="line x" title="64:132	(4) The similarity between word w with senses w1,,wn and word v with senses v1,,vm is defined as the maximum similarity between all the pairs of word senses: sim(w,v) = maxi,j sim(wi,vj), (5) whose idea came from Lins method (Lin, 1998)." ></td>
	<td class="line x" title="65:132	4.2 Discrimination Rate The following two sections describe two evaluation measures based on the reference similarity." ></td>
	<td class="line x" title="66:132	The first one is discrimination rate (DR)." ></td>
	<td class="line x" title="67:132	DR, originally proposed by Kojima et al.(2004), is the rate 1To be precise, the structure of WordNet, where some word senses have more than one parent, isnt a tree but a DAG." ></td>
	<td class="line x" title="69:132	The depth of a node is, therefore, defined here as the maximum distance from the root node." ></td>
	<td class="line x" title="70:132	entity 0 inanimate-object 1 natural-object 2 geological-formation 3 4 natural-elevation 5 hill shore 4 coast 5 Figure 2: Example of automatic similarity calculation based on tree structure (answer, reply)(phone, telephone) (sign, signal)(concern, worry) (animal, coffee)(him, technology) (track, vote)(path, youth)  highly related unrelated Figure 3: Test-sets for discrimination rate calculation." ></td>
	<td class="line x" title="71:132	(percentage) of pairs (w1,w2) whose degree of association between two words w1,w2 is successfully discriminated by the similarity derived by the method under evaluation." ></td>
	<td class="line x" title="72:132	Kojima et al. dealt with three-level discrimination of a pair of words, that is, highly related (synonyms or nearly synonymous), moderately related (a certain degree of association), and unrelated (irrelevant)." ></td>
	<td class="line x" title="73:132	However, we omitted the moderately related level and limited the discrimination to two-level: high or none, because of the difficulty of preparing a test set that consists of moderately related pairs." ></td>
	<td class="line x" title="74:132	The calculation of DR follows these steps: first, two test sets, one of which consists of highly related word pairs and the other of unrelated ones, are prepared, as shown in Figure 3." ></td>
	<td class="line x" title="75:132	The similarity between w1 and w2 is then calculated for each pair (w1,w2) in both test sets via the method under evaluation, and the pair is labeled highly related when similarity exceeds a given threshold t and unrelated when the similarity is lower than t. The number of pairs labeled highly related in the highly related test set and unrelated in the unrelated test set are denoted na and nb, respectively." ></td>
	<td class="line x" title="76:132	356 DR is then given by: 1 2 parenleftbiggn a Na + nb Nb parenrightbigg, (6) where Na and Nb are the numbers of pairs in highly related and unrelated test sets, respectively." ></td>
	<td class="line x" title="77:132	Since DR changes depending on threshold t, maximum value is adopted by varying t. We used the reference similarity to create these two test sets." ></td>
	<td class="line x" title="78:132	Firstly, Np = 100,000 pairs of words are randomly created using the target vocabulary set for synonym acquisition." ></td>
	<td class="line x" title="79:132	Proper nouns are omitted from the choice here because of their high ambiguity." ></td>
	<td class="line x" title="80:132	The two testsets are then created extracting n = 2,000 most related (with high reference similarity) and unrelated (with low reference similarity) pairs." ></td>
	<td class="line x" title="81:132	4.3 Correlation coefficient The second evaluation measure is correlation coefficient (CC) between the obtained similarity and the reference similarity." ></td>
	<td class="line x" title="82:132	The higher CC value is, the more similar the obtained similarities are to WordNet, thus more accurate the synonym acquisition result is. The value of CC is calculated as follows." ></td>
	<td class="line x" title="83:132	Let the set of the sample pairs be Ps, the sequence of the reference similarities calculated for the pairs in Ps be r = (r1,r2,,rn), the corresponding sequence of the target similarity to be evaluated be r = (s1,s2,,sn), respectively." ></td>
	<td class="line x" title="84:132	Correlation coefficient  is then defined by:  = 1 n summationtextn i=1(ri  r)(si  s) rs, (7) where r,s,r, and s represent the average of r and s and the standard deviation of r and s, respectively." ></td>
	<td class="line x" title="85:132	The set of the sample pairs Ps is created in a similar way to the preparation of highly related test set used in DR calculation, except that we employed Np = 4,000,n = 2,000 to avoid extreme nonuniformity." ></td>
	<td class="line x" title="86:132	5 Experiments Now we desribe the experimental conditions and results of contextual information selection." ></td>
	<td class="line x" title="87:132	5.1 Condition We used the following three corpora for the experiment: (1) Wall Street Journal (WSJ) corpus (approx." ></td>
	<td class="line x" title="88:132	68,000 sentences, 1.4 million tokens), (2) Brown Corpus (BROWN) (approx." ></td>
	<td class="line x" title="89:132	60,000 sentences, 1.3 million tokens), both of which are contained in Treebank 3 (Marcus, 1994), and (3) written sentences in WordBank (WB) (approx." ></td>
	<td class="line x" title="90:132	190,000 sentences, 3.5 million words) (HyperCollins, 2002)." ></td>
	<td class="line x" title="91:132	No additional annotation such as POS tags provided for Treebank was used, which means that we gave the plain texts stripped off any additional information to RASP as input." ></td>
	<td class="line x" title="92:132	To distinguish nouns, using POS tags annotated by RASP, any words with POS tags APP, ND, NN, NP, PN, PP were labeled as nouns." ></td>
	<td class="line x" title="93:132	The window radius for proximity is set to 3." ></td>
	<td class="line x" title="94:132	We also set a threshold tf on occurrence frequency in order to filter out any words or contexts with low frequency and to reduce computational cost." ></td>
	<td class="line x" title="95:132	More specifically, any words w such that summationtextc tf(w,c) < tf and any contexts c such that summationtextw tf(w,c) < tf were removed from the co-occurrence data." ></td>
	<td class="line x" title="96:132	tf was set to tf = 5 for WSJ and BROWN, and tf = 10 for WB in Sections 5.2 and 5.3, and tf = 2 for WSJ and BROWN and tf = 5 for WB in Section 5.4." ></td>
	<td class="line x" title="97:132	5.2 Contextual Information Selection In this section, we experimented to discover what kind of contextual information extracted in Section 2 is useful for synonym extraction." ></td>
	<td class="line x" title="98:132	The performances, i.e. DR and CC are evaluated for each of the three categories and their combinations." ></td>
	<td class="line x" title="99:132	The evaluation result for three corpora is shown in Figure 4." ></td>
	<td class="line x" title="100:132	Notice that the range and scale of the vertical axes of the graphs vary according to corpus." ></td>
	<td class="line x" title="101:132	The result shows that dependency and proximity perform relatively well alone, while sentence co-occurrence has almost no contributions to performance." ></td>
	<td class="line x" title="102:132	However, when combined with other kinds of context information, every category, even sentence co-occurrence, serves to stabilize the overall performance, although in some cases combination itself decreases individual measures slightly." ></td>
	<td class="line x" title="103:132	It is no surprise that the combination of all categories achieves the best performance." ></td>
	<td class="line x" title="104:132	Therefore, in choosing combination of different kinds of context information, one should take into consideration the economical efficiency and trade-off between computational complexity and overall performance stability." ></td>
	<td class="line x" title="105:132	5.3 Dependency Selection We then focused on the contribution of individual categories of dependency relation, i.e. groups of grammatical relations." ></td>
	<td class="line x" title="106:132	The following four groups 357 65.0% 65.5% 66.0% 66.5% 67.0% 67.5% 68.0% 68.5% dis crim ina tio n ra te ( DR )a 0.09 0.10 0.11 0.12 0.13 cor rela tio n c oef fici ent (C C)) DR CC dep sent prox dep sent dep prox sent prox all (1) WSJ DR = 52.8% CC = -0.0029 sent: 65.0% 65.5% 66.0% 66.5% 67.0% 67.5% 68.0% 68.5% 69.0% dis crim ina tio n ra te ( DR )a 0.13 0.14 0.15 cor rela tio n c oef fici ent (C C)) DR CC dep sent prox dep sent dep prox sent prox all (2) BROWN DR = 53.8% CC = 0.060 sent: 66.0% 66.5% 67.0% 67.5% 68.0% 68.5% 69.0% dis crim ina tio n ra te ( DR )a 0.16 0.17 0.18 0.19 cor rela tio n c oef fici ent (C C)) DR CC dep sent prox dep sent dep prox sent prox all (3) WB DR = 52.2%CC = 0.0066 sent: Figure 4: Contextual information selection performances Discrimination rate (DR) and correlation coefficient (CC) for (1) Wall Street Journal corpus, (2) Brown Corpus, and (3) WordBank." ></td>
	<td class="line x" title="107:132	of GRs are considered for comparison convenience: (1) subj group (subj, ncsubj, xsubj, and csubj), (2) obj group (obj, dobj, obj2, and iobj), (3) mod group (mod, ncmod, xmod, cmod, and detmod), and (4) etc group (others), as shown in the circles in Figure 1." ></td>
	<td class="line x" title="108:132	This is because distinction between relations in a group is sometimes unclear, and is considered to strongly depend on the parser implementation." ></td>
	<td class="line x" title="109:132	The final target is seven kinds of combinations of the above four groups: subj, obj, mod, etc, subj+obj, subj+obj+mod, and all." ></td>
	<td class="line x" title="110:132	The two evaluation measures are similarly calculated for each group and combination, and shown in Figure 5." ></td>
	<td class="line x" title="111:132	Although subjects, objects, and their combination are widely used contextual information, the performances for subj and obj categories, as well as their combination subj+obj, were relatively poor." ></td>
	<td class="line x" title="112:132	On the contrary, the result clearly shows the importance of modification, which alone is even better than widely adopted subj+obj." ></td>
	<td class="line x" title="113:132	The stabilization effect of combinations observed in the previous experiment is also confirmed here as well." ></td>
	<td class="line x" title="114:132	Because the size of the co-occurrence data varies from one category to another, we conducted another experiment to verify that the superiority of the modification category is simply due to the difference in the quality (content) of the group, not the quantity (size)." ></td>
	<td class="line x" title="115:132	We randomly extracted 100,000 pairs from each of mod and subj+obj categories to cancel out the quantity difference and compared the performance by calculating averaged DR and CC of ten trials." ></td>
	<td class="line x" title="116:132	The result showed that, while the overall performances substantially decreased due to the size reduction, the relation between groups was preserved before and after the extraction throughout all of the three corpora, although the detailed result is not shown due to the space limitation." ></td>
	<td class="line x" title="117:132	This means that what essentially contributes to the performance is not the size of the modification category but its content." ></td>
	<td class="line x" title="118:132	5.4 Modification Selection As the previous experiment shows that modifications have the biggest significance of all the dependency relationship, we further investigated what kind of modifications is useful for the purpose." ></td>
	<td class="line x" title="119:132	To do this, we broke down the mod group into these five categories according to modifying words category: (1) detmod, when the GR label is det358 54.0% 56.0% 58.0% 60.0% 62.0% 64.0% 66.0% 68.0% dis crim ina tio n ra te ( DR )a 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 cor rela tio n c oef fici ent (C C)) DR CC subj obj mod etc subjobj subjobj mod all (1) WSJ 54.0% 56.0% 58.0% 60.0% 62.0% 64.0% 66.0% 68.0% dis crim ina tio n ra te ( DR )a 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 cor rela tio n c oef fici ent (C C)) DR CC subj obj mod etc subjobj subjobj mod all (2) BROWN 54.0% 56.0% 58.0% 60.0% 62.0% 64.0% 66.0% 68.0% 70.0% dis crim ina tio n ra te ( DR )a 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 cor rela tio n c oef fici ent (C C)) DR CC subj obj mod etc subjobj subjobj mod all (3) WB Figure 5: Dependency selection performances Discrimination rate (DR) and correlation coefficient (CC) for (1) Wall Street Journal corpus, (2) Brown Corpus, and (3) WordBank." ></td>
	<td class="line x" title="120:132	50.0% 52.0% 54.0% 56.0% 58.0% 60.0% 62.0% 64.0% 66.0% dis crim ina tio n ra te ( DR )a 0.00 0.02 0.04 0.06 0.08 0.10 0.12 cor rela tio n c oef fici ent (C C)) DR CC detmod ncmod-n ncmod-j ncmod-p etc all (1) WSJ 50.0% 52.0% 54.0% 56.0% 58.0% 60.0% 62.0% 64.0% 66.0% dis crim ina tio n ra te ( DR )a 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 cor rela tio n c oef fici ent (C C)) DR CC detmod ncmod-n ncmod-j ncmod-p etc all (2) BROWN CC = -0.018 57.0% 59.0% 61.0% 63.0% 65.0% 67.0% dis crim ina tio n ra te ( DR )a 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 cor rela tio n c oef fici ent (C C)) DR CC detmod ncmod-n ncmod-j ncmod-p etc all (3) WB Figure 6: Modification selection performances Discrimination rate (DR) and correlation coefficient (CC) for (1) Wall Street Journal corpus, (2) Brown Corpus, and (3) WordBank." ></td>
	<td class="line x" title="121:132	359 mod, i.e., the modifying word is a determiner, (2) ncmod-n, when the GR label is ncmod and the modifying word is a noun, (3) ncmod-j, when the GR label is ncmod and the modifying word is an adjective or number, (4) ncmod-p, when the GR label is ncmod and the modification is through a preposition (e.g. state and affairs in state of affairs), and (5) etc (others)." ></td>
	<td class="line x" title="122:132	The performances for each modification category are evaluated and shown in Figure 6." ></td>
	<td class="line x" title="123:132	Although some individual modification categories such as detmod and ncmod-j outperform other categories in some cases, the overall observation is that all the modification categories contribute to synonym acquisition to some extent, and the effect of individual categories are accumulative." ></td>
	<td class="line x" title="124:132	We therefore conclude that the main contributing factor on utilizing modification relationship in synonym acquisition isnt the type of modification, but the diversity of the relations." ></td>
	<td class="line x" title="125:132	6 Conclusion In this study, we experimentally investigated the impact of contextual information selection, by extracting three kinds of contextual information  dependency, sentence co-occurrence, and proximity  from three different corpora." ></td>
	<td class="line x" title="126:132	The acquisition result was evaluated using two evaluation measures, DR and CC using the existing thesaurus WordNet." ></td>
	<td class="line x" title="127:132	We showed that while dependency and proximity perform relatively well by themselves, combination of two or more kinds of contextual information, even with the poorly performing sentence co-occurrence, gives more stable result." ></td>
	<td class="line x" title="128:132	The selection should be chosen considering the tradeoff between computational complexity and overall performance stability." ></td>
	<td class="line x" title="129:132	We also showed that modification has the greatest contribution to the acquisition of all the dependency relations, even greater than the widely adopted subject-object combination." ></td>
	<td class="line x" title="130:132	It is also shown that all the modification categories contribute to the acquisition to some extent." ></td>
	<td class="line x" title="131:132	Because we limited the target to nouns, the result might be specific to nouns, but the same experimental framework is applicable to any other categories of words." ></td>
	<td class="line x" title="132:132	Although the result also shows the possibility that the bigger the corpus is, the better the performance will be, the contents and size of the corpora we used are diverse, so their relationship, including the effect of the window radius, should be examined as the future work." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-1072
Annealing Structural Bias In Multilingual Weighted Grammar Induction
Smith, Noah A.;Eisner, Jason M.;"></td>
	<td class="line x" title="1:216	Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 569576, Sydney, July 2006." ></td>
	<td class="line x" title="2:216	c2006 Association for Computational Linguistics Annealing Structural Bias in Multilingual Weighted Grammar Induction Noah A. Smith and Jason Eisner Department of Computer Science / Center for Language and Speech Processing Johns Hopkins University, Baltimore, MD 21218 USA {nasmith,jason}@cs.jhu.edu Abstract We first show how a structural locality bias can improve the accuracy of state-of-the-art dependency grammar induction models trained by EM from unannotated examples (Klein and Manning, 2004)." ></td>
	<td class="line x" title="3:216	Next, by annealing the free parameter that controls this bias, we achieve further improvements." ></td>
	<td class="line x" title="4:216	We then describe an alternative kind of structural bias, toward broken hypotheses consisting of partial structures over segmented sentences, and show a similar pattern of improvement." ></td>
	<td class="line x" title="5:216	We relate this approach to contrastive estimation (Smith and Eisner, 2005a), apply the latter to grammar induction in six languages, and show that our new approach improves accuracy by 117% (absolute) over CE (and 830% over EM), achieving to our knowledge the best results on this task to date." ></td>
	<td class="line x" title="6:216	Our method, structural annealing, is a general technique with broad applicability to hidden-structure discovery problems." ></td>
	<td class="line x" title="7:216	1 Introduction Inducing a weighted context-free grammar from flat text is a hard problem." ></td>
	<td class="line x" title="8:216	A common starting point for weighted grammar induction is the Expectation-Maximization (EM) algorithm (Dempster et al. , 1977; Baker, 1979)." ></td>
	<td class="line x" title="9:216	EMs mediocre performance (Table 1) reflects two problems." ></td>
	<td class="line x" title="10:216	First, it seeks to maximize likelihood, but a grammar that makes the training data likely does not necessarily assign a linguistically defensible syntactic structure." ></td>
	<td class="line x" title="11:216	Second, the likelihood surface is not globally concave, and learners such as the EM algorithm can get trapped on local maxima (Charniak, 1993)." ></td>
	<td class="line x" title="12:216	We seek here to capitalize on the intuition that, at least early in learning, the learner should search primarily for string-local structure, because most structure is local.1 By penalizing dependencies between two words that are farther apart in the string, we obtain consistent improvements in accuracy of the learned model (3)." ></td>
	<td class="line x" title="13:216	We then explore how gradually changing  over time affects learning (4): we start out with a This work was supported by a Fannie and John Hertz Foundation fellowship to the first author and NSF ITR grant IIS-0313193 to the second author." ></td>
	<td class="line x" title="14:216	The views expressed are not necessarily endorsed by the sponsors." ></td>
	<td class="line x" title="15:216	We thank three anonymous COLING-ACL reviewers for comments." ></td>
	<td class="line x" title="16:216	1To be concrete, in the corpora tested here, 95% of dependency links cover  4 words (English, Bulgarian, Portuguese),  5 words (German, Turkish),  6 words (Mandarin)." ></td>
	<td class="line x" title="17:216	model selection among values of  and (0) worst unsup." ></td>
	<td class="line x" title="18:216	sup." ></td>
	<td class="line x" title="19:216	oracle German 19.8 19.8 54.4 54.4 English 21.8 41.6 41.6 42.0 Bulgarian 24.7 44.6 45.6 45.6 Mandarin 31.8 37.2 50.0 50.0 Turkish 32.1 41.2 48.0 51.4 Portuguese 35.4 37.4 42.3 43.0 Table 1: Baseline performance of EM-trained dependency parsing models: F1 on non-$ attachments in test data, with various model selection conditions (3 initializers6 smoothing values)." ></td>
	<td class="line x" title="20:216	The languages are listed in decreasing order by the training set size." ></td>
	<td class="line x" title="21:216	Experimental details can be found in the appendix." ></td>
	<td class="line x" title="22:216	strong preference for short dependencies, then relax the preference." ></td>
	<td class="line x" title="23:216	The new approach, structural annealing, often gives superior performance." ></td>
	<td class="line x" title="24:216	An alternative structural bias is explored in 5." ></td>
	<td class="line x" title="25:216	This approach views a sentence as a sequence of one or more yields of separate, independent trees." ></td>
	<td class="line x" title="26:216	The points of segmentation are a hidden variable, and during learning all possible segmentations are entertained probabilistically." ></td>
	<td class="line x" title="27:216	This allows the learner to accept hypotheses that explain the sentences as independent pieces." ></td>
	<td class="line x" title="28:216	In 6 we briefly review contrastive estimation (Smith and Eisner, 2005a), relating it to the new method, and show its performance alone and when augmented with structural bias." ></td>
	<td class="line x" title="29:216	2 Task and Model In this paper we use a simple unlexicalized dependency model due to Klein and Manning (2004)." ></td>
	<td class="line x" title="30:216	The model is a probabilistic head automaton grammar (Alshawi, 1996) with a split form that renders it parseable in cubic time (Eisner, 1997)." ></td>
	<td class="line x" title="31:216	Let x = x1,x2,,xn be the sentence." ></td>
	<td class="line x" title="32:216	x0 is a special wall symbol, $, on the left of every sentence." ></td>
	<td class="line x" title="33:216	A tree y is defined by a pair of functions yleft and yright (both {0,1,2,,n}  21,2,,n}) that map each word to its sets of left and right dependents, respectively." ></td>
	<td class="line x" title="34:216	The graph is constrained to be a projective tree rooted at $: each word except $ has a single parent, and there are no cycles 569 or crossing dependencies.2 yleft(0) is taken to be empty, and yright(0) contains the sentences single head." ></td>
	<td class="line x" title="35:216	Let yi denote the subtree rooted at position i. The probability P(yi | xi) of generating this subtree, given its head word xi, is defined recursively: productdisplay D{left,right} pstop(stop | xi,D,[yD(i) = ]) (1)  productdisplay jyD(i) pstop(stop | xi,D,firsty(j)) pchild(xj | xi,D)P(yj | xj) where firsty(j) is a predicate defined to be true iff xj is the closest child (on either side) to its parent xi." ></td>
	<td class="line x" title="36:216	The probability of the entire tree is given by p(x,y) = P(y0 | $)." ></td>
	<td class="line x" title="37:216	The parameters  are the conditional distributions pstop and pchild." ></td>
	<td class="line x" title="38:216	Experimental baseline: EM." ></td>
	<td class="line x" title="39:216	Following common practice, we always replace words by part-ofspeech (POS) tags before training or testing." ></td>
	<td class="line x" title="40:216	We used the EM algorithm to train this model on POS sequences in six languages." ></td>
	<td class="line x" title="41:216	Complete experimental details are given in the appendix." ></td>
	<td class="line x" title="42:216	Performance with unsupervised and supervised model selection across different  values in add- smoothing and three initializers (0) is reported in Table 1." ></td>
	<td class="line x" title="43:216	The supervised-selected model is in the 4055% F1-accuracy range on directed dependency attachments." ></td>
	<td class="line x" title="44:216	(Here F1  precision  recall; see appendix)." ></td>
	<td class="line x" title="45:216	Supervised model selection, which uses a small annotated development set, performs almost as well as the oracle, but unsupervised model selection, which selects the model that maximizes likelihood on an unannotated development set, is often much worse." ></td>
	<td class="line x" title="46:216	3 Locality Bias among Trees Hidden-variable estimation algorithms including EMtypically work by iteratively manipulating the model parameters  to improve an objective function F()." ></td>
	<td class="line x" title="47:216	EM explicitly alternates between the computation of a posterior distribution over hypotheses, p(y | x) (where y is any tree with yield x), and computing a new parameter estimate .3 2A projective parser could achieve perfect accuracy on our English and Mandarin datasets, > 99% on Bulgarian, Turkish, and Portuguese, and > 98% on German." ></td>
	<td class="line x" title="48:216	3For weighted grammar-based models, the posterior does not need to be explicitly represented; instead expectations under p are used to compute updates to ." ></td>
	<td class="line x" title="49:216	0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 -1 -0.8 -0.6 -0.4 -0.2 0 0.2 d F (EM baseline) GermanEnglish BulgarianMandarin TurkishPortuguese Figure 1: Test-set F1 performance of models trained by EM with a locality bias at varying ." ></td>
	<td class="line x" title="50:216	Each curve corresponds to a different language and shows performance of supervised model selection within a given , across  and (0) values." ></td>
	<td class="line x" title="51:216	(See Table 3 for performance of models selected across s.) We decode with  = 0, though we found that keeping the training-time value of  would have had almost no effect." ></td>
	<td class="line x" title="52:216	The EM baseline corresponds to  = 0." ></td>
	<td class="line x" title="53:216	One way to bias a learner toward local explanations is to penalize longer attachments." ></td>
	<td class="line x" title="54:216	This was done for supervised parsing in different ways by Collins (1997), Klein and Manning (2003), and McDonald et al.(2005), all of whom considered intervening material or coarse distance classes when predicting children in a tree." ></td>
	<td class="line x" title="56:216	Eisner and Smith (2005) achieved speed and accuracy improvements by modeling distance directly in a ML-estimated (deficient) generative model." ></td>
	<td class="line x" title="57:216	Here we use string distance to measure the length of a dependency link and consider the inclusion of a sum-of-lengths feature in the probabilistic model, for learning only." ></td>
	<td class="line x" title="58:216	Keeping our original model, we will simply multiply into the probability of each tree another factor that penalizes long dependencies, giving: pprime(x,y)  p(x,y)e    nsummationdisplay i=1 summationdisplay jy(i) |ij|    (2) where y(i) = yleft(i)  yright(i)." ></td>
	<td class="line x" title="59:216	Note that if  = 0, we have the original model." ></td>
	<td class="line x" title="60:216	As   , the new model pprime will favor parses with shorter dependencies." ></td>
	<td class="line x" title="61:216	The dynamic programming algorithms remain the same as before, with the appropriate e|ij| factor multiplied in at each attachment between xi and xj." ></td>
	<td class="line x" title="62:216	Note that when  = 0, pprime  p." ></td>
	<td class="line x" title="63:216	Experiment." ></td>
	<td class="line x" title="64:216	We applied a locality bias to the same dependency model by setting  to different 570 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 -1 -0.5 0 0.5 1 1.5 d F GermanBulgarian Turkish Figure 2: Test-set F1 performance of models trained by EM with structural annealing on the distance weight ." ></td>
	<td class="line x" title="65:216	Here we show performance with add-10 smoothing, the all-zero initializer, for three languages with three different initial values 0." ></td>
	<td class="line x" title="66:216	Time progresses from left to right." ></td>
	<td class="line x" title="67:216	Note that it is generally best to start at 0 lessmuch0; note also the importance of picking the right point on the curve to stop." ></td>
	<td class="line x" title="68:216	See Table 3 for performance of models selected across smoothing, initialization, starting, and stopping choices, in all six languages." ></td>
	<td class="line x" title="69:216	values in [1,0.2] (see Eq." ></td>
	<td class="line x" title="70:216	2)." ></td>
	<td class="line x" title="71:216	The same initializers (0) and smoothing conditions were tested." ></td>
	<td class="line x" title="72:216	Performance of supervised model selection among models trained at different  values is plotted in Fig." ></td>
	<td class="line x" title="73:216	1." ></td>
	<td class="line x" title="74:216	When a model is selected across all conditions (3 initializers  6 smoothing values  7 s) using annotated development data, performance is notably better than the EM baseline using the same selection procedure (see Table 3, second column)." ></td>
	<td class="line x" title="75:216	4 Structural Annealing The central idea of this paper is to gradually change (anneal) the bias ." ></td>
	<td class="line x" title="76:216	Early in learning, local dependencies are emphasized by setting  lessmuch 0." ></td>
	<td class="line x" title="77:216	Then  is iteratively increased and training repeated, using the last learned model to initialize." ></td>
	<td class="line x" title="78:216	This idea bears a strong similarity to deterministic annealing (DA), a technique used in clustering and classification to smooth out objective functions that are piecewise constant (hence discontinuous) or bumpy (non-concave) (Rose, 1998; Ueda and Nakano, 1998)." ></td>
	<td class="line x" title="79:216	In unsupervised learning, DA iteratively re-estimates parameters like EM, but begins by requiring that the entropy of the posterior p(y | x) be maximal, then gradually relaxes this entropy constraint." ></td>
	<td class="line x" title="80:216	Since entropy is concave in , the initial task is easy (maximize a concave, continuous function)." ></td>
	<td class="line x" title="81:216	At each step the optimization task becomes more difficult, but the initializer is given by the previous step and, in practice, tends to be close to a good local maximum of the more difficult objective." ></td>
	<td class="line x" title="82:216	By the last iteration the objective is the same as in EM, but the annealed search process has acted like a good initializer." ></td>
	<td class="line x" title="83:216	This method was applied with some success to grammar induction models by Smith and Eisner (2004)." ></td>
	<td class="line x" title="84:216	In this work, instead of imposing constraints on the entropy of the model, we manipulate bias toward local hypotheses." ></td>
	<td class="line x" title="85:216	As  increases, we penalize long dependencies less." ></td>
	<td class="line x" title="86:216	We call this structural annealing, since we are varying the strength of a soft constraint (bias) on structural hypotheses." ></td>
	<td class="line x" title="87:216	In structural annealing, the final objective would be the same as EM if our final , f = 0, but we found that annealing farther (f > 0) works much better.4 Experiment: Annealing ." ></td>
	<td class="line x" title="88:216	We experimented with annealing schedules for ." ></td>
	<td class="line x" title="89:216	We initialized at 0  {1,0.4,0.2}, and increased  by 0.1 (in the first case) or 0.05 (in the others) up to f = 3." ></td>
	<td class="line x" title="90:216	Models were trained to convergence at each epoch." ></td>
	<td class="line x" title="91:216	Model selection was applied over the same initialization and regularization conditions as before, 0, and also over the choice of f, with stopping allowed at any stage along the  trajectory." ></td>
	<td class="line x" title="92:216	Trajectories for three languages with three different 0 values are plotted in Fig." ></td>
	<td class="line x" title="93:216	2." ></td>
	<td class="line x" title="94:216	Generally speaking, 0 lessmuch 0 performs better." ></td>
	<td class="line x" title="95:216	There is consistently an early increase in performance as  increases, but the stopping f matters tremendously." ></td>
	<td class="line x" title="96:216	Selected annealed- models surpass EM in all six languages; see the third column of Table 3." ></td>
	<td class="line x" title="97:216	Note that structural annealing does not always outperform fixed- training (English and Portuguese)." ></td>
	<td class="line x" title="98:216	This is because we only tested a few values of 0, since annealing requires longer runtime." ></td>
	<td class="line x" title="99:216	5 Structural Bias via Segmentation A related way to focus on local structure early in learning is to broaden the set of hypotheses to include partial parse structures." ></td>
	<td class="line x" title="100:216	If x = x1,x2,,xn, the standard approach assumes that x corresponds to the vertices of a single dependency tree." ></td>
	<td class="line x" title="101:216	Instead, we entertain every hypothesis in which x is a sequence of yields from separate, independently-generated trees." ></td>
	<td class="line x" title="102:216	For example, x1,x2,x3 is the yield of one tree, x4,x5 is the 4The reader may note that f > 0 actually corresponds to a bias toward longer attachments." ></td>
	<td class="line x" title="103:216	A more apt description in the context of annealing is to say that during early stages the learner starts liking local attachments too much, and we need to exaggerate  to coax it to new hypotheses." ></td>
	<td class="line x" title="104:216	See Fig." ></td>
	<td class="line x" title="105:216	2." ></td>
	<td class="line x" title="106:216	571 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 -1.5-1-0.5 0 0.5 b F GermanBulgarianTurkish Figure 3: Test-set F1 performance of models trained by EM with structural annealing on the breakage weight ." ></td>
	<td class="line x" title="107:216	Here we show performance with add-10 smoothing, the all-zero initializer, for three languages with three different initial values 0." ></td>
	<td class="line x" title="108:216	Time progresses from left (large ) to right." ></td>
	<td class="line x" title="109:216	See Table 3 for performance of models selected across smoothing, initialization, and stopping choices, in all six languages." ></td>
	<td class="line x" title="110:216	yield of a second, and x6,,xn is the yield of a third." ></td>
	<td class="line x" title="111:216	One extreme hypothesis is that x is n singlenode trees." ></td>
	<td class="line x" title="112:216	At the other end of the spectrum is the original set of hypothesesfull trees on x. Each has a nonzero probability." ></td>
	<td class="line x" title="113:216	Segmented analyses are intermediate representations that may be helpful for a learner to use to formulate notions of probable local structure, without committing to full trees.5 We only allow unobserved breaks, never positing a hard segmentation of the training sentences." ></td>
	<td class="line x" title="114:216	Over time, we increase the bias against broken structures, forcing the learner to commit most of its probability mass to full trees." ></td>
	<td class="line x" title="115:216	5.1 Vine Parsing At first glance broadening the hypothesis space to entertain all 2n1 possible segmentations may seem expensive." ></td>
	<td class="line x" title="116:216	In fact the dynamic programming computation is almost the same as summing or maximizing over connected dependency trees." ></td>
	<td class="line x" title="117:216	For the latter, we use an inside-outside algorithm that computes a score for every parse tree by computing the scores of items, or partial structures, through a bottom-up process." ></td>
	<td class="line x" title="118:216	Smaller items are built first, then assembled using a set of rules defining how larger items can be built.6 Now note that any sequence of partial trees over x can be constructed by combining the same items into trees." ></td>
	<td class="line oc" title="119:216	The only difference is that we 5See also work on partial parsing as a task in its own right: Hindle (1990) inter alia." ></td>
	<td class="line x" title="120:216	6See Eisner and Satta (1999) for the relevant algorithm used in the experiments." ></td>
	<td class="line x" title="121:216	are willing to consider unassembled sequences of these partial trees as hypotheses, in addition to the fully connected trees." ></td>
	<td class="line x" title="122:216	One way to accomplish this in terms of yright(0) is to say that the root, $, is allowed to have multiple children, instead of just one." ></td>
	<td class="line x" title="123:216	Here, these children are independent of each other (e.g. , generated by a unigram Markov model)." ></td>
	<td class="line x" title="124:216	In supervised dependency parsing, Eisner and Smith (2005) showed that imposing a hard constraint on the whole structure specifically that each non-$ dependency arc cross fewer than k wordscan give guaranteed O(nk2) runtime with little to no loss in accuracy (for simple models)." ></td>
	<td class="line x" title="125:216	This constraint could lead to highly contrived parse trees, or none at all, for some sentencesboth are avoided by the allowance of segmentation into a sequence of trees (each attached to $)." ></td>
	<td class="line x" title="126:216	The construction of the vine (sequence of $s children) takes only O(n) time once the chart has been assembled." ></td>
	<td class="line x" title="127:216	Our broadened hypothesis model is a probabilistic vine grammar with a unigram model over $s children." ></td>
	<td class="line x" title="128:216	We allow (but do not require) segmentation of sentences, where each independent child of $ is the root of one of the segments." ></td>
	<td class="line x" title="129:216	We do not impose any constraints on dependency length." ></td>
	<td class="line x" title="130:216	5.2 Modeling Segmentation Now the total probability of an n-length sentence x, marginalizing over its hidden structures, sums up not only over trees, but over segmentations of x. For completeness, we must include a probability model over the number of trees generated, which could be anywhere from 1 to n. The model over the number T of trees given a sentence of length n will take the following log-linear form: P(T = t | n) = et slashBigg nsummationdisplay i=1 ei where   R is the sole parameter." ></td>
	<td class="line x" title="131:216	When  = 0, every value of T is equally likely." ></td>
	<td class="line x" title="132:216	For  lessmuch 0, the model prefers larger structures with few breaks." ></td>
	<td class="line x" title="133:216	At the limit (  ), we achieve the standard learning setting, where the model must explain x using a single tree." ></td>
	<td class="line x" title="134:216	We start however at  greatermuch 0, where the model prefers smaller trees with more breaks, in the limit preferring each word in x to be its own tree." ></td>
	<td class="line x" title="135:216	We could describe brokenness as a feature in the model whose weight, , is chosen extrinsically (and time-dependently), rather than empiricallyjust as was done with ." ></td>
	<td class="line x" title="136:216	572 model selection among values of 2 and (0) worst unsup." ></td>
	<td class="line x" title="137:216	sup." ></td>
	<td class="line x" title="138:216	oracle DORT1 32.5 59.3 63.4 63.4 Ger." ></td>
	<td class="line x" title="139:216	LENGTH 30.5 56.4 57.3 57.8 DORT1 20.9 56.6 57.4 57.4 Eng." ></td>
	<td class="line x" title="140:216	LENGTH 29.1 37.2 46.2 46.2 DORT1 19.4 26.0 40.5 43.1 Bul." ></td>
	<td class="line x" title="141:216	LENGTH 25.1 35.3 38.3 38.3 DORT1 9.4 24.2 41.1 41.1 Man. LENGTH 13.7 17.9 26.2 26.2 DORT1 7.3 38.6 58.2 58.2 Tur . LENGTH 21.5 34.1 55.5 55.5 DORT1 35.0 59.8 71.8 71.8 Por . LENGTH 30.8 33.6 33.6 33.6 Table 2: Performance of CE on test data, for different neighborhoods and with different levels of regularization." ></td>
	<td class="line x" title="142:216	Boldface marks scores better than EM-trained models selected the same way (Table 1)." ></td>
	<td class="line x" title="143:216	The score is the F1 measure on non-$ attachments." ></td>
	<td class="line x" title="144:216	Annealing  resembles the popular bootstrapping technique (Yarowsky, 1995), which starts out aiming for high precision, and gradually improves coverage over time." ></td>
	<td class="line x" title="145:216	With strong bias ( greatermuch 0), we seek a model that maintains high dependency precision on (non-$) attachments by attaching most tags to $." ></td>
	<td class="line x" title="146:216	Over time, as this is iteratively weakened (  ), we hope to improve coverage (dependency recall)." ></td>
	<td class="line x" title="147:216	Bootstrapping was applied to syntax learning by Steedman et al.(2003)." ></td>
	<td class="line x" title="149:216	Our approach differs in being able to remain partly agnostic about each tags true parent (e.g. , by giving 50% probability to attaching to $), whereas Steedman et al. make a hard decision to retrain on a whole sentence fully or leave it out fully." ></td>
	<td class="line x" title="150:216	In earlier work, Brill and Marcus (1992) adopted a local first iterative merge strategy for discovering phrase structure." ></td>
	<td class="line x" title="151:216	Experiment: Annealing ." ></td>
	<td class="line x" title="152:216	We experimented with different annealing schedules for ." ></td>
	<td class="line x" title="153:216	The initial value of , 0, was one of {12,0, 12}." ></td>
	<td class="line x" title="154:216	After EM training,  was diminished by 110; this was repeated down to a value of f = 3." ></td>
	<td class="line x" title="155:216	Performance after training at each  value is shown in Fig." ></td>
	<td class="line x" title="156:216	3.7 We see that, typically, there is a sharp increase in performance somewhere during training, which typically lessens as   ." ></td>
	<td class="line x" title="157:216	Starting  too high can also damage performance." ></td>
	<td class="line x" title="158:216	This method, then, 7Performance measures are given using a full parser that finds the single best parse of the sentence with the learned parsing parameters." ></td>
	<td class="line x" title="159:216	Had we decoded with a vine parser, we would see a precisionarrowsoutheast, recallarrownortheast curve as  decreased." ></td>
	<td class="line x" title="160:216	is not robust to the choice of ,0, or f, nor does it always do as well as annealing , although considerable gains are possible; see the fifth column of Table 3." ></td>
	<td class="line x" title="161:216	By testing models trained with a fixed value of  (for values in [1,1]), we ascertained that the performance improvement is due largely to annealing, not just the injection of segmentation bias (fourth vs. fifth column of Table 3).8 6 Comparison and Combination with Contrastive Estimation Contrastive estimation (CE) was recently introduced (Smith and Eisner, 2005a) as a class of alternatives to the likelihood objective function locally maximized by EM." ></td>
	<td class="line x" title="162:216	CE was found to outperform EM on the task of focus in this paper, when applied to English data (Smith and Eisner, 2005b)." ></td>
	<td class="line x" title="163:216	Here we review the method briefly, show how it performs across languages, and demonstrate that it can be combined effectively with structural bias." ></td>
	<td class="line x" title="164:216	Contrastive training defines for each example xi a class of presumably poor, but similar, instances called the neighborhood, N(xi), and seeks to maximize CN() = summationdisplay i logp(xi |N(xi)) = summationdisplay i log summationtext y p(xi,y)summationtext xprimeN(xi) summationtext y p(xprime,y) At this point we switch to a log-linear (rather than stochastic) parameterization of the same weighted grammar, for ease of numerical optimization." ></td>
	<td class="line x" title="165:216	All this means is that  (specifically, pstop and pchild in Eq." ></td>
	<td class="line x" title="166:216	1) is now a set of nonnegative weights rather than probabilities." ></td>
	<td class="line x" title="167:216	Neighborhoods that can be expressed as finitestate lattices built from xi were shown to give significant improvements in dependency parser quality over EM." ></td>
	<td class="line x" title="168:216	Performance of CE using two of those neighborhoods on the current model and datasets is shown in Table 2.9 0-mean diagonal Gaussian smoothing was applied, with different variances, and model selection was applied over smoothing conditions and the same initializers as 8In principle, segmentation can be combined with the locality bias in 3 ()." ></td>
	<td class="line x" title="169:216	In practice, we found that this usually under-performed the EM baseline." ></td>
	<td class="line x" title="170:216	9We experimented with DELETE1, TRANSPOSE1, DELETEORTRANSPOSE1, and LENGTH." ></td>
	<td class="line x" title="171:216	To conserve space we show only the latter two, which tend to perform best." ></td>
	<td class="line x" title="172:216	573 EM fixed  annealed  fixed  annealed  CE fixed  + CE  0 f  0 f N N, German 54.4 61.3 0.2 70.0 -0.4  0.4 66.2 0.4 68.9 0.5  -2.4 63.4 DORT1 63.8 DORT1, -0.2 English 41.6 61.8 -0.6 53.8 -0.4  0.3 55.6 0.2 58.4 0.5  0.0 57.4 DORT1 63.5 DORT1, -0.4 Bulgarian 45.6 49.2 -0.2 58.3 -0.4  0.2 47.3 -0.2 56.5 0  -1.7 40.5 DORT1  Mandarin 50.0 51.1 -0.4 58.0 -1.0  0.2 38.0 0.2 57.2 0.5  -1.4 43.4 DEL1  Turkish 48.0 62.3 -0.2 62.4 -0.2  -0.15 53.6 -0.2 59.4 0.5  -0.7 58.2 DORT1 61.8 DORT1, -0.6 Portuguese 42.3 50.4 -0.4 50.2 -0.4  -0.1 51.5 0.2 62.7 0.5  -0.5 71.8 DORT1 72.6 DORT1, -0.2 Table 3: Summary comparing models trained in a variety of ways with some relevant hyperparameters." ></td>
	<td class="line x" title="173:216	Supervised model selection was applied in all cases, including EM (see the appendix)." ></td>
	<td class="line x" title="174:216	Boldface marks the best performance overall and trials that this performance did not significantly surpass under a sign test (i.e. , p negationslash< 0.05)." ></td>
	<td class="line x" title="175:216	The score is the F1 measure on non-$ attachments." ></td>
	<td class="line x" title="176:216	The fixed  + CE condition was tested only for languages where CE improved over EM." ></td>
	<td class="line x" title="177:216	before." ></td>
	<td class="line x" title="178:216	Four of the languages have at least one effective CE condition, supporting our previous English results (Smith and Eisner, 2005b), but CE was harmful for Bulgarian and Mandarin." ></td>
	<td class="line x" title="179:216	Perhaps better neighborhoods exist for these languages, or there is some ideal neighborhood that would perform well for all languages." ></td>
	<td class="line x" title="180:216	Our approach of allowing broken trees (5) is a natural extension of the CE framework." ></td>
	<td class="line x" title="181:216	Contrastive estimation views learning as a process of moving posterior probability mass from (implicit) negative examples to (explicit) positive examples." ></td>
	<td class="line x" title="182:216	The positive evidence, as in MLE, is taken to be the observed data." ></td>
	<td class="line x" title="183:216	As originally proposed, CE allowed a redefinition of the implicit negative evidence from all other sentences (as in MLE) to sentences like xi, but perturbed. Allowing segmentation of the training sentences redefines the positive and negative evidence." ></td>
	<td class="line x" title="184:216	Rather than moving probability mass only to full analyses of the training example xi, we also allow probability mass to go to partial analyses of xi." ></td>
	<td class="line x" title="185:216	By injecting a bias ( negationslash= 0 or  > ) among tree hypotheses, however, we have gone beyond the CE framework." ></td>
	<td class="line x" title="186:216	We have added features to the tree model (dependency length-sum, number of breaks), whose weights we extrinsically manipulate over time to impose locality bias CN and improve search on CN." ></td>
	<td class="line x" title="187:216	Another idea, not explored here, is to change the contents of the neighborhood N over time." ></td>
	<td class="line x" title="188:216	Experiment: Locality Bias within CE." ></td>
	<td class="line x" title="189:216	We combined CE with a fixed- locality bias for neighborhoods that were successful in the earlier CE experiment, namely DELETEORTRANSPOSE1 for German, English, Turkish, and Portuguese." ></td>
	<td class="line x" title="190:216	Our results, shown in the seventh column of Table 3, show that, in all cases except Turkish, the combination improves over either technique on its own." ></td>
	<td class="line x" title="191:216	We leave exploration of structural annealing with CE to future work." ></td>
	<td class="line x" title="192:216	Experiment: Segmentation Bias within CE." ></td>
	<td class="line x" title="193:216	For (language, N) pairs where CE was effective, we trained models using CE with a fixed segmentation model." ></td>
	<td class="line x" title="194:216	Across conditions (  [1,1]), these models performed very badly, hypothesizing extremely local parse trees: typically over 90% of dependencies were length 1 and pointed in the same direction, compared with the 6070% length-1 rate seen in gold standards." ></td>
	<td class="line x" title="195:216	To understand why, consider that the CE goal is to maximize the score of a sentence and all its segmentations while minimizing the scores of neighborhood sentences and their segmentations." ></td>
	<td class="line x" title="196:216	An ngram model can accomplish this, since the same n-grams are present in all segmentations of x, and (some) different n-grams appear in N(x) (for LENGTH and DELETEORTRANSPOSE1)." ></td>
	<td class="line x" title="197:216	A bigram-like model that favors monotone branching, then, is not a bad choice for a CE learner that must account for segmentations of x and N(x)." ></td>
	<td class="line x" title="198:216	Why doesnt CE without segmentation resort to n-gram-like models?" ></td>
	<td class="line x" title="199:216	Inspection of models trained using the standard CE method (no segmentation) with transposition-based neighborhoods TRANSPOSE1 and DELETEORTRANSPOSE1 did have high rates of length-1 dependencies, while the poorly-performing DELETE1 models found low length-1 rates." ></td>
	<td class="line x" title="200:216	This suggests that a bias toward locality (n-gram-ness) is built into the former neighborhoods, and may partly explain why CE works when it does." ></td>
	<td class="line x" title="201:216	We achieved a similar locality bias in the likelihood framework when we broadened the hypothesis space, but doing so under CE over-focuses the model on local structures." ></td>
	<td class="line x" title="202:216	574 7 Error Analysis We compared errors made by the selected EM condition with the best overall condition, for each language." ></td>
	<td class="line x" title="203:216	We found that the number of corrected attachments always outnumbered the number of new errors by a factor of two or more." ></td>
	<td class="line x" title="204:216	Further, the new models are not getting better by merely reversing the direction of links made by EM; undirected accuracy also improved significantly under a sign test (p < 106), across all six languages." ></td>
	<td class="line x" title="205:216	While the most common corrections were to nouns, these account for only 2541% of corrections, indicating that corrections are not all of the same kind. Finally, since more than half of corrections in every language involved reattachment to a noun or a verb (content word), we believe the improved models to be getting closer than EM to the deeper semantic relations between words that, ideally, syntactic models should uncover." ></td>
	<td class="line x" title="206:216	8 Future Work One weakness of all recent weighted grammar induction workincluding Klein and Manning (2004), Smith and Eisner (2005b), and the present paperis a sensitivity to hyperparameters, including smoothing values, choice of N (for CE), and annealing schedulesnot to mention initialization." ></td>
	<td class="line x" title="207:216	This is quite observable in the results we have presented." ></td>
	<td class="line x" title="208:216	An obstacle for unsupervised learning in general is the need for automatic, efficient methods for model selection." ></td>
	<td class="line x" title="209:216	For annealing, inspiration may be drawn from continuation methods; see, e.g., Elidan and Friedman (2005)." ></td>
	<td class="line x" title="210:216	Ideally one would like to select values simultaneously for many hyperparameters, perhaps using a small annotated corpus (as done here), extrinsic figures of merit on successful learning trajectories, or plausibility criteria (Eisner and Karakos, 2005)." ></td>
	<td class="line x" title="211:216	Grammar induction serves as a tidy example for structural annealing." ></td>
	<td class="line x" title="212:216	In future work, we envision that other kinds of structural bias and annealing will be useful in other difficult learning problems where hidden structure is required, including machine translation, where the structure can consist of word correspondences or phrasal or recursive syntax with correspondences." ></td>
	<td class="line x" title="213:216	The technique bears some similarity to the estimation methods described by Brown et al.(1993), which started by estimating simple models, using each model to seed the next." ></td>
	<td class="line x" title="215:216	9 Conclusion We have presented a new unsupervised parameter estimation method, structural annealing, for learning hidden structure that biases toward simplicity and gradually weakens (anneals) the bias over time." ></td>
	<td class="line x" title="216:216	We applied the technique to weighted dependency grammar induction and achieved a significant gain in accuracy over EM and CE, raising the state-of-the-art across six languages from 42 54% to 5873% accuracy." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-1100
Ontologizing Semantic Relations
Pennacchiotti, Marco;Pantel, Patrick;"></td>
	<td class="line x" title="1:185	Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 793800, Sydney, July 2006." ></td>
	<td class="line x" title="2:185	c2006 Association for Computational Linguistics Ontologizing Semantic Relations Marco Pennacchiotti ART Group DISP University of Rome Tor Vergata Viale del Politecnico 1 Rome, Italy pennacchiotti@info.uniroma2.it Patrick Pantel Information Sciences Institute University of Southern California 4676 Admiralty Way Marina del Rey, CA90292 pantel@isi.edu Abstract Many algorithms have been developed to harvest lexical semantic resources, however few have linked the mined knowledge into formal knowledge repositories." ></td>
	<td class="line x" title="3:185	In this paper, we propose two algorithms for automatically ontologizing (attaching) semantic relations into WordNet." ></td>
	<td class="line x" title="4:185	We present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model." ></td>
	<td class="line oc" title="5:185	1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al. 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990)." ></td>
	<td class="line x" title="6:185	Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations." ></td>
	<td class="line x" title="7:185	The output of most of these systems is flat lists of lexical semantic knowledge such as Italy is-a country and orange similar-to blue." ></td>
	<td class="line x" title="8:185	However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as ontologies or term banks like WordNet (Fellbaum 1998)." ></td>
	<td class="line x" title="9:185	Pantel (2005) defined the task of ontologizing a lexical semantic resource as linking its terms to the concepts in a WordNet-like hierarchy." ></td>
	<td class="line x" title="10:185	For example, orange similar-to blue ontologizes in WordNet to orange#2 similar-to blue#1 and orange#2 similar-to blue#2." ></td>
	<td class="line x" title="11:185	In his framework, Pantel proposed a method of inducing ontological co-occurrence vectors 1 which are subsequently used to ontologize unknown terms into WordNet with 74% accuracy." ></td>
	<td class="line x" title="12:185	In this paper, we take the next step and explore two algorithms for ontologizing binary semantic relations into WordNet and we present empirical results on the task of attaching part-of and causation relations." ></td>
	<td class="line x" title="13:185	Formally, given an instance (x, r, y) of a binary relation r between terms x and y, the ontologizing task is to identify the WordNet senses of x and y where r holds." ></td>
	<td class="line x" title="14:185	For example, the instance (proton, PART-OF, element) ontologizes into WordNet as (proton#1, PART-OF, element#2)." ></td>
	<td class="line x" title="15:185	The first algorithm that we explore, called the anchoring approach, was suggested as a promising avenue of future work in (Pantel 2005)." ></td>
	<td class="line x" title="16:185	This bottom up algorithm is based on the intuition that x can be disambiguated by retrieving the set of terms that occur in the same relation r with y and then finding the senses of x that are most similar to this set." ></td>
	<td class="line x" title="17:185	The assumption is that terms occurring in the same relation will tend to have similar meaning." ></td>
	<td class="line x" title="18:185	In this paper, we propose a measure of similarity to capture this intuition." ></td>
	<td class="line x" title="19:185	In contrast to anchoring, our second algorithm, called the clustering approach, takes a top-down view." ></td>
	<td class="line x" title="20:185	Given a relation r, suppose that we are given every conceptual instance of r, i.e., instances of r in the upper ontology like (particles#1, PART-OF, substances#1)." ></td>
	<td class="line x" title="21:185	An instance (x, r, y) can then be ontologized easily by finding the senses of x and y that are subsumed by ancestors linked by a conceptual instance of r. For example, the instance (proton, PART-OF, element) ontologizes to (proton#1, PART-OF, element#2) since proton#1 is subsumed by particles and element#2 is subsumed by substances." ></td>
	<td class="line x" title="22:185	The problem then is to automatically infer the set of con1 The ontological co-occurrence vector of a concept consists of all lexical co-occurrences with the concept in a corpus." ></td>
	<td class="line x" title="23:185	793 ceptual instances." ></td>
	<td class="line x" title="24:185	In this paper, we develop a clustering algorithm for generalizing a set of relation instances to conceptual instances by looking up the WordNet hypernymy hierarchy for common ancestors, as specific as possible, that subsume as many instances as possible." ></td>
	<td class="line x" title="25:185	An instance is then attached to its senses that are subsumed by the highest scoring conceptual instances." ></td>
	<td class="line x" title="26:185	2 Relevant Work Several researchers have worked on ontologizing semantic resources." ></td>
	<td class="line x" title="27:185	Most recently, Pantel (2005) developed a method to propagate lexical cooccurrence vectors to WordNet synsets, forming ontological co-occurrence vectors." ></td>
	<td class="line x" title="28:185	Adopting an extension of the distributional hypothesis (Harris 1985), the co-occurrence vectors are used to compute the similarity between synset/synset and between lexical term/synset." ></td>
	<td class="line x" title="29:185	An unknown term is then attached to the WordNet synset whose cooccurrence vector is most similar to the terms co-occurrence vector." ></td>
	<td class="line x" title="30:185	Though the author suggests a method for attaching more complex lexical structures like binary semantic relations, the paper focused only on attaching terms." ></td>
	<td class="line x" title="31:185	Basili (2000) proposed an unsupervised method to infer semantic classes (WordNet synsets) for terms in domain-specific verb relations." ></td>
	<td class="line x" title="32:185	These relations, such as (x, EXPAND, y) are first automatically learnt from a corpus." ></td>
	<td class="line x" title="33:185	The semantic classes of x and y are then inferred using conceptual density (Agirre and Rigau 1996), a WordNet-based measure applied to all instantiation of x and y in the corpus." ></td>
	<td class="line x" title="34:185	Semantic classes represent possible common generalizations of the verb arguments." ></td>
	<td class="line x" title="35:185	At the end of the process, a set of syntactic-semantic patterns are available for each verb, such as: (social_group#1, expand, act#2) (instrumentality#2, expand, act#2) The method is successful on specific relations with few instances (such as domain verb relations) while its value on generic and frequent relations, such as part-of, was untested." ></td>
	<td class="line x" title="36:185	Girju et al.(2003) presented a highly supervised machine learning algorithm to infer semantic constraints on part-of relations, such as (object#1, PART-OF, social_event#1)." ></td>
	<td class="line x" title="38:185	These constraints are then used as selectional restrictions in harvesting part-of instances from ambiguous lexical patterns, like X of Y." ></td>
	<td class="line x" title="39:185	The approach shows high performance in terms of precision and recall, but, as the authors acknowledge, it requires large human effort during the training phase." ></td>
	<td class="line x" title="40:185	Others have also made significant additions to WordNet." ></td>
	<td class="line x" title="41:185	For example, in eXtended WordNet (Harabagiu et al. 1999), the glosses in WordNet are enriched by disambiguating the nouns, verbs, adverbs, and adjectives with synsets." ></td>
	<td class="line x" title="42:185	Another work has enriched WordNet synsets with topically related words extracted from the Web (Agirre et al. 2001)." ></td>
	<td class="line x" title="43:185	Finally, the general task of word sense disambiguation (Gale et al. 1991) is relevant since there the task is to ontologize each term in a passage into a WordNet-like sense inventory." ></td>
	<td class="line x" title="44:185	If we had a large collection of sensetagged text, then our mining algorithms could directly discover WordNet attachment points at harvest time." ></td>
	<td class="line x" title="45:185	However, since there is little high precision sense-tagged corpora, methods are required to ontologize semantic resources without fully disambiguating text." ></td>
	<td class="line x" title="46:185	3 Ontologizing Semantic Relations Given an instance (x, r, y) of a binary relation r between terms x and y, the ontologizing task is to identify the senses of x and y where r holds." ></td>
	<td class="line x" title="47:185	In this paper, we focus on WordNet 2.0 senses, though any similar term bank would apply." ></td>
	<td class="line x" title="48:185	Let S x and S y be the sets of all WordNet senses of x and y. A sense pair, s xy, is defined as any pair of senses of x and y: s xy ={s x, s y } where s x S x and s y S y. The set of all sense pairs S xy consists of all permutations between senses in S x and S y . In order to attach a relation instance (x, r, y) into WordNet, one must:  Disambiguate x and y, that is, find the subsets S' x S x and S' y S y for which the relation r holds; and  Instantiate the relation in WordNet, using the synsets corresponding to all correct permutations between the senses in S' x and S' y . We denote this set of attachment points as S' xy . If S x or S y is empty, no attachments are produced." ></td>
	<td class="line x" title="49:185	For example, the instance (study, PART-OF, report) is ontologized into WordNet through the senses S' x ={survey#1, study#2} and S y ={report#1}." ></td>
	<td class="line x" title="50:185	The final attachment points S' xy are: (survey#1, PART-OF, report#1) (study#1, PART-OF, report#1) Unlike common algorithms for word sense disambiguation, here it is important to take into consideration the semantic dependency between the two terms x and y. For example, an entity that is part-of a study has to be some kind of informa794 tion." ></td>
	<td class="line x" title="51:185	This knowledge about mutual selectional preference (the preferred semantic class that fills a certain relation role, as x or y) can be exploited to ontologize the instance." ></td>
	<td class="line x" title="52:185	In the following sections, we propose two algorithms for ontologizing binary semantic relations." ></td>
	<td class="line x" title="53:185	3.1 Method 1: Anchor Approach Given an instance (x, r, y), this approach fixes the term y, called the anchor, and then disambiguates x by looking at all other terms that occur in the relation r with y. Based on the principle of distributional similarity (Harris 1985), the algorithm assumes that the words that occur in the same relation r with y will be more similar to the correct sense(s) of x than the incorrect ones." ></td>
	<td class="line x" title="54:185	After disambiguating x, the process is then inverted with x as the anchor to disambiguate y. In the first step, y is fixed and the algorithm retrieves the set of all other terms X' that occur in an instance (x', r, y), x'  X' 2 . For example, given the instance (reflections, PART-OF, book), and a resource containing the following relations: (false allegations, PART-OF, book) (stories, PART-OF, book) (expert analysis, PART-OF, book) (conclusions, PART-OF, book) the resulting set X' would be: {allegations, stories, analysis, conclusions}." ></td>
	<td class="line x" title="55:185	All possible permutations, S xx', between the senses of x and the senses of each term in X', called S x', are computed." ></td>
	<td class="line x" title="56:185	For each sense pair {s x, s x' }  S xx', a similarity score r(s x, s x' ) is calculated using WordNet: )( 1),( 1 ),( ' ' ' x xx xx sf ssd ssr  + = where the distance d(s x, s x' ) is the length of the shortest path connecting the two synsets in the hypernymy hierarchy of WordNet, and f(s x' ) is the number of times sense s x' occurs in any of the instances of X'." ></td>
	<td class="line x" title="57:185	Note that if no connection between two synsets exists, then r(s x, s x' ) = 0." ></td>
	<td class="line x" title="58:185	The overall sense score for each sense s x of x is calculated as:   = '' ),()( ' xx Ss xxx ssrsr Finally, the algorithm inverts the process by setting x as the anchor and computes r(s y ) for 2 For semantic relations between complex terms, like (expert analysis, PART-OF, book), only the head noun of terms are recorded, like analysis." ></td>
	<td class="line x" title="59:185	As a future work, we plan to use the whole term if it is present in WordNet." ></td>
	<td class="line x" title="60:185	each sense of y. All possible permutations of senses are computed and scored by averaging r(s x ) and r(s y )." ></td>
	<td class="line x" title="61:185	Permutations scoring higher than a threshold  1 are selected as the attachment points in WordNet." ></td>
	<td class="line x" title="62:185	We experimentally set  1 = 0.02." ></td>
	<td class="line x" title="63:185	3.2 Method 2: Clustering Approach The main idea of the clustering approach is to leverage the lexical behaviors of the two terms in an instance as a whole." ></td>
	<td class="line x" title="64:185	The assumption is that the general meaning of the relation is derived from the combination of the two terms." ></td>
	<td class="line x" title="65:185	The algorithm is divided in two main phases." ></td>
	<td class="line x" title="66:185	In the first phase, semantic clusters are built using the WordNet senses of all instances." ></td>
	<td class="line x" title="67:185	A semantic cluster is defined by the set of instances that have a common semantic generalization." ></td>
	<td class="line x" title="68:185	We denote the conceptual instance of the semantic cluster as the pair of WordNet synsets that represents this generalization." ></td>
	<td class="line x" title="69:185	For example the following two part-of instances: (second section, PART-OF, Los Angeles-area news) (Sandag study, PART-OF, report) are in a common cluster represented by the following conceptual instance: [writing#2, PART-OF, message#2] since writing#2 is a hypernym of both section and study, and message#2 is a hypernym of news and report 3 . In the second phase, the algorithm attaches an instance into WordNet by using WordNet distance metrics and frequency scores to select the best cluster for each instance." ></td>
	<td class="line x" title="70:185	A good cluster is one that:  achieves a good trade-off between generality and specificity; and  disambiguates among the senses of x and y using the other instances senses as support." ></td>
	<td class="line x" title="71:185	For example, given the instance (second section, PART-OF, Los Angeles-area news) and the following conceptual instances: [writing#2, PART-OF, message#2] object#1, PART-OF, message#2] [writing#2, PART-OF, communication#2] social_group#1, PART-OF, broadcast#2] [organization#, PART-OF, message#2] the first conceptual instance should be scored highest since it is both not too generic nor too specific and is supported by the instance (Sandag study, PART-OF, report), i.e., the conceptual instance subsumes both instances." ></td>
	<td class="line x" title="72:185	The second and 3 Again, here, we use the syntactic head of each term for generalization since we assume that it drives the meaning of the term itself." ></td>
	<td class="line x" title="73:185	795 the third conceptual instances should be scored lower since they are too generic, while the last two should be scored lower since the sense for section and news are not supported by other instances." ></td>
	<td class="line x" title="74:185	The system then outputs, for each instance, the set of sense pairs that are subsumed by the highest scoring conceptual instance." ></td>
	<td class="line x" title="75:185	In the previous example: (section#1, PART-OF, news#1) (section#1, PART-OF, news#2) (section#1, PART-OF, news#3) are selected, as they are subsumed by [writing#2, PART-OF, message#2]." ></td>
	<td class="line x" title="76:185	These sense pairs are then retained as attachment points into WordNet." ></td>
	<td class="line x" title="77:185	Below, we describe each phase in more detail." ></td>
	<td class="line x" title="78:185	Phase 1: Cluster Building Given an instance (x, r, y), all sense pair permutations s xy ={s x, s y } are retrieved from WordNet." ></td>
	<td class="line x" title="79:185	A set of candidate conceptual instances, C xy, is formed for each instance from the permutation of each WordNet ancestor of s x and s y, following the hypernymy link, up to degree  2 . Each candidate conceptual instance, c={c x, c y }, is scored by its degree of generalization as follows: )1()1( 1 )( ++ = yx nn cr where n i is the number of hypernymy links needed to go from s i to c i, for i  {x, y}." ></td>
	<td class="line x" title="80:185	r(c) ranges from [0, 1] and is highest when little generalization is needed." ></td>
	<td class="line x" title="81:185	For example, the instance (Sandag study, PART-OF, report) produces 70 sense pairs since study has 10 senses and report has 7 senses." ></td>
	<td class="line x" title="82:185	Assuming  2 =1, the instance sense (survey#1, PARTOF, report#1) has the following set of candidate conceptual instances: C xy n x n y r(c) (survey#1, PART-OF,report#1) 0 0 1 (survey#1, PART-OF,document#1) 0 1 0.5 (examination#1, PART-OF,report#1) 1 0 0.5 (examination#1, PART-OF,document#1) 1 1 0.25 Finally, each candidate conceptual instance c forms a cluster of all instances (x, r, y) that have some sense pair s x and s y as hyponyms of c. Note also that candidate conceptual instances may be subsumed by other candidate conceptual instances." ></td>
	<td class="line x" title="83:185	Let G c refer to the set of all candidate conceptual instances subsumed by candidate conceptual instance c. Intuitively, better candidate conceptual instances are those that subsume both many instances and other candidate conceptual instances, but at the same time that have the least distance from subsumed instances." ></td>
	<td class="line x" title="84:185	We capture this intuition with the following score of c: cc c Gg GI G gr cscore c loglog )( )( =   where I c is the set of instances subsumed by c. We experimented with different variations of this score and found that it is important to put more weight on the distance between subsumed conceptual instances than the actual number of subsumed instances." ></td>
	<td class="line x" title="85:185	Without the log terms, the highest scoring conceptual instances are too generic (i.e. , they are too high up in the ontology)." ></td>
	<td class="line x" title="86:185	Phase 2: Attachment Points Selection In this phase, we utilize the conceptual instances of the previous phase to attach each instance (x, r, y) into WordNet." ></td>
	<td class="line x" title="87:185	At the end of Phase 1, an instance can be clustered in different conceptual instances." ></td>
	<td class="line x" title="88:185	In order to select an attachment, the algorithm selects the sense pair of x and y that is subsumed by the highest scoring candidate conceptual instance." ></td>
	<td class="line x" title="89:185	It and all other sense pairs that are subsumed by this conceptual instance are then retained as the final attachment points." ></td>
	<td class="line x" title="90:185	As a side effect, a final set of conceptual instances is obtained by deleting from each candidate those instances that are subsumed by a higher scoring conceptual instance." ></td>
	<td class="line x" title="91:185	Remaining conceptual instances are then re-scored using score(c)." ></td>
	<td class="line x" title="92:185	The final set of conceptual instances thus contains unambiguous sense pairs." ></td>
	<td class="line x" title="93:185	4 Experimental Results In this section we provide an empirical evaluation of our two algorithms." ></td>
	<td class="line x" title="94:185	4.1 Experimental Setup Researchers have developed many algorithms for harvesting semantic relations from corpora and the Web." ></td>
	<td class="line x" title="95:185	For the purposes of this paper, we may choose any one of them and manually validate its mined relations." ></td>
	<td class="line x" title="96:185	We choose Espresso 4, a generalpurpose, broad, and accurate corpus harvesting algorithm requiring minimal supervision." ></td>
	<td class="line x" title="97:185	Adopt4 Reference suppressed  the paper introducing Espresso has also been submitted to COLING/ACL 2006." ></td>
	<td class="line x" title="98:185	796 ing a bootstrapping approach, Espresso takes as input a few seed instances of a particular relation and iteratively learns surface patterns to extract more instances." ></td>
	<td class="line x" title="99:185	Test Sets We experiment with two relations: part-of and causation." ></td>
	<td class="line x" title="100:185	The causation relation occurs when an entity produces an effect or is responsible for events or results, for example (virus, CAUSE, influenza) and (burning fuel, CAUSE, pollution)." ></td>
	<td class="line x" title="101:185	We manually built five seed relation instances for both relations and apply Espresso to a dataset consisting of a sample of articles from the Aquaint (TREC-9) newswire text collection." ></td>
	<td class="line x" title="102:185	The sample consists of 55.7 million words extracted from the Los Angeles Times data files." ></td>
	<td class="line x" title="103:185	Espresso extracted 1,468 part-of instances and 1,129 causation instances." ></td>
	<td class="line x" title="104:185	We manually validated the output and randomly selected 200 correct relation instances of each relation for ontologizing into WordNet 2.0." ></td>
	<td class="line x" title="105:185	Gold Standard We manually built a gold standard of all correct attachments of the test sets in WordNet." ></td>
	<td class="line x" title="106:185	For each relation instance (x, r, y), two human annotators selected from all sense permutations of x and y the correct attachment points in WordNet." ></td>
	<td class="line x" title="107:185	For example, for (synthetic material, PART-OF, filter), the judges selected the following attachment points: (synthetic material#1, PART-OF, filter#1) and (synthetic material#1, PART-OF, filter#2)." ></td>
	<td class="line x" title="108:185	The kappa statistic (Siegel and Castellan Jr. 1988) on the two relations together was  = 0.73." ></td>
	<td class="line x" title="109:185	Systems The following three systems are evaluated:  BL: the baseline system that attaches each relation instance to the first (most common) WordNet sense of both terms;  AN: the anchor approach described in Section 3.1." ></td>
	<td class="line x" title="110:185	 CL: the clustering approach described in Section 3.2." ></td>
	<td class="line x" title="111:185	4.2 Precision, Recall and F-score For both the part-of and causation relations, we apply the three systems described above and compare their attachment performance using precision, recall, and F-score." ></td>
	<td class="line x" title="112:185	Using the manually built gold standard, the precision of a system on a given relation instance is measured as the percentage of correct attachments and recall is measured as the percentage of correct attachments retrieved by the system." ></td>
	<td class="line x" title="113:185	Overall system precision and recall are then computed by averaging the precision and recall of each relation instance." ></td>
	<td class="line x" title="114:185	Table 1 and Table 2 report the results on the part-of and causation relations." ></td>
	<td class="line x" title="115:185	We experimentally set the CL generalization parameter  2 to 5 and the  1 parameter for AN to 0.02." ></td>
	<td class="line x" title="116:185	4.3 Discussion For both relations, CL and AN outperform the baseline in overall F-score." ></td>
	<td class="line x" title="117:185	For part-of, Table 1 shows that CL outperforms BL by 13.6% in Fscore and AN by 9.4%." ></td>
	<td class="line x" title="118:185	For causation, Table 2 shows that AN outperforms BL by 4.4% on Fscore and CL by 0.6%." ></td>
	<td class="line x" title="119:185	The good results of the CL method on the part-of relation suggest that instances of this relation are particularly amenable to be clustered." ></td>
	<td class="line x" title="120:185	The generality of the part-of relation in fact allows the creation of fairly natural clusters, corresponding to different sub-types of part-of, as those proposed in (Winston 1983)." ></td>
	<td class="line x" title="121:185	The causation relation, however, being more difficult to define at a semantic level (Girju 2003), is less easy to cluster and thus to disambiguate." ></td>
	<td class="line x" title="122:185	Both CL and AN have better recall than BL, but precision results vary with CL beating BL only on the part-of relation." ></td>
	<td class="line x" title="123:185	Overall, the system performances suggest that ontologizing semantic relations into WordNet is in general not easy." ></td>
	<td class="line x" title="124:185	The better results of CL and AN with respect to BL suggest that the use of comparative semantic analysis among corpus instances is a good way to carry out disambiguation." ></td>
	<td class="line x" title="125:185	Yet, the BL SYSTEM PRECISION RECALL F-SCORE BL 45.0% 25.0% 32.1% AN 41.7% 32.4% 36.5% CL 40.0% 32.6% 35.9% Table 2." ></td>
	<td class="line x" title="126:185	System precision, recall and F-score on the causation relation." ></td>
	<td class="line x" title="127:185	SYSTEM PRECISION RECALL F-SCORE BL 54.0% 31.3% 39.6% AN 40.7% 47.3% 43.8% CL 57.4% 49.6% 53.2% Table 1." ></td>
	<td class="line x" title="128:185	System precision, recall and F-score on the part-of relation." ></td>
	<td class="line x" title="129:185	797 method shows surprisingly good results." ></td>
	<td class="line x" title="130:185	This indicates that also a simple method based on word sense usage in language can be valuable." ></td>
	<td class="line x" title="131:185	An interesting avenue of future work is to better combine these two different views in a single system." ></td>
	<td class="line x" title="132:185	The low recall results for CL are mostly attributed to the fact that in Phase 2 only the best scoring cluster is retained for each instance." ></td>
	<td class="line x" title="133:185	This means that instances with multiple senses that do not have a common generalization are not captured." ></td>
	<td class="line x" title="134:185	For example the part-of instance (wings, PART-OF, chicken) should cluster both in [body_part#1, PART-OF, animal#1] and [body_part#1, PART-OF, food#2], but only the best scoring one is retained." ></td>
	<td class="line x" title="135:185	5 Conceptual Instances: Other Uses Our clustering approach from Section 3.2 is enabled by learning conceptual instances  relations between mid-level ontological concepts." ></td>
	<td class="line x" title="136:185	Beyond the ontologizing task, conceptual instances may be useful for several other tasks." ></td>
	<td class="line x" title="137:185	In this section, we discuss some of these opportunities and present small qualitative evaluations." ></td>
	<td class="line x" title="138:185	Conceptual instances represent common semantic generalizations of a particular relation." ></td>
	<td class="line x" title="139:185	For example, below are two possible conceptual instances for the part-of relation: [person#1, PART-OF, organization#1] [act#1, PART-OF, plan#1] The first conceptual instance in the example subsumes all the part-of instances in which one or more persons are part of an organization, such as: (president Brown, PART-OF, executive council) (representatives, PART-OF, organization) (students, PART-OF, orchestra) (players, PART-OF, Metro League) Below, we present three possible ways of exploiting these conceptual instances." ></td>
	<td class="line x" title="140:185	Support to Relation Extraction Tools Conceptual instances may be used to support relation extraction algorithms such as Espresso." ></td>
	<td class="line x" title="141:185	Most minimally supervised harvesting algorithm do not exploit generic patterns, i.e. those patterns with high recall but low precision, since they cannot separate correct and incorrect relation instances." ></td>
	<td class="line x" title="142:185	For example, the pattern X of Y extracts many correct relation instances like wheel of the car but also many incorrect ones like house of representatives." ></td>
	<td class="line x" title="143:185	Girju et al.(2003) described a highly supervised algorithm for learning semantic constraints on generic patterns, leading to a very significant increase in system recall without deteriorating precision." ></td>
	<td class="line x" title="145:185	Conceptual instances can be used to automatically learn such semantic constraints by acting as a filter for generic patterns, retaining only those instances that are subsumed by high scoring conceptual instances." ></td>
	<td class="line x" title="146:185	Effectively, conceptual instances are used as selectional restrictions for the relation." ></td>
	<td class="line x" title="147:185	For example, our system discards the following incorrect instances: (week, CAUSE, coalition) (demeanor, CAUSE, vacuum) as they are both part of the very low scoring conceptual instance [abstraction#6, CAUSE, state#1]." ></td>
	<td class="line x" title="148:185	Ontology Learning from Text Each conceptual instance can be viewed as a formal specification of the relation at hand." ></td>
	<td class="line x" title="149:185	For example, Winston (1983) manually identified six sub-types of the part-of relation: membercollection, component-integral object, portionmass, stuff-object, feature-activity and placearea." ></td>
	<td class="line x" title="150:185	Such classifications are useful in applications and tasks where a semantically rich organization of knowledge is required." ></td>
	<td class="line x" title="151:185	Conceptual instances can be viewed as an automatic derivation of such a classification based on corpus usage." ></td>
	<td class="line x" title="152:185	Moreover, conceptual instances can be used to improve the ontology learning process itself." ></td>
	<td class="line x" title="153:185	For example, our clustering approach can be seen as an inductive step producing conceptual instances that are then used in a deductive step to learn new instances." ></td>
	<td class="line x" title="154:185	An algorithm could iterate between the induction/deduction cycle until no new relation instances and conceptual instances can be inferred." ></td>
	<td class="line x" title="155:185	Word Sense Disambiguation Word Sense Disambiguation (WSD) systems can exploit the selectional restrictions identified by conceptual instances to disambiguate ambiguous terms occurring in particular contexts." ></td>
	<td class="line x" title="156:185	For example, given the sentence: the board is composed by members of different countries and a harvesting algorithm that extracts the partof relation (members, PART-OF, board), the system could infer the correct senses for board and members by looking at their closest conceptual instance." ></td>
	<td class="line x" title="157:185	In our system, we would infer the attachment (member#1, PART-OF, board#1) since it is part of the highest scoring conceptual instance [person#1, PART-OF, organization#1]." ></td>
	<td class="line x" title="158:185	798 5.1 Qualitative Evaluation Table 3 and Table 4 list samples of the highest ranking conceptual instances obtained by our system for the part-of and causation relations." ></td>
	<td class="line x" title="159:185	Below we provide a small evaluation to verify:  the correctness of the conceptual instances." ></td>
	<td class="line x" title="160:185	Incorrect conceptual instances such as [attribute#2, CAUSE, state#4], discovered by our system, can impede WSD and extraction tools where precise selectional restrictions are needed; and  the accuracy of the conceptual instances." ></td>
	<td class="line x" title="161:185	Sometimes, an instance is incorrectly attached to a correct conceptual instance." ></td>
	<td class="line x" title="162:185	For example, the instance (air mass, PART-OF, cold front) is incorrectly clustered in [group#1, PART-OF, multitude#3] since mass and front both have a sense that is descendant of group#1 and multitude#3." ></td>
	<td class="line x" title="163:185	However, these are not the correct senses of mass and front for which the part-of relation holds." ></td>
	<td class="line x" title="164:185	For evaluating correctness, we manually verify how many correct conceptual instances are produced by Phase 2 of the clustering approach described in Section 3.2." ></td>
	<td class="line x" title="165:185	The claim is that a correct conceptual instance is one for which the relation holds for all possible subsumed senses." ></td>
	<td class="line x" title="166:185	For example, the conceptual instance [group#1, PART-OF, multitude#3] is correct, as the relation holds for every semantic subsumption of the two senses." ></td>
	<td class="line x" title="167:185	An example of an incorrect conceptual instance is [state#4, CAUSE, abstraction#6] since it subsumes the incorrect instance (audience, CAUSE, new context)." ></td>
	<td class="line x" title="168:185	A manual evaluation of the highest scoring 200 conceptual instances, generated on our test sets described in Section 4.1, showed 82% correctness for the part-of relation and 86% for causation." ></td>
	<td class="line x" title="169:185	For estimating the overall clustering accuracy, we evaluated the number of correctly clustered instances in each conceptual instance." ></td>
	<td class="line x" title="170:185	For example, the instance (business people, PART-OF, committee) is correctly clustered in [multitude#3, PART-OF, group#1] and the instance (law, PARTOF, constitutional pitfalls) is incorrectly clustered in [group#1, PART-OF, artifact#1]." ></td>
	<td class="line x" title="171:185	We estimated the overall accuracy by manually judging the instances attached to 10 randomly sampled conceptual instances." ></td>
	<td class="line x" title="172:185	The accuracy for part-of is 84% and for causation it is 76.6%." ></td>
	<td class="line x" title="173:185	6 Conclusions In this paper, we proposed two algorithms for automatically ontologizing binary semantic relations into WordNet: an anchoring approach and a clustering approach." ></td>
	<td class="line x" title="174:185	Experiments on the partof and causation relations showed promising results." ></td>
	<td class="line x" title="175:185	Both algorithms outperformed the baseline on F-score." ></td>
	<td class="line x" title="176:185	Our best results were on the part-of relation where the clustering approach achieved 13.6% higher F-score than the baseline." ></td>
	<td class="line x" title="177:185	The induction of conceptual instances has opened the way for many avenues of future work." ></td>
	<td class="line x" title="178:185	We intend to pursue the ideas presented in Section 5 for using conceptual instances to: i) support knowledge acquisition tools by learning semantic constraints on extracting patterns; ii) support ontology learning from text; and iii) improve word sense disambiguation through selectional restrictions." ></td>
	<td class="line x" title="179:185	Also, we will try different similarity score functions for both the clustering and the anchor approaches, as those surveyed in Corley and Mihalcea (2005)." ></td>
	<td class="line x" title="180:185	CONCEPTUAL INSTANCE SCORE # INSTANCES INSTANCES [multitude#3, PART-OF, group#1] 2.04 10 (ordinary people, PART-OF, Democratic Revolutionary Party) (unlicensed people, PART-OF, underground economy) (young people, PART-OF, commission) (air mass, PART-OF, cold front) [person#1, PART-OF, organization#1] 1.71 43 (foreign ministers, PART-OF, council) (students, PART-OF, orchestra) (socialists, PART-OF, Iraqi National Joint Action Committee) (players, PART-OF, Metro League) [act#2, PART-OF, plan#1] 1.60 16 (major concessions, PART-OF, new plan) (attacks, PART-OF, coordinated terrorist plan) (visit, PART-OF, exchange program) (survey, PART-OF, project) [communication#2, PART-OF, book#1] 1.14 10 (hints, PART-OF, booklet) (soup recipes, PART-OF, book) (information, PART-OF, instruction manual) (extensive expert analysis, PART-OF, book) [compound#2, PART-OF, waste#1] 0.57 3 (salts, PART-OF, powdery white waste) (lime, PART-OF, powdery white waste) (resin, PART-OF, waste) Table 3." ></td>
	<td class="line x" title="181:185	Sample of the highest scoring conceptual instances learned for the part-of relation." ></td>
	<td class="line x" title="182:185	For each conceptual instance, we report the score(c), the number of instances, and some example instances." ></td>
	<td class="line x" title="183:185	799 The algorithms described in this paper may be applied to ontologize many lexical resources of semantic relations, no matter the harvesting algorithm used to mine them." ></td>
	<td class="line x" title="184:185	In doing so, we have the potential to quickly enrich our ontologies, like WordNet, thus reducing the knowledge acquisition bottleneck." ></td>
	<td class="line x" title="185:185	It is our hope that we will be able to leverage these enriched resources, albeit with some noisy additions, to improve performance on knowledge-rich problems such as question answering and textual entailment." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-1101
Semantic Taxonomy Induction From Heterogenous Evidence
Snow, Rion;Jurafsky, Daniel;Ng, Andrew Y.;"></td>
	<td class="line x" title="1:138	Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 801808, Sydney, July 2006." ></td>
	<td class="line x" title="2:138	c2006 Association for Computational Linguistics Semantic Taxonomy Induction from Heterogenous Evidence Rion Snow Computer Science Department Stanford University Stanford, CA 94305 rion@cs.stanford.edu Daniel Jurafsky Linguistics Department Stanford University Stanford, CA 94305 jurafsky@stanford.edu Andrew Y. Ng Computer Science Department Stanford University Stanford, CA 94305 ang@cs.stanford.edu Abstract We propose a novel algorithm for inducing semantic taxonomies." ></td>
	<td class="line x" title="3:138	Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns." ></td>
	<td class="line x" title="4:138	By contrast, our algorithm flexibly incorporates evidence from multiple classifiers over heterogenous relationships to optimize the entire structure of the taxonomy, using knowledge of a words coordinate terms to help in determining its hypernyms, and vice versa." ></td>
	<td class="line x" title="5:138	We apply our algorithm on the problem of sense-disambiguated noun hyponym acquisition, where we combine the predictions of hypernym and coordinate term classifiers with the knowledge in a preexisting semantic taxonomy (WordNet 2.1)." ></td>
	<td class="line x" title="6:138	We add 10,000 novel synsets to WordNet 2.1 at 84% precision, a relative error reduction of 70% over a non-joint algorithm using the same component classifiers." ></td>
	<td class="line x" title="7:138	Finally, we show that a taxonomy built using our algorithm shows a 23% relative F-score improvement over WordNet 2.1 on an independent testset of hypernym pairs." ></td>
	<td class="line x" title="8:138	1 Introduction The goal of capturing structured relational knowledge about lexical terms has been the motivating force underlying many projects in lexical acquisition, information extraction, and the construction of semantic taxonomies." ></td>
	<td class="line x" title="9:138	Broad-coverage semantic taxonomies such as WordNet (Fellbaum, 1998) and CYC (Lenat, 1995) have been constructed by hand at great cost; while a crucial source of knowledge about the relations between words, these taxonomies still suffer from sparse coverage." ></td>
	<td class="line x" title="10:138	Many algorithms with the potential for automatically extending lexical resources have been proposed, including work in lexical acquisition (Riloff and Shepherd, 1997; Roark and Charniak, 1998) and in discovering instances, named entities, and alternate glosses (Etzioni et al. , 2005; Pasca, 2005)." ></td>
	<td class="line x" title="11:138	Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hyponyms (Hearst, 1992), meronyms (Girju, 2003), synonyms (Lin et al. , 2003), a variety of verb relations (Chklovski and Pantel, 2004), and general purpose analogy relations (Turney et al. , 2003)." ></td>
	<td class="line x" title="12:138	Such classifiers use hand-written or automaticallyinduced patterns like Such NPy as NPx or NPy like NPx to determine, for example that NPy is a hyponym of NPx (i.e. , NPy IS-A NPx)." ></td>
	<td class="line x" title="13:138	While such classifiers have achieved some degree of success, they frequently lack the global knowledge necessary to integrate their predictions into a complex taxonomy with multiple relations." ></td>
	<td class="line x" title="14:138	Past work on semantic taxonomy induction includes the noun hypernym hierarchy created in (Caraballo, 2001), the part-whole taxonomies in (Girju, 2003), and a great deal of recent work described in (Buitelaar et al. , 2005)." ></td>
	<td class="line x" title="15:138	Such work has typically either focused on only inferring small taxonomies over a single relation, or as in (Caraballo, 2001), has used evidence for multiple relations independently from one another, by for example first focusing strictly on inferring clusters of coordinate terms, and then by inferring hypernyms over those clusters." ></td>
	<td class="line x" title="16:138	Another major shortfall in previous techniques for taxonomy induction has been the inability to handle lexical ambiguity." ></td>
	<td class="line x" title="17:138	Previous approaches have typically sidestepped the issue of polysemy altogether by making the assumption of only a single sense per word, and inferring taxonomies explicitly over words and not senses." ></td>
	<td class="line x" title="18:138	Enforcing a false monosemy has the downside of making potentially erroneous inferences; for example, collapsing the polysemous term Bush into a single sense might lead one to infer by transitivity that a rose bush is a kind of U.S. president." ></td>
	<td class="line x" title="19:138	Our approach simultaneously provides a solution to the problems of jointly considering evidence about multiple relationships as well as lexical ambiguity within a single probabilistic framework." ></td>
	<td class="line x" title="20:138	The key contribution of this work is to offer a solution to two crucial problems in taxonomy in801 duction and hyponym acquisition: the problem of combining heterogenous sources of evidence in a flexible way, and the problem of correctly identifying the appropriate word sense of each new word added to the taxonomy.1 2 A Probabilistic Framework for Taxonomy Induction In section 2.1 we introduce our definitions for taxonomies, relations, and the taxonomic constraints that enforce dependencies between relations; in section 2.2 we give a probabilistic model for defining the conditional probability of a set of relational evidence given a taxonomy; in section 2.3 we formulate a local search algorithm to find the taxonomy maximizing this conditional probability; and in section 2.4 we extend our framework to deal with lexical ambiguity." ></td>
	<td class="line x" title="21:138	2.1 Taxonomies, Relations, and Taxonomic Constraints We define a taxonomy T as a set of pairwise relations R over some domain of objects DT." ></td>
	<td class="line x" title="22:138	For example, the relations in WordNet include hypernymy, holonymy, verb entailment, and many others; the objects of WordNet between which these relations hold are its word senses or synsets." ></td>
	<td class="line x" title="23:138	We define that each relation R  R is a set of ordered or unordered pairs of objects (i,j)  DT; we define Rij  T if relationship R holds over objects (i,j) in T. Relations for Hyponym Acquisition For the case of hyponym acquisition, the objects in our taxonomy are WordNet synsets." ></td>
	<td class="line x" title="24:138	In this paper we focus on two of the many possible relationships between senses: the hypernym relation and the coordinate term relation." ></td>
	<td class="line x" title="25:138	We treat the hypernym or ISA relation as atomic; we use the notation Hnij if a sense j is the n-th ancestor of a sense i in the hypernym hierarchy." ></td>
	<td class="line x" title="26:138	We will simply use Hij to indicate that j is an ancestor of i at some unspecified level." ></td>
	<td class="line x" title="27:138	Two senses are typically considered to be coordinate terms or taxonomic sisters if they share an immediate parent in the hypernym hierarchy." ></td>
	<td class="line x" title="28:138	We generalize this notion of siblinghood to state that two senses i and j are (m,n)-cousins if their closest least common 1The taxonomies discussed in this paper are available for download at http://ai.stanford.edu/rion/swn." ></td>
	<td class="line x" title="29:138	subsumer (LCS)2 is within exactly m and n links, respectively.3 We use the notation Cmnij to denote that i and j are (m,n)-cousins." ></td>
	<td class="line x" title="30:138	Thus coordinate terms are (1,1)-cousins; technically the hypernym relation may also be seen as a specific case of this representation; an immediate parent in the hypernym hierarchy is a (1,0)-cousin, and the k-th ancestor is a (k,0)-cousin." ></td>
	<td class="line x" title="31:138	Taxonomic Constraints A semantic taxonomy such as WordNet enforces certain taxonomic constraints which disallow particular taxonomies T. For example, the ISA transitivity constraint in WordNet requires that each synset inherits the hypernyms of its hypernym, and the part-inheritance constraint requires that each synset inherits the meronyms of its hypernyms." ></td>
	<td class="line x" title="32:138	For the case of hyponym acquisition we enforce the following two taxonomic constraints on the hypernym and (m,n)-cousin relations: 1." ></td>
	<td class="line x" title="33:138	ISA Transitivity: Hmij Hnjk  Hm+nik." ></td>
	<td class="line x" title="34:138	2." ></td>
	<td class="line x" title="35:138	Definition of (m,n)-cousinhood: Cmnij k.k = LCS(i,j)Hmik Hnjk." ></td>
	<td class="line x" title="36:138	Constraint (1) requires that the each synset inherits the hypernyms of its direct hypernym; constraint (2) simply defines the (m,n)-cousin relation in terms of the atomic hypernym relation." ></td>
	<td class="line x" title="37:138	The addition of any new hypernym relation to a preexisting taxonomy will usually necessitate the addition of a set of other novel relations as implied by the taxonomic constraints." ></td>
	<td class="line x" title="38:138	We refer to the full set of novel relations implied by a new link Rij as I(Rij); we discuss the efficient computation of the set of implied links for the purpose of hyponym acquisition in Section 3.4." ></td>
	<td class="line x" title="39:138	2.2 A Probabilistic Formulation We propose that the event Rij  T has some prior probability P(Rij  T), and P(Rij  2A least common subsumer LCS(i,j) is defined as a synset that is an ancestor in the hypernym hierarchy of both i and j which has no child that is also an ancestor of both i and j. When there is more than one LCS (due to multiple inheritance), we refer to the closest LCS, i.e.,the LCS that minimizes the maximum distance to i and j. 3An (m,n)-cousin for m  2 corresponds to the English kinship relation (m1)-th cousin |mn|-times removed. 802 T)+P(Rij negationslash T) = 1." ></td>
	<td class="line x" title="40:138	We define the probability of the taxonomy as a whole as the joint probability of its component relations; given a partition of all possible relations R = {A,B} where A  T and B negationslash T, we define: P(T) = P(A  T,B negationslash T)." ></td>
	<td class="line x" title="41:138	We assume that we have some set of observed evidence E consisting of observed features over pairs of objects in some domain DE; well begin with the assumption that our features are over pairs of words, and that the objects in the taxonomy also correspond directly to words.4 Given a set of features ERij  E, we assume we have some model for inferring P(Rij  T|ERij), i.e., the posterior probability of the event Rij  T given the corresponding evidence ERij for that relation." ></td>
	<td class="line x" title="42:138	For example, evidence for the hypernym relation EHij might be the set of all observed lexico-syntactic patterns containing i and j in all sentences in some corpus." ></td>
	<td class="line x" title="43:138	For simplicity we make the following independence assumptions: first, we assume that each item of observed evidence ERij is independent of all other observed evidence given the taxonomyT, i.e., P(E|T) = producttextER ijE P(ERij|T)." ></td>
	<td class="line x" title="44:138	Further, we assume that each item of observed evidence ERij depends on the taxonomy T only by way of the corresponding relation Rij, i.e., P(ERij|T) = braceleftbigg P(ER ij|Rij  T) if Rij  T P(ERij|Rij negationslash T) if Rij negationslash T For example, if our evidence EHij is a set of observed lexico-syntactic patterns indicative of hypernymy between two words i and j, we assume that whatever dependence the relations in T have on our observations may be explained entirely by dependence on the existence or non-existence of the single hypernym relation H(i,j)." ></td>
	<td class="line x" title="45:138	Applying these two independence assumptions we may express the conditional probability of our evidence given the taxonomy: P(E|T) = productdisplay RijT P(ERij|Rij  T)  productdisplay RijnegationslashT P(ERij|Rij negationslash T)." ></td>
	<td class="line x" title="46:138	Rewriting the conditional probability in terms of our estimates of the posterior probabilities 4In section 2.4 we drop this assumption, extending our model to manage lexical ambiguity." ></td>
	<td class="line x" title="47:138	P(Rij|ERij) using Bayes Rule, we obtain: P(E|T) = productdisplay RijT P(Rij  T|ERij)P(ERij) P(Rij  T)  productdisplay RijnegationslashT P(Rij negationslash T|ERij)P(ERij) P(Rij negationslash T) . Within our model we define the goal of taxonomy induction to be to find the taxonomy T that maximizes the conditional probability of our observations E given the relationships of T, i.e., to find T = argmax T P(E|T)." ></td>
	<td class="line x" title="48:138	2.3 Local Search Over Taxonomies We propose a search algorithm for finding T for the case of hyponym acquisition." ></td>
	<td class="line x" title="49:138	We assume we begin with some initial (possibly empty) taxonomy T. We restrict our consideration of possible new taxonomies to those created by the single operation ADD-RELATION(Rij,T), which adds the single relation Rij to T. We define the multiplicative change T(Rij) to the conditional probability P(E|T) given the addition of a single relation Rij: T(Rij) = P(E|Tprime)/P(E|T) = P(Rij  T|E Rij)P(ERij) P(Rij negationslash T|ERij)P(ERij)  P(Rij negationslash T) P(Rij  T) = k   P parenleftBig Rij  T|ERij parenrightBig 1P parenleftBig Rij  T|ERij parenrightBig  ." ></td>
	<td class="line x" title="50:138	Here k is the inverse odds of the prior on the event Rij  T; we consider this to be a constant independent of i,j, and the taxonomy T. To enforce the taxonomic constraints in T, for each application of the ADD-RELATION operator we must add all new relations in the implied set I(Rij) not already in T.5 Thus we define the multiplicative change of the full set of implied relations as the product over all new relations: T(I(Rij)) = productdisplay RI(Rij) T(R)." ></td>
	<td class="line x" title="51:138	5For example, in order to add the new synset microsoft under the noun synset company#n#1 in WordNet 2.1, we must necessarily add the new relations H2(microsoft,institution#n#1) C11(microsoft,dotcom#n#1), and so on." ></td>
	<td class="line x" title="52:138	803 This definition leads to the following best-first search algorithm for hyponym acquisition, which at each iteration defines the new taxonomy as the union of the previous taxonomy T and the set of novel relations implied by the relation Rij that maximizes T(I(Rij)) and thus maximizes the conditional probability of the evidence over all possible single relations: WHILE max RijnegationslashT T(I(Rij)) > 1 T  TI(arg max RijnegationslashT T(I(Rij)))." ></td>
	<td class="line x" title="53:138	2.4 Extending the Model to Manage Lexical Ambiguity Since word senses are not directly observable, if the objects in the taxonomy are word senses (as in WordNet), we must extend our model to allow for a many-to-many mapping (e.g. , a word-to-sense mapping) between DE and DT." ></td>
	<td class="line x" title="54:138	For this setting we assume we know the function senses(i), mapping from the word i to all of iprimes possible corresponding senses." ></td>
	<td class="line x" title="55:138	We assume that each set of word-pair evidence ERij we possess is in fact sense-pair evidence ERkl for a specific pair of senses k0  senses(i),l0  senses(j)." ></td>
	<td class="line x" title="56:138	Further, we assume that a new relation between two words is probable only between the correct sense pair, i.e.: P(Rkl|ERij) = 1k = k0,l = l0}P(Rij|ERij)." ></td>
	<td class="line x" title="57:138	When computing the conditional probability of a specific new relation Rkl  I(Rab), we assume that the relevant sense pair k0,l0 is the one which maximizes the probability of the new relation, i.e. for k  senses(i),l  senses(j), (k0,l0) = argmax k,l P(Rkl  T|ERij)." ></td>
	<td class="line x" title="58:138	Our independence assumptions for this extension need only to be changed slightly; we now assume that the evidence ERij depends on the taxonomy T via only a single relation between sensepairs Rkl." ></td>
	<td class="line x" title="59:138	Using this revised independence assumption the derivation for best-first search over taxonomies for hyponym acquisition remains unchanged." ></td>
	<td class="line x" title="60:138	One side effect of this revised independence assumption is that the addition of the single sense-collapsed relation Rkl in the taxonomy T will explain the evidence ERij for the relation over words i and j now that such evidence has been revealed to concern only the specific senses k and l. 3 Extending WordNet We demonstrate the ability of our model to use evidence from multiple relations to extend WordNet with novel noun hyponyms." ></td>
	<td class="line x" title="61:138	While in principle we could use any number of relations, for simplicity we consider two primary sources of evidence: the probability of two words in WordNet being in a hypernym relation, and the probability of two words in WordNet being in a coordinate relation." ></td>
	<td class="line x" title="62:138	In sections 3.1 and 3.2 we describe the construction of our hypernym and coordinate classifiers, respectively; in section 3.3 we outline the efficient algorithm we use to perform local search over hyponym-extended WordNets; and in section 3.4 we give an example of the implicit structure-based word sense disambiguation performed within our framework." ></td>
	<td class="line x" title="63:138	3.1 Hyponym Classification Our classifier for the hypernym relation is derived from the hypernym-only classifier described in (Snow et al. , 2005)." ></td>
	<td class="line x" title="64:138	The features used for predicting the hypernym relationship are obtained by parsing a large corpus of newswire and encyclopedia text with MINIPAR (Lin, 1998)." ></td>
	<td class="line x" title="65:138	From the resulting dependency trees the evidence EHij for each word pair (i,j) is constructed; the evidence takes the form of a vector of counts of occurrences that each labeled syntactic dependency path was found as the shortest path connecting i and j in some dependency tree." ></td>
	<td class="line x" title="66:138	The labeled training set is constructed by labeling the collected feature vectors as positive known hypernym or negative known non-hypernym examples using WordNet 2.0; 49,922 feature vectors were labeled as positive training examples, and 800,828 noun pairs were labeled as negative training examples." ></td>
	<td class="line x" title="67:138	The model for predicting P(Hij|EHij ) is then trained using logistic regression, predicting the noun-pair hypernymy label from WordNet from the feature vector of lexico-syntactic patterns." ></td>
	<td class="line x" title="68:138	The hypernym classifier described above predicts the probability of the generalized hypernymancestor relation over words P(Hij|EHij )." ></td>
	<td class="line x" title="69:138	For the purposes of taxonomy induction, we would prefer an ancestor-distance specific set of classifiers over senses, i.e., for k  senses(i),l  senses(j), the set of classifiers estimating {P(H1kl|EHij ),P(H2kl|EHij ),}." ></td>
	<td class="line x" title="70:138	804 One problem that arises from directly assigning the probability P(Hnij|EHij )  P(Hij|EHij ) for all n is the possibility of adding a novel hyponym to an overly-specific hypernym, which might still satisfy P(Hnij|EHij ) for a very large n. In order to discourage unnecessary overspecification, we penalize each probability P(Hkij|EHij ) by a factor k1 for some  < 1, and renormalize: P(Hkij|EHij )  k1P(Hij|EHij )." ></td>
	<td class="line x" title="71:138	In our experiments we set  = 0.95." ></td>
	<td class="line oc" title="72:138	3.2 (m,n)-cousin Classification The classifier for learning coordinate terms relies on the notion of distributional similarity, i.e., the idea that two words with similar meanings will be used in similar contexts (Hindle, 1990)." ></td>
	<td class="line o" title="73:138	We extend this notion to suggest that words with similar meanings should be near each other in a semantic taxonomy, and in particular will likely share a hypernym as a near parent." ></td>
	<td class="line x" title="74:138	Our classifier for (m,n)-cousins is derived from the algorithm and corpus given in (Ravichandran et al. , 2005)." ></td>
	<td class="line x" title="75:138	In that work an efficient randomized algorithm is derived for computing clusters of similar nouns." ></td>
	<td class="line x" title="76:138	We use a set of more than 1000 distinct clusters of English nouns collected by their algorithm over 70 million webpages6, with each noun i having a score representing its cosine similarity to the centroid c of the cluster to which it belongs, cos((i,c))." ></td>
	<td class="line x" title="77:138	We use the cluster scores of noun pairs as input to our own algorithm for predicting the (m,n)cousin relationship between the senses of two words i and j. If two words i and j appear in a cluster together, with cluster centroid c, we set our single coordinate input feature to be the minimum cluster score min(cos((i,c)),cos((j,c))), and zero otherwise." ></td>
	<td class="line x" title="78:138	For each such noun pair feature, we construct a labeled training set of (m,n)cousin relation labels from WordNet 2.1." ></td>
	<td class="line x" title="79:138	We define a noun pair (i,j) to be a known (m,n)cousin if for some senses k  senses(i),l  senses(j), Cmnij  WordNet; if more than one such relation exists, we assume the relation with smallest sum m + n, breaking ties by smallest absolute difference |m  n|." ></td>
	<td class="line x" title="80:138	We consider all such labeled relationships from WordNet with 0  m,n  7; pairs of words that have no corresponding pair of synsets connected in the hypernym hi6As a preprocessing step we hand-edit the clusters to remove those containing non-English words, terms related to adult content, and other webpage-specific clusters." ></td>
	<td class="line x" title="81:138	erarchy, or with min(m,n) > 7, are assigned to a single class C." ></td>
	<td class="line x" title="82:138	Further, due to the symmetry of the similarity score, we merge each class Cmn = Cmn Cnm; this implies that the resulting classifier will predict, as expected given a symmetric input, P(Cmnkl |ECij) = P(Cnmkl |ECij)." ></td>
	<td class="line x" title="83:138	We find 333,473 noun synset pairs in our training set with similarity score greater than 0.15." ></td>
	<td class="line x" title="84:138	We next apply softmax regression to learn a classifier that predicts P(Cmnij |ECij), predicting the WordNet class labels from the single similarity score derived from the noun pairs cluster similarity." ></td>
	<td class="line x" title="85:138	3.3 Details of our Implementation Hyponym acquisition is among the simplest and most straightforward of the possible applications of our model; here we show how we efficiently implement our algorithm for this problem." ></td>
	<td class="line x" title="86:138	First, we identify the set of all the word pairs (i,j) over which we have hypernym and/or coordinate evidence, and which might represent additions of a novel hyponym to the WordNet 2.1 taxonomy (i.e. , that has a known noun hypernym and an unknown hyponym, or has a known noun coordinate term and an unknown coordinate term)." ></td>
	<td class="line x" title="87:138	This yields a list of 95,000 single links over threshold P(Rij) > 0.12." ></td>
	<td class="line x" title="88:138	For each unknown hyponym i we may have several pieces of evidence; for example, for the unknown term continental we have 21 relevant pieces of hypernym evidence, with links to possible hypernyms {carrier, airline, unit, . . .}; and we have 5 pieces of coordinate evidence, with links to possible coordinate terms {airline, american eagle, airbus, . . .}." ></td>
	<td class="line x" title="89:138	For each proposed hypernym or coordinate link involved with the novel hyponym i, we compute the set of candidate hypernyms for i; in practice we consider all senses of the immediate hypernym j for each potential novel hypernym, and all senses of the coordinate term k and its first two hypernym ancestors for each potential coordinate." ></td>
	<td class="line x" title="90:138	In the continental example, from the 26 individual pieces of evidence over words we construct the set of 99 unique synsets that we will consider as possible hypernyms; these include the two senses of the word airline, the ten senses of the word carrier, and so forth." ></td>
	<td class="line x" title="91:138	Next, we iterate through each of the possible hypernym synsets l under which we might add the new word i; for each synset l we com805 pute the change in taxonomy score resulting from adding the implied relations I(H1il) required by the taxonomic constraints of T. Since typically our set of all evidence involving i will be much smaller than the set of possible relations in I(H1il), we may efficiently check whether, for each sense s  senses(w), for all words where we have some evidence ERiw, whether s participates in some relation with i in the set of implied relations I(H1il).7 If there is more than one sense s  senses(w), we add to I(H1il) the single relationship Ris that maximizes the taxonomy likelihood, i.e. argmaxssenses(w) T(Ris)." ></td>
	<td class="line x" title="92:138	3.4 Hypernym Sense Disambiguation A major strength of our model is its ability to correctly choose the sense of a hypernym to which to add a novel hyponym, despite collecting evidence over untagged word pairs." ></td>
	<td class="line x" title="93:138	In our algorithm word sense disambiguation is an implicit side-effect of our algorithm; since our algorithm chooses to add the single link which, with its implied links, yields the most likely taxonomy, and since each distinct synset in WordNet has a different immediate neighborhood of relations, our algorithm simply disambiguates each node based on its surrounding structural information." ></td>
	<td class="line x" title="94:138	As an example of sense disambiguation in practice, consider our example of continental." ></td>
	<td class="line x" title="95:138	Suppose we are iterating through each of the 99 possible synsets under which we might add continental as a hyponym, and we come to the synset airline#n#2 in WordNet 2.1, i.e. a commercial organization serving as a common carrier. In this case we will iterate through each piece of hypernym and coordinate evidence; we find that the relation H(continental, carrier) is satisfied with high probability for the specific synset carrier#n#5, the grandparent of airline#n#2; thus the factor T(H3(continental, carrier#n#5)) is included in the factor of the set of implied relations TparenleftbigI(H1(continental, airline#n#2))parenrightbig." ></td>
	<td class="line x" title="96:138	Suppose we instead evaluate the first synset of airline, i.e., airline#n#1, with the gloss a hose that carries air under pressure. For this synset none of the other 20 relationships directly implied by hypernym evidence or the 5 relationships implied by the coordinate ev7Checking whether or not Ris  I(H1 il) may be effi-ciently computed by checking whether s is in the hypernym ancestors of l or if it shares a least common subsumer with l within 7 steps." ></td>
	<td class="line x" title="97:138	idence are implied by adding the single link H1(continental,airline#n#1); thus the resulting change in the set of implied links given by the correct carrier sense of airline is much higher than that of the hose sense." ></td>
	<td class="line x" title="98:138	In fact it is the largest of all the 99 considered hypernym links for continental; H1(continental, airline#n#2) is link #18,736 added to the taxonomy by our algorithm." ></td>
	<td class="line x" title="99:138	4 Evaluation In order to evaluate our framework for taxonomy induction, we have applied hyponym acquisition to construct several distinct taxonomies, starting with the base of WordNet 2.1 and only adding novel noun hyponyms." ></td>
	<td class="line x" title="100:138	Further, we have constructed taxonomies using a baseline algorithm, which uses the identical hypernym and coordinate classifiers used in our joint algorithm, but which does not combine the evidence of the classifiers." ></td>
	<td class="line x" title="101:138	In section 4.1 we describe our evaluation methodology; in sections 4.2 and 4.3 we analyze the fine-grained precision and disambiguation precision of our algorithm compared to the baseline; in section 4.4 we compare the coarse-grained precision of our links (motivated by categories defined by the WordNet supersenses) against the baseline algorithm and against an oracle for named entity recognition." ></td>
	<td class="line x" title="102:138	Finally, in section 4.5 we evaluate the taxonomies inferred by our algorithm directly against the WordNet 2.1 taxonomy; we perform this evaluation by testing each taxonomy on a set of human judgments of hypernym and non-hypernym noun pairs sampled from newswire text." ></td>
	<td class="line x" title="103:138	4.1 Methodology We evaluate the quality of our acquired hyponyms by direct judgment." ></td>
	<td class="line x" title="104:138	In four separate annotation sessions, two judges labeled {50,100,100,100} samples uniformly generated from the first {100,1000,10000,20000} single links added by our algorithm." ></td>
	<td class="line x" title="105:138	For the direct measure of fine-grained precision, we simply ask for each link H(X,Y) added by the system, is X a Y ? In addition to the fine-grained precision, we give a coarse-grained evaluation, inspired by the idea of supersense-tagging in (Ciaramita and Johnson, 2003)." ></td>
	<td class="line x" title="106:138	The 26 supersenses used in WordNet 2.1 are listed in Table 1; we label a hyponym link as correct in the coarse-grained evaluation if the novel hyponym is placed under the appropriate supersense." ></td>
	<td class="line x" title="107:138	This evaluation task 806 1 Tops 8 communication 15 object 22 relation 2 act 9 event 16 person 23 shape 3 animal 10 feeling 17 phenomenon 24 state 4 artifact 11 food 18 plant 25 substance 5 attribute 12 group 19 possession 26 time 6 body 13 location 20 process 7 cognition 14 motive 21 quantity Table 1: The 26 WordNet supersenses is similar to a fine-grained Named Entity Recognition (Fleischman and Hovy, 2002) task with 26 categories; for example, if our algorithm mistakenly inserts a novel non-capital city under the hyponym state capital, it will inherit the correct supersense location." ></td>
	<td class="line x" title="108:138	Finally, we evaluate the ability of our algorithm to correctly choose the appropriate sense of the hypernym under which a novel hyponym is being added." ></td>
	<td class="line x" title="109:138	Our labelers categorize each candidate sense-disambiguated hypernym synset suggested by our algorithm into the following categories: c1: Correct sense-disambiguated hypernym." ></td>
	<td class="line x" title="110:138	c2: Correct hypernym word, but incorrect sense of that word." ></td>
	<td class="line x" title="111:138	c3: Incorrect hypernym, but correct supersense." ></td>
	<td class="line x" title="112:138	c4: Any other relation is considered incorrect." ></td>
	<td class="line x" title="113:138	A single hyponym/hypernym pair is allowed to be simultaneously labeled 2 and 3." ></td>
	<td class="line x" title="114:138	4.2 Fine-grained evaluation Table 2 displays the results of our evaluation of fine-grained precision for the baseline non-joint algorithm (Base) and our joint algorithm (Joint), as well as the relative error reduction (ER) of our algorithm over the baseline." ></td>
	<td class="line x" title="115:138	We use the minimum of the two judges scores." ></td>
	<td class="line x" title="116:138	Here we define fine-grained precision as c1/total." ></td>
	<td class="line x" title="117:138	We see that our joint algorithm strongly outperforms the baseline, and has high precision for predicting novel hyponyms up to 10,000 links." ></td>
	<td class="line x" title="118:138	4.3 Hypernym sense disambiguation Also in Table 2 we compare the sense disambiguation precision of our algorithm and the baseline." ></td>
	<td class="line x" title="119:138	Here we measure the precision of sense-disambiguation among all examples where each algorithm found a correct hyponym word; our calculation for disambiguation precision is c1/(c1 +c2)." ></td>
	<td class="line x" title="120:138	Again our joint algorithm outperforms the baseline algorithm at all levels of recall." ></td>
	<td class="line x" title="121:138	Interestingly the baseline disambiguation precision improves with higher recall; this may Fine-grained Pre." ></td>
	<td class="line x" title="122:138	Disambiguation Pre." ></td>
	<td class="line x" title="123:138	#Links Base Joint ER Base Joint ER 100 0.60 1.00 100% 0.86 1.00 100% 1000 0.52 0.93 85% 0.84 1.00 100% 10000 0.46 0.84 70% 0.90 1.00 100% 20000 0.46 0.68 41% 0.94 0.98 68% Table 2: Fine-grained and disambiguation precision and error reduction for hyponym acquisition # Links NER Base Joint ER vs. ER vs. Oracle NER Base 100 1.00 0.72 1.00 0% 100% 1000 0.69 0.68 0.99 97% 85% 10000 0.45 0.69 0.96 93% 70% 20000 0.54 0.69 0.92 83% 41% Table 3: Coarse-grained precision and error reduction vs. Non-joint baseline and NER Oracle be attributed to the observation that the highestconfidence hypernyms predicted by individual classifiers are likely to be polysemous, whereas hypernyms of lower confidence are more frequently monosemous (and thus trivially easy to disambiguate)." ></td>
	<td class="line x" title="124:138	4.4 Coarse-grained evaluation We compute coarse-grained precision as (c1 + c3)/total." ></td>
	<td class="line x" title="125:138	Inferring the correct coarse-grained supersense of a novel hyponym can be viewed as a fine-grained (26-category) Named Entity Recognition task; our algorithm for taxonomy induction can thus be viewed as performing high-accuracy fine-grained NER." ></td>
	<td class="line x" title="126:138	Here we compare against both the baseline non-joint algorithm as well as an oracle algorithm for Named Entity Recognition, which perfectly classifies the supersense of all nouns that fall under the four supersenses {person,group,location,quantity}, but works only for those supersenses." ></td>
	<td class="line x" title="127:138	Table 3 shows the results of this coarse-grained evaluation." ></td>
	<td class="line x" title="128:138	We see that the baseline non-joint algorithm has higher precision than the NER oracle as 10,000 and 20,000 links; however, both are significantly outperformed by our joint algorithm, which maintains high coarse-grained precision (92%) even at 20,000 links." ></td>
	<td class="line x" title="129:138	4.5 Comparison of inferred taxonomies and WordNet For our final evaluation we compare our learned taxonomies directly against the currently existing hypernym links in WordNet 2.1." ></td>
	<td class="line x" title="130:138	In order to compare taxonomies we use a hand-labeled test 807 WN +10K +20K +30K +40K PRE 0.524 0.524 0.574 0.583 0.571 REC 0.165 0.165 0.203 0.211 0.211 F 0.251 0.251 0.300 0.309 0.307 Table 4: Taxonomy hypernym classification vs. WordNet 2.1 on hand-labeled testset set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al. , 2005))." ></td>
	<td class="line x" title="131:138	We measured the performance of both our inferred taxonomies and WordNet against this test set.8 The performance and comparison of the best WordNet classifier vs. our taxonomies is given in Table 4." ></td>
	<td class="line x" title="132:138	Our best-performing inferred taxonomy on this test set is achieved after adding 30,000 novel hyponyms, achieving an 23% relative improvement in F-score over the WN2.1 classifier." ></td>
	<td class="line x" title="133:138	5 Conclusions We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy." ></td>
	<td class="line x" title="134:138	Our probabilistic architecture also includes a new model for learning coordinate terms based on (m,n)-cousin classification." ></td>
	<td class="line x" title="135:138	The models ability to integrate heterogeneous evidence from different classifiers offers a solution to the key problem of choosing the correct word sense to which to attach a new hypernym." ></td>
	<td class="line x" title="136:138	Acknowledgements Thanks to Christiane Fellbaum, Rajat Raina, Bill MacCartney, and Allison Buckley for useful discussions and assistance annotating data." ></td>
	<td class="line x" title="137:138	Rion Snow is supported by an NDSEG Fellowship sponsored by the DOD and AFOSR." ></td>
	<td class="line x" title="138:138	This work was supported in part by the Disruptive Technology Office (DTO)s Advanced Question Answering for Intelligence (AQUAINT) Program." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-1102
Names And Similarities On The Web: Fact Extraction In The Fast Lane
Paca, Marius;Lin, Dekang;Bigham, Jeffrey;Lifchits, Andrei;Jain, Alpa;"></td>
	<td class="line x" title="1:168	Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 809816, Sydney, July 2006." ></td>
	<td class="line x" title="2:168	c2006 Association for Computational Linguistics Names and Similarities on the Web: Fact Extraction in the Fast Lane Marius Pasca Google Inc. Mountain View, CA 94043 mars@google.com Dekang Lin Google Inc. Mountain View, CA 94043 lindek@google.com Jeffrey Bigham University of Washington Seattle, WA 98195 jbigham@cs.washington.edu Andrei Lifchits University of British Columbia Vancouver, BC V6T 1Z4 alifchit@cs.ubc.ca Alpa Jain Columbia University New York, NY 10027 alpa@cs.columbia.edu Abstract In a new approach to large-scale extraction of facts from unstructured text, distributional similarities become an integral part of both the iterative acquisition of high-coverage contextual extraction patterns, and the validation and ranking of candidate facts." ></td>
	<td class="line x" title="3:168	The evaluation measures the quality and coverage of facts extracted from one hundred million Web documents, starting from ten seed facts and using no additional knowledge, lexicons or complex tools." ></td>
	<td class="line x" title="4:168	1 Introduction 1.1 Background The potential impact of structured fact repositories containing billions of relations among named entities on Web search is enormous." ></td>
	<td class="line x" title="5:168	They enable the pursuit of new search paradigms, the processing of database-like queries, and alternative methods of presenting search results." ></td>
	<td class="line x" title="6:168	The preparation of exhaustive lists of hand-written extraction rules is impractical given the need for domainindependent extraction of many types of facts from unstructured text." ></td>
	<td class="line x" title="7:168	In contrast, the idea of bootstrapping for relation and information extraction was first proposed in (Riloff and Jones, 1999), and successfully applied to the construction of semantic lexicons (Thelen and Riloff, 2002), named entity recognition (Collins and Singer, 1999), extraction of binary relations (Agichtein and Gravano, 2000), and acquisition of structured data for tasks such as Question Answering (Lita and Carbonell, 2004; Fleischman et al. , 2003)." ></td>
	<td class="line x" title="8:168	In the context of fact extraction, the resulting iterative acquisition Work done during internships at Google Inc. framework starts from a small set of seed facts, finds contextual patterns that extract the seed facts from the underlying text collection, identifies a larger set of candidate facts that are extracted by the patterns, and adds the best candidate facts to the previous seed set." ></td>
	<td class="line x" title="9:168	1.2 Contributions Figure 1 describes an architecture geared towards large-scale fact extraction." ></td>
	<td class="line x" title="10:168	The architecture is similar to other instances of bootstrapping for information extraction." ></td>
	<td class="line x" title="11:168	The main processing stages are the acquisition of contextual extraction patterns given the seed facts, acquisition of candidate facts given the extraction patterns, scoring and ranking of the patterns, and scoring and ranking of the candidate facts, a subset of which is added to the seed set of the next round." ></td>
	<td class="line x" title="12:168	Within the existing iterative acquisition framework, our first contribution is a method for automatically generating generalized contextual extraction patterns, based on dynamically-computed classes of similar words." ></td>
	<td class="line x" title="13:168	Traditionally, the acquisition of contextual extraction patterns requires hundreds or thousands of consecutive iterations over the entire text collection (Lita and Carbonell, 2004), often using relatively expensive or restrictive tools such as shallow syntactic parsers (Riloff and Jones, 1999; Thelen and Riloff, 2002) or named entity recognizers (Agichtein and Gravano, 2000)." ></td>
	<td class="line x" title="14:168	Comparatively, generalized extraction patterns achieve exponentially higher coverage in early iterations." ></td>
	<td class="line x" title="15:168	The extraction of large sets of candidate facts opens the possibility of fast-growth iterative extraction, as opposed to the de-facto strategy of conservatively growing the seed set by as few as five items (Thelen and Riloff, 2002) after each iteration." ></td>
	<td class="line x" title="16:168	809 Acquisition of contextual extraction patterns Distributional similaritiesText collection Candidate facts Acquisition of candidate facts Occurrences of extraction patterns Validation of candidate facts Scored extraction patternsScored candidate facts Scoring and ranking Validated candidate facts Seed facts Occurrences of seed facts Extraction patterns Validated extraction patterns Validation of patterns Generalized extraction patterns Figure 1: Large-scale fact extraction architecture The second contribution of the paper is a method for domain-independent validation and ranking of candidate facts, based on a similarity measure of each candidate fact relative to the set of seed facts." ></td>
	<td class="line x" title="17:168	Whereas previous studies assume clean text collections such as news corpora (Thelen and Riloff, 2002; Agichtein and Gravano, 2000; Hasegawa et al. , 2004), the validation is essential for low-quality sets of candidate facts collected from noisy Web documents." ></td>
	<td class="line x" title="18:168	Without it, the addition of spurious candidate facts to the seed set would result in a quick divergence of the iterative acquisition towards irrelevant information (Agichtein and Gravano, 2000)." ></td>
	<td class="line x" title="19:168	Furthermore, the finer-grained ranking induced by similarities is necessary in fast-growth iterative acquisition, whereas previously proposed ranking criteria (Thelen and Riloff, 2002; Lita and Carbonell, 2004) are implicitly designed for slow growth of the seed set." ></td>
	<td class="line x" title="20:168	2 Similarities for Pattern Acquisition 2.1 Generalization via Word Similarities The extraction patterns are acquired by matching the pairs of phrases from the seed set into document sentences." ></td>
	<td class="line x" title="21:168	The patterns consist of contiguous sequences of sentence terms, but otherwise differ from the types of patterns proposed in earlier work in two respects." ></td>
	<td class="line x" title="22:168	First, the terms of a pattern are either regular words or, for higher generality, any word from a class of similar words." ></td>
	<td class="line x" title="23:168	Second, the amount of textual context encoded in a pattern is limited to the sequence of terms between (i.e. , infix) the pair of phrases from a seed fact that could be matched in a document sentence, thus excluding any context to the left (i.e. , prefix) and to the right (i.e. , postfix) of the seed." ></td>
	<td class="line x" title="24:168	The pattern shown at the top of Figure 2, which (Irving Berlin, 1888) NNP NNP CD Infix Aurelio de la Vega was born November 28, 1925, in Havana, Cuba." ></td>
	<td class="line x" title="25:168	FW FW FW NNP VBD VBN NNP CD, CD, IN NNP, NNP . foundnot found Infix not found Prefix PostfixInfix Matching on sentences Seed fact Infixonly pattern The poet was born Jan. 13, several years after the revolution . not found British  native Glenn Cornick of Jethro Tull was born April 23, 1947 . NNP : JJ NNP NNP IN NNP NNP VBD VBN NNP CD, CD . Infix foundfound Chester Burton Atkins was born June 20, 1924, on a farm near Luttrell . NNP NNP NNP VBD VBN NNP CD, CD, IN DT NN IN NNP . Infix Infix found The youngest child of three siblings, Mariah Carey was born March 27, 1970 in Huntington, Long Island in New York . DT JJS NN IN CD NNS, NNP NNP VBD VBN NNP CD, CD IN NNP, JJ NN IN NNP NNP . found foundfound (S1) (S2) (S3) (S4) (S5) (Jethro Tull, 1947) (Mariah Carey, 1970) (Chester Burton Atkins, 1924) Candidate facts DT NN VBD VBN NNP CD, JJ NNS IN DT NN . N/A CL1 born CL2 00, N/A Figure 2: Extraction via infix-only patterns contains the sequence [CL1 born CL2 00 .], illustrates the use of classes of distributionally similar words within extraction patterns." ></td>
	<td class="line x" title="26:168	The first word class in the sequence, CL1, consists of words such as {was, is, could}, whereas the second class includes {February, April, June, Aug. , November} and other similar words." ></td>
	<td class="line x" title="27:168	The classes of words are computed on the fly over all sequences of terms in the extracted patterns, on top of a large set of pairwise similarities among words (Lin, 1998) extracted in advance from around 50 million news articles indexed by the Google search engine over three years." ></td>
	<td class="line x" title="28:168	All digits in both patterns and sentences are replaced with a common marker, such 810 that any two numerical values with the same number of digits will overlap during matching." ></td>
	<td class="line oc" title="29:168	Many methods have been proposed to compute distributional similarity between words, e.g., (Hindle, 1990), (Pereira et al. , 1993), (Grefenstette, 1994) and (Lin, 1998)." ></td>
	<td class="line o" title="30:168	Almost all of the methods represent a word by a feature vector, where each feature corresponds to a type of context in which the word appeared." ></td>
	<td class="line o" title="31:168	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed." ></td>
	<td class="line x" title="32:168	In our approach, we define the features of a word w to be the set of words that occurred within a small window of w in a large corpus." ></td>
	<td class="line x" title="33:168	The context window of an instance of w consists of the closest non-stopword on each side of w and the stopwords in between." ></td>
	<td class="line x" title="34:168	The value of a feature wprime is defined as the pointwise mutual information between wprime and w: PMI(wprime, w) = log( P(w,wprime)P(w)P(wprime))." ></td>
	<td class="line x" title="35:168	The similarity between two different words w1 and w2, S(w1, w2), is then computed as the cosine of the angle between their feature vectors." ></td>
	<td class="line x" title="36:168	While the previous approaches to distributional similarity have only applied to words, we applied the same technique to proper names as well as words." ></td>
	<td class="line x" title="37:168	The following are some example similar words and phrases with their similarities, as obtained from the Google News corpus:  Carey: Higgins 0.39, Lambert 0.39, Payne 0.38, Kelley 0.38, Hayes 0.38, Goodwin 0.38, Griffin 0.38, Cummings 0.38, Hansen 0.38, Williamson 0.38, Peters 0.38, Walsh 0.38, Burke 0.38, Boyd 0.38, Andrews 0.38, Cunningham 0.38, Freeman 0.37, Stephens 0.37, Flynn 0.37, Ellis 0.37, Bowers 0.37, Bennett 0.37, Matthews 0.37, Johnston 0.37, Richards 0.37, Hoffman 0.37, Schultz 0.37, Steele 0.37, Dunn 0.37, Rowe 0.37, Swanson 0.37, Hawkins 0.37, Wheeler 0.37, Porter 0.37, Watkins 0.37, Meyer 0.37 [];  Mariah Carey: Shania Twain 0.38, Christina Aguilera 0.35, Sheryl Crow 0.35, Britney Spears 0.33, Celine Dion 0.33, Whitney Houston 0.32, Justin Timberlake 0.32, Beyonce Knowles 0.32, Bruce Springsteen 0.30, Faith Hill 0.30, LeAnn Rimes 0.30, Missy Elliott 0.30, Aretha Franklin 0.29, Jennifer Lopez 0.29, Gloria Estefan 0.29, Elton John 0.29, Norah Jones 0.29, Missy Elliot 0.29, Alicia Keys 0.29, Avril Lavigne 0.29, Kid Rock 0.28, Janet Jackson 0.28, Kylie Minogue 0.28, Beyonce 0.27, Enrique Iglesias 0.27, Michelle Branch 0.27 [];  Jethro Tull: Motley Crue 0.28, Black Crowes 0.26, Pearl Jam 0.26, Silverchair 0.26, Black Sabbath 0.26, Doobie Brothers 0.26, Judas Priest 0.26, Van Halen 0.25, Midnight Oil 0.25, Pere Ubu 0.24, Black Flag 0.24, Godsmack 0.24, Grateful Dead 0.24, Grand Funk Railroad 0.24, Smashing Pumpkins 0.24, Led Zeppelin 0.24, Aerosmith 0.24, Limp Bizkit 0.24, Counting Crows 0.24, Echo And The Bunnymen 0.24, Cold Chisel 0.24, Thin Lizzy 0.24 []." ></td>
	<td class="line x" title="38:168	To our knowledge, the only previous study that embeds similarities into the acquisition of extraction patterns is (Stevenson and Greenwood, 2005)." ></td>
	<td class="line x" title="39:168	The authors present a method for computing pairwise similarity scores among large sets of potential syntactic (subject-verb-object) patterns, to detect centroids of mutually similar patterns." ></td>
	<td class="line x" title="40:168	By assuming the syntactic parsing of the underlying text collection to generate the potential patterns in the first place, the method is impractical on Web-scale collections." ></td>
	<td class="line x" title="41:168	Two patterns, e.g. chairman-resign and CEO-quit, are similar to each other if their components are present in an external hand-built ontology (i.e. , WordNet), and the similarity among the components is high over the ontology." ></td>
	<td class="line x" title="42:168	Since general-purpose ontologies, and WordNet in particular, contain many classes (e.g. , chairman and CEO) but very few instances such as Osasuna, Crewe etc. , the patterns containing an instance rather than a class will not be found to be similar to one another." ></td>
	<td class="line x" title="43:168	In comparison, the classes and instances are equally useful in our method for generalizing patterns for fact extraction." ></td>
	<td class="line x" title="44:168	We merge basic patterns into generalized patterns, regardless of whether the similar words belong, as classes or instances, in any external ontology." ></td>
	<td class="line x" title="45:168	2.2 Generalization via Infix-Only Patterns By giving up the contextual constraints imposed by the prefix and postfix, infix-only patterns represent the most aggressive type of extraction patterns that still use contiguous sequences of terms." ></td>
	<td class="line x" title="46:168	In the absence of the prefix and postfix, the outer boundaries of the fact are computed separately for the beginning of the first (left) and end of the second (right) phrases of the candidate fact." ></td>
	<td class="line x" title="47:168	For generality, the computation relies only on the partof-speech tags of the current seed set." ></td>
	<td class="line x" title="48:168	Starting forward from the right extremity of the infix, we collect a growing sequence of terms whose partof-speech tags are [P1+ P2+  Pn+], where the 811 notation Pi+ represents one or more consecutive occurrences of the part-of-speech tag Pi." ></td>
	<td class="line x" title="49:168	The sequence [P1 P2  Pn] must be exactly the sequence of part of speech tags from the right side of one of the seed facts." ></td>
	<td class="line x" title="50:168	The point where the sequence cannot be grown anymore defines the boundary of the fact." ></td>
	<td class="line x" title="51:168	A similar procedure is applied backwards, starting from the left extremity of the infix." ></td>
	<td class="line x" title="52:168	An infix-only pattern produces a candidate fact from a sentence only if an acceptable sequence is found to the left and also to the right of the infix." ></td>
	<td class="line x" title="53:168	Figure 2 illustrates the process on the infixonly pattern mentioned earlier, and one seed fact." ></td>
	<td class="line x" title="54:168	The part-of-speech tags for the seed fact are [NNP NNP] and [CD] for the left and right sides respectively." ></td>
	<td class="line x" title="55:168	The infix occurs in all sentences." ></td>
	<td class="line x" title="56:168	However, the matching of the part-of-speech tags of the sentence sequences to the left and right of the infix, against the part-of-speech tags of the seed fact, only succeeds for the last three sentences." ></td>
	<td class="line x" title="57:168	It fails for the first sentence S1 to the left of the infix, because [ NNP] (for Vega) does not match [NNP NNP]." ></td>
	<td class="line x" title="58:168	It also fails for the second sentence S2 to both the left and the right side of the infix, since [ NN] (for poet) does not match [NNP NNP], and [JJ ] (for several) does not match [CD]." ></td>
	<td class="line x" title="59:168	3 Similarities for Validation and Ranking 3.1 Revisiting Standard Ranking Criteria Because some of the acquired extraction patterns are too generic or wrong, all approaches to iterative acquisition place a strong emphasis on the choice of criteria for ranking." ></td>
	<td class="line x" title="60:168	Previous literature quasi-unanimously assesses the quality of each candidate fact based on the number and quality of the patterns that extract the candidate fact (more is better); and the number of seed facts extracted by the same patterns (again, more is better) (Agichtein and Gravano, 2000; Thelen and Riloff, 2002; Lita and Carbonell, 2004)." ></td>
	<td class="line x" title="61:168	However, our experiments using many variations of previously proposed scoring functions suggest that they have limited applicability in large-scale fact extraction, for two main reasons." ></td>
	<td class="line x" title="62:168	The first is that it is impractical to perform hundreds of acquisition iterations on terabytes of text." ></td>
	<td class="line x" title="63:168	Instead, one needs to grow the seed set aggressively in each iteration." ></td>
	<td class="line x" title="64:168	Previous scoring functions were implicitly designed for cautious acquisition strategies (Collins and Singer, 1999), which expand the seed set very slowly across consecutive iterations." ></td>
	<td class="line x" title="65:168	In that case, it makes sense to single out a small number of best candidates, among the other available candidates." ></td>
	<td class="line x" title="66:168	Comparatively, when 10,000 candidate facts or more need to be added to a seed set of 10 seeds as early as after the first iteration, it is difficult to distinguish the quality of extraction patterns based, for instance, only on the percentage of the seed set that they extract." ></td>
	<td class="line x" title="67:168	The second reason is the noisy nature of the Web." ></td>
	<td class="line x" title="68:168	A substantial number of factors can and will concur towards the worst-case extraction scenarios on the Web." ></td>
	<td class="line x" title="69:168	Patterns of apparently high quality turn out to produce a large quantity of erroneous facts such as (A-League, 1997), but also the more interesting (Jethro Tull, 1947) as shown earlier in Figure 2, or (Web Site David, 1960) or (New York, 1831)." ></td>
	<td class="line x" title="70:168	As for extraction patterns of average or lower quality, they will naturally lead to even more spurious extractions." ></td>
	<td class="line x" title="71:168	3.2 Ranking of Extraction Patterns The intuition behind our criteria for ranking generalized pattern is that patterns of higher precision tend to contain words that are indicative of the relation being mined." ></td>
	<td class="line x" title="72:168	Thus, a pattern is more likely to produce good candidate facts if its infix contains the words language or spoken if extracting Language-SpokenIn-Country facts, or the word capital if extracting City-CapitalOf-Country relations." ></td>
	<td class="line x" title="73:168	In each acquisition iteration, the scoring of patterns is a two-pass procedure." ></td>
	<td class="line x" title="74:168	The first pass computes the normalized frequencies of all words excluding stopwords, over the entire set of extraction patterns." ></td>
	<td class="line x" title="75:168	The computation applies separately to the prefix, infix and postfix of the patterns." ></td>
	<td class="line x" title="76:168	In the second pass, the score of an extraction pattern is determined by the words with the highest frequency score in its prefix, infix and postfix, as computed in the first pass and adjusted for the relative distance to the start and end of the infix." ></td>
	<td class="line x" title="77:168	3.3 Ranking of Candidate Facts Figure 3 introduces a new scheme for assessing the quality of the candidate facts, based on the computation of similarity scores for each candidate relative to the set of seed facts." ></td>
	<td class="line x" title="78:168	A candidate fact, e.g., (Richard Steele, 1672), is similar to the seed set if both its phrases, i.e., Richard Steele and 1672, are similar to the corresponding phrases (John Lennon or Stephen Foster in the case of Richard Steele) from the seed facts." ></td>
	<td class="line x" title="79:168	For a phrase of a candidate fact to be assigned a non-default (non-minimum) 812  Lennon Lambert McFadden Bateson McNamara Costello Cronin Wooley Baker  Foster Hansen Hawkins Fisher Holloway Steele Sweeney Chris John James Andrew Mike Matt Brian Christopher  John Lennon 1940 Seed facts Stephen Foster 1826 Brian McFadden 1980 (4)(3) Robert S. McNamara 1916 (6)(5) Barbara Steele 1937 (7) (2) Stan Hansen 1949 (9)(8) Similar wordsSimilar words for: John Similar words for: Stephen for: Lennon Similar words for: Foster  Stephen Robert Michael Peter William Stan Richard(1) Barbara (3) (5) (7) (2) (8) (9) (4) (6) (2)(1) Candidate facts Jethro Tull 1947 Richard Steele 1672 Figure 3: The role of similarities in estimating the quality of candidate facts similarity score, the words at its extremities must be similar to one or more words situated at the same positions in the seed facts." ></td>
	<td class="line x" title="80:168	This is the case for the first five candidate facts in Figure 3." ></td>
	<td class="line x" title="81:168	For example, the first word Richard from one of the candidate facts is similar to the first word John from one of the seed facts." ></td>
	<td class="line x" title="82:168	Concurrently, the last word Steele from the same phrase is similar to Foster from another seed fact." ></td>
	<td class="line x" title="83:168	Therefore Robert Foster is similar to the seed facts." ></td>
	<td class="line x" title="84:168	The score of a phrase containing N words is:braceleftBigg C1 + summationtextNi=1 log(1 + Simi), if Sim1,N > 0 C2, otherwise." ></td>
	<td class="line x" title="85:168	where Simi is the similarity of the component word at position i in the phrase, and C1 and C2 are scaling constants such that C2lessmuchC1." ></td>
	<td class="line x" title="86:168	Thus, the similarity score of a candidate fact aggregates individual word-to-word similarity scores, for the left side and then for the right side of a candidate fact." ></td>
	<td class="line x" title="87:168	In turn, the similarity score of a component word Simi is higher if: a) the computed word-toword similarity scores are higher relative to words at the same position i in the seeds; and b) the component word is similar to words from more than one seed fact." ></td>
	<td class="line x" title="88:168	The similarity scores are one of a linear combination of features that induce a ranking over the candidate facts." ></td>
	<td class="line x" title="89:168	Three other domain-independent features contribute to the final ranking: a) a phrase completeness score computed statistically over the entire set of candidate facts, which demotes candidate facts if any of their two sides is likely to be incomplete (e.g. , Mary Lou vs. Mary Lou Retton, or John F. vs. John F. Kennedy); b) the average PageRank value over all documents from which the candidate fact is extracted; and c) the patternbased scores of the candidate fact." ></td>
	<td class="line x" title="90:168	The latter feature converts the scores of the patterns extracting the candidate fact into a score for the candidate fact." ></td>
	<td class="line x" title="91:168	For this purpose, it considers a fixed-length window of words around each match of a candidate fact in some sentence from the text collection." ></td>
	<td class="line x" title="92:168	This is equivalent to analyzing all sentence contexts from which a candidate fact can be extracted." ></td>
	<td class="line x" title="93:168	For each window, the word with the highest frequency score, as computed in the first pass of the procedure for scoring the patterns, determines the score of the candidate fact in that context." ></td>
	<td class="line x" title="94:168	The overall pattern-based score of a candidate fact is the sum of the scores over all its contexts of occurrence, normalized by the frequency of occurrence of the candidate over all sentences." ></td>
	<td class="line x" title="95:168	Besides inducing a ranking over the candidate facts, the similarity scores also serve as a validation filter over the candidate facts." ></td>
	<td class="line x" title="96:168	Indeed, any candidates that are not similar to the seed set can be filtered out." ></td>
	<td class="line x" title="97:168	For instance, the elimination of (Jethro Tull, 1947) is a side effect of verifying that Tull is not similar to any of the last-position words from phrases in the seed set." ></td>
	<td class="line x" title="98:168	4 Evaluation 4.1 Data The source text collection consists of three chunks W1, W2, W3 of approximately 100 million documents each." ></td>
	<td class="line x" title="99:168	The documents are part of a larger snapshot of the Web taken in 2003 by the Google search engine." ></td>
	<td class="line x" title="100:168	All documents are in English." ></td>
	<td class="line x" title="101:168	The textual portion of the documents is cleaned of Html, tokenized, split into sentences and partof-speech tagged using the TnT tagger (Brants, 2000)." ></td>
	<td class="line x" title="102:168	The evaluation involves facts of type PersonBornIn-Year." ></td>
	<td class="line x" title="103:168	The reasons behind the choice of this particular type are threefold." ></td>
	<td class="line x" title="104:168	First, many Person-BornIn-Year facts are probably available on the Web (as opposed to, e.g., City-CapitalOfCountry facts), to allow for a good stress test for large-scale extraction." ></td>
	<td class="line x" title="105:168	Second, either side of the facts (Person and Year) may be involved in many other types of facts, such that the extraction would easily divergence unless it performs correctly." ></td>
	<td class="line x" title="106:168	Third, the phrases from one side (Person) have an utility in their own right, for lexicon 813 Table 1: Set of seed Person-BornIn-Year facts Name Year Name Year Paul McCartney 1942 John Lennon 1940 Vincenzo Bellini 1801 Stephen Foster 1826 Hoagy Carmichael 1899 Irving Berlin 1888 Johann Sebastian Bach 1685 Bela Bartok 1881 Ludwig van Beethoven 1770 Bob Dylan 1941 construction or detection of person names." ></td>
	<td class="line x" title="107:168	The Person-BornIn-Year type is specified through an initial set of 10 seed facts shown in Table 1." ></td>
	<td class="line x" title="108:168	Similarly to source documents, the facts are also part-of-speech tagged." ></td>
	<td class="line x" title="109:168	4.2 System Settings In each iteration, the case-insensitive matching of the current set of seed facts onto the sentences produces basic patterns." ></td>
	<td class="line x" title="110:168	The patterns are converted into generalized patterns." ></td>
	<td class="line x" title="111:168	The length of the infix may vary between 1 and 6 words." ></td>
	<td class="line x" title="112:168	Potential patterns are discarded if the infix contains only stopwords." ></td>
	<td class="line x" title="113:168	When a pattern is retained, it is used as an infix-only pattern, and allowed to generate at most 600,000 candidate facts." ></td>
	<td class="line x" title="114:168	At the end of an iteration, approximately one third of the validated candidate facts are added to the current seed set." ></td>
	<td class="line x" title="115:168	Consequently, the acquisition expands the initial seed set of 10 facts to 100,000 facts (after iteration 1) and then to one million facts (after iteration 2) using chunk W1." ></td>
	<td class="line x" title="116:168	4.3 Precision A separate baseline run extracts candidate facts from the text collection following the traditional iterative acquisition approach." ></td>
	<td class="line x" title="117:168	Pattern generalization is disabled, and the ranking of patterns and facts follows strictly the criteria and scoring functions from (Thelen and Riloff, 2002), which are also used in slightly different form in (Lita and Carbonell, 2004) and (Agichtein and Gravano, 2000)." ></td>
	<td class="line x" title="118:168	The theoretical option of running thousands of iterations over the text collection is not viable, since it would imply a non-justifiable expense of our computational resources." ></td>
	<td class="line x" title="119:168	As a more realistic compromise over overly-cautious acquisition, the baseline run retains as many of the top candidate facts as the size of the current seed, whereas (Thelen and Riloff, 2002) only add the top five candidate facts to the seed set after each iteration." ></td>
	<td class="line x" title="120:168	The evaluation considers all 80, a sample of the 320, and another sample of the 10,240 facts retained after iterations 3, 5 and 10 respectively." ></td>
	<td class="line x" title="121:168	The correctness assessment of each fact consists in manually finding some Web page that contains clear evidence that the fact is correct." ></td>
	<td class="line x" title="122:168	If no such page exists, the fact is marked as incorrect." ></td>
	<td class="line x" title="123:168	The corresponding precision values after the three iterations are 91.2%, 83.8% and 72.9%." ></td>
	<td class="line x" title="124:168	For the purpose of evaluating the precision of our system, we select a sample of facts from the entire list of one million facts extracted from chunk W1, ranked in decreasing order of their computed scores." ></td>
	<td class="line x" title="125:168	The sample is generated automatically from the top of the list to the bottom, by retaining a fact and skipping the following consecutive N facts, where N is incremented at each step." ></td>
	<td class="line x" title="126:168	The resulting list, which preserves the relative order of the facts, contains 1414 facts." ></td>
	<td class="line x" title="127:168	The 115 facts for which a Web search engine does not return any documents, when the name (as a phrase) and the year are submitted together in a conjunctive query, are discarded from the sample of 1414 facts." ></td>
	<td class="line x" title="128:168	In those cases, the facts were acquired from the 2003 snapshot of the Web, but queries are submitted to a search engine with access to current Web documents, hence the difference when some of the 2003 documents are no longer available or indexable." ></td>
	<td class="line x" title="129:168	Based on the sample set, the average precision of the list of one million facts extracted from chunk W1 is 98.5% over the top 1/100 of the list, 93.1% over the top half of the list, and 88.3% over the entire list of one million facts." ></td>
	<td class="line x" title="130:168	Table 2 shows examples of erroneous facts extracted from chunk W1." ></td>
	<td class="line x" title="131:168	Causes of errors include incorrect approximations of the name boundaries (e.g. , Alma in Alma Theresa Rausch is incorrectly tagged as an adjective), and selection of the wrong year as birth year (e.g. , for Henry Lumbar)." ></td>
	<td class="line x" title="132:168	In the case of famous people, the extracted facts tend to capture the correct birth year for several variations of the names, as shown in Table 3." ></td>
	<td class="line x" title="133:168	Conversely, it is not necessary that a fact occur with high frequency in order for it to be extracted, which is an advantage over previous approaches that rely strongly on redundancy (cf.(Cafarella et al. , 2005))." ></td>
	<td class="line x" title="135:168	Table 4 illustrates a few of the correctly extracted facts that occur rarely on the Web." ></td>
	<td class="line x" title="136:168	4.4 Recall In contrast to the assessment of precision, recall can be evaluated automatically, based on external 814 Table 2: Incorrect facts extracted from the Web Spurious Fact Context in Source Sentence (Theresa Rausch, Alma Theresa Rausch was born 1912) on 9 March 1912 (Henry Lumbar, Henry Lumbar was born 1861 1937) and died 1937 (Concepcion Paxety, Maria de la Concepcion Paxety 1817) b. 08 Dec. 1817 St. Aug., FL." ></td>
	<td class="line x" title="137:168	(Mae Yaeger, Ella May/Mae Yaeger was born 1872) 20 May 1872 in Mt." ></td>
	<td class="line x" title="138:168	(Charles Whatley, Long, Charles Whatley b. 16 1821) FEB 1821 d. 29 AUG (HOLT George W. HOLT (new line) George W. Holt Holt, 1845) was born in Alabama in 1845 (David Morrish David Morrish (new line) Canadian, 1953) Canadian, b. 1953 (Mary Ann, 1838) had a daughter, Mary Ann, who was born in Tennessee in 1838 (Mrs. Blackmore, Mrs. Blackmore was born April 1918) 28, 1918, in Labaddiey Table 3: Birth years extracted for both pseudonyms and corresponding real names Pseudonym Real Name Year Gloria Estefan Gloria Fajardo 1957 Nicolas Cage Nicolas Kim Coppola 1964 Ozzy Osbourne John Osbourne 1948 Ringo Starr Richard Starkey 1940 Tina Turner Anna Bullock 1939 Tom Cruise Thomas Cruise Mapother IV 1962 Woody Allen Allen Stewart Konigsberg 1935 lists of birth dates of various people." ></td>
	<td class="line x" title="139:168	We start by collecting two gold standard sets of facts." ></td>
	<td class="line x" title="140:168	The first set is a random set of 609 actors and their birth years from a Web compilation (GoldA)." ></td>
	<td class="line x" title="141:168	The second set is derived from the set of questions used in the Question Answering track (Voorhees and Tice, 2000) of the Text REtrieval Conference from 1999 through 2002." ></td>
	<td class="line x" title="142:168	Each question asking for the birth date of a person (e.g. , What year was Robert Frost born?) results in a pair containing the persons name and the birth year specified in the answer keys." ></td>
	<td class="line x" title="143:168	Thus, the second gold standard set contains 17 pairs of people and their birth years (GoldT )." ></td>
	<td class="line x" title="144:168	Table 5 shows examples of facts in each of the gold standard sets." ></td>
	<td class="line x" title="145:168	Table 6 shows two types of recall scores computed against the gold standard sets." ></td>
	<td class="line x" title="146:168	The recall scores over Gold take into consideration only the set of person names from the gold standard with some extracted year(s)." ></td>
	<td class="line x" title="147:168	More precisely, given that some years were extracted for a person name, it verifies whether they include the year specified in the gold standard for that person name." ></td>
	<td class="line x" title="148:168	Comparatively, the recall score denoted AllGold is comTable 4: Extracted facts that occur infrequently Fact Source Domain (Irvine J Forcier, 1912) geocities.com (Marie Louise Azelie Chabert, 1861) vienici.com (Jacob Shalles, 1750) selfhost.com (Robert Chester Claggett, 1898) rootsweb.com (Charoltte Mollett, 1843) rootsweb.com (Nora Elizabeth Curran, 1979) jimtravis.com Table 5: Composition of gold standard sets Gold Set Composition and Examples of Facts GoldA Actors (Web compilation) Nr." ></td>
	<td class="line x" title="149:168	facts: 609 (Andie MacDowell, 1958), (Doris Day, 1924), (Diahann Carroll, 1935) GoldT People (TREC QA track) Nr." ></td>
	<td class="line x" title="150:168	facts: 17 (Davy Crockett, 1786), (Julius Caesar, 100 B.C.), (King Louis XIV, 1638) puted over the entire set of names from the gold standard." ></td>
	<td class="line x" title="151:168	For the GoldA set, the size of the Gold set of person names changes little when the facts are extracted from chunk W1 vs. W2 vs. W3." ></td>
	<td class="line x" title="152:168	The recall scores over Gold exhibit little variation from one Web chunk to another, whereas the AllGold score is slightly higher on the W3 chunk, probably due to a higher number of documents that are relevant to the extraction task." ></td>
	<td class="line x" title="153:168	When the facts are extracted from a combination of two or three of the available Web chunks, the recall scores computed over AllGold are significantly higher as the size of the Gold set increases." ></td>
	<td class="line x" title="154:168	In comparison, the recall scores over the growing Gold set increases slightly with larger evaluation sets." ></td>
	<td class="line x" title="155:168	The highest value of the recall score for GoldA is 89.9% over the Gold set, and 70.7% over AllGold." ></td>
	<td class="line x" title="156:168	The smaller size of the second gold standard set, GoldT, explains the higher variation of the values shown in the lower portion of Table 6." ></td>
	<td class="line x" title="157:168	4.5 Comparison to Previous Results Another recent approach specifically addresses the problem of extracting facts from a similarly-sized collection of Web documents." ></td>
	<td class="line x" title="158:168	In (Cafarella et al. , 2005), manually-prepared extraction rules are applied to a collection of 60 million Web documents to extract entities of types Company and Country, as well as facts of type Person-CeoOf-Company and City-CapitalOf-Country." ></td>
	<td class="line x" title="159:168	Based on manual evaluation of precision and recall, a total of 23,128 company names are extracted at precision of 80%; the number decreases to 1,116 at precision of 90%." ></td>
	<td class="line x" title="160:168	In addition, 2,402 Person-CeoOf-Company facts 815 Table 6: Automatic evaluation of recall, over two gold standard sets GoldA (609 person names) and GoldT (17 person names) Gold Set Input Data Recall (%) (Web Chunk) Gold AllGold GoldA W1 86.4 49.4 W2 85.0 50.5 W3 86.3 54.1 W1+W2 88.5 64.5 W1+W2+W3 89.9 70.7 GoldT W1 81.8 52.9 W2 90.0 52.9 W3 100.0 64.7 W1+W2 81.8 52.9 W1+W2+W3 91.6 64.7 are extracted at precision 80%." ></td>
	<td class="line x" title="161:168	The recall value is 80% at precision 90%." ></td>
	<td class="line x" title="162:168	Recall is evaluated against the set of company names extracted by the system, rather than an external gold standard with pairs of a CEO and a company name." ></td>
	<td class="line x" title="163:168	As such, the resulting metric for evaluating recall used in (Cafarella et al. , 2005) is somewhat similar to, though more relaxed than, the recall score over the Gold set introduced in the previous section." ></td>
	<td class="line x" title="164:168	5 Conclusion The combination of generalized extraction patterns and similarity-driven ranking criteria results in a fast-growth iterative approach for large-scale fact extraction." ></td>
	<td class="line x" title="165:168	From 10 Person-BornIn-Year facts and no additional knowledge, a set of one million facts of the same type is extracted from a collection of 100 million Web documents of arbitrary quality, with a precision around 90%." ></td>
	<td class="line x" title="166:168	This corresponds to a growth ratio of 100,000:1 between the size of the extracted set of facts and the size of the initial set of seed facts." ></td>
	<td class="line x" title="167:168	To our knowledge, the growth ratio and the number of extracted facts are several orders of magnitude higher than in any of the previous studies on fact extraction based on either hand-written extraction rules (Cafarella et al. , 2005), or bootstrapping for relation and information extraction (Agichtein and Gravano, 2000; Lita and Carbonell, 2004)." ></td>
	<td class="line x" title="168:168	The next research steps converge towards the automatic construction of a searchable repository containing billions of facts regarding people." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P06-1116
A Bootstrapping Approach To Unsupervised Detection Of Cue Phrase Variants
Abdalla, Rashid M.;Teufel, Simone;"></td>
	<td class="line x" title="1:231	Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 921928, Sydney, July 2006." ></td>
	<td class="line x" title="2:231	c2006 Association for Computational Linguistics A Bootstrapping Approach to Unsupervised Detection of Cue Phrase Variants Rashid M. Abdalla and Simone Teufel Computer Laboratory, University of Cambridge 15 JJ Thomson Avenue, Cambridge CB3 OFD, UK rma33@cam.ac.uk, sht25@cam.ac.uk Abstract We investigate the unsupervised detection of semixed cue phrases such as This paper proposes a novel approach." ></td>
	<td class="line x" title="3:231	1 from unseen text, on the basis of only a handful of seed cue phrases with the desired semantics." ></td>
	<td class="line x" title="4:231	The problem, in contrast to bootstrapping approaches for Question Answering and Information Extraction, is that it is hard to nd a constraining context for occurrences of semixed cue phrases." ></td>
	<td class="line x" title="5:231	Our method uses components of the cue phrase itself, rather than external context, to bootstrap." ></td>
	<td class="line x" title="6:231	It successfully excludes phrases which are different from the target semantics, but which look super cially similar." ></td>
	<td class="line x" title="7:231	The method achieves 88% accuracy, outperforming standard bootstrapping approaches." ></td>
	<td class="line x" title="8:231	1 Introduction Cue phrases such as This paper proposes a novel approach to." ></td>
	<td class="line x" title="9:231	., no method for . . ." ></td>
	<td class="line x" title="10:231	exists or even you will hear from my lawyer are semixed in that they constitute a formulaic pattern with a clear semantics, but with syntactic and lexical variations which are hard to predict and thus hard to detect in unseen text (e.g. a new algorithm for . . ." ></td>
	<td class="line x" title="11:231	is suggested in the current paper or I envisage legal action )." ></td>
	<td class="line x" title="12:231	In scienti c discourse, such metadiscourse (Myers, 1992; Hyland, 1998) abounds and plays an important role in marking the discourse structure of the texts." ></td>
	<td class="line x" title="13:231	Finding these variants can be useful for many text understanding tasks because semixed cue phrases act as linguistic markers indicating the importance and/or the rhetorical role of some adjacent text." ></td>
	<td class="line x" title="14:231	For the summarisation of scienti c 1In contrast to standard work in discourse linguistics, which mostly considers sentence connectives and adverbials as cue phrases, our de nition includes longer phrases, sometimes even entire sentences." ></td>
	<td class="line x" title="15:231	papers, cue phrases such as Our paper deals with." ></td>
	<td class="line x" title="16:231	are commonly used as indicators of extraction-worthiness of sentences (Kupiec et al. , 1995)." ></td>
	<td class="line x" title="17:231	Re-generative (rather than extractive) summarisation methods may want to go further than that and directly use the knowledge that a certain sentence contains the particular research aim of a paper, or a claimed gap in the literature." ></td>
	<td class="line x" title="18:231	Similarly, in the task of automatic routing of customer emails and automatic answering of some of these, the detection of threats of legal action could be useful." ></td>
	<td class="line x" title="19:231	However, systems that use cue phrases usually rely on manually compiled lists, the acquisition of which is time-consuming and error-prone and results in cue phrases which are genre-speci c. Methods for nding cue phrases automatically include Hovy and Lin (1998) (using the ratio of word frequency counts in summaries and their corresponding texts), Teufel (1998) (using the most frequent n-grams), and Paice (1981) (using a pattern matching grammar and a lexicon of manually collected equivalence classes)." ></td>
	<td class="line x" title="20:231	The main issue with string-based pattern matching techniques is that they cannot capture syntactic generalisations such as active/passive constructions, different tenses and modi cation by adverbial, adjectival or prepositional phrases, appositions and other parenthetical material." ></td>
	<td class="line x" title="21:231	For instance, we may be looking for sentences expressing the goal or main contribution of a paper; Fig." ></td>
	<td class="line x" title="22:231	1 shows candidates of such sentences." ></td>
	<td class="line x" title="23:231	Cases a) e), which do indeed describe the authors goal, display a wide range of syntactic variation." ></td>
	<td class="line x" title="24:231	a) In this paper, we introduce a method for similaritybased estimation of . . ." ></td>
	<td class="line x" title="25:231	b) We introduce and justify a method." ></td>
	<td class="line x" title="26:231	c) A method (described in section 1) is introduced d) The method introduced here is a variation." ></td>
	<td class="line x" title="27:231	e) We wanted to introduce a method." ></td>
	<td class="line x" title="28:231	f) We do not introduce a method." ></td>
	<td class="line x" title="29:231	g) We introduce and adopt the method given in [1]." ></td>
	<td class="line x" title="30:231	h) Previously we introduced a similar method." ></td>
	<td class="line x" title="31:231	i) They introduce a similar method." ></td>
	<td class="line x" title="32:231	Figure 1: Goal statements and syntactic variation correct matches (a-e) and incorrect matches (f-i) 921 Cases f) i) in contrast are false matches: they do not express the authors goals, although they are super cially similar to the correct contexts." ></td>
	<td class="line x" title="33:231	While string-based approaches (Paice, 1981; Teufel, 1998) are too restrictive to cover the wide variation within the correct contexts, bag-of-words approaches such as Agichtein and Gravanos (2000) are too permissive and would miss many of the distinctions between correct and incorrect contexts." ></td>
	<td class="line x" title="34:231	Lisacek et al.(2005) address the task of identifying paradigm shift sentences in the biomedical literature, i.e. statements of thwarted expectation." ></td>
	<td class="line x" title="36:231	This task is somewhat similar to ours in its de nition by rhetorical context." ></td>
	<td class="line x" title="37:231	Their method goes beyond string-based matching: In order for a sentence to qualify, the right set of concepts must be present in a sentence, with any syntactic relationship holding between them." ></td>
	<td class="line x" title="38:231	Each concept set is encoded as a xed, manually compiled lists of strings." ></td>
	<td class="line x" title="39:231	Their method covers only one particular context (the paradigm shift one), whereas we are looking for a method where many types of cue phrases can be acquired." ></td>
	<td class="line x" title="40:231	Whereas it relies on manually assembled lists, we advocate data-driven acquisition of new contexts." ></td>
	<td class="line x" title="41:231	This is generally preferrable to manual de nition, as language use is changing, inventive and hard to predict and as many of the relevant concepts in a domain may be infrequent (cf.the formulation be cursed, which was used in our corpus as a way of describing a methods problems)." ></td>
	<td class="line x" title="43:231	It also allows the acquisition of cue phrases in new domains, where the exact prevalent meta-discourse might not be known." ></td>
	<td class="line x" title="44:231	Riloffs (1993) method for learning information extraction (IE) patterns uses a syntactic parse and correspondences between the text and lled MUCstyle templates to learn context in terms of lexicosemantic patterns." ></td>
	<td class="line x" title="45:231	However, it too requires substantial hand-crafted knowledge: 1500 lled templates as training material, and a lexicon of semantic features for roughly 3000 nouns for constraint checking." ></td>
	<td class="line x" title="46:231	Unsupervised methods for similar tasks include Agichtein and Gravanos (2000) work, which shows that clusters of vector-spacebased patterns can be successfully employed to detect speci c IE relationships (companies and their headquarters), and Ravichandran and Hovys (2002) algorithm for nding patterns for a Question Answering (QA) task." ></td>
	<td class="line x" title="47:231	Based on training material in the shape of pairs of question and answer terms e.g., (e.g. {Mozart, 1756}), they learn the a) In this paper, we introduce a method for similaritybased estimation of . . ." ></td>
	<td class="line x" title="48:231	b) Here, we present a similarity-based approach for estimation of." ></td>
	<td class="line x" title="49:231	c) In this paper, we propose an algorithm which is . . ." ></td>
	<td class="line x" title="50:231	d) We will here de ne a technique for similarity-based." ></td>
	<td class="line x" title="51:231	Figure 2: Context around cue phrases (lexical variants) semantics holding between these terms ( birth year ) via frequent string patterns occurring in the context, such as A was born in B, by considering n-grams of all repeated substrings." ></td>
	<td class="line x" title="52:231	What is common to these three works is that bootstrapping relies on constraints between the context external to the extracted material and the extracted material itself, and that the target extraction material is de ned by real-world relations." ></td>
	<td class="line x" title="53:231	Our task differs in that the cue phrases we extract are based on general rhetorical relations holding in all scienti c discourse." ></td>
	<td class="line x" title="54:231	Our approach for nding semantically similar variants in an unsupervised fashion relies on bootstrapping of seeds from within the cue phrase." ></td>
	<td class="line x" title="55:231	The assumption is that every semixed cue phrase contains at least two main concepts whose syntax and semantics mutually constrain each other (e.g. verb and direct object in phrases such as (we) present an approach for )." ></td>
	<td class="line x" title="56:231	The expanded cue phrases are recognised in various syntactic contexts using a parser2." ></td>
	<td class="line x" title="57:231	General semantic constraints valid for groups of semantically similar cue phrases are then applied to model, e.g., the fact that it must be the authors who present the method, not somebody else." ></td>
	<td class="line x" title="58:231	We demonstrate that such an approach is more appropriate for our task than IE/QA bootstrapping mechanisms based on cue phrase-external context." ></td>
	<td class="line x" title="59:231	Part of the reason for why normal bootstrapping does not work for our phrases is the difculty of nding negatives contexts, essential in bootstrapping to evaluate the quality of the patterns automatically." ></td>
	<td class="line x" title="60:231	IE and QA approaches, due to uniqueness assumptions of the real-world relations that these methods search for, have an automatic de nition of negative contexts by hard constraints (i.e. , all contexts involving Mozart and any other year are by de nition of the wrong semantics; so are all contexts involving Microsoft and a city other than Redmond)." ></td>
	<td class="line x" title="61:231	As our task is not grounded in real-world relations but in rhetorical ones, constraints found in the context tend to be 2Thus, our task shows some parallels to work in paraphrasing (Barzilay and Lee, 2002) and syntactic variant generation (Jacquemin et al. , 1997), but the methods are very different." ></td>
	<td class="line x" title="62:231	922 soft rather than hard (cf.Fig 2): while it it possible that strings such as we and in this paper occur more often in the context of a given cue phrase, they also occur in many other places in the paper where the cue phrase is not present." ></td>
	<td class="line x" title="64:231	Thus, it is hard to de ne clear negative contexts for our task." ></td>
	<td class="line x" title="65:231	The novelty of our work is thus the new pattern extraction task ( nding variants of semixed cue phrases), a task for which it is hard to directly use the context the patterns appear in, and an iterative unsupervised bootstrapping algorithm for lexical variants, using phrase-internal seeds and ranking similar candidates based on relation strength between the seeds." ></td>
	<td class="line x" title="66:231	While our method is applicable to general cue phrases, we demonstrate it here with transitive verb direct object pairs, namely a) cue phrases introducing a new methodology (and thus the main research goal of the scienti c article; e.g. In this paper, we propose a novel algorithm." ></td>
	<td class="line x" title="67:231	) we call those goal-type cue phrases; and b) cue phrases indicating continuation of previous other research (e.g. Therefore, we adopt the approach presented in [1]." ></td>
	<td class="line x" title="68:231	) continuation-type cue phrases." ></td>
	<td class="line x" title="69:231	2 Lexical Bootstrapping Algorithm The task of this module is to nd lexical variants of the components of the seed cue phrases." ></td>
	<td class="line x" title="70:231	Given the seed phrases we introduce a method and we propose a model, the algorithm starts by nding all direct objects of introduce in a given corpus and, using an appropriate similarity measure, ranks them according to their distributional similarity to the nouns method and model . Subsequently, the noun method is used to nd transitive verbs and rank them according to their similarity to introduce and propose . In both cases, the ranking step retains variants that preserve the semantics of the cue phrase (e.g. develop and approach ) and lters irrelevant terms that change the phrase semantics (e.g. need and example )." ></td>
	<td class="line x" title="71:231	Stopping at this point would limit us to those terms that co-occur with the seed words in the training corpus." ></td>
	<td class="line x" title="72:231	Therefore additional iterations using automatically generated verbs and nouns are applied in order to recover more and more variants." ></td>
	<td class="line x" title="73:231	The full algorithm is given in Fig." ></td>
	<td class="line x" title="74:231	3." ></td>
	<td class="line x" title="75:231	The algorithm requires corpus data for the steps Hypothesize (producing a list of potential candidates) and Rank (testing them for similarity)." ></td>
	<td class="line x" title="76:231	We Input: Tuples {A1, A2, . . ., Am} and {B1, B2, . . ., Bn}." ></td>
	<td class="line x" title="77:231	Initialisation: Set the concept-A reference set to {A1, A2, . . ., Am} and the concept-B reference set to {B1, B2, . . ., Bn}." ></td>
	<td class="line x" title="78:231	Set the concept-A active element to A1 and the concept-B active element to B1." ></td>
	<td class="line x" title="79:231	Recursion: 1." ></td>
	<td class="line x" title="80:231	Concept B retrieval: (i) Hypothesize: Find terms in the corpus which are in the desired relationship with the concept-A active element (e.g. direct objects of a verb active element)." ></td>
	<td class="line x" title="81:231	This results in the concept-B candidate set." ></td>
	<td class="line x" title="82:231	(ii) Rank: Rank the concept-B candidate set using a suitable ranking methodology that may make use of the concept-B reference set." ></td>
	<td class="line x" title="83:231	In this process, each member of the candidate set is assigned a score." ></td>
	<td class="line x" title="84:231	(iii) Accumulate: Add the top s items of the concept-B candidate set to the concept-B accumulator list (based on empirical results, s is the rank of the candidate set during the initial iteration and 50 for the remaining iterations)." ></td>
	<td class="line x" title="85:231	If an item is already on the accumulator list, add its ranking score to the existing items score." ></td>
	<td class="line x" title="86:231	2." ></td>
	<td class="line x" title="87:231	Concept A retrieval: as above, with concepts A and B swapped." ></td>
	<td class="line x" title="88:231	3." ></td>
	<td class="line x" title="89:231	Updating active elements: (i) Set the concept-B active element to the highest ranked instance in the concept-B accumulator list which has not been used as an active element before." ></td>
	<td class="line x" title="90:231	(ii) Set the concept-A active element to the highest ranked instance in the concept-A accumulator list which has not been used as an active element before." ></td>
	<td class="line x" title="91:231	Repeat steps 1-3 for k iterations Output: top M words of concept-A (verb) accumulator list and top N words of concept-B (noun) accumulator list Reference set: a set of seed words which de ne the collective semantics of the concept we are looking for in this iteration Active element: the instance of the concept used in the current iteration for retrieving instances of the other concept." ></td>
	<td class="line x" title="92:231	If we are nding lexical variants of Concept A by exploiting relationships between Concepts A and B, then the active element is from Concept B. Candidate set: the set of candidate terms for one concept (eg." ></td>
	<td class="line x" title="93:231	Concept A) obtained using an active element from the other concept (eg." ></td>
	<td class="line x" title="94:231	Concept B)." ></td>
	<td class="line x" title="95:231	The more semantically similar a term in the candidate set is to the members of the reference set, the higher its ranking should be." ></td>
	<td class="line x" title="96:231	This set contains verbs if the active element is a noun and vice versa." ></td>
	<td class="line x" title="97:231	Accumulator list: a sorted list that accumulates the ranked members of the candidate set." ></td>
	<td class="line x" title="98:231	Figure 3: Lexical variant bootstrapping algorithm estimate frequencies for the Rank step from the written portion of the British National Corpus (BNC, Burnard (1995)), 90 Million words." ></td>
	<td class="line x" title="99:231	For the Hypothesize step, we experiment with two data sets: First, the scienti c subsection of the BNC (24 Million words), which we parse using RASP (Briscoe and Carroll, 2002); we then examine the grammatical relations (GRs) for transitive verb constructions, both in active and passive voice." ></td>
	<td class="line x" title="100:231	This method guarantees that we nd almost all transitive verb constructions cleanly; Carroll et al.(1999) report an accuracy of .85 for 923 DOs, Active: 'AGENT STRING AUX active-verb-element DETERMINER * POSTMOD' DOs, Passive: 'DETERMINER * AUX active-verb-element element' TVs, Active: 'AGENT STRING AUX * DETERMINER active-nounelement POSTMOD' TVs, Passive:'DET active-noun-element AUX * POSTMOD' Figure 4: Query patterns for retrieving direct objects (DOs) and transitive verbs (TVs) in the Hypothesize step." ></td>
	<td class="line x" title="102:231	newspaper articles for this relation." ></td>
	<td class="line x" title="103:231	Second, in order to obtain larger coverage and more current data we also experiment with Google Scholar3, an automatic web-based indexer of scienti c literature (mainly peer-reviewed papers, technical reports, books, pre-prints and abstracts)." ></td>
	<td class="line x" title="104:231	Google Scholar snippets are often incomplete fragments which cannot be parsed." ></td>
	<td class="line x" title="105:231	For practical reasons, we decided against processing the entire documents, and obtain an approximation to direct objects and transitive verbs with regular expressions over the result snippets in both active and passive voice (cf.Fig." ></td>
	<td class="line x" title="107:231	4), designed to be high-precision4." ></td>
	<td class="line x" title="108:231	The amount of data available from BNC and Google Scholar is not directly comparable: harvesting Google Scholar snippets for both active and passive constructions gives around 2000 sentences per seed (Google Scholar returns up to 1000 results per query), while the number of BNC sentences containing seed words in active and passive form varies from 11 ( formalism ) to 5467 ( develop ) with an average of 1361 sentences for the experimental seed pairs." ></td>
	<td class="line x" title="109:231	Ranking Having obtained our candidate sets (either from the scienti c subsection of the BNC or from Google Scholar), the members are ranked using BNC frequencies." ></td>
	<td class="line x" title="110:231	We investigate two ranking methodologies: frequency-based and contextbased." ></td>
	<td class="line x" title="111:231	Frequency-based ranking simply ranks each member of the candidate set by how many times it is retrieved together with the current active element." ></td>
	<td class="line x" title="112:231	Context-based ranking uses a similarity measure for computing the scores, giving a higher score to those words that share suf ciently similar contexts with the members of the reference set." ></td>
	<td class="line x" title="113:231	We consider similarity measures in a vector space de ned either by a xed window, by the sentence window, or by syntactic relationships." ></td>
	<td class="line x" title="114:231	The score assigned to each word in the candidate set is the sum of its semantic similarity values computed with respect to each member in the reference set." ></td>
	<td class="line x" title="115:231	3http://scholar.google.com 4The capitalised words in these patterns are replaced by actual words (e.g. AGENT STRING: We/I, DETERMINER: a/ an/our), and the extracted words (indicated by * ) are lemmatised." ></td>
	<td class="line x" title="116:231	Syntactic contexts, as opposed to window-based contexts, constrain the context of a word to only those words that are grammatically related to it." ></td>
	<td class="line x" title="117:231	We use verb-object relations in both active and passive voice constructions as did Pereira et al.(1993) and Lee (1999), among others." ></td>
	<td class="line oc" title="119:231	We use the cosine similarity measure for windowbased contexts and the following commonly used similarity measures for the syntactic vector space: Hindles (1990) measure, the weighted Lin measure (Wu and Zhou, 2003), the -Skew divergence measure (Lee, 1999), the Jensen-Shannon (JS) divergence measure (Lin, 1991), Jaccards coef cient (van Rijsbergen, 1979) and the Confusion probability (Essen and Steinbiss, 1992)." ></td>
	<td class="line x" title="120:231	The Jensen-Shannon measure JS (x1, x2) = summationtext yY summationtext x{x1,x2} parenleftbigg P (y|x) log parenleftbigg P(y|x) 1 2 (P(y|x1)+P(y|x2)) parenrightbiggparenrightbigg subsequently performed best for our task." ></td>
	<td class="line x" title="121:231	We compare the different ranking methodologies and data sets with respect to a manually-de ned gold standard list of 20 goal-type verbs and 20 nouns." ></td>
	<td class="line x" title="122:231	This list was manually assembled from Teufel (1999); WordNet synonyms and other plausible verbs and nouns found via Web searches on scienti c articles were added." ></td>
	<td class="line x" title="123:231	We ensured by searches on the ACL anthology that there is good evidence that the gold-standard words indeed occur in the right contexts, i.e. in goal statement sentences." ></td>
	<td class="line x" title="124:231	As we want to nd similarity metrics and data sources which result in accumulator lists with many of these gold members at high ranks, we need a measure that rewards exactly those lists." ></td>
	<td class="line x" title="125:231	We use non-interpolated Mean Average Precision (MAP), a standard measure for evaluating ranked information retrieval runs, which combines precision and recall and ranges from 0 to 15." ></td>
	<td class="line x" title="126:231	We use 8 pairs of 2-tuples as input (e.g. [introduce, study] & [approach, method]), randomly selected from the gold standard list." ></td>
	<td class="line x" title="127:231	MAP was cal5MAP = 1 N summationtextN j=1 APj = 1 N summationtextN j=1 1 M summationtextM i=1 P (gi) where P (gi) = nijrij if gi is retrieved and 0 otherwise, N is the number of seed combinations, M is the size of the golden list, gi is the ith member of the golden list and rij is its rank in the retrieved list of combination j while nij is the number of golden members found up to and including rank rij." ></td>
	<td class="line o" title="128:231	924 Ranking scheme BNC Google Scholar Frequency-based 0.123 0.446 Sentence-window 0.200 0.344 Fixedsize-window 0.184 0.342 Hindle 0.293 0.416 Weighted Lin 0.358 0.509 -Skew 0.361 0.486 Jensen-Shannon 0.404 0.550 Jaccards coef." ></td>
	<td class="line x" title="129:231	0.301 0.436 Confusion prob." ></td>
	<td class="line x" title="130:231	0.171 0.293 Figure 5: MAPs after the rst iteration culated over the verbs and nouns retrieved using our algorithm and averaged." ></td>
	<td class="line x" title="131:231	Fig." ></td>
	<td class="line x" title="132:231	5 summarises the MAP scores for the rst iteration, where Google Scholar signi cantly outperformed the BNC." ></td>
	<td class="line x" title="133:231	The best result for this iteration (MAP=.550) was achieved by combining Google Scholar and the Jensen-Shannon measure." ></td>
	<td class="line x" title="134:231	The algorithm stops to iterate when no more improvement can be obtained, in this case after 4 iterations, resulting in a nal MAP of .619." ></td>
	<td class="line x" title="135:231	Although -Skew outperforms the simpler measures in ranking nouns, its performance on verbs is worse than the performance of Weighted Lin." ></td>
	<td class="line x" title="136:231	While Lee (1999) argues that -Skews asymmetry can be advantageous for nouns, this probably does not hold for verbs: verb hierarchies have much shallower structure than noun hierarchies with most verbs concentrated on one level (Miller et al. , 1990)." ></td>
	<td class="line x" title="137:231	This would explain why JS, which is symmetric compared to the -Skew metric, performed better in our experiments." ></td>
	<td class="line x" title="138:231	In the evaluation presented here we therefore use Google Scholar data and the JS measure." ></td>
	<td class="line x" title="139:231	An additional improvement (MAP=.630) is achieved when we incorporate a lter based on the following hypothesis: goal-type verbs should be more likely to have their direct objects preceded by inde nite articles rather than de nite articles or possessive determiners (because a new method is introduced) whereas continuation-type verbs should prefer de nite articles with their direct objects (as an existing method is involved)." ></td>
	<td class="line x" title="140:231	3 Syntactic variants and semantic lters The syntactic variant extractor takes as its input the raw text and the lists of verbs and nouns generated by the lexical bootstrapper." ></td>
	<td class="line x" title="141:231	After RASPparsing the input text, all instances of the input verbs are located and, based on the grammatical relations output by RASP6, a set of relevant en6The grammatical relations used are nsubj, dobj, iobj, aux, argmod, detmod, ncmod and mod." ></td>
	<td class="line x" title="142:231	The agent of the verb (e.g. , We adopt." ></td>
	<td class="line x" title="143:231	adopted by the author ), the agents determiner and related adjectives." ></td>
	<td class="line x" title="144:231	The direct object of the verb, the objects determiner and adjectives, in addition to any post-modi ers (e.g. , . . ." ></td>
	<td class="line x" title="145:231	apply a method proposed by [1] . . ., . . ." ></td>
	<td class="line x" title="146:231	follow an approach of [1] . . ." ></td>
	<td class="line x" title="147:231	Auxiliaries of the verb (e.g. , In a similar manner, we may propose a . . ." ></td>
	<td class="line x" title="148:231	) Adverbial modi cation of the verb (e.g. , We have previously presented a . . ." ></td>
	<td class="line x" title="149:231	) Prepositional phrases related to the verb (e.g. , In this paper we present." ></td>
	<td class="line x" title="150:231	adopted from their work ) Figure 6: Grammatical relations considered tities and modi ers for each verb is constructed, grouped into ve categories (cf.Fig." ></td>
	<td class="line x" title="152:231	6)." ></td>
	<td class="line x" title="153:231	Next, semantic lters are applied to each of the potential candidates (represented by the extracted entities and modi ers), and a tness score is calculated." ></td>
	<td class="line x" title="154:231	These constraints encode semantic principles that will apply to all cue phrases of that rhetorical category." ></td>
	<td class="line x" title="155:231	Examples for constraints are: if work is referred to as being done in previous own work, it is probably not a goal statement; the work in a goal statement must be presented here or in the current paper (the concept of here-ness ); and the agents of a goal statement have to be the authors, not other people." ></td>
	<td class="line x" title="156:231	While these lters are manually de ned, they are modular, encode general principles, and can be combined to express a wide range of rhetorical contexts." ></td>
	<td class="line x" title="157:231	We veri ed that around 20 semantic constraints are enough to cover a large sets of different cue phrases (the 1700 cue phrases from Teufel (1999)), though not all of these are implemented yet." ></td>
	<td class="line x" title="158:231	A nice side-effect of our approach is the simple characterisation of a cue phrase (by a syntactic relationship, some seed words for each concept, and some general, reusable semantic constraints)." ></td>
	<td class="line x" title="159:231	This characterisation is more informative and speci c than string-based approaches, yet it has the potential for generalisation (useful if the cue phrases are ever manually assessed and put into a lexicon)." ></td>
	<td class="line x" title="160:231	Fig." ></td>
	<td class="line x" title="161:231	7 shows successful extraction examples from our corpus7, illustrating the dif culty of the task: the system correctly identi ed sentences with syntactically complex goal-type and continuation-type cue phrases, and correctly rejected deceptive variants8." ></td>
	<td class="line x" title="162:231	7Numbers after examples give CmpLg archive numbers, followed by sentence numbers according to our preprocessing." ></td>
	<td class="line x" title="163:231	8The seeds in this example were [analyse, present] & [architecture, method] (for goal) and [improve, adopt] & [model, method] (for continuation)." ></td>
	<td class="line x" title="164:231	925 Correctly found: Goal-type: What we aim in this paper is to propose a paradigm that enables partial/local generation through decompositions and reorganizations of tentative local structures." ></td>
	<td class="line x" title="165:231	(9411021, S-5) Continuation-type: In this paper we have discussed how the lexicographical concept of lexical functions, introduced by Melcuk to describe collocations, can be used as an interlingual device in the machine translation of such structures." ></td>
	<td class="line x" title="166:231	(9410009, S-126) Correctly rejected: Goal-type: Perhaps the method proposed by Pereira et al.(1993) is the most relevant in our context." ></td>
	<td class="line x" title="168:231	(9605014, S-76) Continuation-type: Neither Kamp nor Kehler extend their copying/ substitution mechanism to anything besides pronouns, as we have done." ></td>
	<td class="line x" title="169:231	(9502014, S-174) Figure 7: Sentences correctly processed by our system 4 Gold standard evaluation We evaluated the quality of the extracted phrases in two ways: by comparing our system output to gold standard annotation, and by human judgement of the quality of the returned sentences." ></td>
	<td class="line x" title="170:231	In both cases bootstrapping was done using the seed tuples [analyse, present] & [architecture, method]." ></td>
	<td class="line x" title="171:231	For the gold standard-evaluation, we ran our system on a test set of 121 scienti c articles drawn from the CmpLg corpus (Teufel, 1999) entirely different texts from the ones the system was trained on." ></td>
	<td class="line x" title="172:231	Documents were manually annotated by the second author for (possibly more than one) goal-type sentence; annotation of that type has been previously shown to be reliable at K=.71 (Teufel, 1999)." ></td>
	<td class="line x" title="173:231	Our evaluation recorded how often the systems highest-ranked candidate was indeed a goal-type sentence; as this is a precision-critical task, we do not measure recall here." ></td>
	<td class="line x" title="174:231	We compared our system against our reimplementation of Ravichandran and Hovys (2002) paraphrase learning." ></td>
	<td class="line x" title="175:231	The seed words were of the form {goal-verb, goal-noun}, and we submitted each of the 4 combinations of the seed pair to Google Scholar." ></td>
	<td class="line x" title="176:231	From the top 1000 documents for each query, we harvested 3965 sentences containing both the goal-verb and the goal-noun." ></td>
	<td class="line x" title="177:231	By considering all possible substrings, an extensive list of candidate patterns was assembled." ></td>
	<td class="line x" title="178:231	Patterns with single occurrences were discarded, leaving a list of 5580 patterns (examples in Fig." ></td>
	<td class="line x" title="179:231	8)." ></td>
	<td class="line x" title="180:231	In order to rank the patterns by precision, the goal-verbs were submitted as queries and the top 1000 documents were downloaded for each." ></td>
	<td class="line x" title="181:231	From these, we <verb> a <noun> for of a new <noun> to <verb> the In this section, we <verb> the <noun> of the <noun> <verb> in this paper is to <verb> the <noun> after Figure 8: Examples of patterns extracted using Ravichandran and Hovys (2002) method Method Correct sentences Our system with bootstrapping 88 (73%) Ravichandran and Hovy (2002) 58 (48%) Our system, no bootstrapping, WordNet 50 (41%) Our system, no bootstrapping, seeds only 37 (30%) Figure 9: Gold standard evaluation: results the precision of each pattern was calculated by dividing the number of strings matching the pattern instantiated with both the goal-verb and all WordNet synonyms of the goal-noun, by the number of strings matching the patterns instantiated with the goal-verb only." ></td>
	<td class="line x" title="182:231	An important point here is that while the tight semantic coupling between the question and answer terms in the original method accurately identi es all the positive and negative examples, we can only approximate this by using a sensible synonym set for the seed goal-nouns." ></td>
	<td class="line x" title="183:231	For each document in the test set, the sentence containing the pattern with the highest precision (if any) was extracted as the goal sentence." ></td>
	<td class="line x" title="184:231	We also compared our system to two baselines." ></td>
	<td class="line x" title="185:231	We replaced the lists obtained from the lexical bootstrapping module with a) just the seed pair and b) the seed pair and all the WordNet synonyms of the components of the seed pair9." ></td>
	<td class="line x" title="186:231	The results of these experiments are given in Fig." ></td>
	<td class="line x" title="187:231	9." ></td>
	<td class="line x" title="188:231	All differences are statistically signi cant with the 2 test at p=.01 (except those between Ravichandran/Hovy and our nonbootstrapping/WordNet system)." ></td>
	<td class="line x" title="189:231	Our bootstrapping system outperforms the Ravichandran and Hovy algorithm by 34%." ></td>
	<td class="line x" title="190:231	This is not surprising, because this algorithm was not designed to perform well in tasks where there is no clear negative context." ></td>
	<td class="line x" title="191:231	The results also show that bootstrapping outperforms a general thesaurus such as WordNet." ></td>
	<td class="line x" title="192:231	Out of the 33 articles where our systems favourite was not an annotated goal-type sentence, only 15 are due to bootstrapping errors (i.e. , to an incorrect ranking of the lexical variants), corre9Bootstrapping should in principle do better than a thesaurus, as some of our correctly identi ed variants are not true synonyms (e.g. , theory vs. method), and as noise through overgeneration of unrelated senses might occur unless automatic word sense diambiguation is performed." ></td>
	<td class="line x" title="193:231	926 System chose: but should have chosen: derive set compare model illustrate algorithm present formalisation discuss measures present variations describe modi cations propose measures accommodate material describe approach examine material present study Figure 10: Wrong bootstrapping decisions Ceiling System Baseline Exp. A 3.91 3.08 1.58 Exp.B 4.33 3.67 2.50 Figure 11: Extrinsic evaluation: judges scores sponding to a 88% accuracy of the bootstrapping module." ></td>
	<td class="line x" title="194:231	Examples from those 15 error cases are given in Fig." ></td>
	<td class="line x" title="195:231	10." ></td>
	<td class="line x" title="196:231	The other errors were due to the cue phrase not being a transitive verb direct object pattern (e.g. we show that, our goal is and we focus on), so the system could not have found anything (11 cases, or an 80% accuracy), ungrammatical English or syntactic construction too complex, resulting in a lack of RASP detection of the crucial grammatical relation (2) and failure of the semantic lter to catch non-goal contexts (5)." ></td>
	<td class="line x" title="197:231	5 Human evaluation We next perform two human experiments to indirectly evaluate the quality of the automatically generated cue phrase variants." ></td>
	<td class="line x" title="198:231	Given an abstract of an article and a sentence extracted from the article, judges are asked to assign a score ranging from 1 (low) to 5 (high) depending on how well the sentence expresses the goal of that article (Exp. A), or the continuation of previous work (Exp. B)." ></td>
	<td class="line x" title="199:231	Each experiment involves 24 articles drawn randomly from a subset of 80 articles in the CmpLg corpus that contain manual annotation for goaltype and continuation-type sentences." ></td>
	<td class="line x" title="200:231	The experiments use three external judges (graduate students in computational linguistics), and a Latin Square experimental design with three conditions: Baseline (see below), System-generated and Ceiling (extracted from the gold standard annotation used in Teufel (1999))." ></td>
	<td class="line x" title="201:231	Judges were not told how the sentences were generated, and no judge saw an item in more than one condition." ></td>
	<td class="line x" title="202:231	The baseline for Experiment A was a random selection of sentences with the highest TF*IDF scores, because goal-type sentences typically contain many content-words." ></td>
	<td class="line x" title="203:231	The baseline for experiment B (continuation-type) were randomly selected sentences containing citations, because they often co-occur with statements of continuation." ></td>
	<td class="line x" title="204:231	In both cases, the length of the baseline sentence was controlled for by the average lengths of the gold standard and the system-extracted sentences in the document." ></td>
	<td class="line x" title="205:231	Fig." ></td>
	<td class="line x" title="206:231	11 shows that judges gave an average score of 3.08 to system-extracted sentences in Exp. A, compared with a baseline of 1.58 and a ceiling of 3.9110; in Exp. B, the system scored 3.67, with a higher baseline of 2.50 and a ceiling of 4.33." ></td>
	<td class="line x" title="207:231	According to the Wilcoxon signed-ranks test at  = .01, the system is indistinguishable from the gold standard, but signi cantly different from the baseline, in both experiments." ></td>
	<td class="line x" title="208:231	Although this study is on a small scale, it indicates that humans judged sentences obtained with our method as almost equally characteristic of their rhetorical function as human-chosen sentences, and much better than non-trivial baselines." ></td>
	<td class="line x" title="209:231	6 Conclusion In this paper we have investigated the automatic acquisition of semixed cue phrases as a bootstrapping task which requires very little manual input for each cue phrase and yet generalises to a wide range of syntactic and lexical variants in running text." ></td>
	<td class="line x" title="210:231	Our system takes a few seeds of the type of cue phrase as input, and bootstraps lexical variants from a large corpus." ></td>
	<td class="line x" title="211:231	It lters out many semantically invalid contexts, and nds cue phrases in various syntactic variants." ></td>
	<td class="line x" title="212:231	The system achieved 80% precision of goal-type phrases of the targeted syntactic shape (88% if only the bootstrapping module is evaluated), and good quality ratings from human judges." ></td>
	<td class="line x" title="213:231	We found Google Scholar to perform better than BNC as source for nding hypotheses for lexical variants, which may be due to the larger amount of data available to Google Scholar." ></td>
	<td class="line x" title="214:231	This seems to outweigh the disadvantage of only being able to use POS patterns with Google Scholar, as opposed to robust parsing with the BNC." ></td>
	<td class="line x" title="215:231	In the experiments reported, we bootstrap only from one type of cue phrase (transitive verbs and direct objects)." ></td>
	<td class="line x" title="216:231	This type covers a large proportion of the cue phrases needed practically, but our algorithm should in principle work for any kind of semixed cue phrase, as long as they have two core concepts and a syntactic and semantic 10This score seems somewhat low, considering that these were the best sentences available as goal descriptions, according to the gold standard." ></td>
	<td class="line x" title="217:231	927 CUE PHRASE: (previous) methods fail (Subj Verb) VARIANTS SEED 1: methodology, approach, technique." ></td>
	<td class="line x" title="218:231	VARIANTS SEED 2: be cursed, be incapable of, be restricted to, be troubled, degrade, fall prey to, . . ." ></td>
	<td class="line x" title="219:231	CUE PHRASE: advantage over previous methods (NP PP postmod + adj noun premod.)" ></td>
	<td class="line x" title="220:231	VARIANTS SEED 1: bene t, breakthrough, edge, improvement, innovation, success, triumph." ></td>
	<td class="line x" title="221:231	VARIANTS SEED 2: available, better-known, cited, classic, common, conventional, current, customary, established, existing, extant,." ></td>
	<td class="line x" title="222:231	Figure 12: Cues with other syntactic relationships relation between them." ></td>
	<td class="line x" title="223:231	Examples for such other types of phrases are given in Fig." ></td>
	<td class="line x" title="224:231	12; the second cue phrase involves a complex syntactic relationship between the two seeds (or possibly it could be considered as a cue phrase with three seeds)." ></td>
	<td class="line x" title="225:231	We will next investigate if the positive results presented here can be maintained for other syntactic contexts and for cue phrases with more than two seeds." ></td>
	<td class="line x" title="226:231	The syntactic variant extractor could be enhanced in various ways, eg." ></td>
	<td class="line x" title="227:231	by resolving anaphora in cue phrases." ></td>
	<td class="line x" title="228:231	A more sophisticated model of syntactically weighted vector space (Pado and Lapata, 2003) may help improve the lexical acquisition phase." ></td>
	<td class="line x" title="229:231	Another line for future work is bootstrapping meaning across cue phrases within the same rhetorical class, e.g. to learn that we propose a method for X and we aim to do X are equivalent." ></td>
	<td class="line x" title="230:231	As some papers will contain both variants of the cue phrase, with very similar material (X) in the vicinity, they could be used as starting point for experiments to validate cue phrase equivalence." ></td>
	<td class="line x" title="231:231	7 Acknowledgements This work was funded by the EPSRC projects CITRAZ (GR/S27832/01, Rhetorical Citation Maps and Domain-independent Argumentative Zoning ) and SCIBORG (EP/C010035/1, Extracting the Science from Scienti c Publications )." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="W06-2904
Improved Large Margin Dependency Parsing Via Local Constraints And Laplacian Regularization
Wang, Qin Iris;Cherry, Colin;Lizotte, Dan;Schuurmans, Dale;"></td>
	<td class="line x" title="1:160	Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X), pages 2128, New York City, June 2006." ></td>
	<td class="line x" title="2:160	c2006 Association for Computational Linguistics Improved Large Margin Dependency Parsing via Local Constraints and Laplacian Regularization Qin Iris Wang Colin Cherry Dan Lizotte Dale Schuurmans Department of Computing Science University of Alberta a0 wqin,colinc,dlizotte,dale a1 @cs.ualberta.ca Abstract We present an improved approach for learning dependency parsers from treebank data." ></td>
	<td class="line x" title="3:160	Our technique is based on two ideas for improving large margin training in the context of dependency parsing." ></td>
	<td class="line x" title="4:160	First, we incorporate local constraints that enforce the correctness of each individual link, rather than just scoring the global parse tree." ></td>
	<td class="line x" title="5:160	Second, to cope with sparse data, we smooth the lexical parameters according to their underlying word similarities using Laplacian Regularization." ></td>
	<td class="line x" title="6:160	To demonstrate the bene ts of our approach, we consider the problem of parsing Chinese treebank data using only lexical features, that is, without part-of-speech tags or grammatical categories." ></td>
	<td class="line x" title="7:160	We achieve state of the art performance, improving upon current large margin approaches." ></td>
	<td class="line x" title="8:160	1 Introduction Over the past decade, there has been tremendous progress on learning parsing models from treebank data (Collins, 1997; Charniak, 2000; Wang et al. , 2005; McDonald et al. , 2005)." ></td>
	<td class="line x" title="9:160	Most of the early work in this area was based on postulating generative probability models of language that included parse structure (Collins, 1997)." ></td>
	<td class="line x" title="10:160	Learning in this context consisted of estimating the parameters of the model with simple likelihood based techniques, but incorporating various smoothing and back-off estimation tricks to cope with the sparse data problems (Collins, 1997; Bikel, 2004)." ></td>
	<td class="line x" title="11:160	Subsequent research began to focus more on conditional models of parse structure given the input sentence, which allowed discriminative training techniques such as maximum conditional likelihood (i.e. maximum entropy ) to be applied (Ratnaparkhi, 1999; Charniak, 2000)." ></td>
	<td class="line x" title="12:160	In fact, recently, effective conditional parsing models have been learned using relatively straightforward plug-in estimates, augmented with similarity based smoothing (Wang et al. , 2005)." ></td>
	<td class="line x" title="13:160	Currently, the work on conditional parsing models appears to have culminated in large margin training (Taskar et al. , 2003; Taskar et al. , 2004; Tsochantaridis et al. , 2004; McDonald et al. , 2005), which currently demonstrates the state of the art performance in English dependency parsing (McDonald et al. , 2005)." ></td>
	<td class="line x" title="14:160	Despite the realization that maximum margin training is closely related to maximum conditional likelihood for conditional models (McDonald et al. , 2005), a suf ciently uni ed view has not yet been achieved that permits the easy exchange of improvements between the probabilistic and nonprobabilistic approaches." ></td>
	<td class="line x" title="15:160	For example, smoothing methods have played a central role in probabilistic approaches (Collins, 1997; Wang et al. , 2005), and yet they are not being used in current large margin training algorithms." ></td>
	<td class="line x" title="16:160	However, as we demonstrate, not only can smoothing be applied in a large margin training framework, it leads to generalization improvements in much the same way as probabilistic approaches." ></td>
	<td class="line x" title="17:160	The second key observation we make is somewhat more subtle." ></td>
	<td class="line x" title="18:160	It turns out that probabilistic approaches pay closer attention to the individual errors made by each component of a parse, whereas the training error minimized in the large margin approach the structured margin loss (Taskar et al. , 2003; Tsochantaridis et al. , 2004; McDonald et al. , 2005) is a coarse measure that only assesses the total error of an entire parse rather than focusing on the error of any particular component." ></td>
	<td class="line x" title="19:160	21 funds Investors continue to pour cash into money Figure 1: A dependency tree In this paper, we make two contributions to the large margin approach to learning parsers from supervised data." ></td>
	<td class="line x" title="20:160	First, we show that smoothing based on lexical similarity is not only possible in the large margin framework, but more importantly, allows better generalization to new words not encountered during training." ></td>
	<td class="line x" title="21:160	Second, we show that the large margin training objective can be signi cantly re ned to assess the error of each component of a given parse, rather than just assess a global score." ></td>
	<td class="line x" title="22:160	We show that these two extensions together lead to greater training accuracy and better generalization to novel input sentences than current large margin methods." ></td>
	<td class="line x" title="23:160	To demonstrate the bene t of combining useful learning principles from both the probabilistic and large margin frameworks, we consider the problem of learning a dependency parser for Chinese." ></td>
	<td class="line x" title="24:160	This is an interesting test domain because Chinese does not have clearly de ned parts-of-speech, which makes lexical smoothing one of the most natural approaches to achieving reasonable results (Wang et al. , 2005)." ></td>
	<td class="line x" title="25:160	2 Lexicalized Dependency Parsing A dependency tree speci es which words in a sentence are directly related." ></td>
	<td class="line x" title="26:160	That is, the dependency structure of a sentence is a directed tree where the nodes are the words in the sentence and links represent the direct dependency relationships between the words; see Figure 1." ></td>
	<td class="line x" title="27:160	There has been a growing interest in dependency parsing in recent years." ></td>
	<td class="line x" title="28:160	(Fox, 2002) found that the dependency structures of a pair of translated sentences have a greater degree of cohesion than phrase structures." ></td>
	<td class="line x" title="29:160	(Cherry and Lin, 2003) exploited such cohesion between the dependency structures to improve the quality of word alignment of parallel sentences." ></td>
	<td class="line x" title="30:160	Dependency relations have also been found to be useful in information extraction (Culotta and Sorensen, 2004; Yangarber et al. , 2000)." ></td>
	<td class="line x" title="31:160	A key aspect of a dependency tree is that it does not necessarily report parts-of-speech or phrase labels." ></td>
	<td class="line x" title="32:160	Not requiring parts-of-speech is especially bene cial for languages such as Chinese, where parts-of-speech are not as clearly de ned as English." ></td>
	<td class="line x" title="33:160	In Chinese, clear indicators of a words partof-speech such as suf xes -ment, -ous or function words such as the, are largely absent." ></td>
	<td class="line x" title="34:160	One of our motivating goals is to develop an approach to learning dependency parsers that is strictly lexical." ></td>
	<td class="line x" title="35:160	Hence the parser can be trained with a treebank that only contains the dependency relationships, making annotation much easier." ></td>
	<td class="line x" title="36:160	Of course, training a parser with bare word-toword relationships presents a serious challenge due to data sparseness." ></td>
	<td class="line x" title="37:160	It was found in (Bikel, 2004) that Collins parser made use of bi-lexical statistics only 1.49% of the time." ></td>
	<td class="line x" title="38:160	The parser has to compute backoff probability using parts-of-speech in vast majority of the cases." ></td>
	<td class="line x" title="39:160	In fact, it was found in (Gildea, 2001) that the removal of bi-lexical statistics from a state of the art PCFG parser resulted in very little change in the output." ></td>
	<td class="line x" title="40:160	(Klein and Manning, 2003) presented an unlexicalized parser that eliminated all lexicalized parameters." ></td>
	<td class="line x" title="41:160	Its performance was close to the state of the art lexicalized parsers." ></td>
	<td class="line x" title="42:160	Nevertheless, in this paper we follow the recent work of (Wang et al. , 2005) and consider a completely lexicalized parser that uses no parts-ofspeech or grammatical categories of any kind." ></td>
	<td class="line x" title="43:160	Even though a part-of-speech lexicon has always been considered to be necessary in any natural language parser, (Wang et al. , 2005) showed that distributional word similarities from a large unannotated corpus can be used to supplant part-of-speech smoothing with word similarity smoothing, to still achieve state of the art dependency parsing accuracy for Chinese." ></td>
	<td class="line x" title="44:160	Before discussing our modi cations to large margin training for parsing in detail, we rst present the dependency parsing model we use." ></td>
	<td class="line x" title="45:160	We then give a brief overview of large margin training, and then present our two modi cations." ></td>
	<td class="line x" title="46:160	Subsequently, we present our experimental results on fully lexical dependency parsing for Chinese." ></td>
	<td class="line x" title="47:160	3 Dependency Parsing Model Given a sentence a2 a3 a4a6a5a8a7a10a9a12a11a13a11a13a11a13a9a14a5a16a15a18a17 we are interested in computing a directed dependency tree, 22 a19, over a2." ></td>
	<td class="line x" title="48:160	In particular, we assume that a directed dependency tree a19 consists of ordered pairs a4a6a5a16a20a22a21a23a5a25a24a26a17 of words in a2 such that each word appears in at least one pair and each word has in-degree at most one." ></td>
	<td class="line x" title="49:160	Dependency trees are usually assumed to be projective (no crossing arcs), which means that if there is an arc a4a6a5a27a20a25a21a28a5a25a24a29a17, then a5a16a20 is an ancestor of all the words between a5a30a20 and a5a25a24 . Let a31a32a4a33a2a34a17 denote the set of all the directed, projective trees that span a2 . Given an input sentence a2, we would like to be able to compute the best parse; that is, a projective tree, a19a36a35 a31a32a4a33a2a34a17, that obtains the highest score . In particular, we follow (Eisner, 1996; Eisner and Satta, 1999; McDonald et al. , 2005) and assume that the score of a complete spanning tree a19 for a given sentence, whether probabilistically motivated or not, can be decomposed as a sum of local scores for each link (a word pair)." ></td>
	<td class="line x" title="50:160	In which case, the parsing problem reduces to a19a38a37 a3a40a39a42a41a44a43a46a45a47a39a26a48 a49a51a50a42a52a54a53a56a55a58a57 a59 a53a61a60a63a62a6a64a65a60a67a66a44a57a68a50a29a49 sa4a6a5 a20 a21a69a5 a24 a17 (1) where the score sa4a6a5a27a20a70a21 a5a25a24a71a17 can depend on any measurable property of a5a30a20 and a5a25a24 within the tree a19 . This formulation is suf ciently general to capture most dependency parsing models, including probabilistic dependency models (Wang et al. , 2005; Eisner, 1996) as well as non-probabilistic models (McDonald et al. , 2005)." ></td>
	<td class="line x" title="51:160	For standard scoring functions, parsing requires an a72a58a4a6a73a75a74a12a17 dynamic programming algorithm to compute a projective tree that obtains the maximum score (Eisner and Satta, 1999; Wang et al. , 2005; McDonald et al. , 2005)." ></td>
	<td class="line x" title="52:160	For the purpose of learning, we decompose each link score into a weighted linear combination of features sa4a6a5 a20 a21a76a5 a24 a17a46a3 a77a54a78a75a79a80a4a6a5 a20 a21a36a5 a24 a17 (2) where a77 are the weight parameters to be estimated during training." ></td>
	<td class="line x" title="53:160	Of course, the speci c features used in any real situation are critical for obtaining a reasonable dependency parser." ></td>
	<td class="line x" title="54:160	The natural sets of features to consider in this setting are very large, consisting at the very least of features indexed by all possible lexical items (words)." ></td>
	<td class="line x" title="55:160	For example, natural features to use for dependency parsing are indicators of each possible word pair a81a26a82a29a83 a4a6a5a16a20a51a21a69a5a25a24a71a17a46a3 a84 a53a85a60a63a62a87a86 a82 a57 a84 a53a61a60a67a66a88a86 a83 a57 which allows one to represent the tendency of two words, a89 and a90, to be directly linked in a parse." ></td>
	<td class="line x" title="56:160	In this case, there is a corresponding parameter a91 a82a10a83 to be learned for each word pair, which represents the strength of the possible linkage." ></td>
	<td class="line x" title="57:160	A large number of features leads to a serious risk of overtting due to sparse data problems." ></td>
	<td class="line x" title="58:160	The standard mechanisms for mitigating such effects are to combine features via abstraction (e.g. using partsof-speech) or smoothing (e.g. using word similarity based smoothing)." ></td>
	<td class="line x" title="59:160	For abstraction, a common strategy is to use parts-of-speech to compress the feature set, for example by only considering the tag of the parent a81a93a92a12a83 a4a6a5a16a20a94a21a76a5a25a24a71a17a46a3 a84 a53posa53a61a60a63a62a95a57a87a86 a92 a57 a84 a53a85a60a67a66a96a86 a83 a57 However, rather than use abstraction, we will follow a purely lexical approach and only consider features that are directly computable from the words themselves (or statistical quantities that are directly measurable from these words)." ></td>
	<td class="line x" title="60:160	In general, the most important aspect of a link feature is simply that it measures something about a candidate word pair that is predictive of whether the words will actually be linked in a given sentence." ></td>
	<td class="line x" title="61:160	Thus, many other natural features, beyond parts-of-speech and abstract grammatical categories, immediately suggest themselves as being predictive of link existence." ></td>
	<td class="line x" title="62:160	For example, one very useful feature is simply the degree of association between the two words as measured by their pointwise mutual information a81 PMIa4a6a5a16a20a94a21a76a5a25a24a71a17a46a3 PMIa4a6a5a16a20a97a9a14a5a25a24a71a17 (We describe in Section 6 below how we compute this association measure on an auxiliary corpus of unannotated text)." ></td>
	<td class="line x" title="63:160	Another useful link feature is simply the distance between the two words in the sentence; that is, how many words they have between them a81 dista4a6a5a16a20a51a21a69a5a25a24a29a17a98a3 a99positiona4a6a5a27a20a100a17a102a101 positiona4a6a5a25a24a26a17a12a99 23 In fact, the likelihood of a direct link between two words diminishes quickly with distance, which motivates using more rapidly increasing functions of distance, such as the square a81 dist2a4a6a5a16a20a103a21a36a5a25a24a29a17a104a3a105a4 positiona4a6a5a27a20a68a17a106a101 positiona4a6a5a25a24a26a17a14a17a97a107 In our experiments below, we used only these simple, lexically determined features, a108 a81a109a82a10a83a42a110, a81 PMI, a81 dist and a81 dist2, without the parts-of-speech a108 a81a29a92a12a83a42a110 . Currently, we only use undirected forms of these features, where, for example, a81 a82a10a83 a3 a81 a83a44a82 for all pairs (or, put another way, we tie the parameters a91 a82a10a83 a3 a91 a83a44a82 together for all a89a75a9a14a90 )." ></td>
	<td class="line x" title="64:160	Ideally, we would like to use directed features, but we have already found that these simple undirected features permit state of the art accuracy in predicting (undirected) dependencies." ></td>
	<td class="line x" title="65:160	Nevertheless, extending our approach to directed features and contextual features, as in (Wang et al. , 2005), remains an important direction for future research." ></td>
	<td class="line x" title="66:160	4 Large Margin Training Given a training set of sentences annotated with their correct dependency parses, a4a33a2 a7 a9a19 a7 a17a96a9a12a11a13a11a13a11a13a9a29a4a33a2a112a111a104a9a19 a111a38a17, the goal of learning is to estimate the parameters of the parsing model, a77 . In particular, we seek values for the parameters that can accurately reconstruct the training parses, but more importantly, are also able to accurately predict the dependency parse structure on future test sentences." ></td>
	<td class="line x" title="67:160	To train a77 we follow the large margin training approach of (Taskar et al. , 2003; Tsochantaridis et al. , 2004), which has been applied with great success to dependency parsing (Taskar et al. , 2004; McDonald et al. , 2005)." ></td>
	<td class="line x" title="68:160	Large margin training can be expressed as minimizing a regularized loss (Hastie et al. , 2004) a45a58a113a115a114 a77 a116a117 a77 a78 a77 a118 (3) a59 a20 a45a47a39a26a48 a119a67a62a121a120 a4a123a122a25a20a124a9 a19 a20a100a17a102a101a125a4 sa4a68a77a75a9 a19 a20a100a17a126a101 sa4a68a77a75a9a44a122a25a20a100a17a14a17 where a19 a20 is the target tree for sentence a2 a20 ; a122 a20 ranges over all possible alternative trees in a31a32a4a33a2a127a20a33a17 ; sa4a68a77a102a9a19 a17a128a3 a129 a53a61a60a63a62a95a64a32a60a67a66a130a57a68a50a29a49 a77a54a78a102a79a67a4a6a5a16a20a105a21 a5a25a24a71a17 ; and a120 a4a123a122a25a20a124a9 a19 a20a100a17 is a measure of distance between the two trees a122a25a20 and a19 a20 . Using the techniques of (Hastie et al. , 2004) one can show that minimizing (4) is equivalent to solving the quadratic program a45a47a113a115a114 a131a71a132a133 a116a117 a77a54a78a102a77a134a118a98a135a136a78a75a137 subject to (4) a138 a20a102a139 a120 a4 a19 a20a97a9a44a122a140a20a100a17a103a118 sa4a68a77a75a9a44a122a25a20a68a17a126a101 sa4a68a77a102a9 a19 a20a33a17 for all a141a44a9a44a122a25a20 a35 a31a32a4a33a2a142a20a68a17 which corresponds to the training problem posed in (McDonald et al. , 2005)." ></td>
	<td class="line x" title="69:160	Unfortunately, the quadratic program (4) has three problems one must address." ></td>
	<td class="line x" title="70:160	First, there are exponentially many constraints corresponding to each possible parse of each training sentence which forces one to use alternative training procedures, such as incremental constraint generation, to slowly converge to a solution (McDonald et al. , 2005; Tsochantaridis et al. , 2004)." ></td>
	<td class="line x" title="71:160	Second, and related, the original loss (4) is only evaluated at the global parse tree level, and is not targeted at penalizing any speci c component in an incorrect parse." ></td>
	<td class="line x" title="72:160	Although (McDonald et al. , 2005) explicitly describes this as an advantage over previous approaches (Ratnaparkhi, 1999; Yamada and Matsumoto, 2003), below we nd that changing the loss to enforce a more detailed set of constraints leads to a more effective approach." ></td>
	<td class="line x" title="73:160	Third, given the large number of bi-lexical features a108 a81a42a82a10a83a143a110 in our model, solving (4) directly will overt any reasonable training corpus." ></td>
	<td class="line x" title="74:160	(Moreover, using a large a116 to shrink the a77 values does not mitigate the sparse data problem introduced by having so many features)." ></td>
	<td class="line x" title="75:160	We now present our re nements that address each of these issues in turn." ></td>
	<td class="line x" title="76:160	5 Training with Local Constraints We are initially focusing on training on just an undirected link model, where each parameter in the model is a weight a91 a60a144a60a146a145 between two words, a5 and a5a30a147, respectively." ></td>
	<td class="line x" title="77:160	Since links are undirected, these weights are symmetric a91 a60a146a60a144a145 a3a148a91 a60a146a145a149a60, and we can also write the score in an undirected fashion as: sa4a6a5a150a9a14a5 a147a17a151a3a152a77 a78 a79a67a4a6a5a150a9a14a5 a147a17 . The main advantage of working with the undirected link model is that the constraints needed to ensure correct parses on the training data are much easier to specify in this case." ></td>
	<td class="line x" title="78:160	Ignoring the projective (no crossing arcs) constraint for the moment, an undirected dependency parse can 24 be equated with a maximum score spanning tree of a sentence." ></td>
	<td class="line x" title="79:160	Given a target parse, the set of constraints needed to ensure the target parse is in fact the maximum score spanning tree under the weights a77, by at least a minimum amount, is a simple set of linear constraints: for any edge a5a150a7a44a5 a107 that is not in the target parse, one simply adds two constraints a77a146a78a102a79a80a4a6a5a65a7a10a9a14a5 a147 a7 a17a40a139 a77a54a78a102a79a67a4a6a5a65a7a10a9a14a5 a107 a17a103a118a153a84 a77a146a78a102a79a80a4a6a5 a107 a9a14a5 a147 a107 a17a40a139 a77a54a78a102a79a67a4a6a5 a7 a9a14a5 a107 a17a103a118a153a84 (5) where the edges a5a8a7a44a5 a147 a7 and a5 a107 a5 a147 a107 are the adjacent edges that actually occur in the target parse that are also on the path between a5a150a7 and a5 a107 ." ></td>
	<td class="line x" title="80:160	(These would have to be the only such edges, or there would be a loop in the parse tree)." ></td>
	<td class="line x" title="81:160	These constraints behave very naturally by forcing the weight of an omitted edge to be smaller than the adjacent included edges that would form a loop, which ensures that the omitted edge would not be added to the maximum score spanning tree before the included edges." ></td>
	<td class="line x" title="82:160	In this way, one can simply accumulate the set of linear constraints (5) for every edge that fails to be included in the target parse for the sentences where it is a candidate." ></td>
	<td class="line x" title="83:160	We denote this set of constraints by a154 a3 a108a26a77 a78 a79a80a4a6a5a65a7a12a9a14a5 a147a7 a17a155a139a125a77 a78 a79a67a4a6a5a65a7a10a9a14a5 a107 a17a51a118a153a84 a110 Importantly, the constraint seta154 is convex in the link weight parameters a77, as it consists only of linear constraints." ></td>
	<td class="line x" title="84:160	Ignoring the non-crossing condition, the constraint set a154 is exact." ></td>
	<td class="line x" title="85:160	However, because of the non-crossing condition, the constraint set a154 is more restrictive than necessary." ></td>
	<td class="line x" title="86:160	For example, consider the word sequence a11a13a11a13a11a156a5a30a20a123a5a16a20a115a157a75a7a44a5a16a20a13a157 a107 a5a16a20a115a157 a74 a11a13a11a13a11, where the edge a5a16a20a115a157a75a7a44a5a16a20a115a157 a74 is in the target parse." ></td>
	<td class="line x" title="87:160	Then the edge a5 a20a5 a20a13a157 a107 can be ruled out of the parse in one of two ways: it can be ruled out by making its score less than the adjacent scores as speci ed in (5), or it can be ruled out by making its score smaller than the score of a5a27a20a115a157a75a7a14a5a16a20a115a157 a74 . Thus, the exact constraint contains a disjunction of two different constraints, which creates a non-convex constraint in a77 ." ></td>
	<td class="line x" title="88:160	(The union of two convex sets is not necessarily convex.)" ></td>
	<td class="line x" title="89:160	This is a weakening of the original constraint set a154 . Unfortunately, this means that, given a large training corpus, the constraint set a154 can easily become infeasible." ></td>
	<td class="line x" title="90:160	Nevertheless, the constraints in a154 capture much of the relevant structure in the data, and are easy to enforce." ></td>
	<td class="line x" title="91:160	Therefore, we wish to maintain them." ></td>
	<td class="line x" title="92:160	However, rather than impose the constraints exactly, we enforce them approximately through the introduction of slack variables a137 . The relaxed constraints can then be expressed as a77 a78 a79a67a4a6a5a65a7a12a9a14a5 a147 a7 a17a97a139a25a77 a78 a79a67a4a6a5a65a7a10a9a14a5 a107 a17a103a118a153a84a30a101 a138 a60a103a158a68a60a144a159 a132a60a103a158a68a60 a145 a158 (6) and therefore a maximum soft margin solution can then be expressed as a quadratic program a45a47a113a115a114 a131a10a132a133 a116a117 a77 a78 a77a134a118a160a137 a78 a135 subject to (7) a108a71a77a54a78a102a79a67a4a6a5a65a7a10a9a14a5 a147 a7 a17a155a139a151a77a54a78a102a79a67a4a6a5a65a7a10a9a14a5 a107 a17a94a118a153a84a16a101 a138 a60a103a158a68a60a144a159 a132a60a103a158a68a60 a145 a158 a110 for all constraints in a154 where a135 denotes the vector of all 1s. Even though the slacks are required because we have slightly over-constrained the parameters, given that there are so many parameters and a sparse data problem as well, it seems desirable to impose a stronger set of constraints." ></td>
	<td class="line x" title="93:160	A set of solution parameters achieved in this way will allow maximum weight spanning trees to correctly parse nearly all of the training sentences, even without the noncrossing condition (see the results in Section 8)." ></td>
	<td class="line x" title="94:160	This quadratic program has the advantage of producing link parameters that will correctly parse most of the training data." ></td>
	<td class="line x" title="95:160	Unfortunately, the main drawback of this method thus far is that it does not offer any mechanism by which the link weights a91 a60a144a60 a145 can be generalized to new or rare words." ></td>
	<td class="line x" title="96:160	Given the sparse data problem, some form of generalization is necessary to achieve good test results." ></td>
	<td class="line x" title="97:160	We achieve this by exploiting distributional similarities between words to smooth the parameters." ></td>
	<td class="line x" title="98:160	6 Distributional Word Similarity Treebanks are an extremely precious resource." ></td>
	<td class="line x" title="99:160	The average cost of producing a treebank parse can run as high as 30 person-minutes per sentence (20 words on average)." ></td>
	<td class="line x" title="100:160	Similarity-based smoothing, on the other hand, allows one to tap into auxiliary sources of raw unannotated text, which is practically unlimited." ></td>
	<td class="line x" title="101:160	With this extra data, one can estimate parameters for words that have never appeared in the training corpus." ></td>
	<td class="line x" title="102:160	25 The basic intuition behind similarity smoothing is that words that tend to appear in the same contexts tend to have similar meanings." ></td>
	<td class="line x" title="103:160	This is known as the Distributional Hypothesis in linguistics (Harris, 1968)." ></td>
	<td class="line oc" title="104:160	For example, the words test and exam are similar because both of them can follow verbs such as administer, cancel, cheat on, conduct, etc. Many methods have been proposed to compute distributional similarity between words, e.g., (Hindle, 1990; Pereira et al. , 1993; Grefenstette, 1994; Lin, 1998)." ></td>
	<td class="line o" title="105:160	Almost all of the methods represent a word by a feature vector where each feature corresponds to a type of context in which the word appeared." ></td>
	<td class="line o" title="106:160	They differ in how the feature vectors are constructed and how the similarity between two feature vectors is computed." ></td>
	<td class="line x" title="107:160	In our approach below, we de ne the features of a word a5 to be the set of words that occurred within a small window of a5 in a large corpus." ></td>
	<td class="line x" title="108:160	The context window of a5 consists of the closest non-stopword on each side of a5 and the stop-words in between." ></td>
	<td class="line x" title="109:160	The value of a feature a5 a147 is de ned as the pointwise mutual information between the a5a8a147 and a5 : PMIa4a6a5a161a147a123a9a14a5a65a17a162a3a76a163a115a164a165a43a144a4a142a166 a53a61a60 a132a60 a145a57 a166 a53a61a60a103a57 a166 a53a85a60a144a145a56a57 a17 . The similarity between two words, a167a16a4a6a5a8a7a10a9a14a5 a107 a17, is then de ned as the cosine of the angle between their feature vectors." ></td>
	<td class="line x" title="110:160	We use this similarity information both in training and in parsing." ></td>
	<td class="line x" title="111:160	For training, we smooth the parameters according to their underlying word-pair similarities by introducing a Laplacian regularizer, which will be introduced in the next section." ></td>
	<td class="line x" title="112:160	For parsing, the link scores in (1) are smoothed by word similarities (similar to the approach used by (Wang et al. , 2005)) before the maximum score projective dependency tree is computed." ></td>
	<td class="line x" title="113:160	7 Laplacian Regularization We wish to incorporate similarity based smoothing in large margin training, while using the more rened constraints outlined in Section 5." ></td>
	<td class="line x" title="114:160	Recall that most of the features we use, and therefore most of the parameters we need to estimate are based on bi-lexical parameters a91 a60a144a60a146a145 that serve as undirected link weights between words a5 and a5a32a147 in our dependency parsing model (Section 3)." ></td>
	<td class="line x" title="115:160	Here we would like to ensure that two different link weights, a91 a60a103a158a68a60 a145 a158 and a91 a60a144a159a124a60 a145 a159, that involve similar words also take on similar values." ></td>
	<td class="line x" title="116:160	The previous optimization (7) needs to be modi ed to take this into account." ></td>
	<td class="line x" title="117:160	Smoothing the link parameters requires us to rst extend the notion of word similarity to word-pair similarities, since each link involves two words." ></td>
	<td class="line x" title="118:160	Given similarities between individual words, computed above, we then de ne the similarity between word pairs by the geometric mean of the similarities between corresponding words." ></td>
	<td class="line x" title="119:160	a167a16a4a6a5a65a7a44a5 a147 a7 a9a14a5 a107 a5 a147 a107 a17a168a3 a169 a167a16a4a6a5a65a7a10a9a14a5 a107 a17a14a167a16a4a6a5 a147 a7 a9a14a5 a147 a107 a17 (8) where a167a16a4a6a5a32a7a10a9a14a5 a107 a17 is de ned as in Section 6 above." ></td>
	<td class="line x" title="120:160	Then, instead of just solving the constraint system (7) we can also ensure that similar links take on similar parameter values by introducing a penalty on their deviations that is weighted by their similarity value." ></td>
	<td class="line x" title="121:160	Speci cally, we use a59 a60a103a158a68a60 a145 a158 a59 a60a144a159a124a60 a145 a159 a167a16a4a6a5a65a7a44a5 a147a7 a9a14a5 a107 a5 a147 a107 a17a93a4a123a91 a60 a158a60 a145 a158 a101a170a91 a60 a159a60 a145 a159 a17a107 a3 a117 a77 a147a78 a122a38a4a33a167a140a17a171a77 a147 (9) Here a122a161a4a33a167a140a17 is the Laplacian matrix of a167, which is de ned by a122a161a4a33a167a25a17a172a3 a173a174a4a33a167a140a17a47a101a175a167 where a173a174a4a33a167a140a17 is a diagonal matrix such that a173 a60a51a158a123a60 a145a158a132a60a103a158a68a60 a145a158 a3 a129 a60a144a159a124a60 a145 a159 a167a27a4a6a5a65a7a44a5a30a147 a7 a9a14a5 a107 a5a30a147 a107 a17 . Also, a77 a147 corresponds to the vector of bi-lexical parameters." ></td>
	<td class="line x" title="122:160	In this penalty function, if two edges a5 a7 a5 a147 a7 and a5 a107 a5 a147 a107 have a high similarity value, their parameters will be encouraged to take on similar values." ></td>
	<td class="line x" title="123:160	By contrast, if two edges have low similarity, then there will be little mutual attraction on their parameter values." ></td>
	<td class="line x" title="124:160	Note, however, that we do not smooth the parameters, a91 PMI, a91 dist, a91 dist2, corresponding to the pointwise mutual information, distance, and squared distance features described in Section 5, respectively." ></td>
	<td class="line x" title="125:160	We only apply similarity smoothing to the bi-lexical parameters." ></td>
	<td class="line x" title="126:160	The Laplacian regularizer (9) provides a natural smoother for the bi-lexical parameter estimates that takes into account valuable word similarity information computed as above." ></td>
	<td class="line x" title="127:160	The Laplacian regularizer also has a signi cant computational advantage: it is guaranteed to be a convex quadratic function of the parameters (Zhu et al. , 2001)." ></td>
	<td class="line x" title="128:160	Therefore, by combining the constraint system (7) with the Laplacian smoother (9), we can obtain a convex optimization 26 Table 1: Accuracy Results on CTB Test Set Features used Trained w/ Trained w/ local loss global loss Pairs 0.6426 0.6184 + Lap 0.6506 0.5622 + Dist 0.6546 0.6466 + Lap + Dist 0.6586 0.5542 + MI + Dist 0.6707 0.6546 + Lap + MI + Dist 0.6827 n/a Table 2: Accuracy Results on CTB Dev Set Features used Trained w/ Trained w/ local loss global loss Pairs 0.6130 0.5688 + Lap 0.6390 0.4935 + Dist 0.6364 0.6130 + Lap + Dist 0.6494 0.5299 + MI + Dist 0.6312 0.6182 + Lap + MI + Dist 0.6571 n/a procedure for estimating the link parameters a45a47a113a115a114 a131a71a132a133 a116a117 a77 a78a150a176a122a38a4a33a167a140a17a171a77a134a118a177a137 a78 a135 subject to (10) a108a26a77 a78 a79a67a4a6a5a65a7a10a9a14a5 a147a7 a17a155a139a178a77 a78 a79a80a4a6a5a65a7a10a9a14a5 a107 a17a103a118a153a84a27a101 a138 a60a103a158a68a60a144a159 a132a60a103a158a68a60 a145 a158 a110 for all constraints in a154 where a176a122a161a4a33a167a140a17 does not apply smoothing to a91 PMI, a91 dist, a91 dist2." ></td>
	<td class="line x" title="129:160	Clearly, (10) describes a large margin training program for dependency parsing, but one which uses word similarity smoothing for the bi-lexical parameters, and a more re ned set of constraints developed in Section 5." ></td>
	<td class="line x" title="130:160	Although the constraints are more re ned, they are fewer in number than (4)." ></td>
	<td class="line x" title="131:160	That is, we now only have a polynomial number of constraints corresponding to each word pair in (5), rather than the exponential number over every possible parse tree in (4)." ></td>
	<td class="line x" title="132:160	Thus, we obtain a polynomial size quadratic program that can be solved for moderately large problems using standard software packages." ></td>
	<td class="line x" title="133:160	We used CPLEX in our experiments below." ></td>
	<td class="line x" title="134:160	As before, once optimized, the solution parameters a77 can be introduced into the dependency model (1) according to (2)." ></td>
	<td class="line x" title="135:160	8 Experimental Results We tested our method experimentally on the Chinese Treebank (CTB) (Xue et al. , 2004)." ></td>
	<td class="line x" title="136:160	The parse trees Table 3: Accuracy Results on CTB Training Set Features used Trained w/ Trained w/ local loss global loss Pairs 0.9802 0.8393 + Lap 0.9777 0.7216 + Dist 0.9755 0.8376 + Lap + Dist 0.9747 0.7216 + MI + Dist 0.9768 0.7985 + Lap + MI + Dist 0.9738 n/a in CTB are constituency structures." ></td>
	<td class="line x" title="137:160	We converted them into dependency trees using the same method and headnding rules as in (Bikel, 2004)." ></td>
	<td class="line x" title="138:160	Following (Bikel, 2004), we used Sections 1-270 for training, Sections 271-300 for testing and Sections 301325 for development." ></td>
	<td class="line x" title="139:160	We experimented with two sets of data: CTB-10 and CTB-15, which contains sentences with no more than 10 and 15 words respectively." ></td>
	<td class="line x" title="140:160	Table 1, Table 2 and Table 3 show our experimental results trained and evaluated on Chinese Treebank sentences of length no more than 10, using the standard split." ></td>
	<td class="line x" title="141:160	For any unseen link in the new sentences, the weight is computed as the similarity weighted average of similar links seen in the training corpus." ></td>
	<td class="line x" title="142:160	The regularization parameter a116 was set by 5-fold cross-validation on the training set." ></td>
	<td class="line x" title="143:160	We evaluate parsing accuracy by comparing the undirected dependency links in the parser outputs against the undirected links in the treebank." ></td>
	<td class="line x" title="144:160	We dene the accuracy of the parser to be the percentage of correct dependency links among the total set of dependency links created by the parser." ></td>
	<td class="line x" title="145:160	Table 1 and Table 2 show that training based on the more re ned local loss is far superior to training with the global loss of standard large margin training, on both the test and development sets." ></td>
	<td class="line x" title="146:160	Parsing accuracy also appears to increase with the introduction of each new feature." ></td>
	<td class="line x" title="147:160	Notably, the pointwise mutual information and distance features signi cantly improve parsing accuracy and yet we know of no other research that has investigated these features in this context." ></td>
	<td class="line x" title="148:160	Finally, we note that Laplacian regularization improved performance as expected, but not for the global loss, where it appears to systematically degrade performance (n/a results did not complete in time)." ></td>
	<td class="line x" title="149:160	It seems that the global loss model may have been over-regularized (Table 3)." ></td>
	<td class="line x" title="150:160	However, we have picked the a116 parameter which gave us the 27 best resutls in our experiments." ></td>
	<td class="line x" title="151:160	One possible explanation for this phenomenon is that the interaction between the Laplician regularization in training and the similarity smoothing in parsing, since distributional word similarities are used in both cases." ></td>
	<td class="line x" title="152:160	Finally, we compared our results to the probabilistic parsing approach of (Wang et al. , 2005), which on this data obtained accuracies of 0.7631 on the CTB test set and 0.6104 on the development set." ></td>
	<td class="line x" title="153:160	However, we are using a much simpler feature set here." ></td>
	<td class="line x" title="154:160	9 Conclusion We have presented two improvements to the standard large margin training approach for dependency parsing." ></td>
	<td class="line x" title="155:160	To cope with the sparse data problem, we smooth the parameters according to their underlying word similarities by introducing a Laplacian regularizer." ></td>
	<td class="line x" title="156:160	More signi cantly, we use more re ned local constraints in the large margin criterion, rather than the global parse-level losses that are commonly considered." ></td>
	<td class="line x" title="157:160	We achieve state of the art parsing accuracy for predicting undirected dependencies in test data, competitive with previous large margin and previous probabilistic approaches in our experiments." ></td>
	<td class="line x" title="158:160	Much work remains to be done." ></td>
	<td class="line x" title="159:160	One extension is to consider directed features, and contextual features like those used in current probabilistic parsers (Wang et al. , 2005)." ></td>
	<td class="line x" title="160:160	We would also like to apply our approach to parsing English, investigate the confusion showed in Table 3 more carefully, and possibly re-investigate the use of parts-of-speech features in this context." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N07-1016
Unsupervised Resolution of Objects and Relations on the Web
Yates, Alexander;Etzioni, Oren;"></td>
	<td class="line x" title="1:262	Proceedings of NAACL HLT 2007, pages 121130, Rochester, NY, April 2007." ></td>
	<td class="line x" title="2:262	c2007 Association for Computational Linguistics Unsupervised Resolution of Objects and Relations on the Web Alexander Yates Turing Center Computer Science and Engineering University of Washington Box 352350 Seattle, WA 98195, USA ayates@cs.washington.edu Oren Etzioni Turing Center Computer Science and Engineering University of Washington Box 352350 Seattle, WA 98195, USA etzioni@cs.washington.edu Abstract The task of identifying synonymous relations and objects, or Synonym Resolution (SR), is critical for high-quality information extraction." ></td>
	<td class="line x" title="3:262	The bulk of previous SR work assumed strong domain knowledge or hand-tagged training examples." ></td>
	<td class="line x" title="4:262	This paper investigates SR in the context of unsupervised information extraction, where neither is available." ></td>
	<td class="line x" title="5:262	The paper presents a scalable, fully-implemented system for SR that runs in O(KN log N) time in the number of extractions N and the maximum number of synonyms per word, K. The system, called RESOLVER, introduces a probabilistic relational model for predicting whether two strings are co-referential based on the similarity of the assertions containing them." ></td>
	<td class="line x" title="6:262	Given two million assertions extracted from the Web, RESOLVER resolves objects with 78% precision and an estimated 68% recall and resolves relations with 90% precision and 35% recall." ></td>
	<td class="line x" title="7:262	1 Introduction Web Information Extraction (WIE) systems extract assertions that describe a relation and its arguments from Web text (e.g. , (is capital of,D.C. ,United States))." ></td>
	<td class="line x" title="8:262	WIE systems can extract hundreds of millions of assertions containing millions of different strings from the Web (e.g. , the TEXTRUNNER system (Banko et al. , 2007)).1 WIE systems often extract assertions that describe the same real-world object or relation using different names." ></td>
	<td class="line x" title="9:262	For example, a WIE system might extract (is capital city of,Washington,U.S.), which describes the same relationship as above but contains a different name for the relation and each argument." ></td>
	<td class="line x" title="10:262	Synonyms are prevalent in text, and the Web corpus is no exception." ></td>
	<td class="line x" title="11:262	Our data set of two million assertions extracted from a Web crawl contained over a half-dozen different names each for the United States and Washington, D.C., and three for the is capital of relation." ></td>
	<td class="line x" title="12:262	The top 80 most commonly extracted objects had an average of 2.9 extracted names per entity, and several had as many as 10 names." ></td>
	<td class="line x" title="13:262	The top 100 most commonly extracted relations had an average of 4.9 synonyms per relation." ></td>
	<td class="line x" title="14:262	We refer to the problem of identifying synonymous object and relation names as Synonym Resolution (SR).2 An SR system for WIE takes a set of assertions as input and returns a set of clusters, with each cluster containing coreferential object strings or relation strings." ></td>
	<td class="line x" title="15:262	Previous techniques for SR have focused on one particular aspect of the problem, either objects or relations." ></td>
	<td class="line x" title="16:262	In addition, the techniques either depend on a large set of training examples, or are tailored to a specific domain by assuming knowledge of the domains schema." ></td>
	<td class="line x" title="17:262	Due to the number and diversity of the relations extracted, these tech1For a demo see www.cs.washington.edu/research/textrunner." ></td>
	<td class="line x" title="18:262	2Ironically, SR has a number of synonyms in the literature, including Entity Resolution, Record Linkage, and Deduplication." ></td>
	<td class="line x" title="19:262	121 niques are not feasible for WIE systems." ></td>
	<td class="line x" title="20:262	Schemata are not available for the Web, and hand-labeling training examples for each relation would require a prohibitive manual effort." ></td>
	<td class="line x" title="21:262	In response, we present RESOLVER, a novel, domain-independent, unsupervised synonym resolution system that applies to both objects and relations." ></td>
	<td class="line x" title="22:262	RESOLVER clusters coreferential names together using a probabilistic model informed by string similarity and the similarity of the assertions containing the names." ></td>
	<td class="line x" title="23:262	Our contributions are: 1." ></td>
	<td class="line x" title="24:262	A scalable clustering algorithm that runs in time O(KN log N) in the number of extractions N and maximum number of synonyms per word, K, without discarding any potentially matching pair, under exceptionally weak assumptions about the data." ></td>
	<td class="line x" title="25:262	2." ></td>
	<td class="line x" title="26:262	An unsupervised probabilistic model for predicting whether two object or relation names co-refer." ></td>
	<td class="line x" title="27:262	3." ></td>
	<td class="line x" title="28:262	An empirical demonstration that RESOLVER can resolve objects with 78% precision and 68% recall, and relations with 90% precision and 35% recall." ></td>
	<td class="line x" title="29:262	The next section discusses previous work." ></td>
	<td class="line x" title="30:262	Section 3 introduces our probabilistic model for SR. Section 4 describes our clustering algorithm." ></td>
	<td class="line x" title="31:262	Section 5 describes extensions to our basic SR system." ></td>
	<td class="line x" title="32:262	Section 6 presents our experiments, and section 7 discusses our conclusions and areas for future work." ></td>
	<td class="line x" title="33:262	2 Previous Work The DIRT algorithm (Lin and Pantel, 2001) addresses a piece of the unsupervised SR problem." ></td>
	<td class="line x" title="34:262	DIRT is a heuristic method for finding synonymous relations, or inference rules. DIRT uses a dependency parser and mutual information statistics over a corpus to identify relations that have similar sets of arguments." ></td>
	<td class="line x" title="35:262	In contrast, our algorithm provides a formal probabilistic model that applies equally well to relations and objects, and we provide an evaluation of the algorithm in terms of precision and recall." ></td>
	<td class="line x" title="36:262	There are many unsupervised approaches for object resolution in databases, but unlike our algorithm these approaches depend on a known, fixed schema." ></td>
	<td class="line x" title="37:262	Ravikumar and Cohen (Ravikumar and Cohen, 2004) present an unsupervised approach to object resolution using Expectation-Maximization on a hierarchical graphical model." ></td>
	<td class="line x" title="38:262	Several other recent approaches leverage domain-specific information and heuristics for object resolution." ></td>
	<td class="line x" title="39:262	For example, many (Dong et al. , 2005; Bhattacharya and Getoor, 2005; Bhattacharya and Getoor, 2006) rely on evidence from observing which strings appear as arguments to the same relation simultaneously (e.g. , co-authors of the same publication)." ></td>
	<td class="line x" title="40:262	While this is useful information when resolving authors in the citation domain, it is extremely rare to find relations with similar properties in extracted assertions." ></td>
	<td class="line x" title="41:262	None of these approaches applies to the problem of resolving relations." ></td>
	<td class="line x" title="42:262	See (Winkler, 1999) for a survey of this area." ></td>
	<td class="line x" title="43:262	Several supervised learning techniques make entity resolution decisions (Kehler, 1997; McCallum and Wellner, 2004; Singla and Domingos, 2006), but of course these systems depend on the availability of training data, and often on a significant number of labeled examples per relation of interest." ></td>
	<td class="line x" title="44:262	These approaches also depend on complex probabilistic models and learning algorithms, and they have order O(n3) time complexity, or worse." ></td>
	<td class="line x" title="45:262	They currently do not scale to the amounts of data extracted from the Web." ></td>
	<td class="line x" title="46:262	Previous systems were tested on at most a few thousand examples, compared with millions or hundreds of millions of extractions from WIE systems such as TEXTRUNNER." ></td>
	<td class="line x" title="47:262	Coreference resolution systems (e.g. , (Lappin and Leass, 1994; Ng and Cardie, 2002)), like SR systems, try to merge references to the same object (typically pronouns, but potentially other types of noun phrases)." ></td>
	<td class="line x" title="48:262	This problem differs from the SR problem in several ways: first, it deals with unstructered text input, possibly with syntactic annotation, rather than relational input." ></td>
	<td class="line x" title="49:262	Second, it deals only with resolving objects." ></td>
	<td class="line x" title="50:262	Finally, it requires local decisions about strings; that is, the same word may appear twice in a text and refer to two different things, so each occurrence of a word must be treated separately." ></td>
	<td class="line x" title="51:262	The PASCAL Recognising Textual Entailment Challenge proposes the task of recognizing when two sentences entail one another, and many authors have submitted responses to this challenge (Dagan et al. , 2006)." ></td>
	<td class="line x" title="52:262	Synonym resolution is a subtask of this problem." ></td>
	<td class="line x" title="53:262	Our task differs significantly from the textual entailment task in that it has no labeled training 122 data, and its input is in the form of relational extractions rather than raw text." ></td>
	<td class="line x" title="54:262	Two probabilistic models for information extraction have a connection with ours." ></td>
	<td class="line x" title="55:262	Our probabilistic model is partly inspired by the ball-and-urns abstraction of information extraction presented by Downey et al.(2005) Our task and probability model are different from theirs, but we make many of the same modeling assumptions." ></td>
	<td class="line x" title="57:262	Second, we follow Snow et al.s work (2006) on taxonomy induction in incorporating transitive closure constraints in our probability calculations, as explained below." ></td>
	<td class="line x" title="58:262	3 Probabilistic Model Our probabilistic model provides a formal, rigorous method for resolving synonyms in the absence of training data." ></td>
	<td class="line x" title="59:262	It has two sources of evidence: the similarity of the strings themselves (i.e. , edit distance) and the similarity of the assertions they appear in." ></td>
	<td class="line oc" title="60:262	This second source of evidence is sometimes referred to as distributional similarity (Hindle, 1990)." ></td>
	<td class="line x" title="61:262	Section 3.2 presents a simple model for predicting whether a pair of strings co-refer based on string similarity." ></td>
	<td class="line x" title="62:262	Section 3.3 then presents a model called the Extracted Shared Property (ESP) Model for predicting whether a pair of strings co-refer based on their distributional similarity." ></td>
	<td class="line x" title="63:262	Finally, a method is presented for combining these models to come up with an overall prediction for coreference decisions between two clusters of strings." ></td>
	<td class="line x" title="64:262	3.1 Terminology and Notation We use the following notation to describe the probabilistic models." ></td>
	<td class="line x" title="65:262	The input is a data set D containing extracted assertions of the form a = (r,o1,,on), where r is a relation string and each oi is an object string representing the arguments to the relation." ></td>
	<td class="line x" title="66:262	In our data, all of the extracted assertions are binary, so n = 2." ></td>
	<td class="line x" title="67:262	The subset of all assertions in D containing a string s is called Ds." ></td>
	<td class="line x" title="68:262	For strings si and sj, let Ri,j be the random variable for the event that si and sj refer to the same entity." ></td>
	<td class="line x" title="69:262	Let Rti,j denote the event that Ri,j is true, and Rfi,j denote the event that it is false." ></td>
	<td class="line x" title="70:262	A pair of strings (r,s2) is called a property of a string s1 if there is an assertion (r,s1,s2)  D or (r,s2,s1)  D. A pair of strings (s1,s2) is an instance of a string r if there is an assertion (r,s1,s2)  D. Equivalently, the property p = (r,s2) applies to s1, and the relation r applies to the instance i = (s1,s2)." ></td>
	<td class="line x" title="71:262	Finally, two strings x and y share a property (or instance) if both x and y are extracted with the same property (or instance)." ></td>
	<td class="line x" title="72:262	3.2 String Similarity Model Many objects appear with multiple names that are substrings, acronyms, abbreviations, or other simple variations of one another." ></td>
	<td class="line x" title="73:262	Thus string similarity can be an important source of evidence for whether two strings co-refer." ></td>
	<td class="line x" title="74:262	Our probabilistic String Similarity Model (SSM) assumes a similarity function sim(s1,s2): STRINGSTRING  [0,1]." ></td>
	<td class="line x" title="75:262	The model sets the probability of s1 co-referring with s2 to a smoothed version of the similarity: P(Rti,j|sim(s1,s2)) = sim(s1,s2)+1+ The particular choice of  and  make little difference to our results, so long as they are chosen such that the resulting probability can never be one or zero." ></td>
	<td class="line x" title="76:262	In our experiments  = 20 and  = 5, and we use the well-known Monge-Elkan string similarity function for objects and the Levenshtein string editdistance function for relations (Cohen et al. , 2003)." ></td>
	<td class="line x" title="77:262	3.3 The Extracted Shared Property Model The Extracted Shared Property (ESP) Model outputs the probability that s1 and s2 co-refer based on how many properties (or instances) they share." ></td>
	<td class="line x" title="78:262	As an example, consider the strings Mars and Red Planet, which appear in our data 659 and 26 times respectively." ></td>
	<td class="line x" title="79:262	Out of these extracted assertions, they share four properties." ></td>
	<td class="line x" title="80:262	For example, (lacks,Mars,ozone layer) and (lacks,Red Planet,ozone layer) both appear as assertions in our data." ></td>
	<td class="line x" title="81:262	The ESP model determines the probability that Mars and Red Planet refer to the same entity after observing k, the number of properties that apply to both, n1, the total number of extracted properties for Mars, and n2, the total number of extracted properties for Red Planet. ESP models the extraction of assertions as a generative process, much like the URNS model (Downey et al. , 2005)." ></td>
	<td class="line x" title="82:262	For each string si, a certain 123 number, Pi, of properties of the string are written on balls and placed in an urn." ></td>
	<td class="line x" title="83:262	Extracting ni assertions that contain si amounts to selecting a subset of size ni from these labeled balls.3 Properties in the urn are called potential properties to distinguish them from extracted properties." ></td>
	<td class="line x" title="84:262	To model coreference decisions, ESP uses a pair of urns, containing Pi and Pj balls respectively, for the two strings si and sj." ></td>
	<td class="line x" title="85:262	Some subset of the Pi balls have the exact same labels as an equal-sized subset of the Pj balls." ></td>
	<td class="line x" title="86:262	Let the size of this subset be Si,j. The ESP model assumes that coreferential strings share as many potential properties as possible, though only a few of the potential properties will be extracted for both." ></td>
	<td class="line x" title="87:262	For non-coreferential strings, the number of shared potential properties is a strict subset of the potential properties of each string." ></td>
	<td class="line x" title="88:262	Thus if Ri,j is true then Si,j = min(Pi,Pj), and if Ri,j is false then Si,j < min(Pi,Pj)." ></td>
	<td class="line x" title="89:262	The ESP model makes several simplifying assumptions in order to make probability predictions." ></td>
	<td class="line x" title="90:262	As is suggested by the ball-and-urn abstraction, it assumes that each ball for a string is equally likely to be selected from its urn." ></td>
	<td class="line x" title="91:262	Because of data sparsity, almost all properties are very rare, so it would be difficult to get a better estimate for the prior probability of selecting a particular potential property." ></td>
	<td class="line x" title="92:262	Second, it assumes that without knowing the value of k, every value of Si,j is equally likely, since we have no better information." ></td>
	<td class="line x" title="93:262	Finally, it assumes that all subsets of potential properties are equally likely to be shared by two non-coreferential objects, regardless of the particular labels on the balls, given the size of the shared subset." ></td>
	<td class="line x" title="94:262	Given these assumptions, we can derive an expression for P(Rti,j)." ></td>
	<td class="line x" title="95:262	First, note that there areparenleftbig Pi ni parenrightbigparenleftbigPj nj parenrightbig total ways of extracting n i and nj assertions for si and sj." ></td>
	<td class="line x" title="96:262	Given a particular value of Si,j, the number of ways in which ni and nj assertions can be extracted such that they share exactly k is given by Count(k,ni,nj|Pi,Pj,Si,j) = parenleftbigSi,j k parenrightbigsummationtext r,s0 parenleftbigSi,jk r+s parenrightbigparenleftbigr+s r parenrightbigparenleftbig PiSi,j ni(k+r) parenrightbigparenleftbig PjSi,j nj(k+s) parenrightbig By our assumptions, 3Unlike the URNS model, balls are drawn without replacement because each extracted property is distinct in our data." ></td>
	<td class="line x" title="97:262	P(k|ni,nj,Pi,Pj,Si,j) = Count(k,ni,nj|Pi,Pj,Si,j)parenleftbig Pi ni parenrightbigparenleftbigPj nj parenrightbig (1) Let Pmin = min(Pi,Pj)." ></td>
	<td class="line x" title="98:262	The result below follows from Bayes Rule and our assumptions above: Proposition 1 If two strings si and sj have Pi and Pj potential properties (or instances), and they appear in extracted assertions Di and Dj such that |Di| = ni and|Dj| = nj, and they share k extracted properties (or instances), the probability that si and sj co-refer is: P(Rti,j|Di,Dj,Pi,Pj) = P(k|ni,nj,Pi,Pj,Si,j = Pmin)summationtext kSi,jPmin P(k|ni,nj,Pi,Pj,Si,j) (2) Substituting equation 1 into equation 2 gives us a complete expression for the probability we are looking for." ></td>
	<td class="line x" title="99:262	Note that the probability for Ri,j depends on just two hidden parameters, Pi and Pj." ></td>
	<td class="line x" title="100:262	Since we have no labeled data to estimate these parameters from, we tie these parameters to the number of times the respective strings si and sj are extracted." ></td>
	<td class="line x" title="101:262	Thus we set Pi = N ni, and we set N = 50 in our experiments." ></td>
	<td class="line x" title="102:262	3.4 Combining the Evidence For each potential coreference relationship Ri,j, there are now two pieces of probabilistic evidence." ></td>
	<td class="line x" title="103:262	Let Eei,j be the evidence for ESP, and let Esi,j be the evidence for SSM." ></td>
	<td class="line x" title="104:262	Our method for combining the two uses the Nave Bayes assumption that each piece of evidence is conditionally independent, given the coreference relation: P(Esi,j,Eei,j|Ri,j) = P(Esi,j|Ri,j)P(Eei,j|Ri,j) Given this simplifying assumption, we can combine the evidence to find the probability of a coference relationship by applying Bayes Rule to both sides (we omit the i,j indices for brevity): P(Rt|Es,Ee) = P(Rt|Es)P(Rt|Ee)(1P(Rt))summationtext i{t,f}P(Ri|Es)P(Ri|Ee)(1P(Ri)) 124 3.5 Comparing Clusters of Strings Our algorithm merges clusters of strings with one another, using one of the above models." ></td>
	<td class="line x" title="105:262	However, these models give probabilities for coreference decisions between two individual strings, not two clusters of strings." ></td>
	<td class="line x" title="106:262	We follow the work of Snow et al.(2006) in incorporating transitive closure constraints in probabilistic modeling, and make the same independence assumptions." ></td>
	<td class="line x" title="108:262	The benefit of this approach is that the calculation for merging two clusters depends only on coreference decisions between individual strings, which can be calculated independently." ></td>
	<td class="line x" title="109:262	Let a clustering be a set of coreference relationships between pairs of strings such that the coreference relationships obey the transitive closure property." ></td>
	<td class="line x" title="110:262	We let the probability of a set of assertions D given a clustering C be: P(D|C) = productdisplay Rti,jC P(Di Dj|Rti,j) productdisplay Rfi,jC P(Di Dj|Rfi,j) The metric used to determine if two clusters should be merged is the likelihood ratio, or the probability for the set of assertions given the merged clusters over the probability given the original clustering." ></td>
	<td class="line x" title="111:262	Let Cprime be a clustering that differs from C only in that two clusters in C have been merged in Cprime, and let C be the set of coreference relationships in Cprime that are true, but the corresponding ones in C are false." ></td>
	<td class="line x" title="112:262	This metric is given by: P(D|Cprime)/P(D|C) = producttext Rti,jC P(Rti,j|Di Dj)(1P(Rti,j))producttext Rti,jC(1P(Rti,j|Di Dj))P(Rti,j) The probability P(Rti,j|DiDj) may be supplied by the SSM, ESP, or combination model." ></td>
	<td class="line x" title="113:262	In our experiments, we let the prior for the SSM model be 0.5." ></td>
	<td class="line x" title="114:262	For the ESP and combined models, we set the prior to P(Rti,j) = 1min(P1,P2)." ></td>
	<td class="line x" title="115:262	4 RESOLVERs Clustering Algorithm Our clustering algorithm iteratively merges clusters of co-referential names, making each iteration in S := set of all strings For each property or instance p, Sp := {s  S|s has property p} 1." ></td>
	<td class="line x" title="116:262	Scores := {} 2." ></td>
	<td class="line x" title="117:262	Build index mapping properties (and instances) to strings with those properties (instances) 3." ></td>
	<td class="line x" title="118:262	For each property or instance p: If |Sp| < Max: For each pair {s1,s2} Sp: Add mergeScore(s1,s2) to Scores 4." ></td>
	<td class="line x" title="119:262	Repeat until no merges can be performed: Sort Scores UsedClusters := {} While score of top clusters c1,c2 is above Threshold: Skip if either is in UsedClusters Merge c1 and c2 Add c1,c2 to UsedClusters Merge properties containing c1,c2 Recalculate merge scores as in Steps 1-3 Figure 1: RESOLVERs Clustering Algorithm time O(N log N) in the number of extracted assertions." ></td>
	<td class="line x" title="120:262	The algorithm requires only basic assumptions about which strings to compare." ></td>
	<td class="line x" title="121:262	Previous work on speeding up clustering algorithms for SR has either required far stronger assumptions, or else it has focused on heuristic methods that remain, in the worst case, O(N2) in the number of distinct objects." ></td>
	<td class="line x" title="122:262	Our algorithm, a greedy agglomerative clustering method, is outlined in Figure 1." ></td>
	<td class="line x" title="123:262	The first novel part of the algorithm, step 3, compares pairs of strings that share the same property or instance, so long as no more than Max strings share that same property or instance." ></td>
	<td class="line x" title="124:262	After the scores for all comparisons are made, each string is assigned its own cluster." ></td>
	<td class="line x" title="125:262	Then the scores are sorted and the best cluster pairs are merged until no pair of clusters has a score above threshold." ></td>
	<td class="line x" title="126:262	The second novel aspect of this algorithm is that as it merges clusters in Step 4, it merges properties containing those clusters in a process we call mutual recursion, which is discussed below." ></td>
	<td class="line x" title="127:262	This algorithm compares every pair of clusters that have the potential to be merged, assuming two properties of the data." ></td>
	<td class="line x" title="128:262	First, it assumes that pairs of clusters with no shared properties are not worth 125 comparing." ></td>
	<td class="line x" title="129:262	Since the number of shared properties is a key source of evidence for our approach, these clusters almost certainly will not be merged, even if they are compared, so the assumption is quite reasonable." ></td>
	<td class="line x" title="130:262	Second, the approach assumes that clusters sharing only properties that apply to very many strings (more than Max) need not be compared." ></td>
	<td class="line x" title="131:262	Since properties shared by many strings provide little evidence that the strings are coreferential, this assumption is reasonable for SR. We use Max = 50 in our experiments." ></td>
	<td class="line x" title="132:262	Less than 0.1% of the properties are thrown out using this cutoff." ></td>
	<td class="line x" title="133:262	4.1 Algorithm Analysis Let D be the set of extracted assertions." ></td>
	<td class="line x" title="134:262	The following analysis shows that one iteration of merges takes time O(N log N), where N = |D|." ></td>
	<td class="line x" title="135:262	Let NC be the number of comparisons between strings in step 3." ></td>
	<td class="line x" title="136:262	To simplify the analysis, we consider only those properties that contain a relation string and an argument 1 string." ></td>
	<td class="line x" title="137:262	Let A be the set of all such properties." ></td>
	<td class="line x" title="138:262	NC is linear in N:4 NC = summationdisplay pA |Sp|(|Sp|1) 2  (Max1)2  summationdisplay pA |Sp| = (Max1)2 N Note that this bound is quite loose because most properties apply to only a few strings." ></td>
	<td class="line x" title="139:262	Step 4 requires time O(N log N) to sort the comparison scores and perform one iteration of merges." ></td>
	<td class="line x" title="140:262	If the largest cluster has size K, in the worst case the algorithm will take K iterations." ></td>
	<td class="line x" title="141:262	In our experiments, the algorithm never took more than 9 iterations." ></td>
	<td class="line x" title="142:262	4.2 Relation to other speed-up techniques The merge/purge algorithm (Hernandez and Stolfo, 1995) assumes the existence of a particular attribute such that when the data set is sorted on this attribute, matching pairs will all appear within a narrow window of one another." ></td>
	<td class="line x" title="143:262	This algorithm is O(M log M) where M is the number of distinct strings." ></td>
	<td class="line x" title="144:262	However, there is no attribute or set of attributes that comes 4If the Max parameter is allowed to vary with log|D|, rather than remaining constant, the same analysis leads to a slightly looser bound that is still better than O(N2)." ></td>
	<td class="line x" title="145:262	close to satisfying this assumption in the context of domain-independent information extraction." ></td>
	<td class="line x" title="146:262	There are several techniques that often provide speed-ups in practice, but in the worst case they make O(M2) comparisons at each merge iteration, where M is the number of distinct strings." ></td>
	<td class="line x" title="147:262	This can cause problems on very large data sets." ></td>
	<td class="line x" title="148:262	Notably, McCallum et al.(2000) use a cheap comparison metric to place objects into overlapping canopies, and then use a more expensive metric to cluster objects appearing in the same canopy." ></td>
	<td class="line x" title="150:262	The RESOLVER clustering algorithm is in fact an adaptation of the canopy method; it adds the restriction that strings are not compared when they share only high-frequency properties." ></td>
	<td class="line x" title="151:262	The canopy method works well on highdimensional data with many clusters, which is the case with our problem, but its time complexity is worse than ours." ></td>
	<td class="line x" title="152:262	For information extraction data, a complexity of O(M2) in the number of distinct strings turns out to be considerably worse than our algorithms complexity of O(N log N) in the number of extracted assertions." ></td>
	<td class="line x" title="153:262	This is because the data obeys a Zipf law relationship between the frequency of a string and its rank, so the number of distinct strings grows linearly or almost linearly with the number of assertions.5 4.3 Mutual Recursion Mutual recursion refers to the novel property of our algorithm that as it clusters relation strings together into sets of synonyms, it collapses properties together for object strings and potentially finds more shared properties between coreferential object strings." ></td>
	<td class="line x" title="154:262	Likewise, as it clusters objects together into sets of coreferential names, it collapses instances of relations together and potentially finds more shared instances between coreferential relations." ></td>
	<td class="line x" title="155:262	Thus the clustering decisions for relations and objects mutually depend on one another." ></td>
	<td class="line x" title="156:262	For example, the strings Kennedy and President Kennedy appear in 430 and 97 assertions in our data, respectively, but none of their extracted properties match exactly." ></td>
	<td class="line x" title="157:262	Many properties, 5The exact relationship depends on the shape parameter z of the Zipf curve." ></td>
	<td class="line x" title="158:262	If z < 1, as it is for our data set, the number of total extractions grows linearly with the number of distinct strings extracted." ></td>
	<td class="line x" title="159:262	If z = 1, then n extractions will contain ( nln n) distinct strings." ></td>
	<td class="line x" title="160:262	126 however, almost match." ></td>
	<td class="line x" title="161:262	For example, the assertions (challenged,Kennedy,Premier Krushchev) and (stood up to,President Kennedy,Kruschev) both appear in our data." ></td>
	<td class="line x" title="162:262	Because challenged and stood up to are similar, and Krushchev and Premier Krushchev are similar, our algorithm is able to merge these pairs into two clusters, thereby creating a new shared property between Kennedy and President Kennedy. Eventually it can merge these two strings as well." ></td>
	<td class="line x" title="163:262	5 Extensions to RESOLVER While the basic RESOLVER system can cluster synonyms accurately and quickly, there is one type of error that it frequently makes." ></td>
	<td class="line x" title="164:262	In some cases, it has difficulty distinguishing between similar pairs of objects and identical pairs." ></td>
	<td class="line x" title="165:262	For example, Virginia and West Virginia share several extractions because they have the same type, and they have high string similarity." ></td>
	<td class="line x" title="166:262	As a result, RESOLVER clusters these two together." ></td>
	<td class="line x" title="167:262	The next two sections describe two extensions to RESOLVER that address the problem of similarity vs. identity." ></td>
	<td class="line x" title="168:262	5.1 Function Filtering RESOLVER can use functions and one-to-one relations to help distinguish between similar and identical pairs." ></td>
	<td class="line x" title="169:262	For example, West Virginia and Virginia have different capitals: Richmond and Charleston, respectively." ></td>
	<td class="line x" title="170:262	If both of these facts are extracted, and if RESOLVER knows that the capital of relation is functional, it should prevent Virginia and West Virginia from merging." ></td>
	<td class="line x" title="171:262	The Function Filter prevents merges between strings that have different values for the same function." ></td>
	<td class="line x" title="172:262	More precisely, it decides that two strings y1 and y2 match if their string similarity is above a high threshold." ></td>
	<td class="line x" title="173:262	It prevents a merge between strings x1 and x2 if there exist a function f and extractions f(x1,y1) and f(x2,y2), and there are no such extractions such that y1 and y2 match (and vice versa for one-to-one relations)." ></td>
	<td class="line x" title="174:262	Experiments described in section 6 show that the Function Filter can improve the precision of RESOLVER without significantly affecting its recall." ></td>
	<td class="line x" title="175:262	While the Function Filter currently uses functions and one-to-one relations as negative evidence, it is also possible to use them as positive evidence." ></td>
	<td class="line x" title="176:262	For example, the relation married is not strictly one-to-one, but for most people the set of spouses is very small." ></td>
	<td class="line x" title="177:262	If a pair of strings are extracted with the same spousee.g. , FDR and President Roosevelt share the property (married, Eleanor Roosevelt)this is far stronger evidence that the two strings are identical than if they shared some random property." ></td>
	<td class="line x" title="178:262	Unfortunately, various techniques that attempted to model this insight, including a TF-IDF weighting of properties, yielded essentially no improvement of RESOLVER." ></td>
	<td class="line x" title="179:262	One major reason is that there are relatively few examples of shared functional or oneto-one properties because of sparsity." ></td>
	<td class="line x" title="180:262	This idea deserves more investigation, however, and is an area for future work." ></td>
	<td class="line x" title="181:262	5.2 Using Web Hitcounts While names for two similar objects may often appear together in the same sentence, it is relatively rare for two different names of the same object to appear in the same sentence." ></td>
	<td class="line x" title="182:262	RESOLVER exploits this fact by querying the Web to determine how often a pair of strings appears together in a large corpus." ></td>
	<td class="line x" title="183:262	When the hitcount is high, RESOLVER can prevent the merge." ></td>
	<td class="line x" title="184:262	Specifically, the Coordination-Phrase Filter searches for hitcounts of the phrase s1 and s2, where s1 and s2 are a candidate pair for merging." ></td>
	<td class="line x" title="185:262	It then computes a variant of pointwise mutual information, given by coordination score(s1,s2) = hits(s1 and s2) 2 hits(s1) hits(s2) The filter prevents any merge for which the coordination score is above a threshold, which is determined on a development set." ></td>
	<td class="line x" title="186:262	The results of Coordination-Phrase filtering are discussed in the next section." ></td>
	<td class="line x" title="187:262	6 Experiments Our experiments demonstrate that the ESP model is significantly better at resolving synonyms than a widely-used distributional similarity metric, the cosine similarity metric (CSM) (Salton and McGill, 1983), and that RESOLVER is significantly better at 127 resolving synonyms than either of its components, SSM or ESP. We test these models on a data set of 2.1 million assertions extracted from a Web crawl.6 All models ran over all assertions, but compared only those objects or relations that appeared at least 25 times in the data, to give the ESP and CSM models sufficient data for estimating similarity." ></td>
	<td class="line x" title="188:262	However, the models do use strings that appear less than 25 times as features." ></td>
	<td class="line x" title="189:262	In all, the data contains 9,797 distinct object strings and 10,151 distinct relation strings that appear at least 25 times." ></td>
	<td class="line x" title="190:262	We judged the precision of each model by manually labeling all of the clusters that each model outputs." ></td>
	<td class="line x" title="191:262	Judging recall would require inspecting not just the clusters that the system outputs, but the entire data set, to find all of the true clusters." ></td>
	<td class="line x" title="192:262	Because of the size of the data set, we instead estimated recall over a smaller subset of the data." ></td>
	<td class="line x" title="193:262	We took the top 200 most frequent object strings and top 200 most frequent relation strings in the data." ></td>
	<td class="line x" title="194:262	For each one of these high-frequency strings, we manually searched through all strings with frequency over 25 that shared at least one property, as well as all strings that contained one of the keywords in the high-frequency strings or obvious variations of them." ></td>
	<td class="line x" title="195:262	We manually clustered the resulting matches." ></td>
	<td class="line x" title="196:262	The top 200 object strings formed 51 clusters of size greater than one, with an average cluster size of 2.9." ></td>
	<td class="line x" title="197:262	For relations, the top 200 strings and their matches formed 110 clusters with size greater than one, with an average cluster size of 4.9." ></td>
	<td class="line x" title="198:262	We measured the recall of our models by comparing the set of all clusters containing at least one of the high-frequency words against these gold standard clusters." ></td>
	<td class="line x" title="199:262	For our precision and recall measures, we only compare clusters of size two or more, in order to focus on the interesting cases." ></td>
	<td class="line x" title="200:262	Using the term hypothesis cluster for clusters created by one of the models, we define the precision of a model to be the number of elements in all hypothesis clusters which are correct divided by the total number of elements in hypothesis clusters." ></td>
	<td class="line x" title="201:262	An element s is marked correct if a plurality of the elements in ss cluster refer to the same entity as s; we break ties arbitrarily, as 6The data is made available at http://www.cs.washington.edu/homes/ayates/." ></td>
	<td class="line x" title="202:262	they do not affect results." ></td>
	<td class="line x" title="203:262	We define recall as the sum over gold standard clusters of the most number of elements found in a single hypothesis cluster, divided by the total number of elements in gold standard clusters." ></td>
	<td class="line x" title="204:262	For the ESP and SSM models in our experiment, we prevented mutual recursion by clustering relations and objects separately." ></td>
	<td class="line x" title="205:262	Only the full RESOLVER system uses mutual recursion." ></td>
	<td class="line x" title="206:262	For the CSM model, we create for each distinct string a row vector, with each column representing a property." ></td>
	<td class="line x" title="207:262	If that property applies to the string, we set the value of that column to the inverse frequency of the property and zero otherwise." ></td>
	<td class="line x" title="208:262	CSM finds the cosine of the angle between the vectors for each pair of strings, and merges the best pairs that score above threshold." ></td>
	<td class="line x" title="209:262	Each model requires a threshold parameter to determine which scores are suitable for merging." ></td>
	<td class="line x" title="210:262	For these experiments we arbitrarily chose a threshold of 3 for the ESP model (that is, the data needs to be 3 times more likely given the merged cluster than the unmerged clusters in order to perform the merge) and chose thresholds for the other models by hand so that the difference between them and ESP would be roughly even between precision and recall, although for relations it was harder to improve the recall." ></td>
	<td class="line x" title="211:262	It is an important item for future work to be able to estimate these thresholds and perhaps other parameters of our models from unlabeled data, but the chosen parameters worked well enough for the experiments." ></td>
	<td class="line x" title="212:262	Table 1 shows the precision and recall of our models." ></td>
	<td class="line x" title="213:262	6.1 Discussion ESP significantly outperforms CSM on both object and relation clustering." ></td>
	<td class="line x" title="214:262	CSM had particular trouble with lower-frequency strings, judging far too many of them to be co-referential on too little evidence." ></td>
	<td class="line x" title="215:262	If the threshold for clustering using CSM is increased, however, the recall begins to approach zero." ></td>
	<td class="line x" title="216:262	ESP and CSM make predictions based on a very noisy signal." ></td>
	<td class="line x" title="217:262	Canada, for example, shares more properties with United States in our data than U.S. does, even though Canada appears less often than U.S. The results show that both models perform below the SSM model on its own for object merging, and both perform slightly better than SSM on relations because of SSMs poor recall." ></td>
	<td class="line x" title="218:262	We found a significant improvement in both pre128 Objects Relations Model Prec." ></td>
	<td class="line x" title="219:262	Rec." ></td>
	<td class="line x" title="220:262	F1 Prec." ></td>
	<td class="line x" title="221:262	Rec." ></td>
	<td class="line x" title="222:262	F1 CSM 0.51 0.36 0.42 0.62 0.29 0.40 ESP 0.56 0.41 0.47 0.79 0.33 0.47 SSM 0.62 0.53 0.57 0.85 0.25 0.39 RESOLVER 0.71 0.66 0.68 0.90 0.35 0.50 Table 1: Comparison of the cosine similarity metric (CSM), RESOLVER components (SSM and ESP), and the RESOLVER system." ></td>
	<td class="line x" title="223:262	Bold indicates the score is significantly different from the score in the row above at p < 0.05 using the chi-squared test with one degree of freedom." ></td>
	<td class="line x" title="224:262	Using the same test, RESOLVER is also significantly different from ESP and CSM in recall on objects, and from CSM and SSM in recall on relations." ></td>
	<td class="line x" title="225:262	RESOLVERs F1 on objects is a 19% increase over SSMs F1." ></td>
	<td class="line x" title="226:262	RESOLVERs F1 on relations is a 28% increase over SSMs F1." ></td>
	<td class="line x" title="227:262	cision and recall when using a combined model over using SSM alone." ></td>
	<td class="line x" title="228:262	RESOLVERs F1 is 19% higher than SSMs on objects, and 28% higher on relations." ></td>
	<td class="line x" title="229:262	In a separate experiment we found that mutual recursion provides mixed results." ></td>
	<td class="line x" title="230:262	A combination of SSM and ESP without mutual recursion had a precision of 0.76 and recall of 0.59 on objects, and a precision of 0.91 and recall of 0.35 on relations." ></td>
	<td class="line x" title="231:262	Mutual recursion increased recall and decreased precision for both objects and relations." ></td>
	<td class="line x" title="232:262	None of the differences were statistically significant, however." ></td>
	<td class="line x" title="233:262	There is clearly room for improvement on the SR task." ></td>
	<td class="line x" title="234:262	Except for the problem of confusing similar and identical pairs (see section 5), error analysis shows that most of RESOLVERs mistakes are because of two kinds of errors: 1." ></td>
	<td class="line x" title="235:262	Extraction errors." ></td>
	<td class="line x" title="236:262	For example, US News gets extracted separately from World Report, and then RESOLVER clusters them together because they share almost all of the same properties." ></td>
	<td class="line x" title="237:262	2." ></td>
	<td class="line x" title="238:262	Multiple word senses." ></td>
	<td class="line x" title="239:262	For example, there are two President Bushes; also, there are many terms like President and Army that can refer to many different entities." ></td>
	<td class="line x" title="240:262	6.2 Experiments with Extensions The extensions to RESOLVER attempt to address the confusion between similar and identical pairs." ></td>
	<td class="line x" title="241:262	Experiments with the extensions, using the same datasets and metrics as above, demonstrate that the Function Filter (FF) and the Coordination-Phrase Filter (CPF) boost RESOLVERs performance." ></td>
	<td class="line x" title="242:262	FF requires as input the set of functional and oneto-one relations in the data." ></td>
	<td class="line x" title="243:262	Table 2 contains a samis capital of is capital city of named after was named after headquartered in is headquartered in Table 2: A sample of the set of functions used by the Function Filter." ></td>
	<td class="line x" title="244:262	Model Prec." ></td>
	<td class="line x" title="245:262	Rec." ></td>
	<td class="line x" title="246:262	F1 RESOLVER 0.71 0.66 0.68 RESOLVER+FF 0.74 0.66 0.70 RESOLVER+CPF 0.78 0.68 0.73 RESOLVER+FF+CPF 0.78 0.68 0.73 Table 3: Comparison of object merging results for the RESOLVER system, RESOLVER plus Function Filtering (RESOLVER+FF), RESOLVER plus Coordination-Phrase Filtering (RESOLVER+CPF), and RESOLVER plus both types of filtering (RESOLVER+FF+CPF)." ></td>
	<td class="line x" title="247:262	Bold indicates the score is significantly different from RESOLVERs score at p < 0.05 using the chi-squared test with one degree of freedom." ></td>
	<td class="line x" title="248:262	RESOLVER+CPFs F1 on objects is a 28% increase over SSMs F1, and a 7% increase over RESOLVERs F1." ></td>
	<td class="line x" title="249:262	pling of the manually-selected functions used in our experiment." ></td>
	<td class="line x" title="250:262	Automatically discovering such functions from extractions has been addressed in AnaMaria Popescus dissertation (Popescu, 2007), and we did not attempt to duplicate this effort in RESOLVER." ></td>
	<td class="line x" title="251:262	Table 3 contains the results of our experiments." ></td>
	<td class="line x" title="252:262	With coordination-phrase filtering, RESOLVERs F1 is 28% higher than SSMs on objects, and 6% higher than RESOLVERs F1 without filtering." ></td>
	<td class="line x" title="253:262	While function filtering is a promising idea, FF provides a smaller benefit than CPF on this dataset, and the 129 merges that it prevents are, with a few exceptions, a subset of the merges prevented by CPF." ></td>
	<td class="line x" title="254:262	This is in part due to the limited number of functions available in the data." ></td>
	<td class="line x" title="255:262	In addition to outperforming FF on this dataset, CPF has the added advantage that it does not require additional input, like a set of functions." ></td>
	<td class="line x" title="256:262	7 Conclusion and Future Work We have shown that the unsupervised and scalable RESOLVER system is able to find clusters of coreferential object names in extracted relations with a precision of 78% and a recall of 68% with the aid of coordination-phrase filtering, and can find clusters of co-referential relation names with precision of 90% and recall of 35%." ></td>
	<td class="line x" title="257:262	We have demonstrated significant improvements over using simple similarity metrics for this task by employing a novel probabilistic model of coreference." ></td>
	<td class="line x" title="258:262	In future work, we plan to use RESOLVER on a much larger data set of over a hundred million assertions, further testing its scalability and its ability to improve in accuracy given additional data." ></td>
	<td class="line x" title="259:262	We also plan to add techniques for handling multiple word senses." ></td>
	<td class="line x" title="260:262	Finally, to make the probabilistic model more accurate and easier to use, we plan to investigate methods for automatically estimating its parameters from unlabeled data." ></td>
	<td class="line x" title="261:262	Acknowledgements This research was supported in part by NSF grants IIS-0535284 and IIS-0312988, DARPA contract NBCHD030010, ONR grant N00014-05-1-0185 as well as gifts from Google, and carried out at the University of Washingtons Turing Center." ></td>
	<td class="line x" title="262:262	We thank Doug Downey, Michele Banko, Stef Schoenmackers, Dan Weld, Fei Wu, and the anonymous reviewers for their helpful comments on previous drafts." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P07-1028
A Simple, Similarity-based Model for Selectional Preferences
Erk, Katrin;"></td>
	<td class="line x" title="1:188	Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 216223, Prague, Czech Republic, June 2007." ></td>
	<td class="line x" title="2:188	c2007 Association for Computational Linguistics A Simple, Similarity-based Model for Selectional Preferences Katrin Erk University of Texas at Austin katrin.erk@mail.utexas.edu Abstract We propose a new, simple model for the automatic induction of selectional preferences, using corpus-based semantic similarity metrics." ></td>
	<td class="line x" title="3:188	Focusing on the task of semantic role labeling, we compute selectional preferences for semantic roles." ></td>
	<td class="line x" title="4:188	In evaluations the similarity-based model shows lower error rates than both Resniks WordNet-based model and the EM-based clustering model, but has coverage problems." ></td>
	<td class="line x" title="5:188	1 Introduction Selectional preferences, which characterize typical arguments of predicates, are a very useful and versatile knowledge source." ></td>
	<td class="line x" title="6:188	They have been used for example for syntactic disambiguation (Hindle and Rooth, 1993), word sense disambiguation (WSD) (McCarthy and Carroll, 2003) and semantic role labeling (SRL) (Gildea and Jurafsky, 2002)." ></td>
	<td class="line x" title="7:188	The corpus-based induction of selectional preferences was first proposed by Resnik (1996)." ></td>
	<td class="line x" title="8:188	All later approaches have followed the same twostep procedure, first collecting argument headwords from a corpus, then generalizing to other, similar words." ></td>
	<td class="line x" title="9:188	Some approaches have used WordNet for the generalization step (Resnik, 1996; Clark and Weir, 2001; Abe and Li, 1993), others EM-based clustering (Rooth et al. , 1999)." ></td>
	<td class="line x" title="10:188	In this paper we propose a new, simple model for selectional preference induction that uses corpus-based semantic similarity metrics, such as Cosine or Lins (1998) mutual informationbased metric, for the generalization step." ></td>
	<td class="line x" title="11:188	This model does not require any manually created lexical resources." ></td>
	<td class="line x" title="12:188	In addition, the corpus for computing the similarity metrics can be freely chosen, allowing greater variation in the domain of generalization than a fixed lexical resource." ></td>
	<td class="line x" title="13:188	We focus on one application of selectional preferences: semantic role labeling." ></td>
	<td class="line x" title="14:188	The argument positions for which we compute selectional preferences will be semantic roles in the FrameNet (Baker et al. , 1998) paradigm, and the predicates we consider will be semantic classes of words rather than individual words (which means that different preferences will be learned for different senses of a predicate word)." ></td>
	<td class="line x" title="15:188	In SRL, the two most pressing issues today are (1) the development of strong semantic features to complement the current mostly syntacticallybased systems, and (2) the problem of the domaindependence (Carreras andMarquez, 2005)." ></td>
	<td class="line x" title="16:188	In the CoNLL-05 shared task, participating systems showed about 10 points F-score difference between in-domain and out-of-domain test data." ></td>
	<td class="line x" title="17:188	Concerning (1), we focus on selectional preferences as the strongest candidate for informative semantic features." ></td>
	<td class="line x" title="18:188	Concerning (2), the corpusbased similarity metrics that we use for selectional preference induction open up interesting possibilities of mixing domains." ></td>
	<td class="line x" title="19:188	We evaluate the similarity-based model against Resniks WordNet-based model as well as the EM-based clustering approach." ></td>
	<td class="line x" title="20:188	In the evaluation, the similarity-model shows lower error rates than both Resniks WordNet-based model and the EM-based clustering model." ></td>
	<td class="line x" title="21:188	However, the EM-based clustering model has higher coverage than both other paradigms." ></td>
	<td class="line x" title="22:188	Plan of the paper." ></td>
	<td class="line x" title="23:188	After discussing previ216 ous approaches to selectional preference induction in Section 2, we introduce the similaritybased model in Section 3." ></td>
	<td class="line x" title="24:188	Section 4 describes the data used for the experiments reported in Section 5, and Section 6 concludes." ></td>
	<td class="line x" title="25:188	2 Related Work Selectional restrictions and selectional preferences that predicates impose on their arguments have long been used in semantic theories, (see e.g.(Katz and Fodor, 1963; Wilks, 1975))." ></td>
	<td class="line x" title="27:188	The induction of selectional preferences from corpus data was pioneered by Resnik (1996)." ></td>
	<td class="line x" title="28:188	All subsequent approaches have followed the same twostep procedure, first collecting argument headwords from a corpus, then generalizing over the seen headwords to similar words." ></td>
	<td class="line x" title="29:188	Resnik uses the WordNet noun hierarchy for generalization." ></td>
	<td class="line x" title="30:188	His information-theoretic approach models the selectional preference strength of an argument position1 rp of a predicate p as S(rp) = summationdisplay c P(c|rp)log P(c|rp)P(c) where the c are WordNet synsets." ></td>
	<td class="line x" title="31:188	The preference that rp has for a given synset c0, the selectional association between the two, is then defined as the contribution of c0 to rps selectional preference strength: A(rp,c0) = P(c0|rp)log P(c0|rp)P(c0) S(rp) Further WordNet-based approaches to selectional preference induction include Clark and Weir (2001), and Abe and Li (1993)." ></td>
	<td class="line x" title="32:188	Brockmann and Lapata (2003) perform a comparison of WordNet-based models." ></td>
	<td class="line x" title="33:188	Rooth et al.(1999) generalize over seen headwords using EM-based clustering rather than WordNet." ></td>
	<td class="line x" title="35:188	They model the probability of a word w occurring as the argument rp of a predicate p as being independently conditioned on a set of classes C: P(rp,w) = summationdisplay cC P(c,rp,w) = summationdisplay cC P(c)P(rp|c)P(w|c) 1We write rp to indicate predicate-specific roles, like the direct object of catch, rather than just obj." ></td>
	<td class="line x" title="36:188	The parameters P(c), P(rp|c) and P(w|c) are estimated using the EM algorithm." ></td>
	<td class="line x" title="37:188	While there have been no isolated comparisons of the two generalization paradigms that we are aware of, Gildea and Jurafskys (2002) task-based evaluation has found clusteringbased approaches to have better coverage than WordNet generalization, that is, for a given role there are more words for which they can state a preference." ></td>
	<td class="line x" title="38:188	3 Model The approach we are proposing makes use of two corpora, a primary corpus and a generalization corpus (which may, but need not, be identical)." ></td>
	<td class="line x" title="39:188	The primary corpus is used to extract tuples (p,rp,w) of a predicate, an argument position and a seen headword." ></td>
	<td class="line x" title="40:188	The generalization corpus is used to compute a corpus-based semantic similarity metric." ></td>
	<td class="line x" title="41:188	Let Seen(rp) be the set of seen headwords for an argument rp of a predicate p. Then we model the selectional preference S of rp for a possible headword w0 as a weighted sum of the similarities between w0 and the seen headwords: Srp(w0) = summationdisplay wSeen(rp) sim(w0,w)wtrp(w) sim(w0,w) is the similarity between the seen and the potential headword, and wtrp(w) is the weight of seen headword w. Similarity sim(w0,w) will be computed on the generalization corpus, again on the basis of extracted tuples (p,rp,w)." ></td>
	<td class="line oc" title="42:188	We will be using the similarity metrics shown in Table 1: Cosine, the Dice and Jaccard coefficients, and Hindles (1990) and Lins (1998) mutual information-based metrics." ></td>
	<td class="line x" title="43:188	We write f for frequency, I for mutual information, and R(w) for the set of arguments rp for which w occurs as a headword." ></td>
	<td class="line x" title="44:188	In this paper we only study corpus-based metrics." ></td>
	<td class="line x" title="45:188	The sim function can equally well be instantiated with a WordNet-based metric (for an overview see Budanitsky and Hirst (2006)), but we restrict our experiments to corpus-based metrics (a) in the interest of greatest possible 217 simcosine(w,wprime) = P rp f(w,rp)f(wprime,rp)qP rp f(w,rp)2 qP rp f(wprime,rp)2 simDice(w,wprime) = 2|R(w)R(wprime)||R(w)|+|R(wprime)| simLin(w,wprime) = P rpR(w)R(wprime) I(w,r,p)I(wprime,r,p)P rpR(w) I(w,r,p) P rpR(w) I(wprime,r,p) simJaccard(w,wprime) = |R(w)R(wprime)||R(w)R(wprime)| simHindle(w,wprime) = summationtextrp simHindle(w,wprime,rp) where simHindle(w,wprime,rp) =    min(I(w,rp),I(wprime,rp) if I(w,rp) > 0 and I(wprime,rp) > 0 abs(max(I(w,rp),I(wprime,rp))) if I(w,rp) < 0 and I(wprime,rp) < 0 0 else Table 1: Similarity measures used resource-independence and (b) in order to be able to shape the similarity metric by the choice of generalization corpus." ></td>
	<td class="line x" title="46:188	For the headword weights wtrp(w), the simplest possibility is to assume a uniform weight distribution, i.e. wtrp(w) = 1." ></td>
	<td class="line x" title="47:188	In addition, we test a frequency-based weight, i.e. wtrp(w) = f(w,rp), and inverse document frequency, which weighs a word according to its discriminativity: wtrp(w) = log num." ></td>
	<td class="line x" title="48:188	wordsnum." ></td>
	<td class="line x" title="49:188	words to whose context w belongs." ></td>
	<td class="line x" title="50:188	This similarity-based model of selectional preferences is a straightforward implementation of the idea of generalization from seen headwords to other, similar words." ></td>
	<td class="line x" title="51:188	Like the clustering-based model, it is not tied to the availability of WordNet or any other manually created resource." ></td>
	<td class="line x" title="52:188	The model uses two corpora, a primary corpus for the extraction of seen headwords and a generalization corpus for the computation of semantic similarity metrics." ></td>
	<td class="line x" title="53:188	This gives the model flexibility to influence the similarity metric through the choice of text domain of the generalization corpus." ></td>
	<td class="line x" title="54:188	Instantiation used in this paper." ></td>
	<td class="line x" title="55:188	Our aim is to compute selectional preferences for semantic roles." ></td>
	<td class="line x" title="56:188	So we choose a particular instantiation of the similarity-based model that makes use of the fact that the two-corpora approach allows us to use different notions of predicate and argument in the primary and generalization corpus." ></td>
	<td class="line x" title="57:188	Our primary corpus will consist of manually semantically annotated data, and we will use semantic verb classes as predicates and semantic roles as arguments." ></td>
	<td class="line x" title="58:188	Examples of extracted (p,rp,w) tuples are (Morality evaluation, Evaluee, gamblers) and (Placing, Goal, briefcase)." ></td>
	<td class="line x" title="59:188	Semantic similarity, on the other hand, will be computed on automatically syntactically parsed corpus, where the predicates are words and the arguments are syntactic dependents." ></td>
	<td class="line x" title="60:188	Examples of extracted (p,rp,w) tuples from the generalization corpus include (catch, obj, frogs) and (intervene, in, deal).2 This instantiation of the similarity-based model allows us to compute word sense specific selectional preferences, generalizing over manually semantically annotated data using automatically syntactically annotated data." ></td>
	<td class="line x" title="61:188	4 Data We use FrameNet (Baker et al. , 1998), a semantic lexicon for English that groups words in semantic classes called frames and lists semantic roles for each frame." ></td>
	<td class="line x" title="62:188	The FrameNet 1.3 annotated data comprises 139,439 sentences from the British National Corpus (BNC)." ></td>
	<td class="line x" title="63:188	For our experiments, we chose 100 frame-specific semantic roles at random, 20 each from five frequency bands: 50-100 annotated occurrences of the role, 100-200 occurrences, 200-500, 5001000, and more than 1000 occurrences." ></td>
	<td class="line x" title="64:188	The annotated data for these 100 roles comprised 59,608 sentences, our primary corpus." ></td>
	<td class="line x" title="65:188	To determine headwords of the semantic roles, the corpus was parsed using the Collins (1997) parser." ></td>
	<td class="line x" title="66:188	Our generalization corpus is the BNC." ></td>
	<td class="line x" title="67:188	It was parsed using Minipar (Lin, 1993), which is considerably faster than the Collins parser but failed to parse about a third of all sentences." ></td>
	<td class="line x" title="68:188	2For details about the syntactic and semantic analyses used, see Section 4." ></td>
	<td class="line x" title="69:188	218 Accordingly, the arguments r extracted from the generalization corpus are Minipar dependencies, except that paths through preposition nodes were collapsed, using the preposition as the dependency relation." ></td>
	<td class="line x" title="70:188	We obtained parses for 5,941,811 sentences of the generalization corpus." ></td>
	<td class="line x" title="71:188	The EM-based clustering model was computed with all of the FrameNet 1.3 data (139,439 sentences) as input." ></td>
	<td class="line x" title="72:188	Resniks model was trained on the primary corpus (59,608 sentences)." ></td>
	<td class="line x" title="73:188	5 Experiments In this section we describe experiments comparing the similarity-based model for selectional preferences to Resniks WordNet-based model and to an EM-based clustering model3." ></td>
	<td class="line x" title="74:188	For the similarity-based model we test the five similarity metrics and three weighting schemes listed in section 3." ></td>
	<td class="line x" title="75:188	Experimental design Like Rooth et al.(1999) we evaluate selectional preference induction approaches in a pseudodisambiguation task." ></td>
	<td class="line x" title="77:188	In a test set of pairs (rp,w), each headword w is paired with a confounder wprime chosen randomly from the BNC according to its frequency4." ></td>
	<td class="line x" title="78:188	Noun headwords are paired with noun confounders in order not to disadvantage Resniks model, which only works with nouns." ></td>
	<td class="line x" title="79:188	The headword/confounder pairs are only computed once and reused in all crossvalidation runs." ></td>
	<td class="line x" title="80:188	The task is to choose the more likely role headword from the pair (w,wprime)." ></td>
	<td class="line x" title="81:188	In the main part of the experiment, we count a pair as covered if both w and wprime are assigned some level of preference by a model (full coverage)." ></td>
	<td class="line x" title="82:188	We contrast this with another condition, where we count a pair as covered if at least one of the two words w,wprime is assigned a level of preference by a model (half coverage)." ></td>
	<td class="line x" title="83:188	If only one is assigned a preference, that word is counted as chosen." ></td>
	<td class="line x" title="84:188	To test the performance difference between models for significance, we use Dietterichs 3We are grateful to Carsten Brockmann and Detlef Prescher for the use of their software." ></td>
	<td class="line x" title="85:188	4We exclude potential confounders that occur less than 30 or more than 3,000 times." ></td>
	<td class="line x" title="86:188	Error Rate Coverage Cosine 0.2667 0.3284 Dice 0.1951 0.3506 Hindle 0.2059 0.3530 Jaccard 0.1858 0.3506 Lin 0.1635 0.2214 EM 30/20 0.3115 0.5460 EM 40/20 0.3470 0.9846 Resnik 0.3953 0.3084 Table 2: Error rate and coverage (microaverage), similarity-based models with uniform weights." ></td>
	<td class="line x" title="87:188	5x2cv (Dietterich, 1998)." ></td>
	<td class="line x" title="88:188	The test involves five 2-fold cross-validation runs." ></td>
	<td class="line x" title="89:188	Let di,j (i  {1,2},j  {1,,5}) be the difference in error rates between the two models when using split i of cross-validation run j as training data." ></td>
	<td class="line x" title="90:188	Let s2j = (d1,j dj)2+(d2,j dj)2 be the variance for cross-validation run j, with dj = d1,j+d2,j2." ></td>
	<td class="line x" title="91:188	Then the 5x2cv t statistic is defined as t = d1,1radicalBig 1 5 summationtext5 j=1 s2j Under the null hypothesis, the t statistic has approximately a t distribution with 5 degrees of freedom.5 Results and discussion Error rates." ></td>
	<td class="line x" title="92:188	Table 2 shows error rates and coverage for the different selectional preference induction methods." ></td>
	<td class="line x" title="93:188	The first five models are similarity-based, computed with uniform weights." ></td>
	<td class="line x" title="94:188	The name in the first column is the name of the similarity metric used." ></td>
	<td class="line x" title="95:188	Next come EM-based clustering models, using 30 (40) clusters and 20 re-estimation steps6, and the last row lists the results for Resniks WordNet-based method." ></td>
	<td class="line x" title="96:188	Results are micro-averaged." ></td>
	<td class="line x" title="97:188	The table shows very low error rates for the similarity-based models, up to 15 points lower than the EM-based models." ></td>
	<td class="line x" title="98:188	The error rates 5Since the 5x2cv test fails when the error rates vary wildly, we excluded cases where error rates differ by 0.8 or more across the 10 runs, using the threshold recommended by Dietterich." ></td>
	<td class="line x" title="99:188	6The EM-based clustering software determines good values for these two parameters through pseudodisambiguation tests on the training data." ></td>
	<td class="line x" title="100:188	219 Cos Dic Hin Jac Lin EM 40/20 Resnik Cos -16 (73) -12 (73) -18 (74) -22 (57) 11 (67) 11 (74) Dic 16 (73) 2 (74) -8 (85) -10 (64) 39 (47) 27 (62) Hin 12 (73) -2 (74) -8 (75) -11 (63) 33 (57) 16 (67) Jac 18 (74) 8 (85) 8 (75) -7 (68) 42 (45) 30 (62) Lin 22 (57) 10 (64) 11 (63) 7 ( 68) 29 (41) 28 (51) EM 40/20 -11 ( 67 ) -39 ( 47 ) -33 ( 57 ) -42 ( 45 ) -29 ( 41 ) 3 ( 72 ) Resnik -11 (74) -27 (62) -16 (67) -30 (62) -28 (51) -3 (72) Table 3: Comparing similarity measures: number of wins minus losses (in brackets non-significant cases) using Dietterichs 5x2cv; uniform weights; condition (1): both members of a pair must be covered 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0 100 200 300 400 500 error_rate numhw Learning curve: num." ></td>
	<td class="line x" title="101:188	headwords, sim_based-Jaccard-Plain, error_rate, all Mon Apr 09 02:30:47 2007 1000100-200 500-1000 200-500 50-100 Figure 1: Learning curve: seen headwords versus error rate by frequency band, Jaccard, uniform weights 50-100 100-200 200-500 500-1000 1000Cos 0.3167 0.3203 0.2700 0.2534 0.2606 Jac 0.1802 0.2040 0.1761 0.1706 0.1927 Table 4: Error rates for similarity-based models, by semantic role frequency band." ></td>
	<td class="line x" title="102:188	Microaverages, uniform weights of Resniks model are considerably higher than both the EM-based and the similarity-based models, which is unexpected." ></td>
	<td class="line x" title="103:188	While EM-based models have been shown to work better in SRL tasks (Gildea and Jurafsky, 2002), this has been attributed to the difference in coverage." ></td>
	<td class="line x" title="104:188	In addition to the full coverage condition, we also computed error rate and coverage for the half coverage case." ></td>
	<td class="line x" title="105:188	In this condition, the error rates of the EM-based models are unchanged, while the error rates for all similarity-based models as well as Resniks model rise to values between 0.4 and 0.6." ></td>
	<td class="line x" title="106:188	So the EM-based model tends to have preferences only for the right words." ></td>
	<td class="line x" title="107:188	Why this is so is not clear." ></td>
	<td class="line x" title="108:188	It may be a genuine property, or an artifact of the FrameNet data, which only contains chosen, illustrative sentences for each frame." ></td>
	<td class="line x" title="109:188	It is possible that these sentences have fewer occurrences of highly frequent but semantically less informative role headwords like it or that exactly because of their illustrative purpose." ></td>
	<td class="line x" title="110:188	Table 3 inspects differences between error rates using Dietterichs 5x2cv, basically confirming Table 2." ></td>
	<td class="line x" title="111:188	Each cell shows the wins minus losses for the method listed in the row when compared against the method in the column." ></td>
	<td class="line x" title="112:188	The number of cases that did not reach significance is given in brackets." ></td>
	<td class="line x" title="113:188	Coverage." ></td>
	<td class="line x" title="114:188	The coverage rates of the similarity-based models, while comparable to Resniks model, are considerably lower than for EM-based clustering, which achieves good coverage with 30 and almost perfect coverage with 40 clusters (Table 2)." ></td>
	<td class="line x" title="115:188	While peculiarities of the FrameNet data may have influenced the results in the EM-based models favor (see the discussion of the half coverage condition above), the low coverage of the similarity-based models is still surprising." ></td>
	<td class="line x" title="116:188	After all, the generalization corpus of the similarity-based models is far larger than the corpus used for clustering." ></td>
	<td class="line x" title="117:188	Given the learning curve in Figure 1 it is unlikely that the reason for the lower coverage is data sparseness." ></td>
	<td class="line x" title="118:188	However, EM-based clustering is a soft clustering method, which relates every predicate and every headword to every cluster, if only with a very low probabil220 ity." ></td>
	<td class="line x" title="119:188	In similarity-based models, on the other hand, two words that have never been seen in the same argument slot in the generalization corpus will have zero similarity." ></td>
	<td class="line x" title="120:188	That is, a similarity-based model can assign a level of preference for an argument rp and word w0 only if R(w0)  R(Seen(rp)) is nonempty." ></td>
	<td class="line x" title="121:188	Since the flexibility of similarity-based models extends to the vector space for computing similarities, one obvious remedy to the coverage problem would be the use of a less sparse vector space." ></td>
	<td class="line x" title="122:188	Given the low error rates of similarity-based models, it may even be advisable to use two vector spaces, backing off to the denser one for words not covered by the sparse but highly accurate space used in this paper." ></td>
	<td class="line x" title="123:188	Parameters of similarity-based models." ></td>
	<td class="line x" title="124:188	Besides the similarity metric itself, which we discuss below, parameters of the similarity-based models include the number of seen headwords, the weighting scheme, and the number of similar words for each headword." ></td>
	<td class="line x" title="125:188	Table 4 breaks down error rates by semantic role frequency band for two of the similaritybased models, micro-averaging over roles of the same frequency band and over cross-validation runs." ></td>
	<td class="line x" title="126:188	As the table shows, there was some variation across frequency bands, but not as much as between models." ></td>
	<td class="line x" title="127:188	The question of the number of seen headwords necessary to compute selectional preferences is further explored in Figure 1." ></td>
	<td class="line x" title="128:188	The figure charts the number of seen headwords against error rate for a Jaccard similarity-based model (uniform weights)." ></td>
	<td class="line x" title="129:188	As can be seen, error rates reach a plateau at about 25 seen headwords for Jaccard." ></td>
	<td class="line x" title="130:188	For other similarity metrics the result is similar." ></td>
	<td class="line x" title="131:188	The weighting schemes wtrp had surprisingly little influence on results." ></td>
	<td class="line x" title="132:188	For Jaccard similarity, the model had an error rate of 0.1858 for uniform weights, 0.1874 for frequency weighting, and 0.1806 for discriminativity." ></td>
	<td class="line x" title="133:188	For other similarity metrics the results were similar." ></td>
	<td class="line x" title="134:188	A cutoff was used in the similarity-based model: For each seen headword, only the 500 most similar words (according to a given similarity measure) were included in the computaCos Dic Hin Jac Lin (a) Freq." ></td>
	<td class="line x" title="135:188	sim." ></td>
	<td class="line x" title="136:188	1889 3167 2959 3167 860 (b) Freq." ></td>
	<td class="line x" title="137:188	wins 65% 73% 79% 72% 58% (c) Num." ></td>
	<td class="line x" title="138:188	sim." ></td>
	<td class="line x" title="139:188	81 60 67 60 66 (d) Intersec." ></td>
	<td class="line x" title="140:188	7.3 2.3 7.2 2.1 0.5 Table 5: Comparing sim." ></td>
	<td class="line x" title="141:188	metrics: (a) avg." ></td>
	<td class="line x" title="142:188	freq." ></td>
	<td class="line x" title="143:188	of similar words; (b) % of times the more frequent word won; (c) number of distinct similar words per seen headword; (d) avg." ></td>
	<td class="line x" title="144:188	size of intersection between roles tion; for all others, a similarity of 0 was assumed." ></td>
	<td class="line x" title="145:188	Experiments testing a range of values for this parameter show that error rates stay stable for parameter values  200." ></td>
	<td class="line x" title="146:188	So similarity-based models seem not overly sensitive to the weighting scheme used, the number of seen headwords, or the number of similar words per seen headword." ></td>
	<td class="line x" title="147:188	The difference between similarity metrics, however, is striking." ></td>
	<td class="line x" title="148:188	Differences between similarity metrics." ></td>
	<td class="line n" title="149:188	As Table 2 shows, Lin and Jaccard worked best (though Lin has very low coverage), Dice and Hindle not as good, and Cosine showed the worst performance." ></td>
	<td class="line x" title="150:188	To determine possible reasons for the difference, Table 5 explores properties of the five similarity measures." ></td>
	<td class="line x" title="151:188	Given a set S = Seen(rp) of seen headwords for some role rp, each similarity metric produces a set like(S) of words that have nonzero similarity to S, that is, to at least one word in S. Line (a) shows the average frequency of words in like(S)." ></td>
	<td class="line x" title="152:188	The results confirm that the Lin and Cosine metrics tend to propose less frequent words as similar." ></td>
	<td class="line x" title="153:188	Line (b) pursues the question of the frequency bias further, showing the percentage of headword/confounder pairs for which the more frequent of the two words won in the pseudodisambiguation task (using uniform weights)." ></td>
	<td class="line x" title="154:188	This it is an indirect estimate of the frequency bias of a similarity metric." ></td>
	<td class="line x" title="155:188	Note that the headword actually was more frequent than the confounder in only 36% of all pairs." ></td>
	<td class="line x" title="156:188	These first two tests do not yield any explanation for the low performance of Cosine, as the results they show do not separate Cosine from 221 Jaccard Cosine Ride vehicle:Vehicle truck 0.05 boat 0.05 coach 0.04 van 0.04 ship 0.04 lorry 0.04 creature 0.04 flight 0.04 guy 0.04 carriage 0.04 helicopter 0.04 lad 0.04 Ingest substance:Substance loaf 0.04 ice cream 0.03 you 0.03 some 0.03 that 0.03 er 0.03 photo 0.03 kind 0.03 he 0.03 type 0.03 thing 0.03 milk 0.03 Ride vehicle:Vehicle it 1.18 there 0.88 they 0.43 that 0.34 i 0.23 ship 0.19 second one 0.19 machine 0.19 e 0.19 other one 0.19 response 0.19 second 0.19 Ingest substance:Substance there 1.23 that 0.50 object 0.27 argument 0.27 theme 0.27 version 0.27 machine 0.26 result 0.26 response 0.25 item 0.25 concept 0.25 s 0.24 Table 6: Highest-ranked induced headwords (seen headwords omitted) for two semantic classes of the verb take: similarity-based models, Jaccard and Cosine, uniform weights." ></td>
	<td class="line x" title="157:188	all other metrics." ></td>
	<td class="line x" title="158:188	Lines (c) and (d), however, do just that." ></td>
	<td class="line x" title="159:188	Line (c) looks at the size of like(S)." ></td>
	<td class="line x" title="160:188	Since we are using a cutoff of 500 similar words computed per word in S, the size of like(S) can only vary if the same word is suggested as similar for several seen headwords in S. This way, the size of like(S) functions as an indicator of the degree of uniformity or similarity that a similarity metric perceives among the members of S. To facilitate comparison across frequency bands, line (c) normalizes by the size of S, showing |like(S)||S| micro-averaged over all roles." ></td>
	<td class="line x" title="161:188	Here we see that Cosine seems to perceive considerably less similarity among the seen headwords than any of the other metrics." ></td>
	<td class="line x" title="162:188	Line (d) looks at the sets s25(r) of the 25 most preferred potential headwords of roles r, showing the average size of the intersection s25(r)  s25(rprime) between two roles (preferences computed with uniform weights)." ></td>
	<td class="line x" title="163:188	It indicates another possible reason for Cosines problem: Cosine seems to keep proposing the same words as similar for different roles." ></td>
	<td class="line x" title="164:188	We will see this tendency also in the sample results we discuss next." ></td>
	<td class="line x" title="165:188	Sample results." ></td>
	<td class="line x" title="166:188	Table 6 shows samples of headwords induced by the similarity-based model for two FrameNet senses of the verb take: Ride vehicle (take the bus) and Ingest substance (take drugs), a semantic class that is exclusively about ingesting controlled substances." ></td>
	<td class="line x" title="167:188	The semantic role Vehicle of the Ride vehicle frame and the role Substance of Ingest substance are both typically realized as the direct object of take." ></td>
	<td class="line x" title="168:188	The table only shows new induced headwords; seen headwords were omitted from the list." ></td>
	<td class="line x" title="169:188	The particular implementation of the similarity-based model we have chosen, using frames and roles as predicates and arguments in the primary corpus, should enable the model to compute preferences specific to word senses." ></td>
	<td class="line x" title="170:188	The sample in Table 6 shows that this is indeed the case: The preferences differ considerably for the two senses (frames) of take, at least for the Jaccard metric, which shows a clear preference for vehicles for the Vehicle role." ></td>
	<td class="line x" title="171:188	The Substance role of Ingest substance is harder to characterize, with very diverse seen headwords such as crack, lines, fluid, speed." ></td>
	<td class="line x" title="172:188	While the highest-ranked induced words for Jaccard do include three food items, there is no word, with the possible exception of ice cream, that could be construed as a controlled substance." ></td>
	<td class="line x" title="173:188	The induced headwords for the Cosine metric are considerably less pertinent for both roles and show the above-mentioned tendency to repeat some high-frequency words." ></td>
	<td class="line x" title="174:188	The inspection of take anecdotally confirms that different selectional preferences are learned for different senses." ></td>
	<td class="line x" title="175:188	This point (which comes down to the usability of selectional preferences for WSD) should be verified in an empirical evaluation, possibly in another pseudodisambiguation task, choosing as confounders seen headwords for other senses of a predicate word." ></td>
	<td class="line x" title="176:188	6 Conclusion We have introduced the similarity-based model for inducing selectional preferences." ></td>
	<td class="line x" title="177:188	Computing selectional preference as a weighted sum of similarities to seen headwords, it is a straight222 forward implementation of the idea of generalization from seen headwords to other, similar words." ></td>
	<td class="line x" title="178:188	The similarity-based model is particularly simple and easy to compute, and seems not very sensitive to parameters." ></td>
	<td class="line x" title="179:188	Like the EM-based clustering model, it is not dependent on lexical resources." ></td>
	<td class="line x" title="180:188	It is, however, more flexible in that it induces similarities from a separate generalization corpus, which allows us to control the similarities we compute by the choice of text domain for the generalization corpus." ></td>
	<td class="line x" title="181:188	In this paper we have used the model to compute sense-specific selectional preferences for semantic roles." ></td>
	<td class="line x" title="182:188	In a pseudo-disambiguation task the similarity-based model showed error rates down to 0.16, far lower than both EM-based clustering and Resniks WordNet model." ></td>
	<td class="line x" title="183:188	However its coverage is considerably lower than that of EMbased clustering, comparable to Resniks model." ></td>
	<td class="line x" title="184:188	The most probable reason for this is the sparsity of the underlying vector space." ></td>
	<td class="line x" title="185:188	The choice of similarity metric is critical in similarity-based models, with Jaccard and Lin achieving the best performance, and Cosine surprisingly bringing up the rear." ></td>
	<td class="line x" title="186:188	Next steps will be to test the similarity-based model in vivo, in an SRL task; to test the model in a WSD task; to evaluate the model on a primary corpus that is not semantically analyzed, for greater comparability to previous approaches; to explore other vector spaces to address the coverage issue; and to experiment on domain transfer, using an appropriate generalization corpus to induce selectional preferences for a domain different from that of the primary corpus." ></td>
	<td class="line x" title="187:188	This is especially relevant in view of the domain-dependence problem that SRL faces." ></td>
	<td class="line x" title="188:188	Acknowledgements Many thanks to Jason Baldridge, Razvan Bunescu, Stefan Evert, Ray Mooney, Ulrike and Sebastian Pado, and Sabine Schulte im Walde for helpful discussions." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P07-1057
Clustering Clauses for High-Level Relation Detection: An Information-theoretic Approach
Brody, Samuel;"></td>
	<td class="line x" title="1:202	Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 448455, Prague, Czech Republic, June 2007." ></td>
	<td class="line x" title="2:202	c2007 Association for Computational Linguistics Clustering Clauses for High-Level Relation Detection: An Information-theoretic Approach Samuel Brody School of Informatics University of Edinburgh s.brody@sms.ed.ac.uk Abstract Recently, there has been a rise of interest in unsupervised detection of highlevel semantic relations involving complex units, such as phrases and whole sentences." ></td>
	<td class="line x" title="3:202	Typically such approaches are faced with two main obstacles: data sparseness and correctly generalizing from the examples." ></td>
	<td class="line x" title="4:202	In this work, we describe the Clustered Clause representation, which utilizes information-based clustering and inter-sentence dependencies to create a simplified and generalized representation of the grammatical clause." ></td>
	<td class="line x" title="5:202	We implement an algorithm which uses this representation to detect a predefined set of high-level relations, and demonstrate our models effectiveness in overcoming both the problems mentioned." ></td>
	<td class="line x" title="6:202	1 Introduction The semantic relationship between words, and the extraction of meaning from syntactic data has been one of the main points of research in the field of computational linguistics (see Section 5 and references therein)." ></td>
	<td class="line x" title="7:202	Until recently, the focus has remained largely either at the single word or sentence level (for instance: dependency extraction, word-to-word semantic similarity from syntax, etc)." ></td>
	<td class="line x" title="8:202	or on relations between units at a very high context level such as the entire paragraph or document (e.g. categorizing documents by topic)." ></td>
	<td class="line x" title="9:202	Recently there have been several attempts to define frameworks for detecting and studying interactions at an intermediate context level, and involving whole clauses or sentences." ></td>
	<td class="line x" title="10:202	Dagan et al.(2005) have emphasized the importance of detecting textual-entailment/implication between two sentences, and its place as a key component in many real-world applications, such as Information Retrieval and Question Answering." ></td>
	<td class="line x" title="12:202	When designing such a framework, one is faced with several obstacles." ></td>
	<td class="line x" title="13:202	As we approach higher levels of complexity, the problem of defining the basic units we study (e.g. words, sentences etc)." ></td>
	<td class="line x" title="14:202	and the increasing amount of interactions make the task very difficult." ></td>
	<td class="line x" title="15:202	In addition, the data sparseness problem becomes more acute as the data units become more complex and have an increasing number of possible values, despite the fact that many of these values have similar or identical meaning." ></td>
	<td class="line x" title="16:202	In this paper we demonstrate an approach to solving the complexity and data sparseness problems in the task of detecting relations between sentences or clauses." ></td>
	<td class="line x" title="17:202	We present the Clustered Clause structure, which utilizes information-based clustering and dependencies within the sentence to create a simplified and generalized representation of the grammatical clause and is designed to overcome both these problems." ></td>
	<td class="line x" title="18:202	The clustering method we employ is an integral part of the model." ></td>
	<td class="line x" title="19:202	We evaluate our clusters against semantic similarity measures defined on the human-annotated WordNet structure (Fellbaum, 1998)." ></td>
	<td class="line x" title="20:202	The results of these comparisons show that our cluster members are very similar semantically." ></td>
	<td class="line x" title="21:202	We also define a high-level relation detection task involving relations between clauses, evaluate our results, and demonstrate 448 the effectiveness of using our model in this task." ></td>
	<td class="line x" title="22:202	This work extends selected parts of Brody (2005), where further details can be found." ></td>
	<td class="line x" title="23:202	2 Model Construction When designing our framework, we must address the complexity and sparseness problems encountered when dealing with whole sentences." ></td>
	<td class="line x" title="24:202	Our solution to these issues combines two elements." ></td>
	<td class="line x" title="25:202	First, to reduce complexity, we simplify a grammatical clause to its primary components the subject, verb and object." ></td>
	<td class="line x" title="26:202	Secondly, to provide a generalization framework which will enable us to overcome data-sparseness, we cluster each part of the clause using data from within the clause itself." ></td>
	<td class="line x" title="27:202	By combining the simplified clause structure and the clustering we produce our Clustered Clause model a triplet of clusters representing a generalized clause." ></td>
	<td class="line x" title="28:202	The Simplified Clause: In order to extract clauses from the text, we use Lins parser MINIPAR (Lin, 1994)." ></td>
	<td class="line x" title="29:202	The output of the parser is a dependency tree of each sentence, also containing lemmatized versions of the component words." ></td>
	<td class="line x" title="30:202	We extract the verb, subject and object of every clause (including subordinate clauses), and use this triplet of values, the simplified clause, in place of the original complete clause." ></td>
	<td class="line x" title="31:202	As seen in Figure 1, these components make up the top (root) triangle of the clause parse tree." ></td>
	<td class="line x" title="32:202	We also use the lemmatized form of the words provided by the parser, to further reduce complexity." ></td>
	<td class="line x" title="33:202	Figure 1: The parse tree for the sentence John found a solution to the problem." ></td>
	<td class="line x" title="34:202	The subjectverb-object triplet is marked with a border." ></td>
	<td class="line x" title="35:202	Clustering Clause Components: For our model, we cluster the data to provide both generalization, by using a cluster to represent a more generalized concept shared by its component words, and a form of dimensionality reduction, by using fewer units (clusters) to represent a much larger amount of words." ></td>
	<td class="line x" title="36:202	We chose to use the Sequential Information Bottleneck algorithm (Slonim et al. , 2002) for our clustering tasks." ></td>
	<td class="line x" title="37:202	The information Bottleneck principle views the clustering task as an optimization problem, where the clustering algorithm attempts to group together values of one variable while retaining as much information as possible regarding the values of another (target) variable." ></td>
	<td class="line x" title="38:202	There is a trade-off between the compactness of the clustering and the amount of retained information." ></td>
	<td class="line x" title="39:202	This algorithm (and others based on the IB principle) is especially suited for use with graphical models or dependency structures, since the distance measure it employs in the clustering is defined solely by the dependency relation between two variables, and therefore required no external parameters." ></td>
	<td class="line x" title="40:202	The values of one variable are clustered using their cooccurrence distribution with regard to the values of the second (target) variable in the dependency relation." ></td>
	<td class="line x" title="41:202	As an example, consider the following subject-verb co-occurrence matrix: S \ V tell scratch drink dog 0 4 5 John 4 0 9 cat 0 6 3 man 6 1 2 The value in cell (i,j) indicates the number of times the noun i occurred as the subject of the verb j. Calculating the Mutual Information between the subjects variable (S) and verbs variable (V) in this table, we get MI(S,V) = 0.52 bits." ></td>
	<td class="line x" title="42:202	Suppose we wish to cluster the subject nouns into two clusters while preserving the highest Mutual Information with regard to the verbs." ></td>
	<td class="line x" title="43:202	The following co-occurrence matrix is the optimal clustering, and retains a M.I. value of 0.4 bits (77% of original): Clustered S \ V tell scratch drink {dog,cat} 0 10 8 {John,man} 10 1 11 Notice that although the values in the drink column are higher than in others, and we may be 449 tempted to cluster together dog and John based on this column, the informativeness of this verb is smaller if we know the verb is tell we can be sure the noun is not dog or cat, whereas if we know it is drink, we can only say it is slightly more probable that the noun is John or dog." ></td>
	<td class="line x" title="44:202	Our dependency structure consists of three variables: subject, verb, and object, and we take advantage of the subject-verb and verb-object dependencies in our clustering." ></td>
	<td class="line x" title="45:202	The clustering was performed on each variable separately, in a two phase procedure (see Figure 2)." ></td>
	<td class="line x" title="46:202	In the first stage, we clustered the subject variable into 200 clusters1, using the subject-verb dependency (i.e. the verb variable was the target)." ></td>
	<td class="line x" title="47:202	The same was done with the object variable, using the verb-object dependency." ></td>
	<td class="line x" title="48:202	In the second phase, we wish to cluster the verb values with regard to both the subject and object variables." ></td>
	<td class="line x" title="49:202	We could not use all pairs of subjects and objects values as the target variable in this task, since too many such combinations exist." ></td>
	<td class="line x" title="50:202	Instead, we used a variable composed of all the pairs of subject and object clusters as the target for the verb clustering." ></td>
	<td class="line x" title="51:202	In this fashion we produced 100 verb clusters." ></td>
	<td class="line x" title="52:202	Figure 2: The two clustering phases." ></td>
	<td class="line x" title="53:202	Arrows represent dependencies between the variables which are used in the clustering." ></td>
	<td class="line x" title="54:202	Combining the Model Elements: Having obtained our three clustered variables, our original simplified clause triplet can now be used to produce the Clustered Clause model." ></td>
	<td class="line x" title="55:202	This model represents a clause in the data by a triplet of cluster indexes, one cluster index for each clustered variable." ></td>
	<td class="line x" title="56:202	In order to map a clause in 1The chosen numbers of clusters are such that each the resulting clustered variables preserved approximately half of the co-occurrence mutual information that existed between the original (unclustered) variable and its target." ></td>
	<td class="line x" title="57:202	the text to its corresponding clustered clause, it is first parsed and lemmatized to obtain the subject, verb and object values, as described above, and then assigned to the clustered clause in which the subject cluster index is that of the cluster containing the subject word of the clause, and the same for the verb and object words." ></td>
	<td class="line x" title="58:202	For example, the sentence The terrorist threw the grenade would be converted to the triplet (terrorist, throw, grenade) and assigned to the clustered clause composed of the three clusters to which these words belong." ></td>
	<td class="line x" title="59:202	Other triplets assigned to this clustered clause might include (fundamentalist, throw, bomb) or (militant, toss, explosive)." ></td>
	<td class="line x" title="60:202	Applying this procedure to the entire text corpus results in a distillation of the text into a series of clustered clauses containing the essential information about the actions described in the text." ></td>
	<td class="line x" title="61:202	Technical Specifications: For this work we chose to use the entire Reuters Corpus (English, release 2000), containing 800,000 news articles collected uniformly from 20/8/1996 to 19/8/1997." ></td>
	<td class="line x" title="62:202	Before clustering, several preprocessing steps were taken." ></td>
	<td class="line x" title="63:202	We had a very large amount of word values for each of the Subject (85,563), Verb (4,593) and Object (74,842) grammatical categories." ></td>
	<td class="line x" title="64:202	Many of the words were infrequent proper nouns or rare verbs and were of little interest in the pattern recognition task." ></td>
	<td class="line x" title="65:202	We therefore removed the less frequent words those appearing in their category less than one hundred times." ></td>
	<td class="line x" title="66:202	We also cleaned our data by removing all words that were one letter in length, other than the word I." ></td>
	<td class="line x" title="67:202	These were mostly initials in names of people or companies, which were uninformative without the surrounding context." ></td>
	<td class="line x" title="68:202	This processing step brought us to the final count of 2,874,763 clause triplets (75.8% of the original number), containing 3,153 distinct subjects, 1,716 distinct verbs, and 3,312 distinct objects." ></td>
	<td class="line x" title="69:202	These values were clustered as described above." ></td>
	<td class="line x" title="70:202	The clusters were used to convert the simplified clauses into clustered clauses." ></td>
	<td class="line x" title="71:202	3 Evaluating Cluster Quality Examples of some of the resulting clusters are provided in Table 1." ></td>
	<td class="line x" title="72:202	When manually examin450 Technical Developements (Subject Cluster 160): treatment, drug, method, tactic, version, technology, software, design, device, vaccine, ending, tool, mechanism, technique, instrument, therapy, concept, model Ideals/Virtues (Object Cluster 14): sovereignty, dominance, logic, validity, legitimacy, freedom, discipline, viability, referendum, wisdom, innocence, credential, integrity, independence Emphasis Verbs (Verb Cluster 92): imply, signify, highlight, mirror, exacerbate, mark, signal, underscore, compound, precipitate, mask, illustrate, herald, reinforce, suggest, underline, aggravate, reflect, demonstrate, spell, indicate, deepen Plans (Object Cluster 33): journey, arrangement, trip, effort, attempt, revolution, pullout, handover, sweep, preparation, filing, start, play, repatriation, redeployment, landing, visit, push, transition, process Table 1: Example clusters (labeled manually)." ></td>
	<td class="line x" title="73:202	ing the clusters, we noticed the fine-tuning of some of the clusters." ></td>
	<td class="line x" title="74:202	For instance, we had a cluster of countries involved in military conflicts, and another for other countries; a cluster for winning game scores, and another for ties; etc. The fact that the algorithm separated these clusters indicates that the distinction between them is important with regard to the interactions within the clause." ></td>
	<td class="line x" title="75:202	For instance, in the first example, the context in which countries from the first cluster appear is very different from that involving countries in the second cluster." ></td>
	<td class="line x" title="76:202	The effect of the dependencies we use is also strongly felt." ></td>
	<td class="line x" title="77:202	Many clusters can be described by labels such as things that are thrown (rock, flower, bottle, grenade and others), or verbs describing attacks (spearhead, foil, intensify, mount, repulse and others)." ></td>
	<td class="line x" title="78:202	While such criteria may not be the first choice of someone who is asked to cluster verbs or nouns, they represent unifying themes which are very appropriate to pattern detection tasks, in which we wish to detect connections between actions described in the clauses." ></td>
	<td class="line x" title="79:202	For instance, we would like to detect the relation between throwing and military/police action (much of the throwing described in the news reports fits this relation)." ></td>
	<td class="line x" title="80:202	In order to do this, we must have clusters which unite the words relevant to those actions." ></td>
	<td class="line x" title="81:202	Other criteria for clustering would most likely not be suitable, since they would probably not put egg, bottle and rock in the same category." ></td>
	<td class="line x" title="82:202	In this respect, our clustering method provides a more effective modeling of the domain knowledge." ></td>
	<td class="line x" title="83:202	3.1 Evaluation via Semantic Resource Since the success of our pattern detection task depends to a large extent on the quality of our clusters, we performed an experiment designed to evaluate semantic similarity between members of our clusters." ></td>
	<td class="line x" title="84:202	For this purpose we made use of the WordNet Similarity package (Pedersen et al. , 2004)." ></td>
	<td class="line x" title="85:202	This package contains many similarity measures, and we selected three of them (Resnik (1995), Leacock and Chodorow (1997), Hirst and St-Onge (1997)), which make use of different aspects of WordNet (hierarchy and graph structure)." ></td>
	<td class="line x" title="86:202	We measured the average pairwise similarity between any two words appearing in the same cluster." ></td>
	<td class="line x" title="87:202	We then performed the same calculation on a random grouping of the words, and compared the two scores." ></td>
	<td class="line x" title="88:202	The results (Fig." ></td>
	<td class="line x" title="89:202	3) show that our clustering, based on co-occurrence statistics and dependencies within the sentence, correlates with a purely semantic similarity as represented by the WordNet structure, and cannot be attributed to chance." ></td>
	<td class="line x" title="90:202	Figure 3: Inter-cluster similarity (average pairwise similarity between cluster members) in our clustering (light) and a random one (dark)." ></td>
	<td class="line x" title="91:202	Random clustering was performed 10 times." ></td>
	<td class="line x" title="92:202	Average values are shown with error bars to indicate standard deviation." ></td>
	<td class="line x" title="93:202	Only Hirst & St-Onge measure verb similarity." ></td>
	<td class="line x" title="94:202	4 Relation Detection Task Motivation: In order to demonstrate the use of our model, we chose a relation detection task." ></td>
	<td class="line x" title="95:202	The workshop on entailment mentioned in the introduction was mainly focused on detecting whether or not an entailment relation exists between two texts." ></td>
	<td class="line x" title="96:202	In this work we present a com451 plementary approach a method designed to automatically detect relations between portions of text and generate a knowledge base of the detected relations in a generalized form." ></td>
	<td class="line x" title="97:202	As stated by (Dagan et al. , 2005), such relations are important for IR applications." ></td>
	<td class="line x" title="98:202	In addition, the patterns we employ are likely to be useful in other linguistic tasks involving whole clauses, such as paraphrase acquisition." ></td>
	<td class="line x" title="99:202	Pattern Definition: For our relation detection task, we searched for instances of predefined patterns indicating a relation between two clustered clauses." ></td>
	<td class="line x" title="100:202	We restricted the search to clause pairs which co-occur within a distance of ten clauses2 from each other." ></td>
	<td class="line x" title="101:202	In addition to the distance restriction, we required an anchor: a noun that appears in both clauses, to further strengthen the relation between them." ></td>
	<td class="line x" title="102:202	Noun anchors establish the fact that the two component actions described by the pattern involve the same entities, implying a direct connection between them." ></td>
	<td class="line x" title="103:202	The use of verb anchors was also tested, but found to be less helpful in detecting significant patterns, since in most cases it simply found verbs which tend to repeat themselves frequently in a context." ></td>
	<td class="line x" title="104:202	The method we describe assumes that statistically significant cooccurrences indicate a relationship between the clauses, but does not attempt to determine the type of relation." ></td>
	<td class="line x" title="105:202	Significance Calculation: The patterns detected by the system were scored using the statistical p-value measure." ></td>
	<td class="line x" title="106:202	This value represents the probability of detecting a certain number of occurrences of a given pattern in the data under the independence assumption, i.e. assuming there is no connection between the two halves of the pattern." ></td>
	<td class="line x" title="107:202	If the system has detected k instances of a certain pattern, we calculate the probability of encountering this number of instances under the independence assumption." ></td>
	<td class="line x" title="108:202	The smaller the probability, the higher the significance." ></td>
	<td class="line x" title="109:202	We consider patterns with a chance probability lower than 5% to be significant." ></td>
	<td class="line x" title="110:202	We assume a Gaussian-like distribution of oc2Our experiments showed that increasing the distance beyond this point did not result in significant increase in the number of detected patterns." ></td>
	<td class="line x" title="111:202	currence probability for each pattern3." ></td>
	<td class="line x" title="112:202	In order to estimate the mean and standard deviation values, we created 100 simulated sequences of triplets (representing clustered clauses) which were independently distributed and varied only in their overall probability of occurrence." ></td>
	<td class="line x" title="113:202	We then estimated the mean and standard deviation for any pair of clauses in the actual data using the simulated sequences." ></td>
	<td class="line x" title="114:202	(X,V C36,OC7) 10 (X,V C57,OC85) storm, lash, province storm, cross, Cuba quake, shake, city  quake, hit, Iran earthquake, jolt, city  earthquake, hit, Iran (X,V C40,OC165) 10 (X,V C52,OC152) police, arrest, leader  police, search, mosque police, detain, leader  police, search, mosque police, arrest, member  police, raid, enclave (SC39,V C21,X) 10 (X,beat 4,OC155) sun, report, earnings  earnings,beat,expectation xerox, report, earnings  earnings, beat, forecast microsoft,release,result  result, beat, forecast (X,V C57,OC7) 10 (X,cause 4,OC153) storm, hit, coast  storm, cause, damage cyclone, near, coast  cyclone, cause, damage earthquake,hit,northwest  earthquake,cause,damage quake, hit, northwest  quake, cause, casualty earthquake,hit,city  earthquake,cause,damage Table 2: Example Patterns 4.1 Pattern Detection Results In Table 2 we present several examples of high ranking (i.e. significance) patterns with different anchorings detected by our method." ></td>
	<td class="line x" title="115:202	The detected patterns are represented using the notation of the form (SCi,VCj,X) n (X,VCiprime,OCjprime)." ></td>
	<td class="line x" title="116:202	X indicates the anchoring word." ></td>
	<td class="line x" title="117:202	In the example notation, the anchoring word is the object of the first clause and the subject of the second (O-S for short)." ></td>
	<td class="line x" title="118:202	n indicates the maximal distance between the two clauses." ></td>
	<td class="line x" title="119:202	The terms SC, VC or OC with a subscripted index represent the cluster containing the subject, verb or object (respectively) of the appropriate clause." ></td>
	<td class="line x" title="120:202	For instance, in the first example in Table 2, VC36 indicates verb cluster no. 36, containing the verbs lash, shake and jolt, among others." ></td>
	<td class="line x" title="121:202	3Based on Gwadera et al.(2003), dealing with a similar, though simpler, case." ></td>
	<td class="line x" title="123:202	4In two of the patterns, instead of a cluster for the verb, we have a single word beat or cause." ></td>
	<td class="line x" title="124:202	This is the result of an automatic post-processing stage intended to prevent over-generalization." ></td>
	<td class="line x" title="125:202	If all the instances of the pat452 Anchoring Number of System Patterns Found Subject-Subject 428 Object-Object 291 Subject-Object 180 Object-Subject 178 Table 3: Numbers of patterns found (p < 5%) Table 3 lists the number of patterns found, for each anchoring system." ></td>
	<td class="line x" title="126:202	The different anchoring systems produce quantitatively different results." ></td>
	<td class="line x" title="127:202	Anchoring between the same categories produces more patterns than between the same noun in different grammatical roles." ></td>
	<td class="line x" title="128:202	This is expected, since many nouns can only play a certain part in the clause (for instance, many verbs cannot have an inanimate entity as their subject)." ></td>
	<td class="line x" title="129:202	The number of instances of patterns we found for the anchored template might be considered low, and it is likely that some patterns were missed simply because their occurrence probability was very low and not enough instances of the pattern occurred in the text." ></td>
	<td class="line x" title="130:202	In Section 4 we stated that in this task, we were more interested in precision than in recall." ></td>
	<td class="line x" title="131:202	In order to detect a wider range of patterns, a less restricted definition of the patterns, or a different significance indicator, should be used (see Sec." ></td>
	<td class="line x" title="132:202	6)." ></td>
	<td class="line x" title="133:202	Human Evaluation: In order to better determine the quality of patterns detected by our system, and confirm that the statistical significance testing is consistent with human judgment, we performed an evaluation experiment with the help of 22 human judges." ></td>
	<td class="line x" title="134:202	We presented each of the judges with 60 example groups, 15 for each type of anchoring." ></td>
	<td class="line x" title="135:202	Each example group contained three clause pairs conforming to the anchoring relation." ></td>
	<td class="line x" title="136:202	The clauses were presented in a normalized form consisting only of a subject, object and verb converted to past tense, with the addition of necessary determiners and prepositions." ></td>
	<td class="line x" title="137:202	For example, the triplet (police, detain, leader) was converted to The police detained the leader." ></td>
	<td class="line x" title="138:202	In half the cases (randomly tern in the text contained the same word in a certain position (in these examples the verb position in the second clause), this word was placed in that position in the generalized pattern, rather than the cluster it belonged to." ></td>
	<td class="line x" title="139:202	Since we have no evidence for the fact that other words in the cluster can fit that position, using the cluster indicator would be over-generalizing." ></td>
	<td class="line x" title="140:202	selected), these clause pairs were actual examples (instances) of a pattern detected by our system (instances group), such as those appearing in Table 2." ></td>
	<td class="line x" title="141:202	In the other half, we listed three clause pairs, each of which conformed to the anchoring specification listed in Section 4, but which were randomly sampled from the data, and so had no connection to one another (baseline group)." ></td>
	<td class="line x" title="142:202	We asked the judges to rate on a scale of 1-5 whether they thought the clause pairs were a good set of examples of a common relation linking the first clause in each pair to the second one." ></td>
	<td class="line x" title="143:202	Instances Instances Baseline Baseline Score StdDev Score StdDev All 3.5461 0.4780 2.6341 0.4244 O-S 3.9266 0.6058 2.8761 0.5096 O-O 3.4938 0.5144 2.7464 0.6205 S-O 3.4746 0.7340 2.5758 0.6314 S-S 3.2398 0.4892 2.3584 0.5645 Table 4: Results for human evaluation Table 4 reports the overall average scores for baseline and instances groups, and for each of the four anchoring types individually." ></td>
	<td class="line x" title="144:202	The scores were averaged over all examples and all judges." ></td>
	<td class="line x" title="145:202	An ANOVA showed the difference in scores between the baseline and instance groups to be significant (p < 0.001) in all four cases." ></td>
	<td class="line x" title="146:202	Achievement of Model Goals: We employed clustering in our model to overcome datasparseness." ></td>
	<td class="line x" title="147:202	The importance of this decision was evident in our results." ></td>
	<td class="line x" title="148:202	For example, the second pattern shown in Table 2 appeared only four times in the text." ></td>
	<td class="line x" title="149:202	In these instances, verb cluster 40 was represented twice by the verb arrest and twice by detain." ></td>
	<td class="line x" title="150:202	Two appearances are within the statistical deviation of all but the rarest words, and would not have been detected as significant without the clustering effect." ></td>
	<td class="line x" title="151:202	This means the pattern would have been overlooked, despite the strongly intuitive connection it represents." ></td>
	<td class="line x" title="152:202	The system detected several such patterns." ></td>
	<td class="line x" title="153:202	The other reason for clustering was generalization." ></td>
	<td class="line x" title="154:202	Even in cases where patterns involving single words could have been detected, it would have been impossible to unify similar patterns into generalized ones." ></td>
	<td class="line x" title="155:202	In addition, when encountering a new clause which differs slightly from 453 the ones we recognized in the original data, there would be no way to recognize it and draw the appropriate conclusions." ></td>
	<td class="line x" title="156:202	For example, there would be no way to relate the sentence The typhoon approached the coast to the fourth example pattern, and the connection with the resulting damage would not be recognized." ></td>
	<td class="line x" title="157:202	5 Comparison with Previous Work The relationship between textual features and semantics and the use of syntax as an indicator of semantics has been widespread." ></td>
	<td class="line x" title="158:202	Following the idea proposed in Harris Distributional Hypothesis (Harris, 1985), that words occurring in similar contexts are semantically similar, many works have used different definitions of context to identify various types of semantic similarity." ></td>
	<td class="line oc" title="159:202	Hindle (1990) uses a mutual-information based metric derived from the distribution of subject, verb and object in a large corpus to classify nouns." ></td>
	<td class="line x" title="160:202	Pereira et al.(1993) cluster nouns according to their distribution as direct objects of verbs, using information-theoretic tools (the predecessors of the tools we use in this work)." ></td>
	<td class="line x" title="162:202	They suggest that information theoretic measures can also measure semantic relatedness." ></td>
	<td class="line n" title="163:202	These works focus only on relatedness of individual words and do not describe how the automatic estimation of semantic similarity can be useful in real-world tasks." ></td>
	<td class="line x" title="164:202	In our work we demonstrate that using clusters as generalized word units helps overcome the sparseness and generalization problems typically encountered when attempting to extract high-level patterns from text, as required for many applications." ></td>
	<td class="line x" title="165:202	The DIRT system (Lin and Pantel, 2001) deals with inference rules, and employs the notion of paths between two nouns in a sentences parse tree." ></td>
	<td class="line x" title="166:202	The system extracts such path structures from text, and provides a similarity measure between two such paths by comparing the words which fill the same slots in the two paths." ></td>
	<td class="line x" title="167:202	After extracting the paths, the system finds groups of similar paths." ></td>
	<td class="line x" title="168:202	This approach bears several similarities to the ideas described in this paper, since our structure can be seen as a specific path in the parse tree (probably the most basic one, see Fig." ></td>
	<td class="line x" title="169:202	1)." ></td>
	<td class="line x" title="170:202	In our setup, similar clauses are clustered together in the same Clustered-Clause, which could be compared to clustering DIRTs paths using its similarity measure." ></td>
	<td class="line x" title="171:202	Despite these similarities, there are several important differences between the two systems." ></td>
	<td class="line x" title="172:202	Our method uses only the relationships inside the path or clause in the clustering procedure, so the similarity is based on the structure itself." ></td>
	<td class="line x" title="173:202	Furthermore, Lin and Pantel did not create path clusters or generalized paths, so that while their method allowed them to compare phrases for similarity, there is no convenient way to identify high level contextual relationships between two nearby sentences." ></td>
	<td class="line x" title="174:202	This is one of the significant advantages that clustering has over similarity measures it allows a group of similar objects to be represented by a single unit." ></td>
	<td class="line x" title="175:202	There have been several attempts to formulate and detect relationships at a higher context level." ></td>
	<td class="line x" title="176:202	The VerbOcean project (Chklovski and Pantel, 2004) deals with relations between verbs." ></td>
	<td class="line x" title="177:202	It presents an automatically acquired network of such relations, similar to the WordNet framework." ></td>
	<td class="line x" title="178:202	Though the patterns used to acquire the relations are usually parts of a single sentence, the relationships themselves can also be used to describe connections between different sentences, especially the enablement and happensbefore relations." ></td>
	<td class="line x" title="179:202	Since verbs are the central part of the clause, VerbOcean can be viewed as detecting relations between clauses as whole units, as well as those between individual words." ></td>
	<td class="line x" title="180:202	As a solution to the data sparseness problem, web queries are used." ></td>
	<td class="line x" title="181:202	Torisawa (2006) addresses a similar problem, but focuses on temporal relations, and makes use of the phenomena of Japanese coordinate sentences." ></td>
	<td class="line x" title="182:202	Neither of these approaches attempt to create generalized relations or group verbs into clusters, though in the case of VerbOcean this could presumably be done using the similarity and strength values which are defined and detected by the system." ></td>
	<td class="line x" title="183:202	6 Future Work The clustered clause model presents many directions for further research." ></td>
	<td class="line x" title="184:202	It may be productive to extend the model further, and include other parts of the sentence, such as adjectives 454 and adverbs." ></td>
	<td class="line x" title="185:202	Clustering nouns by the adjectives that describe them may provide a more intuitive grouping." ></td>
	<td class="line x" title="186:202	The addition of further elements to the structure may also allow the detection of new kinds of relations." ></td>
	<td class="line x" title="187:202	The news-oriented domain of the corpus we used strongly influenced our results." ></td>
	<td class="line x" title="188:202	If we were interested in more mundane relations, involving day-to-day actions of individuals, a literary corpus would probably be more suitable." ></td>
	<td class="line x" title="189:202	In defining our pattern template, several elements were tailored specifically to our task." ></td>
	<td class="line x" title="190:202	We limited ourselves to a very restricted set of patterns in order to better demonstrate the effectiveness of our model." ></td>
	<td class="line x" title="191:202	For a more general knowledge acquisition task, several of these restrictions may be relaxed, allowing a much larger set of relations to be detected." ></td>
	<td class="line x" title="192:202	For example, a less strict significance filter, such as the support and confidence measures commonly used in data mining, may be preferable." ></td>
	<td class="line x" title="193:202	These can be set to different thresholds, according to the users preference." ></td>
	<td class="line x" title="194:202	In our current work, in order to prevent overgeneralization, we employed a single step postprocessing algorithm which detected the incorrect use of an entire cluster in place of a single word (see footnote for Table 2)." ></td>
	<td class="line x" title="195:202	This method allows only two levels of generalization single words and whole clusters." ></td>
	<td class="line x" title="196:202	A more appropriate way to handle generalization would be to use a hierarchical clustering algorithm." ></td>
	<td class="line x" title="197:202	The Agglomerative Information Bottleneck (Slonim and Tishby, 1999) is an example of such an algorithm, and could be employed for this task." ></td>
	<td class="line x" title="198:202	Use of a hierarchical method would result in several levels of clusters, representing different levels of generalization." ></td>
	<td class="line x" title="199:202	It would be relatively easy to modify our procedure to reduce generalization to the level indicated by the pattern examples in the text, producing a more accurate description of the patterns detected." ></td>
	<td class="line x" title="200:202	Acknowledgments The author acknowledges the support of EPSRC grant EP/C538447/1." ></td>
	<td class="line x" title="201:202	The author would like to thank Naftali Tishby and Mirella Lapata for their supervision and assistance on large portions of the work presented here." ></td>
	<td class="line x" title="202:202	I would also like to thank the anonymous reviewers and my friends and colleagues for their helpful comments." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="C08-1051
Using Hidden Markov Random Fields to Combine Distributional and Pattern-Based Word Clustering
Kaji, Nobuhiro;Kitsuregawa, Masaru;"></td>
	<td class="line x" title="1:191	Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 401408 Manchester, August 2008 Using Hidden Markov Random Fields to Combine Distributional and Pattern-based Word Clustering Nobuhiro Kaji and Masaru Kitsuregawa Institute of Industrial Science, University of Tokyo 4-6-1 Komaba, Meguro-ku, Tokyo 153-8505 Japan {kaji,kitsure}@tkl.iis.u-tokyo.ac.jp Abstract Word clustering is a conventional and important NLP task, and the literature has suggested two kinds of approaches to this problem." ></td>
	<td class="line x" title="2:191	One is based on the distributional similarity and the other relies on the co-occurrence of two words in lexicosyntactic patterns." ></td>
	<td class="line x" title="3:191	Although the two methods have been discussed separately, it is promising to combine them since they are complementary with each other." ></td>
	<td class="line x" title="4:191	This paper proposes to integrate them using hidden Markov random fields and demonstrates its effectiveness through experiments." ></td>
	<td class="line x" title="5:191	1 Introduction Word clustering is a technique of grouping similar words together, and it is important for various NLP systems." ></td>
	<td class="line x" title="6:191	Applications of word clustering include language modeling (Brown et al., 1992), text classification (Baker and McCallum, 1998), thesaurus construction (Lin, 1998) and so on." ></td>
	<td class="line x" title="7:191	Furthermore, recent studies revealed that word clustering is useful for semi-supervised learning in NLP (Miller et al., 2004; Li and McCallum, 2005; Kazama and Torisawa, 2008; Koo et al., 2008)." ></td>
	<td class="line x" title="8:191	A well-known approach to grouping similar words is to use distribution of contexts in which target words appear." ></td>
	<td class="line x" title="9:191	It is founded on the hypothesis that similar words tend to appear in similar contexts (Harris, 1968)." ></td>
	<td class="line x" title="10:191	Based on this idea, some studies proposed probabilistic models for word clustering (Pereira et al., 1993; Li and Abe, 1998; Rooth c2008." ></td>
	<td class="line x" title="11:191	Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/)." ></td>
	<td class="line x" title="12:191	Some rights reserved." ></td>
	<td class="line x" title="13:191	et al., 1999; Torisawa, 2002)." ></td>
	<td class="line oc" title="14:191	Others proposed distributional similarity measures between words (Hindle, 1990; Lin, 1998; Lee, 1999; Weeds et al., 2004)." ></td>
	<td class="line x" title="15:191	Once such similarity is defined, it is trivial to perform clustering." ></td>
	<td class="line x" title="16:191	On the other hand, some researchers utilized co-occurrence for word clustering." ></td>
	<td class="line x" title="17:191	The idea behind it is that similar words tend to co-occur in certain patterns." ></td>
	<td class="line x" title="18:191	Considerable efforts have been devoted to measure word similarity based on cooccurrence frequency of two words in a window (Church and Hanks, 1989; Turney, 2001; Terra and Clarke, 2003; Matsuo et al., 2006)." ></td>
	<td class="line x" title="19:191	In addition to the classical window-based technique, some studies investigated the use of lexico-syntactic patterns (e.g., X or Y) to get more accurate co-occurrence statistics (Chilovski and Pantel, 2004; Bollegala et al., 2007)." ></td>
	<td class="line x" title="20:191	These two approaches are complementary with each other, because they are founded on different hypotheses and utilize different corpus statistics." ></td>
	<td class="line x" title="21:191	Consider to cluster a set of words based on the distributional similarity." ></td>
	<td class="line x" title="22:191	It is likely that some words are difficult to cluster due to the data sparseness or some other problems, while we can still expect that those words are correctly classified using patterns." ></td>
	<td class="line x" title="23:191	This consideration leads us to combine distributional and pattern-based word clustering." ></td>
	<td class="line x" title="24:191	In this paper we propose to combine them using mixture models based on hidden Markov random fields." ></td>
	<td class="line x" title="25:191	This model was originally proposed by (Basu et al., 2004) for semi-supervised clustering." ></td>
	<td class="line x" title="26:191	In semisupervised clustering, the system is provided with supervision in the form of pair-wise constraints specifying data points that are likely to belong to the same cluster." ></td>
	<td class="line x" title="27:191	These constraints are directly incorporated into the clustering process as a prior knowledge." ></td>
	<td class="line x" title="28:191	Our idea is to view the co-occurrence 401 of two words in lexico-syntactic patterns as constraints, and incorporate them into distributional word clustering." ></td>
	<td class="line x" title="29:191	In summary, this paper discusses the problem of integrating multiple approaches for word clustering." ></td>
	<td class="line x" title="30:191	We consider that the clustering results are improved if multiple approaches are successfully combined and if they are complementary with each other." ></td>
	<td class="line x" title="31:191	Our contribution is to provide a probabilistic framework for this problem." ></td>
	<td class="line x" title="32:191	Although our proposal aims at combining the distributional and pattern-based approaches, it is also applicable to combine other approaches like (Lin et al., 2003), as we will discuss in Section 5.4." ></td>
	<td class="line x" title="33:191	2 Distributional Clustering This and next section describe distributional and pattern-based word clustering respectively." ></td>
	<td class="line x" title="34:191	Section 4 will explain how to combine them." ></td>
	<td class="line x" title="35:191	2.1 Probabilistic model In distributional word clustering, similarity between words (= nouns) is measured by the distribution of contexts in which they appear." ></td>
	<td class="line x" title="36:191	As a context, verbs that appear in certain grammatical relations with the target nouns are typically used." ></td>
	<td class="line x" title="37:191	Using the distribution of such verbs, we can express a noun n by a feature vector (n): (n)=(f nv 1 ,f nv 2 ,f nv V ) where f nv i denotes the frequency of noun-verb pair (n,v i ), and V denotes the number of distinct verbs." ></td>
	<td class="line x" title="38:191	The basic idea of using the distribution for clustering is to group n and n prime together if (n) and (n prime ) are similar." ></td>
	<td class="line x" title="39:191	Let us consider a soft clustering model." ></td>
	<td class="line x" title="40:191	We hypothesize that (n) is a mixture of multinomial, and the probability of n is defined by 1 p(n)= Z summationdisplay z=1 p(z)p((n)|z) = Z summationdisplay z=1  z f n ! producttext v f nv ! productdisplay v  f nv vz where Z is the number of mixture components,  z is the mixing coefficient ( summationtext z  z =1), f n = summationtext v f nv is the total number of occurrence of n, and 1 We ignored p(f n ) by assuming that it is independent of hidden variables." ></td>
	<td class="line x" title="41:191	See (McCallum and Nigam, 1998) for detail discussion." ></td>
	<td class="line x" title="42:191	 vz is the parameter of the multinomial distribution ( summationtext v  vz =1)." ></td>
	<td class="line x" title="43:191	In this model the hidden variables can be interpreted as semantic class of nouns." ></td>
	<td class="line x" title="44:191	Now consider a set of nouns n = {n i } N i=1 . Let z = {z i } N i=1 be a set of hidden variables corresponding to n. Assuming that the hidden variables are independent and n i is also independent of other nouns given the hidden variables, the probability of n is defined by p(n)= summationdisplay z p(z)p(n|z) where p(z)= N productdisplay i=1 p(z i ) p(n|z)= N productdisplay i=1 p(n i |z i )." ></td>
	<td class="line x" title="45:191	Hereafter, we use p(n|z) instead of p((n)|z) to keep the notation simple." ></td>
	<td class="line x" title="46:191	p(n|z) is the conditional distribution on all nouns given all the hidden variables, and p(z) is the prior distribution on the hidden variables." ></td>
	<td class="line x" title="47:191	Computing the log-likelihood of the complete data (n,z), we found log p(n,z)= N summationdisplay i=1 log p(z i )p(n i |z i )." ></td>
	<td class="line x" title="48:191	(1) 2.2 Parameter estimation The parameters can be estimated by the EM algorithm." ></td>
	<td class="line x" title="49:191	In the E-step, p(z i |n i ) is computed based on current parameters." ></td>
	<td class="line x" title="50:191	It is computed by p(z i = k|n i )= p(z i = k)p(n i |z i = k) summationtext z p(z)p(n i |z) =  k producttext v  f n i v vk summationtext z  z producttext v  f n i v vz . In the M-step, the parameters are re-estimated by using the result of the E-step:  k =  + summationtext i f n i  p(z i = k|n i ) V + summationtext v summationtext i f n i v p(z i = k|n i )  k =  + summationtext i p(z i = k|n i ) Z + summationtext z summationtext i p(z i = z|n i ) where  is a smoothing factor." ></td>
	<td class="line x" title="51:191	2 Both steps are repeated until a convergence criteria is satisfied." ></td>
	<td class="line x" title="52:191	The important point to note is that the E-step can be computed using the above equation because the hidden variables are independent." ></td>
	<td class="line x" title="53:191	2 =1.0 in our experiment." ></td>
	<td class="line x" title="54:191	402 X ya YXmo Y mo X to Y to X, Y nado (X or Y) (X and Y) (X and Y) (X, Y etc.) Table 1: Four lexico-syntactic patterns, where X and Y are extracted as co-occurring words." ></td>
	<td class="line x" title="55:191	Note that ya, mo, and to are Japanese postpositions, and they correspond to or or and in English." ></td>
	<td class="line x" title="56:191	3 Pattern-based Clustering A graph-based algorithm was employed in order to cluster words using patterns." ></td>
	<td class="line x" title="57:191	3.1 Graph Construction We first construct the graph in which vertices and edges correspond to words and their cooccurrences in patterns respectively (Figure 1)." ></td>
	<td class="line x" title="58:191	We employed four lexico-syntactic patterns (Table 1) to extract co-occurrence of two words from corpus." ></td>
	<td class="line x" title="59:191	Note that we target Japanese in this paper although our proposal is independent of languages." ></td>
	<td class="line x" title="60:191	The edges are weighted by the strength of cooccurrence that is computed by the Point-wise Mutual Information (PMI): PMI(n i ,n j )=log f(n i ,n j )f(,) f(n i ,)f(,n j ) where f(n i ,n j ) is the co-occurrence frequency of two nouns, and  means summation over all nouns." ></td>
	<td class="line x" title="61:191	If PMI is less than zero, the edge is removed." ></td>
	<td class="line x" title="62:191	3.2 Graph Partitioning Assuming that similar words tend to co-occur in the lexico-syntactic patterns, it is reasonable to consider that a dense subgraph is a good cluster (Figure 1)." ></td>
	<td class="line x" title="63:191	Following (Matsuo et al., 2006), we exploit the Newman clustering (Newman, 2004) to partition the graph into such dense subgraphs." ></td>
	<td class="line x" title="64:191	We start by describing Newmans algorithm for unweighted graphs and we will generalize it to weighted graphs later." ></td>
	<td class="line x" title="65:191	The Newman clustering is an algorithm that divides a graph into subgraphs based on connectivity." ></td>
	<td class="line x" title="66:191	Roughly speaking, it divides a graph such that there are a lot of edges between vertices in the same cluster." ></td>
	<td class="line x" title="67:191	In the algorithm goodness of clustering is measured by score Q: Q = summationdisplay i parenleftBig e ii  a 2 i parenrightBig ramen dumpling pasta steak Japan U.S.A. Germany China France Figure 1: An example of the graph consisting of two dense subgraphs." ></td>
	<td class="line x" title="68:191	where e ij = # of edges between two vertices in cluster i and j # of all edges a i = summationdisplay k e ik . The term e ij is the fraction of edges between cluster i and j. a i is the sum of e ik over all clusters, and a 2 i represents the expected number of fraction of edges within the cluster i when edges are given at random." ></td>
	<td class="line x" title="69:191	See (Newman, 2004) for the detail." ></td>
	<td class="line x" title="70:191	The Newman clustering optimizes Q in an agglomerative fashion." ></td>
	<td class="line x" title="71:191	At the beginning of the algorithm every vertex forms a singleton cluster, and we repeatedly merge two clusters so that the join results in the largest increase in Q. The change in Q when cluster i and j are merged is given by Q = e ij + e ji  2a i a j =2(e ij  a i a j )." ></td>
	<td class="line x" title="72:191	The above procedure is repeated until Q reaches local maximum." ></td>
	<td class="line x" title="73:191	The algorithm can be easily generalized to weighted graphs by substituting sum of weights of edges for # of edges in the definition of e ij . The other part of the algorithm remains the same." ></td>
	<td class="line x" title="74:191	4 Integration based on Hidden Markov Random Fields This section represents how to integrate the distribution and pattern for word clustering." ></td>
	<td class="line x" title="75:191	4.1 Background and idea Clustering has long been discussed as an unsupervised learning problem." ></td>
	<td class="line x" title="76:191	In some applications, however, it is possible to provide some form of supervision by hand in order to improve the clustering result." ></td>
	<td class="line x" title="77:191	This motivated researchers to investigate semi-supervised clustering, which uses not only unlabeled data but supervision in the form of pair-wise constraints (Basu et al., 2004)." ></td>
	<td class="line x" title="78:191	In this 403 framework, the clustering system is provided with a set of pair-wise constraints specifying data points that are likely to belong to the same cluster." ></td>
	<td class="line x" title="79:191	These constraints are directly incorporated into the clustering process as a prior knowledge." ></td>
	<td class="line x" title="80:191	Our idea is to view the co-occurrence of two words in lexico-syntactic patterns as constraints, and incorporate them into the distributional clustering." ></td>
	<td class="line x" title="81:191	The rest of this section describes how to extend the distributional clustering so as to incorporate the constraints, and how to generate the constraints using the patterns." ></td>
	<td class="line x" title="82:191	4.2 Probabilistic model Let C be a set of pair-wise constraints, and consider to incorporate the constraints into the distributional clustering (Section 2)." ></td>
	<td class="line x" title="83:191	In what follows we assume each constraint i,jC represents that z i and z j are likely to have the same value, and it is associated with a weight w ij (> 0) corresponding to a penalty for constraint violation." ></td>
	<td class="line x" title="84:191	It is easy to extend the distributional clustering algorithm so as to incorporate the constraints." ></td>
	<td class="line x" title="85:191	This is done by just changing the prior distribution on hidden variables p(z)." ></td>
	<td class="line x" title="86:191	Following (Basu et al., 2004), we construct the Markov random field on the hidden variables so as to incorporate the constraints." ></td>
	<td class="line x" title="87:191	The new prior distribution is defined as p(z)= N productdisplay i=1 p(z i )  1 G exp{ summationdisplay i,jC (z i negationslash= z j )w ij } where () is the delta function." ></td>
	<td class="line x" title="88:191	(z i negationslash= z j ) takes one if the constraint i,j is violated and otherwise zero." ></td>
	<td class="line x" title="89:191	G is the normalization factor of the Markov random field (the second term)." ></td>
	<td class="line x" title="90:191	By examining the log-likelihood of the complete data, we can see how violation of constraints is penalized." ></td>
	<td class="line x" title="91:191	Using the new prior distribution, we get log p(n,z)= N summationdisplay i=1 log p(z i )p(n i |z i )  summationdisplay i,jC (z i negationslash= z j )w ij  log G. The first term in the right-hand side is equal to the log-likelihood of the multinomial mixture, namely equation (1)." ></td>
	<td class="line x" title="92:191	The second term can be interpreted as the penalty for constraint violation." ></td>
	<td class="line x" title="93:191	The last term is a constant." ></td>
	<td class="line x" title="94:191	It is worth pointing out that the resulting algorithm makes a soft assignment and polysemous words can belong to more than one clusters." ></td>
	<td class="line x" title="95:191	4.3 Parameter estimation The parameters are estimated by the EM algorithm." ></td>
	<td class="line x" title="96:191	The M-step is exactly the same as discussed in Section 2.2." ></td>
	<td class="line x" title="97:191	The problem is that the hidden variables are no longer independent and the E-step requires the calculation of p(z i |n)= summationdisplay z i p(z i ,z i |n)  summationdisplay z i p(z i ,z i )p(n|z i ,z i ) where z i means all hidden variables but z i . The computation of the above equation is intractable because the summation in it requires O(Z N1 ) operations." ></td>
	<td class="line x" title="98:191	Instead of exactly computing p(z i |n), we approximate it by using the mean field approximation (Lange et al., 2005)." ></td>
	<td class="line x" title="99:191	In the mean field approximation, p(z|n) is approximated by a factorized distribution q(z), in which all hidden variables are independent: q(z)= N productdisplay i=1 q i (z i )." ></td>
	<td class="line x" title="100:191	(2) Using q(z) instead of p(z|n), computation of the E-step can be written as follows: p(z i |n) similarequal summationdisplay z i q(z i ,z i )=q i (z i )." ></td>
	<td class="line x" title="101:191	(3) The parameters of q(z) are determined such that the KL divergence between q(z) and p(z|n) is minimized." ></td>
	<td class="line x" title="102:191	In other words, the approximate distribution q(z) is determined by minimizing summationdisplay z q(z)log q(z) p(z|n) (4) under the condition that summationtext k q i (z i = k)=1 for all i. This optimization problem can be resolved by introducing Lagrange multipliers." ></td>
	<td class="line x" title="103:191	Because we cannot get the solution in closed form, an iterative method is employed." ></td>
	<td class="line x" title="104:191	Taking the derivative of equation (4) with respect to a parameter q ik = q i (z i = k) and setting it to zero, we get the following updating formula: q (t+1) ik  p(n i ,k)exp{ summationdisplay jN i (1  q (t) jk )w ij } (5) 404 where N i = {j|i,jC} and q (t) ik is the value of q ik at t-th iteration." ></td>
	<td class="line x" title="105:191	The derivation of this formula is found in Appendix." ></td>
	<td class="line x" title="106:191	4.4 Generation of constraints It is often pointed out that even small amounts of misspecified constraints significantly decrease the performance of semi-supervised clustering." ></td>
	<td class="line x" title="107:191	This is because the error of misspecified constraints is propagated to the entire transitive neighborhoods of the constrained data (Nelson and Cohen, 2007)." ></td>
	<td class="line x" title="108:191	As an example, consider that we have two constraints i,j and j, k." ></td>
	<td class="line x" title="109:191	If the former is misspecified one, the error propagate to k through j. To tackle this problem, we propose a technique to put an upper bound  on the size of the transitive neighborhoods." ></td>
	<td class="line x" title="110:191	Our constraint generation process is as follows." ></td>
	<td class="line x" title="111:191	To begin with, we modified the Newman clustering so that the maximum cluster size does not exceed ." ></td>
	<td class="line x" title="112:191	This can be done by prohibiting such merge that results in larger cluster than ." ></td>
	<td class="line x" title="113:191	Given the result of the modified Newman clustering, it is straightforward to generate constraints." ></td>
	<td class="line x" title="114:191	Constraints are generated between two nouns in the same cluster if they co-occur in the lexicosyntactic patterns at least one time." ></td>
	<td class="line x" title="115:191	The penalty for constraint violation w ij was set to PMI(n i ,n j )." ></td>
	<td class="line x" title="116:191	This procedure obviously ensures that the size of the transitive neighborhoods is less than ." ></td>
	<td class="line x" title="117:191	5 Experiments 5.1 Data sets We parsed 15 years of news articles by KNP 3 so as to obtain data sets for the distributional and pattern-based word clustering (Table 2)." ></td>
	<td class="line x" title="118:191	The number of distinct nouns in total was 297,719." ></td>
	<td class="line x" title="119:191	Note that, due to the computational efficiency, we removed such nouns that appeared less than 10 times with verbs and did not appear at all in the patterns." ></td>
	<td class="line x" title="120:191	A test set was created using manually tailored Japanese thesaurus (Ikehara et al., 1997)." ></td>
	<td class="line x" title="121:191	We randomly selected 500 unambiguous nouns from 25 categories (20 words for each category)." ></td>
	<td class="line x" title="122:191	5.2 Baselines For comparison we implemented the following baseline systems." ></td>
	<td class="line x" title="123:191	 The multinomial mixture (Section 2)." ></td>
	<td class="line x" title="124:191	 The Newman clustering (Newman, 2004)." ></td>
	<td class="line x" title="125:191	3 http://nlp.kuee.kyoto-u.ac.jp/nl-resource/ nouns 208,934 verbs 64,954 noun-verb pairs 4,804,715 nouns 245,465 noun-noun pairs 633,302 Table 2: Data sets statistics." ></td>
	<td class="line x" title="126:191	The first and second row shows the number of distinct words (and word pairs) used for the distributional and pattern-based word clustering respectively." ></td>
	<td class="line x" title="127:191	 Three K-means algorithms using different distributional similarity or dissimilarity measures: cosine, -skew divergence (Lee, 1999) 4 , and Lins similarity (Lin, 1998)." ></td>
	<td class="line x" title="128:191	 The CBC algorithm (Lin and Pantel, 2002; Pantel and Lin, 2002)." ></td>
	<td class="line x" title="129:191	5.3 Evaluation procedure All the nouns in the data set were clustered by the proposed and baseline systems." ></td>
	<td class="line x" title="130:191	5 For the mixture models and K-means, the number of clusters was set to 1,000." ></td>
	<td class="line x" title="131:191	The parameter  was set to 100." ></td>
	<td class="line x" title="132:191	The result was assessed by precision and recall using the test data." ></td>
	<td class="line x" title="133:191	The precision and recall were computed by the B-CUBED algorithm as follows (Bagga and Baldwin, 1998)." ></td>
	<td class="line x" title="134:191	For each noun n i in the test data, precision i and recall i are defined as precision i = |S i  T i | |S i | recall i = |S i  T i | | T i | where S i is the system generated cluster containing n i and T i is the goldstandard cluster containing n i . The precision and recall are defined as an average of precision i and recall i for all the nouns in the test data respectively." ></td>
	<td class="line x" title="135:191	The result of soft clustering models cannot be directly evaluated by the precision and recall." ></td>
	<td class="line x" title="136:191	In such cases, each noun is assigned to the cluster that maximizes p(z|n)." ></td>
	<td class="line x" title="137:191	5.4 The result and discussion Table 3 shows the experimental results." ></td>
	<td class="line x" title="138:191	The best results for each statistic are shown in bold." ></td>
	<td class="line x" title="139:191	For the mixture models and K-means, the precision and recall are an average of 10 trials." ></td>
	<td class="line x" title="140:191	Table 3 demonstrates the impact of combining distribution and pattern." ></td>
	<td class="line x" title="141:191	Our method outperformed 4  = 0.99 in our experiment." ></td>
	<td class="line x" title="142:191	5 Our implementation is available from http://www.tkl.iis.u-tokyo.ac.jp/kaji/clustering." ></td>
	<td class="line x" title="143:191	405 PRF 1 proposed .383 .437 .408 multinomial mixture .360 .374 .367 Newman (2004) .318 .353 .334 cosine .603 .114 .192 -skew divergence (Lee, 1999) .730 .155 .255 Lins similarity (Lin, 1998) .691 .096 .169 CBC (Lin and Pantel, 2002) .981 .060 .114 Table 3: Precision, recall, and F-measure." ></td>
	<td class="line x" title="144:191	all the baseline systems." ></td>
	<td class="line x" title="145:191	It was statistically significantly better than the multinomial mixture (P < 0.01, Mann-Whitney U-test)." ></td>
	<td class="line x" title="146:191	Note that it is possible to improve some baseline systems, especially CBC, by tuning the parameters." ></td>
	<td class="line x" title="147:191	For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002)." ></td>
	<td class="line x" title="148:191	Compared with the multinomial mixture, one advantage of our method is that it has broad coverage." ></td>
	<td class="line x" title="149:191	Our method can successfully handle unknown words, which do not appear with verbs at all (i.e., f n =0and (n) is zero vector), if they co-occur with other words in the lexico-syntactic patterns." ></td>
	<td class="line x" title="150:191	For unknown words, the hidden variables are determined based only on p(z) because p(n|z) takes the same value for all hidden variables." ></td>
	<td class="line x" title="151:191	This means that our method clusters unknown words using pair-wise constraints." ></td>
	<td class="line x" title="152:191	On the other hand, the multinomial mixture assigns all the unknown words to the cluster that maximizes p(z)." ></td>
	<td class="line x" title="153:191	The test set included 51 unknown words." ></td>
	<td class="line x" title="154:191	6 We split the test set into two parts: f n =0and f n negationslash=0, and calculated precision and recall for each subset (Table 4)." ></td>
	<td class="line x" title="155:191	Although the improvement is especially significant for the unknown words, we can clearly confirm the improvement for both subsets." ></td>
	<td class="line x" title="156:191	For the Newman clustering we can discuss similar things (Table 5)." ></td>
	<td class="line x" title="157:191	Different from the Newman clustering, our method can handle nouns that do not co-occur with other nouns if 0 <f n . In this case the test set included 64 unknown words." ></td>
	<td class="line x" title="158:191	It is interesting to point out that our framework can further incorporate lexico-syntactic patterns for dissimilar words (Lin et al., 2003)." ></td>
	<td class="line x" title="159:191	Namely, we can use patterns so as to prevent distributionally similar but semantically different words (e.g., ally and supporter (Lin et al., 2003)) from being assigned to the same cluster." ></td>
	<td class="line x" title="160:191	This can be achieved by using cannot-link constraints, which specify data points that are likely to belong to different clus6 The baseline systems assigned the unknown words to a default cluster as the multinomial mixture does." ></td>
	<td class="line x" title="161:191	f n =0 f n negationslash=0 PRF 1 PRF 1 proposed .320 .632 .435 .412 .450 .430 multi." ></td>
	<td class="line x" title="162:191	.099 1.000 .181 .402 .394 .398 Table 4: Detail comparison with the multinomial mixture." ></td>
	<td class="line x" title="163:191	f(n i ,)=0 f(n i ,) negationslash=0 PRF 1 PRF 1 proposed .600 .456 .518 .380 .479 .424 Newman .071 1.000 .133 .354 .412 .381 Table 5: Detail comparison with the Newman clustering." ></td>
	<td class="line x" title="164:191	ters (Basu et al., 2004)." ></td>
	<td class="line x" title="165:191	The remaining problem is which patterns to use so as to extract dissimilar words." ></td>
	<td class="line x" title="166:191	Although this problem has already been discussed by (Lin et al., 2003), they mainly addressed antonyms." ></td>
	<td class="line x" title="167:191	We believe that a more exhaustive investigation is required." ></td>
	<td class="line x" title="168:191	In addition, it is still unclear whether dissimilar words are really useful to improve clustering results." ></td>
	<td class="line x" title="169:191	One problem that we did not examine is how to determine optimal number of clusters." ></td>
	<td class="line x" title="170:191	In the experiment, the number was decided with trial-anderror through our initial experiment." ></td>
	<td class="line x" title="171:191	We leave it as our future work to test methods of automatically determining the cluster number (Pedersen and Kulkarni, 2006; Blei and Jordan, 2006)." ></td>
	<td class="line x" title="172:191	6 Related work As far as we know, the distributional and patternbased word clustering have been discussed independently (e.g., (Pazienza et al., 2006))." ></td>
	<td class="line x" title="173:191	One of the most relevant work is (Bollegala et al., 2007), which proposed to integrate various patterns in order to measure semantic similarity between words." ></td>
	<td class="line x" title="174:191	Although they extensively discussed the use of patterns, they did not address the distributional approach." ></td>
	<td class="line x" title="175:191	Mirkin (2006) pointed out the importance of integrating distributional similarity and lexicosyntactic patterns, and showed how to combine the two approaches for textual entailment acquisition." ></td>
	<td class="line x" title="176:191	Although their work inspired our research, we discussed word clustering, which is related to but different from entailment acquisition." ></td>
	<td class="line x" title="177:191	Lin (2003) also proposed to use both distributional similarity and lexico-syntactic patterns for finding synonyms." ></td>
	<td class="line x" title="178:191	However, they present an opposite viewpoint from our research." ></td>
	<td class="line x" title="179:191	Their proposal is to exploit patterns in order to filter dissimilar 406 words." ></td>
	<td class="line x" title="180:191	As we have already discussed, the integration of such patterns can also be formalized using similar probabilistic model to ours." ></td>
	<td class="line x" title="181:191	A variety of studies discussed determining polarity of words." ></td>
	<td class="line x" title="182:191	Because this problem is ternary (positive, negative, and neutral) classification of words, it can be seen as one kind of word clustering." ></td>
	<td class="line x" title="183:191	The literature suggested two methods of determining polarity, and they are analogous to the distributional and co-occurrence-based approaches in word clustering (Takamura et al., 2005; Higashiyama et al., 2008)." ></td>
	<td class="line x" title="184:191	We consider it is also promising to integrate them for polarity determination." ></td>
	<td class="line x" title="185:191	7 Conclusion The distributional and pattern-based word clustering have long been discussed separately despite the potentiality for their integration." ></td>
	<td class="line x" title="186:191	In this paper, we provided a probabilistic framework for combining the two approaches, and demonstrated that the clustering result is significantly improved." ></td>
	<td class="line x" title="187:191	Our important future work is to extend current framework so as to incorporate patterns for dissimilar words using cannot-link constraints." ></td>
	<td class="line x" title="188:191	We consider such patterns further improve the clustering result." ></td>
	<td class="line x" title="189:191	Combining distribution and pattern is important for other NLP problems as well (e.g., entailment acquisition, polarity determination)." ></td>
	<td class="line x" title="190:191	Although this paper examined word clustering, we consider a part of our idea can be applied to other problems." ></td>
	<td class="line x" title="191:191	Acknowledgement This work was supported by the Comprehensive Development of e-Society Foundation Software program of the Ministry of Education, Culture, Sports, Science and Technology, Japan." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I08-1060
Bilingual Synonym Identification with Spelling Variations
Tsunakawa, Takashi;Tsujii, Jun'ichi;"></td>
	<td class="line x" title="1:163	Bilingual Synonym Identication with Spelling Variations Takashi Tsunakawa Junichi Tsujiiyz Department of Computer Science, Graduate School of Information Science and Technology, University of Tokyo 7-3-1, Hongo, Bunkyo-ku, Tokyo, 113-0033 Japan ySchool of Computer Science, University of Manchester Oxford Road, Manchester, M13 9PL, UK zNational Centre for Text Mining 131 Princess Street, Manchester, M1 7DN, UK {tuna, tsujii}@is.s.u-tokyo.ac.jp Abstract This paper proposes a method for identifying synonymous relations in a bilingual lexicon, which is a set of translation-equivalent term pairs." ></td>
	<td class="line x" title="2:163	We train a classier for identifying those synonymous relations by using spelling variations as main clues." ></td>
	<td class="line x" title="3:163	We compared two approaches: the direct identication of bilingual synonym pairs, and the merger of two monolingual synonyms." ></td>
	<td class="line x" title="4:163	We showed that our approach achieves a high pair-wise precision and recall, and outperforms the baseline method." ></td>
	<td class="line x" title="5:163	1 Introduction Automatically collecting synonyms from language resources is an ongoing task for natural language processing (NLP)." ></td>
	<td class="line x" title="6:163	Most NLP systems have difculties in dealing with synonyms, which are different representations that have the same meaning in a language." ></td>
	<td class="line x" title="7:163	Information retrieval (IR) could leverage synonyms to improve the coverage of search results (Qiu and Frei, 1993)." ></td>
	<td class="line x" title="8:163	For example, when we input the query transportation in India into an IR system, the system can expand the query to its synonyms; e.g. transport and railway, to nd more documents." ></td>
	<td class="line x" title="9:163	This paper proposes a method for the automatic identication of bilingual synonyms in a bilingual lexicon, with spelling variation clues." ></td>
	<td class="line x" title="10:163	A bilingual synonym set is a set of translation-equivalent term pairs sharing the same meaning." ></td>
	<td class="line x" title="11:163	Although a number of studies have aimed at identifying synonyms, this is the rst study that simultaneously nds synonyms in two languages, to our best knowledge." ></td>
	<td class="line x" title="12:163	Let us consider the case where a user enters the Japanese query kflojflo (	, industrial plant) into a cross-lingual IR system to nd English documents." ></td>
	<td class="line x" title="13:163	After translating the query into the English translation equivalent, plant, the cross-lingual IR system may expand the query to its English synonyms, e.g. factory, and workshop, and retrieve documents that include the expanded terms." ></td>
	<td class="line x" title="14:163	However, the term plant is ambiguous; the system may also expand the query to vegetable, and the system is prevented by the term which is different from our intention." ></td>
	<td class="line x" title="15:163	In contrast, the system can easily reject the latter expansion, vegetable, if we are aware of bilingual synonyms, which indicate synonymous relationsoverbilinguallexicons: (kflojflo, plant)(kflojflo, factory) and (shokubutsu1, plant)  (shokubutsu, vegetable)2 (See Figure 1)." ></td>
	<td class="line x" title="16:163	The expression of the translation equivalent, (kflojflo, plant), helps a crosslingual IR system to retrieve documents that include the term plant, used in the meaning for kflojflo, or industrial plants." ></td>
	<td class="line x" title="17:163	We present a supervised machine learning approach for identifying bilingual synonyms." ></td>
	<td class="line x" title="18:163	Designing features for bilingual synonyms such as spelling variations and bilingual associations, we train a classier with a manually annotated bilingual lexicon with synonymous information." ></td>
	<td class="line x" title="19:163	In order to evaluate the performance of our method, we carried out experiments to identify bilingual synonyms by two approaches: the direct identication of bilingual synonym pairs, and bilingual synonym pairs merged from two monolingual synonym lists." ></td>
	<td class="line x" title="20:163	Experimental results show that our approach achieves the F-scores 1Shokubutsu (	) means botanical plant." ></td>
	<td class="line x" title="21:163	2 represents the synonymous relation." ></td>
	<td class="line x" title="22:163	457 Figure 1: An example of an ambiguous term plant, and the synonyms and translation equivalents (TE) 89.3% in the former approach and 91.4% in the latter, thus outperforming the baseline method that employs only bilingual relations as its clues." ></td>
	<td class="line x" title="23:163	The remainder of this paper is organized as follows." ></td>
	<td class="line x" title="24:163	The next section describes related work on synonym extraction and spelling variations." ></td>
	<td class="line x" title="25:163	Section 3 describes the overview and denition of bilingual synonyms, the proposed method and employed features." ></td>
	<td class="line x" title="26:163	In Section 4 we evaluate our method and conclude this paper." ></td>
	<td class="line x" title="27:163	2 Related work There have been many approaches for detecting synonyms and constructing thesauri." ></td>
	<td class="line x" title="28:163	Two main resources for synonym extraction are large text corpora and dictionaries." ></td>
	<td class="line x" title="29:163	Many studies extract synonyms from large monolingual corpora by using context information around targetterms(CroachandYang, 1992; ParkandChoi, 1996; Waterman, 1996; Curran, 2004)." ></td>
	<td class="line oc" title="30:163	Some researchers (Hindle, 1990; Grefenstette, 1994; Lin, 1998) classify terms by similarities based on their distributional syntactic patterns." ></td>
	<td class="line o" title="31:163	These methods often extract not only synonyms, but also semantically related terms, such as antonyms, hyponyms and coordinate terms such as cat and dog. Some studies make use of bilingual corpora or dictionaries to nd synonyms in a target language (Barzilay and McKeown, 2001; Shimohata and Sumita, 2002; Wu and Zhou, 2003; Lin et al., 2003)." ></td>
	<td class="line x" title="32:163	Lin et al.(2003) chose a set of synonym candidates for a term by using a bilingual dictionary and computing distributional similarities in the candidate set to extract synonyms." ></td>
	<td class="line x" title="34:163	They adopt the bilingual information to exclude non-synonyms (e.g., antonyms and hyponyms) that may be used in the similar contexts." ></td>
	<td class="line x" title="35:163	Although they make use of bilingual dictionaries, this study aims at nding bilingual synonyms directly." ></td>
	<td class="line x" title="36:163	In the approaches based on monolingual dictionaries, the similarities of denitions of lexical items are important clues for identifying synonyms (Blondel et al., 2004; Muller et al., 2006)." ></td>
	<td class="line x" title="37:163	For instance, Blondel et al.(2004) constructed an associated dictionary graph whose vertices are the terms, and whose edges from v1 to v2 represent occurrence of v2 in the denition for v1." ></td>
	<td class="line x" title="39:163	They choose synonyms from the graph by collecting terms pointed to and from the same terms." ></td>
	<td class="line x" title="40:163	Another strategy for nding synonyms is to consider the terms themselves." ></td>
	<td class="line x" title="41:163	We divide it into two approaches: rule-based and distance-based." ></td>
	<td class="line x" title="42:163	Rule-based approaches implement rules with language-specic patterns and detect variations by applying rules to terms." ></td>
	<td class="line x" title="43:163	Stemming (Lovins, 1968; Porter, 1980) is one of the rule-based approaches, which cuts morphological sufx inections, and obtains the stems of words." ></td>
	<td class="line x" title="44:163	There are other types of variations for phrases; for example, insertion, deletion or substitution of words, and permutation of words such as view point and point of view are such variations (Daille et al., 1996)." ></td>
	<td class="line x" title="45:163	Distance-based approaches model the similarity or dissimilarity measure between two terms to nd similar terms." ></td>
	<td class="line x" title="46:163	The edit distance (Levenshtein, 1966) is the most widely-used measure, based on the minimum number of operations of insertion, deletion, or substitution of characters for transforming one term into another." ></td>
	<td class="line x" title="47:163	It can be efciently calculated by using 458 Term pairs Concept p1 = (shflomei (	), light) c1 p2 = (shflomei, lights) c1 p3 = (karui (0M), light) c2 p4 = (raito (), light) c1,c2 p5 = (raito, lights) c1 p6 = (raito, right) c3 p7 = (migi (), right) c3 p8 = (raito, right elder) c4 p9 = (kenri (Vb), right) c5 p10 = (kenri, rights) c5 Table 1: An Example of a bilingual lexicon and synonym sets (concepts) J terms E terms Description c1 shflomei, raito light, lights illumination c2 karui, raito light lightweight c3 migi, raito right right-side c4 raito right elder (baseball) c5 kenri right, rights privilege Table 2: The concepts in Table 1 a dynamic programming algorithm, and we can set the costs/weights for each character type." ></td>
	<td class="line x" title="48:163	3 Bilingual Synonyms and Translation Equivalents This section describes the notion of bilingual synonyms and our method for identifying the synonymous pairs of translation equivalents." ></td>
	<td class="line x" title="49:163	We consider a bilingual synonym as a set of translation-equivalent term pairs referring to the same concept." ></td>
	<td class="line x" title="50:163	Tables 1 and 2 are an example of bilingual synonym sets." ></td>
	<td class="line x" title="51:163	There are ten Japanese-English translation-equivalent term pairs and ve bilingual synonym sets in this example." ></td>
	<td class="line x" title="52:163	A Japanese term raito is the phonetic transcription of both light and right, and it covers four concepts described by the three English terms." ></td>
	<td class="line x" title="53:163	Figure 2 illustrates the relationship among these terms." ></td>
	<td class="line x" title="54:163	The synonymous relation and the translation equivalence are considered to be similar in that two terms share the meanings." ></td>
	<td class="line x" title="55:163	Following synonymous relation between terms in one language, we deal with the synonymous relation between bilingual translation-equivalent term pairs Figure 2: Relations among terms in Table 2 Solid lines show that two terms are translation equivalents, while dotted lines show that two terms are (monolingual) synonyms." ></td>
	<td class="line x" title="56:163	as bilingual synonyms." ></td>
	<td class="line x" title="57:163	The advantage of managing the lexicon in the format of bilingual synonyms is that we can facilitate to tie the concepts and the terms." ></td>
	<td class="line x" title="58:163	3.1 Denitions Let E and F be monolingual lexicons." ></td>
	<td class="line x" title="59:163	We rst assume that a term e  E (or f  F) refers to one or more concepts, and dene that a term e is a synonym3 of e0( E) if and only if e and e0 share an identical concept4." ></td>
	<td class="line x" title="60:163	Let  represent the synonymous relation, and this relation is not transitive because a term often has several concepts: e  e0  e0  e00 6= e  e00." ></td>
	<td class="line x" title="61:163	(1) We dene a synonym set (synset) Ec as a set whose elements share an identical concept c: Ec = {e  E|e refers to c}." ></td>
	<td class="line x" title="62:163	For a term set Ec( E), Ec is a synonym set (synset) = e,e0  Ec e  e0 (2) is true, but the converse is not necessarily true, because of the ambiguity of terms." ></td>
	<td class="line x" title="63:163	Note that one term can belong to multiple synonym sets from the denition." ></td>
	<td class="line x" title="64:163	Let D( F  E) be a bilingual lexicon dened as a set of term pairs (f,e) (f  F,e  E) satisfying that f and e refer to an identical concept." ></td>
	<td class="line x" title="65:163	We 3For distinguishing from bilingual synonyms, we often call the synonym a monolingual synonym." ></td>
	<td class="line x" title="66:163	4The denition of concepts, that is, the criteria of deciding whether two terms are synonymous or not, is beyond the focus of this paper." ></td>
	<td class="line x" title="67:163	We do not assume that related terms such as hypernyms, hyponyms and coordinates are kinds of synonyms." ></td>
	<td class="line x" title="68:163	In our experiments the criteria depend on manual annotation of synonym IDs in the training data." ></td>
	<td class="line x" title="69:163	459 call these pairs translation equivalents, which refer to concepts that both f and e refer to." ></td>
	<td class="line x" title="70:163	We dene that two bilingual lexical items p and p0( D) are bilingual synonyms if and only if p and p0 refer to an identical concept in common with the denition of (monolingual) synonyms." ></td>
	<td class="line x" title="71:163	This relation is not transitive again, and if e  e0 and f  f0, it is not necessarily true that p  p0: e  e0  f  f0 6= p  p0 (3) because of the ambiguity of terms." ></td>
	<td class="line x" title="72:163	Similarly, we can dene a bilingual synonym set (synset) Dc as a set whose elements share an identical meaning c: Dc = {p  D|p refers to c}." ></td>
	<td class="line x" title="73:163	For a set of translation eqiuvalents Dc, Dc is a bilingual synonym set (synset) = p,p0  Dc p  p0 (4) is true, but the converse is not necessarily true." ></td>
	<td class="line x" title="74:163	3.2 Identifying bilingual synonym pairs In this section, we describe an algorithm to identify bilingual synonym pairs by using spelling variation clues." ></td>
	<td class="line x" title="75:163	After identifying the pairs, we can construct bilingual synonym sets by assuming that the converse of the condition (4) is true, and nding sets of bilingual lexical items in which all paired items are bilingual synonyms." ></td>
	<td class="line x" title="76:163	We can see this method as the complete-linkage clustering of translationequivalent term pairs." ></td>
	<td class="line x" title="77:163	We can adopt another option to construct them by assuming also that the bilingual synonymous relation has transitivity: p  p0 p0  p00 = p  p00, and this can be seen as simplelinkage clustering." ></td>
	<td class="line x" title="78:163	This simplied method ignores the ambiguity of terms, and it may construct a bilingual synonym sets which includes many senses." ></td>
	<td class="line x" title="79:163	In spite of the risk, it is effective to nd large synonym sets in case the bilingual synonym pairs are not sufciently detected." ></td>
	<td class="line x" title="80:163	In this paper we focus only on identifying bilingual synonym pairs and evaluating the performance of the identication." ></td>
	<td class="line x" title="81:163	We employ a supervised machine learning technique with features related to spelling variations and so on." ></td>
	<td class="line x" title="82:163	Figure 3 shows the framework for this method." ></td>
	<td class="line x" title="83:163	At rst we prepare a bilingual lexicon with synonymous information as training data, and generate a list consisting of all bilingual lexical item Figure 3: Overview of our framework pairs in the bilingual lexicon." ></td>
	<td class="line x" title="84:163	The presence or absence of bilingual synonymous relations is attached to each element of the list." ></td>
	<td class="line x" title="85:163	Then, we build a classier learned by training data, using a maximum entropy model (Berger et al., 1996) and the features related to spelling variations in Table 3." ></td>
	<td class="line x" title="86:163	We apply some preprocessings for extracting some features." ></td>
	<td class="line x" title="87:163	For English, we transform all terms into lower-case, and do not apply any other transformations such as tokenization by symbols." ></td>
	<td class="line x" title="88:163	For Japanese, we apply a morphological analyzer JUMAN (Kurohashi et al., 1994) and obtain hiragana representations5 as much as possible6." ></td>
	<td class="line x" title="89:163	We may require other language-specic preprocessings for applying this method to other languages." ></td>
	<td class="line x" title="90:163	We employed binary or real-valued features described in Table 3." ></td>
	<td class="line x" title="91:163	Moreover, we introduce the following combinatorial features: h1F  h1E, h2F h2E, h3F h3E, h5E  h5F, h6  h2F and h7 h2E." ></td>
	<td class="line x" title="92:163	3.2.1 Two approaches for identifying bilingual synonym pairs There are two approaches for identifying bilingual synonym pairs: one is directly identifying whether two bilingual lexical items are bilingual synonyms (bilingual method), and another is rst 5Hiragana is one of normalized representations of Japanese terms, which denotes how to pronounce the term." ></td>
	<td class="line x" title="93:163	Japanese vocabularyhasmanyofhomonyms, whicharesemanticallydifferent but have the same pronunciation." ></td>
	<td class="line x" title="94:163	Despite the risk of classifying homonyms into synonyms, we do not use original forms of Japanese terms because they are typically too short to extract character similarities." ></td>
	<td class="line x" title="95:163	6We keep unknown terms of JUMAN unchanged." ></td>
	<td class="line x" title="96:163	460 h1F,h1E: Agreement of the rst characters Whether the rst characters match or not h2F,h2E: Normalized edit distance 1 ED(w,w0)max(jwj,jw0j), where ED(w,w0) is a non-weighted edit distance between w and w0 and |w| is the number of characters in w h3F,h3E: Bigram similarity jbigram(w)\bigram(w0)jmax(jwj,jw0j)1 , where bigram(w) is a multiset of character-based bigrams in w h4F,h4E: Agreement or known synonymous relation of word sub-sequences The count that sub-sequences of the target terms match as known terms or are in known synonymous relation h5F,h5E: Existence of crossing bilingual lexical items For bilingual lexical items (f1,e1) and (f2,e2), whether (f1,e2) (for h5F) or (f2,e1) (for h5E) is in the bilingual lexicon of the training set h6: Acronyms Whether one English term is an acronym for another (Schwartz and Hearst, 2003) h7: Katakana variants Whether one Japanese term is a katakana variant for another (Masuyama et al., 2004) Table 3: Features used for identifying bilingual synonym pairs hiF is the feature value when the terms w and w0( F) are compared in the i-th feature and so as hiE." ></td>
	<td class="line x" title="97:163	h6 is only for English and h7 is only for Japanese." ></td>
	<td class="line x" title="98:163	identifying monolingual synonyms in each language and then merging them according to the bilingual items (monolingual method)." ></td>
	<td class="line x" title="99:163	We implement these two approaches and compare the results." ></td>
	<td class="line x" title="100:163	For identifying monolingual synonyms, we use features with bilingual items as follows: For a term pair e1 and e2, we obtain all the translation candidates F1 = {f|(f,e1)  D} and F2 = {f0|(f0,e2)  D}, and calculate feature values related to F1 and/or F2 by obtaining the maximum feature value using F1 and/or F2." ></td>
	<td class="line x" title="101:163	After that, if all the following four conditions (p1 = (f1,e1)  D, p2 = (f2,e2)  D, f1  e1 and f2  e2) are satised, we assume that p1 and p2 are bilingual synonym pairs7." ></td>
	<td class="line x" title="102:163	4 Experiment 4.1 Experimental settings We performed experiments to identify bilingual synonym pairs by using the Japanese-English lexicon with synonymous information8." ></td>
	<td class="line x" title="103:163	The lexicon consists of translation-equivalent term pairs extracted from titles and abstracts of scientic papers published in Japan." ></td>
	<td class="line x" title="104:163	It contains many spelling variations and synonyms for constructing and maintaining the 7Actually, these conditions are not sufcient to derive the bilingual synonym pairs described in Section 3.1." ></td>
	<td class="line x" title="105:163	We assume this approximation because there seems to be few counter examples in actual lexicons." ></td>
	<td class="line x" title="106:163	8This data was edited and provided by Japan Science and Technology Agency (JST)." ></td>
	<td class="line x" title="107:163	Total train dev." ></td>
	<td class="line x" title="108:163	test |D| 210647 168837 20853 20957 |J| 136128 108325 13937 13866 |E| 115002 91057 11862 12803 Synsets 50710 40568 5071 5071 Pairs 814524 651727 77706 85091 Table 5: Statistics of the bilingual lexicon for our experiment |D|,|J|, and |E| are the number of bilingual lexical items, the number of Japanese vocabularies, and the number of English vocabularies, respectively." ></td>
	<td class="line x" title="109:163	Synsets and Pairs are the numbers of synonym sets and synonym pairs, respectively." ></td>
	<td class="line x" title="110:163	thesaurus of scientic terms and improving the coverage." ></td>
	<td class="line x" title="111:163	Table 4 illustrates this lexicon." ></td>
	<td class="line x" title="112:163	Table 5 shows the statistics of the dictionary." ></td>
	<td class="line x" title="113:163	We used information only synonym IDs and Japanese and English representations." ></td>
	<td class="line x" title="114:163	We extract pairs of bilingual lexical items, and treat them as events for training of the maximum entropy method." ></td>
	<td class="line x" title="115:163	The parameters were adjusted so that the performance is the best for the development set." ></td>
	<td class="line x" title="116:163	For a monolingual method, we used Tb = 0.8, and for a bilingual method, we used Tb = 0.7." ></td>
	<td class="line x" title="117:163	4.2 Evaluation We evaluated the performance of identifying bilingual synonym pairs by the pair-wise precision P, 461 Synset ID J term E term 130213 . (shintai-bui) Body Regions 130213 . (shintai-bui) body part 130213 . (shintai-bui) body region 130213 .  (shintai-bubun) body part 130217 Douglas0(Douglas-ka) Douglas Pouch 130217 DouglasT(Douglas-ka) Douglas Pouch 1302170(Dagurasu-ka) pouch of Douglas 130217T(Dagurasu-ka) pouch of Douglas 130217v0(chokuchflo-shikyflu-ka) rectouterine pouch 130217vT(chokuchflo-shikyflu-ka) rectouterine pouch Table 4: A part of the lexicon used Each bilingual synonym set consists of items that have the same synset ID.  (bubun) is a synonym of  (bui).T(ka) is a hiragana representation of0(ka).(Dagurasu) is a Japanese transcription of Douglas." ></td>
	<td class="line x" title="118:163	recall R and F-score F dened as follows: P = CT ,R = CN,F = 2PRP +R, (5) where C,T and N are the number of correctly predicted pairs as synonyms, predicted pairs to become synonyms, and synonym pairs in the lexicon9, respectively." ></td>
	<td class="line x" title="119:163	We compared the results with the baseline and the upper bound." ></td>
	<td class="line x" title="120:163	The baseline assumes that each bilingual lexical item is a bilingual synonym if either the Japanese or English terms are identical." ></td>
	<td class="line x" title="121:163	The upper bound assumes that all the monolingual synonyms are known and each bilingual item is a bilingual synonym if the Japanese terms and the English terms are synonymous." ></td>
	<td class="line x" title="122:163	The baseline represents the performance when we do not consider spelling variations, and the upper bound shows the limitation of the monolingual approach." ></td>
	<td class="line x" title="123:163	4.3 Result Table 6 shows the evaluation scores of our experiments." ></td>
	<td class="line x" title="124:163	The monolingual and bilingual methods are described in Section 3.2.1." ></td>
	<td class="line x" title="125:163	We obtained high precision and recall scores, although we used features primarily with spelling variations." ></td>
	<td class="line x" title="126:163	Both methods signicantly outperform the baseline, and show the importance of considering spelling variations." ></td>
	<td class="line x" title="127:163	9N includes the number of synonym pairs ltered out from training set by the bigram similarity threshold Tb." ></td>
	<td class="line x" title="128:163	Set Method Precision Recall F-score dev." ></td>
	<td class="line x" title="129:163	baseline 0.977 (31845/32581) 0.410 (31845/77706) 0.577 monolingual 0.911 (74263/81501) 0.956 (74263/77706) 0.932 bilingual 0.879 (72782/82796) 0.937 (72782/77706) 0.907 upper bound 0.984 (77706/78948) 1 0.992 test baseline 0.972 (33382/34347) 0.392 (33382/85091) 0.559 monolingual 0.900 (79099/87901) 0.930 (79099/85091) 0.914 bilingual 0.875 (77640/88714) 0.912 (77640/85091) 0.893 upper bound 0.979 (85091/86937) 1 0.989 Table 6: Evaluation scores The monolingual method achieved higher precision and recall than the bilingual method." ></td>
	<td class="line x" title="130:163	It indicates that monolingual synonym identication is effective in nding bilingual synonyms." ></td>
	<td class="line x" title="131:163	The upper bound shows that there are still a few errors by the assumption used by the monolingual method." ></td>
	<td class="line x" title="132:163	However, the high precision of the upper bound represents the well-formedness of the lexicon we used." ></td>
	<td class="line x" title="133:163	We need more experiments on other bilingual lexicons to conclude that our method is available for 462 Features Precision Recall F-score All 0.911 0.956 0.932 h1F,h1E 0.911 0.974 0.941 h2F,h2E 0.906 0.947 0.926 h3F,h3E 0.939 0.930 0.934 h4F,h4E 0.919 0.734 0.816 h5F,h5E 0.869 0.804 0.831 h6,h7 0.940 0.934 0.937 combs." ></td>
	<td class="line x" title="134:163	0.936 0.929 0.932 Table 7: Evaluation scores of the bilingual method with removing features on the development set h represents removing the feature h and combinatorial features using h. combs." ></td>
	<td class="line x" title="135:163	represents removing all the combinatorial features." ></td>
	<td class="line x" title="136:163	many kinds of lexicons." ></td>
	<td class="line x" title="137:163	To investigate the effectiveness of each feature, we compared the scores when we remove several features." ></td>
	<td class="line x" title="138:163	Table 7 shows these results." ></td>
	<td class="line x" title="139:163	Contrary to our intuition, we found that features of agreement of the rst characters (h1) remarkably degraded the recall without gains in precision." ></td>
	<td class="line x" title="140:163	One of the reasons for such results is that there are many cases of non-synonyms that have the same rst character." ></td>
	<td class="line x" title="141:163	We need to investigate more effective combinations of features or to apply other machine learning techniques for improving the performance." ></td>
	<td class="line x" title="142:163	From these results, we consider that the features of h4 are effective for improving the recall, and that the features of h2 and h5 contribute improvement of both the precision and the recall." ></td>
	<td class="line x" title="143:163	h3, h6, h7, and combinatorial features seem to improve the recall at the expense of precision." ></td>
	<td class="line x" title="144:163	Which measure is important depends on the importance of our target for using this technique." ></td>
	<td class="line x" title="145:163	It depends on the requirements that we emphasize, but in general the recall is more important for nding more bilingual synonyms." ></td>
	<td class="line x" title="146:163	5 Conclusion and future work This paper proposed a method for identifying bilingual synonyms in a bilingual lexicon by using clues of spelling variations." ></td>
	<td class="line x" title="147:163	We described the notion of bilingual synonyms, and presented two approaches for identifying them: one is to directly predict the relation, and another is to merge monolingual synonyms identied, according to the bilingual lexicon." ></td>
	<td class="line x" title="148:163	Our experiments showed that the proposed method signicantly outperformed the method that did not use features primarily with spelling variations; the proposed method extracted bilingual synonyms with high precision and recall." ></td>
	<td class="line x" title="149:163	In addition, we found that merging monolingual synonyms by the dictionary is effective for nding bilingual synonyms; there occur few errors through the assumption described in Section 3.2.1." ></td>
	<td class="line x" title="150:163	Our future work contains implementing more features for identifying synonymous relations, constructing bilingual synonym sets, and evaluating our methodforspecictaskssuchasthesaurusconstruction or cross-lingual information retrieval." ></td>
	<td class="line x" title="151:163	Currently, the features used do not include other clues with spelling variations, such as the weighted edit distance, transformation patterns, stemming and so on." ></td>
	<td class="line x" title="152:163	Another important clue is distributional information, such as the context." ></td>
	<td class="line x" title="153:163	We can use both monolingual and bilingual corpora for extracting distributions of terms, and bilingual corpora are expected to be especially effective for our goal." ></td>
	<td class="line x" title="154:163	We did not perform an experiment to construct bilingual synonym sets from synonym pairs in this paper." ></td>
	<td class="line x" title="155:163	Described in Section 3.1, bilingual synonym sets can be constructed from bilingual synonym pairs by assuming some approximations." ></td>
	<td class="line x" title="156:163	The approximation that permits transitivity of bilingual synonymous relations increases identied bilingual synonyms, and thus causes an increase in recall and decrease in precision." ></td>
	<td class="line x" title="157:163	It is an open problem to nd appropriate strategies for constructing bilingual synonym sets." ></td>
	<td class="line x" title="158:163	Finally, we plan to evaluate our method for specic tasks." ></td>
	<td class="line x" title="159:163	For data-driven machine translation, it is expected that data sparseness problem is alleviated by merging the occurrences of low-frequency terms." ></td>
	<td class="line x" title="160:163	Another application is cross-lingual information retrieval, which can be improved by using candidate expanded queries from bilingual synonym sets." ></td>
	<td class="line x" title="161:163	Acknowledgments This work was partially supported by Grant-in-Aid for Specially Promoted Research (MEXT, Japan) and Japanese/Chinese Machine Translation Project in Special Coordination Funds for Promoting Science and Technology (MEXT, Japan)." ></td>
	<td class="line x" title="162:163	We thank 463 Japan Science and Technology Agency (JST) for providing a useful bilingual lexicon with synonymous information." ></td>
	<td class="line x" title="163:163	We acknowledge the anonymous reviewers for helpful comments and suggestions." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="I08-1072
Context Feature Selection for Distributional Similarity
Hagiwara, Masato;Ogawa, Yasuhiro;Toyama, Katsuhiko;"></td>
	<td class="line x" title="1:114	Context Feature Selection for Distributional Similarity Masato Hagiwara, Yasuhiro Ogawa, and Katsuhiko Toyama Graduate School of Information Science, Nagoya University Furo-cho, Chikusa-ku, Nagoya, JAPAN 464-8603 {hagiwara, yasuhiro, toyama}@kl.i.is.nagoya-u.ac.jp Abstract Distributional similarity is a widely used concept to capture the semantic relatedness ofwordsinvariousNLPtasks." ></td>
	<td class="line x" title="2:114	However, accurate similarity calculation requires a large number of contexts, which leads to impractically high computational complexity." ></td>
	<td class="line x" title="3:114	To alleviate the problem, we have investigated the effectiveness of automatic context selection by applying feature selection methods explored mainly for text categorization." ></td>
	<td class="line x" title="4:114	Our experiments on synonym acquisition have shown that while keeping or sometimes increasing the performance, we can drastically reduce the unique contexts up to 10% of the original size." ></td>
	<td class="line x" title="5:114	We have also extended the measures so that they cover context categories." ></td>
	<td class="line x" title="6:114	The result shows a considerable correlation between the measures and the performance, enabling the automatic selection of effective context categories for distributional similarity." ></td>
	<td class="line x" title="7:114	1 Introduction Semantic similarity of words is one of the most important lexical knowledge for NLP tasks including word sense disambiguation and synonym acquisition." ></td>
	<td class="line x" title="8:114	To measure the semantic relatedness of words, a concept called distributional similarity has been widely used." ></td>
	<td class="line x" title="9:114	Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts." ></td>
	<td class="line pc" title="10:114	A wide range of contextual information, such as surrounding words (Lowe and McDonald, 2000; Curran and Moens, 2002a), dependency or case structure (Hindle, 1990; Ruge, 1997; Lin, 1998), and dependency path (Lin and Pantel, 2001; Pado and Lapata, 2007), has been utilized for similarity calculation, and achieved considerable success." ></td>
	<td class="line n" title="11:114	However, amajorproblemwhichariseswhenadopting distributional similarity is that it easily yields a huge amount of unique contexts." ></td>
	<td class="line n" title="12:114	This can lead to high dimensionality of context space, often up to the orderoftensorhundredsofthousands, whichmakes the calculation computationally impractical." ></td>
	<td class="line x" title="13:114	Because not all of the contexts are useful, it is strongly required for the efciency to eliminate the unwanted contexts to ease the expensive cost." ></td>
	<td class="line x" title="14:114	To tackle this issue, Curran and Moens (2002b) suggest assigning an index vector of canonical attributes, i.e., a small number of representative elements extracted from the original vector, to each word." ></td>
	<td class="line x" title="15:114	Whenthecomparisonisperformed, canonical attributes of two target words are rstly consulted, and the original vectors are referred to only if the attributes have a match between them." ></td>
	<td class="line x" title="16:114	However, it is not clear whether the condition for canonical attributes they adopted, i.e., that the attributes must be the most weighted subject, direct object, or indirect object, is optimal in terms of the performance." ></td>
	<td class="line x" title="17:114	There are also some existing studies which paid attention to the comparison of context categories for synonym acquisition (Curran and Moens, 2002a; Hagiwara et al., 2006)." ></td>
	<td class="line x" title="18:114	However, they have conductedonlyaposterioricomparisonbasedonperformance evaluation, and we are afraid that these nd553 ings are somewhat limited to their own experimental settings which may not be applicable to completely new settings, e.g., one with a new set of contexts extracted from different sources." ></td>
	<td class="line x" title="19:114	Therefore, general quantitative measures which can be used for reduction and selection of any kind of contexts and context categories are strongly required." ></td>
	<td class="line x" title="20:114	Shifting our attention from word similarity to other areas, a great deal of studies on feature selection has been conducted in the literature, especially for text categorization (Yang and Pedersen, 1997) and gene expression classication (Ding and Peng, 2003)." ></td>
	<td class="line x" title="21:114	Whereas these methods have been successful in reducing feature size while keeping classication performance, the problem of distributional similarity is radically different from that of classication, and whether the same methods are applicable and effective for automatic context selection in the similarity problem is yet to be investigated." ></td>
	<td class="line x" title="22:114	In this paper, we rstly introduce existing quantitative methods for feature selection, namely, DF, TS, MI, IG, CHI2, and show how to apply them to the distributional similarity problem to measure the context importance." ></td>
	<td class="line x" title="23:114	We then extracted dependency relations as context from the corpus, and conducted automatic synonym acquisition experiments to evaluate the context selection performance, reducing the unimportant contexts based on the feature selection methods." ></td>
	<td class="line x" title="24:114	Finally we extend the context importance to cover context categories (RASP2 grammatical relations), and show that the above methods are also effective in selecting categories." ></td>
	<td class="line x" title="25:114	This paper is organized as follows: in Section 2, ve existing context selection methods are introduced, and how to apply classication-based selection methods to distributional similarity is described." ></td>
	<td class="line x" title="26:114	In Section 3 and 4, the synonym acquisition method and evaluation measures, AP and CC, employed in the evaluation experiments are detailed." ></td>
	<td class="line x" title="27:114	Section 5 includes two main experiments and their results: context reduction and context category selection, along with experimental settings and discussions." ></td>
	<td class="line x" title="28:114	Section 6 concludes this paper." ></td>
	<td class="line x" title="29:114	2 Context Selection Methods In this section, context selection methods proposed for text categorization or information retrieval are introduced." ></td>
	<td class="line x" title="30:114	In the following, n and m represent the number of unique words and unique contexts, respectively, and N(w,c) denotes the number of cooccurrence of word w and context c. 2.1 Document Frequency (DF) Document frequency (DF), commonly used for weighting in information retrieval, is the number of documents a term co-occur with." ></td>
	<td class="line x" title="31:114	However, in the distributional similarity settings, DF corresponds to word frequency, i.e., thenumberofuniquewordsthe context co-occurs with: df(c) = |{w|N(w,c) > 0}|." ></td>
	<td class="line x" title="32:114	ThemotivationofadoptingDFasacontextselection criterion is the assumption that the contexts shared by many words should be informative." ></td>
	<td class="line x" title="33:114	It is to note, however, that the contexts with too high DF are not always useful, since there are some exceptions including so-called stopwords." ></td>
	<td class="line x" title="34:114	2.2 Term Strength (TS) Term strength (TS), proposed by Wilbur and Sirotkin (1992) and applied to text categorization by Yang and Wilbur (1996), measures how likely a term is to appear in  similar documents, and it is shown to achieve a successful outcome in reducing the amount of vocabulary for text retrieval." ></td>
	<td class="line x" title="35:114	For distributional similarity, TS is dened as: s(c) = P(c  C(w2)|c  C(w1)), where (w1,w2) is a related word pair and C(w) is a set of contexts co-occurring with the word w, i.e., C(w) = {c|N(w,c) > 0}." ></td>
	<td class="line x" title="36:114	s(c) is calculated, letting PH be a set of related word pairs, as s(c) = |{(w1,w2)  PH|c  C(w1) C(w2)}||{(w 1,w2)  PH|c  C(w1)}| . What makes TS different from DF is that it requires a training set PH consisting of related word pairs." ></td>
	<td class="line x" title="37:114	We used the test set for class s = 1 as PH described in the next section." ></td>
	<td class="line x" title="38:114	2.3 Formalization of Distributional Similarity The following methods, MI, IG, and CHI2, are radically different from the above ones, in that they are 554 designed essentially for  class classication problems." ></td>
	<td class="line x" title="39:114	Thus we formalize distributional similarity as a classication problem as described below." ></td>
	<td class="line x" title="40:114	First of all, we deal with word pairs, instead of words, asthetargetsofclassication, anddenefeatures f1,,fm corresponding to contexts c1,,cm, for each pair." ></td>
	<td class="line x" title="41:114	The feature fj = 1 if the two words of the pair has the context cj in common, and fj = 0 otherwise." ></td>
	<td class="line x" title="42:114	Then, we dene target class s, so that s = 1 when the pair is semantically related, and s = 0 if not." ></td>
	<td class="line x" title="43:114	These dened, distributional similarity is formalized as a binary classication problem which assigns the word pairs to the class s  {0,1} based on the features c1,,cm." ></td>
	<td class="line x" title="44:114	Finally, to calculate the specic values of the following feature importance measures, we prepare two test sets of related word pairs for class s = 1 and unrelated ones for class s = 0." ></td>
	<td class="line x" title="45:114	This enables us to apply existing feature selection methods designed for classication problems to the automatic context selection." ></td>
	<td class="line x" title="46:114	The two test sets, related and unrelated one, are prepared using the reference sets described in Section 4." ></td>
	<td class="line x" title="47:114	More specically, we created 5,000 related word pairs by extracting from synonym pairs in the referenceset,and5,000unrelatedonesbyrstlycreatingrandompairsofLDV,whosedetailisdescribed later, and then manually making sure that no related pairs are included in these random pairs." ></td>
	<td class="line x" title="48:114	2.4 Mutual Information (MI) Mutual information (MI), commonly used for word association and co-occurrence weighing in statistical NLP, is the measure of the degree of dependence between two events." ></td>
	<td class="line x" title="49:114	The pointwise MI value of feature f and class s is calculated as: I(f,s) = log P(f,s)P(f)P(s)." ></td>
	<td class="line x" title="50:114	To obtain the nal context importance, we combine the MI value over both of the classes as Imax(cj) = maxs{0,1} I(fj,s)." ></td>
	<td class="line x" title="51:114	Note that, here we employed the maximum value of pointwise MI values since it is claimed to be the best in (Yang and Pedersen, 1997), although there can be other combination ways such as weighted average." ></td>
	<td class="line x" title="52:114	2.5 Information Gain (IG) Information gain (IG), often employed in the machine learning eld as a criterion for feature importance, is the amount of gained information of an event by knowing the outcome of the other event, and is calculated as the weighted sum of the pointwise MI values over all the event combinations: G(cj) =  fj{0,1}  s{0,1} P(fj,s)log P(fj,s)P(f j)P(s) . 2.6 2 Statistic (CHI2) 2 statistic (CHI2) estimates the lack of independence between classes and features, which is equal to the summed difference of observed and expected frequency over the contingency table cells." ></td>
	<td class="line x" title="53:114	More specically,lettingFjnm(n,m  {0,1})bethenumber of word pairs with fj = n and s = m, and the number of all pairs be N, 2 statistic is dened as: 2(cj) = N(F11F00 F01F10)(F 11 + F01)(F10 + F00)(F11 + F10)(F01 + F00) . 3 Synonym Acquisition Method This section describes the synonym acquisition method, a major and important application of distributional similarity, which we employed for the evaluation of automatic context selection." ></td>
	<td class="line x" title="54:114	Here we mention how to extract the original contexts from corpora in detail, as well as the calculation of weight and similarity between words." ></td>
	<td class="line x" title="55:114	3.1 Context Extraction We adopted dependency structure as the context of words since it is the most widely used and wellperforming contextual information in the past studies (Ruge, 1997; Lin, 1998)." ></td>
	<td class="line x" title="56:114	As the extraction of accurateandcomprehensivedependencystructureisin itself a difcult task, the sophisticated parser RASP Toolkit 2 (Briscoe et al., 2006) was utilized to extract this kind of word relations." ></td>
	<td class="line x" title="57:114	Take the following sentence for example: Shipments have been relatively level since January, the Commerce Department noted." ></td>
	<td class="line x" title="58:114	555 RASP outputs the extracted dependency structure as n-ary relations as follows, which are called grammatical relations." ></td>
	<td class="line x" title="59:114	Annotations regarding sufx, part of speech tags, offsets for individual words are omitted for simplicity." ></td>
	<td class="line x" title="60:114	(ncsubj be Shipment _) (aux be have) (xcomp _ be level) (ncmod _ be relatively) (ccomp _ level note) (ncmod _ note since) (ncsubj note Department _) (det Department the) (ncmod _ Department Commerce) (dobj since January) While the RASP outputs are n-ary relations in general, what we need here is co-occurrences of words and contexts, so we extract the set of cooccurrences of stemmed words and contexts by taking out the target word from the relation and replacing the slot by an asterisk  * : (words) (contexts) Shipment ncsubj:be:*_ have aux:be:* be ncsubj:*:Shipment:_ be aux:*:have be xcomp:_:*:level be ncmod:_:*:relatively relatively ncmod:_:be:* level xcomp:_:be:* level ccomp:_:*:note  Summing all these up produces the raw cooccurrence count N(w,c) of word w and context c. 3.2 Similarity Calculation Although it is possible to use the raw count acquired above for the similarity calculation, directly using the raw count may cause performance degradation, thus we need an appropriate weighting measure." ></td>
	<td class="line x" title="61:114	In response to the preliminary experiment results, we employed pointwise mutual information as weight: wgt(w,c) = log P(w,c)P(w)P(c) Here we made a small modication to bind the weight to non-negative such that wgt(w,c)  0, because negative weight values sometimes worsen the performance (Curran and Moens, 2002b)." ></td>
	<td class="line x" title="62:114	The weightingbyPMIisappliedafterthepre-processing including frequency cutoff and context selection." ></td>
	<td class="line x" title="63:114	Asforthesimilaritymeasure,weusedJaccardcoefcient, which is widely adopted to capture overlap proportion of two sets:  cC(w1)C(w2) min(wgt(w1,c),wgt(w2,c)) cC(w1)C(w2) max(wgt(w1,c),wgt(w2,c)) . 4 Evaluation Measures This section describes the two evaluation methods we employed  average precision (AP) and correlation coefcient (CC)." ></td>
	<td class="line x" title="64:114	4.1 Average Precision (AP) The rst evaluation measure, average precision (AP), is a common evaluation scheme for information retrieval, which evaluates how accurately the methods are able to extract synonyms." ></td>
	<td class="line x" title="65:114	We rst prepare a set of query words, for which synonyms are obtained to evaluate the precision." ></td>
	<td class="line x" title="66:114	We adopted the Longman Dening Vocabulary (LDV) 1 as the candidate set of query words." ></td>
	<td class="line x" title="67:114	For each word in LDV, three existing thesauri are consulted: Rogets Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998)." ></td>
	<td class="line x" title="68:114	The union of synonyms obtained when the LDV word is looked up as a noun is used as the reference set, except for words marked as  idiom,  informal,  slang and phrases comprised of two or more words." ></td>
	<td class="line x" title="69:114	The LDV words for which no noun synonyms are found in any of the reference thesauri are omitted." ></td>
	<td class="line x" title="70:114	From the remaining 771 LDV words, 100 query words are randomly extracted, and for eachofthemtheelevenprecisionvaluesat0%,10%, , and 100% recall levels are averaged to calculate the nal AP value." ></td>
	<td class="line x" title="71:114	4.2 Correlation Coefcient (CC) The second evaluation measure is correlation coefcient (CC) between the target similarity and the reference similarity, i.e., the answer value of similarity for word pairs." ></td>
	<td class="line x" title="72:114	The reference similarity is calculated based on the closeness of two words in the tree structure of WordNet." ></td>
	<td class="line x" title="73:114	More specically, the similarity between word w with senses w1,,wm1 andwordv withsensesv1,,vm2 isobtainedasfollows." ></td>
	<td class="line x" title="74:114	Let the depth of node wi and vj be di and dj, 1http://www.cs.utexas.edu/users/kbarker/working notes/ ldoce-vocab.html 556 and the depth of the deepest common ancestors of both nodes be ddca." ></td>
	<td class="line x" title="75:114	The similarity is then sim(w,v) = maxi,j sim(wi,vj) = maxi,j 2 ddcad i + dj , which takes the value between 0.0 and 1.0." ></td>
	<td class="line x" title="76:114	Then, the value of CC is calculated as the correlation coefcient of reference similarities r = (r1,r2,,rn) and target similarities s = (s1,s2,,sn) over the word pairs in sample set Ps, which is created by choosing the most similar 2,000 word pairs from 4,000 randomly created pairs from LDV." ></td>
	<td class="line x" title="77:114	To avoid test-set dependency, all the CC values presented in this paper are the average values of three trials using different test sets." ></td>
	<td class="line x" title="78:114	5 Experiments Now we describe the experimental settings and the evaluation results of context selection methods." ></td>
	<td class="line x" title="79:114	5.1 Experimental Settings As for the corpus, New York Times section of English Gigaword 2, consisting of around 914 million words and 1.3 million documents was analyzed to obtainword-contextco-occurrences." ></td>
	<td class="line x" title="80:114	Frequencycutoff was applied as a pre-processing in order to lter out any words and contexts with low frequency and to reduce computational cost." ></td>
	<td class="line x" title="81:114	More specically, any words w such that c tf(w,c) <  f and any contexts c such thatw tf(w,c) <  f, with  f = 40, were removed from the co-occurrence data." ></td>
	<td class="line x" title="82:114	Since we set our purpose here to the automatic acquisition of synonymous nouns, only the nouns except for proper nouns were selected." ></td>
	<td class="line x" title="83:114	To distinguish nouns, using POS tags annotated by RASP2, any words with POS tags APP, ND, NN, NP, PN, PP were labeled as nouns." ></td>
	<td class="line x" title="84:114	This left a total of 40,461 unique words and 139,618 unique context, which corresponds to the number of vectors and the dimensionality of semantic space, respectively." ></td>
	<td class="line x" title="85:114	5.2 Context Reduction In the rst experiment, we show the effectiveness of the ve contextual selection methods introduced in Section 2 for context reduction problem." ></td>
	<td class="line x" title="86:114	The ve 2http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?" ></td>
	<td class="line x" title="87:114	catalogId=LDC2003T05 measures were calculated for each context, and contextsweresortedbytheirimportance." ></td>
	<td class="line x" title="88:114	Thechangeof performance, AP and CC, was calculated on eliminating the low-ranked contexts and varying the proportion of remaining ones, until only 0.2% (279 in number) of the unique contexts are left." ></td>
	<td class="line x" title="89:114	The result is displayed in Figure 1." ></td>
	<td class="line x" title="90:114	The overall observation is that the performance not only kept the original level but also slightly improved even during the  aggressive reduction when more than 80% of the original contexts were eliminated and less than 20,000 contexts were left." ></td>
	<td class="line x" title="91:114	It was not until 90% (approx." ></td>
	<td class="line x" title="92:114	10,000 remaining) elimination that the AP values began to fall." ></td>
	<td class="line x" title="93:114	The tendency of performance change was almost the same for AP and CC, but we observe a slight difference regarding which of the ve measures were effective." ></td>
	<td class="line x" title="94:114	More specically, TS, IG and CHI2 worked well for AP, and DF, TS, while CHI2 did for CC." ></td>
	<td class="line x" title="95:114	On the whole, TS and CHI2 were performing the best, whereas the performance of MI quickly worsened." ></td>
	<td class="line x" title="96:114	Although the task is different, this experiment showed a very consistent result compared with the one of Yang and Pedersens (1997)." ></td>
	<td class="line x" title="97:114	This means that feature selection methods are also effective for context selection in distributional similarity, and our formalization of the problem described in Section 2 turned out to be appropriate for the purpose." ></td>
	<td class="line x" title="98:114	5.3 Context Category Selection We are then naturally interested in what kinds of contexts are included in these top-ranked effective ones and how much they affect the overall performance." ></td>
	<td class="line x" title="99:114	To investigate this, we rstly built a set of elite contexts, by gathering each top 10% (13,961 in number) contexts chosen by DF, TS, IG, and CHI2, and obtaining the intersection of these four top-rankedcontexts." ></td>
	<td class="line x" title="100:114	Itwasfoundthatthesefourhad a great deal of overlap among them, the number of which turned out to be 6,440." ></td>
	<td class="line x" title="101:114	Secondly, to measure the degree of effect a context category has, we dened category importance as the sum of all IG values of the contexts which belong to the category." ></td>
	<td class="line x" title="102:114	The reason is that, (a) IG was one of the best-performing criteria as the previous experiment showed, and (b) IG value for a set of contexts can be calculated as the sum of IG values of individual elements, assuming that all the contexts 557 0.10 0.15 0.20 0.25 020000400006000080000100000120000 Number of Unique Context Correlation Coefficient (CC) DFTS MIIG CHI2 ` (c) 6.0% 8.0% 10.0% 12.0% 14.0% 020000400006000080000100000120000 Number of Unique Context Average Precision (AP) DFTS MIIG CHI2 (a) 0.10 0.15 0.20 0.25 05000100001500020000 Number of Unique Context Correlation Coefficient (CC) DFTS IGCHI2 ` (d) 6.0% 8.0% 10.0% 12.0% 14.0% 05000100001500020000 Number of Unique Context Average Precision (AP) DFTS IGCHI2 (b) Figure 1: Performance of synonym acquisition on automatic context reduction (a) The overall view and (b) the close-up of 0 to 20,000 unique contexts for AP, and (c) the overall view and (b) the close-up for CC are mutually independent, which is a naive but practical assumption because of the high independence of acquired contexts from corpora." ></td>
	<td class="line x" title="103:114	For the categories: ncsubj, dobj, obj, obj2, ncmod, xmod, cmod, ccomp, det, ta, based on the RASP2 grammatical relations which occur frequently (more than 1.0%) in the corpus, their category importance within the elite context set was computed and showed in Figure 2." ></td>
	<td class="line x" title="104:114	The graph also shows the performance of individual context categories, calculated when each category was separately extracted from the entire corpus." ></td>
	<td class="line x" title="105:114	The result indicates that there is a considerable correlation (r = 0.760) between category importance and performance, which means it is possible to predict the nal performance of any context categories by calculating their category importance values in the limited size of selected context set." ></td>
	<td class="line x" title="106:114	Asforthequalitativedifferenceofcategorytypes, the result also shows the effectiveness of modication (ncmod) category, which is consistent with the result (Hagiwara et al., 2006) that mod is more contributing than subj and obj, which have been extensively used in the past." ></td>
	<td class="line x" title="107:114	However, it can be seen that the reason why the ncmod performs well may be only because it is the largest category in size (2,515 558 0% 2% 4% 6% 8% 10%12%14% ncsubj dobj obj obj2 ncmod xmod cmod ccomp det ta Average Precision (AP) 0 2 4 6 8 10Category Importance (CI) APCI Figure 2: Performance of synonym acquisition vs context category importance in the elite contexts)." ></td>
	<td class="line x" title="108:114	The investigation of the relations between context size and performance should be conducted in the future." ></td>
	<td class="line x" title="109:114	6 Conclusion In this study, we rstly introduced feature selection methods, previously proposed for text categorization, and showed how to apply them for automatic context selection for distributional similarity by formalizing the similarity problem as classication." ></td>
	<td class="line x" title="110:114	We then extracted dependency-based context from the corpus, and conducted evaluation experiments on automatic synonym acquisition." ></td>
	<td class="line x" title="111:114	The experimental results showed that while keeping or even improving the original performance, it is possible to eliminate a large proportion of contexts (almost up to 90%)." ></td>
	<td class="line x" title="112:114	We also extended the context importance to cover context categories based on RASP2grammaticalrelations, andshowedaconsiderable correlation between the importance and the actual performance, suggesting the possibility of automatic context category selection." ></td>
	<td class="line x" title="113:114	As the future works, we should further discuss other kinds of formalization of distributional similarity and their impact, because we introduced and only briey described a quite simple formalization model in Section 2.3." ></td>
	<td class="line x" title="114:114	More detailed investigations on the contributions of sub-categories of contexts, and other contexts than dependency structure, such as surrounding words and dependency path, is also the future work." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P08-1002
Distributional Identification of Non-Referential Pronouns
Bergsma, Shane;Lin, Dekang;Goebel, Randy;"></td>
	<td class="line x" title="1:251	Proceedings of ACL-08: HLT, pages 1018, Columbus, Ohio, USA, June 2008." ></td>
	<td class="line x" title="2:251	c2008 Association for Computational Linguistics Distributional Identification of Non-Referential Pronouns Shane Bergsma Department of Computing Science University of Alberta Edmonton, Alberta Canada, T6G 2E8 bergsma@cs.ualberta.ca Dekang Lin Google, Inc. 1600 Amphitheatre Parkway Mountain View California, 94301 lindek@google.com Randy Goebel Department of Computing Science University of Alberta Edmonton, Alberta Canada, T6G 2E8 goebel@cs.ualberta.ca Abstract We present an automatic approach to determining whether a pronoun in text refers to a preceding noun phrase or is instead nonreferential." ></td>
	<td class="line x" title="3:251	We extract the surrounding textual context of the pronoun and gather, from a large corpus, the distribution of words that occur within that context." ></td>
	<td class="line x" title="4:251	We learn to reliably classify these distributions as representing either referential or non-referential pronoun instances." ></td>
	<td class="line x" title="5:251	Despite its simplicity, experimental results on classifying the English pronoun it show the system achieves the highest performance yet attained on this important task." ></td>
	<td class="line x" title="6:251	1 Introduction The goal of coreference resolution is to determine which noun phrases in a document refer to the same real-world entity." ></td>
	<td class="line x" title="7:251	As part of this task, coreference resolution systems must decide which pronouns refer to preceding noun phrases (called antecedents) and which do not." ></td>
	<td class="line x" title="8:251	In particular, a long-standing challenge has been to correctly classify instances of the English pronoun it." ></td>
	<td class="line x" title="9:251	Consider the sentences: (1) You can make it in advance." ></td>
	<td class="line x" title="10:251	(2) You can make it in Hollywood." ></td>
	<td class="line x" title="11:251	In sentence (1), it is an anaphoric pronoun referring to some previous noun phrase, like  the sauce or  an appointment." ></td>
	<td class="line x" title="12:251	In sentence (2), it is part of the idiomatic expression  make it meaning  succeed." ></td>
	<td class="line x" title="13:251	A coreference resolution system should  nd an antecedent for the  rst it but not the second." ></td>
	<td class="line x" title="14:251	Pronouns that do not refer to preceding noun phrases are called non-anaphoric or non-referential pronouns." ></td>
	<td class="line x" title="15:251	The word it is one of the most frequent words in the English language, accounting for about 1% of tokens in text and over a quarter of all third-person pronouns.1 Usually between a quarter and a half of it instances are non-referential (e.g. Section 4, Table 3)." ></td>
	<td class="line x" title="16:251	As with other pronouns, the preceding discourse can affect its interpretation." ></td>
	<td class="line x" title="17:251	For example, sentence (2) can be interpreted as referential if the preceding sentence is  You want to make a movie?" ></td>
	<td class="line x" title="18:251	We show, however, that we can reliably classify a pronoun as being referential or non-referential based solely on the local context surrounding the pronoun." ></td>
	<td class="line x" title="19:251	We do this by turning the context into patterns and enumerating all the words that can take the place of it in these patterns." ></td>
	<td class="line x" title="20:251	For sentence (1), we can extract the context pattern  make * in advance and for sentence (2)  make * in Hollywood, where  * is a wildcard that can be  lled by any token." ></td>
	<td class="line x" title="21:251	Nonreferential distributions tend to have the word it  lling the wildcard position." ></td>
	<td class="line x" title="22:251	Referential distributions occur with many other noun phrase  llers." ></td>
	<td class="line x" title="23:251	For example, in our n-gram collection (Section 3.4),  make it in advance and  make them in advance occur roughly the same number of times (442 vs. 449), indicating a referential pattern." ></td>
	<td class="line x" title="24:251	In contrast,  make it in Hollywood occurs 3421 times while  make them in Hollywood does not occur at all." ></td>
	<td class="line x" title="25:251	These simple counts strongly indicate whether another noun can replace the pronoun." ></td>
	<td class="line x" title="26:251	Thus we can computationally distinguish between a) pronouns that refer to nouns, and b) all other instances: including those that have no antecedent, like sentence (2), 1e.g. http://ucrel.lancs.ac.uk/bncfreq/ ists.html 10 and those that refer to sentences, clauses, or implied topics of discourse." ></td>
	<td class="line x" title="27:251	Beyond the practical value of this distinction, Section 3 provides some theoretical justi cation for our binary classi cation." ></td>
	<td class="line x" title="28:251	Section 3 also shows how to automatically extract and collect counts for context patterns, and how to combine the information using a machine learned classi er." ></td>
	<td class="line x" title="29:251	Section 4 describes our data for learning and evaluation, It-Bank: a set of over three thousand labelled instances of the pronoun it from a variety of text sources." ></td>
	<td class="line x" title="30:251	Section 4 also explains our comparison approaches and experimental methodology." ></td>
	<td class="line x" title="31:251	Section 5 presents our results, including an interesting comparison of our system to human classi cation given equivalent segments of context." ></td>
	<td class="line x" title="32:251	2 Related Work The dif culty of non-referential pronouns has been acknowledged since the beginning of computational resolution of anaphora." ></td>
	<td class="line x" title="33:251	Hobbs (1978) notes his algorithm does not handle pronominal references to sentences nor cases where it occurs in time or weather expressions." ></td>
	<td class="line x" title="34:251	Hirst (1981, page 17) emphasizes the importance of detecting non-referential pronouns,  lest precious hours be lost in bootless searches for textual referents." ></td>
	<td class="line x" title="35:251	Mcurrency1uller (2006) summarizes the evolution of computational approaches to nonreferential it detection." ></td>
	<td class="line x" title="36:251	In particular, note the pioneering work of Paice and Husk (1987), the inclusion of non-referential it detection in a full anaphora resolution system by Lappin and Leass (1994), and the machine learning approach of Evans (2001)." ></td>
	<td class="line x" title="37:251	There has recently been renewed interest in non-referential pronouns, driven by three primary sources." ></td>
	<td class="line x" title="38:251	First of all, research in coreference resolution has shown the bene ts of modules for general noun anaphoricity determination (Ng and Cardie, 2002; Denis and Baldridge, 2007)." ></td>
	<td class="line x" title="39:251	Unfortunately, these studies handle pronouns inadequately; judging from the decision trees and performance  gures, Ng and Cardie (2002)s system treats all pronouns as anaphoric by default." ></td>
	<td class="line x" title="40:251	Secondly, while most pronoun resolution evaluations simply exclude non-referential pronouns, recent unsupervised approaches (Cherry and Bergsma, 2005; Haghighi and Klein, 2007) must deal with all pronouns in unrestricted text, and therefore need robust modules to automatically handle non-referential instances." ></td>
	<td class="line x" title="41:251	Finally, reference resolution has moved beyond written text into in spoken dialog." ></td>
	<td class="line x" title="42:251	Here, non-referential pronouns are pervasive." ></td>
	<td class="line x" title="43:251	Eckert and Strube (2000) report that in the Switchboard corpus, only 45% of demonstratives and third-person pronouns have a noun phrase antecedent." ></td>
	<td class="line x" title="44:251	Handling the common nonreferential instances is thus especially vital." ></td>
	<td class="line x" title="45:251	One issue with systems for non-referential detection is the amount of language-speci c knowledge that must be encoded." ></td>
	<td class="line x" title="46:251	Consider a system that jointly performs anaphora resolution and word alignment in parallel corpora for machine translation." ></td>
	<td class="line x" title="47:251	For this task, we need to identify non-referential anaphora in multiple languages." ></td>
	<td class="line x" title="48:251	It is not always clear to what extent the features and modules developed for English systems apply to other languages." ></td>
	<td class="line x" title="49:251	For example, the detector of Lappin and Leass (1994) labels a pronoun as non-referential if it matches one of several syntactic patterns, including:  It is Cogv-ed that Sentence, where Cogv is a  cognitive verb such as recommend, think, believe, know, anticipate, etc. Porting this approach to a new language would require not only access to a syntactic parser and a list of cognitive verbs in that language, but the development of new patterns to catch non-referential pronoun uses that do not exist in English." ></td>
	<td class="line x" title="50:251	Moreover, writing a set of rules to capture this phenomenon is likely to miss many less-common uses." ></td>
	<td class="line x" title="51:251	Alternatively, recent machine-learning approaches leverage a more general representation of a pronoun instance." ></td>
	<td class="line x" title="52:251	For example, Mcurrency1uller (2006) has a feature for  distance to next complementizer (that, if, whether) and features for the tokens and part-of-speech tags of the context words." ></td>
	<td class="line x" title="53:251	Unfortunately, there is still a lot of implicit and explicit English-speci c knowledge needed to develop these features, including, for example, lists of  seem verbs such as appear, look, mean, happen." ></td>
	<td class="line x" title="54:251	Similarly, the machine-learned system of Boyd et al.(2005) uses a set of  idiom patterns like  on the face of it that trigger binary features if detected in the pronoun context." ></td>
	<td class="line x" title="56:251	Although machine learned systems can  exibly balance the various indicators and contra-indicators of non-referentiality, a particular feature is only useful if it is relevant to an example in limited labelled training data." ></td>
	<td class="line x" title="57:251	Our approach avoids hand-crafting a set of spe11 ci c indicator features; we simply use the distribution of the pronouns context." ></td>
	<td class="line oc" title="58:251	Our method is thus related to previous work based on Harris (1985)s distributional hypothesis.2 It has been used to determine both word and syntactic path similarity (Hindle, 1990; Lin, 1998a; Lin and Pantel, 2001)." ></td>
	<td class="line x" title="59:251	Our work is part of a trend of extracting other important information from statistical distributions." ></td>
	<td class="line x" title="60:251	Dagan and Itai (1990) use the distribution of a pronouns context to determine which candidate antecedents can  t the context." ></td>
	<td class="line x" title="61:251	Bergsma and Lin (2006) determine the likelihood of coreference along the syntactic path connecting a pronoun to a possible antecedent, by looking at the distribution of the path in text." ></td>
	<td class="line x" title="62:251	These approaches, like ours, are ways to inject sophisticated  world knowledge into anaphora resolution." ></td>
	<td class="line x" title="63:251	3 Methodology 3.1 Definition Our approach distinguishes contexts where pronouns cannot be replaced by a preceding noun phrase (non-noun-referential) from those where nouns can occur (noun-referential)." ></td>
	<td class="line x" title="64:251	Although coreference evaluations, such as the MUC (1997) tasks, also make this distinction, it is not necessarily used by all researchers." ></td>
	<td class="line x" title="65:251	Evans (2001), for example, distinguishes between  clause anaphoric and  pleonastic as in the following two instances: (3) The paper reported that it had snowed." ></td>
	<td class="line x" title="66:251	It was obvious." ></td>
	<td class="line x" title="67:251	(clause anaphoric) (4) It was obvious that it had snowed." ></td>
	<td class="line x" title="68:251	(pleonastic) The word It in sentence (3) is considered referential, while the word It in sentence (4) is considered non-referential.3 From our perspective, this interpretation is somewhat arbitrary." ></td>
	<td class="line x" title="69:251	One could also say that the It in both cases refers to the clause  that it had snowed." ></td>
	<td class="line x" title="70:251	Indeed, annotation experiments using very  ne-grained categories show low annotation reliability (Mcurrency1uller, 2006)." ></td>
	<td class="line x" title="71:251	On the other hand, there is no debate over the importance nor the de nition of distinguishing pronouns that refer to nouns from those that do not." ></td>
	<td class="line x" title="72:251	We adopt this distinction for our 2Words occurring in similar contexts have similar meanings 3The it in  it had snowed is, of course, non-referential." ></td>
	<td class="line x" title="73:251	work, and show it has good inter-annotator reliability (Section 4.1)." ></td>
	<td class="line x" title="74:251	We henceforth refer to non-nounreferential simply as non-referential, and thus consider the word It in both sentences (3) and (4) as non-referential." ></td>
	<td class="line x" title="75:251	Non-referential pronouns are widespread in natural language." ></td>
	<td class="line x" title="76:251	The es in the German  Wie geht es Ihnen and the il in the French  Sil vous pla  t are both non-referential." ></td>
	<td class="line x" title="77:251	In pro-drop languages that may omit subject pronouns, there remains the question of whether an omitted pronoun is referential (Zhao and Ng, 2007)." ></td>
	<td class="line x" title="78:251	Although we focus on the English pronoun it, our approach should differentiate any words that have both a structural and a referential role in language, e.g. words like this, there and that (Mcurrency1uller, 2007)." ></td>
	<td class="line x" title="79:251	We believe a distributional approach could also help in related tasks like identifying the generic use of you (Gupta et al., 2007)." ></td>
	<td class="line x" title="80:251	3.2 Context Distribution Our method extracts the context surrounding a pronoun and determines which other words can take the place of the pronoun in the context." ></td>
	<td class="line x" title="81:251	The extracted segments of context are called context patterns." ></td>
	<td class="line x" title="82:251	The words that take the place of the pronoun are called pattern fillers." ></td>
	<td class="line x" title="83:251	We gather pattern  llers from a large collection of n-gram frequencies." ></td>
	<td class="line x" title="84:251	The maximum size of a context pattern depends on the size of ngrams available in the data." ></td>
	<td class="line x" title="85:251	In our n-gram collection (Section 3.4), the lengths of the n-grams range from unigrams to 5-grams, so our maximum pattern size is  ve." ></td>
	<td class="line x" title="86:251	For a particular pronoun in text, there are  ve possible 5-grams that span the pronoun." ></td>
	<td class="line x" title="87:251	For example, in the following instance of it:  said here Thursday that it is unnecessary to continue  We can extract the following 5-gram patterns: said here Thursday that * here Thursday that * is Thursday that * is unnecessary that * is unnecessary to * is unnecessary to continue Similarly, we extract the four 4-gram patterns." ></td>
	<td class="line x" title="88:251	Shorter n-grams were not found to improve performance on development data and hence are not extracted." ></td>
	<td class="line x" title="89:251	We only use context within the current sentence (including the beginning-of-sentence and endof-sentence tokens) so if a pronoun occurs near a sentence boundary, some patterns may be missing." ></td>
	<td class="line x" title="90:251	12 Pattern Filler Type String #1: 3rd-person pron." ></td>
	<td class="line x" title="91:251	sing." ></td>
	<td class="line x" title="92:251	it/its #2: 3rd-person pron." ></td>
	<td class="line x" title="93:251	plur." ></td>
	<td class="line x" title="94:251	they/them/their #3: any other pronoun he/him/his/, I/me/my, etc. #4: infrequent word token UNK #5: any other token * Table 1: Pattern  ller types We take a few steps to improve generality." ></td>
	<td class="line x" title="95:251	We change the patterns to lower-case, convert sequences of digits to the # symbol, and run the Porter stemmer4 (Porter, 1980)." ></td>
	<td class="line x" title="96:251	To generalize rare names, we convert capitalized words longer than  ve characters to a special NE tag." ></td>
	<td class="line x" title="97:251	We also added a few simple rules to stem the irregular verbs be, have, do, and said, and convert the common contractions nt, s, m, re, ve, d, and ll to their most likely stem." ></td>
	<td class="line x" title="98:251	We do the same processing to our n-gram corpus." ></td>
	<td class="line x" title="99:251	We then  nd all n-grams matching our patterns, allowing any token to match the wildcard in place of it." ></td>
	<td class="line x" title="100:251	Also, other pronouns in the pattern are allowed to match a corresponding pronoun in an n-gram, regardless of differences in in ection and class." ></td>
	<td class="line x" title="101:251	We now discuss how to use the distribution of pattern  llers." ></td>
	<td class="line x" title="102:251	For identifying non-referential it in English, we are interested in how often it occurs as a pattern  ller versus other nouns." ></td>
	<td class="line x" title="103:251	However, determining part-of-speech in a large n-gram corpus is not simple, nor would it easily extend to other languages." ></td>
	<td class="line x" title="104:251	Instead, we gather counts for  ve different classes of words that  ll the wildcard position, easily determined by string match (Table 1)." ></td>
	<td class="line x" title="105:251	The third-person plural they (#2) reliably occurs in patterns where referential it also resides." ></td>
	<td class="line x" title="106:251	The occurrence of any other pronoun (#3) guarantees that at the very least the pattern  ller is a noun." ></td>
	<td class="line x" title="107:251	A match with the infrequent word token UNK (#4) (explained in Section 3.4) will likely be a noun because nouns account for a large proportion of rare words in a corpus." ></td>
	<td class="line x" title="108:251	Gathering any other token (#5) also mostly  nds nouns; inserting another part-of-speech usually 4Adapted from the Bow-toolkit (McCallum, 1996)." ></td>
	<td class="line x" title="109:251	Our method also works without the stemmer; we simply truncate the words in the pattern at a given maximum length (see Section 5.1)." ></td>
	<td class="line x" title="110:251	With simple truncation, all the pattern processing can be easily applied to other languages." ></td>
	<td class="line x" title="111:251	Pattern Filler Counts#1 #2 #3 #5 sai here NE that * 84 0 291 3985 here NE that * be 0 0 0 93 NE that * be unnecessari 0 0 0 0 that * be unnecessari to 16726 56 0 228 * be unnecessari to continu 258 0 0 0 Table 2: 5-gram context patterns and patternller counts for the Section 3.2 example." ></td>
	<td class="line x" title="112:251	results in an unlikely, ungrammatical pattern." ></td>
	<td class="line x" title="113:251	Table 2 gives the stemmed context patterns for our running example." ></td>
	<td class="line x" title="114:251	It also gives the n-gram counts of pattern  llers matching the  rst four  ller types (there were no matches of the UNK type, #4)." ></td>
	<td class="line x" title="115:251	3.3 Feature Vector Representation There are many possible ways to use the above counts." ></td>
	<td class="line x" title="116:251	Intuitively, our method should identify as non-referential those instances that have a high proportion of  llers of type #1 (i.e., the word it), while labelling as referential those with high counts for other types of  llers." ></td>
	<td class="line x" title="117:251	We would also like to leverage the possibility that some of the patterns may be more predictive than others, depending on where the wildcard lies in the pattern." ></td>
	<td class="line x" title="118:251	For example, in Table 2, the cases where the it-position is near the beginning of the pattern best re ect the non-referential nature of this instance." ></td>
	<td class="line x" title="119:251	We can achieve these aims by ordering the counts in a feature vector, and using a labelled set of training examples to learn a classi er that optimally weights the counts." ></td>
	<td class="line x" title="120:251	For classi cation, we de ne non-referential as positive and referential as negative." ></td>
	<td class="line x" title="121:251	Our feature representation very much resembles Table 2." ></td>
	<td class="line x" title="122:251	For each of the  ve 5-gram patterns, ordered by the position of the wildcard, we have features for the logarithm of counts for  ller types #1, #2,  #5." ></td>
	<td class="line x" title="123:251	Similarly, for each of the four 4-gram patterns, we provide the log-counts corresponding to types #1, #2,  #5 as well." ></td>
	<td class="line x" title="124:251	Before taking the logarithm, we smooth the counts by adding a  xed number to all observed values." ></td>
	<td class="line x" title="125:251	We also provide, for each pattern, a feature that indicates if the pattern is not available because the it-position would cause the pattern to span beyond the current sentence." ></td>
	<td class="line x" title="126:251	There are twentyve 5-gram, twenty 4-gram, and nine indicator features in total." ></td>
	<td class="line x" title="127:251	13 Our classi er should learn positive weights on the type #1 counts and negative weights on the other types, with higher absolute weights on the more predictive  ller types and pattern positions." ></td>
	<td class="line x" title="128:251	Note that leaving the pattern counts unnormalized automatically allows patterns with higher counts to contribute more to the prediction of their associated instances." ></td>
	<td class="line x" title="129:251	3.4 N-Gram Data We now describe the collection of n-grams and their counts used in our implementation." ></td>
	<td class="line x" title="130:251	We use, to our knowledge, the largest publicly available collection: the Google Web 1T 5-gram Corpus Version 1.1.5 This collection was generated from approximately 1 trillion tokens of online text." ></td>
	<td class="line x" title="131:251	In this data, tokens appearing less than 200 times have been mapped to the UNK symbol." ></td>
	<td class="line x" title="132:251	Also, only n-grams appearing more than 40 times are included." ></td>
	<td class="line x" title="133:251	For languages where such an extensive n-gram resource is not available, the n-gram counts could also be taken from the pagecounts returned by an Internet search engine." ></td>
	<td class="line x" title="134:251	4 Evaluation 4.1 Labelled It Data We need labelled data for training and evaluation of our system." ></td>
	<td class="line x" title="135:251	This data indicates, for every occurrence of the pronoun it, whether it refers to a preceding noun phrase or not." ></td>
	<td class="line x" title="136:251	Standard coreference resolution data sets annotate all noun phrases that have an antecedent noun phrase in the text." ></td>
	<td class="line x" title="137:251	Therefore, we can extract labelled instances of it from these sets." ></td>
	<td class="line x" title="138:251	We do this for the dry-run and formal sets from MUC-7 (1997), and merge them into a single data set." ></td>
	<td class="line x" title="139:251	Of course, full coreference-annotated data is a precious resource, with the pronoun it making up only a small portion of the marked-up noun phrases." ></td>
	<td class="line x" title="140:251	We thus created annotated data speci cally for the pronoun it." ></td>
	<td class="line x" title="141:251	We annotated 1020 instances in a collection of Science News articles (from 1995-2000), downloaded from the Science News website." ></td>
	<td class="line x" title="142:251	We also annotated 709 instances in the WSJ portion of the DARPA TIPSTER Project (Harman, 1992), and 279 instances in the English portion of the Europarl Corpus (Koehn, 2005)." ></td>
	<td class="line x" title="143:251	A single annotator (A1) labelled all three data sets, while two additional annotators not connected 5Available from the LDC as LDC2006T13 Data Set Number of It % Non-Referential Europarl 279 50.9 Sci-News 1020 32.6 WSJ 709 25.1 MUC 129 31.8 Train 1069 33.2 Test 1067 31.7 Test-200 200 30.0 Table 3: Data sets used in experiments." ></td>
	<td class="line x" title="144:251	with the project (A2 and A3) were asked to separately re-annotate a portion of each, so that interannotator agreement could be calculated." ></td>
	<td class="line x" title="145:251	A1 and A2 agreed on 96% of annotation decisions, while A1-A3, and A2-A3, agreed on 91% and 93% of decisions, respectively." ></td>
	<td class="line x" title="146:251	The Kappa statistic (Jurafsky and Martin, 2000, page 315), with P(E) computed from the confusion matrices, was a high 0.90 for A1A2, and 0.79 and 0.81 for the other pairs, around the 0.80 considered to be good reliability." ></td>
	<td class="line x" title="147:251	These are, perhaps surprisingly, the only known it-annotationagreement statistics available for written text." ></td>
	<td class="line x" title="148:251	They contrast favourably with the low agreement seen on categorizing it in spoken dialog (Mcurrency1uller, 2006)." ></td>
	<td class="line x" title="149:251	We make all the annotations available in It-Bank, an online repository for annotated it-instances.6 It-Bank also allows other researchers to distribute their it annotations." ></td>
	<td class="line x" title="150:251	Often, the full text of articles containing annotations cannot be shared because of copyright." ></td>
	<td class="line x" title="151:251	However, sharing just the sentences containing the word it, randomly-ordered, is permissible under fair-use guidelines." ></td>
	<td class="line x" title="152:251	The original annotators retain their copyright on the annotations." ></td>
	<td class="line x" title="153:251	We use our annotated data in two ways." ></td>
	<td class="line x" title="154:251	First of all, we perform cross-validation experiments on each of the data sets individually, to help gauge the dif culty of resolution on particular domains and volumes of training data." ></td>
	<td class="line x" title="155:251	Secondly, we randomly distribute all instances into two main sets, a training set and a test set." ></td>
	<td class="line x" title="156:251	We also construct a smaller test set, Test-200, containing only the  rst 200 instances in the Test set." ></td>
	<td class="line x" title="157:251	We use Test-200 for human experiments and error analysis (Section 5.2)." ></td>
	<td class="line x" title="158:251	Table 3 summarizes all the sets used in the experiments." ></td>
	<td class="line x" title="159:251	6www.cs.ualberta.ca/ bergsma/ItBank/." ></td>
	<td class="line x" title="160:251	It-Bank also contains an additional 1,077 examples used as development data." ></td>
	<td class="line x" title="161:251	14 4.2 Comparison Approaches We represent feature vectors exactly as described in Section 3.3." ></td>
	<td class="line x" title="162:251	We smooth by adding 40 to all counts, equal to the minimum count in the n-gram data." ></td>
	<td class="line x" title="163:251	For classi cation, we use a maximum entropy model (Berger et al., 1996), from the logistic regression package in Weka (Witten and Frank, 2005), with all default parameter settings." ></td>
	<td class="line x" title="164:251	Results with our distributional approach are labelled as DISTRIB." ></td>
	<td class="line x" title="165:251	Note that our maximum entropy classi er actually produces a probability of non-referentiality, which is thresholded at 50% to make a classi cation." ></td>
	<td class="line x" title="166:251	As a baseline, we implemented the non-referential it detector of Lappin and Leass (1994), labelled as LL in the results." ></td>
	<td class="line x" title="167:251	This is a syntactic detector, a point missed by Evans (2001) in his criticism: the patterns are robust to intervening words and modi ers (e.g.  it was never thought by the committee that ) provided the sentence is parsed correctly.7 We automatically parse sentences with Minipar, a broad-coverage dependency parser (Lin, 1998b)." ></td>
	<td class="line x" title="168:251	We also use a separate, extended version of the LL detector, implemented for large-scale nonreferential detection by Cherry and Bergsma (2005)." ></td>
	<td class="line x" title="169:251	This system, also for Minipar, additionally detects instances of it labelled with Minipars pleonastic category Subj." ></td>
	<td class="line x" title="170:251	It uses Minipars named-entity recognition to identify time expressions, such as  it was midnight, and provides a number of other patterns to match common non-referential it uses, such as in expressions like  darn it,  dont overdo it, etc. This extended detector is labelled as MINIPL (for Minipar pleonasticity) in our results." ></td>
	<td class="line x" title="171:251	Finally, we tested a system that combines the above three approaches." ></td>
	<td class="line x" title="172:251	We simply add the LL and MINIPL decisions as binary features in the DISTRIB system." ></td>
	<td class="line x" title="173:251	This system is called COMBO in our results." ></td>
	<td class="line x" title="174:251	4.3 Evaluation Criteria We follow Mcurrency1uller (2006)s evaluation criteria." ></td>
	<td class="line x" title="175:251	Precision (P) is the proportion of instances that we label as non-referential that are indeed non-referential." ></td>
	<td class="line x" title="176:251	Recall (R) is the proportion of true non-referentials that we detect, and is thus a measure of the coverage 7Our approach, on the other hand, would seem to be susceptible to such intervening material, if it pushes indicative context tokens out of the 5-token window." ></td>
	<td class="line x" title="177:251	System P R F Acc LL 93.4 21.0 34.3 74.5 MINIPL 66.4 49.7 56.9 76.1 DISTRIB 81.4 71.0 75.8 85.7 COMBO 81.3 73.4 77.1 86.2 Table 4: Train/Test-split performance (%)." ></td>
	<td class="line x" title="178:251	of the system." ></td>
	<td class="line x" title="179:251	F-Score (F) is the geometric average of precision and recall; it is the most common nonreferential detection metric." ></td>
	<td class="line x" title="180:251	Accuracy (Acc) is the percentage of instances labelled correctly." ></td>
	<td class="line x" title="181:251	5 Results 5.1 System Comparison Table 4 gives precision, recall, F-score, and accuracy on the Train/Test split." ></td>
	<td class="line x" title="182:251	Note that while the LL system has high detection precision, it has very low recall, sharply reducing F-score." ></td>
	<td class="line x" title="183:251	The MINIPL approach sacri ces some precision for much higher recall, but again has fairly low F-score." ></td>
	<td class="line x" title="184:251	To our knowledge, our COMBO system, with an F-Score of 77.1%, achieves the highest performance of any non-referential system yet implemented." ></td>
	<td class="line x" title="185:251	Even more importantly, DISTRIB, which requires only minimal linguistic processing and no encoding of speci c indicator patterns, achieves 75.8% F-Score." ></td>
	<td class="line x" title="186:251	The difference between COMBO and DISTRIB is not statistically signi cant, while both are signi cantly better than the rule-based approaches.8 This provides strong motivation for a  light-weight approach to non-referential it detection  one that does not require parsing or hand-crafted rules and  is easily ported to new languages and text domains." ></td>
	<td class="line x" title="187:251	Since applying an English stemmer to the context words (Section 3.2) reduces the portability of the distributional technique, we investigated the use of more portable pattern abstraction." ></td>
	<td class="line x" title="188:251	Figure 1 compares the use of the stemmer to simply truncating the words in the patterns at a certain maximum length." ></td>
	<td class="line x" title="189:251	Using no truncation (Unaltered) drops the F-Score by 4.3%, while truncating the patterns to a length of four only drops the F-Score by 1.4%, a difference which is not statistically signi cant." ></td>
	<td class="line x" title="190:251	Simple truncation may be a good option for other languages where stemmers are not readily available." ></td>
	<td class="line x" title="191:251	The optimum 8All signi cance testing uses McNemars test, p<0.05 15  68  70  72  74  76  78  80  1  2  3  4  5  6  7  8  9  10 F-Score Truncated word length Stemmed patterns Truncated patterns Unaltered patterns Figure 1: Effect of pattern-word truncation on nonreferential it detection (COMBO system, Train/Test split)." ></td>
	<td class="line x" title="192:251	System Europl." ></td>
	<td class="line x" title="193:251	Sci-News WSJ MUC LL 44.0 39.3 21.5 13.3 MINIPL 70.3 61.8 22.0 50.7 DISTRIB 79.7 77.2 69.5 68.2 COMBO 76.2 78.7 68.1 65.9 COMBO4 83.6 76.5 67.1 74.7 Table 5: 10-fold cross validation F-Score (%)." ></td>
	<td class="line x" title="194:251	truncation size will likely depend on the length of the base forms of words in that language." ></td>
	<td class="line x" title="195:251	For realworld application of our approach, truncation also reduces the table sizes (and thus storage and lookup costs) of any pre-compiled it-pattern database." ></td>
	<td class="line x" title="196:251	Table 5 compares the 10-fold cross-validation Fscore of our systems on the four data sets." ></td>
	<td class="line x" title="197:251	The performance of COMBO on Europarl and MUC is affected by the small number of instances in these sets (Section 4, Table 3)." ></td>
	<td class="line x" title="198:251	We can reduce data fragmentation by removing features." ></td>
	<td class="line x" title="199:251	For example, if we only use the length-4 patterns in COMBO (labelled as COMBO4), performance increases dramatically on Europarl and MUC, while dipping slightly for the larger Sci-News and WSJ sets." ></td>
	<td class="line x" title="200:251	Furthermore, selecting just the three most useful  ller type counts as features (#1,#2,#5), boosts F-Score on Europarl to 86.5%, 10% above the full COMBO system." ></td>
	<td class="line x" title="201:251	5.2 Analysis and Discussion In light of these strong results, it is worth considering where further gains in performance might yet be found." ></td>
	<td class="line x" title="202:251	One key question is to what extent a limited context restricts identi cation performance." ></td>
	<td class="line x" title="203:251	We  rst tested the importance of the pattern length by System P R F Acc DISTRIB 80.0 73.3 76.5 86.5 COMBO 80.7 76.7 78.6 87.5 Human-1 92.7 63.3 75.2 87.5 Human-2 84.0 70.0 76.4 87.0 Human-3 72.2 86.7 78.8 86.0 Table 6: Evaluation on Test-200 (%)." ></td>
	<td class="line x" title="204:251	using only the length-4 counts in the DISTRIB system (Train/Test split)." ></td>
	<td class="line x" title="205:251	Surprisingly, the drop in FScore was only one percent, to 74.8%." ></td>
	<td class="line x" title="206:251	Using only the length-5 counts drops F-Score to 71.4%." ></td>
	<td class="line x" title="207:251	Neither are statistically signi cant; however there seems to be diminishing returns from longer context patterns." ></td>
	<td class="line x" title="208:251	Another way to view the limited context is to ask, given the amount of context we have, are we making optimum use of it?" ></td>
	<td class="line x" title="209:251	We answer this by seeing how well humans can do with the same information." ></td>
	<td class="line x" title="210:251	As explained in Section 3.2, our system uses 5-gram context patterns that together span from four-to-theleft to four-to-the-right of the pronoun." ></td>
	<td class="line x" title="211:251	We thus provide these same nine-token windows to our human subjects, and ask them to decide whether the pronouns refer to previous noun phrases or not, based on these contexts." ></td>
	<td class="line x" title="212:251	Subjects  rst performed a dryrun experiment on separate development data." ></td>
	<td class="line x" title="213:251	They were shown their errors and sources of confusion were clari ed." ></td>
	<td class="line x" title="214:251	They then made the judgments unassisted on the  nal Test-200 data." ></td>
	<td class="line x" title="215:251	Three humans performed the experiment." ></td>
	<td class="line x" title="216:251	Their results show a range of preferences for precision versus recall, with both F-Score and Accuracy on average below the performance of COMBO (Table 6)." ></td>
	<td class="line x" title="217:251	Foremost, these results show that our distributional approach is already getting good leverage from the limited context information, around that achieved by our best human." ></td>
	<td class="line x" title="218:251	It is instructive to inspect the twentyve Test-200 instances that the COMBO system classi ed incorrectly, given human performance on this same set." ></td>
	<td class="line x" title="219:251	Seventeen of the twentyve COMBO errors were also made by one or more human subjects, suggesting system errors are also mostly due to limited context." ></td>
	<td class="line x" title="220:251	For example, one of these errors was for the context:  it takes an astounding amount Here, the non-referential nature of the instance is not apparent without the in nitive clause that ends the sentence:   of time to compare very long DNA sequences 16 with each other." ></td>
	<td class="line x" title="221:251	Six of the eight errors unique to the COMBO system were cases where the system falsely said the pronoun was non-referential." ></td>
	<td class="line x" title="222:251	Four of these could have referred to entire sentences or clauses rather than nouns." ></td>
	<td class="line x" title="223:251	These confusing cases, for both humans and our system, result from our de nition of a referential pronoun: pronouns with verbal or clause antecedents are considered non-referential (Section 3.1)." ></td>
	<td class="line x" title="224:251	If an antecedent verb or clause is replaced by a nominalization (Smith researched to Smiths research), a referring pronoun, in the same context, becomes referential." ></td>
	<td class="line x" title="225:251	When we inspect the probabilities produced by the maximum entropy classi er (Section 4.2), we see only a weak bias for the non-referential class on these examples, re ecting our classi ers uncertainty." ></td>
	<td class="line x" title="226:251	It would likely be possible to improve accuracy on these cases by encoding the presence or absence of preceding nominalizations as a feature of our classi er." ></td>
	<td class="line x" title="227:251	Another false non-referential decision is for the phrase   machine he had installed it on." ></td>
	<td class="line x" title="228:251	The it is actually referential, but the extracted patterns (e.g.  he had install * on ) are nevertheless usually  lled with it.9 Again, it might be possible to  x such examples by leveraging the preceding discourse." ></td>
	<td class="line x" title="229:251	Notably, the  rst noun-phrase before the context is the word  software." ></td>
	<td class="line x" title="230:251	There is strong compatibility between the pronoun-parent  install and the candidate antecedent  software." ></td>
	<td class="line x" title="231:251	In a full coreference resolution system, when the anaphora resolution module has a strong preference to link it to an antecedent (which it should when the pronoun is indeed referential), we can override a weak non-referential probability." ></td>
	<td class="line x" title="232:251	Non-referential it detection should not be a pre-processing step, but rather part of a globallyoptimal con guration, as was done for general noun phrase anaphoricity by Denis and Baldridge (2007)." ></td>
	<td class="line x" title="233:251	The suitability of this kind of approach to correcting some of our systems errors is especially obvious when we inspect the probabilities of the maximum entropy models output decisions on the Test-200 set." ></td>
	<td class="line x" title="234:251	Where the maximum entropy classi er makes mistakes, it does so with less con dence than when it classi es correct examples." ></td>
	<td class="line x" title="235:251	The average predicted 9This example also suggests using  ller counts for the word  the as a feature when it is the last word in the pattern." ></td>
	<td class="line x" title="236:251	probability of the incorrect classi cations is 76.0% while the average probability of the correct classi cations is 90.3%." ></td>
	<td class="line x" title="237:251	Many incorrect decisions are ready to switch sides; our next step will be to use features of the preceding discourse and the candidate antecedents to help give them a push." ></td>
	<td class="line x" title="238:251	6 Conclusion We have presented an approach to detecting nonreferential pronouns in text based on the distribution of the pronouns context." ></td>
	<td class="line x" title="239:251	The approach is simple to implement, attains state-of-the-art results, and should be easily ported to other languages." ></td>
	<td class="line x" title="240:251	Our technique demonstrates how large volumes of data can be used to gather world knowledge for natural language processing." ></td>
	<td class="line x" title="241:251	A consequence of this research was the creation of It-Bank, a collection of thousands of labelled examples of the pronoun it, which will bene t other coreference resolution researchers." ></td>
	<td class="line x" title="242:251	Error analysis reveals that our system is getting good leverage out of the pronoun context, achieving results comparable to human performance given equivalent information." ></td>
	<td class="line x" title="243:251	To boost performance further, we will need to incorporate information from preceding discourse." ></td>
	<td class="line x" title="244:251	Future research will also test the distributional classi cation of other ambiguous pronouns, like this, you, there, and that." ></td>
	<td class="line x" title="245:251	Another avenue of study will look at the interaction between coreference resolution and machine translation." ></td>
	<td class="line x" title="246:251	For example, if a single form in English (e.g. that) is separated into different meanings in another language (e.g., Spanish demonstrative ese, nominal reference ese, abstract or statement reference eso, and complementizer que), then aligned examples provide automatically-disambiguated English data." ></td>
	<td class="line x" title="247:251	We could extract context patterns and collect statistics from these examples like in our current approach." ></td>
	<td class="line x" title="248:251	In general, jointly optimizing translation and coreference is an exciting and largely unexplored research area, now partly enabled by our portable nonreferential detection methodology." ></td>
	<td class="line x" title="249:251	Acknowledgments We thank Kristin Musselman and Christopher Pinchak for assistance preparing the data, and we thank Google Inc. for sharing their 5-gram corpus." ></td>
	<td class="line x" title="250:251	We gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada, the Alberta Ingenuity Fund, and the Alberta Informatics Circle of Research Excellence." ></td>
	<td class="line x" title="251:251	17" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P08-2008
Novel Semantic Features for Verb Sense Disambiguation
Dligach, Dmitriy;Palmer, Martha Stone;"></td>
	<td class="line x" title="1:83	Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 2932, Columbus, Ohio, USA, June 2008." ></td>
	<td class="line x" title="2:83	c2008 Association for Computational Linguistics Novel Semantic Features for Verb Sense Disambiguation Dmitriy Dligach The Center for Computational Language and Education Research 1777 Exposition Drive Boulder, Colorado 80301 Dmitriy.Dligach @colorado.edu Martha Palmer Department of Linguistics University of Colorado at Boulder 295 UCB Boulder, Colorado 80309 Martha.Palmer @colorado.edu   Abstract We propose a novel method for extracting semantic information about a verb's arguments and apply it to Verb Sense Disambiguation (VSD)." ></td>
	<td class="line x" title="3:83	We contrast this method with two popular approaches to retrieving this information and show that it improves the performance of our VSD system and outperforms the other two approaches 1 Introduction The task of Verb Sense Disambiguation (VSD) consists in automatically assigning a sense to a verb (target verb) given its context." ></td>
	<td class="line x" title="4:83	In a supervised setting, a VSD system is usually trained on a set of pre-labeled examples; the goal of this system is to tag unseen examples with a sense from some sense inventory." ></td>
	<td class="line x" title="5:83	An automatic VSD system usually has at its disposal a diverse set of features among which the semantic features play an important role: verb sense distinctions often depend on the distinctions in the semantics of the target verb's arguments (Hanks, 1996)." ></td>
	<td class="line x" title="6:83	Therefore, some method of capturing the semantic knowledge about the verb's arguments is crucial to the success of a VSD system." ></td>
	<td class="line x" title="7:83	The approaches to obtaining this kind of knowledge can be based on extracting it from ele ctronic dictionaries such as WordNet (Fellbaum, 1998), using Named Entity (NE) tags, or a combination of both (Chen, 2005)." ></td>
	<td class="line x" title="8:83	In this paper, we propose a novel method for obtaining semantic knowledge about words and show how it can be applied to VSD." ></td>
	<td class="line x" title="9:83	We contrast this method with the other two approaches and compare their performances in a series of experiments." ></td>
	<td class="line x" title="10:83	2 Lexical and Syntactic Features We view VSD as a supervised learning problem, solving which requires three groups of features: lexical, syntactic, and semantic." ></td>
	<td class="line x" title="11:83	Lexical features include all open class words; we extract them from the target sentence and the two surrounding sentences." ></td>
	<td class="line x" title="12:83	We also use as features two words on the right and on the left of the target verb as well as their POS tags." ></td>
	<td class="line x" title="13:83	We extract syntactic features from constituency parses; they indicate whether the target verb has a subject/object and what their head words and POS tags are, whether the target verb is in a passive or active form, whether the target verb has a subordinate clause, and whether the target verb has a PP adjunct." ></td>
	<td class="line x" title="14:83	Additionally, we implement several new syntactic features, which have not been used in VSD before: the path through the parse tree from the target verb to the verb's arguments and the subcategorization frame, as used in semantic role labeling." ></td>
	<td class="line x" title="15:83	3 Semantic Features Consider the verb prepare for which our sense inventory defines two senses: (1) to put together, assemble (e.g. He is going to prepare breakfast for the whole crowd ; I haven't prepared my lecture 29 yet); (2) to make ready (e.g. She prepared the children for school every morning)." ></td>
	<td class="line x" title="16:83	Knowing the semantic class of the objects breakfast, lecture and children is the decisive factor in distinguishing the two senses and facilitates better generalization from the training data." ></td>
	<td class="line x" title="17:83	One way to obtain this knowledge is from Wor dNet (WN) or from the output of a NE-tagger." ></td>
	<td class="line x" title="18:83	However, both approaches suffer from the same limitation: they collapse multiple semantic properties of nouns into a finite number of predefined static classes." ></td>
	<td class="line x" title="19:83	E.g., the most immediate hypernym of breakfast in WN is meal, while the most immediate hypernym of lecture is address, which makes these two nouns unrelated." ></td>
	<td class="line x" title="20:83	Yet, breakfast and lecture are both social events which share some semantic properties: they both can be attended, hosted, delivered, given, held, organized etc. To discover these class-like descriptions of nouns, one can observe which verbs take these nouns as objects." ></td>
	<td class="line x" title="21:83	E.g. breakfast can serve as the object of serve, host, attend, and cook  which are all indicative of breakfast's semantic properties." ></td>
	<td class="line x" title="22:83	Given a noun, we can dynamically retrieve other verbs that take that noun as an object from a dependency-parsed corpus; we call this kind of data Dynamic Dependency Neighbors  (DDNs) because it is obtained dynamically and based on the dependency relations in the neighborhood of the noun of interest." ></td>
	<td class="line x" title="23:83	The top 501 DDNs can be viewed as a reliable inventory of semantic properties of the noun." ></td>
	<td class="line x" title="24:83	To collect this data, we utilized two resources: (1) MaltParser (Nivre, 2007)  a high-efficiency dependency parser; (2) English Gigaword  a large corpus of 5.7M news articles." ></td>
	<td class="line x" title="25:83	We preprocessed Gigaword with MaltParser, extracted all pairs of nouns and verbs that were parsed as participants of the object-verb relation, and counted the frequency of occurrence of all the unique pa irs." ></td>
	<td class="line x" title="26:83	Finally, we indexed the resulting records of the form <frequency, verb, object> using the Lucene2 indexing engine." ></td>
	<td class="line x" title="27:83	As an example, consider four nouns: dinner, breakfast, lecture, child." ></td>
	<td class="line x" title="28:83	When used as the objects of prepare, the first three of them correspond to the instances of the sense 1 of prepare; the fourth one  1 In future, we will try to optimize this parameter 2 Available at http://lucene.apache.org/ corresponds to an instance of the sense 2." ></td>
	<td class="line x" title="29:83	With the help of our index, we can retrieve their DDNs." ></td>
	<td class="line x" title="30:83	There is a considerable overlap among the DDNs of the first three nouns and a much smaller overlap between child  and the first three nouns." ></td>
	<td class="line x" title="31:83	E.g., dinner and breakfast have 34 DDNs in common, while dinner and child  only share 14." ></td>
	<td class="line x" title="32:83	Once we have set up the framework for the extraction of DDNs, the algorithm for applying them to VSD is straightforward: (1) find the noun object of the ambiguous verb (2) extract the DDNs for that noun (3) sort the DDNs by frequency and keep the top 50 (4) include these DDNs in the feature vector so that each of the extracted verbs becomes a separate feature." ></td>
	<td class="line x" title="33:83	4 Relevant Work At the core of our work lies the notion of distrib utional similarity (Harris, 1968), which states that similar words occur in similar contexts." ></td>
	<td class="line x" title="34:83	In various sources, the notion of context ranges from bag-ofwords-like approaches to more structured ones in which syntax plays a role." ></td>
	<td class="line x" title="35:83	Schutze (1998) used bag-of-words contexts for sense discrimination." ></td>
	<td class="line oc" title="36:83	Hindle (1990) grouped nouns into thesaurus-like lists based on the similarity of their syntactic contexts." ></td>
	<td class="line x" title="37:83	Our approach is similar with the difference that we do not group noun arguments into finite categories, but instead leave the category boundaries blurry and allow overlaps." ></td>
	<td class="line x" title="38:83	The DDNs are essentially a form of world knowledge which we extract automatically and apply to VSD." ></td>
	<td class="line x" title="39:83	Other researches attacked the problem of unsupervised extraction of world know ledge: Schubert (2003) reports a method for extracting general facts about the world from treebanked Brown corpus." ></td>
	<td class="line x" title="40:83	Lin and Pantel in (2001) describe their DIRT system for extraction of paraphrase-like inference rules." ></td>
	<td class="line x" title="41:83	5 Evaluation We selected a subset of the verbs annotated in the OntoNotes project (Chen, 2007) that had at least 50 instances." ></td>
	<td class="line x" title="42:83	The resulting data set consisted of 46,577 instances of 217 verbs." ></td>
	<td class="line x" title="43:83	The predominant sense baseline for this data is 68%." ></td>
	<td class="line x" title="44:83	We used 30 libsvm3 for classification." ></td>
	<td class="line x" title="45:83	We computed the accuracy and error rate using 5-fold cross-validation." ></td>
	<td class="line x" title="46:83	5.1 Experiments with a limited set of features The main objective of this experiment was to isolate the effect of the novel semantic features we proposed in this paper, i.e. the DDN features." ></td>
	<td class="line x" title="47:83	Toward that goal, we stripped our system of all the features but the most essential ones to investigate whether the DDN features would have a clearly positive or negative impact on the system performance." ></td>
	<td class="line x" title="48:83	Lexical features are the most essential to our system: a model that includes only the lexical features achieves an accuracy of 80.22, while the accuracy of our full-blown VSD system is 82.88%4." ></td>
	<td class="line x" title="49:83	Since the DDN features have no effect when the object is not present, we identified 18,930 instances where the target verb had an object (about 41% of all instances) and used only them in the experiment." ></td>
	<td class="line x" title="50:83	We built three models that included (1) the lexical features only (2) the lexical and the DDN features (3) the lexical and the object features." ></td>
	<td class="line x" title="51:83	The object features consist of the head word of the NP object and the head word's POS tag." ></td>
	<td class="line x" title="52:83	The object is included since extracting the DDN features requires knowledge of the object; therefore the performance of a model that only includes lexical features cannot be considered a fair baseline for studying the effect of the DDN features." ></td>
	<td class="line x" title="53:83	Results are in Table 4." ></td>
	<td class="line x" title="54:83	Features Included in Model Accuracy, % Error Rate, % Lexical 78.95 21.05 Lexical + Object  79.34 20.66 Lexical + DDN 82.40 17.60  Table 4." ></td>
	<td class="line x" title="55:83	Experiments with object instances  As we see, the model that includes the DDN features performs more than 3 percentage points better than the model that only includes the object features (approximately 15% reduction in error rate)." ></td>
	<td class="line x" title="56:83	Also, based on the comparison of the performance of the 'lexical features only' and the 'lexical + DDN' models, we can claim that the  3 http://www.csie.ntu.edu.tw/~cjlin/libsvm/ 4 Given this high baseline, we include error rate when reporting the results of the experiments as it is more informative knowledge of the DDNs provides richer semantic knowledge than just the knowledge of the object's head word." ></td>
	<td class="line x" title="57:83	5.2 Integrating the DDN features into a fullfledged VSD system The objective of this experiment was to investigate whether the DDN features improve the performance of a full-fledged VSD system." ></td>
	<td class="line x" title="58:83	We built two models which consisted of (1) the entire set of features (2) all the features of the first model exclu ding the DDN features." ></td>
	<td class="line x" title="59:83	The entire data set (46K instances) participated in the experiment." ></td>
	<td class="line x" title="60:83	Results are in Table 5." ></td>
	<td class="line x" title="61:83	Features Included in Model Accuracy, % Error Rate, % All Features  DDN 82.38 17.62 All Features 82.88 17.12  Table 5." ></td>
	<td class="line x" title="62:83	Performance of the full-fledged VSD system  The DDN features improved performance by 0.5% (3% drop in error rate)." ></td>
	<td class="line x" title="63:83	The difference between the accuracies is statistically significant (p=0.05)." ></td>
	<td class="line x" title="64:83	5.3 Relative Contribution of Various Semantic Fe atures The goal of this experiment was to study the relative contribution of various semantic features to the performance of our VSD system." ></td>
	<td class="line x" title="65:83	We built five models each of which, in addition to the lexical and syntactic features, included only certain type(s) of semantic feature: (1) WN (2) NE (3) WN and NE (4) DDN (5) no semantic features (baseline)." ></td>
	<td class="line x" title="66:83	All 46K instances participated in the experiment." ></td>
	<td class="line x" title="67:83	The results are shown in Table 6." ></td>
	<td class="line x" title="68:83	Features Included in Model Accuracy, % Error Rate, % Lexical + Syntactic 81.82 18.18 Lexical + Syntactic + WN 82.34 17.60 Lexical + Syntactic + NE 82.01 17.99 Lexical + Syntactic + WN + NE 82.38 17.62 Lexical + Syntactic + DDN 82.97 17.03  Table 6." ></td>
	<td class="line x" title="69:83	Relative Contribution of Semantic Features  The DDN features outperform the other two types of semantic features used separately and in conjunction." ></td>
	<td class="line x" title="70:83	The difference in performance is statistically significant (p=0.05)." ></td>
	<td class="line x" title="71:83	31 6 Discussion and Conclusion As we saw, the novel semantic features we proposed are beneficial to the task of VSD: they resulted in a decrease in error rate from 3% to 15%, depending on the particular experiment." ></td>
	<td class="line x" title="72:83	We also discovered that the DDN features contributed twice as much as the other two types of semantic features combined: adding the WN and NE features to the baseline resulted in about a 3% decrease in error rate, while adding the DDN features caused a more than 6% drop." ></td>
	<td class="line x" title="73:83	Our results suggest that DDNs duplicate the effect of WN and NE: our system achieved the same performance when all three types of semantic features were used and when we discarded WN and NE features and kept only the DDNs." ></td>
	<td class="line x" title="74:83	This finding is important because such resources as WN and NE-taggers are domain and language specific while the DDNs have the advantage of being obtainable from a large collection of texts in the domain or language of interest." ></td>
	<td class="line x" title="75:83	Thus, the DDNs can become a crucial part of building a robust VSD system for a resource-poor domain or language, given a high-accuracy parser." ></td>
	<td class="line x" title="76:83	7 Future Work In this paper we only experimented with verbs' objects, however the concept of DDNs can be easily extended to other arguments of the target verb." ></td>
	<td class="line x" title="77:83	Also, we only utilized the object-verb relation in the dependency parses, but the range of potentially useful relations does not have to be limited only to it." ></td>
	<td class="line x" title="78:83	Finally, we used as features the 50 most frequent verbs that took the noun argument as an object." ></td>
	<td class="line x" title="79:83	However, the raw frequency is certainly not the only way to rank the verbs; we plan on exploring other metrics such as Mutual Information." ></td>
	<td class="line x" title="80:83	Acknowledgements  We gratefully acknowledge the support of the National Science Foundation Grant NSF-0715078, Consistent Criteria for Word Sense Disambiguation, and the GALE program of the Defense Advanced Research Projects Agency, Contract No." ></td>
	<td class="line x" title="81:83	HR0011-06-C-0022, a subcontract from the BBNAGILE Team." ></td>
	<td class="line x" title="82:83	Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Sc ience Foundation." ></td>
	<td class="line x" title="83:83	We also thank our colleagues Rodney Nielsen and Philipp Wetzler for parsing English Gigaword with MaltParser." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P08-3001
A Supervised Learning Approach to Automatic Synonym Identification Based on Distributional Features
Hagiwara, Masato;"></td>
	<td class="line x" title="1:136	Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 16, Columbus, June 2008." ></td>
	<td class="line x" title="2:136	c2008 Association for Computational Linguistics A Supervised Learning Approach to Automatic Synonym Identification based on Distributional Features Masato Hagiwara Graduate School of Information Science Nagoya University Furo-cho, Chikusa-ku, Nagoya 464-8603, JAPAN hagiwara@kl.i.is.nagoya-u.ac.jp Abstract Distributional similarity has been widely used to capture the semantic relatedness of words in many NLP tasks." ></td>
	<td class="line x" title="3:136	However, various parameters such as similarity measures must be handtuned to make it work effectively." ></td>
	<td class="line x" title="4:136	Instead, we propose a novel approach to synonym identification based on supervised learning and distributional features, which correspond to the commonality of individual context types shared by word pairs." ></td>
	<td class="line x" title="5:136	Considering the integration with pattern-based features, we have built and compared five synonym classifiers." ></td>
	<td class="line x" title="6:136	The evaluation experiment has shown a dramatic performance increase of over 120% on the F-1 measure basis, compared to the conventional similarity-based classification." ></td>
	<td class="line x" title="7:136	On the other hand, the pattern-based features have appeared almost redundant." ></td>
	<td class="line x" title="8:136	1 Introduction Semantic similarity of words is one of the most important lexical knowledge for NLP tasks including word sense disambiguation and automatic thesaurus construction." ></td>
	<td class="line x" title="9:136	To measure the semantic relatedness of words, a concept called distributional similarity has been widely used." ></td>
	<td class="line x" title="10:136	Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts." ></td>
	<td class="line oc" title="11:136	A number of researches which utilized distributional similarity have been conducted, including (Hindle, 1990; Lin, 1998; Geffet and Dagan, 2004) and many others." ></td>
	<td class="line n" title="12:136	Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved." ></td>
	<td class="line x" title="13:136	As Weeds et al.(2004) pointed out, it is not at all obvious that one universally best measure exists for all application, thus they must be tuned by hand in an ad-hoc manner." ></td>
	<td class="line x" title="15:136	The fact that no theoretic basis is given is making the matter more difficult." ></td>
	<td class="line x" title="16:136	On the other hand, if we pay attention to lexical knowledge acquisition in general, a variety of systems which utilized syntactic patterns are found in the literature." ></td>
	<td class="line x" title="17:136	In her landmark paper in the field, Hearst (1992) utilized syntactic patterns such as such X as Y and Y and other X, and extracted hypernym/hyponym relation of X and Y. Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives." ></td>
	<td class="line x" title="18:136	What is worth attention here is that supervised machine learning is easily incorporated with syntactic patterns." ></td>
	<td class="line x" title="19:136	For example, Snow et al.(2004) further extended Hearsts idea and built hypernym classifiers based on machine learning and syntactic pattern-based features, with a considerable success." ></td>
	<td class="line x" title="21:136	These two independent approaches, distributional similarity and syntactic patterns, were finally integrated by Mirkin et al.(2006)." ></td>
	<td class="line x" title="23:136	Although they reported that their system successfully improved the performance, it did not achieve a complete integration and was still relying on an independent module to compute the similarity." ></td>
	<td class="line x" title="24:136	This configuration inherits a large portion of drawbacks of the similaritybased approach mentioned above." ></td>
	<td class="line x" title="25:136	To achieve a full integration of both approaches, we suppose that re1 formalization of similarity-based approach would be essential, as pattern-based approach is enhanced with the supervised machine learning." ></td>
	<td class="line x" title="26:136	In this paper, we propose a novel approach to automatic synonym identification based on supervised learning technique." ></td>
	<td class="line x" title="27:136	Firstly, we re-formalize synonym acquisition as a classification problem: one which classifies word pairs into synonym/nonsynonym classes, without depending on a single value of distributional similarity." ></td>
	<td class="line x" title="28:136	Instead, classification is done using a set of distributional features, which correspond to the degree of commonality of individual context types shared by word pairs." ></td>
	<td class="line x" title="29:136	This formalization also enables to incorporate pattern-based features, and we finally build five classifiers based on distributional and/or pattern-based features." ></td>
	<td class="line x" title="30:136	In the experiment, their performances are compared in terms of synonym acquisition precision and recall, and the differences of actually acquired synonyms are to be clarified." ></td>
	<td class="line x" title="31:136	The rest of this paper is organized as follows: in Sections 2 and 3, distributional and pattern-based features are defined, along with the extraction methods." ></td>
	<td class="line x" title="32:136	Using the features, in Section 4 we build five types of synonym classifiers, and compare their performances in Section 5." ></td>
	<td class="line x" title="33:136	Section 6 concludes this paper, mentioning the future direction of this study." ></td>
	<td class="line x" title="34:136	2 Distributional Features In this section, we firstly describe how we extract contexts from corpora and then how distributional features are constructed for word pairs." ></td>
	<td class="line x" title="35:136	2.1 Context Extraction We adopted dependency structure as the context of words since it is the most widely used and wellperforming contextual information in the past studies (Ruge, 1997; Lin, 1998)." ></td>
	<td class="line x" title="36:136	In this paper the sophisticated parser RASP Toolkit 2 (Briscoe et al., 2006) was utilized to extract this kind of word relations." ></td>
	<td class="line x" title="37:136	We use the following example for illustration purposes: The library has a large collection of classic books by such authors as Herrick and Shakespeare." ></td>
	<td class="line x" title="38:136	RASP outputs the extracted dependency structure as n-ary relations as follows: (ncsubj have library _) (dobj have collection) (det collection a) (ncmod _ collection large) (iobj collection of) (dobj of book) (ncmod _ book by) (dobj by author) (det author such) (ncmod _ author as)  , whose graphical representation is shown in Figure 1." ></td>
	<td class="line x" title="39:136	While the RASP outputs are n-ary relations in general, what we need here is co-occurrences of words and contexts, so we extract the set of cooccurrences of stemmed words and contexts by taking out the target word from the relation and replacing the slot by an asterisk *: library (ncsubj have * _) library (det * The) collection (dobj have *) collection (det * a) collection (ncmod _ * large) collection (iobj * of) book (dobj of *) book (ncmod _ * by) book (ncmod _ * classic) author (dobj by *) author (det * such)  Summing all these up produces the raw cooccurrence count N(w,c) of the word w and the context c. In the following, the set of context types co-occurring with the word w is denoted as C(w), i.e., C(w) = {c|N(w,c) > 0}." ></td>
	<td class="line x" title="40:136	2.2 Feature Construction Using the co-occurrences extracted above, we define distributional features fDj (w1,w2) for the word pair (w1,w2)." ></td>
	<td class="line x" title="41:136	The feature value fDj is determined so that it represents the degree of commonality of the context cj shared by the word pair." ></td>
	<td class="line x" title="42:136	We adopted pointwise total correlation, one of the generalizations of pointwise mutual information, as the feature value: fDj (w1,w2) = log P(w1,w2,cj)P(w 1)P(w2)P(cj) ." ></td>
	<td class="line x" title="43:136	(1) The advantage of this feature construction is that, given the independence assumption between the words w1 and w2, the feature value is easily calculated as the simple sum of two corresponding pointwise mutual information weights as: fDj (w1,w2) = PMI(w1,cj)+PMI(w2,cj), (2) 2 The library has a large collection of classic books by such authors as Herrick and Shakespeare." ></td>
	<td class="line x" title="44:136	ncsubj dobj det ncmod iobj dobj ncmod dobj det ncmod dobj conjconjncmod det (dobj) (dobj) Figure 1: Dependency structure of the example sentence, along with conjunction shortcuts (dotted lines)." ></td>
	<td class="line x" title="45:136	where the value of PMI, which is also the weights wgt(wi,cj) assigned for distributional similarity, is calculated as: wgt(wi,cj) = PMI(wi,cj) = log P(wi,cj)P(w i)P(cj) ." ></td>
	<td class="line x" title="46:136	(3) There are three things to note here: when N(wi,cj) = 0 and PMI cannot be defined, then we define wgt(wi,cj) = 0." ></td>
	<td class="line x" title="47:136	Also, because it has been shown (Curran and Moens, 2002) that negative PMI values worsen the distributional similarity performance, we bound PMI so that wgt(wi,cj) = 0 if PMI(wi,cj) < 0." ></td>
	<td class="line x" title="48:136	Finally, the feature value fDj (w1,w2) is defined as shown in Equation (2) only when the context cj co-occurs with both w1 and w2." ></td>
	<td class="line x" title="49:136	In other words, fDj (w1,w2) = 0 if PMI(w1,cj) = 0 and/or PMI(w2,cj) = 0." ></td>
	<td class="line x" title="50:136	3 Pattern-based Features This section describes the other type of features, extracted from syntactic patterns in sentences." ></td>
	<td class="line x" title="51:136	3.1 Syntactic Pattern Extraction We define syntactic patterns based on dependency structure of sentences." ></td>
	<td class="line x" title="52:136	Following Snow et al.(2004)s definition, the syntactic pattern of words w1,w2 is defined as the concatenation of the words and relations which are on the dependency path from w1 to w2, not including w1 and w2 themselves." ></td>
	<td class="line x" title="54:136	The syntactic pattern of word authors and books in Figure 1 is, for example, dobj:by:ncmod, while that of authors and Herrick is ncmod-of:as:dobj-of:and:conj-of." ></td>
	<td class="line x" title="55:136	Notice that, although not shown in the figure, every relation has a reverse edge as its counterpart, with the direction opposite and the postfix -of attached to the label." ></td>
	<td class="line x" title="56:136	This allows to follow the relations in reverse, increasing the flexibility and expressive power of patterns." ></td>
	<td class="line x" title="57:136	In the experiment, we limited the maximum length of syntactic path to five, meaning that word pairs having six or more relations in between were disregarded." ></td>
	<td class="line x" title="58:136	Also, we considered conjunction shortcuts to capture the lexical relations more precisely, following Snow et al.(2004)." ></td>
	<td class="line x" title="60:136	This modification cuts short the conj edges when nouns are connected by conjunctions such as and and or." ></td>
	<td class="line x" title="61:136	After this shortcut, the syntactic pattern between authors and Herrick is ncmod-of:as:dobj-of, and that of Herrick and Shakespeare is conj-and, which is a newly introduced special symmetric relation, indicating that the nouns are mutually conjunctional." ></td>
	<td class="line x" title="62:136	3.2 Feature Construction After the corpus is analyzed and patterns are extracted, the pattern based feature fPk (w1,w2), which corresponds to the syntactic pattern pk, is defined as the conditional probability of observing pk given that the pair (w1,w2) is observed." ></td>
	<td class="line x" title="63:136	This definition is similar to (Mirkin et al., 2006) and is calculated as: fPk (w1,w2) = P(pk|w1,w2) = N(w1,w2,pk)N(w 1,w2) ." ></td>
	<td class="line x" title="64:136	(4) 4 Synonym Classifiers Now that we have all the features to consider, we construct the following five classifiers." ></td>
	<td class="line x" title="65:136	This section gives the construction detail of the classifiers and corresponding feature vectors." ></td>
	<td class="line x" title="66:136	Distributional Similarity (DSIM) DSIM classifier is simple acquisition relying only on distributional similarity, not on supervised learning." ></td>
	<td class="line x" title="67:136	Similar to conventional methods, distributional similarity between words w1 and w2, sim(w1,w2), is calculated for each word pair using Jaccard coefficient:  cC(w1)C(w2) min(wgt(w1,c),wgt(w2,c)) cC(w1)C(w2) max(wgt(w1,c),wgt(w2,c)) , 3 considering the preliminary experimental result." ></td>
	<td class="line x" title="68:136	A threshold is set on the similarity and classification is performed based on whether the similarity is above or below of the given threshold." ></td>
	<td class="line x" title="69:136	How to optimally set this threshold is described later in Section 5.1." ></td>
	<td class="line x" title="70:136	Distributional Features (DFEAT) DFEAT classifier does not rely on the conventional distributional similarity and instead uses the distributional features described in Section 2." ></td>
	<td class="line x" title="71:136	The feature vector vectorv of a word pair (w1,w2) is constructed as: vectorv = (fD1 , , fDM)." ></td>
	<td class="line x" title="72:136	(5) Pattern-based Features (PAT) This classifier PAT uses only pattern-based features, essentially the same as the classifier of Snow et al.(2004)." ></td>
	<td class="line x" title="74:136	The feature vector is: vectorv = (fP1 , , fPK)." ></td>
	<td class="line x" title="75:136	(6) Distributional Similarity and Pattern-based Features (DSIM-PAT) DSIM-PAT uses the distributional similarity of pairs as a feature, in addition to pattern-based features." ></td>
	<td class="line x" title="76:136	This classifier is essentially the same as the integration method proposed by Mirkin et al.(2006)." ></td>
	<td class="line x" title="78:136	Letting fS = sim(w1,w2), the feature vector is: vectorv = (fS, fP1 , , fPK)." ></td>
	<td class="line x" title="79:136	(7) Distributional and Pattern-based Features (DFEAT-PAT) The last classifier, DFEAT-PAT, truly integrates both distributional and pattern-based features." ></td>
	<td class="line x" title="80:136	The feature vector is constructed by replacing the fS component of DSIM-PAT with distributional features fD1 , , fDM as: vectorv = (fD1 , , fDM, fP1 , , fPK)." ></td>
	<td class="line x" title="81:136	(8) 5 Experiments Finally, this section describes the experimental setting and the comparison of synonym classifiers." ></td>
	<td class="line x" title="82:136	5.1 Experimental Settings Corpus and Preprocessing As for the corpus, New York Times section (1994) of English Gigaword 1, consisting of approx." ></td>
	<td class="line x" title="83:136	46,000 documents, 1http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?" ></td>
	<td class="line x" title="84:136	catalogId=LDC2003T05 922,000 sentences, and 30 million words, was analyzed to obtain word-context co-occurrences." ></td>
	<td class="line x" title="85:136	This can yield 10,000 or more context types, thus we applied feature selection and reduced the dimensionality." ></td>
	<td class="line x" title="86:136	Firstly, we simply applied frequency cutoff to filter out any words and contexts with low frequency." ></td>
	<td class="line x" title="87:136	More specifically, any words w such that c N(w,c) < f and any contexts c such that w N(w,c) < f, with f = 5, were removed." ></td>
	<td class="line x" title="88:136	DF (document frequency) thresholding is then applied, and context types with the lowest values of DF were removed until 10% of the original contexts were left." ></td>
	<td class="line x" title="89:136	We verified through a preliminary experiment that this feature selection keeps the performance loss at minimum." ></td>
	<td class="line x" title="90:136	As a result, this process left a total of 8,558 context types, or feature dimensionality." ></td>
	<td class="line x" title="91:136	The feature selection was also applied to patternbased features to avoid high sparseness  only syntactic patterns which occurred more than or equal to 7 times were used." ></td>
	<td class="line x" title="92:136	The number of syntactic pattern types left after this process is 17,964." ></td>
	<td class="line x" title="93:136	Supervised Learning Training and test sets were created as follows: firstly, the nouns listed in the Longman Defining Vocabulary (LDV) 2 were chosen as the target words of classification." ></td>
	<td class="line x" title="94:136	Then, all the LDV pairs which co-occur more than or equal to 3 times with any of the syntactic patterns, i.e., {(w1,w2)|w1,w2  LDV,p N(w1,w2,p)  3} were classified into synonym/non-synonym classes as mentioned in Section 5.2." ></td>
	<td class="line x" title="95:136	All the positive-marked pair, as well as randomly chosen 1 out of 5 negativemarked pairs, were collected as the example set E. This random selection is to avoid extreme bias toward the negative examples." ></td>
	<td class="line x" title="96:136	The example set E ended up with 2,148 positive and 13,855 negative examples, with their ratio being approx." ></td>
	<td class="line x" title="97:136	6.45." ></td>
	<td class="line x" title="98:136	The example set E was then divided into five partitions to conduct five-fold cross validation, of which four partitions were used for learning and the one for testing." ></td>
	<td class="line x" title="99:136	SVMlight was adopted for machine learning, and RBF as the kernel." ></td>
	<td class="line x" title="100:136	The parameters, i.e., the similarity threshold of DSIM classifier, gamma parameter of RBF kernel, and the cost-factor j of SVM, i.e., the ratio by which training errors on positive examples outweight errors on negative ones, 2http://www.cs.utexas.edu/users/kbarker/working notes/ ldoce-vocab.html 4 Table 1: Performance comparison of synonym classifiers Classifier Precision Recall F-1 DSIM 33.13% 49.71% 39.76% DFEAT 95.25% 82.31% 88.30% PAT 23.86% 45.17% 31.22% DSIM-PAT 30.62% 51.34% 38.36% DFEAT-PAT 95.37% 82.31% 88.36% were optimized using one of the 5-fold cross validation train-test pair on the basis of F-1 measure." ></td>
	<td class="line x" title="101:136	The performance was evaluated for the other four traintest pairs and the average values were recorded." ></td>
	<td class="line x" title="102:136	5.2 Evaluation To test whether or not a given word pair (w1,w2) is a synonym pair, three existing thesauri were consulted: Rogets Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998)." ></td>
	<td class="line x" title="103:136	The union of synonyms obtained when the head word is looked up as a noun is used as the answer set, except for words marked as idiom, informal, slang and phrases comprised of two or more words." ></td>
	<td class="line x" title="104:136	The pair (w1,w2) is marked as synonyms if and only if w2 is contained in the answer set of w1, or w1 is contained in that of w2." ></td>
	<td class="line x" title="105:136	5.3 Classifier Performance The performances, i.e., precision, recall, and F-1 measure, of the five classifiers were evaluated and shown in Table 1." ></td>
	<td class="line x" title="106:136	First of all, we observed a drastic improvement of DFEAT over DSIM  over 120% increase of F-1 measure." ></td>
	<td class="line x" title="107:136	When combined with pattern-based features, DSIM-PAT showed a slight recall increase compared to DSIM, partially reconfirming the favorable integration result of (Mirkin et al., 2006)." ></td>
	<td class="line x" title="108:136	However, the combination DFEAT-PAT showed little change, meaning that the discriminative ability of DFEAT was so high that pattern-based features were almost redundant." ></td>
	<td class="line x" title="109:136	To note, the performance of PAT was the lowest, reflecting the fact that synonym pairs rarely occur in the same sentence, making the identification using only syntactic pattern clues even more difficult." ></td>
	<td class="line x" title="110:136	The reason of the drastic improvement is that, as far as we speculate, the supervised learning may have favorably worked to cause the same effect as automatic feature selection technique." ></td>
	<td class="line x" title="111:136	Features with high discriminative power may have been automatically promoted." ></td>
	<td class="line x" title="112:136	In the distributional similarity setting, in contrast, the contributions of context types are uniformly fixed." ></td>
	<td class="line x" title="113:136	In order to elucidate what is happening in this situation, the investigations on machine learning settings, as well as algorithms other than SVM should be conducted as the future work." ></td>
	<td class="line x" title="114:136	5.4 Acquired Synonyms In the second part of this experiment, we further investigated what kind of synonyms were actually acquired by the classifiers." ></td>
	<td class="line x" title="115:136	The targets are not LDV, but all of 27,501 unique nouns appeared in the corpus, because we cannot rule out the possibility that the high performance seen in the previous experiment was simply due to the rather limited target word settings." ></td>
	<td class="line x" title="116:136	The rest of the experimental setting was almost the same as the previous one, except that the construction of training set is rather artificial  we used all of the 18,102 positive LDV pairs and randomly chosen 20,000 negative LDV pairs." ></td>
	<td class="line x" title="117:136	Table 2 lists the acquired synonyms of video and program." ></td>
	<td class="line x" title="118:136	The results of DSIM and DFEAT are ordered by distributional similarity and the value of decision function of SVM, respectively." ></td>
	<td class="line x" title="119:136	Notice that because neither word is included in LDV, all the pairs of the query and the words listed in the table are guaranteed to be excluded from the training set." ></td>
	<td class="line x" title="120:136	The result shows the superiority of DFEAT over DSIM." ></td>
	<td class="line x" title="121:136	The irrelevant words (marked by * by human judgement) seen in the DSIM list are demoted and replaced with more relevant words in the DFEAT list." ></td>
	<td class="line x" title="122:136	We observed the same trend for lower ranked words and other query words." ></td>
	<td class="line x" title="123:136	6 Conclusion and Future Direction In this paper, we proposed a novel approach to automatic synonym identification based on supervised machine learning and distributional features." ></td>
	<td class="line x" title="124:136	For this purpose, we re-formalized synonym acquisition as a classification problem, and constructed the features as the total correlation of pairs and contexts." ></td>
	<td class="line x" title="125:136	Since this formalization allows to integrate patternbased features in a seamless way, we built five classifiers based on distributional and/or pattern-based features." ></td>
	<td class="line x" title="126:136	The result was promising, achieving more than 120% increase over conventional DSIM classi5 Table 2: Acquired synonyms of video and program For query word: video Rank DSIM DFEAT 1 computer computer 2 television television 3 movie multimedia 4 film communication 5 food* entertainment 6 multimedia advertisement 7 drug* food* 8 entertainment recording 9 music portrait 10 radio movie For query word: program Rank DSIM DFEAT 1 system project 2 plan system 3 project unit 4 service status 5 policy schedule 6 effort* organization* 7 bill* activity* 8 company* plan 9 operation scheme 10 organization* policy fier." ></td>
	<td class="line x" title="127:136	Pattern-based features were partially effective when combined with DSIM whereas with DFEAT they were simply redundant." ></td>
	<td class="line x" title="128:136	The impact of this study is that it makes unnecessary to carefully choose similarity measures such as Jaccards  instead, features can be directly input to supervised learning right after their construction." ></td>
	<td class="line x" title="129:136	There are still a great deal of issues to address as the current approach is only in its infancy." ></td>
	<td class="line x" title="130:136	For example, the formalization of distributional features requires further investigation." ></td>
	<td class="line x" title="131:136	Although we adopted total correlation this time, there can be some other construction methods which show higher performance." ></td>
	<td class="line x" title="132:136	Still, we believe that this is one of the best acquisition performances achieved ever and will be an important step to truly practical lexical knowledge acquisition." ></td>
	<td class="line x" title="133:136	Setting our future direction on the completely automatic construction of reliable thesaurus or ontology, the approach proposed here is to be applied to and integrated with various kinds of lexical knowledge acquisition methods in the future." ></td>
	<td class="line x" title="134:136	Acknowledgments The author would like to thank Assoc." ></td>
	<td class="line x" title="135:136	Prof. Katsuhiko Toyama and Assis." ></td>
	<td class="line x" title="136:136	Prof. Yasuhiro Ogawa for their kind supervision and advice." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="E09-1086
Unsupervised Recognition of Literal and Non-Literal Use of Idiomatic Expressions
Sporleder, Caroline;Li, Linlin;"></td>
	<td class="line x" title="1:224	Proceedings of the 12th Conference of the European Chapter of the ACL, pages 754762, Athens, Greece, 30 March  3 April 2009." ></td>
	<td class="line x" title="2:224	c2009 Association for Computational Linguistics Unsupervised Recognition of Literal and Non-Literal Use of Idiomatic Expressions Caroline Sporleder and Linlin Li Saarland University Postfach 15 11 50 66041 Saarbrucken, Germany {csporled,linlin}@coli.uni-saarland.de Abstract We propose an unsupervised method for distinguishing literal and non-literal usages of idiomatic expressions." ></td>
	<td class="line x" title="3:224	Our method determines how well a literal interpretation is linked to the overall cohesive structure of the discourse." ></td>
	<td class="line x" title="4:224	If strong links can be found, the expression is classified as literal, otherwise as idiomatic." ></td>
	<td class="line x" title="5:224	We show that this method can help to tell apart literal and non-literal usages, even for idioms which occur in canonical form." ></td>
	<td class="line x" title="6:224	1 Introduction Texts frequently contain expressions whose meaning is not strictly literal, such as metaphors or idioms." ></td>
	<td class="line x" title="7:224	Non-literal expressions pose a major challenge to natural language processing as they often exhibit lexical and syntactic idiosyncrasies." ></td>
	<td class="line x" title="8:224	For example, idioms can violate selectional restrictions (as in push ones luck under the assumption that only concrete things can normally be pushed), disobey typical subcategorisation constraints (e.g., in line without a determiner before line), or change the default assignments of semantic roles to syntactic categories (e.g., in break sth with X the argument X would typically be an instrument but for the idiom break the ice it is more likely to fill a patient role, as in break the ice with Russia)." ></td>
	<td class="line x" title="9:224	To avoid erroneous analyses, a natural language processing system should recognise if an expression is used non-literally." ></td>
	<td class="line x" title="10:224	While there has been a lot of work on recognising idioms (see Section 2), most previous approaches have focused on a typebased classification, dividing expressions into idiom or not an idiom irrespective of their actual use in a discourse context." ></td>
	<td class="line x" title="11:224	However, while some expressions, such as by and large, always have a non-compositional, idiomatic meaning, many idioms, such as break the ice or spill the beans, share their linguistic form with perfectly literal expressions (see examples (1) and (2), respectively)." ></td>
	<td class="line x" title="12:224	For some expressions, such as drop the ball, the literal usage can even dominate in some domains." ></td>
	<td class="line x" title="13:224	Hence, whether a potentially ambiguous expression has literal or non-literal meaning has to be inferred from the discourse context." ></td>
	<td class="line x" title="14:224	(1) Dad had to break the ice on the chicken troughs so that they could get water." ></td>
	<td class="line x" title="15:224	(2) Somehow I always end up spilling the beans all over the floor and looking foolish when the clerk comes to sweep them up." ></td>
	<td class="line x" title="16:224	Type-based idiom classification thus only addresses part of the problem." ></td>
	<td class="line x" title="17:224	While it can automatically compile lists of potentially idiomatic expressions, it does not say anything about the idiomaticity of an expression in a particular context." ></td>
	<td class="line x" title="18:224	In this paper, we propose a novel, cohesion-based approach for detecting non-literal usages (token-based idiom classification)." ></td>
	<td class="line x" title="19:224	Our approach is unsupervised and similar in spirit to Hirst and St-Onges (1998) method for detecting malapropisms." ></td>
	<td class="line x" title="20:224	Like them, we rely on the presence or absence of cohesive links between the words in a text." ></td>
	<td class="line x" title="21:224	However, unlike Hirst and St-Onge we do not require a hand-crafted resource like WordNet or Rogets Thesaurus; our approach is knowledgelean." ></td>
	<td class="line x" title="22:224	2 Related Work Most studies on idiom classification focus on typebased classification; few researchers have worked on token-based approaches." ></td>
	<td class="line x" title="23:224	Type-based methods frequently exploit the fact that idioms have 754 a number of properties which differentiate them from other expressions." ></td>
	<td class="line x" title="24:224	Apart from not having a (strictly) compositional meaning, they also exhibit some degree of syntactic and lexical fixedness." ></td>
	<td class="line x" title="25:224	For example, some idioms do not allow internal modifiers (*shoot the long breeze) or passivisation (*the bucket was kicked)." ></td>
	<td class="line x" title="26:224	They also typically only allow very limited lexical variation (*kick the vessel, *strike the bucket)." ></td>
	<td class="line x" title="27:224	Many approaches for identifying idioms focus on one of these two aspects." ></td>
	<td class="line x" title="28:224	For instance, measures that compute the association strength between the elements of an expression have been employed to determine its degree of compositionality (Lin, 1999; Fazly and Stevenson, 2006) (see also Villavicencio et al.(2007) for an overview and a comparison of different measures)." ></td>
	<td class="line x" title="30:224	Other approaches use Latent Semantic Analysis (LSA) to determine the similarity between a potential idiom and its components (Baldwin et al., 2003)." ></td>
	<td class="line x" title="31:224	Low similarity is supposed to indicate low compositionality." ></td>
	<td class="line x" title="32:224	Bannard (2007) proposes to identify idiomatic expressions by looking at their syntactic fixedness, i.e., how likely they are to take modifiers or be passivised, and comparing this to what would be expected based on the observed behaviour of the component words." ></td>
	<td class="line x" title="33:224	Fazly and Stevenson (2006) combine information about syntactic and lexical fixedness (i.e., estimated degree of compositionality) into one measure." ></td>
	<td class="line x" title="34:224	The few token-based approaches include a study by Katz and Giesbrecht (2006), who devise a supervised method in which they compute the meaning vectors for the literal and non-literal usages of a given expression in the training data." ></td>
	<td class="line x" title="35:224	An unseen test instance of the same expression is then labelled by performing a nearest neighbour classification." ></td>
	<td class="line x" title="36:224	They report an average accuracy of 72%, though their evaluation is fairly small scale, using only one expression and 67 instances." ></td>
	<td class="line x" title="37:224	Birke and Sarkar (2006) model literal vs. non-literal classification as a word sense disambiguation task and use a clustering algorithm which compares test instances to two automatically constructed seed sets (one with literal and one with non-literal expressions), assigning the label of the closest set." ></td>
	<td class="line x" title="38:224	While the seed sets are created without immediate human intervention they do rely on manually created resources such as databases of known idioms." ></td>
	<td class="line x" title="39:224	Cook et al.(2007) and Fazly et al.(To appear) propose an alternative method which crucially relies on the concept of canonical form (CForm)." ></td>
	<td class="line x" title="42:224	It is assumed that for each idiom there is a fixed form (or a small set of those) corresponding to the syntactic pattern(s) in which the idiom normally occurs (Riehemann, 2001).1 The canonical form allows for inflectional variation of the head verb but not for other variations (such as nominal inflection, choice of determiner etc.)." ></td>
	<td class="line x" title="43:224	It has been observed that if an expression is used idiomatically, it typically occurs in its canonical form." ></td>
	<td class="line x" title="44:224	For example, Riehemann (2001, p. 34) found that for decomposable idioms 75% of the occurrences are in canonical form, rising to 97% for non-decomposable idioms.2 Cook et al. exploit this behaviour and propose an unsupervised method in which an expression is classified as idiomatic if it occurs in canonical form and literal otherwise." ></td>
	<td class="line x" title="45:224	Canonical forms are determined automatically using a statistical, frequency-based measure." ></td>
	<td class="line x" title="46:224	The authors report an average accuracy of 72% for their classifier." ></td>
	<td class="line x" title="47:224	3 Using Lexical Cohesion to Identify Idiomatic Expressions 3.1 Lexical Cohesion In this paper we exploit lexical cohesion to detect idiomatic expressions." ></td>
	<td class="line x" title="48:224	Lexical cohesion is a property exhibited by coherent texts: concepts referred to in individual sentences are typically related to other concepts mentioned elsewhere (Halliday and Hasan, 1976)." ></td>
	<td class="line x" title="49:224	Such sequences of semantically related concepts are called lexical chains." ></td>
	<td class="line x" title="50:224	Given a suitable measure of semantic relatedness, such chains can be computed automatically and have been used successfully in a number of NLP applications, starting with Hirst and St-Onges (1998) seminal work on detecting real-word spelling errors." ></td>
	<td class="line x" title="51:224	Their approach is based on the insight that misspelled words do not fit their context, i.e., they do not normally participate in lexical chains." ></td>
	<td class="line x" title="52:224	Content words which do not belong to any lexical chain but which are orthographically close to words which do, are therefore good candidates for spelling errors." ></td>
	<td class="line x" title="53:224	Idioms behave similarly to spelling errors in that they typically also do not exhibit a high de1This is also the form in which an idiom is usually listed in a dictionary." ></td>
	<td class="line x" title="54:224	2Decomposable idioms are expressions such as spill the beans which have a composite meaning whose parts can be mapped to the words of the expression (e.g., spillreveal, beanssecret)." ></td>
	<td class="line x" title="55:224	755 gree of lexical cohesion with their context, at least not if one assumes a literal meaning for their component words." ></td>
	<td class="line x" title="56:224	Hence if the component words of a potentially idiomatic expression do not participate in any lexical chain, it is likely that the expression is indeed used idiomatically, otherwise it is probably used literally." ></td>
	<td class="line x" title="57:224	For instance, in example (3), where the expression play with fire is used in a literal sense, the word fire does participate in a chain (shown in bold face) that also includes the words grilling, dry-heat, cooking, and coals, while for the non-literal usage in example (4) there are no chains which include fire.3 (3) Grilling outdoors is much more than just another dry-heat cooking method." ></td>
	<td class="line x" title="58:224	Its the chance to play with fire, satisfying a primal urge to stir around in coals ." ></td>
	<td class="line x" title="59:224	(4) And PLO chairman Yasser Arafat has accused Israel of playing with fire by supporting HAMAS in its infancy." ></td>
	<td class="line x" title="60:224	Unfortunately, there are also a few cases in which a cohesion-based approach fails." ></td>
	<td class="line x" title="61:224	Sometimes an expression is used literally but does not feature prominently enough in the discourse to participate in a chain, as in example (5) where the main focus of the discourse is on the use of morphine and not on children playing with fire.4 The opposite case also exists: sometimes idiomatic usages do exhibit lexical cohesion on the component word level." ></td>
	<td class="line x" title="62:224	This situation is often a consequence of a deliberate play with words, e.g. the use of several related idioms or metaphors (see example (6))." ></td>
	<td class="line x" title="63:224	However, we found that both cases are relatively rare." ></td>
	<td class="line x" title="64:224	For instance, in a study of 75 literal usages of various expressions, we only discovered seven instances in which no relevant chain could be found, including some cases where the context was too short to establish the cohesive structure (e.g., because the expression occurred in a headline)." ></td>
	<td class="line x" title="65:224	(5) Chinamasa compared McGowns attitude to morphine to a childs attitude to playing with fire  a lack of concern over the risks involved." ></td>
	<td class="line x" title="66:224	(6) Saying that the Americans were playing with fire the official press speculated that the gunpowder barrel which is Taiwan might well explode if Washington and Taipei do not put a stop to their incendiary gesticulations. 3Idioms may, of course, link to the surrounding discourse with their idiomatic meaning, i.e., for play with fire one may expect other words in the discourse which are related to the concept danger." ></td>
	<td class="line x" title="67:224	4Though one could argue that there is a chain linking child and play which points to the literal usage here." ></td>
	<td class="line x" title="68:224	3.2 Modelling Semantic Relatedness While a cohesion-based approach to token-based idiom classification should be intuitively successful, its practical usefulness depends crucially on the availability of a suitable method for computing semantic relatedness." ></td>
	<td class="line x" title="69:224	This is currently an area of active research." ></td>
	<td class="line x" title="70:224	There are two main approaches." ></td>
	<td class="line x" title="71:224	Methods based on manually built lexical knowledge bases, such as WordNet, model semantic relatedness by computing the shortest path between two concepts in the knowledge base and/or by looking at word overlap in the glosses (see Budanitsky and Hirst (2006) for an overview)." ></td>
	<td class="line oc" title="72:224	Distributional approaches, on the other hand, rely on text corpora, and model relatedness by comparing the contexts in which two words occur, assuming that related words occur in similar context (e.g., Hindle (1990), Lin (1998), Mohammad and Hirst (2006))." ></td>
	<td class="line x" title="73:224	More recently, there has also been research on using Wikipedia and related resources for modelling semantic relatedness (Ponzetto and Strube, 2007; Zesch et al., 2008)." ></td>
	<td class="line x" title="74:224	All approaches have advantages and disadvantages." ></td>
	<td class="line x" title="75:224	WordNet-based approaches, for instance, typically have a low coverage and only work for so-called classical relations like hypernymy, antonymy etc. Distributional approaches usually conflate different word senses and may therefore lead to unintuitive results." ></td>
	<td class="line x" title="76:224	For our task, we need to model a wide range of semantic relations (Morris and Hirst, 2004), for example, relations based on some kind of functional or situational association, as between fire and coal in (3) or between ice and water in example (1)." ></td>
	<td class="line x" title="77:224	Likewise we also need to model relations between non-nouns, for instance between spill and sweep up in example (2)." ></td>
	<td class="line x" title="78:224	Some relations also require world-knowledge, as in example (7), where the literal usage of drop the ball is not only indicated by the presence of goalkeeper but also by knowing that Wayne Rooney and Kevin Campbell are both football players." ></td>
	<td class="line x" title="79:224	(7) When Rooney collided with the goalkeeper, causing him to drop the ball, Kevin Campbell followed in." ></td>
	<td class="line x" title="80:224	We thus decided against a WordNet-based measure of semantic relatedness, opting instead for a distributional approach, Normalized Google Distance (NGD, see Cilibrasi and Vitanyi (2007)), which computes relatedness on the basis of page counts returned by a search engine." ></td>
	<td class="line x" title="81:224	NGD is a measure of association that quantifies the strength of a 756 relationship between two words." ></td>
	<td class="line x" title="82:224	It is defined as follows: NGD(x,y) = max{log f(x),log f(y)}log f(x,y)log Mmin{log f(x),log f(y)} (8) where x and y are the two words whose association strength is computed (e.g., fire and coal), f(x) is the page count returned by the search engine for the term x (and likewise for f(y) and y), f(x,y) is the page count returned when querying for x AND y (i.e., the number of pages that contain both, x and y), and M is the number of web pages indexed by the search engine." ></td>
	<td class="line x" title="83:224	The basic idea is that the more often two terms occur together relative to their overall occurrence the more closely they are related." ></td>
	<td class="line x" title="84:224	For most pairs of search terms the NGD falls between 0 and 1, though in a small number of cases NGD can exceed 1 (see Cilibrasi and Vitanyi (2007) for a detailed discussion of the mathematical properties of NGD)." ></td>
	<td class="line x" title="85:224	Using web counts rather than bi-gram counts from a corpus as the basis for computing semantic relatedness was motivated by the fact that the web is a significantly larger database than any compiled corpus, which makes it much more likely that we can find information about the concepts we are looking for (thus alleviating data sparseness)." ></td>
	<td class="line x" title="86:224	The information is also more up-to-date, which is important for modelling the kind of world knowledge about named entities we need to resolve examples like (7)." ></td>
	<td class="line x" title="87:224	Furthermore, it has been shown that web counts can be used as reliable proxies for corpus-based counts and often lead to better statistical models (Zhu and Rosenfeld, 2001; Lapata and Keller, 2005)." ></td>
	<td class="line x" title="88:224	To obtain the web counts we used Yahoo rather than Google because we found Yahoo gave us more stable counts over time." ></td>
	<td class="line x" title="89:224	Both the Yahoo and the Google API seemed to have problems with very high frequency words, so we excluded those cases." ></td>
	<td class="line x" title="90:224	Effectively, this amounted to filtering out function words." ></td>
	<td class="line x" title="91:224	As it is difficult to obtain reliable figures for the number of pages indexed by a search engine, we approximated this number (M in formula (8) above) by setting it to the number of hits obtained for the word the, assuming that this word occurs in virtually all English language pages (Lapata and Keller, 2005)." ></td>
	<td class="line x" title="92:224	When generating the queries we made sure that we queried for all combinations of inflected forms (for example fire AND coal would be expanded to fire AND coal, fires AND coal, fire AND coals, and fires AND coals)." ></td>
	<td class="line x" title="93:224	The inflected forms were generated by the morph tools developed at the University of Sussex (Minnen et al., 2001).5 3.3 Cohesion-based Classifiers We implemented two cohesion-based classifiers: the first one computes the lexical chains for the input text and classifies an expression as literal or non-literal depending on whether its component words participate in any of the chains, the second classifier builds a cohesion graph and determines how this graph changes when the expression is inserted or left out." ></td>
	<td class="line x" title="94:224	Chain-based classifier Various methods for building lexical chains have been proposed in the literature (Hirst and St-Onge, 1998; Barzilay and Elhadad, 1997; Silber and McCoy, 2002) but the basic idea is as follows: the content words of the text are considered in sequence and for each word it is determined whether it is similar enough to (the words in) one of the existing chains to be placed in that chain, if not it is placed in a chain of its own." ></td>
	<td class="line x" title="95:224	Depending on the chain building algorithm used, a word is placed in a chain if it is related to one other word in the chain or to all of them." ></td>
	<td class="line x" title="96:224	The latter strategy is more conservative and tends to lead to shorter but more reliable chains and it is the method we adopted here.6 Note that the chaining algorithm has a free parameter, namely a threshold which has to be surpassed to consider two words related (relatedness threshold)." ></td>
	<td class="line x" title="97:224	On the basis of the computed chains, the classifier has to decide whether the target expression is used literally or not." ></td>
	<td class="line x" title="98:224	A simple strategy would classify an expression as literal whenever one or more of its component words participates in any chain." ></td>
	<td class="line x" title="99:224	However, as the chains are potentially noisy, this may not be the best strategy." ></td>
	<td class="line x" title="100:224	We therefore also evaluate the strength of the chain(s) in which the expression participates." ></td>
	<td class="line x" title="101:224	If a component word of the expression participates in a long chain (and is related to all words in the chain, as we require) 5The tools are available at: http://www." ></td>
	<td class="line x" title="102:224	informatics.susx.ac.uk/research/groups/ nlp/carroll/morph.html." ></td>
	<td class="line x" title="103:224	6If a WordNet-based relatedness measure is used, the chaining algorithm has to perform word sense disambiguation as well." ></td>
	<td class="line x" title="104:224	As we use a distributional relatedness measure which conflates different senses anyway, we do not have to disambiguate here." ></td>
	<td class="line x" title="105:224	757 then this is good evidence that the expression is indeed used in a literal sense." ></td>
	<td class="line x" title="106:224	For instance, in (3) the word fire belongs to the relatively long chain grilling  dry-heat  cooking  fire  coals, providing strong evidence of literal usage of play with fire." ></td>
	<td class="line x" title="107:224	To determine the strength of the evidence in favour of a literal interpretation, we take the longest chain in which any of the component words of the idiom participate7 and check whether this is above a predefined threshold (the classification threshold)." ></td>
	<td class="line x" title="108:224	Both the relatedness threshold and the classification threshold are set empirically by optimising on a manually annotated development set (see Section 4.2)." ></td>
	<td class="line x" title="109:224	Graph-based classifier The chain-based classifier has two parameters which need to be optimised on labelled data, making this method weakly supervised." ></td>
	<td class="line x" title="110:224	To overcome this drawback, we designed a second classifier which does not have free parameters and is thus fully unsupervised." ></td>
	<td class="line x" title="111:224	This classifier relies on cohesion graphs." ></td>
	<td class="line x" title="112:224	The vertices of such a cohesion graph correspond to the (content) word tokens in the text, each pair of vertices is connected by an edge and the edges are weighted by the semantic relatedness (i.e., the inverse NGD) between the two words." ></td>
	<td class="line x" title="113:224	The cohesion graph for example (1) is shown in Figure 1 (for expository reasons, edge weights are excluded from the figure)." ></td>
	<td class="line x" title="114:224	Once we have built the cohesion graph we compute its connectivity (defined as the average edge weight) and compare it to the connectivity of the graph that results from removing the (component words of the) target expression." ></td>
	<td class="line x" title="115:224	For instance in Figure 1, we would compare the connectivity of the graph as it is shown to the connectivity that results from removing the dashed edges." ></td>
	<td class="line x" title="116:224	If removing the idiom words from the graph leads to a higher connectivity, we assume that the idiom is used non-literally, otherwise we assume it is used literally." ></td>
	<td class="line x" title="117:224	In Figure 1, for example, most edges would have a relatively low weight, indicating a weak relation between the words they link." ></td>
	<td class="line x" title="118:224	The edge between ice and water, however, would have a higher weight." ></td>
	<td class="line x" title="119:224	Removing ice from the graph would therefore lead to a decreased connectivity and the classifier would predict that break the ice is used in the literal sense in example (1)." ></td>
	<td class="line x" title="120:224	Effectively, we replace the ex7Note, that it is not only the noun that can participate in a chain." ></td>
	<td class="line x" title="121:224	In example (2), the word spill can be linked to sweep up to provide evidence of literal usage." ></td>
	<td class="line x" title="122:224	break ice water troughschicken Dad Figure 1: Cohesion graph for example (1) plicit thresholds of the lexical chain method by an implicit threshold (i.e., change in connectivity), which does not have to be optimised." ></td>
	<td class="line x" title="123:224	4 Evaluating the Cohesion-Based Approach We tested our two cohesion-based classifiers as well as a supervised classifier on a manually annotated data set." ></td>
	<td class="line x" title="124:224	Section 4.2 gives details of the experiments and results." ></td>
	<td class="line x" title="125:224	We start, however, by describing the data used in the experiments." ></td>
	<td class="line x" title="126:224	4.1 Data We chose 17 idioms from the Oxford Dictionary of Idiomatic English (Cowie et al., 1997) and other idiom lists found on the internet." ></td>
	<td class="line x" title="127:224	The idioms were more or less selected randomly, subject to two constraints: First, because the focus of the present study is on distinguishing literal and non-literal usage, we chose expressions for which we assumed that the literal meaning was not too infrequent." ></td>
	<td class="line x" title="128:224	We thus disregarded expressions like play the second fiddle or sail under false colours." ></td>
	<td class="line x" title="129:224	Second, in line with many previous approaches to idiom classification (Fazly et al., To appear; Cook et al., 2007; Katz and Giesbrecht, 2006), we focused mainly on expressions of the form V+NP or V+PP as this is a fairly large group and many of these expressions can be used literally as well, making them an ideal test set for our purpose." ></td>
	<td class="line x" title="130:224	However, our approach also works for expressions which match a different syntactic pattern and to test the generality of our method we included a couple of these in the data set (e.g., get ones feet wet)." ></td>
	<td class="line x" title="131:224	For the same reason, we also included some expressions for which we could not find a literal use in the corpus (e.g., back the wrong horse)." ></td>
	<td class="line x" title="132:224	For each of the 17 expressions shown in Table 1, we extracted all occurrences found in the Gigaword corpus that were in canonical form (the forms listed in the table plus inflectional varia758 tions of the head verb).8 Hence, for rock the boat we would extract rocked the boat and rocking the boat but not rock a boat, rock the boats or rock the ship." ></td>
	<td class="line x" title="133:224	The motivation for this was two-fold." ></td>
	<td class="line x" title="134:224	First, as was discussed in Section 2, the vast majority of idiomatic usages are in canonical form." ></td>
	<td class="line x" title="135:224	This is especially true for non-decomposable idioms (most of our 17 idioms), where only around 3% of the idiomatic usages are not in canonical form." ></td>
	<td class="line x" title="136:224	Second, we wanted to test whether our approach would be able to detect literal usages in the set of canonical form expressions as this is precisely the set of expressions that would be classified as idiomatic by the unsupervised CForm classifier (Cook et al.(2007), Fazly et al.(To appear))." ></td>
	<td class="line x" title="139:224	While expressions in the canonical form are more likely to be used idiomatically, it is still possible to find literal usages as in examples (1) and (2)." ></td>
	<td class="line x" title="140:224	For some expressions, such as drop the ball the literal usage even outweighs the non-literal usage." ></td>
	<td class="line x" title="141:224	These literal usages would be mis-classified by the CForm classifier." ></td>
	<td class="line x" title="142:224	In principle, though, our approach is very general and would also work on expressions that are not in canonical form and expressions whose idiomatic status is unclear, i.e., we do not necessarily require a predefined set of idioms but could run the classifiers on any V+NP or V+PP chunk." ></td>
	<td class="line x" title="143:224	For each extracted example, we included five paragraphs of context (the current paragraph plus the two preceding and following ones).9 This was the context used by the classifiers." ></td>
	<td class="line x" title="144:224	The examples were then labelled as literal or non-literal by an experienced annotator." ></td>
	<td class="line x" title="145:224	If the distinction could not be made reliably, e.g., because the context was not long enough to disambiguate, the annotator was allowed to annotate ?." ></td>
	<td class="line x" title="146:224	These cases were excluded from the data sets." ></td>
	<td class="line x" title="147:224	To estimate the reliability of our annotation, a randomly selected sample (300 instances) was annotated independently by a second annotator." ></td>
	<td class="line x" title="148:224	The annotations deviated in eight cases from the original, amounting to an inter-annotator agreement of over 97% and a kappa score of 0.7 (Cohen, 1960)." ></td>
	<td class="line x" title="149:224	All deviations were cases in which one of the annotators chose ?, often because there was not sufficient context and the annotation decision had to be made on the basis of world knowledge." ></td>
	<td class="line x" title="150:224	8The extraction was done via manually built regular expressions." ></td>
	<td class="line x" title="151:224	9Note that paragraphs tend to be rather short in newswire." ></td>
	<td class="line x" title="152:224	For other genres it may be sufficient to extract one paragraph." ></td>
	<td class="line x" title="153:224	expression literal non-literal all back the wrong horse 0 25 25 bite off more than one can chew 2 142 144 bite ones tongue 16 150 166 blow ones own trumpet 0 9 9 bounce off the wall* 39 7 46 break the ice 20 521 541 drop the ball* 688 215 903 get ones feet wet 17 140 157 pass the buck 7 255 262 play with fire 34 532 566 pull the trigger* 11 4 15 rock the boat 8 470 478 set in stone 9 272 281 spill the beans 3 172 175 sweep under the carpet 0 9 9 swim against the tide 1 125 126 tear ones hair out 7 54 61 all 862 3102 3964 Table 1: Idiom statistics (* indicates expressions for which the literal usage is more common than the non-literal one) 4.2 Experimental Set-Up and Results For the lexical chain classifier we ran two experiments." ></td>
	<td class="line x" title="154:224	In the first, we used the data for one expression (break the ice) as a development set for optimising the two parameters (the relatedness threshold and the classification threshold)." ></td>
	<td class="line x" title="155:224	To find good thresholds, a simple hill-climbing search was implemented during which we increased the relatedness threshold in steps of 0.02 and the classification threshold (governing the minimum chain length needed) in steps of 1." ></td>
	<td class="line x" title="156:224	We optimised the FScore for the literal class, though we found that the selected parameters varied only minimally when optimising for accuracy." ></td>
	<td class="line x" title="157:224	We then used the parameter values determined in this way and applied the classifier to the remainder of the data." ></td>
	<td class="line x" title="158:224	The results obtained in this way depend to some extent on the data set used for the parameter setting.10 To control this factor, we also ran another experiment in which we used an oracle to set the parameters (i.e., the parameters were optimised for the complete set)." ></td>
	<td class="line x" title="159:224	While this is not a realistic scenario as it assumes that the labels of the test data are known during parameter setting, it does provide an upper bound for the lexical chain method." ></td>
	<td class="line x" title="160:224	For comparison, we also implemented an informed baseline classifier, which employs a simple model of cohesion, classifying expressions as 10We also ran the experiment for different development sets and found that there was a relatively high degree of variation in the parameters selected and in the results obtained with those settings." ></td>
	<td class="line x" title="161:224	759 literal if the noun inside the expression (e.g., ice for break the ice) is repeated elsewhere in the context, and non-literal otherwise." ></td>
	<td class="line x" title="162:224	One would expect this classifier to have a high precision for literal expressions but a low recall." ></td>
	<td class="line x" title="163:224	Finally, we implemented a supervised classifier." ></td>
	<td class="line x" title="164:224	Supervised classifiers have been used before for this task, notably by Katz and Giesbrecht (2006)." ></td>
	<td class="line x" title="165:224	Our approach is slightly different: instead of creating meaning vectors we look at the word overlap11 of a test instance with the literal and non-literal instances in the training set (for the same expression) and then assign the label of the closest set." ></td>
	<td class="line x" title="166:224	That such an approach might be promising becomes clear when one looks at some examples of literal and non-literal usage." ></td>
	<td class="line x" title="167:224	For instance, nonliteral examples of break the ice occur frequently with words such as diplomacy, relations, dialogue etc. Effectively these words form lexical chains with the idiomatic meaning of break the ice." ></td>
	<td class="line x" title="168:224	They are absent for literal usages." ></td>
	<td class="line x" title="169:224	A supervised classifier can learn which terms are indicative of which usage." ></td>
	<td class="line x" title="170:224	Note that this information is expressionspecific, i.e., it is not possible to train a classifier for play with fire on labelled examples for break the ice." ></td>
	<td class="line x" title="171:224	This makes the supervised approach quite expensive in terms of annotation effort as data has to be labelled for each expression." ></td>
	<td class="line x" title="172:224	Nonetheless, it is instructive to see how well one could do with this approach." ></td>
	<td class="line x" title="173:224	In the experiments, we ran the supervised classifier in leave-one-out mode on each expression for which we had literal examples." ></td>
	<td class="line x" title="174:224	Table 2 shows the results for the five classifiers discussed above: the informed baseline classifier (Rep), the cohesion graph (Graph), the lexical chain classifier with the parameters optimised on break the ice (LC), the lexical chain classifier with the parameters set by an oracle (LC-O), and the supervised classifier (Super)." ></td>
	<td class="line x" title="175:224	The table also shows the accuracy that would be obtained by a CForm classifier (Cook et al., 2007; Fazly et al., To appear) with gold standard canonical forms." ></td>
	<td class="line x" title="176:224	This classifier would label all examples in our data set as non-literal (it is thus equivalent to a majority class baseline)." ></td>
	<td class="line x" title="177:224	Since the majority of examples is indeed used idiomatically, this classifier achieves a relatively high accuracy." ></td>
	<td class="line x" title="178:224	However, accuracy is not the best evaluation measure here be11We used the Dice coefficient as implemented in Ted Pedersens Text::Similarity module: http://www.d.umn." ></td>
	<td class="line x" title="179:224	edu/tpederse/text-similarity.html." ></td>
	<td class="line x" title="180:224	CForm Rep Graph LC LC-O Super Acc 78.25 79.06 79.61 80.50 80.42 95.69 Pl 70.00 52.21 62.26 53.89 84.62 Rl 5.96 67.87 26.21 69.03 96.45 Fl 10.98 59.02 36.90 60.53 90.15 Table 2: Accuracy, literal precision (Pl), recall (Rl), and F-Score (Fl) for the classifiers cause we are interested in detecting literal usages among the canonical forms." ></td>
	<td class="line x" title="181:224	Therefore, we also computed the precision (Pl), recall (Rl), and Fscore (Fl) for the literal class." ></td>
	<td class="line x" title="182:224	It can be seen that all classifiers obtain a relatively high accuracy but vary in precision, recall and F-Score." ></td>
	<td class="line x" title="183:224	For the CForm classifier, precision, recall, and F-Score are undefined as it does not label any examples as literal." ></td>
	<td class="line x" title="184:224	As expected the baseline classifier, which looks for repetitions of the component words of the target expression, has a relatively high precision, showing that the expression is typically used in the literal sense if part of it is repeated in the context." ></td>
	<td class="line x" title="185:224	The recall, though, is very low, indicating that lexical repetition is not a sufficient signal for literal usage." ></td>
	<td class="line x" title="186:224	The graph-based classifier and the globally optimised lexical chain classifier (LC-O) outperform the other two unsupervised classifiers (CForm and Rep), with an F-Score of around 60%." ></td>
	<td class="line x" title="187:224	For both classifiers recall is higher than precision." ></td>
	<td class="line x" title="188:224	Note, however, that this is an upper bound for the lexical chain classifier that would not be obtained in a realistic scenario." ></td>
	<td class="line x" title="189:224	An example of the values that can be expected in a realistic setting (with parameter optimisation on a development set that is separate from the test set) is shown in column five (LC)." ></td>
	<td class="line x" title="190:224	Here the F-Score is much lower due to lower recall." ></td>
	<td class="line x" title="191:224	This classifier is too conservative when creating the chains and deciding how to interpret the chain structure; it thus only rarely outputs the literal class." ></td>
	<td class="line x" title="192:224	The reason for this conservatism may be that literal usages of break the ice (the development data) tend to have very strong chains, hence when optimising the parameters for this data set, it pays to be conservative." ></td>
	<td class="line x" title="193:224	It is positive to note that the (unsupervised) graph-based classifier performs just as well as the (weakly supervised) chain-based classifier does under optimal circumstances." ></td>
	<td class="line x" title="194:224	This means that one can by-pass the parameter setting and the need to label development data by employing the graph-based method." ></td>
	<td class="line x" title="195:224	Finally, as expected, the supervised classifier 760 outperforms all other classifiers." ></td>
	<td class="line x" title="196:224	It does so by a large margin, which is surprising given that it is based on relatively simplistic model." ></td>
	<td class="line x" title="197:224	This shows that the context in which an expression occurs can really provide vital cues about its idiomaticity." ></td>
	<td class="line x" title="198:224	Note that our results are noticeably higher than those reported by Cook et al.(2007), Fazly et al.(To appear) and Katz and Giesbrecht (2006) for similar supervised classifiers." ></td>
	<td class="line x" title="201:224	We believe that this may be partly explained by the size of our data set which is significantly larger than the ones used in these studies." ></td>
	<td class="line x" title="202:224	To assess how well our cohesion-based approach works for different idioms, we also computed the accuracy of the graph-based classifier for each expression individually (Table 3)." ></td>
	<td class="line x" title="203:224	We report accuracy here rather than literal F-Score as the latter is often undefined for the individual data sets (either because all examples of an expression are non-literal or because the classifier only predicts non-literal usages)." ></td>
	<td class="line x" title="204:224	It can be seen that the performance of the classifier is generally relatively stable, with accuracies above 50% for most idioms.12 In particular, the classifier performs well on both, expressions with a dominant non-literal meaning and those with a dominant literal meaning; it is not biased towards the non-literal class." ></td>
	<td class="line x" title="205:224	For expressions with a dominant literal meaning like drop the ball, it correctly classifies more items as literal (530 items, 472 of which are correct) than as nonliteral (373 items, 157 correct)." ></td>
	<td class="line x" title="206:224	5 Conclusion In this paper, we described a novel method for token-based idiom classification." ></td>
	<td class="line x" title="207:224	Our approach is based on the observation that literally used expressions typically exhibit cohesive ties with the surrounding discourse, while idiomatic expressions do not." ></td>
	<td class="line x" title="208:224	Hence idiomatic expressions can be detected by the absence of such ties." ></td>
	<td class="line x" title="209:224	We propose two methods that exploit this behaviour, one based on lexical chains, the other based on cohesion graphs." ></td>
	<td class="line x" title="210:224	We showed that a cohesion-based approach is well suited for distinguishing literal and nonliteral usages, even for expressions in canonical form which tend to be largely idiomatic and would all be classified as non-literal by the previously proposed CForm classifier." ></td>
	<td class="line x" title="211:224	Moreover, our find12Note that the data set for the worst performing idiom, blow ones own trumpet only contained 9 instances." ></td>
	<td class="line x" title="212:224	Hence, the low performance for this idiom may well be accidental." ></td>
	<td class="line x" title="213:224	expression Accuracy back the wrong horse 68.00 bite off more than one can chew 79.17 bite ones tongue 37.35 blow ones own trumpet 11.11 bounce off the wall* 47.82 break the ice 85.03 drop the ball* 69.66 get ones feet wet 64.33 pass the buck 82.44 play with fire 82.33 pull the trigger* 60.00 rock the boat 98.95 set in stone 85.41 spill the beans 83.43 sweep under the carpet 88.89 swim against the tide 93.65 tear ones hair out 49.18 Table 3: Accuracies of the graph-based classifier on each of the expressions (* indicates a dominant literal usage) ings suggest that the graph-based method performs nearly as well as the best performance to be expected for the chain-based method." ></td>
	<td class="line x" title="214:224	This means that the task can be addressed in a completely unsupervised way." ></td>
	<td class="line x" title="215:224	While our results are encouraging they are still below the results obtained by a basic supervised classifier." ></td>
	<td class="line x" title="216:224	In future work we would like to explore whether better performance can be achieved by adopting a bootstrapping strategy, in which we use the examples about which the unsupervised classifier is most confident (i.e., those with the largest difference in connectivity in either direction) as input for a second stage supervised classifier." ></td>
	<td class="line x" title="217:224	Another potential improvement has to do with the way in which the cohesion graph is computed." ></td>
	<td class="line x" title="218:224	Currently the graph includes all content words in the context." ></td>
	<td class="line x" title="219:224	This means that the graph is relatively big and removing the potential idiom often does not have a big effect on the connectivity; all changes in connectivity are fairly close to zero." ></td>
	<td class="line x" title="220:224	In future, we want to explore intelligent strategies for pruning the graph (e.g., by including a smaller context)." ></td>
	<td class="line x" title="221:224	We believe that this might result in more reliable classifications." ></td>
	<td class="line x" title="222:224	Acknowledgments This work was funded by the German Research Foundation DFG (under grant PI 154/9-3 and the MMCI Cluster of Excellence)." ></td>
	<td class="line x" title="223:224	Thanks to Anna Mundelein for her help with preparing the data and to Marco Pennacchiotti and Josef Ruppenhofer, for feedback and comments." ></td>
	<td class="line x" title="224:224	761" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="N09-3007
Building a Semantic Lexicon of English Nouns via Bootstrapping
Qian, Ting;Van Durme, Benjamin;Schubert, Lenhart;"></td>
	<td class="line x" title="1:163	Proceedings of the NAACL HLT Student Research Workshop and Doctoral Consortium, pages 3742, Boulder, Colorado, June 2009." ></td>
	<td class="line x" title="2:163	c 2009 Association for Computational Linguistics Building a Semantic Lexicon of English Nouns via Bootstrapping Ting Qian1, Benjamin Van Durme2 and Lenhart Schubert2 1Department of Brain and Cognitive Sciences 2Department of Computer Science University of Rochester Rochester, NY 14627 USA ting.qian@rochester.edu, {vandurme, schubert}@cs.rochester.edu Abstract We describe the use of a weakly supervised bootstrapping algorithm in discovering contrasting semantic categories from a source lexicon with little training data." ></td>
	<td class="line x" title="3:163	Our method primarily exploits the patterns in sentential contexts where different categories of words may appear." ></td>
	<td class="line x" title="4:163	Experimental results are presented showing that such automatically categorized terms tend to agree with human judgements." ></td>
	<td class="line x" title="5:163	1 Introduction There are important semantic distinctions between different types of English nouns." ></td>
	<td class="line x" title="6:163	For example, some nouns typically refer to a concrete physical object, such as book, tree, etc. Others are used to represent the process or the result of an event (e.g. birth, celebration)." ></td>
	<td class="line x" title="7:163	Such information is useful in disambiguating syntactically similar phrases and sentences, so as to provide more accurate semantic interpretations." ></td>
	<td class="line x" title="8:163	For instance, A MAN WITH HOBBIES and A MAN WITH APPLES share the same structure, but convey very different aspects about the man being referred to (i.e. activities vs possessions)." ></td>
	<td class="line x" title="9:163	Compiling such a lexicon by hand, e.g., WordNet (Fellbaum, 1998), requires tremendous time and expertise." ></td>
	<td class="line x" title="10:163	In addition, when new words appear, these will have to be analyzed and added manually." ></td>
	<td class="line x" title="11:163	Furthermore, a single, global lexicon may contain erroneous categorizations when used within a specific domain/genre; we would like a flexible lexicon, adaptable to a given corpus." ></td>
	<td class="line x" title="12:163	Also, in adapting semantic classifications of words to a particular genre or domain, we would like to be able to exploit continuing improvements in methods of extracting semantic occurrence patterns from text." ></td>
	<td class="line x" title="13:163	We present our initial efforts in discovering semantic classes incrementally under a weakly supervised bootstrapping process." ></td>
	<td class="line x" title="14:163	The approach is able to selectively learn from its own discoveries, thereby minimizing the effort needed to provide seed examples as well as maintaining a reasonable accuracy rate." ></td>
	<td class="line x" title="15:163	In what follows, we first focus on its application to an event-noun classification task, and then use a physical-object vs non-physical-object experiment as a showcase for the algorithms generality." ></td>
	<td class="line x" title="16:163	2 Bootstrapping Algorithm The bootstrapping algorithm discovers words with semantic properties similar to a small set of labelled seed examples." ></td>
	<td class="line x" title="17:163	These examples can be manually selected from an existing lexicon." ></td>
	<td class="line x" title="18:163	By simply changing the semantic property of the seed set, this algorithm can be applied to the task of discovering a variety of semantic classes." ></td>
	<td class="line x" title="19:163	Features Classification is performed using a perceptron-based model (Rosenblatt, 1958) that examines features of each word." ></td>
	<td class="line x" title="20:163	We use two kinds of features in our model: morphological (affix and word length), and contextual." ></td>
	<td class="line x" title="21:163	Suffixes, such as -ion, often reveal the semantic type that a noun belongs to (e.g., destruction, explosion)." ></td>
	<td class="line x" title="22:163	Other suffixes like -er typically suggest non-event nouns (e.g. waiter, hanger)." ></td>
	<td class="line x" title="23:163	The set of affixes can be modified to reflect meaningful distinctions in the task at hand." ></td>
	<td class="line x" title="24:163	Regarding word length, longer words tend to have more 37 syllables, and thus are more likely to contain affixes." ></td>
	<td class="line x" title="25:163	For example, if a word ends with -ment, its number of letters must be  5." ></td>
	<td class="line x" title="26:163	We defined a partition of words based on word length: shortest (fewer than 5 letters), short (5-7), medium (8-12), long (13-19), and longest (> 19)." ></td>
	<td class="line x" title="27:163	Besides morphological features, we also make use of verbalized propositions resulting from the experiments of Van Durme et al.(2008) as contextual features." ></td>
	<td class="line x" title="29:163	These outputs are in the form of world knowledge factoids abstracted from texts, based on logical forms from parsed sentences, produced by the KNEXT system (see Schubert (2002) for details)." ></td>
	<td class="line x" title="30:163	The followings are some sample factoids about the word destruction, extracted from the British National Corpus." ></td>
	<td class="line x" title="31:163	 A PERSON-OR-ORGANIZATION MAY UNDERGO A DESTRUCTION  INDIVIDUAL -S MAY HAVE A DESTRUCTION  PROPERTY MAY UNDERGO A DESTRUCTION We take each verbalization (with the target word removed) as a contextual feature, such as PROPERTY MAY UNDERGO A . Words from the same semantic category (e.g., event nouns) should have semantic and syntactic similarities on the sentential level." ></td>
	<td class="line x" title="32:163	Thus their contextual features, which reflect the use of words both semantically and syntactically, should be similar." ></td>
	<td class="line x" title="33:163	For instance, PROPERTY MAY UNDERGO A PROTECTION is another verbalization produced by KNEXT, suggesting the word protection may belong to the same category as destruction." ></td>
	<td class="line x" title="34:163	A few rough-and-ready heuristics are already employed by KNEXT to do the same task as we wish to automate here." ></td>
	<td class="line x" title="35:163	A built-in classifier judges nominals to be event or non-event ones based on analysis of endings, plus a list of event nouns whose endings are unrevealing, and a list of non-event nouns whose endings tend to suggest they are event nouns." ></td>
	<td class="line x" title="36:163	As a result, the factoids used as contextual features in our work already reflect the built-in classifiers attempt to distinguish event nouns from the rest." ></td>
	<td class="line x" title="37:163	Thus, the use of these contextual features may bias the algorithm to perform seemingly well on event-noun classification." ></td>
	<td class="line x" title="38:163	However, we will show that our algorithm works for classification of other semantic categories, for which KNEXT does not yet have discriminative procedures." ></td>
	<td class="line x" title="39:163	Iterative Training We use a bootstrapping procedure to iteratively train a perceptron-based linear classifier." ></td>
	<td class="line x" title="40:163	A perceptron algorithm determines whether the active features of a test case are similar to those learned from given categories of examples." ></td>
	<td class="line x" title="41:163	In an iterative training process, the classifier first learns from a small seed set, which contains examples of all categories (in binary classification, both positive and negative examples) manually selected to reflect human knowledge of semantic categories." ></td>
	<td class="line x" title="42:163	The classifier then discovers new instances (and corresponding features) of each category." ></td>
	<td class="line x" title="43:163	Based on activation values, these newly discovered instances are selectively admitted into the original training set, which increases the size of training examples for the next iteration." ></td>
	<td class="line x" title="44:163	The iterative training algorithm described above is adopted from Klementiev and Roth (2006)." ></td>
	<td class="line x" title="45:163	The advantage of bootstrapping is the ability to automatically learn from new discoveries, which saves both time and effort required to manually examine a source lexicon." ></td>
	<td class="line x" title="46:163	However, if implemented exactly as described above, this process has two apparent disadvantages: New examples may be wrongly classified by the model; and it is difficult to evaluate the discriminative models produced in successive iterations, as there are no standard data against which to judge them (the new examples are by definition previously unexamined)." ></td>
	<td class="line x" title="47:163	We propose two measures to alleviate these problems." ></td>
	<td class="line x" title="48:163	First, we admit into the training set only those instances whose activation values are higher than the mean activation of their corresponding categories in an iteration." ></td>
	<td class="line x" title="49:163	This sets a variable threshold that is correlated with the performance of the model at each iteration." ></td>
	<td class="line x" title="50:163	Second, we evaluate iterative results posthoc, using a Bootstrapping Score." ></td>
	<td class="line x" title="51:163	This measures the efficacy of bootstrapping (i.e. the ratio of correct newly discovered instances to training examples) and precision (i.e. the proportion of correct discoveries among all those returned by the algorithm)." ></td>
	<td class="line x" title="52:163	We compute this score to decide which iteration has yielded the optimal discriminative model." ></td>
	<td class="line x" title="53:163	3 Building an Event-noun Lexicon We applied the bootstrapping algorithm to the task of discovering event nouns from a source lexicon." ></td>
	<td class="line x" title="54:163	38 Event nouns are words that typically describe the occurrence, the process, or the result of an event." ></td>
	<td class="line x" title="55:163	We first explore the effectiveness of this algorithm, and then describe a method of extracting the optimal model." ></td>
	<td class="line x" title="56:163	Top-ranked features in the optimal model are used to find subcategories of event nouns." ></td>
	<td class="line x" title="57:163	Experimental Setup The WordNet noun-list is chosen as the source lexicon (Fellbaum, 1998), which consists of 21,512 nouns." ></td>
	<td class="line x" title="58:163	The purpose of this task is to explore the separability of event nouns from this collection." ></td>
	<td class="line x" title="59:163	typical suffixes: appeasement, arrival, renewal, construction, robbery, departure, happening irregular cases: birth, collapse, crash, death, decline, demise, loss, murder Table 1: Examples of event-nouns in initial training set." ></td>
	<td class="line x" title="60:163	We manually selected 15 event nouns and 215 non-event nouns for the seed set." ></td>
	<td class="line x" title="61:163	Event-noun examples are representative of subcategories within the semantic class, as well as their commonly seen morphological structures (Table 1)." ></td>
	<td class="line x" title="62:163	Non-event examples are primarily exceptions to morphological regularities (to prevent the algorithm from overly relying on affix features), such as, anything, ambition, diagonal." ></td>
	<td class="line x" title="63:163	The subset of all contextual and morphological features represented by both event and non-event examples are used to bootstrap the training process." ></td>
	<td class="line x" title="64:163	Event Noun Discovery Reducing the number of working features is often an effective strategy in training a perceptron." ></td>
	<td class="line x" title="65:163	We experimented with two cut-off thresholds for features: in Trial 1, features must appear at least 10 times (55,354 remaining); in Trial 2, features must appear at least 15 times (35,457 remaining)." ></td>
	<td class="line x" title="66:163	We set the training process to run for 20 iterations in both trials." ></td>
	<td class="line x" title="67:163	Classification results of each iteration were collected." ></td>
	<td class="line x" title="68:163	We expect the algorithm to discover few event nouns during early iterations." ></td>
	<td class="line x" title="69:163	But with new instances found in each subsequent iteration, it ought to utilize newly seen features and discover more." ></td>
	<td class="line x" title="70:163	Figure 1 confirms our intuition." ></td>
	<td class="line x" title="71:163	The number of classified event-noun instances increased sharply at the 15th iteration in Trial 1 and the 11th iteration in Trial 2, which may suggest overfitting of the training examples used in those iterations." ></td>
	<td class="line x" title="72:163	If so, this should also correlate with an increase of error rate in the classification results (error rate defined as the percentage of non-event nouns identified as event nouns in all discovered event nouns)." ></td>
	<td class="line x" title="73:163	We manually marked all misclassified event noun instances for the first 10 iterations in both trials." ></td>
	<td class="line x" title="74:163	The error rate in Trial 2 is expected to significantly increase at the 10th iteration, while Trial 1 should exhibit little increase in error rate within this interval." ></td>
	<td class="line x" title="75:163	This expectation is confirmed in Figure 2." ></td>
	<td class="line x" title="76:163	Extracting the Optimal Model We further pursued the task of finding the iteration that has yielded the best model." ></td>
	<td class="line x" title="77:163	Optimality is judged from two aspects: 1) the number of correctly identified event nouns should be significantly larger than the size of seed examples; and 2) the accuracy of classification results should be relatively high so that it takes little effort to clean up the result." ></td>
	<td class="line x" title="78:163	Once the optimal model is determined, we analyze its most heavily weighted features and try to derive finer categories from them." ></td>
	<td class="line x" title="79:163	Furthermore, the optimal model could be used to discover new instances from other source lexicons in the future." ></td>
	<td class="line x" title="80:163	We define a measure called the Bootstrapping Score (BS), serving a similar purpose as an F-score." ></td>
	<td class="line x" title="81:163	BS is computed as in Formula (1)." ></td>
	<td class="line x" title="82:163	BS = 2BRPrecisionBR + Precision ." ></td>
	<td class="line x" title="83:163	(1) Here the Bootstrapping Rate (BR) is computed as: BR = |NEW||NEW|+|SEED|, (2) where |NEW| is the number of correctly identified new instances (seed examples excluded), and |SEED| is the size of seed examples." ></td>
	<td class="line x" title="84:163	The rate of bootstrapping reveals how large the effect of the bootstrapping process is. Note that BR is different from the classic measure recall, for which the total number of relevent documents (i.e. true event nouns in English) must be known a priori  again, this knowledge is what we are discovering." ></td>
	<td class="line x" title="85:163	The score is a post hoc solution; both BR and precision are computed for analysis after the algorithm has finished." ></td>
	<td class="line x" title="86:163	Combining Formulas (1) and (2), a higher Bootstrapping Score means better model quality." ></td>
	<td class="line x" title="87:163	Bootstrapping scores of models in the first ten iterations are plotted in Figure 3." ></td>
	<td class="line x" title="88:163	Model quality in 39 5 10 15 20 0 2000 4000 6000 8000 10000 Iteration Number of Event Nouns Discovered Trial 1 Trial 2 Figure 1: Classification rate 2 4 6 8 10 0.05 0.10 0.15 0.20 0.25 0.30 Iteration Error rate Trial 1 Trial 2 Figure 2: Error rate 2 4 6 8 10 0.82 0.84 0.86 0.88 0.90 0.92 0.94 Iteration Bootstrapping Score Trial 1 Trial 2 Figure 3: Bootstrapping score 1 . . ." ></td>
	<td class="line x" title="89:163	6 . . ." ></td>
	<td class="line x" title="90:163	10 incorrect 5 . . ." ></td>
	<td class="line x" title="91:163	32 . . ." ></td>
	<td class="line x" title="92:163	176 correct 79 . . ." ></td>
	<td class="line x" title="93:163	236 . . ." ></td>
	<td class="line x" title="94:163	497 error rate 5.9% . . ." ></td>
	<td class="line x" title="95:163	11.9% . . ." ></td>
	<td class="line x" title="96:163	26.2% score 87.0% . . ." ></td>
	<td class="line x" title="97:163	90.8% . . ." ></td>
	<td class="line x" title="98:163	83.8% Table 2: From iterations 1 to 10, comparison between instance counts, error rates, and bootstrapping scores as the measure of model quality." ></td>
	<td class="line x" title="99:163	Trial 2 is better than in Trial 1 on average." ></td>
	<td class="line x" title="100:163	In addition, within Trial 2, Iteration 6 yielded the best discriminative model with a bootstrapping score of 90.8%." ></td>
	<td class="line x" title="101:163	Compared to instance counts and error rate measures as shown in Table 2, this bootstrapping score provides a balanced measure of model quality." ></td>
	<td class="line x" title="102:163	The model at the 6th iteration (hereafter, Model 6) can be considered the optimal model generated during the bootstrapping training process." ></td>
	<td class="line x" title="103:163	Top-ranked Features in the Optimal Model In order to understand why Model 6 is optimal, we extracted its top 15 features that activate the eventnoun target in Model 6, as listed in Table 3." ></td>
	<td class="line x" title="104:163	Interestingly, top-ranked features are all contextual ones." ></td>
	<td class="line x" title="105:163	In fact, in later models where the ranks of morphological features are boosted, the algorithm performed worse as a result of relying too much on those context-insensitive features." ></td>
	<td class="line x" title="106:163	Collectively, top-ranked features define the contextual patterns of event nouns." ></td>
	<td class="line x" title="107:163	We are interested in finding semantic subcategories within the set of event nouns (497 nouns, Trial 2) by exploiting these features individually." ></td>
	<td class="line x" title="108:163	For instance, some events typically happen to people only (e.g. birth, betrayal), while others usually happen to inanimate objects (e.g. destruction, removal)." ></td>
	<td class="line x" title="109:163	Human actions can also be distinguished by the number of participants, such as group activities (e.g. election) or individual activities (e.g. death)." ></td>
	<td class="line x" title="110:163	It is thus worth distinguishing nouns that describe different sorts of events." ></td>
	<td class="line x" title="111:163	Manual Classification We extracted the top 100 contextual features from Model 6 and grouped them into feature classes." ></td>
	<td class="line x" title="112:163	A feature class consists of contextual features sharing similar meanings." ></td>
	<td class="line x" title="113:163	For instance, A COUNTRY MAY UNDERGO and A STATE MAY UNDERGO both belong to the class social activity." ></td>
	<td class="line x" title="114:163	For each feature class, we enumerate all words that correspond to its feature instances." ></td>
	<td class="line x" title="115:163	Examples are shown in Table 4." ></td>
	<td class="line x" title="116:163	Not all events can be unambiguously classified into one of the subcategories." ></td>
	<td class="line x" title="117:163	However, this is also not necessary because these categories overlap with one another." ></td>
	<td class="line x" title="118:163	For example, death describes an event that tends to occur both individually and briefly." ></td>
	<td class="line x" title="119:163	In addition to the six categories listed here, new categories can be added by creating more feature classes." ></td>
	<td class="line x" title="120:163	Automatic Clustering Representing each noun as a frequency vector over the top 100 most discriminating contextual features, we employed k-means clustering and compared the results to our manually crafted subcategories." ></td>
	<td class="line x" title="121:163	Through trial-and-error, we set k to 12, with the smallest resulting cluster containing 2 nouns (interpretation and perception), while the biggest resulting cluster contained 320 event nouns (that seemed to share no apparent semantic properties)." ></td>
	<td class="line x" title="122:163	Other clusters varied from 5 to 50 words in size, with examples shown in Table 5." ></td>
	<td class="line x" title="123:163	The advantage of automatic clustering is that the results may reflect an English speakers impression of word similarity gained through language use." ></td>
	<td class="line x" title="124:163	Un40 a person-or-organization may undergo a a state may undergo a a can be attempted a country may undergo a a child may have a a can be for a country a company may undergo a a project may undergo a authority may undergo a an explanation can be for a an empire may undergo a a war may undergo a days may have a a can be abrupt a can be rapid Table 3: Top 15 features that promote activation of the event-noun target, ranked from most weighted to least." ></td>
	<td class="line x" title="125:163	human events: adoption, arrival, birth, betrayal, death, development, disappearance, emancipation, funeral . . ." ></td>
	<td class="line x" title="126:163	events of inanimate objects: collapse, construction, definition, destruction, identification, inception, movement, recreation, removal . . ." ></td>
	<td class="line x" title="127:163	individual activities: birth, death, execution, funeral, promotion . . ." ></td>
	<td class="line x" title="128:163	social activities: abolition, evolution, federation, fragmentation, invasion . . ." ></td>
	<td class="line x" title="129:163	lasting events: campaign, development, growth, trial . . ." ></td>
	<td class="line x" title="130:163	brief events: awakening, collapse, death, mention, onset, resignation, thunderstorm . . ." ></td>
	<td class="line x" title="131:163	Table 4: Six subcategories of event nouns." ></td>
	<td class="line x" title="132:163	fortunately, the discovered clusters do not typically come with the same obvious semantic properties as were defined in manual classification." ></td>
	<td class="line x" title="133:163	In the example given above, neither of Cluster 1 and Cluster 3 seems to have a centralized semantic theme." ></td>
	<td class="line x" title="134:163	But Cluster 2 seems to be mostly about human activities." ></td>
	<td class="line x" title="135:163	Comparison with WordNet To compare our results with WordNet resources, we enumerated all children of the gloss something that happens at a given place and time, giving 7655 terms (phrases excluded)." ></td>
	<td class="line x" title="136:163	This gave a broader range of event nouns, such as proper nouns and procedures (e.g. 9/11, CT, MRI), onomatopoeias (e.g. mew, moo), and words whose event reading is only secondary (e.g. picture, politics, teamwork)." ></td>
	<td class="line x" title="137:163	These types of words tend to have very different contextual features from what our algorithm had discovered." ></td>
	<td class="line x" title="138:163	While our method may be limited by the choice of seed examples, we were able to discover event nouns not classified under this set by WordNet, suggesting that the discovery mechanism itself is a robust one." ></td>
	<td class="line x" title="139:163	Among them were low-frequency nouns (e.g. crescendo, demise, names of processes (e.g. absorpCluster 1 (17): cancellation, cessation, closure, crackle, crash, demise, disappearance, dismissal, dissolution, division, introduction, onset, passing, resignation, reversal, termination, transformation Cluster 2 (32): alienation, backing, betrayal, contemplation, election, execution, funeral, hallucination, imitation, juxtaposition, killing, mention, moulding, perfection, prosecution, recognition, refusal, removal, resurrection, semblance, inspection, occupation, promotion, trial . . ." ></td>
	<td class="line x" title="140:163	Cluster 3 (7): development, achievement, arrival, birth, death, loss, survival Table 5: Examples resulting from automatic clustering." ></td>
	<td class="line x" title="141:163	tion, evolution), and particular cases like thunderstorm." ></td>
	<td class="line x" title="142:163	4 Extension to Other Semantic Categories To verify that our bootstrapping algorithm was not simply relying on KNEXTs own event classification heuristics, we set the algorithm to learn the distinction between physical and non-physical objects/entities." ></td>
	<td class="line x" title="143:163	(Non-)Physical-object Nouns 15 physical-object/ entity nouns (e.g. knife, ring, anthropologist) and 34 non-physical ones (e.g. happiness, knowledge) were given to the model as the initial training set." ></td>
	<td class="line x" title="144:163	At the 9th iteration, the number of discovered physical objects (which form the minority group between the two) approaches 2,200 and levels off." ></td>
	<td class="line x" title="145:163	We randomly sampled five 20-word groups (a subset of these words are listed in Table 6) from this entire set of discovered physical objects, and computed an average error rate of 4%." ></td>
	<td class="line x" title="146:163	Prominent features of the model at the 9th iteration are shown in Table 7." ></td>
	<td class="line x" title="147:163	5 Related Work The method of using distributional patterns in a large text corpus to find semantically related En41 heifer, sheriff, collector, hippie, accountant, cape, scab, pebble, box, dick, calculator, sago, brow, ship, ?john, superstar, border, rabbit, poker, garter, grinder, millionaire, ash, herdsman, ?cwm, pug, bra, fulmar, *campaign, stallion, deserter, boot, tear, elbow, cavalry, novel, cardigan, nutcase, ?bulge, businessman, cop, fig, musician, spire, butcher, dog, elk, . . ." ></td>
	<td class="line x" title="148:163	Table 6: Physical-object nouns randomly sampled from results; words with an asterisk are misclassified, ones with a question mark are doubtful." ></td>
	<td class="line x" title="149:163	a male-individual can be a a can be small a person can be a a can be large a can be young a can be german -S*morphological feature a can be british a can be old a can be good Table 7: Top-10 features that promote activation of the physical-object target in the model." ></td>
	<td class="line oc" title="150:163	glish nouns first appeared in Hindle (1990)." ></td>
	<td class="line x" title="151:163	Roark and Charniak (1998) constructed a semantic lexicon using co-occurrence statistics of nouns within noun phrases." ></td>
	<td class="line x" title="152:163	More recently, Liakata and Pulman (2008) induced a hierarchy over nominals using as features knowledge fragments similar to the sort given by KNEXT." ></td>
	<td class="line x" title="153:163	Our work might be viewed as aiming for the same goal (a lexico-semantic based partitioning over nominals, tied to corpus-based knowledge), but allowing for an a priori bias regarding preferred structure." ></td>
	<td class="line x" title="154:163	The idea of bootstrapping lexical semantic properties goes back at least to Hearst (1998), where the idea is suggested of using seed examples of a relation to discover lexico-syntactic extraction patterns and then using these to discover further examples of the desired relation." ></td>
	<td class="line x" title="155:163	The Basilisk system developed by Thelen and Riloff (2002) almost paralleled our effort." ></td>
	<td class="line x" title="156:163	However, negative features  features that would prevent a word from being classified into a semantic category  were not considered in their model." ></td>
	<td class="line x" title="157:163	In addition, in scoring candidate words, their algorithm only looked at the average relevance of syntactic patterns." ></td>
	<td class="line x" title="158:163	Our perceptron-based algorithm examines the combinatorial effect of those patterns, which has yielded results suggesting improved accuracy and bootstrapping efficacy." ></td>
	<td class="line x" title="159:163	Similar to our experiments here using k-means, Lin and Pantel (2001) gave a clustering algorithm for iteratively building semantic classes, using as features argument positions within fragments from a syntactic dependency parser." ></td>
	<td class="line x" title="160:163	6 Conclusion We have presented a bootstrapping approach for creating semantically tagged lexicons." ></td>
	<td class="line x" title="161:163	The method can effectively classify nouns with contrasting semantic properties, even when the initial training set is a very small." ></td>
	<td class="line x" title="162:163	Further classification is possible with both manual and automatic methods by utilizing individual contextual features in the optimal model." ></td>
	<td class="line x" title="163:163	Acknowledgments This work was supported by NSF grants IIS0328849 and IIS-0535105." ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-1052
Employing Topic Models for Pattern-based Semantic Class Discovery
Zhang, Huibin;Zhu, Mingjie;Shi, Shuming;Wen, Ji-Rong;"></td>
	<td class="line x" title="1:246	Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 459467, Suntec, Singapore, 2-7 August 2009." ></td>
	<td class="line x" title="2:246	c2009 ACL and AFNLP Employing Topic Models for Pattern-based Semantic Class Discovery   Huibin Zhang1*     Mingjie Zhu2*     Shuming Shi3     Ji-Rong Wen3 1Nankai University 2University of Science and Technology of China 3Microsoft Research Asia {v-huibzh, v-mingjz, shumings, jrwen}@microsoft.com    Abstract  A semantic class is a collection of items (words or phrases) which have semantically peer or sibling relationship." ></td>
	<td class="line x" title="3:246	This paper studies the employment of topic models to automatically construct semantic classes, taking as the source data a collection of raw semantic classes (RASCs), which were extracted by applying predefined patterns to web pages." ></td>
	<td class="line x" title="4:246	The primary requirement (and challenge) here is dealing with multi-membership: An item may belong to multiple semantic classes; and we need to discover as many as possible the different semantic classes the item belongs to." ></td>
	<td class="line x" title="5:246	To adopt topic models, we treat RASCs as documents, items as words, and the final semantic classes as topics." ></td>
	<td class="line x" title="6:246	Appropriate preprocessing and postprocessing are performed to improve results quality, to reduce computation cost, and to tackle the fixed-k constraint of a typical topic model." ></td>
	<td class="line x" title="7:246	Experiments conducted on 40 million web pages show that our approach could yield better results than alternative approaches." ></td>
	<td class="line x" title="8:246	1 Introduction Semantic class construction (Lin and Pantel, 2001; Pantel and Lin, 2002; Pasca, 2004; Shinzato and Torisawa, 2005; Ohshima et al., 2006) tries to discover the peer or sibling relationship among terms or phrases by organizing them into semantic classes." ></td>
	<td class="line x" title="9:246	For example, {red, white, black} is a semantic class consisting of color instances." ></td>
	<td class="line x" title="10:246	A popular way for semantic class discovery is pattern-based approach, where predefined patterns (Table 1) are applied to a   This work was performed when the authors were interns at Microsoft Research Asia collection of web pages or an online web search engine to produce some raw semantic classes (abbreviated as RASCs, Table 2)." ></td>
	<td class="line x" title="11:246	RASCs cannot be treated as the ultimate semantic classes, because they are typically noisy and incomplete, as shown in Table 2." ></td>
	<td class="line x" title="12:246	In addition, the information of one real semantic class may be distributed in lots of RASCs (R2 and R3 in Table 2)." ></td>
	<td class="line x" title="13:246	Type Pattern SENT NP {, NP}*{,} (and|or) {other} NP TAG <UL>  <LI>item</LI>     <LI>item</LI>  </UL> TAG <SELECT> <OPTION>item <OPTION>item </SELECT> * SENT: Sentence structure patterns; TAG: HTML Tag patterns Table 1." ></td>
	<td class="line x" title="14:246	Sample patterns  R1: {gold, silver, copper, coal, iron, uranium} R2: {red, yellow, color, gold, silver, copper} R3: {red, green, blue, yellow} R4: {HTML, Text, PDF, MS Word, Any file type} R5: {Today, Tomorrow, Wednesday, Thursday, Friday, Saturday, Sunday} R6: {Bush, Iraq, Photos, USA, War} Table 2." ></td>
	<td class="line x" title="15:246	Sample raw semantic classes (RASCs)  This paper aims to discover high-quality semantic classes from a large collection of noisy RASCs." ></td>
	<td class="line x" title="16:246	The primary requirement (and challenge) here is to deal with multi-membership, i.e., one item may belong to multiple different semantic classes." ></td>
	<td class="line x" title="17:246	For example, the term Lincoln can simultaneously represent a person, a place, or a car brand name." ></td>
	<td class="line x" title="18:246	Multi-membership is more popular than at a first glance, because quite a lot of English common words have also been borrowed as company names, places, or product names." ></td>
	<td class="line x" title="19:246	For a given item (as a query) which belongs to multiple semantic classes, we intend to return the semantic classes separately, rather than mixing all their items together." ></td>
	<td class="line x" title="20:246	Existing pattern-based approaches only provide very limited support to multi-membership." ></td>
	<td class="line x" title="21:246	For example, RASCs with the same labels (or hypernyms) are merged in (Pasca, 2004) to gen459 erate the ultimate semantic classes." ></td>
	<td class="line x" title="22:246	This is problematic, because RASCs may not have (accurate) hypernyms with them." ></td>
	<td class="line x" title="23:246	In this paper, we propose to use topic models to address the problem." ></td>
	<td class="line x" title="24:246	In some topic models, a document is modeled as a mixture of hidden topics." ></td>
	<td class="line x" title="25:246	The words of a document are generated according to the word distribution over the topics corresponding to the document (see Section 2 for details)." ></td>
	<td class="line x" title="26:246	Given a corpus, the latent topics can be obtained by a parameter estimation procedure." ></td>
	<td class="line x" title="27:246	Topic modeling provides a formal and convenient way of dealing with multi-membership, which is our primary motivation of adopting topic models here." ></td>
	<td class="line x" title="28:246	To employ topic models, we treat RASCs as documents, items as words, and the final semantic classes as topics." ></td>
	<td class="line x" title="29:246	There are, however, several challenges in applying topic models to our problem." ></td>
	<td class="line x" title="30:246	To begin with, the computation is intractable for processing a large collection of RASCs (our dataset for experiments contains 2.7 million unique RASCs extracted from 40 million web pages)." ></td>
	<td class="line x" title="31:246	Second, typical topic models require the number of topics (k) to be given." ></td>
	<td class="line x" title="32:246	But it lacks an easy way of acquiring the ideal number of semantic classes from the source RASC collection." ></td>
	<td class="line x" title="33:246	For the first challenge, we choose to apply topic models to the RASCs containing an item q, rather than the whole RASC collection." ></td>
	<td class="line x" title="34:246	In addition, we also perform some preprocessing operations in which some items are discarded to further improve efficiency." ></td>
	<td class="line x" title="35:246	For the second challenge, considering that most items only belong to a small number of semantic classes, we fix (for all items q) a topic number which is slightly larger than the number of classes an item could belong to." ></td>
	<td class="line x" title="36:246	And then a postprocessing operation is performed to merge the results of topic models to generate the ultimate semantic classes." ></td>
	<td class="line x" title="37:246	Experimental results show that, our topic model approach is able to generate higher-quality semantic classes than popular clustering algorithms (e.g., K-Medoids and DBSCAN)." ></td>
	<td class="line x" title="38:246	We make two contributions in the paper: On one hand, we find an effective way of constructing high-quality semantic classes in the patternbased category which deals with multimembership." ></td>
	<td class="line x" title="39:246	On the other hand, we demonstrate, for the first time, that topic modeling can be utilized to help mining the peer relationship among words." ></td>
	<td class="line x" title="40:246	In contrast, the general related relationship between words is extracted in existing topic modeling applications." ></td>
	<td class="line x" title="41:246	Thus we expand the application scope of topic modeling." ></td>
	<td class="line x" title="42:246	2 Topic Models In this section we briefly introduce the two widely used topic models which are adopted in our paper." ></td>
	<td class="line x" title="43:246	Both of them model a document as a mixture of hidden topics." ></td>
	<td class="line x" title="44:246	The words of every document are assumed to be generated via a generative probability process." ></td>
	<td class="line x" title="45:246	The parameters of the model are estimated from a training process over a given corpus, by maximizing the likelihood of generating the corpus." ></td>
	<td class="line x" title="46:246	Then the model can be utilized to inference a new document." ></td>
	<td class="line x" title="47:246	pLSI: The probabilistic Latent Semantic Indexing Model (pLSI) was introduced in Hofmann (1999), arose from Latent Semantic Indexing (Deerwester et al., 1990)." ></td>
	<td class="line x" title="48:246	The following process illustrates how to generate a document d in pLSI: 1." ></td>
	<td class="line x" title="49:246	Pick a topic mixture distribution  ( | )." ></td>
	<td class="line x" title="50:246	2." ></td>
	<td class="line x" title="51:246	For each word wi in d a. Pick a latent topic z with the probability  ( | ) for wi b. Generate wi with probability  (  | ) So with k latent topics, the likelihood of generating a document d is   ( ) =           ( | )   (2.1) LDA (Blei et al., 2003): In LDA, the topic mixture is drawn from a conjugate Dirichlet prior that remains the same for all documents (Figure 1)." ></td>
	<td class="line x" title="52:246	The generative process for each document in the corpus is, 1." ></td>
	<td class="line x" title="53:246	Choose document length N from a Poisson distribution Poisson( )." ></td>
	<td class="line x" title="54:246	2." ></td>
	<td class="line x" title="55:246	Choose   from a Dirichlet distribution with parameter  . 3." ></td>
	<td class="line x" title="56:246	For each of the N words wi." ></td>
	<td class="line x" title="57:246	a. Choose a topic z from a Multinomial distribution with parameter  . b. Pick a word wi from       ,  . So the likelihood of generating a document is   ( ) =   ( | )     ( | )      ,      (2.2)   Figure 1." ></td>
	<td class="line x" title="58:246	Graphical model representation of LDA, from Blei et al.(2003)  w z  N M 460 3 Our Approach The source data of our approach is a collection (denoted as CR) of RASCs extracted via applying patterns to a large collection of web pages." ></td>
	<td class="line x" title="60:246	Given an item as an input query, the output of our approach is one or multiple semantic classes for the item." ></td>
	<td class="line x" title="61:246	To be applicable in real-world dataset, our approach needs to be able to process at least millions of RASCs." ></td>
	<td class="line x" title="62:246	3.1 Main Idea As reviewed in Section 2, topic modeling provides a formal and convenient way of grouping documents and words to topics." ></td>
	<td class="line x" title="63:246	In order to apply topic models to our problem, we map RASCs to documents, items to words, and treat the output topics yielded from topic modeling as our semantic classes (Table 3)." ></td>
	<td class="line x" title="64:246	The motivation of utilizing topic modeling to solve our problem and building the above mapping comes from the following observations." ></td>
	<td class="line x" title="65:246	1) In our problem, one item may belong to multiple semantic classes; similarly in topic modeling, a word can appear in multiple topics." ></td>
	<td class="line x" title="66:246	2) We observe from our source data that some RASCs are comprised of items in multiple semantic classes." ></td>
	<td class="line x" title="67:246	And at the same time, one document could be related to multiple topics in some topic models (e.g., pLSI and LDA)." ></td>
	<td class="line x" title="68:246	Topic modeling Semantic class construction word item (word or phrase) document RASC topic semantic class Table 3." ></td>
	<td class="line x" title="69:246	The mapping from the concepts in topic modeling to those in semantic class construction  Due to the above observations, we hope topic modeling can be employed to construct semantic classes from RASCs, just as it has been used in assigning documents and words to topics." ></td>
	<td class="line x" title="70:246	There are some critical challenges and issues which should be properly addressed when topic models are adopted here." ></td>
	<td class="line x" title="71:246	Efficiency: Our RASC collection CR contains about 2.7 million unique RASCs and 26 million (1 million unique) items." ></td>
	<td class="line x" title="72:246	Building topic models directly for such a large dataset may be computationally intractable." ></td>
	<td class="line x" title="73:246	To overcome this challenge, we choose to apply topic models to the RASCs containing a specific item rather than the whole RASC collection." ></td>
	<td class="line x" title="74:246	Please keep in mind that our goal in this paper is to construct the semantic classes for an item when the item is given as a query." ></td>
	<td class="line x" title="75:246	For one item q, we denote CR(q) to be all the RASCs in CR containing the item." ></td>
	<td class="line x" title="76:246	We believe building a topic model over CR(q) is much more effective because it contains significantly fewer documents, words, and topics." ></td>
	<td class="line x" title="77:246	To further improve efficiency, we also perform preprocessing (refer to Section 3.4 for details) before building topic models for CR(q), where some lowfrequency items are removed." ></td>
	<td class="line x" title="78:246	Determine the number of topics: Most topic models require the number of topics to be known beforehand1." ></td>
	<td class="line x" title="79:246	However, it is not an easy task to automatically determine the exact number of semantic classes an item q should belong to." ></td>
	<td class="line x" title="80:246	Actually the number may vary for different q. Our solution is to set (for all items q) the topic number to be a fixed value (k=5 in our experiments) which is slightly larger than the number of semantic classes most items could belong to." ></td>
	<td class="line x" title="81:246	Then we perform postprocessing for the k topics to produce the final properly semantic classes." ></td>
	<td class="line x" title="82:246	In summary, our approach contains three phases (Figure 2)." ></td>
	<td class="line x" title="83:246	We build topic models for every CR(q), rather than the whole collection CR." ></td>
	<td class="line x" title="84:246	A preprocessing phase and a postprocessing phase are added before and after the topic modeling phase to improve efficiency and to overcome the fixed-k problem." ></td>
	<td class="line x" title="85:246	The details of each phase are presented in the following subsections." ></td>
	<td class="line x" title="86:246	Figure 2." ></td>
	<td class="line x" title="87:246	Main phases of our approach  3.2 Adopting Topic Models For an item q, topic modeling is adopted to process the RASCs in CR(q) to generate k semantic classes." ></td>
	<td class="line x" title="88:246	Here we use LDA as an example to  1 Although there is study of non-parametric Bayesian models (Li et al., 2007) which need no prior knowledge of topic number, the computational complexity seems to exceed our efficiency requirement and we shall leave this to future work." ></td>
	<td class="line x" title="89:246	R580 R1 R2 CR Item q Preprocessing  400  1  2 T5 T1 T2 C3 C1 C2 Topic modeling Postprocessing T3 T4 CR(q) 461 illustrate the process." ></td>
	<td class="line x" title="90:246	The case of other generative topic models (e.g., pLSI) is very similar." ></td>
	<td class="line x" title="91:246	According to the assumption of LDA and our concept mapping in Table 3, a RASC (document) is viewed as a mixture of hidden semantic classes (topics)." ></td>
	<td class="line x" title="92:246	The generative process for a RASC R in the corpus CR(q) is as follows, 1) Choose a RASC size (i.e., the number of items in R): NR ~ Poisson( )." ></td>
	<td class="line x" title="93:246	2) Choose a k-dimensional vector    from a Dirichlet distribution with parameter  . 3) For each of the NR items an: a) Pick a semantic class    from a multinomial distribution with parameter   . b) Pick an item an from  (  |  , ) , where the item probabilities are parameterized by the matrix  . There are three parameters in the model:   (a scalar),   (a k-dimensional vector), and   (a     matrix where V is the number of distinct items in CR(q))." ></td>
	<td class="line x" title="94:246	The parameter values can be obtained from a training (or called parameter estimation) process over CR(q), by maximizing the likelihood of generating the corpus." ></td>
	<td class="line x" title="95:246	Once   is determined, we are able to compute  ( | , ), the probability of item a belonging to semantic class z. Therefore we can determine the members of a semantic class z by selecting those items with high      ,   values." ></td>
	<td class="line x" title="96:246	The number of topics k is assumed known and fixed in LDA." ></td>
	<td class="line x" title="97:246	As has been discussed in Section 3.1, we set a constant k value for all different CR(q)." ></td>
	<td class="line x" title="98:246	And we rely on the postprocessing phase to merge the semantic classes produced by the topic model to generate the ultimate semantic classes." ></td>
	<td class="line x" title="99:246	When topic modeling is used in document classification, an inference procedure is required to determine the topics for a new document." ></td>
	<td class="line x" title="100:246	Please note that inference is not needed in our problem." ></td>
	<td class="line x" title="101:246	One natural question here is: Considering that in most topic modeling applications, the words within a resultant topic are typically semantically related but may not be in peer relationship, then what is the intuition that the resultant topics here are semantic classes rather than lists of generally related words?" ></td>
	<td class="line x" title="102:246	The magic lies in the documents we used in employing topic models." ></td>
	<td class="line x" title="103:246	Words co-occurred in real documents tend to be semantically related; while items co-occurred in RASCs tend to be peers." ></td>
	<td class="line x" title="104:246	Experimental results show that most items in the same output semantic class have peer relationship." ></td>
	<td class="line x" title="105:246	It might be noteworthy to mention the exchangeability or bag-of-words assumption in most topic models." ></td>
	<td class="line x" title="106:246	Although the order of words in a document may be important, standard topic models neglect the order for simplicity and other reasons2." ></td>
	<td class="line x" title="107:246	The order of items in a RASC is clearly much weaker than the order of words in an ordinary document." ></td>
	<td class="line x" title="108:246	In some sense, topic models are more suitable to be used here than in processing an ordinary document corpus." ></td>
	<td class="line x" title="109:246	3.3 Preprocessing and Postprocessing Preprocessing is applied to CR(q) before we build topic models for it." ></td>
	<td class="line x" title="110:246	In this phase, we discard from all RASCs the items with frequency (i.e., the number of RASCs containing the item) less than a threshold h. A RASC itself is discarded from CR(q) if it contains less than two items after the item-removal operations." ></td>
	<td class="line x" title="111:246	We choose to remove low-frequency items, because we found that low-frequency items are seldom important members of any semantic class for q. So the goal is to reduce the topic model training time (by reducing the training data) without sacrificing results quality too much." ></td>
	<td class="line x" title="112:246	In the experiments section, we compare the approaches with and without preprocessing in terms of results quality and efficiency." ></td>
	<td class="line x" title="113:246	Interestingly, experimental results show that, for some small threshold values, the results quality becomes higher after preprocessing is performed." ></td>
	<td class="line x" title="114:246	We will give more discussions in Section 4." ></td>
	<td class="line x" title="115:246	In the postprocessing phase, the output semantic classes (topics) of topic modeling are merged to generate the ultimate semantic classes." ></td>
	<td class="line x" title="116:246	As indicated in Sections 3.1 and 3.2, we fix the number of topics (k=5) for different corpus CR(q) in employing topic models." ></td>
	<td class="line x" title="117:246	For most items q, this is a larger value than the real number of semantic classes the item belongs to." ></td>
	<td class="line x" title="118:246	As a result, one real semantic class may be divided into multiple topics." ></td>
	<td class="line x" title="119:246	Therefore one core operation in this phase is to merge those topics into one semantic class." ></td>
	<td class="line x" title="120:246	In addition, the items in each semantic class need to be properly ordered." ></td>
	<td class="line x" title="121:246	Thus main operations include, 1) Merge semantic classes 2) Sort the items in each semantic class Now we illustrate how to perform the operations." ></td>
	<td class="line x" title="122:246	Merge semantic classes: The merge process is performed by repeatedly calculating the simi 2 There are topic model extensions considering word order in documents, such as Griffiths et al.(2005)." ></td>
	<td class="line x" title="124:246	462 larity between two semantic classes and merging the two ones with the highest similarity until the similarity is under a threshold." ></td>
	<td class="line x" title="125:246	One simple and straightforward similarity measure is the Jaccard coefficient,       1, 2 =   1   2   1   2  (3.1) where  1   2  and  1   2  are respectively the intersection and union of semantic classes C1 and C2." ></td>
	<td class="line x" title="126:246	This formula might be over-simple, because the similarity between two different items is not exploited." ></td>
	<td class="line x" title="127:246	So we propose the following measure,       1, 2 =      ( , )   2   1   1    2  (3.2) where |C| is the number of items in semantic class C, and sim(a,b) is the similarity between items a and b, which will be discussed shortly." ></td>
	<td class="line x" title="128:246	In Section 4, we compare the performance of the above two formulas by experiments." ></td>
	<td class="line x" title="129:246	Sort items: We assign an importance score to every item in a semantic class and sort them according to the importance scores." ></td>
	<td class="line x" title="130:246	Intuitively, an item should get a high rank if the average similarity between the item and the other items in the semantic class is high, and if it has high similarity to the query item q. Thus we calculate the importance of item a in a semantic class C as follows,     |  =   sim(a,C)+(1- )  sim(a,q) (3.3) where   is a parameter in [0,1], sim(a,q) is the similarity between a and the query item q, and sim(a,C) is the similarity between a and C, calculated as,       ,  =     ( , )       (3.4) Item similarity calculation: Formulas 3.2, 3.3, and 3.4 rely on the calculation of the similarity between two items." ></td>
	<td class="line x" title="131:246	One simple way of estimating item similarity is to count the number of RASCs containing both of them." ></td>
	<td class="line x" title="132:246	We extend such an idea by distinguishing the reliability of different patterns and punishing term similarity contributions from the same site." ></td>
	<td class="line x" title="133:246	The resultant similarity formula is,     ( , ) =  log(1 +   ( (  , ))    =1 )   =1  (3.5) where Ci,j is a RASC containing both a and b, P(Ci,j) is the pattern via which the RASC is extracted, and w(P) is the weight of pattern P. Assume all these RASCs belong to m sites with Ci,j extracted from a page in site i, and ki being the number of RASCs corresponding to site i. To determine the weight of every type of pattern, we randomly selected 50 RASCs for each pattern and labeled their quality." ></td>
	<td class="line x" title="134:246	The weight of each kind of pattern is then determined by the average quality of all labeled RASCs corresponding to it." ></td>
	<td class="line x" title="135:246	The efficiency of postprocessing is not a problem, because the time cost of postprocessing is much less than that of the topic modeling phase." ></td>
	<td class="line x" title="136:246	3.4 Discussion 3.4.1 Efficiency of processing popular items Our approach receives a query item q from users and returns the semantic classes containing the query." ></td>
	<td class="line x" title="137:246	The maximal query processing time should not be larger than several seconds, because users would not like to wait more time." ></td>
	<td class="line x" title="138:246	Although the average query processing time of our approach is much shorter than 1 second (see Table 4 in Section 4), it takes several minutes to process a popular item such as Washington, because it is contained in a lot of RASCs." ></td>
	<td class="line x" title="139:246	In order to reduce the maximal online processing time, our solution is offline processing popular items and storing the resultant semantic classes on disk." ></td>
	<td class="line x" title="140:246	The time cost of offline processing is feasible, because we spent about 15 hours on a 4core machine to complete the offline processing for all the items in our RASC collection." ></td>
	<td class="line x" title="141:246	3.4.2 Alternative approaches One may be able to easily think of other approaches to address our problem." ></td>
	<td class="line x" title="142:246	Here we discuss some alternative approaches which are treated as our baseline in experiments." ></td>
	<td class="line x" title="143:246	RASC clustering: Given a query item q, run a clustering algorithm over CR(q) and merge all RASCs in the same cluster as one semantic class." ></td>
	<td class="line x" title="144:246	Formula 3.1 or 3.2 can be used to compute the similarity between RASCs in performing clustering." ></td>
	<td class="line x" title="145:246	We try two clustering algorithms in experiments: K-Medoids and DBSCAN." ></td>
	<td class="line x" title="146:246	Please note kmeans cannot be utilized here because coordinates are not available for RASCs." ></td>
	<td class="line x" title="147:246	One drawback of RASC clustering is that it cannot deal with the case of one RASC containing the items from multiple semantic classes." ></td>
	<td class="line x" title="148:246	Item clustering: By Formula 3.5, we are able to construct an item graph GI to record the neighbors (in terms of similarity) of each item." ></td>
	<td class="line x" title="149:246	Given a query item q, we first retrieve its neighbors from GI, and then run a clustering algorithm over the neighbors." ></td>
	<td class="line x" title="150:246	As in the case of RASC clustering, we try two clustering algorithms in experiments: K-Medoids and DBSCAN." ></td>
	<td class="line x" title="151:246	The primary disadvantage of item clustering is that it cannot assign an item (except for the query item q) to 463 multiple semantic classes." ></td>
	<td class="line x" title="152:246	As a result, when we input gold as the query, the item silver can only be assigned to one semantic class, although the term can simultaneously represents a color and a chemical element." ></td>
	<td class="line x" title="153:246	4 Experiments 4.1 Experimental Setup Datasets: By using the Open Directory Project (ODP3) URLs as seeds, we crawled about 40 million English web pages in a breadth-first way." ></td>
	<td class="line x" title="154:246	RASCs are extracted via applying a list of sentence structure patterns and HTML tag patterns (see Table 1 for some examples)." ></td>
	<td class="line x" title="155:246	Our RASC collection CR contains about 2.7 million unique RASCs and 1 million distinct items." ></td>
	<td class="line x" title="156:246	Query set and labeling: We have volunteers to try Google Sets4, record their queries being used, and select overall 55 queries to form our query set." ></td>
	<td class="line x" title="157:246	For each query, the results of all approaches are mixed together and labeled by following two steps." ></td>
	<td class="line x" title="158:246	In the first step, the standard (or ideal) semantic classes (SSCs) for the query are manually determined." ></td>
	<td class="line x" title="159:246	For example, the ideal semantic classes for item Georgia may include Countries, and U.S. states." ></td>
	<td class="line x" title="160:246	In the second step, each item is assigned a label of Good, Fair, or Bad with respect to each SSC." ></td>
	<td class="line x" title="161:246	For example, silver is labeled Good with respect to colors and chemical elements." ></td>
	<td class="line x" title="162:246	We adopt metric MnDCG (Section 4.2) as our evaluation metric." ></td>
	<td class="line x" title="163:246	Approaches for comparison: We compare our approach with the alternative approaches discussed in Section 3.4.2." ></td>
	<td class="line x" title="164:246	LDA: Our approach with LDA as the topic model." ></td>
	<td class="line x" title="165:246	The implementation of LDA is based on Bleis code of variational EM for LDA5." ></td>
	<td class="line x" title="166:246	pLSI: Our approach with pLSI as the topic model." ></td>
	<td class="line x" title="167:246	The implementation of pLSI is based on Schein, et al.(2002)." ></td>
	<td class="line x" title="169:246	KMedoids-RASC: The RASC clustering approach illustrated in Section 3.4.2, with the K-Medoids clustering algorithm utilized." ></td>
	<td class="line x" title="170:246	DBSCAN-RASC: The RASC clustering approach with DBSCAN utilized." ></td>
	<td class="line x" title="171:246	KMedoids-Item: The item clustering approach with the K-Medoids utilized." ></td>
	<td class="line x" title="172:246	DBSCAN-Item: The item clustering approach with the DBSCAN clustering algorithm utilized." ></td>
	<td class="line x" title="173:246	3 http://www.dmoz.org 4 http://labs.google.com/sets 5 http://www.cs.princeton.edu/~blei/lda-c/ K-Medoids clustering needs to predefine the cluster number k. We fix the k value for all different query item q, as has been done for the topic model approach." ></td>
	<td class="line x" title="174:246	For fair comparison, the same postprocessing is made for all the approaches." ></td>
	<td class="line x" title="175:246	And the same preprocessing is made for all the approaches except for the item clustering ones (to which the preprocessing is not applicable)." ></td>
	<td class="line x" title="176:246	4.2 Evaluation Methodology Each produced semantic class is an ordered list of items." ></td>
	<td class="line x" title="177:246	A couple of metrics in the information retrieval (IR) community like Precision@10, MAP (mean average precision), and nDCG (normalized discounted cumulative gain) are available for evaluating a single ranked list of items per query (Croft et al., 2009)." ></td>
	<td class="line x" title="178:246	Among the metrics, nDCG (Jarvelin and Kekalainen, 2000) can handle our three-level judgments (Good, Fair, and Bad, refer to Section 4.1),      @ =      /log( + 1)   =1       /log( + 1) =1  (4.1) where G(i) is the gain value assigned to the ith item, and G*(i) is the gain value assigned to the ith item of an ideal (or perfect) ranking list." ></td>
	<td class="line x" title="179:246	Here we extend the IR metrics to the evaluation of multiple ordered lists per query." ></td>
	<td class="line x" title="180:246	We use nDCG as the basic metric and extend it to MnDCG." ></td>
	<td class="line x" title="181:246	Assume labelers have determined m SSCs (SSC1~SSCm, refer to Section 4.1) for query q and the weight (or importance) of SSCi is wi." ></td>
	<td class="line x" title="182:246	Assume n semantic classes are generated by an approach and n1 of them have corresponding SSCs (i.e., no appropriate SSC can be found for the remaining n-n1 semantic classes)." ></td>
	<td class="line x" title="183:246	We define the MnDCG score of an approach (with respect to query q) as,          =  1           (SSC ) i=1   mi=1  (4.2) where             = 0                                              = 0 1   max  [1,   ](       ,  )        0   (4.3) In the above formula, nDCG(Gi,j) is the nDCG score of semantic class Gi,j; and ki denotes the number of semantic classes assigned to SSCi." ></td>
	<td class="line x" title="184:246	For a list of queries, the MnDCG score of an algorithm is the average of all scores for the queries." ></td>
	<td class="line x" title="185:246	The metric is designed to properly deal with the following cases, 464 i)." ></td>
	<td class="line x" title="186:246	One semantic class is wrongly split into multiple ones: Punished by dividing    in Formula 4.3; ii)." ></td>
	<td class="line x" title="187:246	A semantic class is too noisy to be assigned to any SSC: Processed by the n1/n in Formula 4.2; iii)." ></td>
	<td class="line x" title="188:246	Fewer semantic classes (than the number of SSCs) are produced: Punished in Formula 4.3 by assigning a zero value." ></td>
	<td class="line x" title="189:246	iv)." ></td>
	<td class="line x" title="190:246	Wrongly merge multiple semantic classes into one: The nDCG score of the merged one will be small because it is computed with respect to only one single SSC." ></td>
	<td class="line x" title="191:246	The gain values of nDCG for the three relevance levels (Bad, Fair, and Good) are respectively -1, 1, and 2 in experiments." ></td>
	<td class="line x" title="192:246	4.3 Experimental  Results 4.3.1 Overall performance comparison Figure 3 shows the performance comparison between the approaches listed in Section 4.1, using metrics MnDCG@n (n=110) . Postprocessing is performed for all the approaches, where Formula 3.2 is adopted to compute the similarity between semantic classes." ></td>
	<td class="line x" title="193:246	The results show that that the topic modeling approaches produce higher-quality semantic classes than the other approaches." ></td>
	<td class="line x" title="194:246	It indicates that the topic mixture assumption of topic modeling can handle the multi-membership problem very well here." ></td>
	<td class="line x" title="195:246	Among the alternative approaches, RASC clustering behaves better than item clustering." ></td>
	<td class="line x" title="196:246	The reason might be that an item cannot belong to multiple clusters in the two item clustering approaches, while RASC clustering allows this." ></td>
	<td class="line x" title="197:246	For the RASC clustering approaches, although one item has the chance to belong to different semantic classes, one RASC can only belong to one semantic class." ></td>
	<td class="line x" title="198:246	Figure 3." ></td>
	<td class="line x" title="199:246	Quality comparison (MnDCG@n) among approaches (frequency threshold h = 4 in preprocessing; k = 5 in topic models) 4.3.2 Preprocessing experiments Table 4 shows the average query processing time and results quality of the LDA approach, by varying frequency threshold h. Similar results are observed for the pLSI approach." ></td>
	<td class="line x" title="200:246	In the table, h=1 means no preprocessing is performed." ></td>
	<td class="line x" title="201:246	The average query processing time is calculated over all items in our dataset." ></td>
	<td class="line x" title="202:246	As the threshold h increases, the processing time decreases as expected, because the input of topic modeling gets smaller." ></td>
	<td class="line x" title="203:246	The second column lists the results quality (measured by MnDCG@10)." ></td>
	<td class="line x" title="204:246	Interestingly, we get the best results quality when h=4 (i.e., the items with frequency less than 4 are discarded)." ></td>
	<td class="line x" title="205:246	The reason may be that most low-frequency items are noisy ones." ></td>
	<td class="line x" title="206:246	As a result, preprocessing can improve both results quality and processing efficiency; and h=4 seems a good choice in preprocessing for our dataset." ></td>
	<td class="line x" title="207:246	h Avg." ></td>
	<td class="line x" title="208:246	Query Proc." ></td>
	<td class="line x" title="209:246	Time (seconds) Quality (MnDCG@10) 1 0.414 0.281 2 0.375 0.294 3 0.320 0.322 4 0.268 0.331 5 0.232 0.328 6 0.210 0.315 7 0.197 0.315 8 0.184 0.313 9 0.173 0.288 Table 4." ></td>
	<td class="line x" title="210:246	Time complexity and quality comparison among LDA approaches of different thresholds  4.3.3 Postprocessing experiments  Figure 4." ></td>
	<td class="line x" title="211:246	Results quality comparison among topic modeling approaches with and without postprocessing (metric: MnDCG@10)  The effect of postprocessing is shown in Figure 4." ></td>
	<td class="line x" title="212:246	In the figure, NP means no postprocessing is performed." ></td>
	<td class="line x" title="213:246	Sim1 and Sim2 respectively mean Formula 3.1 and Formula 3.2 are used in postprocessing as the similarity measure between 0 0 . 0 5 0 . 1 0 . 1 5 0 . 2 0 . 2 5 0 . 3 0 . 3 5 0 . 4 0 . 4 5 1 2 3 4 5 6 7 8 9 10 p L SI L DA K M e d o id s R A SC DB SC A N R A SC K M e d o id s I t e m DB SC A N I t e m n 0 . 2 7 0 . 2 8 0 . 2 9 0 . 3 0 . 3 1 0 . 3 2 0 . 3 3 0 . 3 4 L DA p L SI NP Sim 1 Sim 2 465 semantic classes." ></td>
	<td class="line x" title="214:246	The same preprocessing (h=4) is performed in generating the data." ></td>
	<td class="line x" title="215:246	It can be seen that postprocessing improves results quality." ></td>
	<td class="line x" title="216:246	Sim2 achieves more performance improvement than Sim1, which demonstrates the effectiveness of the similarity measure in Formula 3.2." ></td>
	<td class="line x" title="217:246	4.3.4 Sample results Table 5 shows the semantic classes generated by our LDA approach for some sample queries in which the bad classes or bad members are highlighted (to save space, 10 items are listed here, and the query itself is omitted in the resultant semantic classes)." ></td>
	<td class="line x" title="218:246	Query Semantic Classes apple C1: ibm, microsoft, sony, dell, toshiba,  samsung, panasonic, canon, nec, sharp  C2: peach, strawberry, cherry, orange, banana, lemon, pineapple, raspberry, pear, grape  gold C1: silver, copper, platinum, zinc, lead, iron, nickel, tin, aluminum, manganese  C2: silver, red, black, white, blue, purple, orange, pink, brown, navy  C3: silver, platinum, earrings, diamonds, rings, bracelets, necklaces, pendants, jewelry, watches  C4: silver, home, money, business, metal, furniture, shoes, gypsum, hematite, fluorite  lincoln C1: ford, mazda, toyota, dodge, nissan, honda, bmw, chrysler, mitsubishi, audi  C2: bristol, manchester, birmingham, leeds, london, cardiff, nottingham, newcastle, sheffield, southampton  C3: jefferson, jackson, washington, madison, franklin, sacramento, new york city, monroe, Louisville, marion  computer science C1: chemistry, mathematics, physics, biology, psychology, education, history, music, business, economics  Table 5." ></td>
	<td class="line x" title="219:246	Semantic classes generated by our approach for some sample queries (topic model = LDA)  5 Related Work Several categories of work are related to ours." ></td>
	<td class="line x" title="220:246	The first category is about set expansion (i.e., retrieving one semantic class given one term or a couple of terms)." ></td>
	<td class="line oc" title="221:246	Syntactic context information is used (Hindle, 1990; Ruge, 1992; Lin, 1998) to compute term similarities, based on which similar words to a particular word can directly be returned." ></td>
	<td class="line x" title="222:246	Google sets is an online service which, given one to five items, predicts other items in the set." ></td>
	<td class="line x" title="223:246	Ghahramani and Heller (2005) introduce a Bayesian Sets algorithm for set expansion." ></td>
	<td class="line x" title="224:246	Set expansion is performed by feeding queries to web search engines in Wang and Cohen (2007) and Kozareva (2008)." ></td>
	<td class="line x" title="225:246	All of the above work only yields one semantic class for a given query." ></td>
	<td class="line x" title="226:246	Second, there are pattern-based approaches in the literature which only do limited integration of RASCs (Shinzato and Torisawa, 2004; Shinzato and Torisawa, 2005; Pasca, 2004), as discussed in the introduction section." ></td>
	<td class="line x" title="227:246	In Shi et al.(2008), an ad-hoc approach was proposed to discover the multiple semantic classes for one item." ></td>
	<td class="line x" title="229:246	The third category is distributional similarity approaches which provide multi-membership support (Harris, 1985; Lin  and Pantel, 2001; Pantel and Lin, 2002)." ></td>
	<td class="line x" title="230:246	Among them, the CBC algorithm (Pantel and Lin, 2002) addresses the multi-membership problem." ></td>
	<td class="line x" title="231:246	But it relies on term vectors and centroids which are not available in pattern-based approaches." ></td>
	<td class="line x" title="232:246	It is therefore not clear whether it can be borrowed to deal with multi-membership here." ></td>
	<td class="line x" title="233:246	Among the various applications of topic modeling, maybe the efforts of using topic model for Word Sense Disambiguation (WSD) are most relevant to our work." ></td>
	<td class="line x" title="234:246	In Cai et al (2007), LDA is utilized to capture the global context information as the topic features for better performing the WSD task." ></td>
	<td class="line x" title="235:246	In Boyd-Graber et al.(2007), Latent Dirichlet with WordNet (LDAWN) is developed for simultaneously disambiguating a corpus and learning the domains in which to consider each word." ></td>
	<td class="line x" title="237:246	They do not generate semantic classes." ></td>
	<td class="line x" title="238:246	6 Conclusions We presented an approach that employs topic modeling for semantic class construction." ></td>
	<td class="line x" title="239:246	Given an item q, we first retrieve all RASCs containing the item to form a collection CR(q)." ></td>
	<td class="line x" title="240:246	Then we perform some preprocessing to CR(q) and build a topic model for it." ></td>
	<td class="line x" title="241:246	Finally, the output semantic classes of topic modeling are post-processed to generate the final semantic classes." ></td>
	<td class="line x" title="242:246	For the CR(q) which contains a lot of RASCs, we perform offline processing according to the above process and store the results on disk, in order to reduce the online query processing time." ></td>
	<td class="line x" title="243:246	We also proposed an evaluation methodology for measuring the quality of semantic classes." ></td>
	<td class="line x" title="244:246	We show by experiments that our topic modeling approach outperforms the item clustering and RASC clustering approaches." ></td>
	<td class="line x" title="245:246	Acknowledgments We wish to acknowledge help from Xiaokang Liu for mining RASCs from web pages, Changliang Wang and Zhongkai Fu for data process." ></td>
	<td class="line x" title="246:246	466" ></td>
</tr></table>
<table cellspacing="0" cellpadding="0" class="srcPaper"><tr>
<td class="line srcData" title="P09-2018
Directional Distributional Similarity for Lexical Expansion
Kotlerman, Lili;Dagan, Ido;Szpektor, Idan;Zhitomirsky-Geffet, Maayan;"></td>
	<td class="line x" title="1:94	Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 6972, Suntec, Singapore, 4 August 2009." ></td>
	<td class="line x" title="2:94	c 2009 ACL and AFNLP Directional Distributional Similarity for Lexical Expansion Lili Kotlerman, Ido Dagan, Idan Szpektor Department of Computer Science Bar-Ilan University Ramat Gan, Israel lili.dav@gmail.com {dagan,szpekti}@cs.biu.ac.il Maayan Zhitomirsky-Geffet Department of Information Science Bar-Ilan University Ramat Gan, Israel maayan.geffet@gmail.com Abstract Distributional word similarity is most commonly perceived as a symmetric relation." ></td>
	<td class="line x" title="3:94	Yet, one of its major applications is lexical expansion, which is generally asymmetric." ></td>
	<td class="line x" title="4:94	This paper investigates the nature of directional (asymmetric) similarity measures, which aim to quantify distributional feature inclusion." ></td>
	<td class="line x" title="5:94	We identify desired properties of such measures, specify a particular one based on averaged precision, and demonstrate the empirical benefit of directional measures for expansion." ></td>
	<td class="line x" title="6:94	1 Introduction Much work on automatic identification of semantically similar terms exploits Distributional Similarity, assuming that such terms appear in similar contexts." ></td>
	<td class="line oc" title="7:94	This has been now an active research area for a couple of decades (Hindle, 1990; Lin, 1998; Weeds and Weir, 2003)." ></td>
	<td class="line x" title="8:94	This paper is motivated by one of the prominent applications of distributional similarity, namely identifying lexical expansions." ></td>
	<td class="line x" title="9:94	Lexical expansion looks for terms whose meaning implies that of a given target term, such as a query." ></td>
	<td class="line x" title="10:94	It is widely employed to overcome lexical variability in applications like Information Retrieval (IR), Information Extraction (IE) and Question Answering (QA).Often, distributionalsimilaritymeasuresare used to identify expanding terms (e.g.(Xu and Croft, 1996; Mandala et al., 1999))." ></td>
	<td class="line x" title="12:94	Here we denote the relation between an expanding term u and an expanded term v as u  v." ></td>
	<td class="line x" title="13:94	While distributional similarity is most prominently modeled by symmetric measures, lexical expansion is in general a directional relation." ></td>
	<td class="line x" title="14:94	In IR, for instance, a user looking for baby food will be satisfied with documents about baby pap or baby juice (pap  food, juice  food); but when looking for frozen juice she will not be satisfied by frozen food." ></td>
	<td class="line x" title="15:94	More generally, directional relations are abundant in NLP settings, making symmetric similarity measures less suitable for their identification." ></td>
	<td class="line x" title="16:94	Despite the need for directional similarity measures, their investigation counts, to the best of our knowledge, only few works (Weeds and Weir, 2003; Geffet and Dagan, 2005; Bhagat et al., 2007; Szpektor and Dagan, 2008; Michelbacher et al., 2007) and is utterly lacking." ></td>
	<td class="line x" title="17:94	From an expansion perspective, the common expectation is that the context features characterizing an expanding word should be largely included in those of the expanded word." ></td>
	<td class="line x" title="18:94	This paper investigates the nature of directional similarity measures." ></td>
	<td class="line x" title="19:94	We identify their desired properties, design a novel measure based on these properties, and demonstrate its empirical advantage in expansion settings over state-of-the-art measures1." ></td>
	<td class="line x" title="20:94	In broader prospect, we suggest that asymmetric measures might be more suitable than symmetric ones for many other settings as well." ></td>
	<td class="line x" title="21:94	2 Background The distributional word similarity scheme follows two steps." ></td>
	<td class="line x" title="22:94	First, a feature vector is constructed for each word by collecting context words as features." ></td>
	<td class="line x" title="23:94	Each feature is assigned a weight indicating its relevance (or association) to the given word." ></td>
	<td class="line x" title="24:94	Then, word vectors are compared by some vector similarity measure." ></td>
	<td class="line x" title="25:94	1Our directional term-similarity resource will be available at http://aclweb.org/aclwiki/index.php?" ></td>
	<td class="line x" title="26:94	title=Textual_Entailment_Resource_Pool 69 To date, most distributional similarity research concentrated on symmetric measures, such as the widely cited and competitive (as shown in (Weeds and Weir, 2003)) LIN measure (Lin, 1998): LIN(u,v) = summationtext fFVuFVv[wu(f) + wv(f)]summationtext fFVu wu(f) + summationtext fFVv wv(f) where FVx is the feature vector of a word x and wx(f) is the weight of the feature f in that words vector, set to their pointwise mutual information." ></td>
	<td class="line x" title="27:94	Few works investigated a directional similarity approach." ></td>
	<td class="line x" title="28:94	Weeds and Weir (2003) and Weeds et al.(2004) proposed a precision measure, denoted here WeedsPrec, for identifying the hyponymy relation and other generalization/specification cases." ></td>
	<td class="line x" title="30:94	It quantifies the weighted coverage (or inclusion) of the candidate hyponyms features (u) by the hypernyms (v) features: WeedsPrec(u  v) = summationtext fFVuFVv wu(f)summationtext fFVu wu(f) The assumption behind WeedsPrec is that if one word is indeed a generalization of the other then the features of the more specific word are likely to be included in those of the more general one (but not necessarily vice versa)." ></td>
	<td class="line x" title="31:94	Extending this rationale to the textual entailment setting, Geffet and Dagan (2005) expected that if the meaning of a word u entails that of v then all its prominent context features (under a certain notion of prominence) would be included in the feature vector of v as well." ></td>
	<td class="line x" title="32:94	Their experiments indeed revealed a strong empirical correlation between such complete inclusion of prominent features and lexical entailment, based on web data." ></td>
	<td class="line x" title="33:94	Yet, such complete inclusion cannot be feasibly assessed using an off-line corpus, due to the huge amount of required data." ></td>
	<td class="line x" title="34:94	Recently, (Szpektor and Dagan, 2008) tried identifying the entailment relation between lexical-syntactic templates using WeedsPrec, but observed that it tends to promote unreliable relations involving infrequent templates." ></td>
	<td class="line x" title="35:94	To remedy this, they proposed to balance the directional WeedsPrec measure by multiplying it with the symmetric LIN measure, denoted here balPrec: balPrec(uv)= radicalbig LIN(u,v)WeedsPrec(uv) Effectively, thismeasurepenalizesinfrequenttemplates having short feature vectors, as those usuallyyieldlowsymmetricsimilaritywiththelonger vectors of more common templates." ></td>
	<td class="line x" title="36:94	3 A Statistical Inclusion Measure Our research goal was to develop a directional similarity measure suitable for learning asymmetric relations, focusing empirically on lexical expansion." ></td>
	<td class="line x" title="37:94	Thus, we aimed to quantify most effectively the above notion of feature inclusion." ></td>
	<td class="line x" title="38:94	For a candidate pair u  v, we will refer to the set of us features, which are those tested for inclusion, as tested features." ></td>
	<td class="line x" title="39:94	Amongst these features, those found in vs feature vector are termed included features." ></td>
	<td class="line x" title="40:94	In preliminary data analysis of pairs of feature vectors, which correspond to a known set of valid and invalid expansions, we identified the following desired properties for a distributional inclusion measure." ></td>
	<td class="line x" title="41:94	Such measure should reflect: 1." ></td>
	<td class="line x" title="42:94	the proportion of included features amongst the tested ones (the core inclusion idea)." ></td>
	<td class="line x" title="43:94	2." ></td>
	<td class="line x" title="44:94	the relevance of included features to the expanding word." ></td>
	<td class="line x" title="45:94	3." ></td>
	<td class="line x" title="46:94	the relevance of included features to the expanded word." ></td>
	<td class="line x" title="47:94	4." ></td>
	<td class="line x" title="48:94	that inclusion detection is less reliable if the number of features of either expanding or expanded word is small." ></td>
	<td class="line x" title="49:94	3.1 Average Precision as the Basis for an Inclusion Measure As our starting point we adapted the Average Precision (AP) metric, commonly used to score ranked lists such as query search results." ></td>
	<td class="line x" title="50:94	This measure combines precision, relevance ranking and overall recall (Voorhees and Harman, 1999): AP = summationtextN r=1[P(r)  rel(r)] total number of relevant documents where r is the rank of a retrieved document amongst the N retrieved, rel(r) is an indicator function for the relevance of that document, and P(r) is precision at the given cut-off rank r. In our case the feature vector of the expanded word is analogous to the set of all relevant documentswhiletestedfeaturescorrespondtoretrieved documents." ></td>
	<td class="line x" title="51:94	Included features thus correspond to relevant retrieved documents, yielding the follow70 ing analogous measure in our terminology: AP(u  v) = summationtext|FVu| r=1 [P(r)  rel(fr)] |FVv| rel(f) = braceleftbigg 1, if f  FV v 0, if f / FVv P(r) = |included features in ranks 1 to r|r where fr is the feature at rank r in FVu." ></td>
	<td class="line x" title="52:94	This analogy yields a feature inclusion measure that partly addresses the above desired properties." ></td>
	<td class="line x" title="53:94	Its score increases with a larger number of included features (correlating with the 1st property), while giving higher weight to highly ranked features of the expanding word (2nd property)." ></td>
	<td class="line x" title="54:94	To better meet the desired properties we introduce two modifications to the above measure." ></td>
	<td class="line x" title="55:94	First, we use the number of tested features |FVu| for normalization instead of |FVv|." ></td>
	<td class="line x" title="56:94	This captures betterthenotionoffeatureinclusion(1st property), which targets the proportion of included features relative to the tested ones." ></td>
	<td class="line x" title="57:94	Second, in the classical AP formula all relevant documents are considered relevant to the same extent." ></td>
	<td class="line x" title="58:94	However, features of the expanded word differ in their relevance within its vector (3rd property)." ></td>
	<td class="line x" title="59:94	We thus reformulate rel(f) to give higher relevance to highly ranked features in |FVv|: relprime(f) = braceleftbigg 1  rank(f,FVv) |FVv|+1 ,if f  FVv 0 ,if f / FVv where rank(f,FVv) is the rank of f in FVv." ></td>
	<td class="line x" title="60:94	Incorporatingthesetwomodificationsyieldsthe APinc measure: APinc(uv)= summationtext|FVu| r=1 [P(r)  relprime(fr)] |FVu| Finally, we adopt the balancing approach in (Szpektor and Dagan, 2008), which, as explained in Section 2, penalizes similarity for infrequent words having fewer features (4th property) (in our version, we truncated LIN similarity lists after top 1000 words)." ></td>
	<td class="line x" title="61:94	This yields our proposed directional measure balAPinc: balAPinc(uv) = radicalbig LIN(u,v)  APinc(uv) 4 Evaluation and Results 4.1 Evaluation Setting We tested our similarity measure by evaluating its utility for lexical expansion, compared with baselines of the LIN, WeedsPrec and balPrec measures (Section 2) and a balanced version of AP (Section 3), denoted balAP." ></td>
	<td class="line x" title="62:94	Feature vectors were created by parsing the Reuters RCV1 corpus and taking the words related to each term through a dependency relation as its features (coupled with the relationnameanddirection, asin(Lin, 1998))." ></td>
	<td class="line x" title="63:94	We considered for expansion only terms that occur at least 10 times in the corpus, and as features only terms that occur at least twice." ></td>
	<td class="line x" title="64:94	As a typical lexical expansion task we used the ACE 2005 events dataset2." ></td>
	<td class="line x" title="65:94	This standard IE dataset specifies 33 event types, such as Attack, Divorce, and Law Suit, with all event mentions annotated in the corpus." ></td>
	<td class="line x" title="66:94	For our lexical expansion evaluation we considered the first IE subtask of finding sentences that mention the event." ></td>
	<td class="line x" title="67:94	For each event we specified a set of representative words (seeds), by selecting typical terms for the event (4 on average) from its ACE definition." ></td>
	<td class="line x" title="68:94	Next, for each similarity measure, the terms found similar to any of the events seeds (u  seed) were taken as expansion terms." ></td>
	<td class="line x" title="69:94	Finally, to measure the sole contribution of expansion, we removed from the corpus all sentences that contain a seed word and then extracted all sentences that contain expansion terms as mentioning the event." ></td>
	<td class="line x" title="70:94	Each of these sentences was scored by the sum of similarity scores of its expansion terms." ></td>
	<td class="line x" title="71:94	To evaluate expansion quality we compared the ranked list of sentences for each event to the goldstandard annotation of event mentions, using the standard Average Precision (AP) evaluation measure." ></td>
	<td class="line x" title="72:94	We report Mean Average Precision (MAP) for all events whose AP value is at least 0.1 for at least one of the tested measures3." ></td>
	<td class="line x" title="73:94	4.1.1 Results Table 1 presents the results for the different tested measures over the ACE experiment." ></td>
	<td class="line x" title="74:94	It shows that the symmetric LIN measure performs significantly worsethanthedirectionalmeasures, assessingthat a directional approach is more suitable for the expansion task." ></td>
	<td class="line x" title="75:94	In addition, balanced measures consistently perform better than unbalanced ones." ></td>
	<td class="line x" title="76:94	According to the results, balAPinc is the bestperforming measure." ></td>
	<td class="line x" title="77:94	Its improvement over all other measures is statistically significant according to the two-sided Wilcoxon signed-rank test 2http://projects.ldc.upenn.edu/ace/, training part." ></td>
	<td class="line x" title="78:94	3The remaining events seemed useless for our comparative evaluation, since suitable expansion lists could not be found for them by any of the distributional methods." ></td>
	<td class="line x" title="79:94	71 LIN WeedsPrec balPrec AP balAP balAPinc 0.068 0.044 0.237 0.089 0.202 0.312 Table 1: MAP scores of the tested measures on the ACE experiment." ></td>
	<td class="line x" title="80:94	seed LIN balAPinc death murder, killing, incident, arrest, violence suicide, killing, fatality, murder, mortality marry divorce, murder, love, divorce, remarry, dress, abduct father, kiss, care for arrest detain, sentence, charge, jail, convict detain, extradite, round up, apprehend, imprison birth abortion, pregnancy, wedding day, resumption, seizure, dilation, birthdate, passage circumcision, triplet injure wound, kill, shoot, wound, maim, beat detain, burn up, stab, gun down Table 2: Top 5 expansion terms learned by LIN and balAPinc for a sample of ACE seed words." ></td>
	<td class="line x" title="81:94	(Wilcoxon, 1945) at the 0.01 level." ></td>
	<td class="line x" title="82:94	Table 2 presents a sample of the top expansion terms learned for some ACE seeds with either LIN or balAPinc, demonstrating the more accurate expansions generated by balAPinc." ></td>
	<td class="line x" title="83:94	These results support the design of our measure, based on the desired properties that emerged from preliminary data analysis for lexical expansion." ></td>
	<td class="line x" title="84:94	Finally, we note that in related experiments we observed statistically significant advantages of the balAPincmeasureforanunsupervisedtextcategorization task (on the 10 most frequent categories in the Reuters-21578 collection)." ></td>
	<td class="line x" title="85:94	In this setting, category names were taken as seeds and expanded by distributional similarity, further measuring cosine similarity with categorized documents similarly to IR query expansion." ></td>
	<td class="line x" title="86:94	These experiments fall beyond the scope of this paper and will be included in a later and broader description of our work." ></td>
	<td class="line x" title="87:94	5 Conclusions and Future work Thispaperadvocatestheuseofdirectionalsimilarity measures for lexical expansion, and potentially forothertasks, basedondistributionalinclusionof feature vectors." ></td>
	<td class="line x" title="88:94	We first identified desired properties for an inclusion measure and accordingly designed a novel directional measure based on averaged precision." ></td>
	<td class="line x" title="89:94	This measure yielded the best performance in our evaluations." ></td>
	<td class="line x" title="90:94	More generally, the evaluations supported the advantage of multiple directional measures over the typical symmetric LIN measure." ></td>
	<td class="line x" title="91:94	Error analysis showed that many false sentence extractions were caused by ambiguous expanding and expanded words." ></td>
	<td class="line x" title="92:94	In future work we plan to apply disambiguation techniques to address this problem." ></td>
	<td class="line x" title="93:94	Wealsoplantoevaluatetheperformance of directional measures in additional tasks, and compare it with additional symmetric measures." ></td>
	<td class="line x" title="94:94	Acknowledgements This work was partially supported by the NEGEV project (www.negev-initiative.org), the PASCAL2 Network of Excellence of the European Community FP7-ICT-2007-1-216886 and by the Israel Science Foundation grant 1112/08." ></td>
</tr></table>
</div
</body></html>
