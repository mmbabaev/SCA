Until just a few years ago, when citation information was needed the single most comprehensive source was the ISI Citation Indexes. Although the Citation Indexes were often criticized for various reasons, there was no other source to rely on. Data from the ISI Citation Indexes and the Journal Citation Reports are routinely used by promotion committees at universities all over the world. In this paper we refer to the Web version of Citation Indexes, i.e., to the Web of Science (WOS) (http://portal.isiknowledge.com/portal.cgi?DestApp=WOS&Func=Frame).Recently two alternatives to the ISI Citation Indexes have become available. One of them is Scopus (http://www.scopus.com/) developed by Elsevier and the other is the freely available Google Scholar (http://scholar.google.com/). Each of these has aReceived February 12, 2007Address for correspondence:JUDIT BAR-ILANDepartment of Information Science, Bar-Ilan University Ramat Gan, 52900, IsraelE-mail: barilaj@mail.biu.ac.il0138–9130/US $ 20.00Copyright © 2007 Akadémiai Kiadó, Budapest All rights reserved 
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google Scholardifferent collection policy which affects both the publications covered and the number of citations to the publications. How different are these citation databases? In this paper we tried to provide a partial answer by considering the h-indexes [HIRSCH, 2005A, B] of a group of highly cited researchers based on each of the three citation databases.Literature reviewComparing the databasesThe Science Citation Index was first published in print in 1963 with citation data from 1961 [GARFIELD, 1963]. “The Web of Science provides seamless access to current and retrospective multidisciplinary information from approximately 8,700 of the most prestigious, high impact research journals in the world.” [THOMSON SCIENTIFIC, NO DATE]. The references from all the indexed items are extracted and the cited reference interface lists all citation to works of an author regardless of whether the cited items are indexed by WOS or not.Until very recently, the Web of Science was the only comprehensive database to provide citation data. However, in November 2004 the citation database scenery changed considerably at once by the launching of Scopus on November 3, 2004 [REED ELSEVIER, 2004] and Google Scholar on November 18, 2004 [PAYNE, 2004]. Scopus provides full citation coverage from 1996 and onwards, and claims to be “the largest abstract and citation database of research literature and select results from the web. Scopus covers 27 million abstracts, 230 million references and 200 million web pages” [SCOPUS, NO DATE]. Scopus provides citation data only for the items indexed by it.Google, probably on purpose, does not provide any explicit information either about the number of records or about its time coverage. Google Scholar, unlike WOS and Scopus, is freely accessibly. They index data from publishers only if the publisher is willing to provide at least the abstract of the paper freely [GOOGLE SCHOLAR, 2005] – viewing the full text may be fee or subscription based. The data comes from other sources as well, like freely available full text from preprint servers or personal websites as well, thus in many cases the full text is freely available for all users. References are automatically extracted from the full text of the indexed items. In case the reference itself is not indexed by Google Scholar, only the number of citation to that item appear in the search results.Google Scholar was and is received with mixed feelings. For example, GILES [2005] reports: “Although there are no detailed studies, many librarians report that faculty members and students are beginning to use the search engine; some suspect that Scholar will replace more established, and more costly, search tools. It already directs more online traffic to Nature websites than any other multidisciplinary science search engine.” [GILES, 2005 : 554]. Librarians seem to be less enthusiastic than their clients:258 Scientometrics 74 (2008)
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google Scholarin the summer of 2005 only a minority of the 113 ARL library sites linked to Google Scholar [MULLEN & HARTMAN, 2006].Evaluation studies, mainly comparing Google Scholar (GS) with the Web of Science (WOS) had mixed results as well. In an early study, BAUER & BAKKALBASI [2005] analyzed the citation counts of JASIST articles published in 1985 and 2000. The results for 1985 were inconclusive, but for 2000, the citation counts in GS were considerably higher than either in WOS or in Scopus. They conclude: “Based on our preliminary examination and discovery of higher citation counts, we recommend that researchers should consult Google Scholar in addition to Web of Science or Scopus, especially for a relatively recent article, author or subject area.” Indeed when we carried out the literature search on the h-index for this paper, Google Scholar retrieved a considerably larger number of items than either from WOS or Scopus. However, one must note that a large number of these references were to preprint repositories. Preprint repositories allow researchers to become updated on recent developments, but they should be evaluated with care, since they are not peer-reviewed publications. JACSO [2006] criticizes the attention the BAUER & BAKKALBASI [2005] article received by the media (news and blogs), where only the results for 2000, based on 105 articles were highlighted.Jacso emphasizes shortcomings of Google Scholar in several articles; he shows inconsistencies in Google Scholar. For example [JACSO, 2006] one of the most prolific authors according to Google Scholar is “I Introduction” with 40,100 reported documents authored by him/her. We rerun the test on November 4, 2006 – the number of items authored by “I Introduction” (the number of results for the query author:”I Introduction”) increased to 689,000 (!). Another example, more related to informetrics and webometrics was located by us, when we looked for the Almind & Ingwersen article “Informetric analyses on the World Wide Web”. Google Scholar indexed this article which was published in the Journal of Documentation in 1997, and reports that it was cited 197 times (as of November 4, 2006), however Google Scholar is sure that the paper was authored by D. Copenhagen (see Figure 1). Citation counts are deflated both in WOS and in GS, when citations are not grouped together. This is especially emphasized for WOS, which counts exact matches only, as can be seen when carrying out a cited reference search. On the other hand, citations are sometimes inflated in Google Scholar, since [JACSO, 2006] it indexes non-scholarly sources as well. Google Scholar often indexes both the preprint and the journal version of a paper (see Figure 2 for an interesting example we found). What should be the true citation count in this case? The sum of the two counts? A closer examination of the citing papers show that often both sources are cited side-by-side, and it is hard to imagine that the citing authors meant to count both citations separately. A possible exception is the current paper we cited both the journal and the preprint version of the HIRSCH paper [2005A, B] on purpose. The issue of multiple manifestations of a work was discussed extensively in [BAR-ILAN, 2006].Scientometrics 74 (2008) 259
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google ScholarFigure 1. A highly cited paper by “D Copenhagen”JACSO [2006] also notes that neither the Boolean operators nor the range operator (for limiting the date of publication) work properly in GS. These problems are probably directly “inherited” from Google [BAR-ILAN, 2005]. Google Scholar is not always able to correctly identify the publication year of the item, and citations are not always attributed to the correct publication [JACSO, 2006, 2005A]. JACSO [2006] concludes that Google Scholar cannot be a substitute for WOS, unlike the conclusion of PAULY & STERGIOU [2005] based on testing the citation counts of 114 papers from different scientific disciplines. RAHM & THOR [2005] point out the usefulness of Google Scholar in evaluations in the area of computer science. Note that in computer science a major publication venue are proceedings that are only very partially indexed by the Web of Science [BAR-ILAN, 2006; VISSER & MOED, 2005, 2006]. GARDNER & ENG [2006] compared Google Scholar with well-known Social Science databases, and although aware of its current shortcomings, they conclude that “Google Scholar is still in beta testing, so it has the potential to improve significantly before it becomes fully operational”.JACSO [2005A] examined citations received between 1996–2005 for Garfield’s 1955 paper in Science: WOS listed 83 citations, Scopus 76 citations and Google Scholar 82; however only 33 of the citing items appeared in all three databases – showing that citation counts are not everything. KOUSHA & THELWALL [2006B] also found that the overlap of citing documents between WOS and Google Scholar is rather low in some cases (only 33% for chemistry). In terms of the number of indexed items (unknown for GS), JACSO [2005A] found that Scopus overtakes WOS by 2000. It seems that Google Scholar does not fully index items on its partner sites, as demonstrated by JACSO [2005B] and by the search interface specially developed by Peter Jacso to illustrate the260 Scientometrics 74 (2008) 
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google Scholarspotty coverage (available at http://www2.hawaii.edu/~jacso/scholarly/side-by- side2.htm). Rather interestingly, NEUHAUS & AL. [2006] found excellent coverage in the sciences and the life science – 100% for PubMed, and only complained about the low coverage in the Social Science. On the other hand, KOUSHA & THELWALL [2006A] found good coverage of the Social Sciences. NORUZI [2005] studied the citation counts reported by WOS and Google Scholar on a set of webometrics papers: in most cases GS had higher citation counts than WOS. These findings are supported by the results of VAUGHAN & SHAW [2006] for Information Science in general. BELEW [2005] tested the citation counts of 203 publications reported by WOS and Google Scholar respectively, and found “surprisingly good agreement between data citation counts provided by the two services”. SMITH’S [2006] results show that there is high correlation between the Google Scholar citation counts and New Zealand’s Performance Based Research Funding research assessment exercise.BAKKALBASI & AL. [2006] compared citation counts reported by WOS, Scopus and GS, to publications in twenty two journals in oncology and in condensed matter physics published in 1993 and 2003. The results varied with publication year and discipline, and the findings could not “identify any of these three resources as the answer to all citation tracking needs”. BAR-ILAN & AL. [2007] compared the rankings of the publications of highly-cited Israeli researchers induced by the citations counts reported by WOS, Scopus and Scholar. The computed measures show high similarity between Scopus and WOS and lower similarities between Google Scholar and the other tools, indicating that Google Scholar’s coverage is considerably different from that of WOS and Scopus.A few studies compared WOS with Scopus – they emphasize the wider coverage (in terms of the number of indexed publications), the user friendliness and the shorter time span of Scopus when compared with WOS [JACSO, 2004; LAGUARDIA, 2005; DEIS & GOODMAN, 2005; BURNHAM, 2006].The h-indexThe new bibliometric measure, the h-index was introduced by Jorge Hirsch in August 2005 [HIRSCH, 2005A, B], and it is defined as followsA scientist has index h if h of his/her Np papers have at least h citations each, and the other (Np   h) papers have no more than h citations each [HIRSCH, 2005B : 16569].The new measure raised considerable interest in informetric circles and in a short period of time, a considerable number of publications discussed and further developed the ideas introduced by Hirsch.The h-index was applied to compare scientists. HIRSCH [2005A, B] calculated the h-indices of prominent physicists. GLÄNZEL & PERSSON [2005] computed the h-indexScientometrics 74 (2008) 261
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google Scholarfor Price medalists based on data from the Web of Science, BAR-ILAN [2006B] recomputed the values for the same list of people based on data from Google Scholar. CRONIN & MEHO [2006] computed the h-indices of prominent American information scientists, BUTLER & MCALLISTER [2006] studied the applicability of the h-index for researchers in the Social Sciences, SAAD [2006] compared data obtained from WOS and GS for consumer scholars, BORNMANN & DANIEL [2005] studied the relation between the h-index and the acceptance of post-doctoral grants.VAN RAAN [2005] and MOED [2005] prefer to consider the research group as the basic unit for computing the h-index. A number of researchers noted that one should take into account the scientific ages of the authors when calculating the h-index, since researchers who have been around for a longer time, have better chances of having high h-indexes (see [EGGHE, 2006A; KELLY & JENNIONS, 2006; LIANG, 2006]). H-index for journals was introduced by BRAUN & AL. [2005 & 2006]. ROUSSEAU [2006A] calculated the h-index of JASIS and also studied the effect of time on the h-index. SCHUBERT & GLÄNZEL [2006] found through regression analysis a definite relationship between the IF and the h-index for journal. In contrast, MILLER [2006] concluded that for physics periodicals there is no correlation between the IF and the h-index. COSTAS & BORDONS [2006] found good correlations between the h-index and number of publications and the number of citations of individuals. BANKS [2006] applied the concept to compound names and scientific topics in publications.Models for the h-index have also been proposed (see [EGGHE & ROUSSEAU, 2006; GLÄNZEL, 2006; ROUSSEAU, 2006B; BURRELL, 2006]). Some researchers recommend different types of improvements to the h-index [BATISTA & AL., 2006; EGGHE, 2006B; SIDIROPOULUS & AL., 2006; IGLESIAS & PECHORROMAN, 2006]. Finally, as usual, there is also criticism regarding the new measure [PURVIS, 2006].MethodsFor this study, we used the ISI HighlyCited database (http://isihighlycited.com/) as our starting point, which lists 47 Israeli researchers as of November 2006. Even though this list can be criticized – for example it does not include any of the three Israeli Nobel Prize winners in the last two years – it is a list published by a highly respected institution.A few researchers from the list for whom it was extremely difficult to disambiguate their work from works of others with the same or similar name, were excluded from further analysis, and the names of the three recent Nobel Prize winners were added. The final list was comprised of 40 names. The name of each researcher was searched in ISI’s Web of Science (time span: 1996–2006), Elsevier’s Scopus (1996 to present) and Google Scholar (queries of the type author: “J Doe”), with publication dates limited to 1996–2006. We had to limit the publication years from 1996 and onwards since Scopus262 Scientometrics 74 (2008)
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google Scholarhas complete citation data from 1996 and onwards, and we wanted to compare the three citation databases on a “fair” basis. In a few cases there were no or almost no publications during this period, since the ISI Highly-cited databases is based on citation data for publications of the listed researchers between 1981 and 1999 [ISI HIGHLYCITED.COM, NO DATE_A; ISI HIGHLYCITED.COM, NO DATE_B].We searched WOS only through its “General search” interface where the citation counts are only for items indexed by WOS, and citations to items that do not exactly match the indexed citation are ignored. More complete (but much more time consuming) citation counts could have been achieved had we consulted the “Cited reference search” as well (like in [CRONIN & MEHO, 2006]). Most other h-index studies to this day relied on the results of the “General search” interface only.The result sets were sorted by times cited, and the bibliographic details of all the publications that received more citations than the h-index of the author as defined by the specific database were downloaded.The next step was data cleansing, especially for Google Scholar. When providing the initial and the family name of an author, it retrieves publications by authors whose initials are included in the specified initial, for example when searching for author: “L Gillis”, papers published by HL Gillis and LL Gillis are also retrieved (see Figure 3).Figure 2. Multiple manifestations of a work not grouped togetherScientometrics 74 (2008) 263 
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google ScholarFigure 3. Google Scholar allows inexact matches for the authors’ initialsGoogle Scholar is not clean of mistakes either, as can be seen from the literauter review above. Data for the publications of Avi Wigderson was collected from Google Scholar on January 16, 2006 – at them time the top cited item was “Probabilistic encryption” cited 915 times. This item was incorrectly attributed to Avi Wigderson (a mistake that has been corrected since). There are also examples where highly cited publications do not appear when searching for an author. Consider, for example the previously mentioned case of author:“P Ingwersen” (see Figure 1). In some cases the same publication is listed more than once, in these cases the citation counts were combined.In addition, Google Scholar often incorrectly identifies the publication date of the item. This happened especially frequently with publications of the American Physical Society – thus we had to check each item on the Google Scholar lists, to make sure that the item was actually published after 1996, and it was indeed authored by the specific scientist. We had to double-check the title of the item as well – in some cases it was incorrect, while in other cases it was shortened, and for a few authors (especially in high-energy physics) the initial part of two or more papers are identical, for example (1) Ackerstaff et al. QCD studies with e(+)e(–) annihilation data at 161 GeV and (2) Abbiendi et al. QCD studies with e(+)e(–) annihilation data at 172–189 GeV.Searching Scopus was not entirely straightforward either. Although it has an “Author search” interface, where an attempt is made to group together items published264 Scientometrics 74 (2008) 
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google Scholarby the same author (i.e., to differentiate between two or more authors with the same name), the system is not always successful. Thus we preferred to search through the “Basic search” interface and to search using only the initials of the authors. However, unlike WOS, searching for an author with a single letter initial retrieves publications of all authors with the same surname and the specific letter appearing as one of the initials. Thus data cleansing had to be done for Scopus as well. Note that Scopus does not index all the authors of a publication (only the first one hundred). A maximum of one hundred authors is sufficient under regular circumstances, but not for high-energy physics publications (e.g., the OPAL or ATLAS groups).Results and discussionTable 1 displays the selected scientists, their research field(s) as defined by ISI and their h-indices for the period 1996-to present (2006) computed based on WOS, Scopus and Google Scholar respectively. The table contains 40 names – 37 from the 47 Israeli highly cited researchers, as defined by ISI (ten names were excluded because of the difficulty in disambiguating their publications from publications of other researchers with identical names or because they had no publications in the 1996–2006 period) and the three recent Israeli Nobel prize winners – Robert Aumann (economics, 2005), Aaron Ciechanover and Avram Hershko (chemistry, 2004).Recall that ISI created the list of highly cited researchers based on citations for publications between 1981 and 1999, and we computed the h-indices based on publications from 1996 and onwards. During this period some of the previously highly cited researchers were inactive or relatively inactive and had much lower publication and citation counts. We had to base our computations on the 1996–2006 period, because Scopus provides full citation information only for items published after 1995.Except for a few cases the differences in the h-indices between WOS and Scopus are not significant, except for Mikenberg and Wigderson. Avi Wigderson is a theoretical computer scientist and Scopus, unlike WOS, indexes the two major theoretical computer science conference series, STOC and FOCS which explains the difference in the h indices. The case of Giora Mikenberg is rather interesting: in the list of highly cited Israeli researchers, there are three high-energy physicists, Alexander, Duchovni and Mikenberg all three of them are members of both the OPAL and ATLAS (http://atlas.web.cern.ch/Atlas/index.html) groups (each with hundreds of members) where all members of these groups author all (or most) their publications. Alexander and Duchovni are among the first one hundred authors indexed by Scopus, while Mikenberg is not. The authors are usually listed in alphabetical order, WOS indexes all the authors, and this is the major reason for the huge difference between the number of items indexed by WOS and Scopus for Mikenberg.Scientometrics 74 (2008) 265
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google ScholarTable 1. H-index according to WoS, Scopus and Google Scholar for highly cited Israeli researchers for 1996–2006  ResearcherAlexander, Gideon Alon, Noga Aumann, Robert J. Aurbach, Doron Beeri, CatrielChet, Ilan Ciechanover, Aaron Cohen, Irun R. Dagan, Gedeon Dekel, Avishai Dolev, Daniel Duchovni, Ehud Geiger, Benjamin Gohberg, Israel Goldreich, Oded Harel, David Hershko, Avram Hochberg, Yosef Jortner, Joshua Kanner, Joseph Kerem, Batsheva Kotler, Burt P. Leviatan, Yehuda Lubotzky, Alex Mechoulam, Raphael Mikenberg, Giora Moran, Shlomo Netzer, HagaiOren, Moshe Peleg, David Piran, Tsvi Pnueli, Amir Procaccia, Itamar Shainberg, Isaac Shamai, Shlomo Sharir, Micha Shelah, Saharon Sklan, David Turkel, Eli Wigderson, AviCategoryWoS ScopusGoogle Scholar20 27 11 19       8      20      30      26      12      24      18      15      31      11      32      22      21       7      21       6      18       9       5      10      26       4      11      18      38      21      33      23      18       9      20      17      15      15      11      23  PhysicsMathematics, Computer ScienceMathematicsMaterials ScienceComputer SciencePlant & Animal ScienceBiology & BiochemistryImmunologyEngineering, Ecology/EnvironmentSpace SciencesComputer SciencePhysicsMolecular Biology & GeneticsMathematicsComputer ScienceComputer ScienceBiology & BiochemistryMathematicsChemistryAgricultural SciencesMolecular Biology & GeneticsEcology/EnvironmentComputer ScienceMathematicsPharmacologyPhysicsComputer ScienceSpace SciencesMolecular BiologyComputer ScienceSpace SciencesComputer SciencePhysicsEcology/EnvironmentComputer ScienceEngineering, Computer ScienceMathematicsAgricultural SciencesMathematics 9Computer Science 8 13& Genetics32 30 14 17 8 6 29 29 3 3 21 21 33 34 29 32 13 14 25 25 5 7 32 29 34 33 8 8 12 14 9 10 21 21 4 4 26 26 9 9 20 19 10 10 6 5 5 5 28 29 31 10 7 6 28 28 47 49 8 11 32 32 11 8 18 19 8 10 16 17 13 15 10 10 18 20 9  The differences between GS and the two other databases are much more considerable. We partitioned the researchers into three groups:2661. 2.The GS h-index is at least 30% lower than the average of the h indices based on WOS and Scopus.The GS h-index is at least 30% higher than the average of the h indices based on WOS and Scopus.Scientometrics 74 (2008)
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google Scholar3. The GS h-index is between 0.7 and 1.3 times the average of the h indices based on WOS and Scopus.We call the first group low, the second high and the third the same. The high group is comprised entirely of mathematicians and computer scientists. All, except one of the mathematicians and all except two of the computer scientists belong to this group. The exceptions Leviatan, Shamai, and Turkel belong to the same group. Thus there seems to be a discipline specific bias here. For computer science this can be explained by the prevalence of peer-reviewed conference proceedings publications that are highly cited and highly valued. Often the computer science researchers do not submit full versions of their conference papers to journals. Thus proceedings are the major citing and cited venue for computer science. WOS, with the exception of the Lecture Notes in Computer Science and the Lecture Notes in Artificial Intelligence series, does not index computer science proceedings. Scopus indexes a much larger set of computer science conference proceedings (the list can be downloaded from http://www.info.scopus.com/detail/what/titlelistinfo.htm) but still seemingly it covers fewer publications in computer science than GS. GS also indexes Technical Reports, which are sometimes highly cited items as well. For example, the most highly cited publication of Amir Pnueli, is “The temporal logic of programs”, a Technical Report, which was cited 1094 times according to Google Scholar (as of November 11, 2006).All three high-energy physicists are in the low group, which is rather surprising, especially since physicists usually submit their preprints to arxiv.org and Google Scholar indexes arxiv.org extensively.H-index only provides partial information, if a researcher has an h-index h, we can be sure that his publications received at least h2 citations, but the actual number could be much higher. In Table 2 we display the number of citations to the top-h publications for each researcher based on WOS, Scopus and GS respectively.Even for researchers with comparable h-indices for WOS, Scopus and Google Scholar, there can be differences in the citation counts. Note that the citation counts were calculated only for the top h documents (for the h of the specific database and the author). For example for Avram Hersho, the citation count for Google Scholar is about 20% lower than for the other two databases. On the other hand, in some cases the citation counts for GS are much higher than for the other databases. Consider, for example David Harel: only 188 citations in WOS versus 3374 citations in GS. His h-index in WOS is 9 versus 33 in GS, thus some of the increase in the number of citations can be expected. A researcher with h-index 9 is expected to receive at least 81 citations to the top cited publications. Harel actually received 188 citations based on WOS, i.e. 2.32 times more than the minimum for an h-index of 9. Harel’s h-index, according to GS is 22, thus he should have received a minimum of 484 citations to these 22 items. The actual number of citations is 6.97 times higher than the minimum.Scientometrics 74 (2008) 267
J. BAR-ILAN: Which h-index? – A comparison of WoS, Scopus and Google ScholarTable 2. H-index and the number of citations to the h most highly cited publications according to WoS, Scopus and Google Scholar for highly cited Israeli researchers for 1996–2006 ResearcherAlexander, Gideon Alon, Noga Aumann, Robert J. Aurbach, Doron Beeri, CatrielChet, Ilan Ciechanover, Aaron Cohen, Irun R. Dagan, Gedeon Dekel, Avishai Dolev, Daniel Duchovni, Ehud Geiger, Benjamin Gohberg, Israel Goldreich, Oded Harel, David Hershko, Avram Hochberg, Yosef Jortner, Joshua Kanner, Joseph Kerem, Batsheva Kotler, Burt P. Leviatan, Yehuda Lubotzky, Alex Mechoulam, Raphael Mikenberg, Giora Moran, Shlomo Netzer, HagaiOren, Moshe Peleg, David Piran, Tsvi Pnueli, Amir Procaccia, Itamar Shainberg, Isaac Shamai, Shlomo Sharir, Micha Shelah, Saharon Sklan, David Turkel, Eli Wigderson, Avi# cits. # cits.h-WOS WOS h-Scopus Scopus h-GS# cits. GS Thus we see that the average number of citations the top h items received in GS (153.4 citations) is much higher than the average number of citations per item when the calculations are based on WOS (20.9 citations). One has to take into account that the sources and the validity of the citations in GS were not examined in this study